reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.enable
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.enable
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-741771151-172.17.0.12-1596932352804:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37704,DS-d187231f-39dd-418f-842b-6fea817133d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38645,DS-1b4bfded-a999-4a0e-8fe2-1e99b3c9892c,DISK], DatanodeInfoWithStorage[127.0.0.1:41226,DS-8dbc97d5-e579-43b4-995b-9beafad7d0cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38210,DS-c0d456e2-b330-49dd-aed9-5539e1e2f5a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41256,DS-2c51d8f0-8a14-487b-94be-10d057f87e44,DISK], DatanodeInfoWithStorage[127.0.0.1:32905,DS-e8a3cea0-dbfd-49f5-931a-06ef8b529ee8,DISK], DatanodeInfoWithStorage[127.0.0.1:33778,DS-4a85c7a0-cffb-4303-9170-7a75e2421b72,DISK], DatanodeInfoWithStorage[127.0.0.1:42772,DS-ff76949f-73c9-499d-96c5-cce898957839,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-741771151-172.17.0.12-1596932352804:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37704,DS-d187231f-39dd-418f-842b-6fea817133d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38645,DS-1b4bfded-a999-4a0e-8fe2-1e99b3c9892c,DISK], DatanodeInfoWithStorage[127.0.0.1:41226,DS-8dbc97d5-e579-43b4-995b-9beafad7d0cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38210,DS-c0d456e2-b330-49dd-aed9-5539e1e2f5a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41256,DS-2c51d8f0-8a14-487b-94be-10d057f87e44,DISK], DatanodeInfoWithStorage[127.0.0.1:32905,DS-e8a3cea0-dbfd-49f5-931a-06ef8b529ee8,DISK], DatanodeInfoWithStorage[127.0.0.1:33778,DS-4a85c7a0-cffb-4303-9170-7a75e2421b72,DISK], DatanodeInfoWithStorage[127.0.0.1:42772,DS-ff76949f-73c9-499d-96c5-cce898957839,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.enable
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-608302491-172.17.0.12-1596932389350:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41588,DS-7aa1c6bc-a895-49f1-959b-5b2dac74743e,DISK], DatanodeInfoWithStorage[127.0.0.1:37793,DS-1a98d139-10f9-4e15-95f7-2b188ccfe8b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38764,DS-f89dd4cd-86f9-4661-8e28-5f422e846833,DISK], DatanodeInfoWithStorage[127.0.0.1:34695,DS-fe90a35b-a5bf-4701-b948-4afd57ff5413,DISK], DatanodeInfoWithStorage[127.0.0.1:42619,DS-b961997d-875e-40db-849f-0f7357396802,DISK], DatanodeInfoWithStorage[127.0.0.1:46081,DS-b04919b7-b9d1-4783-8208-4542fc37092a,DISK], DatanodeInfoWithStorage[127.0.0.1:46485,DS-81510985-c2c9-4fc1-8bc3-0488753f15c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38812,DS-629407eb-7dad-4fd4-8bce-7bebaad8ecf7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-608302491-172.17.0.12-1596932389350:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41588,DS-7aa1c6bc-a895-49f1-959b-5b2dac74743e,DISK], DatanodeInfoWithStorage[127.0.0.1:37793,DS-1a98d139-10f9-4e15-95f7-2b188ccfe8b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38764,DS-f89dd4cd-86f9-4661-8e28-5f422e846833,DISK], DatanodeInfoWithStorage[127.0.0.1:34695,DS-fe90a35b-a5bf-4701-b948-4afd57ff5413,DISK], DatanodeInfoWithStorage[127.0.0.1:42619,DS-b961997d-875e-40db-849f-0f7357396802,DISK], DatanodeInfoWithStorage[127.0.0.1:46081,DS-b04919b7-b9d1-4783-8208-4542fc37092a,DISK], DatanodeInfoWithStorage[127.0.0.1:46485,DS-81510985-c2c9-4fc1-8bc3-0488753f15c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38812,DS-629407eb-7dad-4fd4-8bce-7bebaad8ecf7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.enable
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-235197601-172.17.0.12-1596932933276:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35587,DS-386f9402-7248-4af5-ad29-78bdc07267d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44017,DS-a3a19eaf-9a34-4613-9e3d-517f96018ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:38621,DS-7d3b94c8-1371-480b-a8e9-069654f91f9e,DISK], DatanodeInfoWithStorage[127.0.0.1:38802,DS-8cb572b5-d948-4338-8329-e81ded11b6ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45807,DS-115c2686-1a75-4171-926e-70275d99d8ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40042,DS-ae0891fa-9e43-44d6-8ce8-90e2bea70560,DISK], DatanodeInfoWithStorage[127.0.0.1:36672,DS-00b58a0f-abf4-4fde-af0c-37ac0ea51dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:46521,DS-7a4ef6ca-fc58-4690-a99d-0e01d23bd410,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-235197601-172.17.0.12-1596932933276:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35587,DS-386f9402-7248-4af5-ad29-78bdc07267d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44017,DS-a3a19eaf-9a34-4613-9e3d-517f96018ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:38621,DS-7d3b94c8-1371-480b-a8e9-069654f91f9e,DISK], DatanodeInfoWithStorage[127.0.0.1:38802,DS-8cb572b5-d948-4338-8329-e81ded11b6ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45807,DS-115c2686-1a75-4171-926e-70275d99d8ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40042,DS-ae0891fa-9e43-44d6-8ce8-90e2bea70560,DISK], DatanodeInfoWithStorage[127.0.0.1:36672,DS-00b58a0f-abf4-4fde-af0c-37ac0ea51dbb,DISK], DatanodeInfoWithStorage[127.0.0.1:46521,DS-7a4ef6ca-fc58-4690-a99d-0e01d23bd410,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.enable
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-224684492-172.17.0.12-1596933269591:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37681,DS-b0a1dcb3-846e-484b-858e-d45237ea3af4,DISK], DatanodeInfoWithStorage[127.0.0.1:40306,DS-21363535-de63-49e6-972a-a8e541dbfa0e,DISK], DatanodeInfoWithStorage[127.0.0.1:36692,DS-43349e98-69b0-4d7c-8fdc-4aae30479794,DISK], DatanodeInfoWithStorage[127.0.0.1:42711,DS-3d36cfb2-b67e-495d-8201-70757677bc65,DISK], DatanodeInfoWithStorage[127.0.0.1:34282,DS-d8c33e39-77ba-4de9-96aa-b5a9d1f7ff2e,DISK], DatanodeInfoWithStorage[127.0.0.1:43799,DS-d6b1be69-cf29-4788-bb7d-1879ce680b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:44784,DS-96d5907d-75cb-4c99-ad79-15df7f22e2a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43290,DS-220c415f-4176-42fe-85d3-b3e6d4ace6bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-224684492-172.17.0.12-1596933269591:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37681,DS-b0a1dcb3-846e-484b-858e-d45237ea3af4,DISK], DatanodeInfoWithStorage[127.0.0.1:40306,DS-21363535-de63-49e6-972a-a8e541dbfa0e,DISK], DatanodeInfoWithStorage[127.0.0.1:36692,DS-43349e98-69b0-4d7c-8fdc-4aae30479794,DISK], DatanodeInfoWithStorage[127.0.0.1:42711,DS-3d36cfb2-b67e-495d-8201-70757677bc65,DISK], DatanodeInfoWithStorage[127.0.0.1:34282,DS-d8c33e39-77ba-4de9-96aa-b5a9d1f7ff2e,DISK], DatanodeInfoWithStorage[127.0.0.1:43799,DS-d6b1be69-cf29-4788-bb7d-1879ce680b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:44784,DS-96d5907d-75cb-4c99-ad79-15df7f22e2a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43290,DS-220c415f-4176-42fe-85d3-b3e6d4ace6bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.enable
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1299194019-172.17.0.12-1596933562603:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38949,DS-794d8dc7-1dab-4d8a-a231-773237d8c289,DISK], DatanodeInfoWithStorage[127.0.0.1:43787,DS-e7622a5c-3e2b-46e6-b28a-047c53ec0006,DISK], DatanodeInfoWithStorage[127.0.0.1:44467,DS-8b56cb47-d64b-4961-a85e-de23be00b67d,DISK], DatanodeInfoWithStorage[127.0.0.1:39055,DS-06dffbd2-d4bf-4ff6-83d1-d6d980db2d89,DISK], DatanodeInfoWithStorage[127.0.0.1:42405,DS-20d8a004-3949-4915-8e13-39e0e22a4b60,DISK], DatanodeInfoWithStorage[127.0.0.1:37559,DS-20cfd9f7-cda5-4e67-a411-f5a5d7f25925,DISK], DatanodeInfoWithStorage[127.0.0.1:45824,DS-51f4d18c-2983-48fa-a3f1-b03719049ec2,DISK], DatanodeInfoWithStorage[127.0.0.1:35063,DS-ebdf9dcf-fae7-4a5b-b9c7-f81993c2e1f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1299194019-172.17.0.12-1596933562603:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38949,DS-794d8dc7-1dab-4d8a-a231-773237d8c289,DISK], DatanodeInfoWithStorage[127.0.0.1:43787,DS-e7622a5c-3e2b-46e6-b28a-047c53ec0006,DISK], DatanodeInfoWithStorage[127.0.0.1:44467,DS-8b56cb47-d64b-4961-a85e-de23be00b67d,DISK], DatanodeInfoWithStorage[127.0.0.1:39055,DS-06dffbd2-d4bf-4ff6-83d1-d6d980db2d89,DISK], DatanodeInfoWithStorage[127.0.0.1:42405,DS-20d8a004-3949-4915-8e13-39e0e22a4b60,DISK], DatanodeInfoWithStorage[127.0.0.1:37559,DS-20cfd9f7-cda5-4e67-a411-f5a5d7f25925,DISK], DatanodeInfoWithStorage[127.0.0.1:45824,DS-51f4d18c-2983-48fa-a3f1-b03719049ec2,DISK], DatanodeInfoWithStorage[127.0.0.1:35063,DS-ebdf9dcf-fae7-4a5b-b9c7-f81993c2e1f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.enable
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1465069307-172.17.0.12-1596934597744:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45860,DS-74f1952e-ce1c-496b-9d53-fc93e159aade,DISK], DatanodeInfoWithStorage[127.0.0.1:38135,DS-40f6c07f-e021-4eb0-9d29-18b5bc58fa22,DISK], DatanodeInfoWithStorage[127.0.0.1:43588,DS-917fa161-f054-44dc-8bfb-072fa467f681,DISK], DatanodeInfoWithStorage[127.0.0.1:34241,DS-cc7b637b-fae0-46df-8613-c2323e86b287,DISK], DatanodeInfoWithStorage[127.0.0.1:35118,DS-83389813-1300-4e7e-b98c-5cedf90ee206,DISK], DatanodeInfoWithStorage[127.0.0.1:38129,DS-4a84eac3-a960-4ff6-8be2-801b7a0916a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33307,DS-b99c8758-1b42-426b-88ff-a84d51b54038,DISK], DatanodeInfoWithStorage[127.0.0.1:43077,DS-577bde25-a712-4aaf-ba1d-d994cfc502f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1465069307-172.17.0.12-1596934597744:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45860,DS-74f1952e-ce1c-496b-9d53-fc93e159aade,DISK], DatanodeInfoWithStorage[127.0.0.1:38135,DS-40f6c07f-e021-4eb0-9d29-18b5bc58fa22,DISK], DatanodeInfoWithStorage[127.0.0.1:43588,DS-917fa161-f054-44dc-8bfb-072fa467f681,DISK], DatanodeInfoWithStorage[127.0.0.1:34241,DS-cc7b637b-fae0-46df-8613-c2323e86b287,DISK], DatanodeInfoWithStorage[127.0.0.1:35118,DS-83389813-1300-4e7e-b98c-5cedf90ee206,DISK], DatanodeInfoWithStorage[127.0.0.1:38129,DS-4a84eac3-a960-4ff6-8be2-801b7a0916a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33307,DS-b99c8758-1b42-426b-88ff-a84d51b54038,DISK], DatanodeInfoWithStorage[127.0.0.1:43077,DS-577bde25-a712-4aaf-ba1d-d994cfc502f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.enable
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-848558970-172.17.0.12-1596934656465:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44706,DS-da996a53-3641-473a-a7bc-2b88bb065e15,DISK], DatanodeInfoWithStorage[127.0.0.1:33714,DS-6dd8f19b-7ada-4f1a-80c2-9a5a752b6c88,DISK], DatanodeInfoWithStorage[127.0.0.1:46312,DS-f9191a25-4b9d-443f-a86f-a0bdc2eb3acd,DISK], DatanodeInfoWithStorage[127.0.0.1:38540,DS-41fb8320-5e79-4713-9e0f-d9ae39f18505,DISK], DatanodeInfoWithStorage[127.0.0.1:41426,DS-c5142145-b595-4a1a-a009-90bba2f4ea91,DISK], DatanodeInfoWithStorage[127.0.0.1:44850,DS-682a9642-fe55-4188-b399-c824213bd402,DISK], DatanodeInfoWithStorage[127.0.0.1:41042,DS-429c3f6d-5ed3-4264-b0e5-43aa982f8c17,DISK], DatanodeInfoWithStorage[127.0.0.1:40859,DS-17471a92-30ac-4190-91d7-13733faff838,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-848558970-172.17.0.12-1596934656465:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44706,DS-da996a53-3641-473a-a7bc-2b88bb065e15,DISK], DatanodeInfoWithStorage[127.0.0.1:33714,DS-6dd8f19b-7ada-4f1a-80c2-9a5a752b6c88,DISK], DatanodeInfoWithStorage[127.0.0.1:46312,DS-f9191a25-4b9d-443f-a86f-a0bdc2eb3acd,DISK], DatanodeInfoWithStorage[127.0.0.1:38540,DS-41fb8320-5e79-4713-9e0f-d9ae39f18505,DISK], DatanodeInfoWithStorage[127.0.0.1:41426,DS-c5142145-b595-4a1a-a009-90bba2f4ea91,DISK], DatanodeInfoWithStorage[127.0.0.1:44850,DS-682a9642-fe55-4188-b399-c824213bd402,DISK], DatanodeInfoWithStorage[127.0.0.1:41042,DS-429c3f6d-5ed3-4264-b0e5-43aa982f8c17,DISK], DatanodeInfoWithStorage[127.0.0.1:40859,DS-17471a92-30ac-4190-91d7-13733faff838,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.enable
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-613828935-172.17.0.12-1596934725239:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37174,DS-da512c0a-7b6a-4c2b-a009-5ed643e9116e,DISK], DatanodeInfoWithStorage[127.0.0.1:37621,DS-517a591d-722c-47ae-9992-985be8ee7743,DISK], DatanodeInfoWithStorage[127.0.0.1:46798,DS-95a0db79-4e2c-4d0c-8479-fc6998c48069,DISK], DatanodeInfoWithStorage[127.0.0.1:35127,DS-5d765804-94e4-42c1-b80c-ffeae8c762c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38213,DS-4bd3a498-420a-48b7-8e77-e05a88a4277c,DISK], DatanodeInfoWithStorage[127.0.0.1:34783,DS-4746eec6-7d70-40d7-a974-ba57ff69be5c,DISK], DatanodeInfoWithStorage[127.0.0.1:38793,DS-025c1bf4-d154-4717-ac5a-a1f5496eada7,DISK], DatanodeInfoWithStorage[127.0.0.1:37539,DS-850e93d3-839d-44f0-910f-6cee08cfd888,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-613828935-172.17.0.12-1596934725239:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37174,DS-da512c0a-7b6a-4c2b-a009-5ed643e9116e,DISK], DatanodeInfoWithStorage[127.0.0.1:37621,DS-517a591d-722c-47ae-9992-985be8ee7743,DISK], DatanodeInfoWithStorage[127.0.0.1:46798,DS-95a0db79-4e2c-4d0c-8479-fc6998c48069,DISK], DatanodeInfoWithStorage[127.0.0.1:35127,DS-5d765804-94e4-42c1-b80c-ffeae8c762c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38213,DS-4bd3a498-420a-48b7-8e77-e05a88a4277c,DISK], DatanodeInfoWithStorage[127.0.0.1:34783,DS-4746eec6-7d70-40d7-a974-ba57ff69be5c,DISK], DatanodeInfoWithStorage[127.0.0.1:38793,DS-025c1bf4-d154-4717-ac5a-a1f5496eada7,DISK], DatanodeInfoWithStorage[127.0.0.1:37539,DS-850e93d3-839d-44f0-910f-6cee08cfd888,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.enable
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2050229836-172.17.0.12-1596935037764:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35436,DS-95d60b5a-b71c-4c3f-9dac-35cebfd772ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37739,DS-0ae2b6fa-9ae1-49b2-bd50-276fdef85c93,DISK], DatanodeInfoWithStorage[127.0.0.1:38288,DS-d063992a-7a63-420b-943a-25b2cbd210bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36057,DS-1626a4d8-ce4f-425d-81bf-26a4ffd9d8e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38074,DS-8a2f633c-edaa-4510-a900-d20b00f6f52d,DISK], DatanodeInfoWithStorage[127.0.0.1:43952,DS-a4ad48a6-b5b7-4feb-b088-030ce0bbcf2c,DISK], DatanodeInfoWithStorage[127.0.0.1:44780,DS-95ff3171-a631-43be-9000-23b0070370a9,DISK], DatanodeInfoWithStorage[127.0.0.1:34103,DS-1a3d7e98-3a90-45b8-9eb6-abb47e7ed950,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2050229836-172.17.0.12-1596935037764:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35436,DS-95d60b5a-b71c-4c3f-9dac-35cebfd772ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37739,DS-0ae2b6fa-9ae1-49b2-bd50-276fdef85c93,DISK], DatanodeInfoWithStorage[127.0.0.1:38288,DS-d063992a-7a63-420b-943a-25b2cbd210bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36057,DS-1626a4d8-ce4f-425d-81bf-26a4ffd9d8e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38074,DS-8a2f633c-edaa-4510-a900-d20b00f6f52d,DISK], DatanodeInfoWithStorage[127.0.0.1:43952,DS-a4ad48a6-b5b7-4feb-b088-030ce0bbcf2c,DISK], DatanodeInfoWithStorage[127.0.0.1:44780,DS-95ff3171-a631-43be-9000-23b0070370a9,DISK], DatanodeInfoWithStorage[127.0.0.1:34103,DS-1a3d7e98-3a90-45b8-9eb6-abb47e7ed950,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.enable
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1195379281-172.17.0.12-1596935188014:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33883,DS-31374373-04d6-4d3a-8a81-be63b2e6e3ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34123,DS-87885c9f-2978-43df-97e9-98e11c069c42,DISK], DatanodeInfoWithStorage[127.0.0.1:36003,DS-469f5d2d-d2b4-47d2-b4c9-28be4caf04a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37412,DS-0b1638f1-2c79-4230-8b37-ea1b5de9c54f,DISK], DatanodeInfoWithStorage[127.0.0.1:32959,DS-5fbccadf-b4d6-4d88-860e-b21c3975531a,DISK], DatanodeInfoWithStorage[127.0.0.1:36092,DS-4d002f4d-2262-4f72-b3ca-bf0261cdcd2b,DISK], DatanodeInfoWithStorage[127.0.0.1:34609,DS-128477b8-0600-4b2f-8c50-14ad0da30d73,DISK], DatanodeInfoWithStorage[127.0.0.1:37936,DS-14637dd7-efdf-47df-85be-729ec440e39b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1195379281-172.17.0.12-1596935188014:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33883,DS-31374373-04d6-4d3a-8a81-be63b2e6e3ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34123,DS-87885c9f-2978-43df-97e9-98e11c069c42,DISK], DatanodeInfoWithStorage[127.0.0.1:36003,DS-469f5d2d-d2b4-47d2-b4c9-28be4caf04a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37412,DS-0b1638f1-2c79-4230-8b37-ea1b5de9c54f,DISK], DatanodeInfoWithStorage[127.0.0.1:32959,DS-5fbccadf-b4d6-4d88-860e-b21c3975531a,DISK], DatanodeInfoWithStorage[127.0.0.1:36092,DS-4d002f4d-2262-4f72-b3ca-bf0261cdcd2b,DISK], DatanodeInfoWithStorage[127.0.0.1:34609,DS-128477b8-0600-4b2f-8c50-14ad0da30d73,DISK], DatanodeInfoWithStorage[127.0.0.1:37936,DS-14637dd7-efdf-47df-85be-729ec440e39b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.enable
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-556699255-172.17.0.12-1596935243827:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42168,DS-88cc3e90-41aa-43a3-9782-dab9e2ed8951,DISK], DatanodeInfoWithStorage[127.0.0.1:45830,DS-04627d0f-af94-4665-b060-193b65077931,DISK], DatanodeInfoWithStorage[127.0.0.1:45474,DS-52de2837-df1d-4753-8743-6df747ba51b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41327,DS-c8c05308-4897-42bc-92ab-3d30bdeea9aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40231,DS-18d5de96-0abf-4976-9102-3eddc5acd022,DISK], DatanodeInfoWithStorage[127.0.0.1:43797,DS-6bcb5e38-bea5-4fcf-8f19-07df8ed64540,DISK], DatanodeInfoWithStorage[127.0.0.1:40964,DS-d217fbb8-b350-45fc-bbb5-3e63c6abd5bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46239,DS-ee88c985-4b0d-4cb0-ba51-6de0809eb3dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-556699255-172.17.0.12-1596935243827:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42168,DS-88cc3e90-41aa-43a3-9782-dab9e2ed8951,DISK], DatanodeInfoWithStorage[127.0.0.1:45830,DS-04627d0f-af94-4665-b060-193b65077931,DISK], DatanodeInfoWithStorage[127.0.0.1:45474,DS-52de2837-df1d-4753-8743-6df747ba51b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41327,DS-c8c05308-4897-42bc-92ab-3d30bdeea9aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40231,DS-18d5de96-0abf-4976-9102-3eddc5acd022,DISK], DatanodeInfoWithStorage[127.0.0.1:43797,DS-6bcb5e38-bea5-4fcf-8f19-07df8ed64540,DISK], DatanodeInfoWithStorage[127.0.0.1:40964,DS-d217fbb8-b350-45fc-bbb5-3e63c6abd5bc,DISK], DatanodeInfoWithStorage[127.0.0.1:46239,DS-ee88c985-4b0d-4cb0-ba51-6de0809eb3dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.enable
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1435982903-172.17.0.12-1596935496370:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39097,DS-38471068-9d49-4802-9c6d-29453c899351,DISK], DatanodeInfoWithStorage[127.0.0.1:44826,DS-d181d585-0f68-4c64-a38a-3c241e5d54f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41902,DS-53d70088-1858-468b-bb1a-22b70ed00eec,DISK], DatanodeInfoWithStorage[127.0.0.1:38138,DS-2f262d71-be4c-4f50-8952-e13c8a0f09bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33705,DS-80159ac5-5bc6-41f6-bd25-b34854361bf2,DISK], DatanodeInfoWithStorage[127.0.0.1:40811,DS-d05f9fc1-d35b-422f-b320-d42107c1a274,DISK], DatanodeInfoWithStorage[127.0.0.1:39924,DS-371802b3-826e-453f-98af-f728fa085767,DISK], DatanodeInfoWithStorage[127.0.0.1:36896,DS-a0c76ab2-10b3-41dd-a718-0af6c07d5c18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1435982903-172.17.0.12-1596935496370:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39097,DS-38471068-9d49-4802-9c6d-29453c899351,DISK], DatanodeInfoWithStorage[127.0.0.1:44826,DS-d181d585-0f68-4c64-a38a-3c241e5d54f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41902,DS-53d70088-1858-468b-bb1a-22b70ed00eec,DISK], DatanodeInfoWithStorage[127.0.0.1:38138,DS-2f262d71-be4c-4f50-8952-e13c8a0f09bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33705,DS-80159ac5-5bc6-41f6-bd25-b34854361bf2,DISK], DatanodeInfoWithStorage[127.0.0.1:40811,DS-d05f9fc1-d35b-422f-b320-d42107c1a274,DISK], DatanodeInfoWithStorage[127.0.0.1:39924,DS-371802b3-826e-453f-98af-f728fa085767,DISK], DatanodeInfoWithStorage[127.0.0.1:36896,DS-a0c76ab2-10b3-41dd-a718-0af6c07d5c18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.enable
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1974772611-172.17.0.12-1596935738558:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42820,DS-d1b90537-8976-4307-ace2-f01e9728e9ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41195,DS-b66faf90-81b0-4dcc-8de0-5e2ee408e480,DISK], DatanodeInfoWithStorage[127.0.0.1:36361,DS-cac2b4fd-3049-43d3-b0b7-11655485c17f,DISK], DatanodeInfoWithStorage[127.0.0.1:38415,DS-4d19a7b5-9b30-4e56-a675-b814d4616e97,DISK], DatanodeInfoWithStorage[127.0.0.1:39620,DS-bb16ad26-d0a2-4533-9dc4-81ba3489425b,DISK], DatanodeInfoWithStorage[127.0.0.1:44232,DS-15d703a9-5d56-43ab-a48a-cf1d57e8f202,DISK], DatanodeInfoWithStorage[127.0.0.1:41675,DS-a35e9097-f242-4f35-b59c-aae8c3b3e1da,DISK], DatanodeInfoWithStorage[127.0.0.1:35337,DS-7f06f154-79e6-4799-9950-2b27eb0f6045,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1974772611-172.17.0.12-1596935738558:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42820,DS-d1b90537-8976-4307-ace2-f01e9728e9ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41195,DS-b66faf90-81b0-4dcc-8de0-5e2ee408e480,DISK], DatanodeInfoWithStorage[127.0.0.1:36361,DS-cac2b4fd-3049-43d3-b0b7-11655485c17f,DISK], DatanodeInfoWithStorage[127.0.0.1:38415,DS-4d19a7b5-9b30-4e56-a675-b814d4616e97,DISK], DatanodeInfoWithStorage[127.0.0.1:39620,DS-bb16ad26-d0a2-4533-9dc4-81ba3489425b,DISK], DatanodeInfoWithStorage[127.0.0.1:44232,DS-15d703a9-5d56-43ab-a48a-cf1d57e8f202,DISK], DatanodeInfoWithStorage[127.0.0.1:41675,DS-a35e9097-f242-4f35-b59c-aae8c3b3e1da,DISK], DatanodeInfoWithStorage[127.0.0.1:35337,DS-7f06f154-79e6-4799-9950-2b27eb0f6045,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.enable
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2085365092-172.17.0.12-1596935797318:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35319,DS-d27a63dc-e4bb-4c0b-a652-deeef6875756,DISK], DatanodeInfoWithStorage[127.0.0.1:45878,DS-fd0e1604-ade9-44f8-82b7-9d3ddf1f9f06,DISK], DatanodeInfoWithStorage[127.0.0.1:34025,DS-b390a465-9c49-4ba3-9c8e-1dff01790985,DISK], DatanodeInfoWithStorage[127.0.0.1:35327,DS-28f38eb0-3f37-4e47-b2af-302b558fe00e,DISK], DatanodeInfoWithStorage[127.0.0.1:38466,DS-134eb57d-c8cc-4b87-8927-437ebc1657a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34582,DS-4b261533-b779-4d19-a881-ce4a557a9b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:43300,DS-0ce371fd-8c8b-47cf-b39e-e64af0c3fb01,DISK], DatanodeInfoWithStorage[127.0.0.1:38068,DS-35597d66-b606-439f-aea9-5c70fb616b30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2085365092-172.17.0.12-1596935797318:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35319,DS-d27a63dc-e4bb-4c0b-a652-deeef6875756,DISK], DatanodeInfoWithStorage[127.0.0.1:45878,DS-fd0e1604-ade9-44f8-82b7-9d3ddf1f9f06,DISK], DatanodeInfoWithStorage[127.0.0.1:34025,DS-b390a465-9c49-4ba3-9c8e-1dff01790985,DISK], DatanodeInfoWithStorage[127.0.0.1:35327,DS-28f38eb0-3f37-4e47-b2af-302b558fe00e,DISK], DatanodeInfoWithStorage[127.0.0.1:38466,DS-134eb57d-c8cc-4b87-8927-437ebc1657a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34582,DS-4b261533-b779-4d19-a881-ce4a557a9b9f,DISK], DatanodeInfoWithStorage[127.0.0.1:43300,DS-0ce371fd-8c8b-47cf-b39e-e64af0c3fb01,DISK], DatanodeInfoWithStorage[127.0.0.1:38068,DS-35597d66-b606-439f-aea9-5c70fb616b30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.enable
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1123326987-172.17.0.12-1596935870499:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34758,DS-52f84118-989f-418d-ab69-69b25b1a3fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:43973,DS-b9251431-a962-4b9e-a0e9-78657a830484,DISK], DatanodeInfoWithStorage[127.0.0.1:39872,DS-4fc99c08-b6c9-4644-99e8-99a0f6267f6a,DISK], DatanodeInfoWithStorage[127.0.0.1:37663,DS-6cea82e8-2a19-4a61-be2d-757c8e661e19,DISK], DatanodeInfoWithStorage[127.0.0.1:34667,DS-7d77c299-c05a-4f54-bda5-7511e19e2ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:37966,DS-de133eb3-256e-4b82-a53e-68fabc0418bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45014,DS-f6bcad0b-de68-497b-a74b-d9b9ed82921b,DISK], DatanodeInfoWithStorage[127.0.0.1:43232,DS-74b47abd-edde-4ad3-a1c6-e1a29a8f4a42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1123326987-172.17.0.12-1596935870499:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34758,DS-52f84118-989f-418d-ab69-69b25b1a3fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:43973,DS-b9251431-a962-4b9e-a0e9-78657a830484,DISK], DatanodeInfoWithStorage[127.0.0.1:39872,DS-4fc99c08-b6c9-4644-99e8-99a0f6267f6a,DISK], DatanodeInfoWithStorage[127.0.0.1:37663,DS-6cea82e8-2a19-4a61-be2d-757c8e661e19,DISK], DatanodeInfoWithStorage[127.0.0.1:34667,DS-7d77c299-c05a-4f54-bda5-7511e19e2ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:37966,DS-de133eb3-256e-4b82-a53e-68fabc0418bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45014,DS-f6bcad0b-de68-497b-a74b-d9b9ed82921b,DISK], DatanodeInfoWithStorage[127.0.0.1:43232,DS-74b47abd-edde-4ad3-a1c6-e1a29a8f4a42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.enable
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-722547791-172.17.0.12-1596935904644:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35924,DS-687d0290-1258-43dc-891f-00e7713d33d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35929,DS-a3e8e838-7810-44b0-b56d-54117188aceb,DISK], DatanodeInfoWithStorage[127.0.0.1:41704,DS-997c8fa1-ca71-4811-bdef-a5fdde8a2bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:44735,DS-6c4ee2b9-2f96-42c7-9436-245b6ad2141b,DISK], DatanodeInfoWithStorage[127.0.0.1:35150,DS-3d42b365-2e28-449b-ba31-b4b77d2d3bec,DISK], DatanodeInfoWithStorage[127.0.0.1:38887,DS-6ab236a2-b5a0-4b6c-bf43-9a9e2b4f6401,DISK], DatanodeInfoWithStorage[127.0.0.1:43443,DS-7c1b008b-a9d9-4f9c-be4e-fa43b1385cf3,DISK], DatanodeInfoWithStorage[127.0.0.1:40047,DS-093c3cc1-5525-4b58-b4fd-768f8cdae9f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-722547791-172.17.0.12-1596935904644:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35924,DS-687d0290-1258-43dc-891f-00e7713d33d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35929,DS-a3e8e838-7810-44b0-b56d-54117188aceb,DISK], DatanodeInfoWithStorage[127.0.0.1:41704,DS-997c8fa1-ca71-4811-bdef-a5fdde8a2bdf,DISK], DatanodeInfoWithStorage[127.0.0.1:44735,DS-6c4ee2b9-2f96-42c7-9436-245b6ad2141b,DISK], DatanodeInfoWithStorage[127.0.0.1:35150,DS-3d42b365-2e28-449b-ba31-b4b77d2d3bec,DISK], DatanodeInfoWithStorage[127.0.0.1:38887,DS-6ab236a2-b5a0-4b6c-bf43-9a9e2b4f6401,DISK], DatanodeInfoWithStorage[127.0.0.1:43443,DS-7c1b008b-a9d9-4f9c-be4e-fa43b1385cf3,DISK], DatanodeInfoWithStorage[127.0.0.1:40047,DS-093c3cc1-5525-4b58-b4fd-768f8cdae9f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.enable
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1367112842-172.17.0.12-1596936172090:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38606,DS-30a9cf7b-212a-4cf5-bf7b-6579d6cf8427,DISK], DatanodeInfoWithStorage[127.0.0.1:37637,DS-c62bc4ec-cff9-4db0-b412-044b999bbb29,DISK], DatanodeInfoWithStorage[127.0.0.1:33015,DS-9db8de50-18a9-4e22-b13d-4d6a1ffbb146,DISK], DatanodeInfoWithStorage[127.0.0.1:40010,DS-6c986097-06d2-4a30-bb4c-18b735de6b39,DISK], DatanodeInfoWithStorage[127.0.0.1:41505,DS-81693dbe-74d6-4369-8068-e6d0efc7e008,DISK], DatanodeInfoWithStorage[127.0.0.1:43815,DS-74f3621d-3ad9-4c6a-a2ce-eef349d86526,DISK], DatanodeInfoWithStorage[127.0.0.1:36328,DS-3fb5bdfc-778b-4829-931c-be20dc4625c5,DISK], DatanodeInfoWithStorage[127.0.0.1:34711,DS-b13c1137-ac69-41e8-8dca-73e47fb605e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1367112842-172.17.0.12-1596936172090:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38606,DS-30a9cf7b-212a-4cf5-bf7b-6579d6cf8427,DISK], DatanodeInfoWithStorage[127.0.0.1:37637,DS-c62bc4ec-cff9-4db0-b412-044b999bbb29,DISK], DatanodeInfoWithStorage[127.0.0.1:33015,DS-9db8de50-18a9-4e22-b13d-4d6a1ffbb146,DISK], DatanodeInfoWithStorage[127.0.0.1:40010,DS-6c986097-06d2-4a30-bb4c-18b735de6b39,DISK], DatanodeInfoWithStorage[127.0.0.1:41505,DS-81693dbe-74d6-4369-8068-e6d0efc7e008,DISK], DatanodeInfoWithStorage[127.0.0.1:43815,DS-74f3621d-3ad9-4c6a-a2ce-eef349d86526,DISK], DatanodeInfoWithStorage[127.0.0.1:36328,DS-3fb5bdfc-778b-4829-931c-be20dc4625c5,DISK], DatanodeInfoWithStorage[127.0.0.1:34711,DS-b13c1137-ac69-41e8-8dca-73e47fb605e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.enable
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-188724933-172.17.0.12-1596936725733:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34436,DS-dee6ab50-b7c9-40e4-84b2-77b9c9da719e,DISK], DatanodeInfoWithStorage[127.0.0.1:40215,DS-d7ac1ec0-acae-4bb2-b49b-0d520c8c8312,DISK], DatanodeInfoWithStorage[127.0.0.1:41334,DS-a810bd05-e2b2-4d13-8888-cbac37a615d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42224,DS-7e70e95a-2fb1-4db7-8d33-2acb04905b83,DISK], DatanodeInfoWithStorage[127.0.0.1:40445,DS-987a5c8c-8cbd-4470-8311-a982ebaffef1,DISK], DatanodeInfoWithStorage[127.0.0.1:33851,DS-0c93d55c-6013-4946-8d67-9c6ff79f70cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46344,DS-f72d1333-5a66-4427-ad9b-82464a5925c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46747,DS-8377b041-3678-45e1-b06b-389ce399c672,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-188724933-172.17.0.12-1596936725733:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34436,DS-dee6ab50-b7c9-40e4-84b2-77b9c9da719e,DISK], DatanodeInfoWithStorage[127.0.0.1:40215,DS-d7ac1ec0-acae-4bb2-b49b-0d520c8c8312,DISK], DatanodeInfoWithStorage[127.0.0.1:41334,DS-a810bd05-e2b2-4d13-8888-cbac37a615d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42224,DS-7e70e95a-2fb1-4db7-8d33-2acb04905b83,DISK], DatanodeInfoWithStorage[127.0.0.1:40445,DS-987a5c8c-8cbd-4470-8311-a982ebaffef1,DISK], DatanodeInfoWithStorage[127.0.0.1:33851,DS-0c93d55c-6013-4946-8d67-9c6ff79f70cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46344,DS-f72d1333-5a66-4427-ad9b-82464a5925c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46747,DS-8377b041-3678-45e1-b06b-389ce399c672,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.enable
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-904362971-172.17.0.12-1596936970729:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44603,DS-6355ecd5-b0c1-4860-9db8-cb186ea67a7a,DISK], DatanodeInfoWithStorage[127.0.0.1:42188,DS-e3fc5087-e161-40c4-99ed-fb9df27a3d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:43830,DS-c60d3540-b891-4375-8145-4bff4298d196,DISK], DatanodeInfoWithStorage[127.0.0.1:46212,DS-0ee327e5-5f74-47ad-bf8e-d2ab14f709aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35412,DS-3c567ed9-c900-4951-9463-03a9dfa92992,DISK], DatanodeInfoWithStorage[127.0.0.1:45880,DS-573438da-c596-43ea-a96d-f488fc2a0a91,DISK], DatanodeInfoWithStorage[127.0.0.1:34982,DS-6783282e-3097-4a99-b36a-11894b58a3d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35784,DS-2a54e26e-bab7-43bf-a4cf-4f6e08c2a6ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-904362971-172.17.0.12-1596936970729:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44603,DS-6355ecd5-b0c1-4860-9db8-cb186ea67a7a,DISK], DatanodeInfoWithStorage[127.0.0.1:42188,DS-e3fc5087-e161-40c4-99ed-fb9df27a3d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:43830,DS-c60d3540-b891-4375-8145-4bff4298d196,DISK], DatanodeInfoWithStorage[127.0.0.1:46212,DS-0ee327e5-5f74-47ad-bf8e-d2ab14f709aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35412,DS-3c567ed9-c900-4951-9463-03a9dfa92992,DISK], DatanodeInfoWithStorage[127.0.0.1:45880,DS-573438da-c596-43ea-a96d-f488fc2a0a91,DISK], DatanodeInfoWithStorage[127.0.0.1:34982,DS-6783282e-3097-4a99-b36a-11894b58a3d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35784,DS-2a54e26e-bab7-43bf-a4cf-4f6e08c2a6ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5177
