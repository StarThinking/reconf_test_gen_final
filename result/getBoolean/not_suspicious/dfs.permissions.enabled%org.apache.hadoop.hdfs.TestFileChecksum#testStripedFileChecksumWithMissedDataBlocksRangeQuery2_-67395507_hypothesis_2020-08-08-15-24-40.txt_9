reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2040141333-172.17.0.14-1596901001336:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39514,DS-a4017043-bfc9-439f-962b-e135995b31f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44300,DS-296737e3-52ea-4c15-a093-b46a722182ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38042,DS-d46a8185-40e7-42d7-96ce-39da5892e6cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36381,DS-8a2e76b8-d6be-4cb6-ae54-2d7a085e79b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45549,DS-3f7028bb-6f6a-4931-9a7c-8e25c744fc87,DISK], DatanodeInfoWithStorage[127.0.0.1:34646,DS-2b2b9d10-ad61-462d-bfcd-fbd350f528f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39468,DS-e5a0b213-a857-4bbd-8aa3-5fe5ebe8a50c,DISK], DatanodeInfoWithStorage[127.0.0.1:34330,DS-dc5c3dae-0604-4491-be78-3d742b660d3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2040141333-172.17.0.14-1596901001336:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39514,DS-a4017043-bfc9-439f-962b-e135995b31f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44300,DS-296737e3-52ea-4c15-a093-b46a722182ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38042,DS-d46a8185-40e7-42d7-96ce-39da5892e6cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36381,DS-8a2e76b8-d6be-4cb6-ae54-2d7a085e79b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45549,DS-3f7028bb-6f6a-4931-9a7c-8e25c744fc87,DISK], DatanodeInfoWithStorage[127.0.0.1:34646,DS-2b2b9d10-ad61-462d-bfcd-fbd350f528f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39468,DS-e5a0b213-a857-4bbd-8aa3-5fe5ebe8a50c,DISK], DatanodeInfoWithStorage[127.0.0.1:34330,DS-dc5c3dae-0604-4491-be78-3d742b660d3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1288748465-172.17.0.14-1596901157926:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46146,DS-9f3d6710-c5ad-4c9d-b28a-e6889402531f,DISK], DatanodeInfoWithStorage[127.0.0.1:39444,DS-6f169ac1-2d8c-448b-9be5-e654faf42957,DISK], DatanodeInfoWithStorage[127.0.0.1:36409,DS-4eaf8a39-1261-4116-8277-18f3ef5d33ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44462,DS-2743a4cb-6f35-4017-a65a-6a8b3a4b3daa,DISK], DatanodeInfoWithStorage[127.0.0.1:43632,DS-4a2d3ea9-ed6d-4dff-ab2d-3baf6c3a2488,DISK], DatanodeInfoWithStorage[127.0.0.1:45212,DS-e6218c81-a2f2-4fb6-bba9-8801d6f6e762,DISK], DatanodeInfoWithStorage[127.0.0.1:40799,DS-2cd33b26-43e4-421f-a2c2-8aa88251583f,DISK], DatanodeInfoWithStorage[127.0.0.1:41073,DS-79919961-fa92-48a2-81d9-1dc4b54c20a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1288748465-172.17.0.14-1596901157926:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46146,DS-9f3d6710-c5ad-4c9d-b28a-e6889402531f,DISK], DatanodeInfoWithStorage[127.0.0.1:39444,DS-6f169ac1-2d8c-448b-9be5-e654faf42957,DISK], DatanodeInfoWithStorage[127.0.0.1:36409,DS-4eaf8a39-1261-4116-8277-18f3ef5d33ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44462,DS-2743a4cb-6f35-4017-a65a-6a8b3a4b3daa,DISK], DatanodeInfoWithStorage[127.0.0.1:43632,DS-4a2d3ea9-ed6d-4dff-ab2d-3baf6c3a2488,DISK], DatanodeInfoWithStorage[127.0.0.1:45212,DS-e6218c81-a2f2-4fb6-bba9-8801d6f6e762,DISK], DatanodeInfoWithStorage[127.0.0.1:40799,DS-2cd33b26-43e4-421f-a2c2-8aa88251583f,DISK], DatanodeInfoWithStorage[127.0.0.1:41073,DS-79919961-fa92-48a2-81d9-1dc4b54c20a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-489071543-172.17.0.14-1596901512367:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37857,DS-eeffc806-46c2-4f5d-ab07-2adba2a98ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:33700,DS-c15a2e18-fb54-4d79-a8a7-7015e5e37773,DISK], DatanodeInfoWithStorage[127.0.0.1:33217,DS-86183eeb-6a67-423e-bd4f-43524674f948,DISK], DatanodeInfoWithStorage[127.0.0.1:40335,DS-a2b4b092-e9c0-45e0-bd12-c90b9fe2c45b,DISK], DatanodeInfoWithStorage[127.0.0.1:34945,DS-7eddfc46-945f-4222-85c8-ec4a0fb67d55,DISK], DatanodeInfoWithStorage[127.0.0.1:35933,DS-00b084df-97cb-41fc-97b5-4cf77b720991,DISK], DatanodeInfoWithStorage[127.0.0.1:41760,DS-c3955657-02ef-4656-a00f-d6c51de8be93,DISK], DatanodeInfoWithStorage[127.0.0.1:44576,DS-638be73e-ec55-415d-b84a-954031b0cf2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-489071543-172.17.0.14-1596901512367:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37857,DS-eeffc806-46c2-4f5d-ab07-2adba2a98ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:33700,DS-c15a2e18-fb54-4d79-a8a7-7015e5e37773,DISK], DatanodeInfoWithStorage[127.0.0.1:33217,DS-86183eeb-6a67-423e-bd4f-43524674f948,DISK], DatanodeInfoWithStorage[127.0.0.1:40335,DS-a2b4b092-e9c0-45e0-bd12-c90b9fe2c45b,DISK], DatanodeInfoWithStorage[127.0.0.1:34945,DS-7eddfc46-945f-4222-85c8-ec4a0fb67d55,DISK], DatanodeInfoWithStorage[127.0.0.1:35933,DS-00b084df-97cb-41fc-97b5-4cf77b720991,DISK], DatanodeInfoWithStorage[127.0.0.1:41760,DS-c3955657-02ef-4656-a00f-d6c51de8be93,DISK], DatanodeInfoWithStorage[127.0.0.1:44576,DS-638be73e-ec55-415d-b84a-954031b0cf2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1011703706-172.17.0.14-1596902230014:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38838,DS-e6bca8b8-d0e5-4a69-a885-7cfbc40334f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44301,DS-df71a808-679f-41d2-90a1-ae9ccf711746,DISK], DatanodeInfoWithStorage[127.0.0.1:35695,DS-71f2d22b-55b9-4f68-becf-eb80c6647e14,DISK], DatanodeInfoWithStorage[127.0.0.1:46083,DS-7538d995-34f5-4f58-97a4-cb4c5246da7c,DISK], DatanodeInfoWithStorage[127.0.0.1:41281,DS-b212f555-724e-41c6-9b59-fee20ae6971f,DISK], DatanodeInfoWithStorage[127.0.0.1:33511,DS-80059d96-fe22-4d2b-b07c-ce79823b6b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:45637,DS-61a151d8-3f92-4f1d-abba-db5aadc481c2,DISK], DatanodeInfoWithStorage[127.0.0.1:41546,DS-778a18c3-025e-4345-8abe-c47c37b89479,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1011703706-172.17.0.14-1596902230014:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38838,DS-e6bca8b8-d0e5-4a69-a885-7cfbc40334f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44301,DS-df71a808-679f-41d2-90a1-ae9ccf711746,DISK], DatanodeInfoWithStorage[127.0.0.1:35695,DS-71f2d22b-55b9-4f68-becf-eb80c6647e14,DISK], DatanodeInfoWithStorage[127.0.0.1:46083,DS-7538d995-34f5-4f58-97a4-cb4c5246da7c,DISK], DatanodeInfoWithStorage[127.0.0.1:41281,DS-b212f555-724e-41c6-9b59-fee20ae6971f,DISK], DatanodeInfoWithStorage[127.0.0.1:33511,DS-80059d96-fe22-4d2b-b07c-ce79823b6b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:45637,DS-61a151d8-3f92-4f1d-abba-db5aadc481c2,DISK], DatanodeInfoWithStorage[127.0.0.1:41546,DS-778a18c3-025e-4345-8abe-c47c37b89479,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1034705725-172.17.0.14-1596902354921:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46554,DS-d053772f-e731-4fdb-81d3-b5b8513b862d,DISK], DatanodeInfoWithStorage[127.0.0.1:44414,DS-48087024-a9d4-4333-97cc-d948a1f2d8dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36732,DS-964c3a37-a066-4bda-b9a2-5db6b3c8661c,DISK], DatanodeInfoWithStorage[127.0.0.1:43716,DS-8bcd77d7-e2ee-47a8-a507-b0b2c6754683,DISK], DatanodeInfoWithStorage[127.0.0.1:35658,DS-961c41c9-754f-4df8-80f1-758f32f39def,DISK], DatanodeInfoWithStorage[127.0.0.1:45152,DS-e11ebe79-33db-4f9a-9250-e4120b5f8e39,DISK], DatanodeInfoWithStorage[127.0.0.1:43892,DS-e26b914c-bef7-4328-82cc-7e53cfeacf71,DISK], DatanodeInfoWithStorage[127.0.0.1:45269,DS-ea5ace2a-a045-4b3e-af53-40407fc36d02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1034705725-172.17.0.14-1596902354921:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46554,DS-d053772f-e731-4fdb-81d3-b5b8513b862d,DISK], DatanodeInfoWithStorage[127.0.0.1:44414,DS-48087024-a9d4-4333-97cc-d948a1f2d8dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36732,DS-964c3a37-a066-4bda-b9a2-5db6b3c8661c,DISK], DatanodeInfoWithStorage[127.0.0.1:43716,DS-8bcd77d7-e2ee-47a8-a507-b0b2c6754683,DISK], DatanodeInfoWithStorage[127.0.0.1:35658,DS-961c41c9-754f-4df8-80f1-758f32f39def,DISK], DatanodeInfoWithStorage[127.0.0.1:45152,DS-e11ebe79-33db-4f9a-9250-e4120b5f8e39,DISK], DatanodeInfoWithStorage[127.0.0.1:43892,DS-e26b914c-bef7-4328-82cc-7e53cfeacf71,DISK], DatanodeInfoWithStorage[127.0.0.1:45269,DS-ea5ace2a-a045-4b3e-af53-40407fc36d02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-665272199-172.17.0.14-1596902655658:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44963,DS-036ba578-d223-428b-ad99-1a0370d98c34,DISK], DatanodeInfoWithStorage[127.0.0.1:36165,DS-b266757b-efad-43b9-ab8b-4fad6acfaf21,DISK], DatanodeInfoWithStorage[127.0.0.1:44578,DS-d212f43b-29f9-4106-9eec-2a89800ddec9,DISK], DatanodeInfoWithStorage[127.0.0.1:41159,DS-896e4cb2-2dc4-4c61-86b7-d05aa03774f7,DISK], DatanodeInfoWithStorage[127.0.0.1:43451,DS-407417b8-fdb1-4869-8680-d70094f12701,DISK], DatanodeInfoWithStorage[127.0.0.1:43924,DS-f2cc2b8a-1535-4521-a6b8-c6d6baebf9b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36237,DS-f5bfc155-2788-47fe-a17e-23a326e783ff,DISK], DatanodeInfoWithStorage[127.0.0.1:46632,DS-35981d38-3c90-4ba6-86e0-d724bc43808a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-665272199-172.17.0.14-1596902655658:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44963,DS-036ba578-d223-428b-ad99-1a0370d98c34,DISK], DatanodeInfoWithStorage[127.0.0.1:36165,DS-b266757b-efad-43b9-ab8b-4fad6acfaf21,DISK], DatanodeInfoWithStorage[127.0.0.1:44578,DS-d212f43b-29f9-4106-9eec-2a89800ddec9,DISK], DatanodeInfoWithStorage[127.0.0.1:41159,DS-896e4cb2-2dc4-4c61-86b7-d05aa03774f7,DISK], DatanodeInfoWithStorage[127.0.0.1:43451,DS-407417b8-fdb1-4869-8680-d70094f12701,DISK], DatanodeInfoWithStorage[127.0.0.1:43924,DS-f2cc2b8a-1535-4521-a6b8-c6d6baebf9b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36237,DS-f5bfc155-2788-47fe-a17e-23a326e783ff,DISK], DatanodeInfoWithStorage[127.0.0.1:46632,DS-35981d38-3c90-4ba6-86e0-d724bc43808a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-688661500-172.17.0.14-1596902688832:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35671,DS-59a9ce43-e7cd-4783-8832-ce5d6ce9601b,DISK], DatanodeInfoWithStorage[127.0.0.1:33055,DS-76a6b54d-8f55-462d-90c7-43b81400a7f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41765,DS-06171d12-8e20-4e9b-abcc-9e97a7cc2435,DISK], DatanodeInfoWithStorage[127.0.0.1:45987,DS-194090e6-3d01-4dff-8dbe-6aac507f9bad,DISK], DatanodeInfoWithStorage[127.0.0.1:35458,DS-9ffd671d-666f-498e-ad50-ebc1e9244020,DISK], DatanodeInfoWithStorage[127.0.0.1:37757,DS-d3cbfa61-b81a-481d-a0f6-2a96255bd4e9,DISK], DatanodeInfoWithStorage[127.0.0.1:46421,DS-361f2300-4a2d-47fd-99e3-8a9ac60ea183,DISK], DatanodeInfoWithStorage[127.0.0.1:44064,DS-bc2772df-08b2-4738-b812-802c6ae2a739,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-688661500-172.17.0.14-1596902688832:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35671,DS-59a9ce43-e7cd-4783-8832-ce5d6ce9601b,DISK], DatanodeInfoWithStorage[127.0.0.1:33055,DS-76a6b54d-8f55-462d-90c7-43b81400a7f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41765,DS-06171d12-8e20-4e9b-abcc-9e97a7cc2435,DISK], DatanodeInfoWithStorage[127.0.0.1:45987,DS-194090e6-3d01-4dff-8dbe-6aac507f9bad,DISK], DatanodeInfoWithStorage[127.0.0.1:35458,DS-9ffd671d-666f-498e-ad50-ebc1e9244020,DISK], DatanodeInfoWithStorage[127.0.0.1:37757,DS-d3cbfa61-b81a-481d-a0f6-2a96255bd4e9,DISK], DatanodeInfoWithStorage[127.0.0.1:46421,DS-361f2300-4a2d-47fd-99e3-8a9ac60ea183,DISK], DatanodeInfoWithStorage[127.0.0.1:44064,DS-bc2772df-08b2-4738-b812-802c6ae2a739,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-474722891-172.17.0.14-1596902733022:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45746,DS-8cf41588-71d2-4edc-81c7-07925e376605,DISK], DatanodeInfoWithStorage[127.0.0.1:35523,DS-255c910a-4204-4fc3-9dff-5aad6b22f2c8,DISK], DatanodeInfoWithStorage[127.0.0.1:46316,DS-de564c89-2e46-462f-9140-ecad523b726d,DISK], DatanodeInfoWithStorage[127.0.0.1:36760,DS-a628f743-2d33-4c27-9230-db3ca08689fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34873,DS-6c15a295-a3a9-4dac-8aba-321c5a5cfff4,DISK], DatanodeInfoWithStorage[127.0.0.1:44506,DS-b4c52b1e-4952-4e31-bab4-57c1f4f6a139,DISK], DatanodeInfoWithStorage[127.0.0.1:39826,DS-6781adc4-6bad-46d7-b2db-9aeb0ee7838f,DISK], DatanodeInfoWithStorage[127.0.0.1:33970,DS-ea85d0aa-83eb-4d6d-8b2a-e0a511eb914d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-474722891-172.17.0.14-1596902733022:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45746,DS-8cf41588-71d2-4edc-81c7-07925e376605,DISK], DatanodeInfoWithStorage[127.0.0.1:35523,DS-255c910a-4204-4fc3-9dff-5aad6b22f2c8,DISK], DatanodeInfoWithStorage[127.0.0.1:46316,DS-de564c89-2e46-462f-9140-ecad523b726d,DISK], DatanodeInfoWithStorage[127.0.0.1:36760,DS-a628f743-2d33-4c27-9230-db3ca08689fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34873,DS-6c15a295-a3a9-4dac-8aba-321c5a5cfff4,DISK], DatanodeInfoWithStorage[127.0.0.1:44506,DS-b4c52b1e-4952-4e31-bab4-57c1f4f6a139,DISK], DatanodeInfoWithStorage[127.0.0.1:39826,DS-6781adc4-6bad-46d7-b2db-9aeb0ee7838f,DISK], DatanodeInfoWithStorage[127.0.0.1:33970,DS-ea85d0aa-83eb-4d6d-8b2a-e0a511eb914d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-120387544-172.17.0.14-1596904882869:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42548,DS-741cc54e-f2a6-4d55-bed9-e348dd96e91b,DISK], DatanodeInfoWithStorage[127.0.0.1:43639,DS-bfe14a16-5354-48b9-b174-3c99967f151b,DISK], DatanodeInfoWithStorage[127.0.0.1:40296,DS-d5a454c0-43b4-437d-86dc-c0fcc467f650,DISK], DatanodeInfoWithStorage[127.0.0.1:43402,DS-cdbe8d9d-3f95-4b36-9a09-601f65226712,DISK], DatanodeInfoWithStorage[127.0.0.1:45353,DS-32d9a4e3-a4df-4e26-9bdd-5076426fa973,DISK], DatanodeInfoWithStorage[127.0.0.1:44077,DS-53a2eaae-6f52-4b99-bc11-6731d085308f,DISK], DatanodeInfoWithStorage[127.0.0.1:41644,DS-27a071bf-17e5-4211-b115-5c4153ef0906,DISK], DatanodeInfoWithStorage[127.0.0.1:44478,DS-ef457a34-9338-4e17-b0e9-2242607ea4da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-120387544-172.17.0.14-1596904882869:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42548,DS-741cc54e-f2a6-4d55-bed9-e348dd96e91b,DISK], DatanodeInfoWithStorage[127.0.0.1:43639,DS-bfe14a16-5354-48b9-b174-3c99967f151b,DISK], DatanodeInfoWithStorage[127.0.0.1:40296,DS-d5a454c0-43b4-437d-86dc-c0fcc467f650,DISK], DatanodeInfoWithStorage[127.0.0.1:43402,DS-cdbe8d9d-3f95-4b36-9a09-601f65226712,DISK], DatanodeInfoWithStorage[127.0.0.1:45353,DS-32d9a4e3-a4df-4e26-9bdd-5076426fa973,DISK], DatanodeInfoWithStorage[127.0.0.1:44077,DS-53a2eaae-6f52-4b99-bc11-6731d085308f,DISK], DatanodeInfoWithStorage[127.0.0.1:41644,DS-27a071bf-17e5-4211-b115-5c4153ef0906,DISK], DatanodeInfoWithStorage[127.0.0.1:44478,DS-ef457a34-9338-4e17-b0e9-2242607ea4da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-40333541-172.17.0.14-1596906287781:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33238,DS-fd9db657-b583-43c0-a17b-44814f92d5c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37300,DS-8b2fb41d-c230-4a58-9d93-c6bad73c3bbc,DISK], DatanodeInfoWithStorage[127.0.0.1:35754,DS-44ba4055-653e-4e9d-92df-efe6d927e3fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44159,DS-c074892b-e24b-4d13-ae73-9cbd737f7d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:34623,DS-9771090d-ce56-46aa-826b-37a04e1d97d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45661,DS-d3a42ffc-43f4-4c6a-834d-36fb5656fd5b,DISK], DatanodeInfoWithStorage[127.0.0.1:38005,DS-5b2642d3-8785-42a0-9fc3-78764522f91f,DISK], DatanodeInfoWithStorage[127.0.0.1:34825,DS-fbbd6b86-fd7d-4b03-a81a-d99bf9af877a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-40333541-172.17.0.14-1596906287781:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33238,DS-fd9db657-b583-43c0-a17b-44814f92d5c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37300,DS-8b2fb41d-c230-4a58-9d93-c6bad73c3bbc,DISK], DatanodeInfoWithStorage[127.0.0.1:35754,DS-44ba4055-653e-4e9d-92df-efe6d927e3fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44159,DS-c074892b-e24b-4d13-ae73-9cbd737f7d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:34623,DS-9771090d-ce56-46aa-826b-37a04e1d97d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45661,DS-d3a42ffc-43f4-4c6a-834d-36fb5656fd5b,DISK], DatanodeInfoWithStorage[127.0.0.1:38005,DS-5b2642d3-8785-42a0-9fc3-78764522f91f,DISK], DatanodeInfoWithStorage[127.0.0.1:34825,DS-fbbd6b86-fd7d-4b03-a81a-d99bf9af877a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1721756768-172.17.0.14-1596906798831:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32868,DS-5a016f0e-e8b4-48f5-812b-05185a98a736,DISK], DatanodeInfoWithStorage[127.0.0.1:40333,DS-c14327ce-ccc5-4898-9273-a76218b3924d,DISK], DatanodeInfoWithStorage[127.0.0.1:41763,DS-d714b2de-4ece-4549-a059-32d334a50aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:43662,DS-b14b92eb-b1d8-4673-b62c-1dc63c3f0398,DISK], DatanodeInfoWithStorage[127.0.0.1:32810,DS-525c4f2b-81bb-42ab-86f8-e7b9a0e0001d,DISK], DatanodeInfoWithStorage[127.0.0.1:34988,DS-d159fa22-cf05-4936-a342-c29d722ec817,DISK], DatanodeInfoWithStorage[127.0.0.1:37999,DS-068bb266-a065-4014-9e46-7603e901d163,DISK], DatanodeInfoWithStorage[127.0.0.1:45236,DS-c59da584-e204-499d-8a71-e63be5dbf2af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1721756768-172.17.0.14-1596906798831:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32868,DS-5a016f0e-e8b4-48f5-812b-05185a98a736,DISK], DatanodeInfoWithStorage[127.0.0.1:40333,DS-c14327ce-ccc5-4898-9273-a76218b3924d,DISK], DatanodeInfoWithStorage[127.0.0.1:41763,DS-d714b2de-4ece-4549-a059-32d334a50aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:43662,DS-b14b92eb-b1d8-4673-b62c-1dc63c3f0398,DISK], DatanodeInfoWithStorage[127.0.0.1:32810,DS-525c4f2b-81bb-42ab-86f8-e7b9a0e0001d,DISK], DatanodeInfoWithStorage[127.0.0.1:34988,DS-d159fa22-cf05-4936-a342-c29d722ec817,DISK], DatanodeInfoWithStorage[127.0.0.1:37999,DS-068bb266-a065-4014-9e46-7603e901d163,DISK], DatanodeInfoWithStorage[127.0.0.1:45236,DS-c59da584-e204-499d-8a71-e63be5dbf2af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: false positive !!!
Total execution time in seconds : 6640
