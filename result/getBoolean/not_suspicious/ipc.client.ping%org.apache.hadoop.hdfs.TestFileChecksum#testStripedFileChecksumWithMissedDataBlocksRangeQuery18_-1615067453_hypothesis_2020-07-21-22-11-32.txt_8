reconf_parameter: ipc.client.ping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2067938364-172.17.0.6-1595369744972:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42329,DS-56bfed96-ba16-40bd-89ff-a5dc77d42849,DISK], DatanodeInfoWithStorage[127.0.0.1:42208,DS-1e7ee320-6cb0-4ff7-96fb-be632f16cdab,DISK], DatanodeInfoWithStorage[127.0.0.1:43501,DS-ef42d075-e230-4ddb-9731-0215e5c150dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45325,DS-8c2c14fc-7798-470c-98fa-e5807e0449e5,DISK], DatanodeInfoWithStorage[127.0.0.1:33049,DS-eb66cace-44fc-43d3-bbee-3a771e291a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:32884,DS-c7152567-1199-495c-962d-25371ecfe21c,DISK], DatanodeInfoWithStorage[127.0.0.1:36484,DS-c2fd0479-3867-4a83-89e0-a958fc3a61bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33546,DS-ebbe108b-c93a-417c-8bd1-4ff824dbe7f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2067938364-172.17.0.6-1595369744972:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42329,DS-56bfed96-ba16-40bd-89ff-a5dc77d42849,DISK], DatanodeInfoWithStorage[127.0.0.1:42208,DS-1e7ee320-6cb0-4ff7-96fb-be632f16cdab,DISK], DatanodeInfoWithStorage[127.0.0.1:43501,DS-ef42d075-e230-4ddb-9731-0215e5c150dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45325,DS-8c2c14fc-7798-470c-98fa-e5807e0449e5,DISK], DatanodeInfoWithStorage[127.0.0.1:33049,DS-eb66cace-44fc-43d3-bbee-3a771e291a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:32884,DS-c7152567-1199-495c-962d-25371ecfe21c,DISK], DatanodeInfoWithStorage[127.0.0.1:36484,DS-c2fd0479-3867-4a83-89e0-a958fc3a61bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33546,DS-ebbe108b-c93a-417c-8bd1-4ff824dbe7f3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1743920585-172.17.0.6-1595370327581:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39722,DS-d0bd912c-659d-4228-83dd-bf8a13a6ac07,DISK], DatanodeInfoWithStorage[127.0.0.1:36208,DS-caa6d4d7-1fac-45e1-ab01-9e21722b647f,DISK], DatanodeInfoWithStorage[127.0.0.1:37625,DS-33a0f6a9-5c49-4f59-ab54-5b12fdb99afe,DISK], DatanodeInfoWithStorage[127.0.0.1:38430,DS-915f49ce-c24f-4f38-9c51-c811da185c58,DISK], DatanodeInfoWithStorage[127.0.0.1:44002,DS-841a479e-bbad-4e40-b50e-e0706514c061,DISK], DatanodeInfoWithStorage[127.0.0.1:34343,DS-a2d8cdeb-84f2-4292-83e9-d3047d956338,DISK], DatanodeInfoWithStorage[127.0.0.1:36668,DS-c7b9d3ec-8ff3-4821-aec5-cf34b8d107f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37906,DS-4cec288d-d644-4a0b-8bd2-625094398136,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1743920585-172.17.0.6-1595370327581:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39722,DS-d0bd912c-659d-4228-83dd-bf8a13a6ac07,DISK], DatanodeInfoWithStorage[127.0.0.1:36208,DS-caa6d4d7-1fac-45e1-ab01-9e21722b647f,DISK], DatanodeInfoWithStorage[127.0.0.1:37625,DS-33a0f6a9-5c49-4f59-ab54-5b12fdb99afe,DISK], DatanodeInfoWithStorage[127.0.0.1:38430,DS-915f49ce-c24f-4f38-9c51-c811da185c58,DISK], DatanodeInfoWithStorage[127.0.0.1:44002,DS-841a479e-bbad-4e40-b50e-e0706514c061,DISK], DatanodeInfoWithStorage[127.0.0.1:34343,DS-a2d8cdeb-84f2-4292-83e9-d3047d956338,DISK], DatanodeInfoWithStorage[127.0.0.1:36668,DS-c7b9d3ec-8ff3-4821-aec5-cf34b8d107f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37906,DS-4cec288d-d644-4a0b-8bd2-625094398136,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1757640649-172.17.0.6-1595370454172:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45370,DS-9d8dfb5a-b8c7-4836-9cd6-c3bc5b107ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:40510,DS-309fb14e-fd5c-4137-b482-a513e3207451,DISK], DatanodeInfoWithStorage[127.0.0.1:36976,DS-2555297e-a239-4148-be95-5464085b6929,DISK], DatanodeInfoWithStorage[127.0.0.1:34631,DS-c4c24d75-2ff7-4e32-b530-f184bb68f2f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33233,DS-133f3875-4121-4988-8bc6-72bc735f8489,DISK], DatanodeInfoWithStorage[127.0.0.1:35538,DS-f32df065-7530-4467-a993-a5951f013717,DISK], DatanodeInfoWithStorage[127.0.0.1:46548,DS-a0f7c16f-46b6-4f94-b5ec-e790b293372b,DISK], DatanodeInfoWithStorage[127.0.0.1:36728,DS-7feee948-c5c8-4653-bd32-64690166d82f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1757640649-172.17.0.6-1595370454172:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45370,DS-9d8dfb5a-b8c7-4836-9cd6-c3bc5b107ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:40510,DS-309fb14e-fd5c-4137-b482-a513e3207451,DISK], DatanodeInfoWithStorage[127.0.0.1:36976,DS-2555297e-a239-4148-be95-5464085b6929,DISK], DatanodeInfoWithStorage[127.0.0.1:34631,DS-c4c24d75-2ff7-4e32-b530-f184bb68f2f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33233,DS-133f3875-4121-4988-8bc6-72bc735f8489,DISK], DatanodeInfoWithStorage[127.0.0.1:35538,DS-f32df065-7530-4467-a993-a5951f013717,DISK], DatanodeInfoWithStorage[127.0.0.1:46548,DS-a0f7c16f-46b6-4f94-b5ec-e790b293372b,DISK], DatanodeInfoWithStorage[127.0.0.1:36728,DS-7feee948-c5c8-4653-bd32-64690166d82f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1332580320-172.17.0.6-1595370520442:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40199,DS-0a6ad5f3-ec1f-48c5-893f-a8a1d3d42f22,DISK], DatanodeInfoWithStorage[127.0.0.1:36481,DS-9ccf2710-983a-458c-b33c-2b5435285ff5,DISK], DatanodeInfoWithStorage[127.0.0.1:37831,DS-63cc16dc-0e2d-482a-b33c-484224a8f523,DISK], DatanodeInfoWithStorage[127.0.0.1:32954,DS-2047fc84-e488-4919-ab67-d12702817d73,DISK], DatanodeInfoWithStorage[127.0.0.1:34198,DS-949fc0a4-83d4-4548-9cdc-0749a6b85bca,DISK], DatanodeInfoWithStorage[127.0.0.1:34880,DS-374507e4-667c-42be-9d65-da758dc6f97b,DISK], DatanodeInfoWithStorage[127.0.0.1:45743,DS-d19abe7b-a5f0-4226-9fd3-054c77f78c93,DISK], DatanodeInfoWithStorage[127.0.0.1:32798,DS-7fda6926-d581-426c-970e-61b17f2e7267,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1332580320-172.17.0.6-1595370520442:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40199,DS-0a6ad5f3-ec1f-48c5-893f-a8a1d3d42f22,DISK], DatanodeInfoWithStorage[127.0.0.1:36481,DS-9ccf2710-983a-458c-b33c-2b5435285ff5,DISK], DatanodeInfoWithStorage[127.0.0.1:37831,DS-63cc16dc-0e2d-482a-b33c-484224a8f523,DISK], DatanodeInfoWithStorage[127.0.0.1:32954,DS-2047fc84-e488-4919-ab67-d12702817d73,DISK], DatanodeInfoWithStorage[127.0.0.1:34198,DS-949fc0a4-83d4-4548-9cdc-0749a6b85bca,DISK], DatanodeInfoWithStorage[127.0.0.1:34880,DS-374507e4-667c-42be-9d65-da758dc6f97b,DISK], DatanodeInfoWithStorage[127.0.0.1:45743,DS-d19abe7b-a5f0-4226-9fd3-054c77f78c93,DISK], DatanodeInfoWithStorage[127.0.0.1:32798,DS-7fda6926-d581-426c-970e-61b17f2e7267,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-540219805-172.17.0.6-1595370790225:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37189,DS-2f2b6ce1-75d3-44b1-9178-7a8df0c9144b,DISK], DatanodeInfoWithStorage[127.0.0.1:35561,DS-1531648e-3209-49d8-8318-e710cd655042,DISK], DatanodeInfoWithStorage[127.0.0.1:44917,DS-3e5e0713-9066-4a0d-933f-f08d44322e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:45442,DS-64f30f62-5307-422b-8d04-e1ae35fdab4e,DISK], DatanodeInfoWithStorage[127.0.0.1:33433,DS-d33906a7-c3f5-49aa-8fc7-d4b9434a66f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41631,DS-6720e765-6e81-4ba4-ac4e-794717e936e0,DISK], DatanodeInfoWithStorage[127.0.0.1:38772,DS-3409e54f-9a62-49f7-8534-3aacabc9f308,DISK], DatanodeInfoWithStorage[127.0.0.1:45633,DS-531dff7b-ec2e-413e-9c81-0f8770a95b6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-540219805-172.17.0.6-1595370790225:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37189,DS-2f2b6ce1-75d3-44b1-9178-7a8df0c9144b,DISK], DatanodeInfoWithStorage[127.0.0.1:35561,DS-1531648e-3209-49d8-8318-e710cd655042,DISK], DatanodeInfoWithStorage[127.0.0.1:44917,DS-3e5e0713-9066-4a0d-933f-f08d44322e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:45442,DS-64f30f62-5307-422b-8d04-e1ae35fdab4e,DISK], DatanodeInfoWithStorage[127.0.0.1:33433,DS-d33906a7-c3f5-49aa-8fc7-d4b9434a66f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41631,DS-6720e765-6e81-4ba4-ac4e-794717e936e0,DISK], DatanodeInfoWithStorage[127.0.0.1:38772,DS-3409e54f-9a62-49f7-8534-3aacabc9f308,DISK], DatanodeInfoWithStorage[127.0.0.1:45633,DS-531dff7b-ec2e-413e-9c81-0f8770a95b6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1374092458-172.17.0.6-1595370961093:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37663,DS-74e54ce3-d284-46d8-a83c-ccb0c4d4d96b,DISK], DatanodeInfoWithStorage[127.0.0.1:37097,DS-69f5a899-b05d-4a47-ab80-053d542a728e,DISK], DatanodeInfoWithStorage[127.0.0.1:45054,DS-f832e9b4-66a7-4776-b79c-c452b68053e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45390,DS-547e4e12-cdd7-456c-aa9d-8cc97c25e944,DISK], DatanodeInfoWithStorage[127.0.0.1:35240,DS-e8ab134a-293f-417f-8077-e49c725fcd69,DISK], DatanodeInfoWithStorage[127.0.0.1:37129,DS-4437f747-4338-4342-bdc4-fa9c289cb4c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36660,DS-1c230100-4c79-4592-a99d-602b541e6d6e,DISK], DatanodeInfoWithStorage[127.0.0.1:35611,DS-fedf3ada-3507-4847-8d73-57416150ce29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1374092458-172.17.0.6-1595370961093:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37663,DS-74e54ce3-d284-46d8-a83c-ccb0c4d4d96b,DISK], DatanodeInfoWithStorage[127.0.0.1:37097,DS-69f5a899-b05d-4a47-ab80-053d542a728e,DISK], DatanodeInfoWithStorage[127.0.0.1:45054,DS-f832e9b4-66a7-4776-b79c-c452b68053e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45390,DS-547e4e12-cdd7-456c-aa9d-8cc97c25e944,DISK], DatanodeInfoWithStorage[127.0.0.1:35240,DS-e8ab134a-293f-417f-8077-e49c725fcd69,DISK], DatanodeInfoWithStorage[127.0.0.1:37129,DS-4437f747-4338-4342-bdc4-fa9c289cb4c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36660,DS-1c230100-4c79-4592-a99d-602b541e6d6e,DISK], DatanodeInfoWithStorage[127.0.0.1:35611,DS-fedf3ada-3507-4847-8d73-57416150ce29,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-635942350-172.17.0.6-1595371178323:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44414,DS-b58a8115-813e-4b6a-ac8f-6e81c814a9e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42408,DS-02e6ccd5-e364-48c3-bf86-05ecc93d6592,DISK], DatanodeInfoWithStorage[127.0.0.1:41348,DS-b7c68bb3-4c44-4445-b49a-064ba3155dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:34801,DS-5d6b24ac-7a2d-4f79-ad9e-f6edd3761798,DISK], DatanodeInfoWithStorage[127.0.0.1:42356,DS-0b5ea31e-d864-4bd3-8b06-6e842dad31c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40531,DS-1a1125be-52f5-40fc-bf09-a09117881ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:46791,DS-e8e123f7-cd55-457c-994a-c430a2919941,DISK], DatanodeInfoWithStorage[127.0.0.1:45988,DS-0007bf60-01b7-4502-b7ab-9b98c426d21e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-635942350-172.17.0.6-1595371178323:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44414,DS-b58a8115-813e-4b6a-ac8f-6e81c814a9e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42408,DS-02e6ccd5-e364-48c3-bf86-05ecc93d6592,DISK], DatanodeInfoWithStorage[127.0.0.1:41348,DS-b7c68bb3-4c44-4445-b49a-064ba3155dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:34801,DS-5d6b24ac-7a2d-4f79-ad9e-f6edd3761798,DISK], DatanodeInfoWithStorage[127.0.0.1:42356,DS-0b5ea31e-d864-4bd3-8b06-6e842dad31c3,DISK], DatanodeInfoWithStorage[127.0.0.1:40531,DS-1a1125be-52f5-40fc-bf09-a09117881ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:46791,DS-e8e123f7-cd55-457c-994a-c430a2919941,DISK], DatanodeInfoWithStorage[127.0.0.1:45988,DS-0007bf60-01b7-4502-b7ab-9b98c426d21e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2076750143-172.17.0.6-1595371529552:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33942,DS-c1b1dbce-6d62-4ca4-825b-d27e34cf0680,DISK], DatanodeInfoWithStorage[127.0.0.1:37756,DS-1c79bb54-51d9-4c2c-b699-5fd60f337077,DISK], DatanodeInfoWithStorage[127.0.0.1:46377,DS-a6f86136-f0c2-4714-8c8c-93696884d163,DISK], DatanodeInfoWithStorage[127.0.0.1:44548,DS-bd3f4abf-b8ff-4f4f-90d5-bcfdff712947,DISK], DatanodeInfoWithStorage[127.0.0.1:36626,DS-b81d8b59-45f8-431e-a016-8752faaa7716,DISK], DatanodeInfoWithStorage[127.0.0.1:39112,DS-8a7de5d9-1ff3-467f-bfde-789d0cbde7f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37351,DS-01c7afac-ee58-4c00-8a1c-fdf6fa3af718,DISK], DatanodeInfoWithStorage[127.0.0.1:36977,DS-bab53e1e-b26d-4977-a66f-07bb558a4e53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2076750143-172.17.0.6-1595371529552:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33942,DS-c1b1dbce-6d62-4ca4-825b-d27e34cf0680,DISK], DatanodeInfoWithStorage[127.0.0.1:37756,DS-1c79bb54-51d9-4c2c-b699-5fd60f337077,DISK], DatanodeInfoWithStorage[127.0.0.1:46377,DS-a6f86136-f0c2-4714-8c8c-93696884d163,DISK], DatanodeInfoWithStorage[127.0.0.1:44548,DS-bd3f4abf-b8ff-4f4f-90d5-bcfdff712947,DISK], DatanodeInfoWithStorage[127.0.0.1:36626,DS-b81d8b59-45f8-431e-a016-8752faaa7716,DISK], DatanodeInfoWithStorage[127.0.0.1:39112,DS-8a7de5d9-1ff3-467f-bfde-789d0cbde7f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37351,DS-01c7afac-ee58-4c00-8a1c-fdf6fa3af718,DISK], DatanodeInfoWithStorage[127.0.0.1:36977,DS-bab53e1e-b26d-4977-a66f-07bb558a4e53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-879208565-172.17.0.6-1595371751447:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41672,DS-cee9aa7a-0061-45a4-88a3-82add9e5d1f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45628,DS-4a2660eb-060b-49cd-bc0e-385811a16bf6,DISK], DatanodeInfoWithStorage[127.0.0.1:38961,DS-139ea6cd-3ba2-423b-907c-7d80e35b84b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40431,DS-e024762d-6cd3-46c8-b2d8-6f70f633635d,DISK], DatanodeInfoWithStorage[127.0.0.1:34441,DS-e239769b-c53b-4b51-a948-170385c50c79,DISK], DatanodeInfoWithStorage[127.0.0.1:39054,DS-53331dec-68af-436a-a7e4-707433fbab9d,DISK], DatanodeInfoWithStorage[127.0.0.1:37176,DS-f11abd36-f88b-47d7-845c-4103f67f5360,DISK], DatanodeInfoWithStorage[127.0.0.1:35675,DS-92263390-4050-430c-ba73-47c99a02e652,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-879208565-172.17.0.6-1595371751447:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41672,DS-cee9aa7a-0061-45a4-88a3-82add9e5d1f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45628,DS-4a2660eb-060b-49cd-bc0e-385811a16bf6,DISK], DatanodeInfoWithStorage[127.0.0.1:38961,DS-139ea6cd-3ba2-423b-907c-7d80e35b84b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40431,DS-e024762d-6cd3-46c8-b2d8-6f70f633635d,DISK], DatanodeInfoWithStorage[127.0.0.1:34441,DS-e239769b-c53b-4b51-a948-170385c50c79,DISK], DatanodeInfoWithStorage[127.0.0.1:39054,DS-53331dec-68af-436a-a7e4-707433fbab9d,DISK], DatanodeInfoWithStorage[127.0.0.1:37176,DS-f11abd36-f88b-47d7-845c-4103f67f5360,DISK], DatanodeInfoWithStorage[127.0.0.1:35675,DS-92263390-4050-430c-ba73-47c99a02e652,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1728306514-172.17.0.6-1595372039972:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34305,DS-06a5b7b8-00fa-4ba9-87ae-b8d8036f15ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42817,DS-1898ab99-ce9a-41bf-8e3e-915d7c18d3fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40939,DS-3655ba12-2a7d-4785-81b9-590be4c1a006,DISK], DatanodeInfoWithStorage[127.0.0.1:33703,DS-4e0fd52d-cc82-471c-93bf-7ceba3c88f51,DISK], DatanodeInfoWithStorage[127.0.0.1:45144,DS-e5b964c1-f1c1-4375-b599-2024884568d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35757,DS-dafd3b68-3e14-4d90-9e7e-fcb87eba7300,DISK], DatanodeInfoWithStorage[127.0.0.1:36417,DS-a83ff7ca-286c-48f9-80a7-e58e407210c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35805,DS-d42c1500-a519-46ad-9e20-5ab139e876a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1728306514-172.17.0.6-1595372039972:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34305,DS-06a5b7b8-00fa-4ba9-87ae-b8d8036f15ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42817,DS-1898ab99-ce9a-41bf-8e3e-915d7c18d3fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40939,DS-3655ba12-2a7d-4785-81b9-590be4c1a006,DISK], DatanodeInfoWithStorage[127.0.0.1:33703,DS-4e0fd52d-cc82-471c-93bf-7ceba3c88f51,DISK], DatanodeInfoWithStorage[127.0.0.1:45144,DS-e5b964c1-f1c1-4375-b599-2024884568d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35757,DS-dafd3b68-3e14-4d90-9e7e-fcb87eba7300,DISK], DatanodeInfoWithStorage[127.0.0.1:36417,DS-a83ff7ca-286c-48f9-80a7-e58e407210c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35805,DS-d42c1500-a519-46ad-9e20-5ab139e876a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-487041262-172.17.0.6-1595372148219:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40071,DS-5467ee51-42db-41cd-b18b-e90f9041c0db,DISK], DatanodeInfoWithStorage[127.0.0.1:39637,DS-0370c0d3-cd13-4053-a0c9-4ba505121dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:35478,DS-36a3d2b9-9a92-4c45-9ea8-e577032477f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39480,DS-8eb71707-cf43-47fd-9673-e5fe81062381,DISK], DatanodeInfoWithStorage[127.0.0.1:37384,DS-c9a2bf85-0400-4e49-a401-21ab1ccf6efe,DISK], DatanodeInfoWithStorage[127.0.0.1:37402,DS-89a7489b-51bc-48a1-9be4-02989d68a5d6,DISK], DatanodeInfoWithStorage[127.0.0.1:46756,DS-58562a25-5254-4bfd-86c7-acacb027001d,DISK], DatanodeInfoWithStorage[127.0.0.1:33055,DS-42185f78-6d8d-4b52-b44c-5cd6a452fa16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-487041262-172.17.0.6-1595372148219:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40071,DS-5467ee51-42db-41cd-b18b-e90f9041c0db,DISK], DatanodeInfoWithStorage[127.0.0.1:39637,DS-0370c0d3-cd13-4053-a0c9-4ba505121dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:35478,DS-36a3d2b9-9a92-4c45-9ea8-e577032477f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39480,DS-8eb71707-cf43-47fd-9673-e5fe81062381,DISK], DatanodeInfoWithStorage[127.0.0.1:37384,DS-c9a2bf85-0400-4e49-a401-21ab1ccf6efe,DISK], DatanodeInfoWithStorage[127.0.0.1:37402,DS-89a7489b-51bc-48a1-9be4-02989d68a5d6,DISK], DatanodeInfoWithStorage[127.0.0.1:46756,DS-58562a25-5254-4bfd-86c7-acacb027001d,DISK], DatanodeInfoWithStorage[127.0.0.1:33055,DS-42185f78-6d8d-4b52-b44c-5cd6a452fa16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1992084595-172.17.0.6-1595372357333:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34769,DS-bec769d8-62e0-4844-bfd3-7203aeed296a,DISK], DatanodeInfoWithStorage[127.0.0.1:38206,DS-e7b9227a-8427-4b1b-8ed4-b9fd0a5a23fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38751,DS-6ab2dc80-ea1d-4638-98e2-357cc4124b7b,DISK], DatanodeInfoWithStorage[127.0.0.1:46154,DS-2dedea1a-3a34-4943-9e73-21f158993f07,DISK], DatanodeInfoWithStorage[127.0.0.1:44067,DS-45fea917-5ba3-4d7e-827a-225d441c9991,DISK], DatanodeInfoWithStorage[127.0.0.1:41807,DS-930481df-aa6d-4b2f-b2c1-7489f5f549b4,DISK], DatanodeInfoWithStorage[127.0.0.1:43714,DS-7b1521d2-36f7-48bb-a82d-77c7aafe3f60,DISK], DatanodeInfoWithStorage[127.0.0.1:46445,DS-9582fa08-f157-4feb-9c77-d62e6cb892b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1992084595-172.17.0.6-1595372357333:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34769,DS-bec769d8-62e0-4844-bfd3-7203aeed296a,DISK], DatanodeInfoWithStorage[127.0.0.1:38206,DS-e7b9227a-8427-4b1b-8ed4-b9fd0a5a23fb,DISK], DatanodeInfoWithStorage[127.0.0.1:38751,DS-6ab2dc80-ea1d-4638-98e2-357cc4124b7b,DISK], DatanodeInfoWithStorage[127.0.0.1:46154,DS-2dedea1a-3a34-4943-9e73-21f158993f07,DISK], DatanodeInfoWithStorage[127.0.0.1:44067,DS-45fea917-5ba3-4d7e-827a-225d441c9991,DISK], DatanodeInfoWithStorage[127.0.0.1:41807,DS-930481df-aa6d-4b2f-b2c1-7489f5f549b4,DISK], DatanodeInfoWithStorage[127.0.0.1:43714,DS-7b1521d2-36f7-48bb-a82d-77c7aafe3f60,DISK], DatanodeInfoWithStorage[127.0.0.1:46445,DS-9582fa08-f157-4feb-9c77-d62e6cb892b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.ping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1008534413-172.17.0.6-1595372392549:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46438,DS-5a0e2672-47ef-47a9-86dd-8766b0e6be72,DISK], DatanodeInfoWithStorage[127.0.0.1:43827,DS-ce4e30eb-b49e-4dce-b9e9-6329e1bcc74b,DISK], DatanodeInfoWithStorage[127.0.0.1:38856,DS-eaadb927-a9aa-4331-8ccf-125fba5de449,DISK], DatanodeInfoWithStorage[127.0.0.1:42623,DS-37d12661-f9d4-4a6c-a78b-6db835d1aa59,DISK], DatanodeInfoWithStorage[127.0.0.1:41552,DS-f245d9e6-841e-4197-9267-8785546f01e7,DISK], DatanodeInfoWithStorage[127.0.0.1:38602,DS-1b432438-2098-4ca2-ad1b-01e5d5592791,DISK], DatanodeInfoWithStorage[127.0.0.1:41466,DS-d22a9ba3-958e-484b-b662-137193e2f685,DISK], DatanodeInfoWithStorage[127.0.0.1:38884,DS-c44eb467-9571-4f23-ae4a-3360db002e68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1008534413-172.17.0.6-1595372392549:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46438,DS-5a0e2672-47ef-47a9-86dd-8766b0e6be72,DISK], DatanodeInfoWithStorage[127.0.0.1:43827,DS-ce4e30eb-b49e-4dce-b9e9-6329e1bcc74b,DISK], DatanodeInfoWithStorage[127.0.0.1:38856,DS-eaadb927-a9aa-4331-8ccf-125fba5de449,DISK], DatanodeInfoWithStorage[127.0.0.1:42623,DS-37d12661-f9d4-4a6c-a78b-6db835d1aa59,DISK], DatanodeInfoWithStorage[127.0.0.1:41552,DS-f245d9e6-841e-4197-9267-8785546f01e7,DISK], DatanodeInfoWithStorage[127.0.0.1:38602,DS-1b432438-2098-4ca2-ad1b-01e5d5592791,DISK], DatanodeInfoWithStorage[127.0.0.1:41466,DS-d22a9ba3-958e-484b-b662-137193e2f685,DISK], DatanodeInfoWithStorage[127.0.0.1:38884,DS-c44eb467-9571-4f23-ae4a-3360db002e68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-314768938-172.17.0.6-1595372573200:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42001,DS-1092f94b-cb63-424f-aeee-4f26d830733f,DISK], DatanodeInfoWithStorage[127.0.0.1:44515,DS-548affe5-d819-4105-a25f-def8c0d2b330,DISK], DatanodeInfoWithStorage[127.0.0.1:32797,DS-02d61b91-839b-446b-b4f5-5c460ec66a42,DISK], DatanodeInfoWithStorage[127.0.0.1:45668,DS-007054af-93af-4d6d-a889-971020ab7421,DISK], DatanodeInfoWithStorage[127.0.0.1:45616,DS-d42270e3-ec4f-4845-ba60-43484b50a13b,DISK], DatanodeInfoWithStorage[127.0.0.1:33920,DS-23e76348-af45-4610-adf6-796332809098,DISK], DatanodeInfoWithStorage[127.0.0.1:38958,DS-a8896e61-165d-4c61-b894-a08146173613,DISK], DatanodeInfoWithStorage[127.0.0.1:38938,DS-95350c6e-08e5-4bf8-88fe-d6620bcf6450,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-314768938-172.17.0.6-1595372573200:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42001,DS-1092f94b-cb63-424f-aeee-4f26d830733f,DISK], DatanodeInfoWithStorage[127.0.0.1:44515,DS-548affe5-d819-4105-a25f-def8c0d2b330,DISK], DatanodeInfoWithStorage[127.0.0.1:32797,DS-02d61b91-839b-446b-b4f5-5c460ec66a42,DISK], DatanodeInfoWithStorage[127.0.0.1:45668,DS-007054af-93af-4d6d-a889-971020ab7421,DISK], DatanodeInfoWithStorage[127.0.0.1:45616,DS-d42270e3-ec4f-4845-ba60-43484b50a13b,DISK], DatanodeInfoWithStorage[127.0.0.1:33920,DS-23e76348-af45-4610-adf6-796332809098,DISK], DatanodeInfoWithStorage[127.0.0.1:38958,DS-a8896e61-165d-4c61-b894-a08146173613,DISK], DatanodeInfoWithStorage[127.0.0.1:38938,DS-95350c6e-08e5-4bf8-88fe-d6620bcf6450,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2132741866-172.17.0.6-1595372948826:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34096,DS-5268852e-c67c-48e6-b13f-1c7eb168b425,DISK], DatanodeInfoWithStorage[127.0.0.1:36093,DS-4f44a0e3-8300-4608-b123-4cb365f2afcb,DISK], DatanodeInfoWithStorage[127.0.0.1:45368,DS-9d13c8e2-e924-4654-bb65-ef0af8852937,DISK], DatanodeInfoWithStorage[127.0.0.1:39711,DS-5ff44a00-20a2-40d3-b76b-305717638ec4,DISK], DatanodeInfoWithStorage[127.0.0.1:43432,DS-dce1c869-34c4-4da3-8318-a30942c6d89d,DISK], DatanodeInfoWithStorage[127.0.0.1:39227,DS-1eec7052-04ac-462b-81e7-737743e93b89,DISK], DatanodeInfoWithStorage[127.0.0.1:41064,DS-e0d464e4-a065-42e5-a563-edabda7ee7d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44974,DS-895415d1-d5ba-4f59-b9f5-a99efd730c6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2132741866-172.17.0.6-1595372948826:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34096,DS-5268852e-c67c-48e6-b13f-1c7eb168b425,DISK], DatanodeInfoWithStorage[127.0.0.1:36093,DS-4f44a0e3-8300-4608-b123-4cb365f2afcb,DISK], DatanodeInfoWithStorage[127.0.0.1:45368,DS-9d13c8e2-e924-4654-bb65-ef0af8852937,DISK], DatanodeInfoWithStorage[127.0.0.1:39711,DS-5ff44a00-20a2-40d3-b76b-305717638ec4,DISK], DatanodeInfoWithStorage[127.0.0.1:43432,DS-dce1c869-34c4-4da3-8318-a30942c6d89d,DISK], DatanodeInfoWithStorage[127.0.0.1:39227,DS-1eec7052-04ac-462b-81e7-737743e93b89,DISK], DatanodeInfoWithStorage[127.0.0.1:41064,DS-e0d464e4-a065-42e5-a563-edabda7ee7d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44974,DS-895415d1-d5ba-4f59-b9f5-a99efd730c6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-628230738-172.17.0.6-1595373336014:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35279,DS-18afb79b-7bac-4cfd-a0b6-240edbb9f4c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35471,DS-85be4b1b-1e0f-4261-8ccb-edc31e87b1f5,DISK], DatanodeInfoWithStorage[127.0.0.1:46312,DS-cfac59c3-c4cd-4f7f-b11b-a1a3c8e9f26b,DISK], DatanodeInfoWithStorage[127.0.0.1:44197,DS-54801ba5-7532-4196-83ff-00fc23892d8d,DISK], DatanodeInfoWithStorage[127.0.0.1:35329,DS-6324e09c-1c33-43e7-b6b9-929f84ccc84d,DISK], DatanodeInfoWithStorage[127.0.0.1:35803,DS-8f4f50e7-e197-43db-b54c-b2459f80dc9a,DISK], DatanodeInfoWithStorage[127.0.0.1:40481,DS-e75ecc52-4f5d-4b38-9a8b-26f9748fa718,DISK], DatanodeInfoWithStorage[127.0.0.1:38773,DS-3ee9cdcd-299f-4bab-b8c6-d8acb882efd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-628230738-172.17.0.6-1595373336014:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35279,DS-18afb79b-7bac-4cfd-a0b6-240edbb9f4c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35471,DS-85be4b1b-1e0f-4261-8ccb-edc31e87b1f5,DISK], DatanodeInfoWithStorage[127.0.0.1:46312,DS-cfac59c3-c4cd-4f7f-b11b-a1a3c8e9f26b,DISK], DatanodeInfoWithStorage[127.0.0.1:44197,DS-54801ba5-7532-4196-83ff-00fc23892d8d,DISK], DatanodeInfoWithStorage[127.0.0.1:35329,DS-6324e09c-1c33-43e7-b6b9-929f84ccc84d,DISK], DatanodeInfoWithStorage[127.0.0.1:35803,DS-8f4f50e7-e197-43db-b54c-b2459f80dc9a,DISK], DatanodeInfoWithStorage[127.0.0.1:40481,DS-e75ecc52-4f5d-4b38-9a8b-26f9748fa718,DISK], DatanodeInfoWithStorage[127.0.0.1:38773,DS-3ee9cdcd-299f-4bab-b8c6-d8acb882efd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1620091476-172.17.0.6-1595373549152:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38809,DS-d7d19f39-36f1-439d-8355-1730058b8bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:41553,DS-8b3502b3-d1e7-4b7b-b6cb-a8601a4294b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34327,DS-5f7a8134-0617-4624-ba42-2a6b2a96b537,DISK], DatanodeInfoWithStorage[127.0.0.1:33912,DS-e2885137-262e-4d13-9b94-f283505d408f,DISK], DatanodeInfoWithStorage[127.0.0.1:35686,DS-c8033c2d-5ef7-42d0-8e2b-2f5aba7cfe9d,DISK], DatanodeInfoWithStorage[127.0.0.1:34545,DS-7433e5a4-73ee-4e2a-8e20-ef259fefe2be,DISK], DatanodeInfoWithStorage[127.0.0.1:46349,DS-d5fd7770-1c82-4a2c-a829-85cc0cda9e02,DISK], DatanodeInfoWithStorage[127.0.0.1:38806,DS-678369c2-b212-4199-8852-3ec10ed3a6c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1620091476-172.17.0.6-1595373549152:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38809,DS-d7d19f39-36f1-439d-8355-1730058b8bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:41553,DS-8b3502b3-d1e7-4b7b-b6cb-a8601a4294b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34327,DS-5f7a8134-0617-4624-ba42-2a6b2a96b537,DISK], DatanodeInfoWithStorage[127.0.0.1:33912,DS-e2885137-262e-4d13-9b94-f283505d408f,DISK], DatanodeInfoWithStorage[127.0.0.1:35686,DS-c8033c2d-5ef7-42d0-8e2b-2f5aba7cfe9d,DISK], DatanodeInfoWithStorage[127.0.0.1:34545,DS-7433e5a4-73ee-4e2a-8e20-ef259fefe2be,DISK], DatanodeInfoWithStorage[127.0.0.1:46349,DS-d5fd7770-1c82-4a2c-a829-85cc0cda9e02,DISK], DatanodeInfoWithStorage[127.0.0.1:38806,DS-678369c2-b212-4199-8852-3ec10ed3a6c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-905532294-172.17.0.6-1595373864601:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45293,DS-07db793d-f318-4358-a35e-178b178aed56,DISK], DatanodeInfoWithStorage[127.0.0.1:38800,DS-803269a2-656c-41f0-81f2-74696f8f00ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41483,DS-403f22e4-967f-4f2c-95a8-944ac80b8247,DISK], DatanodeInfoWithStorage[127.0.0.1:45657,DS-0f95a791-ca3c-455e-a37f-3dd0ed07a058,DISK], DatanodeInfoWithStorage[127.0.0.1:34257,DS-923de95d-8d0e-46a3-b6f0-2abe326c9bc6,DISK], DatanodeInfoWithStorage[127.0.0.1:35355,DS-d15e5b16-5763-45e8-b5af-0ea64dc688bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41113,DS-43bbf902-c72b-4f3d-8068-067de4472fed,DISK], DatanodeInfoWithStorage[127.0.0.1:33769,DS-7c6a50f3-7486-42ad-8dd4-539c55d2c63b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-905532294-172.17.0.6-1595373864601:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45293,DS-07db793d-f318-4358-a35e-178b178aed56,DISK], DatanodeInfoWithStorage[127.0.0.1:38800,DS-803269a2-656c-41f0-81f2-74696f8f00ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41483,DS-403f22e4-967f-4f2c-95a8-944ac80b8247,DISK], DatanodeInfoWithStorage[127.0.0.1:45657,DS-0f95a791-ca3c-455e-a37f-3dd0ed07a058,DISK], DatanodeInfoWithStorage[127.0.0.1:34257,DS-923de95d-8d0e-46a3-b6f0-2abe326c9bc6,DISK], DatanodeInfoWithStorage[127.0.0.1:35355,DS-d15e5b16-5763-45e8-b5af-0ea64dc688bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41113,DS-43bbf902-c72b-4f3d-8068-067de4472fed,DISK], DatanodeInfoWithStorage[127.0.0.1:33769,DS-7c6a50f3-7486-42ad-8dd4-539c55d2c63b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5208
