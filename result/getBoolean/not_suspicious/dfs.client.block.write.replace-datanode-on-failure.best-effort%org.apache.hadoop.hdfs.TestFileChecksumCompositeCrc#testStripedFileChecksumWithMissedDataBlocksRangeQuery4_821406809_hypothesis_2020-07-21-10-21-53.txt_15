reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-303213120-172.17.0.12-1595326965484:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34676,DS-b05d0398-5f68-4b7c-940a-e035d57058e8,DISK], DatanodeInfoWithStorage[127.0.0.1:44813,DS-46ff2c26-287c-4436-9250-e594491a344f,DISK], DatanodeInfoWithStorage[127.0.0.1:36792,DS-eb2a1523-849e-48db-afb7-50dcc4ecdfc2,DISK], DatanodeInfoWithStorage[127.0.0.1:35155,DS-402ed895-2388-4e8e-b5a3-46f18846d712,DISK], DatanodeInfoWithStorage[127.0.0.1:42780,DS-c7d6374c-244a-4b8b-86ec-866aadb85293,DISK], DatanodeInfoWithStorage[127.0.0.1:45967,DS-1563de58-7e0f-4c77-997f-d90565fe4fad,DISK], DatanodeInfoWithStorage[127.0.0.1:43085,DS-57010d53-96db-43ee-bc80-ca1f72a80105,DISK], DatanodeInfoWithStorage[127.0.0.1:44869,DS-5e25f9af-62fd-47dc-8707-55cd37ba1b19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-303213120-172.17.0.12-1595326965484:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34676,DS-b05d0398-5f68-4b7c-940a-e035d57058e8,DISK], DatanodeInfoWithStorage[127.0.0.1:44813,DS-46ff2c26-287c-4436-9250-e594491a344f,DISK], DatanodeInfoWithStorage[127.0.0.1:36792,DS-eb2a1523-849e-48db-afb7-50dcc4ecdfc2,DISK], DatanodeInfoWithStorage[127.0.0.1:35155,DS-402ed895-2388-4e8e-b5a3-46f18846d712,DISK], DatanodeInfoWithStorage[127.0.0.1:42780,DS-c7d6374c-244a-4b8b-86ec-866aadb85293,DISK], DatanodeInfoWithStorage[127.0.0.1:45967,DS-1563de58-7e0f-4c77-997f-d90565fe4fad,DISK], DatanodeInfoWithStorage[127.0.0.1:43085,DS-57010d53-96db-43ee-bc80-ca1f72a80105,DISK], DatanodeInfoWithStorage[127.0.0.1:44869,DS-5e25f9af-62fd-47dc-8707-55cd37ba1b19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-407442973-172.17.0.12-1595327397648:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42258,DS-3bc9c837-6ed5-4e59-95e5-0839138b2588,DISK], DatanodeInfoWithStorage[127.0.0.1:33512,DS-717eaf25-0fbb-47a3-8622-f7c75b2fb593,DISK], DatanodeInfoWithStorage[127.0.0.1:39558,DS-c8af7e8a-1a5e-4698-9e46-b44a6c4806f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33774,DS-c3278afa-6cda-4691-bd7c-2e507a7078f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38157,DS-0d1d801b-a900-4dbe-96a0-eacc988198cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40482,DS-a88fb09f-a181-470c-9fb2-6af1f2de4849,DISK], DatanodeInfoWithStorage[127.0.0.1:40740,DS-1491c221-f290-4ffe-9a2f-952f173090ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36621,DS-f8c6e86a-1c78-4b9e-8458-2efeecc20efd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-407442973-172.17.0.12-1595327397648:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42258,DS-3bc9c837-6ed5-4e59-95e5-0839138b2588,DISK], DatanodeInfoWithStorage[127.0.0.1:33512,DS-717eaf25-0fbb-47a3-8622-f7c75b2fb593,DISK], DatanodeInfoWithStorage[127.0.0.1:39558,DS-c8af7e8a-1a5e-4698-9e46-b44a6c4806f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33774,DS-c3278afa-6cda-4691-bd7c-2e507a7078f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38157,DS-0d1d801b-a900-4dbe-96a0-eacc988198cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40482,DS-a88fb09f-a181-470c-9fb2-6af1f2de4849,DISK], DatanodeInfoWithStorage[127.0.0.1:40740,DS-1491c221-f290-4ffe-9a2f-952f173090ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36621,DS-f8c6e86a-1c78-4b9e-8458-2efeecc20efd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-530367293-172.17.0.12-1595327833996:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40445,DS-ba112b4a-76d8-4383-bd4c-41de0cba709e,DISK], DatanodeInfoWithStorage[127.0.0.1:37516,DS-21d13675-c5d3-4843-8f76-dfdac77b4036,DISK], DatanodeInfoWithStorage[127.0.0.1:42826,DS-52b1070a-efe5-4065-932d-2338acfebe80,DISK], DatanodeInfoWithStorage[127.0.0.1:43818,DS-3fd101ed-9323-4090-a142-070dff30af85,DISK], DatanodeInfoWithStorage[127.0.0.1:40977,DS-f941ef9f-3d94-459a-aa1d-1043c21cfd7d,DISK], DatanodeInfoWithStorage[127.0.0.1:40494,DS-1482f480-218e-4afd-9589-7ce705286da4,DISK], DatanodeInfoWithStorage[127.0.0.1:45689,DS-5e377326-5101-4abf-b400-fe40e3cc3781,DISK], DatanodeInfoWithStorage[127.0.0.1:36592,DS-4eae5cc5-8a13-4043-aa33-b338494c9c10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-530367293-172.17.0.12-1595327833996:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40445,DS-ba112b4a-76d8-4383-bd4c-41de0cba709e,DISK], DatanodeInfoWithStorage[127.0.0.1:37516,DS-21d13675-c5d3-4843-8f76-dfdac77b4036,DISK], DatanodeInfoWithStorage[127.0.0.1:42826,DS-52b1070a-efe5-4065-932d-2338acfebe80,DISK], DatanodeInfoWithStorage[127.0.0.1:43818,DS-3fd101ed-9323-4090-a142-070dff30af85,DISK], DatanodeInfoWithStorage[127.0.0.1:40977,DS-f941ef9f-3d94-459a-aa1d-1043c21cfd7d,DISK], DatanodeInfoWithStorage[127.0.0.1:40494,DS-1482f480-218e-4afd-9589-7ce705286da4,DISK], DatanodeInfoWithStorage[127.0.0.1:45689,DS-5e377326-5101-4abf-b400-fe40e3cc3781,DISK], DatanodeInfoWithStorage[127.0.0.1:36592,DS-4eae5cc5-8a13-4043-aa33-b338494c9c10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-923626033-172.17.0.12-1595328057022:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36192,DS-f7d5d240-b347-408c-afb7-898aef143272,DISK], DatanodeInfoWithStorage[127.0.0.1:34953,DS-d9d6d9fe-504c-4147-a081-d07e14070af1,DISK], DatanodeInfoWithStorage[127.0.0.1:33712,DS-39a6c133-d0bd-4c6c-ac90-86cef4911f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:46541,DS-fd04ec56-fd39-401d-9d38-77d23998b984,DISK], DatanodeInfoWithStorage[127.0.0.1:43296,DS-7c54eb26-1744-444d-a73c-dd6f44e73a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:36569,DS-483ddee5-f18e-469b-9aa3-b2ee6519019c,DISK], DatanodeInfoWithStorage[127.0.0.1:35226,DS-d9a5bc4f-8cb5-4eb3-9dac-30c9d5191a97,DISK], DatanodeInfoWithStorage[127.0.0.1:41432,DS-c6b285ae-58ea-46df-8376-adfa109b50f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-923626033-172.17.0.12-1595328057022:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36192,DS-f7d5d240-b347-408c-afb7-898aef143272,DISK], DatanodeInfoWithStorage[127.0.0.1:34953,DS-d9d6d9fe-504c-4147-a081-d07e14070af1,DISK], DatanodeInfoWithStorage[127.0.0.1:33712,DS-39a6c133-d0bd-4c6c-ac90-86cef4911f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:46541,DS-fd04ec56-fd39-401d-9d38-77d23998b984,DISK], DatanodeInfoWithStorage[127.0.0.1:43296,DS-7c54eb26-1744-444d-a73c-dd6f44e73a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:36569,DS-483ddee5-f18e-469b-9aa3-b2ee6519019c,DISK], DatanodeInfoWithStorage[127.0.0.1:35226,DS-d9a5bc4f-8cb5-4eb3-9dac-30c9d5191a97,DISK], DatanodeInfoWithStorage[127.0.0.1:41432,DS-c6b285ae-58ea-46df-8376-adfa109b50f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-462232500-172.17.0.12-1595328378839:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46052,DS-ca2e368d-731f-42b2-aed6-cf7d40e173f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40826,DS-b0dddfa0-5703-441c-85ec-e6976006ffb5,DISK], DatanodeInfoWithStorage[127.0.0.1:46008,DS-04800ea0-1ca5-4b5f-911b-b63209b8d35e,DISK], DatanodeInfoWithStorage[127.0.0.1:40807,DS-0bbb28fa-c91d-4038-a193-e32a9824a01f,DISK], DatanodeInfoWithStorage[127.0.0.1:42368,DS-17735ab2-b857-4538-a50b-623929cb7dcd,DISK], DatanodeInfoWithStorage[127.0.0.1:36675,DS-57e4dc71-2f59-498b-9532-030d548bbf11,DISK], DatanodeInfoWithStorage[127.0.0.1:33385,DS-ab3c1b7e-bd68-406e-9406-0112a8b72523,DISK], DatanodeInfoWithStorage[127.0.0.1:40232,DS-c707d58d-26e7-482e-b53e-35ae8a7d5f7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-462232500-172.17.0.12-1595328378839:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46052,DS-ca2e368d-731f-42b2-aed6-cf7d40e173f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40826,DS-b0dddfa0-5703-441c-85ec-e6976006ffb5,DISK], DatanodeInfoWithStorage[127.0.0.1:46008,DS-04800ea0-1ca5-4b5f-911b-b63209b8d35e,DISK], DatanodeInfoWithStorage[127.0.0.1:40807,DS-0bbb28fa-c91d-4038-a193-e32a9824a01f,DISK], DatanodeInfoWithStorage[127.0.0.1:42368,DS-17735ab2-b857-4538-a50b-623929cb7dcd,DISK], DatanodeInfoWithStorage[127.0.0.1:36675,DS-57e4dc71-2f59-498b-9532-030d548bbf11,DISK], DatanodeInfoWithStorage[127.0.0.1:33385,DS-ab3c1b7e-bd68-406e-9406-0112a8b72523,DISK], DatanodeInfoWithStorage[127.0.0.1:40232,DS-c707d58d-26e7-482e-b53e-35ae8a7d5f7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1007991292-172.17.0.12-1595328820069:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39029,DS-80e02908-52b1-41e5-baca-53b992ac11b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44035,DS-49a86c25-75f9-4f72-bef8-edba7e39483b,DISK], DatanodeInfoWithStorage[127.0.0.1:38271,DS-9dd213aa-ec6c-41a6-a397-0e4eb6cadef3,DISK], DatanodeInfoWithStorage[127.0.0.1:39258,DS-138b9444-e3fa-4f76-adc8-e56f548156f8,DISK], DatanodeInfoWithStorage[127.0.0.1:43814,DS-50ac29dc-d00b-4b29-8a35-cde1db43cb09,DISK], DatanodeInfoWithStorage[127.0.0.1:38836,DS-e35254db-fc6b-4d2e-94f0-90d4a2be5a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:41424,DS-0e4b6d8e-6e4a-4e2c-89fe-20cbe70ba41c,DISK], DatanodeInfoWithStorage[127.0.0.1:36287,DS-393bddca-a1ca-442e-97ff-7564277cf035,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1007991292-172.17.0.12-1595328820069:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39029,DS-80e02908-52b1-41e5-baca-53b992ac11b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44035,DS-49a86c25-75f9-4f72-bef8-edba7e39483b,DISK], DatanodeInfoWithStorage[127.0.0.1:38271,DS-9dd213aa-ec6c-41a6-a397-0e4eb6cadef3,DISK], DatanodeInfoWithStorage[127.0.0.1:39258,DS-138b9444-e3fa-4f76-adc8-e56f548156f8,DISK], DatanodeInfoWithStorage[127.0.0.1:43814,DS-50ac29dc-d00b-4b29-8a35-cde1db43cb09,DISK], DatanodeInfoWithStorage[127.0.0.1:38836,DS-e35254db-fc6b-4d2e-94f0-90d4a2be5a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:41424,DS-0e4b6d8e-6e4a-4e2c-89fe-20cbe70ba41c,DISK], DatanodeInfoWithStorage[127.0.0.1:36287,DS-393bddca-a1ca-442e-97ff-7564277cf035,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1603957103-172.17.0.12-1595330133307:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41771,DS-78f12059-339c-4bfa-8b09-0dc166306735,DISK], DatanodeInfoWithStorage[127.0.0.1:42678,DS-e2606dc9-bb77-4800-b33a-be698d4a011f,DISK], DatanodeInfoWithStorage[127.0.0.1:46225,DS-39f738f0-d1f4-4316-b83f-f75f384d4c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:32860,DS-bf63f378-bf26-435f-8fb7-248f173eaa91,DISK], DatanodeInfoWithStorage[127.0.0.1:44661,DS-db9f2981-3049-48a5-9b8e-0319afcff194,DISK], DatanodeInfoWithStorage[127.0.0.1:38150,DS-b12c3494-4c35-47d6-9212-b83f278c6613,DISK], DatanodeInfoWithStorage[127.0.0.1:35414,DS-4bb32829-5363-4acc-80e0-6466ca35e9bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41559,DS-22a54ebc-8f7a-4b01-b6df-09052e3f7572,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1603957103-172.17.0.12-1595330133307:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41771,DS-78f12059-339c-4bfa-8b09-0dc166306735,DISK], DatanodeInfoWithStorage[127.0.0.1:42678,DS-e2606dc9-bb77-4800-b33a-be698d4a011f,DISK], DatanodeInfoWithStorage[127.0.0.1:46225,DS-39f738f0-d1f4-4316-b83f-f75f384d4c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:32860,DS-bf63f378-bf26-435f-8fb7-248f173eaa91,DISK], DatanodeInfoWithStorage[127.0.0.1:44661,DS-db9f2981-3049-48a5-9b8e-0319afcff194,DISK], DatanodeInfoWithStorage[127.0.0.1:38150,DS-b12c3494-4c35-47d6-9212-b83f278c6613,DISK], DatanodeInfoWithStorage[127.0.0.1:35414,DS-4bb32829-5363-4acc-80e0-6466ca35e9bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41559,DS-22a54ebc-8f7a-4b01-b6df-09052e3f7572,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-508982345-172.17.0.12-1595330293463:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41917,DS-4541a07e-12d0-4f51-bff6-43b86fda8673,DISK], DatanodeInfoWithStorage[127.0.0.1:36073,DS-a0254290-10cc-4f75-980a-9aa5e280401d,DISK], DatanodeInfoWithStorage[127.0.0.1:44969,DS-21702ff3-85b5-4f27-8316-91b2ca9f5004,DISK], DatanodeInfoWithStorage[127.0.0.1:35171,DS-6914c784-158c-44d9-9f86-6dd54ba45991,DISK], DatanodeInfoWithStorage[127.0.0.1:39711,DS-f0a0d3c5-387a-4750-920c-f11cfcd38dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:35191,DS-89f4bf88-cf03-4a4e-b5cb-c58ae09d365a,DISK], DatanodeInfoWithStorage[127.0.0.1:45109,DS-aa045f75-9a79-4fd4-ba13-778093b9acae,DISK], DatanodeInfoWithStorage[127.0.0.1:39200,DS-fbd9744c-be2d-4aa2-8c08-154e9ebd8a32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-508982345-172.17.0.12-1595330293463:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41917,DS-4541a07e-12d0-4f51-bff6-43b86fda8673,DISK], DatanodeInfoWithStorage[127.0.0.1:36073,DS-a0254290-10cc-4f75-980a-9aa5e280401d,DISK], DatanodeInfoWithStorage[127.0.0.1:44969,DS-21702ff3-85b5-4f27-8316-91b2ca9f5004,DISK], DatanodeInfoWithStorage[127.0.0.1:35171,DS-6914c784-158c-44d9-9f86-6dd54ba45991,DISK], DatanodeInfoWithStorage[127.0.0.1:39711,DS-f0a0d3c5-387a-4750-920c-f11cfcd38dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:35191,DS-89f4bf88-cf03-4a4e-b5cb-c58ae09d365a,DISK], DatanodeInfoWithStorage[127.0.0.1:45109,DS-aa045f75-9a79-4fd4-ba13-778093b9acae,DISK], DatanodeInfoWithStorage[127.0.0.1:39200,DS-fbd9744c-be2d-4aa2-8c08-154e9ebd8a32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-23288926-172.17.0.12-1595330586198:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38527,DS-6ef77cda-b61c-458b-87a3-b63743aac4c5,DISK], DatanodeInfoWithStorage[127.0.0.1:36661,DS-60f329d3-3b2f-4d33-84d2-4c459298c4b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39595,DS-2cfa313c-d54d-4fc6-9a7f-380605b92da9,DISK], DatanodeInfoWithStorage[127.0.0.1:44257,DS-a81108cc-4517-4b94-891d-2e9fcde95344,DISK], DatanodeInfoWithStorage[127.0.0.1:36655,DS-94477e0c-e2df-4314-9757-3801d49655ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40826,DS-084961c3-2e97-4dbe-a697-62666d0166b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43141,DS-75d4de91-336e-45cd-8618-334d43f96946,DISK], DatanodeInfoWithStorage[127.0.0.1:33523,DS-bfc6c7b4-7193-48aa-8422-ac1366f77099,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-23288926-172.17.0.12-1595330586198:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38527,DS-6ef77cda-b61c-458b-87a3-b63743aac4c5,DISK], DatanodeInfoWithStorage[127.0.0.1:36661,DS-60f329d3-3b2f-4d33-84d2-4c459298c4b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39595,DS-2cfa313c-d54d-4fc6-9a7f-380605b92da9,DISK], DatanodeInfoWithStorage[127.0.0.1:44257,DS-a81108cc-4517-4b94-891d-2e9fcde95344,DISK], DatanodeInfoWithStorage[127.0.0.1:36655,DS-94477e0c-e2df-4314-9757-3801d49655ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40826,DS-084961c3-2e97-4dbe-a697-62666d0166b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43141,DS-75d4de91-336e-45cd-8618-334d43f96946,DISK], DatanodeInfoWithStorage[127.0.0.1:33523,DS-bfc6c7b4-7193-48aa-8422-ac1366f77099,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-984596817-172.17.0.12-1595331429166:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33622,DS-7a270418-33b4-4c87-98da-112c5818fae9,DISK], DatanodeInfoWithStorage[127.0.0.1:40014,DS-c750459d-d10b-4cd4-aa9b-7bbe5efaa670,DISK], DatanodeInfoWithStorage[127.0.0.1:36413,DS-8a7d9f65-e131-415e-a80c-dc50c940a622,DISK], DatanodeInfoWithStorage[127.0.0.1:41419,DS-da253c9d-e1c6-44cb-bce8-6a5be080ad95,DISK], DatanodeInfoWithStorage[127.0.0.1:43110,DS-2b6884d8-cbe4-42a5-b0fd-ae613ad6b557,DISK], DatanodeInfoWithStorage[127.0.0.1:34964,DS-206f6f29-cbc7-4847-918d-44ff3fce8a33,DISK], DatanodeInfoWithStorage[127.0.0.1:39331,DS-436fa304-0eb0-4ff6-ae21-9e8ee6af6f87,DISK], DatanodeInfoWithStorage[127.0.0.1:40890,DS-dbfe4020-3bb3-4b70-b7d2-70cd89d23bc1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-984596817-172.17.0.12-1595331429166:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33622,DS-7a270418-33b4-4c87-98da-112c5818fae9,DISK], DatanodeInfoWithStorage[127.0.0.1:40014,DS-c750459d-d10b-4cd4-aa9b-7bbe5efaa670,DISK], DatanodeInfoWithStorage[127.0.0.1:36413,DS-8a7d9f65-e131-415e-a80c-dc50c940a622,DISK], DatanodeInfoWithStorage[127.0.0.1:41419,DS-da253c9d-e1c6-44cb-bce8-6a5be080ad95,DISK], DatanodeInfoWithStorage[127.0.0.1:43110,DS-2b6884d8-cbe4-42a5-b0fd-ae613ad6b557,DISK], DatanodeInfoWithStorage[127.0.0.1:34964,DS-206f6f29-cbc7-4847-918d-44ff3fce8a33,DISK], DatanodeInfoWithStorage[127.0.0.1:39331,DS-436fa304-0eb0-4ff6-ae21-9e8ee6af6f87,DISK], DatanodeInfoWithStorage[127.0.0.1:40890,DS-dbfe4020-3bb3-4b70-b7d2-70cd89d23bc1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-995825386-172.17.0.12-1595331751749:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45795,DS-2ccab653-7ede-48ec-bd54-73c745d2db9b,DISK], DatanodeInfoWithStorage[127.0.0.1:36486,DS-51d67786-b90a-4b7d-bf2d-4321c7e0c75c,DISK], DatanodeInfoWithStorage[127.0.0.1:43944,DS-bf1a0b42-4c57-4d96-a468-3b48c4c347de,DISK], DatanodeInfoWithStorage[127.0.0.1:33585,DS-08a168c1-df79-41f3-99ad-070cbdb6a6b0,DISK], DatanodeInfoWithStorage[127.0.0.1:34852,DS-c2ff6e6a-ad03-4f06-8a39-79077571b214,DISK], DatanodeInfoWithStorage[127.0.0.1:37275,DS-679642f3-9eff-4ab3-99bc-c25e0ed5d52b,DISK], DatanodeInfoWithStorage[127.0.0.1:39686,DS-a9dcbc58-dfef-494b-a70a-15306ff68355,DISK], DatanodeInfoWithStorage[127.0.0.1:36522,DS-b0d5ecc3-bed9-4b52-84f1-de019a79e3c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-995825386-172.17.0.12-1595331751749:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45795,DS-2ccab653-7ede-48ec-bd54-73c745d2db9b,DISK], DatanodeInfoWithStorage[127.0.0.1:36486,DS-51d67786-b90a-4b7d-bf2d-4321c7e0c75c,DISK], DatanodeInfoWithStorage[127.0.0.1:43944,DS-bf1a0b42-4c57-4d96-a468-3b48c4c347de,DISK], DatanodeInfoWithStorage[127.0.0.1:33585,DS-08a168c1-df79-41f3-99ad-070cbdb6a6b0,DISK], DatanodeInfoWithStorage[127.0.0.1:34852,DS-c2ff6e6a-ad03-4f06-8a39-79077571b214,DISK], DatanodeInfoWithStorage[127.0.0.1:37275,DS-679642f3-9eff-4ab3-99bc-c25e0ed5d52b,DISK], DatanodeInfoWithStorage[127.0.0.1:39686,DS-a9dcbc58-dfef-494b-a70a-15306ff68355,DISK], DatanodeInfoWithStorage[127.0.0.1:36522,DS-b0d5ecc3-bed9-4b52-84f1-de019a79e3c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1585727104-172.17.0.12-1595331862775:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45295,DS-06bb9d31-511c-461d-8a25-edede4d1f32e,DISK], DatanodeInfoWithStorage[127.0.0.1:40646,DS-58f4caac-0df5-40c3-b2e8-ee1c8841ebdc,DISK], DatanodeInfoWithStorage[127.0.0.1:43245,DS-85a19736-3783-4080-b793-45227c4fa9ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37555,DS-4e367fc5-fd10-4b6d-ba71-57b826ea3406,DISK], DatanodeInfoWithStorage[127.0.0.1:42148,DS-b1021a6b-d151-49fc-ae3a-4faec457c562,DISK], DatanodeInfoWithStorage[127.0.0.1:37030,DS-e2f11c53-8dab-4c4f-ad80-011aceb6021a,DISK], DatanodeInfoWithStorage[127.0.0.1:38559,DS-1464e795-943b-4a24-a6a9-dc2aec28a53d,DISK], DatanodeInfoWithStorage[127.0.0.1:36106,DS-b44cce0a-58d9-4d68-a5b7-e7e30e418df1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1585727104-172.17.0.12-1595331862775:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45295,DS-06bb9d31-511c-461d-8a25-edede4d1f32e,DISK], DatanodeInfoWithStorage[127.0.0.1:40646,DS-58f4caac-0df5-40c3-b2e8-ee1c8841ebdc,DISK], DatanodeInfoWithStorage[127.0.0.1:43245,DS-85a19736-3783-4080-b793-45227c4fa9ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37555,DS-4e367fc5-fd10-4b6d-ba71-57b826ea3406,DISK], DatanodeInfoWithStorage[127.0.0.1:42148,DS-b1021a6b-d151-49fc-ae3a-4faec457c562,DISK], DatanodeInfoWithStorage[127.0.0.1:37030,DS-e2f11c53-8dab-4c4f-ad80-011aceb6021a,DISK], DatanodeInfoWithStorage[127.0.0.1:38559,DS-1464e795-943b-4a24-a6a9-dc2aec28a53d,DISK], DatanodeInfoWithStorage[127.0.0.1:36106,DS-b44cce0a-58d9-4d68-a5b7-e7e30e418df1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-700472464-172.17.0.12-1595332039365:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34432,DS-006ed72a-0709-4c55-9970-133daa494564,DISK], DatanodeInfoWithStorage[127.0.0.1:41799,DS-818bf369-0e47-4040-8441-a27a13561828,DISK], DatanodeInfoWithStorage[127.0.0.1:37614,DS-5c58ad0c-5e90-4936-aa8c-889b9a10a129,DISK], DatanodeInfoWithStorage[127.0.0.1:34489,DS-c7ac9928-d873-4051-a47b-237db98b9cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:45110,DS-50331fe6-8539-415d-a65e-9f9e94ad80a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33689,DS-97a9475e-2989-4d5b-b145-6ad6bdd73bad,DISK], DatanodeInfoWithStorage[127.0.0.1:45094,DS-b5cef74d-365c-4ba7-94a2-f0612f57c27b,DISK], DatanodeInfoWithStorage[127.0.0.1:38755,DS-79f65c12-c132-4c6a-afde-52ade2452689,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-700472464-172.17.0.12-1595332039365:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34432,DS-006ed72a-0709-4c55-9970-133daa494564,DISK], DatanodeInfoWithStorage[127.0.0.1:41799,DS-818bf369-0e47-4040-8441-a27a13561828,DISK], DatanodeInfoWithStorage[127.0.0.1:37614,DS-5c58ad0c-5e90-4936-aa8c-889b9a10a129,DISK], DatanodeInfoWithStorage[127.0.0.1:34489,DS-c7ac9928-d873-4051-a47b-237db98b9cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:45110,DS-50331fe6-8539-415d-a65e-9f9e94ad80a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33689,DS-97a9475e-2989-4d5b-b145-6ad6bdd73bad,DISK], DatanodeInfoWithStorage[127.0.0.1:45094,DS-b5cef74d-365c-4ba7-94a2-f0612f57c27b,DISK], DatanodeInfoWithStorage[127.0.0.1:38755,DS-79f65c12-c132-4c6a-afde-52ade2452689,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1198794595-172.17.0.12-1595332237485:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41162,DS-a09a0f04-8f03-4bb1-a508-ef7f4da46648,DISK], DatanodeInfoWithStorage[127.0.0.1:44987,DS-90a029f9-4950-4760-a3d3-baae72fcc490,DISK], DatanodeInfoWithStorage[127.0.0.1:45102,DS-0a603cb6-cd8c-4149-a136-96f3c59c6d58,DISK], DatanodeInfoWithStorage[127.0.0.1:34496,DS-47596fe4-8448-4252-99d9-b45bac2bfd5f,DISK], DatanodeInfoWithStorage[127.0.0.1:45284,DS-6f111ce3-20ab-431b-aa93-530e4b3806bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38160,DS-97131251-f1a6-41d5-b75c-99e8b3f2e767,DISK], DatanodeInfoWithStorage[127.0.0.1:39569,DS-f137c3bb-8f7e-4e41-bb1b-339aba5663d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42157,DS-9c500703-a293-4a62-84e9-53e1ab8db574,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1198794595-172.17.0.12-1595332237485:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41162,DS-a09a0f04-8f03-4bb1-a508-ef7f4da46648,DISK], DatanodeInfoWithStorage[127.0.0.1:44987,DS-90a029f9-4950-4760-a3d3-baae72fcc490,DISK], DatanodeInfoWithStorage[127.0.0.1:45102,DS-0a603cb6-cd8c-4149-a136-96f3c59c6d58,DISK], DatanodeInfoWithStorage[127.0.0.1:34496,DS-47596fe4-8448-4252-99d9-b45bac2bfd5f,DISK], DatanodeInfoWithStorage[127.0.0.1:45284,DS-6f111ce3-20ab-431b-aa93-530e4b3806bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38160,DS-97131251-f1a6-41d5-b75c-99e8b3f2e767,DISK], DatanodeInfoWithStorage[127.0.0.1:39569,DS-f137c3bb-8f7e-4e41-bb1b-339aba5663d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42157,DS-9c500703-a293-4a62-84e9-53e1ab8db574,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5419
