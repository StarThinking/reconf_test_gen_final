reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2050537820-172.17.0.18-1596985003698:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34047,DS-768247f2-697e-4e54-b636-6e133ff1f890,DISK], DatanodeInfoWithStorage[127.0.0.1:39130,DS-302b606e-18f8-40d3-aee9-371b0360a8ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35160,DS-aad5d09f-f09a-4455-8655-cf7a4dd91413,DISK], DatanodeInfoWithStorage[127.0.0.1:42890,DS-2f9a6cdb-55e2-407d-a00b-e85d7e66a4e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40674,DS-cebe2bae-d6c5-4292-a7d5-cd946626b2e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36590,DS-366a2273-b501-46c5-9540-deb6fa64c81d,DISK], DatanodeInfoWithStorage[127.0.0.1:38770,DS-d38f6b86-7be0-4026-92ea-65d2cae3bd6c,DISK], DatanodeInfoWithStorage[127.0.0.1:43319,DS-a420567e-bb2a-4c3c-ba3e-752fbb14d1c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2050537820-172.17.0.18-1596985003698:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34047,DS-768247f2-697e-4e54-b636-6e133ff1f890,DISK], DatanodeInfoWithStorage[127.0.0.1:39130,DS-302b606e-18f8-40d3-aee9-371b0360a8ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35160,DS-aad5d09f-f09a-4455-8655-cf7a4dd91413,DISK], DatanodeInfoWithStorage[127.0.0.1:42890,DS-2f9a6cdb-55e2-407d-a00b-e85d7e66a4e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40674,DS-cebe2bae-d6c5-4292-a7d5-cd946626b2e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36590,DS-366a2273-b501-46c5-9540-deb6fa64c81d,DISK], DatanodeInfoWithStorage[127.0.0.1:38770,DS-d38f6b86-7be0-4026-92ea-65d2cae3bd6c,DISK], DatanodeInfoWithStorage[127.0.0.1:43319,DS-a420567e-bb2a-4c3c-ba3e-752fbb14d1c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-15905024-172.17.0.18-1596985497449:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44449,DS-d46c8710-bcd0-4517-8f10-2561b6635dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:41902,DS-459247d8-2c4e-4834-8633-f1e6914d5e14,DISK], DatanodeInfoWithStorage[127.0.0.1:33070,DS-d2e3208b-9824-4610-8751-dbac82fc7b23,DISK], DatanodeInfoWithStorage[127.0.0.1:36330,DS-9f72d8ca-0958-41a7-b793-e06dc5316708,DISK], DatanodeInfoWithStorage[127.0.0.1:44371,DS-51ce21ef-53d9-497c-ba24-4f5f6afe401c,DISK], DatanodeInfoWithStorage[127.0.0.1:41469,DS-61cb6d2b-8bb8-4a0b-94b6-d520c09036d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33807,DS-4076417e-46eb-488b-bb86-b38e7a8b1460,DISK], DatanodeInfoWithStorage[127.0.0.1:41875,DS-b5eabd76-b767-45f2-8198-f34cd51e9929,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-15905024-172.17.0.18-1596985497449:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44449,DS-d46c8710-bcd0-4517-8f10-2561b6635dc2,DISK], DatanodeInfoWithStorage[127.0.0.1:41902,DS-459247d8-2c4e-4834-8633-f1e6914d5e14,DISK], DatanodeInfoWithStorage[127.0.0.1:33070,DS-d2e3208b-9824-4610-8751-dbac82fc7b23,DISK], DatanodeInfoWithStorage[127.0.0.1:36330,DS-9f72d8ca-0958-41a7-b793-e06dc5316708,DISK], DatanodeInfoWithStorage[127.0.0.1:44371,DS-51ce21ef-53d9-497c-ba24-4f5f6afe401c,DISK], DatanodeInfoWithStorage[127.0.0.1:41469,DS-61cb6d2b-8bb8-4a0b-94b6-d520c09036d5,DISK], DatanodeInfoWithStorage[127.0.0.1:33807,DS-4076417e-46eb-488b-bb86-b38e7a8b1460,DISK], DatanodeInfoWithStorage[127.0.0.1:41875,DS-b5eabd76-b767-45f2-8198-f34cd51e9929,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1348735507-172.17.0.18-1596985810798:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34825,DS-70a74c93-a2f6-4f73-93b5-f64c8b280c43,DISK], DatanodeInfoWithStorage[127.0.0.1:40743,DS-14278139-9386-4f87-aea0-6f9b42d80ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:42640,DS-065494fe-a5f2-4bd3-a737-e751ea6820f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38267,DS-7a07ddd0-4d86-4b5d-aa14-864e1be2f412,DISK], DatanodeInfoWithStorage[127.0.0.1:32941,DS-78c2ea54-4d2b-4aa4-8c9a-55444c3a4bba,DISK], DatanodeInfoWithStorage[127.0.0.1:37156,DS-a108e857-0f97-4ed5-83ac-55eb48e6bd1d,DISK], DatanodeInfoWithStorage[127.0.0.1:39049,DS-1665a140-c93d-4379-847f-2f38724926f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43504,DS-17a5e943-3c26-42e7-ae8d-6034ec2110dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1348735507-172.17.0.18-1596985810798:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34825,DS-70a74c93-a2f6-4f73-93b5-f64c8b280c43,DISK], DatanodeInfoWithStorage[127.0.0.1:40743,DS-14278139-9386-4f87-aea0-6f9b42d80ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:42640,DS-065494fe-a5f2-4bd3-a737-e751ea6820f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38267,DS-7a07ddd0-4d86-4b5d-aa14-864e1be2f412,DISK], DatanodeInfoWithStorage[127.0.0.1:32941,DS-78c2ea54-4d2b-4aa4-8c9a-55444c3a4bba,DISK], DatanodeInfoWithStorage[127.0.0.1:37156,DS-a108e857-0f97-4ed5-83ac-55eb48e6bd1d,DISK], DatanodeInfoWithStorage[127.0.0.1:39049,DS-1665a140-c93d-4379-847f-2f38724926f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43504,DS-17a5e943-3c26-42e7-ae8d-6034ec2110dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1084338767-172.17.0.18-1596986264636:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45139,DS-b3b4b8e2-8a40-4f0b-b97b-9c091c65e07e,DISK], DatanodeInfoWithStorage[127.0.0.1:40695,DS-dfea856f-4ce6-4f2e-bf41-84a392677a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:44339,DS-e2b76d0b-2ba3-4e23-bdac-b6236c16cd0b,DISK], DatanodeInfoWithStorage[127.0.0.1:38830,DS-6119eb6f-0027-4d69-b7ef-c43169680730,DISK], DatanodeInfoWithStorage[127.0.0.1:46832,DS-abf61e43-cbd4-4cb7-b4df-b243a1536cb4,DISK], DatanodeInfoWithStorage[127.0.0.1:41935,DS-d733c280-78a1-4242-94e7-cfd9c55151af,DISK], DatanodeInfoWithStorage[127.0.0.1:33673,DS-edcb2f21-ea75-4578-bc9a-168842d2a373,DISK], DatanodeInfoWithStorage[127.0.0.1:40066,DS-ca932cf6-3934-4efa-a0f8-bd3350a07832,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1084338767-172.17.0.18-1596986264636:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45139,DS-b3b4b8e2-8a40-4f0b-b97b-9c091c65e07e,DISK], DatanodeInfoWithStorage[127.0.0.1:40695,DS-dfea856f-4ce6-4f2e-bf41-84a392677a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:44339,DS-e2b76d0b-2ba3-4e23-bdac-b6236c16cd0b,DISK], DatanodeInfoWithStorage[127.0.0.1:38830,DS-6119eb6f-0027-4d69-b7ef-c43169680730,DISK], DatanodeInfoWithStorage[127.0.0.1:46832,DS-abf61e43-cbd4-4cb7-b4df-b243a1536cb4,DISK], DatanodeInfoWithStorage[127.0.0.1:41935,DS-d733c280-78a1-4242-94e7-cfd9c55151af,DISK], DatanodeInfoWithStorage[127.0.0.1:33673,DS-edcb2f21-ea75-4578-bc9a-168842d2a373,DISK], DatanodeInfoWithStorage[127.0.0.1:40066,DS-ca932cf6-3934-4efa-a0f8-bd3350a07832,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1727398872-172.17.0.18-1596986529495:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40930,DS-ac865b88-7618-46ed-a019-4c2238ec4175,DISK], DatanodeInfoWithStorage[127.0.0.1:45081,DS-806eb4e1-6404-45d8-b7ab-001fc325f558,DISK], DatanodeInfoWithStorage[127.0.0.1:41992,DS-dd0df471-b115-4e9c-ba8f-96d5dc63bafc,DISK], DatanodeInfoWithStorage[127.0.0.1:45056,DS-a269ad94-25a6-477f-8b3f-b24a0082d48b,DISK], DatanodeInfoWithStorage[127.0.0.1:41386,DS-2ee6dde2-f200-4750-847d-3f625c539790,DISK], DatanodeInfoWithStorage[127.0.0.1:38254,DS-5fb34f45-99db-4d4d-a8f9-3aea0ab5d5f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36065,DS-240456aa-0b19-4c49-b864-8316a309d0dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42845,DS-89dc8e1e-9032-40b3-9732-1831d1f5bb4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1727398872-172.17.0.18-1596986529495:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40930,DS-ac865b88-7618-46ed-a019-4c2238ec4175,DISK], DatanodeInfoWithStorage[127.0.0.1:45081,DS-806eb4e1-6404-45d8-b7ab-001fc325f558,DISK], DatanodeInfoWithStorage[127.0.0.1:41992,DS-dd0df471-b115-4e9c-ba8f-96d5dc63bafc,DISK], DatanodeInfoWithStorage[127.0.0.1:45056,DS-a269ad94-25a6-477f-8b3f-b24a0082d48b,DISK], DatanodeInfoWithStorage[127.0.0.1:41386,DS-2ee6dde2-f200-4750-847d-3f625c539790,DISK], DatanodeInfoWithStorage[127.0.0.1:38254,DS-5fb34f45-99db-4d4d-a8f9-3aea0ab5d5f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36065,DS-240456aa-0b19-4c49-b864-8316a309d0dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42845,DS-89dc8e1e-9032-40b3-9732-1831d1f5bb4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-174581085-172.17.0.18-1596986625478:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43511,DS-d881970a-9a8d-4f52-a3a5-4c3370987db8,DISK], DatanodeInfoWithStorage[127.0.0.1:46503,DS-d1cbdba9-a642-49a5-8596-62f84f98a4cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36186,DS-bfd9dc1e-ab12-491b-bad6-978fce4aec33,DISK], DatanodeInfoWithStorage[127.0.0.1:46779,DS-74c18acd-3180-4333-adef-ac70b6a0c2b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34991,DS-ac52e126-feb1-4adc-a61a-80549a267f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:37425,DS-e1cc6978-f3ad-44da-a0e7-56d983b13093,DISK], DatanodeInfoWithStorage[127.0.0.1:41492,DS-ec086d98-f261-4fd6-b194-2fcd6f71c720,DISK], DatanodeInfoWithStorage[127.0.0.1:34621,DS-77fb144a-0e72-40f8-809e-59a1b23db532,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-174581085-172.17.0.18-1596986625478:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43511,DS-d881970a-9a8d-4f52-a3a5-4c3370987db8,DISK], DatanodeInfoWithStorage[127.0.0.1:46503,DS-d1cbdba9-a642-49a5-8596-62f84f98a4cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36186,DS-bfd9dc1e-ab12-491b-bad6-978fce4aec33,DISK], DatanodeInfoWithStorage[127.0.0.1:46779,DS-74c18acd-3180-4333-adef-ac70b6a0c2b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34991,DS-ac52e126-feb1-4adc-a61a-80549a267f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:37425,DS-e1cc6978-f3ad-44da-a0e7-56d983b13093,DISK], DatanodeInfoWithStorage[127.0.0.1:41492,DS-ec086d98-f261-4fd6-b194-2fcd6f71c720,DISK], DatanodeInfoWithStorage[127.0.0.1:34621,DS-77fb144a-0e72-40f8-809e-59a1b23db532,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-476560730-172.17.0.18-1596986717483:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39895,DS-a41aa8e8-fc09-415e-ace4-079bcb7a1d8d,DISK], DatanodeInfoWithStorage[127.0.0.1:38281,DS-128a2dce-9d57-4f30-8919-c046e429f5ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34962,DS-09e880a3-5346-4441-a686-036f1df143be,DISK], DatanodeInfoWithStorage[127.0.0.1:33623,DS-ca17d654-34e3-42fc-8def-02c4d111996d,DISK], DatanodeInfoWithStorage[127.0.0.1:38913,DS-7ce31910-4b57-4e43-8c1a-c6ea004b56a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34466,DS-f036c8ae-2523-4387-8d22-c4cdfed02268,DISK], DatanodeInfoWithStorage[127.0.0.1:39419,DS-3d35274c-fa0f-4d51-81c9-ebd30f8366f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39142,DS-eebe5a75-6706-4651-8ac4-3580ed3b86fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-476560730-172.17.0.18-1596986717483:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39895,DS-a41aa8e8-fc09-415e-ace4-079bcb7a1d8d,DISK], DatanodeInfoWithStorage[127.0.0.1:38281,DS-128a2dce-9d57-4f30-8919-c046e429f5ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34962,DS-09e880a3-5346-4441-a686-036f1df143be,DISK], DatanodeInfoWithStorage[127.0.0.1:33623,DS-ca17d654-34e3-42fc-8def-02c4d111996d,DISK], DatanodeInfoWithStorage[127.0.0.1:38913,DS-7ce31910-4b57-4e43-8c1a-c6ea004b56a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34466,DS-f036c8ae-2523-4387-8d22-c4cdfed02268,DISK], DatanodeInfoWithStorage[127.0.0.1:39419,DS-3d35274c-fa0f-4d51-81c9-ebd30f8366f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39142,DS-eebe5a75-6706-4651-8ac4-3580ed3b86fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1938144106-172.17.0.18-1596986820173:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46492,DS-4e520978-57d4-4a68-b988-c13354539e19,DISK], DatanodeInfoWithStorage[127.0.0.1:38901,DS-05c78fb4-1fd4-4461-a23e-bfca47b1633b,DISK], DatanodeInfoWithStorage[127.0.0.1:33458,DS-df31d3fb-f7ff-4b2b-ae93-885d9d6b3243,DISK], DatanodeInfoWithStorage[127.0.0.1:39636,DS-759675bc-58fd-469e-9bfb-d634d9c01eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:34907,DS-959758f2-d58c-44dc-8610-7a516205d69d,DISK], DatanodeInfoWithStorage[127.0.0.1:33519,DS-38a8c3ac-4fc9-411e-8e14-0e2296817238,DISK], DatanodeInfoWithStorage[127.0.0.1:44440,DS-4a8fdeda-6c11-4fd8-bfa2-550821e1086e,DISK], DatanodeInfoWithStorage[127.0.0.1:41744,DS-56d33218-93ff-4f92-a9b2-0f0c437f500a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1938144106-172.17.0.18-1596986820173:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46492,DS-4e520978-57d4-4a68-b988-c13354539e19,DISK], DatanodeInfoWithStorage[127.0.0.1:38901,DS-05c78fb4-1fd4-4461-a23e-bfca47b1633b,DISK], DatanodeInfoWithStorage[127.0.0.1:33458,DS-df31d3fb-f7ff-4b2b-ae93-885d9d6b3243,DISK], DatanodeInfoWithStorage[127.0.0.1:39636,DS-759675bc-58fd-469e-9bfb-d634d9c01eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:34907,DS-959758f2-d58c-44dc-8610-7a516205d69d,DISK], DatanodeInfoWithStorage[127.0.0.1:33519,DS-38a8c3ac-4fc9-411e-8e14-0e2296817238,DISK], DatanodeInfoWithStorage[127.0.0.1:44440,DS-4a8fdeda-6c11-4fd8-bfa2-550821e1086e,DISK], DatanodeInfoWithStorage[127.0.0.1:41744,DS-56d33218-93ff-4f92-a9b2-0f0c437f500a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-249055700-172.17.0.18-1596987605871:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43847,DS-be0174d1-6caf-474d-85d4-5ac767567457,DISK], DatanodeInfoWithStorage[127.0.0.1:44198,DS-35f8a920-6c1d-4a53-aed5-e7eaa75ed278,DISK], DatanodeInfoWithStorage[127.0.0.1:39928,DS-d5178345-d62d-40d8-8955-72eb08e47c3b,DISK], DatanodeInfoWithStorage[127.0.0.1:35899,DS-9160f04c-f42d-4ca0-9dae-f56d1e89d690,DISK], DatanodeInfoWithStorage[127.0.0.1:41860,DS-6691e31d-2401-45dd-abf4-a0f6eccd293b,DISK], DatanodeInfoWithStorage[127.0.0.1:36126,DS-336eb77f-dd8b-426f-9e34-ff4da1ed301e,DISK], DatanodeInfoWithStorage[127.0.0.1:44717,DS-e8f2987a-15ae-409c-99b3-2f4b1881550a,DISK], DatanodeInfoWithStorage[127.0.0.1:32901,DS-96c2a1fd-3f63-4259-83c0-e15d3437d29d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-249055700-172.17.0.18-1596987605871:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43847,DS-be0174d1-6caf-474d-85d4-5ac767567457,DISK], DatanodeInfoWithStorage[127.0.0.1:44198,DS-35f8a920-6c1d-4a53-aed5-e7eaa75ed278,DISK], DatanodeInfoWithStorage[127.0.0.1:39928,DS-d5178345-d62d-40d8-8955-72eb08e47c3b,DISK], DatanodeInfoWithStorage[127.0.0.1:35899,DS-9160f04c-f42d-4ca0-9dae-f56d1e89d690,DISK], DatanodeInfoWithStorage[127.0.0.1:41860,DS-6691e31d-2401-45dd-abf4-a0f6eccd293b,DISK], DatanodeInfoWithStorage[127.0.0.1:36126,DS-336eb77f-dd8b-426f-9e34-ff4da1ed301e,DISK], DatanodeInfoWithStorage[127.0.0.1:44717,DS-e8f2987a-15ae-409c-99b3-2f4b1881550a,DISK], DatanodeInfoWithStorage[127.0.0.1:32901,DS-96c2a1fd-3f63-4259-83c0-e15d3437d29d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1168554722-172.17.0.18-1596987690325:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42988,DS-e9836ec6-7bb6-4888-ac58-ec5ab2f08dc0,DISK], DatanodeInfoWithStorage[127.0.0.1:36940,DS-9b5f77a3-9272-4879-aaf7-bc0eb3a2bb12,DISK], DatanodeInfoWithStorage[127.0.0.1:35993,DS-e13949f4-d685-4bb2-bf92-04df6dc4b1b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41647,DS-1fd409e2-4dc0-4b15-996f-accf4581f1f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36757,DS-5fac2b81-33f9-4f3f-82c4-dc589532e65b,DISK], DatanodeInfoWithStorage[127.0.0.1:45922,DS-ae0292bc-2315-4f1b-be90-b71391f98096,DISK], DatanodeInfoWithStorage[127.0.0.1:33035,DS-92b22106-ec82-44e9-8f6e-3c9bb054b92d,DISK], DatanodeInfoWithStorage[127.0.0.1:43785,DS-b67ea1d7-f3b7-4eb7-96e0-3b9a06faeab4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1168554722-172.17.0.18-1596987690325:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42988,DS-e9836ec6-7bb6-4888-ac58-ec5ab2f08dc0,DISK], DatanodeInfoWithStorage[127.0.0.1:36940,DS-9b5f77a3-9272-4879-aaf7-bc0eb3a2bb12,DISK], DatanodeInfoWithStorage[127.0.0.1:35993,DS-e13949f4-d685-4bb2-bf92-04df6dc4b1b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41647,DS-1fd409e2-4dc0-4b15-996f-accf4581f1f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36757,DS-5fac2b81-33f9-4f3f-82c4-dc589532e65b,DISK], DatanodeInfoWithStorage[127.0.0.1:45922,DS-ae0292bc-2315-4f1b-be90-b71391f98096,DISK], DatanodeInfoWithStorage[127.0.0.1:33035,DS-92b22106-ec82-44e9-8f6e-3c9bb054b92d,DISK], DatanodeInfoWithStorage[127.0.0.1:43785,DS-b67ea1d7-f3b7-4eb7-96e0-3b9a06faeab4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-984885171-172.17.0.18-1596988770124:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38547,DS-107652a8-7b1f-4b7b-ba7e-af63c3bb8f8b,DISK], DatanodeInfoWithStorage[127.0.0.1:37343,DS-909fa126-3d88-4d4f-9f07-10b772bb089d,DISK], DatanodeInfoWithStorage[127.0.0.1:42700,DS-9522cad7-c017-4c0c-9366-074b4fa870d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40230,DS-ac483481-6f7a-4989-b49c-692bcc28dc42,DISK], DatanodeInfoWithStorage[127.0.0.1:34926,DS-8ac82663-7cec-46b1-ae08-04d5a1e8d667,DISK], DatanodeInfoWithStorage[127.0.0.1:40279,DS-e30aa504-8f98-4afd-93a4-38d2876358d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34911,DS-d0bb407c-8824-461d-95eb-1d9792d6d6d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38888,DS-40d26077-b324-453c-af7f-23fa085028c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-984885171-172.17.0.18-1596988770124:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38547,DS-107652a8-7b1f-4b7b-ba7e-af63c3bb8f8b,DISK], DatanodeInfoWithStorage[127.0.0.1:37343,DS-909fa126-3d88-4d4f-9f07-10b772bb089d,DISK], DatanodeInfoWithStorage[127.0.0.1:42700,DS-9522cad7-c017-4c0c-9366-074b4fa870d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40230,DS-ac483481-6f7a-4989-b49c-692bcc28dc42,DISK], DatanodeInfoWithStorage[127.0.0.1:34926,DS-8ac82663-7cec-46b1-ae08-04d5a1e8d667,DISK], DatanodeInfoWithStorage[127.0.0.1:40279,DS-e30aa504-8f98-4afd-93a4-38d2876358d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34911,DS-d0bb407c-8824-461d-95eb-1d9792d6d6d0,DISK], DatanodeInfoWithStorage[127.0.0.1:38888,DS-40d26077-b324-453c-af7f-23fa085028c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1664307024-172.17.0.18-1596988986167:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42438,DS-75e2450b-c676-4c46-af5e-f52a4d161853,DISK], DatanodeInfoWithStorage[127.0.0.1:36284,DS-0d036e56-2486-4223-9b2e-6d65b4855f4e,DISK], DatanodeInfoWithStorage[127.0.0.1:44690,DS-f3a0f408-2196-47d9-8cc1-c6afa2ea5541,DISK], DatanodeInfoWithStorage[127.0.0.1:37716,DS-a7c2a028-53c1-4dfe-b9e6-4ed927c10a00,DISK], DatanodeInfoWithStorage[127.0.0.1:41669,DS-df065655-03c3-4810-b459-5ef5cc712a24,DISK], DatanodeInfoWithStorage[127.0.0.1:33133,DS-7cc1944a-3f98-4638-bd2c-7e75f0fdefce,DISK], DatanodeInfoWithStorage[127.0.0.1:37974,DS-8c56f435-6c8e-497b-a8e1-5ccca4cf90b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41016,DS-1a7aa7df-089f-476f-8b1e-8c2d8a314087,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1664307024-172.17.0.18-1596988986167:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42438,DS-75e2450b-c676-4c46-af5e-f52a4d161853,DISK], DatanodeInfoWithStorage[127.0.0.1:36284,DS-0d036e56-2486-4223-9b2e-6d65b4855f4e,DISK], DatanodeInfoWithStorage[127.0.0.1:44690,DS-f3a0f408-2196-47d9-8cc1-c6afa2ea5541,DISK], DatanodeInfoWithStorage[127.0.0.1:37716,DS-a7c2a028-53c1-4dfe-b9e6-4ed927c10a00,DISK], DatanodeInfoWithStorage[127.0.0.1:41669,DS-df065655-03c3-4810-b459-5ef5cc712a24,DISK], DatanodeInfoWithStorage[127.0.0.1:33133,DS-7cc1944a-3f98-4638-bd2c-7e75f0fdefce,DISK], DatanodeInfoWithStorage[127.0.0.1:37974,DS-8c56f435-6c8e-497b-a8e1-5ccca4cf90b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41016,DS-1a7aa7df-089f-476f-8b1e-8c2d8a314087,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1059960595-172.17.0.18-1596989024514:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45465,DS-b1a83601-aeb5-48bf-85b5-71d8dc08f7dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38109,DS-ae87f86b-a85e-45ed-bb8f-72322be69af8,DISK], DatanodeInfoWithStorage[127.0.0.1:35245,DS-124584e8-aadd-4b99-b6db-fb65f0d01a13,DISK], DatanodeInfoWithStorage[127.0.0.1:36290,DS-76d19fd3-6664-471f-acaa-df6323288fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:40989,DS-d10594dc-8241-40e7-a764-86a89795e3dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37807,DS-24aeecf8-a56a-45a1-aef2-97e6c91f9081,DISK], DatanodeInfoWithStorage[127.0.0.1:41166,DS-4aa7646f-ecb6-4223-9045-610189a6419e,DISK], DatanodeInfoWithStorage[127.0.0.1:38844,DS-f08027fb-eab8-4a2d-914d-3971c454351f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1059960595-172.17.0.18-1596989024514:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45465,DS-b1a83601-aeb5-48bf-85b5-71d8dc08f7dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38109,DS-ae87f86b-a85e-45ed-bb8f-72322be69af8,DISK], DatanodeInfoWithStorage[127.0.0.1:35245,DS-124584e8-aadd-4b99-b6db-fb65f0d01a13,DISK], DatanodeInfoWithStorage[127.0.0.1:36290,DS-76d19fd3-6664-471f-acaa-df6323288fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:40989,DS-d10594dc-8241-40e7-a764-86a89795e3dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37807,DS-24aeecf8-a56a-45a1-aef2-97e6c91f9081,DISK], DatanodeInfoWithStorage[127.0.0.1:41166,DS-4aa7646f-ecb6-4223-9045-610189a6419e,DISK], DatanodeInfoWithStorage[127.0.0.1:38844,DS-f08027fb-eab8-4a2d-914d-3971c454351f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-229993993-172.17.0.18-1596989404220:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33798,DS-568766d5-6f60-437c-96b9-1c96d6a1cb19,DISK], DatanodeInfoWithStorage[127.0.0.1:42980,DS-400a6af1-5907-4f64-bb64-52e037e6184c,DISK], DatanodeInfoWithStorage[127.0.0.1:35457,DS-bf1e361f-183b-44e0-85f8-2e2298086d4f,DISK], DatanodeInfoWithStorage[127.0.0.1:39691,DS-942348d3-bf7b-4e2f-99d2-1b8c91d29a18,DISK], DatanodeInfoWithStorage[127.0.0.1:45141,DS-3d1ccbad-57c8-4295-9859-38d4f729fdf8,DISK], DatanodeInfoWithStorage[127.0.0.1:34230,DS-a7a5f913-f740-473f-b1b3-7f9546d90edd,DISK], DatanodeInfoWithStorage[127.0.0.1:46832,DS-0d8413cf-a541-4ba6-b7ed-eb0e8206d2da,DISK], DatanodeInfoWithStorage[127.0.0.1:37288,DS-9b163f2e-5c0c-44fe-9207-be0211a1da38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-229993993-172.17.0.18-1596989404220:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33798,DS-568766d5-6f60-437c-96b9-1c96d6a1cb19,DISK], DatanodeInfoWithStorage[127.0.0.1:42980,DS-400a6af1-5907-4f64-bb64-52e037e6184c,DISK], DatanodeInfoWithStorage[127.0.0.1:35457,DS-bf1e361f-183b-44e0-85f8-2e2298086d4f,DISK], DatanodeInfoWithStorage[127.0.0.1:39691,DS-942348d3-bf7b-4e2f-99d2-1b8c91d29a18,DISK], DatanodeInfoWithStorage[127.0.0.1:45141,DS-3d1ccbad-57c8-4295-9859-38d4f729fdf8,DISK], DatanodeInfoWithStorage[127.0.0.1:34230,DS-a7a5f913-f740-473f-b1b3-7f9546d90edd,DISK], DatanodeInfoWithStorage[127.0.0.1:46832,DS-0d8413cf-a541-4ba6-b7ed-eb0e8206d2da,DISK], DatanodeInfoWithStorage[127.0.0.1:37288,DS-9b163f2e-5c0c-44fe-9207-be0211a1da38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1634983868-172.17.0.18-1596989720605:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41720,DS-4054af30-cf3a-4bb1-ae9f-5ce3a357d734,DISK], DatanodeInfoWithStorage[127.0.0.1:37049,DS-64db9266-d94c-4f9e-8971-1fe3097f8e63,DISK], DatanodeInfoWithStorage[127.0.0.1:37246,DS-8f17bf12-e04d-41c5-bce2-23a6e90cf8a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39100,DS-10066904-384b-47b7-9302-b27bab62351b,DISK], DatanodeInfoWithStorage[127.0.0.1:40027,DS-fea9eb01-5f94-4278-8515-cfc9104a57b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40465,DS-2c39e28e-2d00-46bd-9712-a8b2adad3c91,DISK], DatanodeInfoWithStorage[127.0.0.1:44476,DS-89d155a6-f1f6-434f-9dc1-c1a74537bae4,DISK], DatanodeInfoWithStorage[127.0.0.1:43750,DS-ead40124-4a69-4398-9d5f-13b9eacbd2e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1634983868-172.17.0.18-1596989720605:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41720,DS-4054af30-cf3a-4bb1-ae9f-5ce3a357d734,DISK], DatanodeInfoWithStorage[127.0.0.1:37049,DS-64db9266-d94c-4f9e-8971-1fe3097f8e63,DISK], DatanodeInfoWithStorage[127.0.0.1:37246,DS-8f17bf12-e04d-41c5-bce2-23a6e90cf8a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39100,DS-10066904-384b-47b7-9302-b27bab62351b,DISK], DatanodeInfoWithStorage[127.0.0.1:40027,DS-fea9eb01-5f94-4278-8515-cfc9104a57b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40465,DS-2c39e28e-2d00-46bd-9712-a8b2adad3c91,DISK], DatanodeInfoWithStorage[127.0.0.1:44476,DS-89d155a6-f1f6-434f-9dc1-c1a74537bae4,DISK], DatanodeInfoWithStorage[127.0.0.1:43750,DS-ead40124-4a69-4398-9d5f-13b9eacbd2e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1176268357-172.17.0.18-1596989764233:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46193,DS-9a562520-36fa-4042-a361-5857d5a980f7,DISK], DatanodeInfoWithStorage[127.0.0.1:46487,DS-61104121-bfc3-46b0-8fe3-4269d5def6ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42767,DS-b2e52cc8-b03f-4b1e-aac9-0ce89f43eb67,DISK], DatanodeInfoWithStorage[127.0.0.1:37193,DS-dd7c85e2-0a4a-4a23-bb10-d680943e85e6,DISK], DatanodeInfoWithStorage[127.0.0.1:43956,DS-33c7d86c-4918-45f1-a56f-7eccae266e17,DISK], DatanodeInfoWithStorage[127.0.0.1:36004,DS-09368641-aa6c-4757-8f0f-639499e1228c,DISK], DatanodeInfoWithStorage[127.0.0.1:34382,DS-b12abe38-08d8-4cd7-89f6-6f08068c90a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34251,DS-00ce4727-99f7-48a2-aa16-b1e0fe666664,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1176268357-172.17.0.18-1596989764233:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46193,DS-9a562520-36fa-4042-a361-5857d5a980f7,DISK], DatanodeInfoWithStorage[127.0.0.1:46487,DS-61104121-bfc3-46b0-8fe3-4269d5def6ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42767,DS-b2e52cc8-b03f-4b1e-aac9-0ce89f43eb67,DISK], DatanodeInfoWithStorage[127.0.0.1:37193,DS-dd7c85e2-0a4a-4a23-bb10-d680943e85e6,DISK], DatanodeInfoWithStorage[127.0.0.1:43956,DS-33c7d86c-4918-45f1-a56f-7eccae266e17,DISK], DatanodeInfoWithStorage[127.0.0.1:36004,DS-09368641-aa6c-4757-8f0f-639499e1228c,DISK], DatanodeInfoWithStorage[127.0.0.1:34382,DS-b12abe38-08d8-4cd7-89f6-6f08068c90a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34251,DS-00ce4727-99f7-48a2-aa16-b1e0fe666664,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1104589085-172.17.0.18-1596990085370:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41937,DS-19741fab-9888-4682-b4f6-08c3fd966d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:36063,DS-6d00a5ba-ecca-4dbf-84c6-d9f80d7058c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33841,DS-da12a004-d77b-44a1-aade-24c4fb733d5a,DISK], DatanodeInfoWithStorage[127.0.0.1:41485,DS-4944b845-55fd-4d1e-a122-ac074de54a29,DISK], DatanodeInfoWithStorage[127.0.0.1:33499,DS-278d78e9-1aea-4d9b-b048-a60e58eb8cec,DISK], DatanodeInfoWithStorage[127.0.0.1:41549,DS-df25188d-8f25-4537-8f86-e9258104bafc,DISK], DatanodeInfoWithStorage[127.0.0.1:34746,DS-9671c7a9-f6d1-49e2-b500-afc5ca14bad1,DISK], DatanodeInfoWithStorage[127.0.0.1:44607,DS-da9ff4da-44d3-4e22-9de8-bac2f94f73be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1104589085-172.17.0.18-1596990085370:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41937,DS-19741fab-9888-4682-b4f6-08c3fd966d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:36063,DS-6d00a5ba-ecca-4dbf-84c6-d9f80d7058c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33841,DS-da12a004-d77b-44a1-aade-24c4fb733d5a,DISK], DatanodeInfoWithStorage[127.0.0.1:41485,DS-4944b845-55fd-4d1e-a122-ac074de54a29,DISK], DatanodeInfoWithStorage[127.0.0.1:33499,DS-278d78e9-1aea-4d9b-b048-a60e58eb8cec,DISK], DatanodeInfoWithStorage[127.0.0.1:41549,DS-df25188d-8f25-4537-8f86-e9258104bafc,DISK], DatanodeInfoWithStorage[127.0.0.1:34746,DS-9671c7a9-f6d1-49e2-b500-afc5ca14bad1,DISK], DatanodeInfoWithStorage[127.0.0.1:44607,DS-da9ff4da-44d3-4e22-9de8-bac2f94f73be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-155971998-172.17.0.18-1596990232965:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44373,DS-6ee97cac-3093-42f8-a869-6f055e65cfda,DISK], DatanodeInfoWithStorage[127.0.0.1:38027,DS-d0259268-4c30-490c-8596-d3b4317601cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45223,DS-1e319297-cc14-43b8-9054-47bbba5c3ce3,DISK], DatanodeInfoWithStorage[127.0.0.1:39717,DS-9da85fba-b15a-4dd1-8452-2cef47cf94fd,DISK], DatanodeInfoWithStorage[127.0.0.1:38243,DS-b8791b9c-a432-4c77-b9d0-1bc5f8fd9735,DISK], DatanodeInfoWithStorage[127.0.0.1:38177,DS-7c38a4a2-e5b2-448d-8d1c-f898f40adc91,DISK], DatanodeInfoWithStorage[127.0.0.1:37825,DS-22e015db-1aea-43b8-b057-867a54ca9920,DISK], DatanodeInfoWithStorage[127.0.0.1:38658,DS-2829882c-6da9-4066-9a4d-97b76dbcb6fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-155971998-172.17.0.18-1596990232965:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44373,DS-6ee97cac-3093-42f8-a869-6f055e65cfda,DISK], DatanodeInfoWithStorage[127.0.0.1:38027,DS-d0259268-4c30-490c-8596-d3b4317601cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45223,DS-1e319297-cc14-43b8-9054-47bbba5c3ce3,DISK], DatanodeInfoWithStorage[127.0.0.1:39717,DS-9da85fba-b15a-4dd1-8452-2cef47cf94fd,DISK], DatanodeInfoWithStorage[127.0.0.1:38243,DS-b8791b9c-a432-4c77-b9d0-1bc5f8fd9735,DISK], DatanodeInfoWithStorage[127.0.0.1:38177,DS-7c38a4a2-e5b2-448d-8d1c-f898f40adc91,DISK], DatanodeInfoWithStorage[127.0.0.1:37825,DS-22e015db-1aea-43b8-b057-867a54ca9920,DISK], DatanodeInfoWithStorage[127.0.0.1:38658,DS-2829882c-6da9-4066-9a4d-97b76dbcb6fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-912750441-172.17.0.18-1596990687771:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40154,DS-9d49611a-e475-438f-a234-3cd3cda5dc78,DISK], DatanodeInfoWithStorage[127.0.0.1:42014,DS-b2737232-c6ab-4a5a-a361-2029d41e1fde,DISK], DatanodeInfoWithStorage[127.0.0.1:33098,DS-6267378b-fc46-4e39-8110-0bfb75c1cab1,DISK], DatanodeInfoWithStorage[127.0.0.1:37990,DS-e9ea3487-7603-4ebf-8d01-6ce0ffea653c,DISK], DatanodeInfoWithStorage[127.0.0.1:45674,DS-54f523ca-e9f3-41eb-aca6-80824840dc37,DISK], DatanodeInfoWithStorage[127.0.0.1:45832,DS-a88c89f6-79f1-4356-8256-d9998b4ac8d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34993,DS-ce9bcf8a-f6c3-41bd-bd95-c274ec6fdbb1,DISK], DatanodeInfoWithStorage[127.0.0.1:40073,DS-534605ce-8c7b-435f-a006-c68344353121,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-912750441-172.17.0.18-1596990687771:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40154,DS-9d49611a-e475-438f-a234-3cd3cda5dc78,DISK], DatanodeInfoWithStorage[127.0.0.1:42014,DS-b2737232-c6ab-4a5a-a361-2029d41e1fde,DISK], DatanodeInfoWithStorage[127.0.0.1:33098,DS-6267378b-fc46-4e39-8110-0bfb75c1cab1,DISK], DatanodeInfoWithStorage[127.0.0.1:37990,DS-e9ea3487-7603-4ebf-8d01-6ce0ffea653c,DISK], DatanodeInfoWithStorage[127.0.0.1:45674,DS-54f523ca-e9f3-41eb-aca6-80824840dc37,DISK], DatanodeInfoWithStorage[127.0.0.1:45832,DS-a88c89f6-79f1-4356-8256-d9998b4ac8d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34993,DS-ce9bcf8a-f6c3-41bd-bd95-c274ec6fdbb1,DISK], DatanodeInfoWithStorage[127.0.0.1:40073,DS-534605ce-8c7b-435f-a006-c68344353121,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 6820
