reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1166989763-172.17.0.9-1595396548814:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43714,DS-08a1ccc9-10d4-4c02-8b20-b16a437a5d22,DISK], DatanodeInfoWithStorage[127.0.0.1:35130,DS-e89c1818-e068-42bb-8e09-3ce7288e993e,DISK], DatanodeInfoWithStorage[127.0.0.1:35855,DS-d29c2cf8-b722-4c2f-8701-e16cf546179a,DISK], DatanodeInfoWithStorage[127.0.0.1:44742,DS-9d628067-4fc2-4981-b169-1d5451c0fe33,DISK], DatanodeInfoWithStorage[127.0.0.1:43473,DS-57f6eeac-39c7-4905-aee2-9d1a2f574d52,DISK], DatanodeInfoWithStorage[127.0.0.1:40975,DS-57cab210-9892-4211-9b58-302f9fb2cdda,DISK], DatanodeInfoWithStorage[127.0.0.1:45137,DS-d5976bef-715d-4a59-91b9-322acc3adeba,DISK], DatanodeInfoWithStorage[127.0.0.1:46033,DS-312972ff-752f-4acc-92cf-f1d6e81d8e68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1166989763-172.17.0.9-1595396548814:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43714,DS-08a1ccc9-10d4-4c02-8b20-b16a437a5d22,DISK], DatanodeInfoWithStorage[127.0.0.1:35130,DS-e89c1818-e068-42bb-8e09-3ce7288e993e,DISK], DatanodeInfoWithStorage[127.0.0.1:35855,DS-d29c2cf8-b722-4c2f-8701-e16cf546179a,DISK], DatanodeInfoWithStorage[127.0.0.1:44742,DS-9d628067-4fc2-4981-b169-1d5451c0fe33,DISK], DatanodeInfoWithStorage[127.0.0.1:43473,DS-57f6eeac-39c7-4905-aee2-9d1a2f574d52,DISK], DatanodeInfoWithStorage[127.0.0.1:40975,DS-57cab210-9892-4211-9b58-302f9fb2cdda,DISK], DatanodeInfoWithStorage[127.0.0.1:45137,DS-d5976bef-715d-4a59-91b9-322acc3adeba,DISK], DatanodeInfoWithStorage[127.0.0.1:46033,DS-312972ff-752f-4acc-92cf-f1d6e81d8e68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-65741927-172.17.0.9-1595397085199:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41898,DS-4d9850e7-65be-4299-8aff-5e615c19c1c2,DISK], DatanodeInfoWithStorage[127.0.0.1:46578,DS-93c6c4b5-86cf-4a10-b1dc-1da1955e5bbb,DISK], DatanodeInfoWithStorage[127.0.0.1:36761,DS-df73f040-e0cb-4a78-af39-18f9a448274c,DISK], DatanodeInfoWithStorage[127.0.0.1:45134,DS-c6a55c43-36b4-4943-9a4d-ddf9344c15c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44797,DS-602a1593-a5ef-45eb-8fda-dd19d4404433,DISK], DatanodeInfoWithStorage[127.0.0.1:46087,DS-b394a672-10cf-4d1a-9d82-b2c71d9ded46,DISK], DatanodeInfoWithStorage[127.0.0.1:41240,DS-051f1b21-554d-467f-bd1c-6417dd841efe,DISK], DatanodeInfoWithStorage[127.0.0.1:41730,DS-51bb60e2-4cc3-4047-85f3-37284c1b90ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-65741927-172.17.0.9-1595397085199:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41898,DS-4d9850e7-65be-4299-8aff-5e615c19c1c2,DISK], DatanodeInfoWithStorage[127.0.0.1:46578,DS-93c6c4b5-86cf-4a10-b1dc-1da1955e5bbb,DISK], DatanodeInfoWithStorage[127.0.0.1:36761,DS-df73f040-e0cb-4a78-af39-18f9a448274c,DISK], DatanodeInfoWithStorage[127.0.0.1:45134,DS-c6a55c43-36b4-4943-9a4d-ddf9344c15c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44797,DS-602a1593-a5ef-45eb-8fda-dd19d4404433,DISK], DatanodeInfoWithStorage[127.0.0.1:46087,DS-b394a672-10cf-4d1a-9d82-b2c71d9ded46,DISK], DatanodeInfoWithStorage[127.0.0.1:41240,DS-051f1b21-554d-467f-bd1c-6417dd841efe,DISK], DatanodeInfoWithStorage[127.0.0.1:41730,DS-51bb60e2-4cc3-4047-85f3-37284c1b90ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-846559213-172.17.0.9-1595397341423:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37897,DS-f4c66697-bb73-4fb7-b8c6-9f2b50d8cc19,DISK], DatanodeInfoWithStorage[127.0.0.1:45604,DS-6c6d05d9-379f-4b6b-ae35-eb06a5cc0ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:34306,DS-19970097-2f01-44fe-a3f8-efbd8669fd3e,DISK], DatanodeInfoWithStorage[127.0.0.1:40358,DS-21ae779f-1dd7-4d4e-969f-3d48a3802dfb,DISK], DatanodeInfoWithStorage[127.0.0.1:34932,DS-cbaff3ee-6393-4ec6-9bf3-3eb5da89a105,DISK], DatanodeInfoWithStorage[127.0.0.1:42301,DS-e3d8131f-6c2d-4b5d-83b5-24ca39f7bbb0,DISK], DatanodeInfoWithStorage[127.0.0.1:35454,DS-f0b73598-999a-4878-87e6-e2b6b3264ac6,DISK], DatanodeInfoWithStorage[127.0.0.1:40697,DS-4e1c5af1-5ea8-470d-906b-af81a1f50919,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-846559213-172.17.0.9-1595397341423:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37897,DS-f4c66697-bb73-4fb7-b8c6-9f2b50d8cc19,DISK], DatanodeInfoWithStorage[127.0.0.1:45604,DS-6c6d05d9-379f-4b6b-ae35-eb06a5cc0ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:34306,DS-19970097-2f01-44fe-a3f8-efbd8669fd3e,DISK], DatanodeInfoWithStorage[127.0.0.1:40358,DS-21ae779f-1dd7-4d4e-969f-3d48a3802dfb,DISK], DatanodeInfoWithStorage[127.0.0.1:34932,DS-cbaff3ee-6393-4ec6-9bf3-3eb5da89a105,DISK], DatanodeInfoWithStorage[127.0.0.1:42301,DS-e3d8131f-6c2d-4b5d-83b5-24ca39f7bbb0,DISK], DatanodeInfoWithStorage[127.0.0.1:35454,DS-f0b73598-999a-4878-87e6-e2b6b3264ac6,DISK], DatanodeInfoWithStorage[127.0.0.1:40697,DS-4e1c5af1-5ea8-470d-906b-af81a1f50919,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-143559311-172.17.0.9-1595397601397:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45560,DS-57eef0a3-d6e8-4ba1-adff-a25baa38f72d,DISK], DatanodeInfoWithStorage[127.0.0.1:42432,DS-4925396e-6140-4041-be88-a0d32d845017,DISK], DatanodeInfoWithStorage[127.0.0.1:37135,DS-bda3e801-6b96-48e3-b5f4-68ac0e8a0861,DISK], DatanodeInfoWithStorage[127.0.0.1:46494,DS-44e3e40e-3d84-4914-959e-6ca94ecba342,DISK], DatanodeInfoWithStorage[127.0.0.1:40732,DS-feb4471d-e51c-46d9-a2c2-f7fba8c03114,DISK], DatanodeInfoWithStorage[127.0.0.1:36402,DS-c457fc0b-4272-4306-8d02-03dab9839136,DISK], DatanodeInfoWithStorage[127.0.0.1:37780,DS-1ea05e92-4b15-4086-b52e-d97fe18a0391,DISK], DatanodeInfoWithStorage[127.0.0.1:36786,DS-8500276f-b54f-4ce3-9c42-351b24085254,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-143559311-172.17.0.9-1595397601397:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45560,DS-57eef0a3-d6e8-4ba1-adff-a25baa38f72d,DISK], DatanodeInfoWithStorage[127.0.0.1:42432,DS-4925396e-6140-4041-be88-a0d32d845017,DISK], DatanodeInfoWithStorage[127.0.0.1:37135,DS-bda3e801-6b96-48e3-b5f4-68ac0e8a0861,DISK], DatanodeInfoWithStorage[127.0.0.1:46494,DS-44e3e40e-3d84-4914-959e-6ca94ecba342,DISK], DatanodeInfoWithStorage[127.0.0.1:40732,DS-feb4471d-e51c-46d9-a2c2-f7fba8c03114,DISK], DatanodeInfoWithStorage[127.0.0.1:36402,DS-c457fc0b-4272-4306-8d02-03dab9839136,DISK], DatanodeInfoWithStorage[127.0.0.1:37780,DS-1ea05e92-4b15-4086-b52e-d97fe18a0391,DISK], DatanodeInfoWithStorage[127.0.0.1:36786,DS-8500276f-b54f-4ce3-9c42-351b24085254,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-49236325-172.17.0.9-1595397830958:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37106,DS-60333efa-7bf6-4078-aa55-938891b986b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44596,DS-0d85c7d0-7ce9-42ab-98bc-cc88d8ebea6c,DISK], DatanodeInfoWithStorage[127.0.0.1:43644,DS-4f745bea-7d2e-4a92-9c5c-e1877583fec3,DISK], DatanodeInfoWithStorage[127.0.0.1:32917,DS-0f814347-1e0b-43f9-b63f-a9309cbec832,DISK], DatanodeInfoWithStorage[127.0.0.1:40539,DS-778b840f-f388-4f7b-be12-b7445c9cefd2,DISK], DatanodeInfoWithStorage[127.0.0.1:39306,DS-1e647bd1-35b2-43ad-b148-375b6492aee6,DISK], DatanodeInfoWithStorage[127.0.0.1:44476,DS-99c93705-7361-4cab-a6d6-1608496c97df,DISK], DatanodeInfoWithStorage[127.0.0.1:43656,DS-929c87a9-d1ee-403c-8961-ce49ad6a51c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-49236325-172.17.0.9-1595397830958:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37106,DS-60333efa-7bf6-4078-aa55-938891b986b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44596,DS-0d85c7d0-7ce9-42ab-98bc-cc88d8ebea6c,DISK], DatanodeInfoWithStorage[127.0.0.1:43644,DS-4f745bea-7d2e-4a92-9c5c-e1877583fec3,DISK], DatanodeInfoWithStorage[127.0.0.1:32917,DS-0f814347-1e0b-43f9-b63f-a9309cbec832,DISK], DatanodeInfoWithStorage[127.0.0.1:40539,DS-778b840f-f388-4f7b-be12-b7445c9cefd2,DISK], DatanodeInfoWithStorage[127.0.0.1:39306,DS-1e647bd1-35b2-43ad-b148-375b6492aee6,DISK], DatanodeInfoWithStorage[127.0.0.1:44476,DS-99c93705-7361-4cab-a6d6-1608496c97df,DISK], DatanodeInfoWithStorage[127.0.0.1:43656,DS-929c87a9-d1ee-403c-8961-ce49ad6a51c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-909537761-172.17.0.9-1595397959988:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44080,DS-6b570960-4ce1-4f30-be03-da9fafb2c9e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41529,DS-da24722a-81ee-46ea-84a8-571d594d3ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:35432,DS-7be4b382-3755-45ee-bc71-58ef5ab458ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42170,DS-fd4498db-211a-4d75-a510-f068b16250b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43591,DS-6bf2e033-642a-4d72-b728-2fce69d7d8bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37414,DS-afd418fe-17ee-4c88-92bb-4795d4039843,DISK], DatanodeInfoWithStorage[127.0.0.1:38514,DS-41430fd7-5535-41fd-8330-2b7d968f8d7e,DISK], DatanodeInfoWithStorage[127.0.0.1:35600,DS-5d181676-5431-4646-aa73-d8ccc2db7a2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-909537761-172.17.0.9-1595397959988:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44080,DS-6b570960-4ce1-4f30-be03-da9fafb2c9e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41529,DS-da24722a-81ee-46ea-84a8-571d594d3ad6,DISK], DatanodeInfoWithStorage[127.0.0.1:35432,DS-7be4b382-3755-45ee-bc71-58ef5ab458ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42170,DS-fd4498db-211a-4d75-a510-f068b16250b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43591,DS-6bf2e033-642a-4d72-b728-2fce69d7d8bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37414,DS-afd418fe-17ee-4c88-92bb-4795d4039843,DISK], DatanodeInfoWithStorage[127.0.0.1:38514,DS-41430fd7-5535-41fd-8330-2b7d968f8d7e,DISK], DatanodeInfoWithStorage[127.0.0.1:35600,DS-5d181676-5431-4646-aa73-d8ccc2db7a2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-100347198-172.17.0.9-1595398487949:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45991,DS-42a11969-ad09-400a-be9c-f3baebefb12a,DISK], DatanodeInfoWithStorage[127.0.0.1:33665,DS-b38a8caa-bd2f-44e8-81aa-f919b2f16cd8,DISK], DatanodeInfoWithStorage[127.0.0.1:40475,DS-c3c760a2-5e24-4d6a-b2a8-638c96d7db38,DISK], DatanodeInfoWithStorage[127.0.0.1:39257,DS-0df60773-f274-4e76-905f-99be10090082,DISK], DatanodeInfoWithStorage[127.0.0.1:34987,DS-dc852424-654e-49e4-9457-3a4b3a0579e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37258,DS-05f3a712-e235-4153-b936-5d9f2d705163,DISK], DatanodeInfoWithStorage[127.0.0.1:34761,DS-77a4ed09-4321-492d-8ce9-a017b82b137b,DISK], DatanodeInfoWithStorage[127.0.0.1:35093,DS-4515ec02-0ad5-4582-ba5e-65c117cde3d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-100347198-172.17.0.9-1595398487949:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45991,DS-42a11969-ad09-400a-be9c-f3baebefb12a,DISK], DatanodeInfoWithStorage[127.0.0.1:33665,DS-b38a8caa-bd2f-44e8-81aa-f919b2f16cd8,DISK], DatanodeInfoWithStorage[127.0.0.1:40475,DS-c3c760a2-5e24-4d6a-b2a8-638c96d7db38,DISK], DatanodeInfoWithStorage[127.0.0.1:39257,DS-0df60773-f274-4e76-905f-99be10090082,DISK], DatanodeInfoWithStorage[127.0.0.1:34987,DS-dc852424-654e-49e4-9457-3a4b3a0579e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37258,DS-05f3a712-e235-4153-b936-5d9f2d705163,DISK], DatanodeInfoWithStorage[127.0.0.1:34761,DS-77a4ed09-4321-492d-8ce9-a017b82b137b,DISK], DatanodeInfoWithStorage[127.0.0.1:35093,DS-4515ec02-0ad5-4582-ba5e-65c117cde3d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1205797616-172.17.0.9-1595398761467:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38741,DS-edb0cc31-5da6-4071-badf-69e966b571c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37850,DS-dcbfc237-e3f7-4276-9d15-8df1d75f8fae,DISK], DatanodeInfoWithStorage[127.0.0.1:44078,DS-59a086c2-1574-4e64-b67d-65fef313d5d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44962,DS-7dd1449d-f371-4af4-8cf5-9bc3098f3934,DISK], DatanodeInfoWithStorage[127.0.0.1:42436,DS-67126a19-03a4-4be9-9c49-18624f0fc3b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45080,DS-19ce645e-4a06-402a-979a-3670dc010ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:34787,DS-b1d3ed79-a6f5-4406-8a04-2a4a5ad87de2,DISK], DatanodeInfoWithStorage[127.0.0.1:38601,DS-a2eb43cd-817a-47b8-ba69-601b7234e8c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1205797616-172.17.0.9-1595398761467:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38741,DS-edb0cc31-5da6-4071-badf-69e966b571c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37850,DS-dcbfc237-e3f7-4276-9d15-8df1d75f8fae,DISK], DatanodeInfoWithStorage[127.0.0.1:44078,DS-59a086c2-1574-4e64-b67d-65fef313d5d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44962,DS-7dd1449d-f371-4af4-8cf5-9bc3098f3934,DISK], DatanodeInfoWithStorage[127.0.0.1:42436,DS-67126a19-03a4-4be9-9c49-18624f0fc3b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45080,DS-19ce645e-4a06-402a-979a-3670dc010ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:34787,DS-b1d3ed79-a6f5-4406-8a04-2a4a5ad87de2,DISK], DatanodeInfoWithStorage[127.0.0.1:38601,DS-a2eb43cd-817a-47b8-ba69-601b7234e8c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-467293274-172.17.0.9-1595398803855:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44390,DS-b086e7aa-ca72-458f-86c1-9449f29e4dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:34153,DS-6c66e5df-7ead-41db-9e28-43416b441382,DISK], DatanodeInfoWithStorage[127.0.0.1:42711,DS-100daf72-73c7-459d-b91e-dfdf392dc506,DISK], DatanodeInfoWithStorage[127.0.0.1:35387,DS-6d9e1de9-3a38-4a89-a0b7-61f5dc9b3572,DISK], DatanodeInfoWithStorage[127.0.0.1:39759,DS-49a6b87d-1899-4e13-81b0-e2fc31926b82,DISK], DatanodeInfoWithStorage[127.0.0.1:42602,DS-9b837784-3088-4b5c-8ccb-15a909577115,DISK], DatanodeInfoWithStorage[127.0.0.1:34655,DS-9d0081c4-e538-4898-8e30-491338ef527c,DISK], DatanodeInfoWithStorage[127.0.0.1:45559,DS-fa934ba0-33da-448e-9326-2c38d17246ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-467293274-172.17.0.9-1595398803855:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44390,DS-b086e7aa-ca72-458f-86c1-9449f29e4dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:34153,DS-6c66e5df-7ead-41db-9e28-43416b441382,DISK], DatanodeInfoWithStorage[127.0.0.1:42711,DS-100daf72-73c7-459d-b91e-dfdf392dc506,DISK], DatanodeInfoWithStorage[127.0.0.1:35387,DS-6d9e1de9-3a38-4a89-a0b7-61f5dc9b3572,DISK], DatanodeInfoWithStorage[127.0.0.1:39759,DS-49a6b87d-1899-4e13-81b0-e2fc31926b82,DISK], DatanodeInfoWithStorage[127.0.0.1:42602,DS-9b837784-3088-4b5c-8ccb-15a909577115,DISK], DatanodeInfoWithStorage[127.0.0.1:34655,DS-9d0081c4-e538-4898-8e30-491338ef527c,DISK], DatanodeInfoWithStorage[127.0.0.1:45559,DS-fa934ba0-33da-448e-9326-2c38d17246ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-495055244-172.17.0.9-1595399004457:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40186,DS-9b1f8d34-eb82-4f7a-8007-ab642eea186a,DISK], DatanodeInfoWithStorage[127.0.0.1:46466,DS-b00dca51-31dc-42c2-b977-00df4b0b160e,DISK], DatanodeInfoWithStorage[127.0.0.1:34091,DS-53ab54a1-e628-458d-92a9-591e40dc2b07,DISK], DatanodeInfoWithStorage[127.0.0.1:34726,DS-d96f04e0-2841-4f0c-879e-da42a82723a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34368,DS-65dead1c-974a-4ac6-8a4c-838b6498f160,DISK], DatanodeInfoWithStorage[127.0.0.1:40259,DS-4a0ec349-f847-4423-98b6-e84d211e63d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45342,DS-23a2a843-6d8e-44fa-aafa-a5072f2f5f2a,DISK], DatanodeInfoWithStorage[127.0.0.1:42488,DS-78d18a88-894e-4dce-a616-7ce227751a14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-495055244-172.17.0.9-1595399004457:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40186,DS-9b1f8d34-eb82-4f7a-8007-ab642eea186a,DISK], DatanodeInfoWithStorage[127.0.0.1:46466,DS-b00dca51-31dc-42c2-b977-00df4b0b160e,DISK], DatanodeInfoWithStorage[127.0.0.1:34091,DS-53ab54a1-e628-458d-92a9-591e40dc2b07,DISK], DatanodeInfoWithStorage[127.0.0.1:34726,DS-d96f04e0-2841-4f0c-879e-da42a82723a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34368,DS-65dead1c-974a-4ac6-8a4c-838b6498f160,DISK], DatanodeInfoWithStorage[127.0.0.1:40259,DS-4a0ec349-f847-4423-98b6-e84d211e63d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45342,DS-23a2a843-6d8e-44fa-aafa-a5072f2f5f2a,DISK], DatanodeInfoWithStorage[127.0.0.1:42488,DS-78d18a88-894e-4dce-a616-7ce227751a14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-269288914-172.17.0.9-1595399562149:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42791,DS-3ae19d9f-a552-47e2-846f-cc67eaf8a647,DISK], DatanodeInfoWithStorage[127.0.0.1:43110,DS-093149f1-052d-42a0-8902-e66e67a11c59,DISK], DatanodeInfoWithStorage[127.0.0.1:44608,DS-d8a04ff6-befb-4b60-a6c8-87bad37f5616,DISK], DatanodeInfoWithStorage[127.0.0.1:46655,DS-910d7dd6-4979-4a99-89b8-a27a700762af,DISK], DatanodeInfoWithStorage[127.0.0.1:36998,DS-e1ebac4a-f3e7-4e78-b72b-675c2f0e2387,DISK], DatanodeInfoWithStorage[127.0.0.1:46661,DS-3e8bbc3d-c7b1-4af9-85e0-3b29d6c36abf,DISK], DatanodeInfoWithStorage[127.0.0.1:35919,DS-3e4991d1-041d-4b5b-90be-a2b90c41789c,DISK], DatanodeInfoWithStorage[127.0.0.1:37356,DS-b88367d0-6762-4157-bd72-017c08204822,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-269288914-172.17.0.9-1595399562149:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42791,DS-3ae19d9f-a552-47e2-846f-cc67eaf8a647,DISK], DatanodeInfoWithStorage[127.0.0.1:43110,DS-093149f1-052d-42a0-8902-e66e67a11c59,DISK], DatanodeInfoWithStorage[127.0.0.1:44608,DS-d8a04ff6-befb-4b60-a6c8-87bad37f5616,DISK], DatanodeInfoWithStorage[127.0.0.1:46655,DS-910d7dd6-4979-4a99-89b8-a27a700762af,DISK], DatanodeInfoWithStorage[127.0.0.1:36998,DS-e1ebac4a-f3e7-4e78-b72b-675c2f0e2387,DISK], DatanodeInfoWithStorage[127.0.0.1:46661,DS-3e8bbc3d-c7b1-4af9-85e0-3b29d6c36abf,DISK], DatanodeInfoWithStorage[127.0.0.1:35919,DS-3e4991d1-041d-4b5b-90be-a2b90c41789c,DISK], DatanodeInfoWithStorage[127.0.0.1:37356,DS-b88367d0-6762-4157-bd72-017c08204822,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-430015310-172.17.0.9-1595399599107:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40973,DS-cc99cf29-659a-452d-8385-f779c4c8cf03,DISK], DatanodeInfoWithStorage[127.0.0.1:33697,DS-2aa9ebc7-e4b1-49be-adf4-5aa9c1ed9291,DISK], DatanodeInfoWithStorage[127.0.0.1:44165,DS-cf5707b4-f194-4439-8cf3-90e1b879b40d,DISK], DatanodeInfoWithStorage[127.0.0.1:45812,DS-0793b530-5c28-41e4-b815-2f74f511625f,DISK], DatanodeInfoWithStorage[127.0.0.1:37044,DS-254f2e4b-bc9f-4aba-bb1a-b5350927e196,DISK], DatanodeInfoWithStorage[127.0.0.1:36645,DS-05c782b2-d09b-4229-a2f0-3bcde1362996,DISK], DatanodeInfoWithStorage[127.0.0.1:39013,DS-1394c09a-3fe7-4640-9d1f-8ddb9841bc2b,DISK], DatanodeInfoWithStorage[127.0.0.1:44576,DS-0c834f49-8c98-4386-9bdc-dc93d70105ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-430015310-172.17.0.9-1595399599107:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40973,DS-cc99cf29-659a-452d-8385-f779c4c8cf03,DISK], DatanodeInfoWithStorage[127.0.0.1:33697,DS-2aa9ebc7-e4b1-49be-adf4-5aa9c1ed9291,DISK], DatanodeInfoWithStorage[127.0.0.1:44165,DS-cf5707b4-f194-4439-8cf3-90e1b879b40d,DISK], DatanodeInfoWithStorage[127.0.0.1:45812,DS-0793b530-5c28-41e4-b815-2f74f511625f,DISK], DatanodeInfoWithStorage[127.0.0.1:37044,DS-254f2e4b-bc9f-4aba-bb1a-b5350927e196,DISK], DatanodeInfoWithStorage[127.0.0.1:36645,DS-05c782b2-d09b-4229-a2f0-3bcde1362996,DISK], DatanodeInfoWithStorage[127.0.0.1:39013,DS-1394c09a-3fe7-4640-9d1f-8ddb9841bc2b,DISK], DatanodeInfoWithStorage[127.0.0.1:44576,DS-0c834f49-8c98-4386-9bdc-dc93d70105ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1894833990-172.17.0.9-1595399771971:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40608,DS-abde3b46-634a-4f57-b2b5-2742463a1524,DISK], DatanodeInfoWithStorage[127.0.0.1:39543,DS-db282751-2874-4bdf-a7fe-9c98b260cbaa,DISK], DatanodeInfoWithStorage[127.0.0.1:36363,DS-bb132e8c-ae55-45bd-8f70-afd4d8ee8c26,DISK], DatanodeInfoWithStorage[127.0.0.1:35285,DS-61eff0cb-5030-45c0-bea3-ac9d561ef5c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38702,DS-9d977534-c00c-4a75-bb2d-5591e92b6358,DISK], DatanodeInfoWithStorage[127.0.0.1:39857,DS-0c1686f1-1f39-47fb-aa33-5e6452bcdc86,DISK], DatanodeInfoWithStorage[127.0.0.1:36884,DS-919699da-1b3d-4374-ac20-ca2ad0984400,DISK], DatanodeInfoWithStorage[127.0.0.1:43292,DS-05227f5e-2dc0-4085-886b-6addc23b2bd9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1894833990-172.17.0.9-1595399771971:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40608,DS-abde3b46-634a-4f57-b2b5-2742463a1524,DISK], DatanodeInfoWithStorage[127.0.0.1:39543,DS-db282751-2874-4bdf-a7fe-9c98b260cbaa,DISK], DatanodeInfoWithStorage[127.0.0.1:36363,DS-bb132e8c-ae55-45bd-8f70-afd4d8ee8c26,DISK], DatanodeInfoWithStorage[127.0.0.1:35285,DS-61eff0cb-5030-45c0-bea3-ac9d561ef5c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38702,DS-9d977534-c00c-4a75-bb2d-5591e92b6358,DISK], DatanodeInfoWithStorage[127.0.0.1:39857,DS-0c1686f1-1f39-47fb-aa33-5e6452bcdc86,DISK], DatanodeInfoWithStorage[127.0.0.1:36884,DS-919699da-1b3d-4374-ac20-ca2ad0984400,DISK], DatanodeInfoWithStorage[127.0.0.1:43292,DS-05227f5e-2dc0-4085-886b-6addc23b2bd9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1198250046-172.17.0.9-1595399806016:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45154,DS-72bbdefc-17c1-47cb-b9af-63b3c84e73f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34246,DS-5f51489f-bdd0-412f-84ba-8f7bbf46b5ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33609,DS-1f20a833-0d46-4059-b781-860e6ce7e2f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40024,DS-26ad3228-fa17-4e4e-af3a-fe1b23d985d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33987,DS-eb58572e-9e3d-4005-aa6f-02ad65c49ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:36758,DS-826e336a-a55b-42cf-8e28-4fbac1333b95,DISK], DatanodeInfoWithStorage[127.0.0.1:41909,DS-3149e8f2-36f5-48cb-adab-acb0cb048108,DISK], DatanodeInfoWithStorage[127.0.0.1:46548,DS-4c52ebbb-36eb-4b79-aac2-ec658609827b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1198250046-172.17.0.9-1595399806016:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45154,DS-72bbdefc-17c1-47cb-b9af-63b3c84e73f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34246,DS-5f51489f-bdd0-412f-84ba-8f7bbf46b5ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33609,DS-1f20a833-0d46-4059-b781-860e6ce7e2f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40024,DS-26ad3228-fa17-4e4e-af3a-fe1b23d985d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33987,DS-eb58572e-9e3d-4005-aa6f-02ad65c49ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:36758,DS-826e336a-a55b-42cf-8e28-4fbac1333b95,DISK], DatanodeInfoWithStorage[127.0.0.1:41909,DS-3149e8f2-36f5-48cb-adab-acb0cb048108,DISK], DatanodeInfoWithStorage[127.0.0.1:46548,DS-4c52ebbb-36eb-4b79-aac2-ec658609827b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2118275485-172.17.0.9-1595399949245:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35272,DS-a8594ae3-282b-4870-8929-c74440b27dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:40286,DS-c1a0b89d-b4ee-4df5-8639-1dd27bf448ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42287,DS-c287554f-8703-43c6-bd12-78e8b62a79fc,DISK], DatanodeInfoWithStorage[127.0.0.1:46507,DS-cfeadf4b-66e2-448b-a503-82896f33f056,DISK], DatanodeInfoWithStorage[127.0.0.1:40974,DS-1b026ae3-780e-41ac-a174-15435cd7252e,DISK], DatanodeInfoWithStorage[127.0.0.1:35768,DS-a1db91b9-c4ff-474a-9c2f-f58bbe218dea,DISK], DatanodeInfoWithStorage[127.0.0.1:42586,DS-13d82d37-54b4-41d6-ab22-5fee8de085a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42781,DS-fbc5a28e-3666-4d22-a1b4-460458cd0ed8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2118275485-172.17.0.9-1595399949245:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35272,DS-a8594ae3-282b-4870-8929-c74440b27dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:40286,DS-c1a0b89d-b4ee-4df5-8639-1dd27bf448ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42287,DS-c287554f-8703-43c6-bd12-78e8b62a79fc,DISK], DatanodeInfoWithStorage[127.0.0.1:46507,DS-cfeadf4b-66e2-448b-a503-82896f33f056,DISK], DatanodeInfoWithStorage[127.0.0.1:40974,DS-1b026ae3-780e-41ac-a174-15435cd7252e,DISK], DatanodeInfoWithStorage[127.0.0.1:35768,DS-a1db91b9-c4ff-474a-9c2f-f58bbe218dea,DISK], DatanodeInfoWithStorage[127.0.0.1:42586,DS-13d82d37-54b4-41d6-ab22-5fee8de085a7,DISK], DatanodeInfoWithStorage[127.0.0.1:42781,DS-fbc5a28e-3666-4d22-a1b4-460458cd0ed8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1265172308-172.17.0.9-1595400024039:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46867,DS-3306c058-0b23-488e-ab16-bd8d2e48a734,DISK], DatanodeInfoWithStorage[127.0.0.1:33846,DS-044685a1-21b9-49e3-92f6-0b95913cc8d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39173,DS-a0883ced-3cfa-4454-b540-99d9de3cc117,DISK], DatanodeInfoWithStorage[127.0.0.1:41708,DS-ce2ae850-3d50-4209-a831-81e78ba88511,DISK], DatanodeInfoWithStorage[127.0.0.1:46002,DS-bb219f2c-0c8b-47a4-aaef-c0ad81ed6369,DISK], DatanodeInfoWithStorage[127.0.0.1:46083,DS-e6abb04f-fdb0-4cff-9bc3-912afbfe720f,DISK], DatanodeInfoWithStorage[127.0.0.1:41485,DS-33a59f66-1c1a-4180-aaf1-7c20abd80e21,DISK], DatanodeInfoWithStorage[127.0.0.1:41312,DS-b43ed9c3-994f-44eb-8d36-69a733c2671f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1265172308-172.17.0.9-1595400024039:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46867,DS-3306c058-0b23-488e-ab16-bd8d2e48a734,DISK], DatanodeInfoWithStorage[127.0.0.1:33846,DS-044685a1-21b9-49e3-92f6-0b95913cc8d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39173,DS-a0883ced-3cfa-4454-b540-99d9de3cc117,DISK], DatanodeInfoWithStorage[127.0.0.1:41708,DS-ce2ae850-3d50-4209-a831-81e78ba88511,DISK], DatanodeInfoWithStorage[127.0.0.1:46002,DS-bb219f2c-0c8b-47a4-aaef-c0ad81ed6369,DISK], DatanodeInfoWithStorage[127.0.0.1:46083,DS-e6abb04f-fdb0-4cff-9bc3-912afbfe720f,DISK], DatanodeInfoWithStorage[127.0.0.1:41485,DS-33a59f66-1c1a-4180-aaf1-7c20abd80e21,DISK], DatanodeInfoWithStorage[127.0.0.1:41312,DS-b43ed9c3-994f-44eb-8d36-69a733c2671f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1316309196-172.17.0.9-1595400065296:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46681,DS-7b4e8b0c-a75c-461e-974e-a5b417686a29,DISK], DatanodeInfoWithStorage[127.0.0.1:40406,DS-603a853b-efad-4875-b8d1-91eefc4de176,DISK], DatanodeInfoWithStorage[127.0.0.1:39035,DS-681c47ce-b09b-42fe-a9f5-3a82a6975b11,DISK], DatanodeInfoWithStorage[127.0.0.1:41630,DS-f9b7f0d4-5adc-4ea9-ad48-776a2b40c67d,DISK], DatanodeInfoWithStorage[127.0.0.1:38391,DS-c257e16b-3ecd-418a-8f0e-7639418ede4f,DISK], DatanodeInfoWithStorage[127.0.0.1:38203,DS-7e1295a8-9d68-4591-b6c8-d5b87d202dea,DISK], DatanodeInfoWithStorage[127.0.0.1:44829,DS-15e92604-a1b1-42bb-822e-25c64989ea02,DISK], DatanodeInfoWithStorage[127.0.0.1:39714,DS-fe5bb109-bc58-4c07-a559-8e8d292b552d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1316309196-172.17.0.9-1595400065296:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46681,DS-7b4e8b0c-a75c-461e-974e-a5b417686a29,DISK], DatanodeInfoWithStorage[127.0.0.1:40406,DS-603a853b-efad-4875-b8d1-91eefc4de176,DISK], DatanodeInfoWithStorage[127.0.0.1:39035,DS-681c47ce-b09b-42fe-a9f5-3a82a6975b11,DISK], DatanodeInfoWithStorage[127.0.0.1:41630,DS-f9b7f0d4-5adc-4ea9-ad48-776a2b40c67d,DISK], DatanodeInfoWithStorage[127.0.0.1:38391,DS-c257e16b-3ecd-418a-8f0e-7639418ede4f,DISK], DatanodeInfoWithStorage[127.0.0.1:38203,DS-7e1295a8-9d68-4591-b6c8-d5b87d202dea,DISK], DatanodeInfoWithStorage[127.0.0.1:44829,DS-15e92604-a1b1-42bb-822e-25c64989ea02,DISK], DatanodeInfoWithStorage[127.0.0.1:39714,DS-fe5bb109-bc58-4c07-a559-8e8d292b552d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1081020310-172.17.0.9-1595400289697:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44964,DS-bcac10c4-d17c-45e6-b754-e7b58b670399,DISK], DatanodeInfoWithStorage[127.0.0.1:36318,DS-97d8e74f-20e6-42aa-88f5-be0a29b14ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:35078,DS-a737a418-f77e-4ff5-b644-c3e8a84e9083,DISK], DatanodeInfoWithStorage[127.0.0.1:36905,DS-3c110cfd-ea32-4bc4-b4dc-9d1ab86f2f08,DISK], DatanodeInfoWithStorage[127.0.0.1:35239,DS-d2e717b3-777b-4a5a-9007-b6a705ed6618,DISK], DatanodeInfoWithStorage[127.0.0.1:46269,DS-5a07ada6-7dd5-4aa6-a2fb-196323ae8b85,DISK], DatanodeInfoWithStorage[127.0.0.1:39164,DS-8afb00cf-bcb1-41d4-9d6f-803ec7564054,DISK], DatanodeInfoWithStorage[127.0.0.1:44371,DS-133e93d3-3788-47de-9559-99be45341147,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1081020310-172.17.0.9-1595400289697:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44964,DS-bcac10c4-d17c-45e6-b754-e7b58b670399,DISK], DatanodeInfoWithStorage[127.0.0.1:36318,DS-97d8e74f-20e6-42aa-88f5-be0a29b14ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:35078,DS-a737a418-f77e-4ff5-b644-c3e8a84e9083,DISK], DatanodeInfoWithStorage[127.0.0.1:36905,DS-3c110cfd-ea32-4bc4-b4dc-9d1ab86f2f08,DISK], DatanodeInfoWithStorage[127.0.0.1:35239,DS-d2e717b3-777b-4a5a-9007-b6a705ed6618,DISK], DatanodeInfoWithStorage[127.0.0.1:46269,DS-5a07ada6-7dd5-4aa6-a2fb-196323ae8b85,DISK], DatanodeInfoWithStorage[127.0.0.1:39164,DS-8afb00cf-bcb1-41d4-9d6f-803ec7564054,DISK], DatanodeInfoWithStorage[127.0.0.1:44371,DS-133e93d3-3788-47de-9559-99be45341147,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-684300619-172.17.0.9-1595400322587:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44972,DS-901c6119-8da4-42ac-8ff0-41f6ec1981cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33509,DS-73e2f1cb-4b45-4009-8eb0-d1b00862d035,DISK], DatanodeInfoWithStorage[127.0.0.1:42498,DS-fb7c5280-cc3a-4144-a2af-b4231923e333,DISK], DatanodeInfoWithStorage[127.0.0.1:43180,DS-ba0dca78-9638-4d52-b844-20ebdf82075a,DISK], DatanodeInfoWithStorage[127.0.0.1:39380,DS-4cee0976-9e4a-409a-b1b0-4af0a3576ea9,DISK], DatanodeInfoWithStorage[127.0.0.1:35609,DS-37e8acbd-720b-4f7a-957d-aeeb70f204c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46680,DS-94ced250-da95-4ef7-be38-b328539712da,DISK], DatanodeInfoWithStorage[127.0.0.1:44533,DS-55a6c453-931b-40bc-bb1d-b2edc3f08fe8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-684300619-172.17.0.9-1595400322587:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44972,DS-901c6119-8da4-42ac-8ff0-41f6ec1981cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33509,DS-73e2f1cb-4b45-4009-8eb0-d1b00862d035,DISK], DatanodeInfoWithStorage[127.0.0.1:42498,DS-fb7c5280-cc3a-4144-a2af-b4231923e333,DISK], DatanodeInfoWithStorage[127.0.0.1:43180,DS-ba0dca78-9638-4d52-b844-20ebdf82075a,DISK], DatanodeInfoWithStorage[127.0.0.1:39380,DS-4cee0976-9e4a-409a-b1b0-4af0a3576ea9,DISK], DatanodeInfoWithStorage[127.0.0.1:35609,DS-37e8acbd-720b-4f7a-957d-aeeb70f204c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46680,DS-94ced250-da95-4ef7-be38-b328539712da,DISK], DatanodeInfoWithStorage[127.0.0.1:44533,DS-55a6c453-931b-40bc-bb1d-b2edc3f08fe8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1224225117-172.17.0.9-1595400397826:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40652,DS-39d6d5c4-7fc5-4c17-b464-bd1c07c77035,DISK], DatanodeInfoWithStorage[127.0.0.1:40904,DS-0e01eb87-72d4-4336-a9da-fad2f1a22c84,DISK], DatanodeInfoWithStorage[127.0.0.1:38844,DS-6e544007-7936-4353-8a24-9d8a4391094f,DISK], DatanodeInfoWithStorage[127.0.0.1:43139,DS-ede2a004-6e10-4e3d-84e4-1d2186f15551,DISK], DatanodeInfoWithStorage[127.0.0.1:44227,DS-cf8485ec-5d6b-4fa6-9a27-95e43c731f77,DISK], DatanodeInfoWithStorage[127.0.0.1:41470,DS-56c8e984-0a86-4091-96e9-61839ecac559,DISK], DatanodeInfoWithStorage[127.0.0.1:37110,DS-e86bd055-4bd0-47e4-b7fa-7186aaceaeea,DISK], DatanodeInfoWithStorage[127.0.0.1:40583,DS-451911ac-1198-4d0a-8b79-f5dcd97cc417,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1224225117-172.17.0.9-1595400397826:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40652,DS-39d6d5c4-7fc5-4c17-b464-bd1c07c77035,DISK], DatanodeInfoWithStorage[127.0.0.1:40904,DS-0e01eb87-72d4-4336-a9da-fad2f1a22c84,DISK], DatanodeInfoWithStorage[127.0.0.1:38844,DS-6e544007-7936-4353-8a24-9d8a4391094f,DISK], DatanodeInfoWithStorage[127.0.0.1:43139,DS-ede2a004-6e10-4e3d-84e4-1d2186f15551,DISK], DatanodeInfoWithStorage[127.0.0.1:44227,DS-cf8485ec-5d6b-4fa6-9a27-95e43c731f77,DISK], DatanodeInfoWithStorage[127.0.0.1:41470,DS-56c8e984-0a86-4091-96e9-61839ecac559,DISK], DatanodeInfoWithStorage[127.0.0.1:37110,DS-e86bd055-4bd0-47e4-b7fa-7186aaceaeea,DISK], DatanodeInfoWithStorage[127.0.0.1:40583,DS-451911ac-1198-4d0a-8b79-f5dcd97cc417,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2137551204-172.17.0.9-1595401135049:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36755,DS-afb42ba1-66d2-43ad-bd3b-0ca1f9ef1df3,DISK], DatanodeInfoWithStorage[127.0.0.1:43955,DS-3891bc1a-ee95-4b59-a325-8a7bcd104ef2,DISK], DatanodeInfoWithStorage[127.0.0.1:40425,DS-60fe90c7-ddf0-4d6b-9dd9-3a85a51b27a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45312,DS-bf90cbca-d612-425b-b2f9-9841302d1468,DISK], DatanodeInfoWithStorage[127.0.0.1:37107,DS-6c4d9060-94b9-4352-b246-2d4e3fb64f91,DISK], DatanodeInfoWithStorage[127.0.0.1:39346,DS-ed66a6ef-4333-47d4-8d82-20f55c00a662,DISK], DatanodeInfoWithStorage[127.0.0.1:37982,DS-90760eeb-dc4c-41b0-9569-fcc97eadff2a,DISK], DatanodeInfoWithStorage[127.0.0.1:39236,DS-0918ec42-17be-4ae0-978a-c416bdd37f54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2137551204-172.17.0.9-1595401135049:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36755,DS-afb42ba1-66d2-43ad-bd3b-0ca1f9ef1df3,DISK], DatanodeInfoWithStorage[127.0.0.1:43955,DS-3891bc1a-ee95-4b59-a325-8a7bcd104ef2,DISK], DatanodeInfoWithStorage[127.0.0.1:40425,DS-60fe90c7-ddf0-4d6b-9dd9-3a85a51b27a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45312,DS-bf90cbca-d612-425b-b2f9-9841302d1468,DISK], DatanodeInfoWithStorage[127.0.0.1:37107,DS-6c4d9060-94b9-4352-b246-2d4e3fb64f91,DISK], DatanodeInfoWithStorage[127.0.0.1:39346,DS-ed66a6ef-4333-47d4-8d82-20f55c00a662,DISK], DatanodeInfoWithStorage[127.0.0.1:37982,DS-90760eeb-dc4c-41b0-9569-fcc97eadff2a,DISK], DatanodeInfoWithStorage[127.0.0.1:39236,DS-0918ec42-17be-4ae0-978a-c416bdd37f54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.jetty.logs.serve.aliases
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1014762732-172.17.0.9-1595401432489:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39588,DS-771833e3-90cf-4143-8b3f-b7bb551cd591,DISK], DatanodeInfoWithStorage[127.0.0.1:42409,DS-18fa893f-39c0-4467-8558-403ac631fb06,DISK], DatanodeInfoWithStorage[127.0.0.1:45706,DS-dafa5af5-ae64-4a97-904e-55f523c88740,DISK], DatanodeInfoWithStorage[127.0.0.1:39531,DS-b3c328c1-033c-4091-ae0d-07024f34ab91,DISK], DatanodeInfoWithStorage[127.0.0.1:43436,DS-bd603c30-f852-4993-bb2d-1257249bcb7d,DISK], DatanodeInfoWithStorage[127.0.0.1:46357,DS-b57b9db9-cf7e-4674-bae3-de9ac1ac1634,DISK], DatanodeInfoWithStorage[127.0.0.1:41789,DS-91425309-3897-4dac-a8a0-ad5ed69d7faf,DISK], DatanodeInfoWithStorage[127.0.0.1:35571,DS-2d6f77b1-63ee-46b4-9665-c5d8b59d08ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1014762732-172.17.0.9-1595401432489:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39588,DS-771833e3-90cf-4143-8b3f-b7bb551cd591,DISK], DatanodeInfoWithStorage[127.0.0.1:42409,DS-18fa893f-39c0-4467-8558-403ac631fb06,DISK], DatanodeInfoWithStorage[127.0.0.1:45706,DS-dafa5af5-ae64-4a97-904e-55f523c88740,DISK], DatanodeInfoWithStorage[127.0.0.1:39531,DS-b3c328c1-033c-4091-ae0d-07024f34ab91,DISK], DatanodeInfoWithStorage[127.0.0.1:43436,DS-bd603c30-f852-4993-bb2d-1257249bcb7d,DISK], DatanodeInfoWithStorage[127.0.0.1:46357,DS-b57b9db9-cf7e-4674-bae3-de9ac1ac1634,DISK], DatanodeInfoWithStorage[127.0.0.1:41789,DS-91425309-3897-4dac-a8a0-ad5ed69d7faf,DISK], DatanodeInfoWithStorage[127.0.0.1:35571,DS-2d6f77b1-63ee-46b4-9665-c5d8b59d08ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5188
