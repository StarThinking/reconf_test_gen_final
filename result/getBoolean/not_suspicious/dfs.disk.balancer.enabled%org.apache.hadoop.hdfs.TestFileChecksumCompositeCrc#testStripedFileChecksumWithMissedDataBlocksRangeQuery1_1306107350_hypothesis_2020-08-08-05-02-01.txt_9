reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-702436665-172.17.0.15-1596862942207:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43102,DS-8619d0fd-7d29-484e-be87-33cb250bd3e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33640,DS-b3377819-e450-42b3-805c-db02342594e5,DISK], DatanodeInfoWithStorage[127.0.0.1:33717,DS-2891ad79-739c-4504-ac9e-8b477a6727f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46646,DS-130f7e0f-78ca-48a8-8cee-2fc4b77b6f92,DISK], DatanodeInfoWithStorage[127.0.0.1:44629,DS-10cca969-287a-4f21-a32a-4604ac097a43,DISK], DatanodeInfoWithStorage[127.0.0.1:41250,DS-b10d5a70-fa7b-4d05-9ffe-115a4443b0b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45784,DS-38f9ea95-ab7c-4c6b-9c55-685d3d66c048,DISK], DatanodeInfoWithStorage[127.0.0.1:45878,DS-14a47054-6a46-48a8-94ba-b88d124f90f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-702436665-172.17.0.15-1596862942207:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43102,DS-8619d0fd-7d29-484e-be87-33cb250bd3e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33640,DS-b3377819-e450-42b3-805c-db02342594e5,DISK], DatanodeInfoWithStorage[127.0.0.1:33717,DS-2891ad79-739c-4504-ac9e-8b477a6727f2,DISK], DatanodeInfoWithStorage[127.0.0.1:46646,DS-130f7e0f-78ca-48a8-8cee-2fc4b77b6f92,DISK], DatanodeInfoWithStorage[127.0.0.1:44629,DS-10cca969-287a-4f21-a32a-4604ac097a43,DISK], DatanodeInfoWithStorage[127.0.0.1:41250,DS-b10d5a70-fa7b-4d05-9ffe-115a4443b0b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45784,DS-38f9ea95-ab7c-4c6b-9c55-685d3d66c048,DISK], DatanodeInfoWithStorage[127.0.0.1:45878,DS-14a47054-6a46-48a8-94ba-b88d124f90f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1079639132-172.17.0.15-1596863991531:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39629,DS-e2cb12ee-4c33-444e-8e19-ec590b34079c,DISK], DatanodeInfoWithStorage[127.0.0.1:32878,DS-decbf2cd-0880-4806-9d0a-dd2ad89e6d4f,DISK], DatanodeInfoWithStorage[127.0.0.1:43620,DS-c61a66d6-e161-4797-9c42-d0831dcf5267,DISK], DatanodeInfoWithStorage[127.0.0.1:32880,DS-7c64e40c-b5be-4b03-8567-aa9dc81023c3,DISK], DatanodeInfoWithStorage[127.0.0.1:36188,DS-a0a68051-c10d-4ab6-b2c4-6b9492c441cf,DISK], DatanodeInfoWithStorage[127.0.0.1:44263,DS-18faee75-36ec-45f3-9b4c-2d97b385c0e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41350,DS-83fcd725-682a-4ff2-a86e-9ae1f8c310a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41768,DS-cc41c6ae-8340-457e-aba0-f2192b7f2b74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1079639132-172.17.0.15-1596863991531:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39629,DS-e2cb12ee-4c33-444e-8e19-ec590b34079c,DISK], DatanodeInfoWithStorage[127.0.0.1:32878,DS-decbf2cd-0880-4806-9d0a-dd2ad89e6d4f,DISK], DatanodeInfoWithStorage[127.0.0.1:43620,DS-c61a66d6-e161-4797-9c42-d0831dcf5267,DISK], DatanodeInfoWithStorage[127.0.0.1:32880,DS-7c64e40c-b5be-4b03-8567-aa9dc81023c3,DISK], DatanodeInfoWithStorage[127.0.0.1:36188,DS-a0a68051-c10d-4ab6-b2c4-6b9492c441cf,DISK], DatanodeInfoWithStorage[127.0.0.1:44263,DS-18faee75-36ec-45f3-9b4c-2d97b385c0e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41350,DS-83fcd725-682a-4ff2-a86e-9ae1f8c310a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41768,DS-cc41c6ae-8340-457e-aba0-f2192b7f2b74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-412510201-172.17.0.15-1596864160245:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39051,DS-8bb0be3a-06c2-4d3d-8e0d-ae9812ea2c4f,DISK], DatanodeInfoWithStorage[127.0.0.1:38187,DS-d69fa730-f48e-47de-bcf1-fa6948579369,DISK], DatanodeInfoWithStorage[127.0.0.1:45307,DS-f0006f91-254e-41d9-8b39-a8d46c378845,DISK], DatanodeInfoWithStorage[127.0.0.1:36536,DS-a6e36f47-baf1-46f9-a4da-98dcc1a5fb1c,DISK], DatanodeInfoWithStorage[127.0.0.1:37018,DS-f92807dd-6917-4d21-88c4-48531cec194f,DISK], DatanodeInfoWithStorage[127.0.0.1:36650,DS-1b61b2af-98f0-4867-8356-0c99e99f310f,DISK], DatanodeInfoWithStorage[127.0.0.1:37587,DS-7c38c1d2-6278-4e15-a7ef-009330fcd76f,DISK], DatanodeInfoWithStorage[127.0.0.1:32953,DS-f5ffd85f-06c7-433c-997c-35d824f325a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-412510201-172.17.0.15-1596864160245:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39051,DS-8bb0be3a-06c2-4d3d-8e0d-ae9812ea2c4f,DISK], DatanodeInfoWithStorage[127.0.0.1:38187,DS-d69fa730-f48e-47de-bcf1-fa6948579369,DISK], DatanodeInfoWithStorage[127.0.0.1:45307,DS-f0006f91-254e-41d9-8b39-a8d46c378845,DISK], DatanodeInfoWithStorage[127.0.0.1:36536,DS-a6e36f47-baf1-46f9-a4da-98dcc1a5fb1c,DISK], DatanodeInfoWithStorage[127.0.0.1:37018,DS-f92807dd-6917-4d21-88c4-48531cec194f,DISK], DatanodeInfoWithStorage[127.0.0.1:36650,DS-1b61b2af-98f0-4867-8356-0c99e99f310f,DISK], DatanodeInfoWithStorage[127.0.0.1:37587,DS-7c38c1d2-6278-4e15-a7ef-009330fcd76f,DISK], DatanodeInfoWithStorage[127.0.0.1:32953,DS-f5ffd85f-06c7-433c-997c-35d824f325a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1735035736-172.17.0.15-1596864974760:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44554,DS-71d988c3-7050-40f4-8ee4-6fc699a42f31,DISK], DatanodeInfoWithStorage[127.0.0.1:42215,DS-e997aae6-3abc-4dc1-95fc-484a9cc1a99d,DISK], DatanodeInfoWithStorage[127.0.0.1:33615,DS-09f38099-5c39-4994-862d-711576f67955,DISK], DatanodeInfoWithStorage[127.0.0.1:43049,DS-fc74ef9d-dd5c-4e72-b7a0-e9cec327c984,DISK], DatanodeInfoWithStorage[127.0.0.1:36879,DS-5fcd61a0-8108-4960-8587-f979f5a55b44,DISK], DatanodeInfoWithStorage[127.0.0.1:41952,DS-94a12df4-c9d3-460a-b3c9-2a077a5f9cc7,DISK], DatanodeInfoWithStorage[127.0.0.1:42335,DS-f1eaeb92-f2d6-464c-91a5-cb171a579544,DISK], DatanodeInfoWithStorage[127.0.0.1:32955,DS-aa919135-de0d-49cf-8539-68c4437ed21f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1735035736-172.17.0.15-1596864974760:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44554,DS-71d988c3-7050-40f4-8ee4-6fc699a42f31,DISK], DatanodeInfoWithStorage[127.0.0.1:42215,DS-e997aae6-3abc-4dc1-95fc-484a9cc1a99d,DISK], DatanodeInfoWithStorage[127.0.0.1:33615,DS-09f38099-5c39-4994-862d-711576f67955,DISK], DatanodeInfoWithStorage[127.0.0.1:43049,DS-fc74ef9d-dd5c-4e72-b7a0-e9cec327c984,DISK], DatanodeInfoWithStorage[127.0.0.1:36879,DS-5fcd61a0-8108-4960-8587-f979f5a55b44,DISK], DatanodeInfoWithStorage[127.0.0.1:41952,DS-94a12df4-c9d3-460a-b3c9-2a077a5f9cc7,DISK], DatanodeInfoWithStorage[127.0.0.1:42335,DS-f1eaeb92-f2d6-464c-91a5-cb171a579544,DISK], DatanodeInfoWithStorage[127.0.0.1:32955,DS-aa919135-de0d-49cf-8539-68c4437ed21f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-539298807-172.17.0.15-1596865340075:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40498,DS-43829a2b-1d5a-4cc9-930b-065287caf3e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46510,DS-cc2e2c60-753a-449b-b305-18170de445ff,DISK], DatanodeInfoWithStorage[127.0.0.1:34909,DS-f3532c24-f4bd-4d4e-a75d-71b981c09a3e,DISK], DatanodeInfoWithStorage[127.0.0.1:42854,DS-b74333cb-413e-4087-9009-4827996df7e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36189,DS-c1aba121-8c2c-4eb3-a5d8-d267a78ed817,DISK], DatanodeInfoWithStorage[127.0.0.1:33678,DS-a16af4e3-7c37-40aa-9c7d-7c863a6c57e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45622,DS-11d4ad49-a45b-4ffc-a4ae-b63457e240ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40785,DS-f7f499ec-b319-4367-8437-0eaf307f321d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-539298807-172.17.0.15-1596865340075:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40498,DS-43829a2b-1d5a-4cc9-930b-065287caf3e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46510,DS-cc2e2c60-753a-449b-b305-18170de445ff,DISK], DatanodeInfoWithStorage[127.0.0.1:34909,DS-f3532c24-f4bd-4d4e-a75d-71b981c09a3e,DISK], DatanodeInfoWithStorage[127.0.0.1:42854,DS-b74333cb-413e-4087-9009-4827996df7e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36189,DS-c1aba121-8c2c-4eb3-a5d8-d267a78ed817,DISK], DatanodeInfoWithStorage[127.0.0.1:33678,DS-a16af4e3-7c37-40aa-9c7d-7c863a6c57e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45622,DS-11d4ad49-a45b-4ffc-a4ae-b63457e240ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40785,DS-f7f499ec-b319-4367-8437-0eaf307f321d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-582854-172.17.0.15-1596865393764:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36082,DS-a92a4cf5-e672-4c48-935d-cf2691619167,DISK], DatanodeInfoWithStorage[127.0.0.1:40041,DS-27d74409-d2dd-475b-b81d-c1137a120a57,DISK], DatanodeInfoWithStorage[127.0.0.1:38630,DS-56d76810-fbc8-405b-86c1-27fb304a0073,DISK], DatanodeInfoWithStorage[127.0.0.1:33736,DS-273eb257-eeb7-4de8-a59a-9b27abc492e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42008,DS-6f0af9dd-1e4a-44f8-bb36-2f4f8def3c8d,DISK], DatanodeInfoWithStorage[127.0.0.1:39113,DS-903ae914-f15e-47fb-be83-3c41f960cdb0,DISK], DatanodeInfoWithStorage[127.0.0.1:43208,DS-c22c3a87-fa08-4e83-b50e-6c14c839b60d,DISK], DatanodeInfoWithStorage[127.0.0.1:40562,DS-3e2d0601-688d-4abd-8bfd-19ce66daedfd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-582854-172.17.0.15-1596865393764:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36082,DS-a92a4cf5-e672-4c48-935d-cf2691619167,DISK], DatanodeInfoWithStorage[127.0.0.1:40041,DS-27d74409-d2dd-475b-b81d-c1137a120a57,DISK], DatanodeInfoWithStorage[127.0.0.1:38630,DS-56d76810-fbc8-405b-86c1-27fb304a0073,DISK], DatanodeInfoWithStorage[127.0.0.1:33736,DS-273eb257-eeb7-4de8-a59a-9b27abc492e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42008,DS-6f0af9dd-1e4a-44f8-bb36-2f4f8def3c8d,DISK], DatanodeInfoWithStorage[127.0.0.1:39113,DS-903ae914-f15e-47fb-be83-3c41f960cdb0,DISK], DatanodeInfoWithStorage[127.0.0.1:43208,DS-c22c3a87-fa08-4e83-b50e-6c14c839b60d,DISK], DatanodeInfoWithStorage[127.0.0.1:40562,DS-3e2d0601-688d-4abd-8bfd-19ce66daedfd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1158004524-172.17.0.15-1596865836698:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41177,DS-f4fe2125-82ba-4d6f-87af-5d5731c65c08,DISK], DatanodeInfoWithStorage[127.0.0.1:44850,DS-beef5b2c-c399-4004-b5f1-09d6e130420a,DISK], DatanodeInfoWithStorage[127.0.0.1:45868,DS-c419a9f9-f377-4480-83c5-c62211b68ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:41723,DS-b29cb1b4-0877-486f-9b66-92324535c81d,DISK], DatanodeInfoWithStorage[127.0.0.1:37794,DS-2fc23fc4-e9a2-44b4-aa1b-4a2fccabc608,DISK], DatanodeInfoWithStorage[127.0.0.1:46463,DS-8560aee0-8995-4629-bbcd-738ac2ce8230,DISK], DatanodeInfoWithStorage[127.0.0.1:35417,DS-e8883cb4-bd6d-4fd0-944c-168133dee371,DISK], DatanodeInfoWithStorage[127.0.0.1:44064,DS-e5d483bd-d7aa-48ec-9ea3-d591ab194db0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1158004524-172.17.0.15-1596865836698:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41177,DS-f4fe2125-82ba-4d6f-87af-5d5731c65c08,DISK], DatanodeInfoWithStorage[127.0.0.1:44850,DS-beef5b2c-c399-4004-b5f1-09d6e130420a,DISK], DatanodeInfoWithStorage[127.0.0.1:45868,DS-c419a9f9-f377-4480-83c5-c62211b68ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:41723,DS-b29cb1b4-0877-486f-9b66-92324535c81d,DISK], DatanodeInfoWithStorage[127.0.0.1:37794,DS-2fc23fc4-e9a2-44b4-aa1b-4a2fccabc608,DISK], DatanodeInfoWithStorage[127.0.0.1:46463,DS-8560aee0-8995-4629-bbcd-738ac2ce8230,DISK], DatanodeInfoWithStorage[127.0.0.1:35417,DS-e8883cb4-bd6d-4fd0-944c-168133dee371,DISK], DatanodeInfoWithStorage[127.0.0.1:44064,DS-e5d483bd-d7aa-48ec-9ea3-d591ab194db0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1324440637-172.17.0.15-1596866102936:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44206,DS-af0389a5-bf07-44d7-a2fb-8899bb4b058b,DISK], DatanodeInfoWithStorage[127.0.0.1:43899,DS-eef2625b-460b-424f-8f03-97bc4eda928d,DISK], DatanodeInfoWithStorage[127.0.0.1:37475,DS-21e72044-120a-457a-800d-5bf9e888be9b,DISK], DatanodeInfoWithStorage[127.0.0.1:34438,DS-9d458c02-bc56-49ee-8aad-188ffd5c8798,DISK], DatanodeInfoWithStorage[127.0.0.1:42509,DS-ec354ffa-8d0d-419b-a259-35be41c34f28,DISK], DatanodeInfoWithStorage[127.0.0.1:39515,DS-7e19b16b-7c0b-4ace-83e7-cdffd3ec9d93,DISK], DatanodeInfoWithStorage[127.0.0.1:40960,DS-4be48a7c-50cb-4a9f-9057-0071495179fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46516,DS-58b6513e-52c1-4869-aa0f-8f98cf7947a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1324440637-172.17.0.15-1596866102936:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44206,DS-af0389a5-bf07-44d7-a2fb-8899bb4b058b,DISK], DatanodeInfoWithStorage[127.0.0.1:43899,DS-eef2625b-460b-424f-8f03-97bc4eda928d,DISK], DatanodeInfoWithStorage[127.0.0.1:37475,DS-21e72044-120a-457a-800d-5bf9e888be9b,DISK], DatanodeInfoWithStorage[127.0.0.1:34438,DS-9d458c02-bc56-49ee-8aad-188ffd5c8798,DISK], DatanodeInfoWithStorage[127.0.0.1:42509,DS-ec354ffa-8d0d-419b-a259-35be41c34f28,DISK], DatanodeInfoWithStorage[127.0.0.1:39515,DS-7e19b16b-7c0b-4ace-83e7-cdffd3ec9d93,DISK], DatanodeInfoWithStorage[127.0.0.1:40960,DS-4be48a7c-50cb-4a9f-9057-0071495179fa,DISK], DatanodeInfoWithStorage[127.0.0.1:46516,DS-58b6513e-52c1-4869-aa0f-8f98cf7947a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-520043414-172.17.0.15-1596866368117:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44486,DS-b29ff7f6-96a4-4e6b-a7d2-3061a046e1f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46218,DS-df0353fe-2826-4069-b0bb-642ee720c03d,DISK], DatanodeInfoWithStorage[127.0.0.1:41690,DS-87e123d4-e566-4129-a617-43d51da97704,DISK], DatanodeInfoWithStorage[127.0.0.1:36756,DS-3def3240-24ad-409a-8c82-94620be22dba,DISK], DatanodeInfoWithStorage[127.0.0.1:45350,DS-f6c1f20c-7593-4e21-a291-1d8295412ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:40116,DS-7c5c0769-4f40-419e-8a08-d2e4c57ba087,DISK], DatanodeInfoWithStorage[127.0.0.1:38634,DS-a425a1b2-3045-4d40-b382-1c50a4be7b10,DISK], DatanodeInfoWithStorage[127.0.0.1:34356,DS-02f5b56e-bd3e-4d0f-8546-3cd35a640495,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-520043414-172.17.0.15-1596866368117:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44486,DS-b29ff7f6-96a4-4e6b-a7d2-3061a046e1f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46218,DS-df0353fe-2826-4069-b0bb-642ee720c03d,DISK], DatanodeInfoWithStorage[127.0.0.1:41690,DS-87e123d4-e566-4129-a617-43d51da97704,DISK], DatanodeInfoWithStorage[127.0.0.1:36756,DS-3def3240-24ad-409a-8c82-94620be22dba,DISK], DatanodeInfoWithStorage[127.0.0.1:45350,DS-f6c1f20c-7593-4e21-a291-1d8295412ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:40116,DS-7c5c0769-4f40-419e-8a08-d2e4c57ba087,DISK], DatanodeInfoWithStorage[127.0.0.1:38634,DS-a425a1b2-3045-4d40-b382-1c50a4be7b10,DISK], DatanodeInfoWithStorage[127.0.0.1:34356,DS-02f5b56e-bd3e-4d0f-8546-3cd35a640495,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-10231505-172.17.0.15-1596866868257:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44867,DS-217e91dc-55f9-45a8-8af4-cf4adaa3f061,DISK], DatanodeInfoWithStorage[127.0.0.1:39509,DS-847f5336-0976-4b7a-ac0b-8cb3c8f4fd61,DISK], DatanodeInfoWithStorage[127.0.0.1:46583,DS-da58507f-6ad6-4a56-ae94-4602fddec1c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33700,DS-c6a1b499-2791-4dd0-8edc-f6b18df9a8ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41150,DS-b7304b3c-7558-469c-a6bf-50730dbc162e,DISK], DatanodeInfoWithStorage[127.0.0.1:39260,DS-ffb18bd0-d987-4fc5-b5c6-21a678fa1588,DISK], DatanodeInfoWithStorage[127.0.0.1:35850,DS-f707e313-61e0-435a-a172-62e5f4d17765,DISK], DatanodeInfoWithStorage[127.0.0.1:38653,DS-66bc1082-ee13-40df-bdb9-17d7e3a77377,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-10231505-172.17.0.15-1596866868257:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44867,DS-217e91dc-55f9-45a8-8af4-cf4adaa3f061,DISK], DatanodeInfoWithStorage[127.0.0.1:39509,DS-847f5336-0976-4b7a-ac0b-8cb3c8f4fd61,DISK], DatanodeInfoWithStorage[127.0.0.1:46583,DS-da58507f-6ad6-4a56-ae94-4602fddec1c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33700,DS-c6a1b499-2791-4dd0-8edc-f6b18df9a8ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41150,DS-b7304b3c-7558-469c-a6bf-50730dbc162e,DISK], DatanodeInfoWithStorage[127.0.0.1:39260,DS-ffb18bd0-d987-4fc5-b5c6-21a678fa1588,DISK], DatanodeInfoWithStorage[127.0.0.1:35850,DS-f707e313-61e0-435a-a172-62e5f4d17765,DISK], DatanodeInfoWithStorage[127.0.0.1:38653,DS-66bc1082-ee13-40df-bdb9-17d7e3a77377,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2113393852-172.17.0.15-1596867840936:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38516,DS-db34ba11-0171-40c3-b1de-0051bbeabdff,DISK], DatanodeInfoWithStorage[127.0.0.1:36179,DS-bc0d7ea3-8ca4-48e0-9f8c-dd620333af88,DISK], DatanodeInfoWithStorage[127.0.0.1:41858,DS-0b58872c-467b-4218-af95-069982ddf938,DISK], DatanodeInfoWithStorage[127.0.0.1:39944,DS-b8c2798d-f3ea-4ee1-aaa6-e0e90555a1a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34700,DS-cac1d3f3-6f72-4ec5-9efc-75c8525b5a18,DISK], DatanodeInfoWithStorage[127.0.0.1:34699,DS-9325b072-4d40-4016-b08c-19b4bc438dae,DISK], DatanodeInfoWithStorage[127.0.0.1:46853,DS-92516dd6-8cac-45ef-85c5-9cdd3b172548,DISK], DatanodeInfoWithStorage[127.0.0.1:33617,DS-cfd38532-0225-4193-8001-8f7000f50a1f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2113393852-172.17.0.15-1596867840936:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38516,DS-db34ba11-0171-40c3-b1de-0051bbeabdff,DISK], DatanodeInfoWithStorage[127.0.0.1:36179,DS-bc0d7ea3-8ca4-48e0-9f8c-dd620333af88,DISK], DatanodeInfoWithStorage[127.0.0.1:41858,DS-0b58872c-467b-4218-af95-069982ddf938,DISK], DatanodeInfoWithStorage[127.0.0.1:39944,DS-b8c2798d-f3ea-4ee1-aaa6-e0e90555a1a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34700,DS-cac1d3f3-6f72-4ec5-9efc-75c8525b5a18,DISK], DatanodeInfoWithStorage[127.0.0.1:34699,DS-9325b072-4d40-4016-b08c-19b4bc438dae,DISK], DatanodeInfoWithStorage[127.0.0.1:46853,DS-92516dd6-8cac-45ef-85c5-9cdd3b172548,DISK], DatanodeInfoWithStorage[127.0.0.1:33617,DS-cfd38532-0225-4193-8001-8f7000f50a1f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1788128280-172.17.0.15-1596868103032:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40911,DS-68c800f0-55fc-4ec0-9285-4227a0e33ddc,DISK], DatanodeInfoWithStorage[127.0.0.1:40190,DS-cb2021c3-56aa-4834-bc7d-db8b31c71a73,DISK], DatanodeInfoWithStorage[127.0.0.1:46134,DS-ce7fced5-bd43-47eb-bb74-3cdf43b5edf5,DISK], DatanodeInfoWithStorage[127.0.0.1:39639,DS-1ee862ce-0b72-4682-b5b1-a471e68d6587,DISK], DatanodeInfoWithStorage[127.0.0.1:35868,DS-e60b9a81-1460-4f9c-b2b5-d13075fa91a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36377,DS-72ebb37b-8bd7-4c75-a8b2-1ef7988aece7,DISK], DatanodeInfoWithStorage[127.0.0.1:34861,DS-b740a675-5b25-4f32-bf3d-2a65d720d60f,DISK], DatanodeInfoWithStorage[127.0.0.1:41243,DS-7b0dad6c-9a92-4c0c-bdd3-49d59970c8ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1788128280-172.17.0.15-1596868103032:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40911,DS-68c800f0-55fc-4ec0-9285-4227a0e33ddc,DISK], DatanodeInfoWithStorage[127.0.0.1:40190,DS-cb2021c3-56aa-4834-bc7d-db8b31c71a73,DISK], DatanodeInfoWithStorage[127.0.0.1:46134,DS-ce7fced5-bd43-47eb-bb74-3cdf43b5edf5,DISK], DatanodeInfoWithStorage[127.0.0.1:39639,DS-1ee862ce-0b72-4682-b5b1-a471e68d6587,DISK], DatanodeInfoWithStorage[127.0.0.1:35868,DS-e60b9a81-1460-4f9c-b2b5-d13075fa91a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36377,DS-72ebb37b-8bd7-4c75-a8b2-1ef7988aece7,DISK], DatanodeInfoWithStorage[127.0.0.1:34861,DS-b740a675-5b25-4f32-bf3d-2a65d720d60f,DISK], DatanodeInfoWithStorage[127.0.0.1:41243,DS-7b0dad6c-9a92-4c0c-bdd3-49d59970c8ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1507389657-172.17.0.15-1596868418989:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37970,DS-8aa829ae-838d-474a-b95b-0175efc499e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42849,DS-be0cdac3-b4df-43e7-a17e-5ee6efd7bd93,DISK], DatanodeInfoWithStorage[127.0.0.1:42299,DS-b8ed7c35-7d8d-4dec-be48-8a3505904ec3,DISK], DatanodeInfoWithStorage[127.0.0.1:41297,DS-95eced3e-0964-4e2d-a1ed-687154cc7537,DISK], DatanodeInfoWithStorage[127.0.0.1:43351,DS-ee7d7f9c-e4d0-472a-993b-f9d070f45d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:36874,DS-ee3c4169-00cf-4fd1-9295-34c51b125704,DISK], DatanodeInfoWithStorage[127.0.0.1:40643,DS-d4df92a5-a7f5-46bd-bcb4-035a8a82dcbc,DISK], DatanodeInfoWithStorage[127.0.0.1:45632,DS-01135099-70ef-4359-a6cd-7dbec5d8111b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1507389657-172.17.0.15-1596868418989:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37970,DS-8aa829ae-838d-474a-b95b-0175efc499e7,DISK], DatanodeInfoWithStorage[127.0.0.1:42849,DS-be0cdac3-b4df-43e7-a17e-5ee6efd7bd93,DISK], DatanodeInfoWithStorage[127.0.0.1:42299,DS-b8ed7c35-7d8d-4dec-be48-8a3505904ec3,DISK], DatanodeInfoWithStorage[127.0.0.1:41297,DS-95eced3e-0964-4e2d-a1ed-687154cc7537,DISK], DatanodeInfoWithStorage[127.0.0.1:43351,DS-ee7d7f9c-e4d0-472a-993b-f9d070f45d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:36874,DS-ee3c4169-00cf-4fd1-9295-34c51b125704,DISK], DatanodeInfoWithStorage[127.0.0.1:40643,DS-d4df92a5-a7f5-46bd-bcb4-035a8a82dcbc,DISK], DatanodeInfoWithStorage[127.0.0.1:45632,DS-01135099-70ef-4359-a6cd-7dbec5d8111b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1834812191-172.17.0.15-1596868898934:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40956,DS-b6570d6d-bab9-48f7-8934-98dcaf2a44f1,DISK], DatanodeInfoWithStorage[127.0.0.1:46288,DS-d276d05a-4695-4788-914d-9c192ee1b0f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35516,DS-ac8c3e85-1fda-4756-ab34-7fde6ce283aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33355,DS-6f8b1de8-590c-42c8-9240-910366a9db0b,DISK], DatanodeInfoWithStorage[127.0.0.1:46273,DS-ee4bbf84-0f79-4400-ae28-7885f045da6f,DISK], DatanodeInfoWithStorage[127.0.0.1:41565,DS-08105363-affc-4fde-9918-60296557ebc5,DISK], DatanodeInfoWithStorage[127.0.0.1:41743,DS-8c796331-7979-4d48-95d8-4315eb960674,DISK], DatanodeInfoWithStorage[127.0.0.1:37782,DS-6e1a1891-ac35-4201-ab0a-9132d18f556a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1834812191-172.17.0.15-1596868898934:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40956,DS-b6570d6d-bab9-48f7-8934-98dcaf2a44f1,DISK], DatanodeInfoWithStorage[127.0.0.1:46288,DS-d276d05a-4695-4788-914d-9c192ee1b0f9,DISK], DatanodeInfoWithStorage[127.0.0.1:35516,DS-ac8c3e85-1fda-4756-ab34-7fde6ce283aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33355,DS-6f8b1de8-590c-42c8-9240-910366a9db0b,DISK], DatanodeInfoWithStorage[127.0.0.1:46273,DS-ee4bbf84-0f79-4400-ae28-7885f045da6f,DISK], DatanodeInfoWithStorage[127.0.0.1:41565,DS-08105363-affc-4fde-9918-60296557ebc5,DISK], DatanodeInfoWithStorage[127.0.0.1:41743,DS-8c796331-7979-4d48-95d8-4315eb960674,DISK], DatanodeInfoWithStorage[127.0.0.1:37782,DS-6e1a1891-ac35-4201-ab0a-9132d18f556a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1445894922-172.17.0.15-1596868984239:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37613,DS-e0b67325-c023-43b4-8d90-b642bfeb2bed,DISK], DatanodeInfoWithStorage[127.0.0.1:41316,DS-fc264716-e83b-413c-8d72-c374541b9e61,DISK], DatanodeInfoWithStorage[127.0.0.1:39581,DS-6d8d809f-3d93-48ad-9ac7-48a68c3fe6f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46627,DS-a74227e7-d003-4c53-925a-8d7d77979b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:37886,DS-477f83ff-ca29-42e9-99cf-adf5c0c99723,DISK], DatanodeInfoWithStorage[127.0.0.1:42018,DS-ef49e01c-ab2f-453c-9890-2df94b082211,DISK], DatanodeInfoWithStorage[127.0.0.1:42087,DS-721f999f-16a0-4f24-94f1-532e556b0eea,DISK], DatanodeInfoWithStorage[127.0.0.1:41722,DS-b1fda4e0-54db-4a68-9e80-94018cad8438,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1445894922-172.17.0.15-1596868984239:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37613,DS-e0b67325-c023-43b4-8d90-b642bfeb2bed,DISK], DatanodeInfoWithStorage[127.0.0.1:41316,DS-fc264716-e83b-413c-8d72-c374541b9e61,DISK], DatanodeInfoWithStorage[127.0.0.1:39581,DS-6d8d809f-3d93-48ad-9ac7-48a68c3fe6f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46627,DS-a74227e7-d003-4c53-925a-8d7d77979b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:37886,DS-477f83ff-ca29-42e9-99cf-adf5c0c99723,DISK], DatanodeInfoWithStorage[127.0.0.1:42018,DS-ef49e01c-ab2f-453c-9890-2df94b082211,DISK], DatanodeInfoWithStorage[127.0.0.1:42087,DS-721f999f-16a0-4f24-94f1-532e556b0eea,DISK], DatanodeInfoWithStorage[127.0.0.1:41722,DS-b1fda4e0-54db-4a68-9e80-94018cad8438,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-675676647-172.17.0.15-1596869157625:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43146,DS-04fcdd42-3cd1-4d04-9c99-0f0186fecba0,DISK], DatanodeInfoWithStorage[127.0.0.1:36139,DS-97aed4ec-7ced-448d-9cbf-d00dc819de08,DISK], DatanodeInfoWithStorage[127.0.0.1:32913,DS-8ab8c8c4-5e91-4b51-8eb0-80fe884cbae2,DISK], DatanodeInfoWithStorage[127.0.0.1:41702,DS-43ef85fe-6436-462a-94e8-911cf815e667,DISK], DatanodeInfoWithStorage[127.0.0.1:41347,DS-6c354813-5682-483b-b1d8-72eac811ab43,DISK], DatanodeInfoWithStorage[127.0.0.1:42243,DS-4b9a30e5-a76e-4169-a6a8-51fb7149a12e,DISK], DatanodeInfoWithStorage[127.0.0.1:40807,DS-636df027-6d85-44e5-9389-75ac2210307c,DISK], DatanodeInfoWithStorage[127.0.0.1:33652,DS-dcd8a7ae-1fb0-4319-9215-4691455db2d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-675676647-172.17.0.15-1596869157625:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43146,DS-04fcdd42-3cd1-4d04-9c99-0f0186fecba0,DISK], DatanodeInfoWithStorage[127.0.0.1:36139,DS-97aed4ec-7ced-448d-9cbf-d00dc819de08,DISK], DatanodeInfoWithStorage[127.0.0.1:32913,DS-8ab8c8c4-5e91-4b51-8eb0-80fe884cbae2,DISK], DatanodeInfoWithStorage[127.0.0.1:41702,DS-43ef85fe-6436-462a-94e8-911cf815e667,DISK], DatanodeInfoWithStorage[127.0.0.1:41347,DS-6c354813-5682-483b-b1d8-72eac811ab43,DISK], DatanodeInfoWithStorage[127.0.0.1:42243,DS-4b9a30e5-a76e-4169-a6a8-51fb7149a12e,DISK], DatanodeInfoWithStorage[127.0.0.1:40807,DS-636df027-6d85-44e5-9389-75ac2210307c,DISK], DatanodeInfoWithStorage[127.0.0.1:33652,DS-dcd8a7ae-1fb0-4319-9215-4691455db2d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1818515472-172.17.0.15-1596869199903:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40008,DS-377413ae-a92a-4fa6-a221-880da88fcca3,DISK], DatanodeInfoWithStorage[127.0.0.1:37635,DS-5530b032-b808-47a6-b816-a920fdbada8b,DISK], DatanodeInfoWithStorage[127.0.0.1:36590,DS-200b651a-204d-4937-aa7c-2387d1cf42bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41903,DS-3dda1ada-caff-453f-8878-39e09096ac6f,DISK], DatanodeInfoWithStorage[127.0.0.1:43733,DS-75668f14-a12d-4e38-b1e0-df40c58eca29,DISK], DatanodeInfoWithStorage[127.0.0.1:38841,DS-807f43c1-bb3a-421c-a97a-015e24308ed0,DISK], DatanodeInfoWithStorage[127.0.0.1:36865,DS-89db4099-71fe-4ea9-afa7-259be657d012,DISK], DatanodeInfoWithStorage[127.0.0.1:42584,DS-a570dd3b-f767-4341-a3e9-3c795f1d3703,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1818515472-172.17.0.15-1596869199903:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40008,DS-377413ae-a92a-4fa6-a221-880da88fcca3,DISK], DatanodeInfoWithStorage[127.0.0.1:37635,DS-5530b032-b808-47a6-b816-a920fdbada8b,DISK], DatanodeInfoWithStorage[127.0.0.1:36590,DS-200b651a-204d-4937-aa7c-2387d1cf42bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41903,DS-3dda1ada-caff-453f-8878-39e09096ac6f,DISK], DatanodeInfoWithStorage[127.0.0.1:43733,DS-75668f14-a12d-4e38-b1e0-df40c58eca29,DISK], DatanodeInfoWithStorage[127.0.0.1:38841,DS-807f43c1-bb3a-421c-a97a-015e24308ed0,DISK], DatanodeInfoWithStorage[127.0.0.1:36865,DS-89db4099-71fe-4ea9-afa7-259be657d012,DISK], DatanodeInfoWithStorage[127.0.0.1:42584,DS-a570dd3b-f767-4341-a3e9-3c795f1d3703,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1633303823-172.17.0.15-1596869426087:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42226,DS-d3eff7ff-42fe-4e1f-959d-ce73f45689c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40380,DS-058d43d4-17bc-4f2e-80bc-0bdb75b4524f,DISK], DatanodeInfoWithStorage[127.0.0.1:43250,DS-58848f98-c0ca-425c-aab2-9eba56b8a546,DISK], DatanodeInfoWithStorage[127.0.0.1:42120,DS-28001fa1-1c44-4b3b-b892-cebee6edddbd,DISK], DatanodeInfoWithStorage[127.0.0.1:40492,DS-f4d3d6fa-0dc5-45cd-9bb6-f4e4a5d7e572,DISK], DatanodeInfoWithStorage[127.0.0.1:39519,DS-7091274d-63fb-45a0-8ae2-8df4d9e7835b,DISK], DatanodeInfoWithStorage[127.0.0.1:42584,DS-10d9076a-02cf-427e-8782-280e7a2d9a8b,DISK], DatanodeInfoWithStorage[127.0.0.1:45943,DS-c8e82fe9-6f0e-495a-ba4e-06010655dea7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1633303823-172.17.0.15-1596869426087:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42226,DS-d3eff7ff-42fe-4e1f-959d-ce73f45689c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40380,DS-058d43d4-17bc-4f2e-80bc-0bdb75b4524f,DISK], DatanodeInfoWithStorage[127.0.0.1:43250,DS-58848f98-c0ca-425c-aab2-9eba56b8a546,DISK], DatanodeInfoWithStorage[127.0.0.1:42120,DS-28001fa1-1c44-4b3b-b892-cebee6edddbd,DISK], DatanodeInfoWithStorage[127.0.0.1:40492,DS-f4d3d6fa-0dc5-45cd-9bb6-f4e4a5d7e572,DISK], DatanodeInfoWithStorage[127.0.0.1:39519,DS-7091274d-63fb-45a0-8ae2-8df4d9e7835b,DISK], DatanodeInfoWithStorage[127.0.0.1:42584,DS-10d9076a-02cf-427e-8782-280e7a2d9a8b,DISK], DatanodeInfoWithStorage[127.0.0.1:45943,DS-c8e82fe9-6f0e-495a-ba4e-06010655dea7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1525316559-172.17.0.15-1596869471479:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41726,DS-92e2de6e-a7ff-45c4-8acd-8d01c6678884,DISK], DatanodeInfoWithStorage[127.0.0.1:37976,DS-68f7193e-cfc9-4f01-be6b-76b9661f24b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36999,DS-9fa03ef1-d0a8-40cd-bd2c-923e28b22ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:37171,DS-b686d4e1-9cc5-4585-be01-40154637740c,DISK], DatanodeInfoWithStorage[127.0.0.1:34685,DS-5fd166c6-e77f-43ef-84a1-fa3d3aca938b,DISK], DatanodeInfoWithStorage[127.0.0.1:35571,DS-543a5547-b1d6-4440-884f-83fd575fa1ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45853,DS-bb8e33bc-ccd7-47f5-85fc-a5afc281d17d,DISK], DatanodeInfoWithStorage[127.0.0.1:44920,DS-a349832e-fea0-4fe5-9137-e51419fd72ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1525316559-172.17.0.15-1596869471479:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41726,DS-92e2de6e-a7ff-45c4-8acd-8d01c6678884,DISK], DatanodeInfoWithStorage[127.0.0.1:37976,DS-68f7193e-cfc9-4f01-be6b-76b9661f24b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36999,DS-9fa03ef1-d0a8-40cd-bd2c-923e28b22ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:37171,DS-b686d4e1-9cc5-4585-be01-40154637740c,DISK], DatanodeInfoWithStorage[127.0.0.1:34685,DS-5fd166c6-e77f-43ef-84a1-fa3d3aca938b,DISK], DatanodeInfoWithStorage[127.0.0.1:35571,DS-543a5547-b1d6-4440-884f-83fd575fa1ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45853,DS-bb8e33bc-ccd7-47f5-85fc-a5afc281d17d,DISK], DatanodeInfoWithStorage[127.0.0.1:44920,DS-a349832e-fea0-4fe5-9137-e51419fd72ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 6580
