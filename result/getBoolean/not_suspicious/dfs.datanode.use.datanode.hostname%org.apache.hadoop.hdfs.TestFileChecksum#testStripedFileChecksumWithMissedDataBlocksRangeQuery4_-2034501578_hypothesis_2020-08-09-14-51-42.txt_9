reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1201117676-172.17.0.16-1596984715494:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32796,DS-f351aa40-fc68-4568-b41f-920da1a847e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46274,DS-80e2b93f-7cbc-467c-bbc1-6a4cfbfe3c09,DISK], DatanodeInfoWithStorage[127.0.0.1:45057,DS-6fcb4d05-cc5a-4bab-940b-ceee93df2455,DISK], DatanodeInfoWithStorage[127.0.0.1:39370,DS-2de4de4c-7ba4-46e1-af4e-c8a0afce169b,DISK], DatanodeInfoWithStorage[127.0.0.1:43290,DS-ebbc913a-4e47-4c63-93df-317c30fc41a1,DISK], DatanodeInfoWithStorage[127.0.0.1:46578,DS-b5dd4011-b9a1-480a-b5c1-4ea5854a4982,DISK], DatanodeInfoWithStorage[127.0.0.1:37493,DS-5e8f4f49-ae79-4812-89e1-8c5dd5c7215e,DISK], DatanodeInfoWithStorage[127.0.0.1:39012,DS-235be359-f858-445f-bf63-387e27a095a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1201117676-172.17.0.16-1596984715494:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32796,DS-f351aa40-fc68-4568-b41f-920da1a847e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46274,DS-80e2b93f-7cbc-467c-bbc1-6a4cfbfe3c09,DISK], DatanodeInfoWithStorage[127.0.0.1:45057,DS-6fcb4d05-cc5a-4bab-940b-ceee93df2455,DISK], DatanodeInfoWithStorage[127.0.0.1:39370,DS-2de4de4c-7ba4-46e1-af4e-c8a0afce169b,DISK], DatanodeInfoWithStorage[127.0.0.1:43290,DS-ebbc913a-4e47-4c63-93df-317c30fc41a1,DISK], DatanodeInfoWithStorage[127.0.0.1:46578,DS-b5dd4011-b9a1-480a-b5c1-4ea5854a4982,DISK], DatanodeInfoWithStorage[127.0.0.1:37493,DS-5e8f4f49-ae79-4812-89e1-8c5dd5c7215e,DISK], DatanodeInfoWithStorage[127.0.0.1:39012,DS-235be359-f858-445f-bf63-387e27a095a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2040843359-172.17.0.16-1596984911335:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43591,DS-bf88ccae-93e1-4255-bd08-beead3c36152,DISK], DatanodeInfoWithStorage[127.0.0.1:45262,DS-6193ccc7-ef9b-46b7-a7f3-ac8541714b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:40292,DS-1066399a-709c-4b9e-8de3-bcff139c751f,DISK], DatanodeInfoWithStorage[127.0.0.1:35546,DS-6e082b53-f3c3-4db4-bd5a-5b1e838ee477,DISK], DatanodeInfoWithStorage[127.0.0.1:40296,DS-1d43cc65-db59-4d38-abb6-7ec0fdd403a4,DISK], DatanodeInfoWithStorage[127.0.0.1:39839,DS-7fe68a40-e2e4-429f-b1a2-81ed7d8fd622,DISK], DatanodeInfoWithStorage[127.0.0.1:39792,DS-5ece731c-5277-420a-9f37-8b022453554d,DISK], DatanodeInfoWithStorage[127.0.0.1:38333,DS-fbfe282d-ee3e-4744-99fb-bbcf6c78379f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2040843359-172.17.0.16-1596984911335:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43591,DS-bf88ccae-93e1-4255-bd08-beead3c36152,DISK], DatanodeInfoWithStorage[127.0.0.1:45262,DS-6193ccc7-ef9b-46b7-a7f3-ac8541714b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:40292,DS-1066399a-709c-4b9e-8de3-bcff139c751f,DISK], DatanodeInfoWithStorage[127.0.0.1:35546,DS-6e082b53-f3c3-4db4-bd5a-5b1e838ee477,DISK], DatanodeInfoWithStorage[127.0.0.1:40296,DS-1d43cc65-db59-4d38-abb6-7ec0fdd403a4,DISK], DatanodeInfoWithStorage[127.0.0.1:39839,DS-7fe68a40-e2e4-429f-b1a2-81ed7d8fd622,DISK], DatanodeInfoWithStorage[127.0.0.1:39792,DS-5ece731c-5277-420a-9f37-8b022453554d,DISK], DatanodeInfoWithStorage[127.0.0.1:38333,DS-fbfe282d-ee3e-4744-99fb-bbcf6c78379f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1820730206-172.17.0.16-1596985214147:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42714,DS-5206b22d-e7df-481f-9aee-e4eea07202c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33836,DS-ef63ab63-d063-4748-9637-8d2d263fb964,DISK], DatanodeInfoWithStorage[127.0.0.1:36075,DS-9f5be008-6d3b-415c-9334-97bd6ae4e003,DISK], DatanodeInfoWithStorage[127.0.0.1:43427,DS-012dd8ce-5dfb-4e89-960e-fcf764472fe7,DISK], DatanodeInfoWithStorage[127.0.0.1:38689,DS-fbccd82c-168d-4258-befe-5d114e7cdcdb,DISK], DatanodeInfoWithStorage[127.0.0.1:37717,DS-b241b36e-43b3-496a-b5d0-97e62c82dfe8,DISK], DatanodeInfoWithStorage[127.0.0.1:42700,DS-7d9de909-e730-4af6-bb54-26d5dfd5eed5,DISK], DatanodeInfoWithStorage[127.0.0.1:40663,DS-af39fe58-2319-4631-9ff5-1a07d4022180,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1820730206-172.17.0.16-1596985214147:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42714,DS-5206b22d-e7df-481f-9aee-e4eea07202c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33836,DS-ef63ab63-d063-4748-9637-8d2d263fb964,DISK], DatanodeInfoWithStorage[127.0.0.1:36075,DS-9f5be008-6d3b-415c-9334-97bd6ae4e003,DISK], DatanodeInfoWithStorage[127.0.0.1:43427,DS-012dd8ce-5dfb-4e89-960e-fcf764472fe7,DISK], DatanodeInfoWithStorage[127.0.0.1:38689,DS-fbccd82c-168d-4258-befe-5d114e7cdcdb,DISK], DatanodeInfoWithStorage[127.0.0.1:37717,DS-b241b36e-43b3-496a-b5d0-97e62c82dfe8,DISK], DatanodeInfoWithStorage[127.0.0.1:42700,DS-7d9de909-e730-4af6-bb54-26d5dfd5eed5,DISK], DatanodeInfoWithStorage[127.0.0.1:40663,DS-af39fe58-2319-4631-9ff5-1a07d4022180,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1749487354-172.17.0.16-1596985668246:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45699,DS-03d94bdb-9c6a-4268-aa22-e2f14e6f3668,DISK], DatanodeInfoWithStorage[127.0.0.1:46089,DS-6200fe97-9a90-43ba-b1c1-7ca28cca2d00,DISK], DatanodeInfoWithStorage[127.0.0.1:35116,DS-5abef251-a02c-4617-a003-e0678a7fd650,DISK], DatanodeInfoWithStorage[127.0.0.1:44161,DS-a254e042-fd45-4c9b-8c57-5fd7236cbcb0,DISK], DatanodeInfoWithStorage[127.0.0.1:43550,DS-756140d6-3313-4871-85ce-a4374fc09a7b,DISK], DatanodeInfoWithStorage[127.0.0.1:40428,DS-aaf5d181-d2df-4b53-89a8-a77e8d20d301,DISK], DatanodeInfoWithStorage[127.0.0.1:41524,DS-75cf9f2e-9067-40cd-afbb-55de8eceb780,DISK], DatanodeInfoWithStorage[127.0.0.1:40970,DS-132e9e01-2008-49f1-839d-89c13f46a951,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1749487354-172.17.0.16-1596985668246:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45699,DS-03d94bdb-9c6a-4268-aa22-e2f14e6f3668,DISK], DatanodeInfoWithStorage[127.0.0.1:46089,DS-6200fe97-9a90-43ba-b1c1-7ca28cca2d00,DISK], DatanodeInfoWithStorage[127.0.0.1:35116,DS-5abef251-a02c-4617-a003-e0678a7fd650,DISK], DatanodeInfoWithStorage[127.0.0.1:44161,DS-a254e042-fd45-4c9b-8c57-5fd7236cbcb0,DISK], DatanodeInfoWithStorage[127.0.0.1:43550,DS-756140d6-3313-4871-85ce-a4374fc09a7b,DISK], DatanodeInfoWithStorage[127.0.0.1:40428,DS-aaf5d181-d2df-4b53-89a8-a77e8d20d301,DISK], DatanodeInfoWithStorage[127.0.0.1:41524,DS-75cf9f2e-9067-40cd-afbb-55de8eceb780,DISK], DatanodeInfoWithStorage[127.0.0.1:40970,DS-132e9e01-2008-49f1-839d-89c13f46a951,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1986530655-172.17.0.16-1596985840244:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45492,DS-cbb693ca-f1eb-44fa-9929-873edc45696a,DISK], DatanodeInfoWithStorage[127.0.0.1:38832,DS-0c750c9f-566c-4878-9e44-bc2b91f3e79b,DISK], DatanodeInfoWithStorage[127.0.0.1:38689,DS-d7cfdc4c-5d1c-468e-aa93-2057cfb13a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:37712,DS-1c263d84-cb5f-4d2e-9cab-a7841238baf2,DISK], DatanodeInfoWithStorage[127.0.0.1:36240,DS-7d578645-4fc1-41be-a713-d88a8b4a7035,DISK], DatanodeInfoWithStorage[127.0.0.1:35694,DS-a23decdf-2b3e-455f-ab8d-d2e789ec20e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45369,DS-e66b9cfa-1e60-4352-afc9-6659177fa0fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37132,DS-2ccde521-eb1b-4728-a25d-9341a1b69c02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1986530655-172.17.0.16-1596985840244:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45492,DS-cbb693ca-f1eb-44fa-9929-873edc45696a,DISK], DatanodeInfoWithStorage[127.0.0.1:38832,DS-0c750c9f-566c-4878-9e44-bc2b91f3e79b,DISK], DatanodeInfoWithStorage[127.0.0.1:38689,DS-d7cfdc4c-5d1c-468e-aa93-2057cfb13a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:37712,DS-1c263d84-cb5f-4d2e-9cab-a7841238baf2,DISK], DatanodeInfoWithStorage[127.0.0.1:36240,DS-7d578645-4fc1-41be-a713-d88a8b4a7035,DISK], DatanodeInfoWithStorage[127.0.0.1:35694,DS-a23decdf-2b3e-455f-ab8d-d2e789ec20e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45369,DS-e66b9cfa-1e60-4352-afc9-6659177fa0fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37132,DS-2ccde521-eb1b-4728-a25d-9341a1b69c02,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-281094736-172.17.0.16-1596986240024:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33407,DS-ee6c039c-a9fa-43d4-a58b-31efe1cfe018,DISK], DatanodeInfoWithStorage[127.0.0.1:34736,DS-32ed0475-aa0f-4550-89c5-2c0b3ed48a8f,DISK], DatanodeInfoWithStorage[127.0.0.1:43134,DS-d47788e9-b9bd-4d77-996a-fa9b63aae4ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45175,DS-5c9552f2-2616-4401-a8cb-ae3d01d76938,DISK], DatanodeInfoWithStorage[127.0.0.1:40556,DS-b5e2e65d-d81f-418c-9c8d-492d58cbd52d,DISK], DatanodeInfoWithStorage[127.0.0.1:42956,DS-8aedb52d-fec7-43a3-a7d5-4b8e5105c513,DISK], DatanodeInfoWithStorage[127.0.0.1:45434,DS-32a02772-5edc-49bc-b61e-324a6f430773,DISK], DatanodeInfoWithStorage[127.0.0.1:33242,DS-843adb9d-64d6-401f-b151-b652de314079,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-281094736-172.17.0.16-1596986240024:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33407,DS-ee6c039c-a9fa-43d4-a58b-31efe1cfe018,DISK], DatanodeInfoWithStorage[127.0.0.1:34736,DS-32ed0475-aa0f-4550-89c5-2c0b3ed48a8f,DISK], DatanodeInfoWithStorage[127.0.0.1:43134,DS-d47788e9-b9bd-4d77-996a-fa9b63aae4ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45175,DS-5c9552f2-2616-4401-a8cb-ae3d01d76938,DISK], DatanodeInfoWithStorage[127.0.0.1:40556,DS-b5e2e65d-d81f-418c-9c8d-492d58cbd52d,DISK], DatanodeInfoWithStorage[127.0.0.1:42956,DS-8aedb52d-fec7-43a3-a7d5-4b8e5105c513,DISK], DatanodeInfoWithStorage[127.0.0.1:45434,DS-32a02772-5edc-49bc-b61e-324a6f430773,DISK], DatanodeInfoWithStorage[127.0.0.1:33242,DS-843adb9d-64d6-401f-b151-b652de314079,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1915931478-172.17.0.16-1596986255874:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41468,DS-33b50a02-add5-4c9f-ba15-f4b46ac6595c,DISK], DatanodeInfoWithStorage[127.0.0.1:34278,DS-7906830b-09be-4285-bdaf-d6750e9c1247,DISK], DatanodeInfoWithStorage[127.0.0.1:42256,DS-68036571-cf14-42c6-b394-b7ea9ee1f74a,DISK], DatanodeInfoWithStorage[127.0.0.1:40362,DS-ec40ef8b-8206-4865-8fd6-832cbf3149ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38440,DS-1b09ca48-265f-4309-890d-ff2f555634de,DISK], DatanodeInfoWithStorage[127.0.0.1:42473,DS-8f569904-5e3f-4bc1-8bc0-9f6d36aaaad6,DISK], DatanodeInfoWithStorage[127.0.0.1:35780,DS-ec394a8e-8837-477e-b6db-150306370eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:34585,DS-6bf54c2e-47d8-46dd-9524-bf2f1ca6abb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1915931478-172.17.0.16-1596986255874:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41468,DS-33b50a02-add5-4c9f-ba15-f4b46ac6595c,DISK], DatanodeInfoWithStorage[127.0.0.1:34278,DS-7906830b-09be-4285-bdaf-d6750e9c1247,DISK], DatanodeInfoWithStorage[127.0.0.1:42256,DS-68036571-cf14-42c6-b394-b7ea9ee1f74a,DISK], DatanodeInfoWithStorage[127.0.0.1:40362,DS-ec40ef8b-8206-4865-8fd6-832cbf3149ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38440,DS-1b09ca48-265f-4309-890d-ff2f555634de,DISK], DatanodeInfoWithStorage[127.0.0.1:42473,DS-8f569904-5e3f-4bc1-8bc0-9f6d36aaaad6,DISK], DatanodeInfoWithStorage[127.0.0.1:35780,DS-ec394a8e-8837-477e-b6db-150306370eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:34585,DS-6bf54c2e-47d8-46dd-9524-bf2f1ca6abb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-780266627-172.17.0.16-1596986318848:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38718,DS-a6c33316-d66b-4d53-b86a-40de7211f601,DISK], DatanodeInfoWithStorage[127.0.0.1:37749,DS-a9df7e7b-5ee3-455f-bf79-19cbc68a4483,DISK], DatanodeInfoWithStorage[127.0.0.1:44103,DS-f0d306ba-6ff1-4c76-a03e-9265b1e910e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36207,DS-a73f26ab-6a43-4201-9144-684a554f07fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45118,DS-46d82d92-2cc2-452f-9250-ff14c5b961f0,DISK], DatanodeInfoWithStorage[127.0.0.1:41053,DS-9887d4f9-49e9-4b95-ba3f-3506c61b44f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40310,DS-197b6856-6386-461a-8b6c-b02c65ed6029,DISK], DatanodeInfoWithStorage[127.0.0.1:36106,DS-61fbe897-fe44-4b3a-93dc-78123e80a03c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-780266627-172.17.0.16-1596986318848:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38718,DS-a6c33316-d66b-4d53-b86a-40de7211f601,DISK], DatanodeInfoWithStorage[127.0.0.1:37749,DS-a9df7e7b-5ee3-455f-bf79-19cbc68a4483,DISK], DatanodeInfoWithStorage[127.0.0.1:44103,DS-f0d306ba-6ff1-4c76-a03e-9265b1e910e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36207,DS-a73f26ab-6a43-4201-9144-684a554f07fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45118,DS-46d82d92-2cc2-452f-9250-ff14c5b961f0,DISK], DatanodeInfoWithStorage[127.0.0.1:41053,DS-9887d4f9-49e9-4b95-ba3f-3506c61b44f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40310,DS-197b6856-6386-461a-8b6c-b02c65ed6029,DISK], DatanodeInfoWithStorage[127.0.0.1:36106,DS-61fbe897-fe44-4b3a-93dc-78123e80a03c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2017316551-172.17.0.16-1596986570076:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38696,DS-de82affa-d2e4-4015-9c6a-958e23e11bcd,DISK], DatanodeInfoWithStorage[127.0.0.1:43819,DS-ff7e03db-4407-479f-bd90-487c9dc7db39,DISK], DatanodeInfoWithStorage[127.0.0.1:34211,DS-fa1da491-a9c5-423d-ac9b-7abb6b624be4,DISK], DatanodeInfoWithStorage[127.0.0.1:41991,DS-e8422534-824d-4d9c-b75a-05f274c95447,DISK], DatanodeInfoWithStorage[127.0.0.1:44441,DS-c08fce55-fbc1-43da-bb9b-172450b47845,DISK], DatanodeInfoWithStorage[127.0.0.1:39691,DS-5c4f72a3-2a48-4562-89d6-8364024bd82a,DISK], DatanodeInfoWithStorage[127.0.0.1:35176,DS-51f50c8f-e035-4b88-8215-8508686abb23,DISK], DatanodeInfoWithStorage[127.0.0.1:41232,DS-b661554c-627d-465f-b037-aeec64968664,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2017316551-172.17.0.16-1596986570076:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38696,DS-de82affa-d2e4-4015-9c6a-958e23e11bcd,DISK], DatanodeInfoWithStorage[127.0.0.1:43819,DS-ff7e03db-4407-479f-bd90-487c9dc7db39,DISK], DatanodeInfoWithStorage[127.0.0.1:34211,DS-fa1da491-a9c5-423d-ac9b-7abb6b624be4,DISK], DatanodeInfoWithStorage[127.0.0.1:41991,DS-e8422534-824d-4d9c-b75a-05f274c95447,DISK], DatanodeInfoWithStorage[127.0.0.1:44441,DS-c08fce55-fbc1-43da-bb9b-172450b47845,DISK], DatanodeInfoWithStorage[127.0.0.1:39691,DS-5c4f72a3-2a48-4562-89d6-8364024bd82a,DISK], DatanodeInfoWithStorage[127.0.0.1:35176,DS-51f50c8f-e035-4b88-8215-8508686abb23,DISK], DatanodeInfoWithStorage[127.0.0.1:41232,DS-b661554c-627d-465f-b037-aeec64968664,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-954879536-172.17.0.16-1596986822423:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37002,DS-794f204a-6a54-48b1-b8e1-9ec6ae6e8f4e,DISK], DatanodeInfoWithStorage[127.0.0.1:35516,DS-c5982e2e-ff71-4119-b652-1fb43881a887,DISK], DatanodeInfoWithStorage[127.0.0.1:32899,DS-86c1e42b-8cb5-4efb-835c-80cff3a9d02b,DISK], DatanodeInfoWithStorage[127.0.0.1:44117,DS-5a40c392-6d66-4523-ac56-800477926433,DISK], DatanodeInfoWithStorage[127.0.0.1:36256,DS-30256d96-077c-4068-935a-333ef182529a,DISK], DatanodeInfoWithStorage[127.0.0.1:46198,DS-0ecfa98c-59b7-49b0-873f-e234736f0f62,DISK], DatanodeInfoWithStorage[127.0.0.1:33317,DS-20e82a2c-ecf0-4087-8e22-3de7897dd40d,DISK], DatanodeInfoWithStorage[127.0.0.1:39216,DS-39f99ead-9a63-4fe8-befb-96b3ad25ef2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-954879536-172.17.0.16-1596986822423:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37002,DS-794f204a-6a54-48b1-b8e1-9ec6ae6e8f4e,DISK], DatanodeInfoWithStorage[127.0.0.1:35516,DS-c5982e2e-ff71-4119-b652-1fb43881a887,DISK], DatanodeInfoWithStorage[127.0.0.1:32899,DS-86c1e42b-8cb5-4efb-835c-80cff3a9d02b,DISK], DatanodeInfoWithStorage[127.0.0.1:44117,DS-5a40c392-6d66-4523-ac56-800477926433,DISK], DatanodeInfoWithStorage[127.0.0.1:36256,DS-30256d96-077c-4068-935a-333ef182529a,DISK], DatanodeInfoWithStorage[127.0.0.1:46198,DS-0ecfa98c-59b7-49b0-873f-e234736f0f62,DISK], DatanodeInfoWithStorage[127.0.0.1:33317,DS-20e82a2c-ecf0-4087-8e22-3de7897dd40d,DISK], DatanodeInfoWithStorage[127.0.0.1:39216,DS-39f99ead-9a63-4fe8-befb-96b3ad25ef2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-677736948-172.17.0.16-1596986933741:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44141,DS-1a1556fa-ce49-4523-8b44-016d853e254e,DISK], DatanodeInfoWithStorage[127.0.0.1:34581,DS-4dfb3339-1d04-47b0-be7b-c09079bcdfb7,DISK], DatanodeInfoWithStorage[127.0.0.1:43360,DS-91dd26cf-d11b-4348-8d49-57dc9c203bbb,DISK], DatanodeInfoWithStorage[127.0.0.1:44604,DS-da83185c-d255-4ece-b176-1cea892e03d7,DISK], DatanodeInfoWithStorage[127.0.0.1:35283,DS-510a7e65-710a-478c-8d98-e59b9d2cd55c,DISK], DatanodeInfoWithStorage[127.0.0.1:37832,DS-c151856c-0e02-4404-afff-d2d359bb0f40,DISK], DatanodeInfoWithStorage[127.0.0.1:44185,DS-d0e06c9c-0fa9-4eff-b29b-35b122c97644,DISK], DatanodeInfoWithStorage[127.0.0.1:42837,DS-e84e7802-5dd1-463b-b46b-ecd2aaf2fa0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-677736948-172.17.0.16-1596986933741:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44141,DS-1a1556fa-ce49-4523-8b44-016d853e254e,DISK], DatanodeInfoWithStorage[127.0.0.1:34581,DS-4dfb3339-1d04-47b0-be7b-c09079bcdfb7,DISK], DatanodeInfoWithStorage[127.0.0.1:43360,DS-91dd26cf-d11b-4348-8d49-57dc9c203bbb,DISK], DatanodeInfoWithStorage[127.0.0.1:44604,DS-da83185c-d255-4ece-b176-1cea892e03d7,DISK], DatanodeInfoWithStorage[127.0.0.1:35283,DS-510a7e65-710a-478c-8d98-e59b9d2cd55c,DISK], DatanodeInfoWithStorage[127.0.0.1:37832,DS-c151856c-0e02-4404-afff-d2d359bb0f40,DISK], DatanodeInfoWithStorage[127.0.0.1:44185,DS-d0e06c9c-0fa9-4eff-b29b-35b122c97644,DISK], DatanodeInfoWithStorage[127.0.0.1:42837,DS-e84e7802-5dd1-463b-b46b-ecd2aaf2fa0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-199709883-172.17.0.16-1596987042825:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37076,DS-d26cbd39-e817-4251-a7bd-76df62fb1dd0,DISK], DatanodeInfoWithStorage[127.0.0.1:46059,DS-3835d260-dd5d-4655-bfdb-fcf14c14caa7,DISK], DatanodeInfoWithStorage[127.0.0.1:40216,DS-dc9f080a-97f7-45f8-8aad-d7c9d2a120fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42032,DS-75e3ec7d-16b5-4bec-b178-5fa71066734f,DISK], DatanodeInfoWithStorage[127.0.0.1:35117,DS-6046dcb1-d67a-4964-8aec-c69a75bf9fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:39079,DS-2aab0ecc-dc0f-46a7-bec4-f1a94f62f935,DISK], DatanodeInfoWithStorage[127.0.0.1:44936,DS-4bb03b9c-a766-44fb-ad62-18afacb8c4b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34202,DS-ebbe2eda-7c89-439b-a9ca-d75af5ecf85b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-199709883-172.17.0.16-1596987042825:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37076,DS-d26cbd39-e817-4251-a7bd-76df62fb1dd0,DISK], DatanodeInfoWithStorage[127.0.0.1:46059,DS-3835d260-dd5d-4655-bfdb-fcf14c14caa7,DISK], DatanodeInfoWithStorage[127.0.0.1:40216,DS-dc9f080a-97f7-45f8-8aad-d7c9d2a120fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42032,DS-75e3ec7d-16b5-4bec-b178-5fa71066734f,DISK], DatanodeInfoWithStorage[127.0.0.1:35117,DS-6046dcb1-d67a-4964-8aec-c69a75bf9fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:39079,DS-2aab0ecc-dc0f-46a7-bec4-f1a94f62f935,DISK], DatanodeInfoWithStorage[127.0.0.1:44936,DS-4bb03b9c-a766-44fb-ad62-18afacb8c4b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34202,DS-ebbe2eda-7c89-439b-a9ca-d75af5ecf85b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-465142375-172.17.0.16-1596987058505:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41508,DS-94973daf-4bdd-43bb-8609-71c124878092,DISK], DatanodeInfoWithStorage[127.0.0.1:38276,DS-61d91e9a-5967-41de-83c3-41ca0b84bbf7,DISK], DatanodeInfoWithStorage[127.0.0.1:43299,DS-a3a4f63f-5527-40ca-96b9-de1ef88e9672,DISK], DatanodeInfoWithStorage[127.0.0.1:37740,DS-d35996c9-ca9f-42eb-8943-c3046f7cbdd0,DISK], DatanodeInfoWithStorage[127.0.0.1:37502,DS-5f899ce6-a57c-4ce7-9802-3196b2bc5b95,DISK], DatanodeInfoWithStorage[127.0.0.1:40086,DS-a6c19888-ccf9-4ff8-a25e-ad1d386cd9e5,DISK], DatanodeInfoWithStorage[127.0.0.1:37507,DS-ef53fba4-4896-47fe-9723-886b8d733f06,DISK], DatanodeInfoWithStorage[127.0.0.1:40159,DS-ae2758af-1ac6-4f05-833f-da0a51f0ffd7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-465142375-172.17.0.16-1596987058505:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41508,DS-94973daf-4bdd-43bb-8609-71c124878092,DISK], DatanodeInfoWithStorage[127.0.0.1:38276,DS-61d91e9a-5967-41de-83c3-41ca0b84bbf7,DISK], DatanodeInfoWithStorage[127.0.0.1:43299,DS-a3a4f63f-5527-40ca-96b9-de1ef88e9672,DISK], DatanodeInfoWithStorage[127.0.0.1:37740,DS-d35996c9-ca9f-42eb-8943-c3046f7cbdd0,DISK], DatanodeInfoWithStorage[127.0.0.1:37502,DS-5f899ce6-a57c-4ce7-9802-3196b2bc5b95,DISK], DatanodeInfoWithStorage[127.0.0.1:40086,DS-a6c19888-ccf9-4ff8-a25e-ad1d386cd9e5,DISK], DatanodeInfoWithStorage[127.0.0.1:37507,DS-ef53fba4-4896-47fe-9723-886b8d733f06,DISK], DatanodeInfoWithStorage[127.0.0.1:40159,DS-ae2758af-1ac6-4f05-833f-da0a51f0ffd7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1036361570-172.17.0.16-1596987324342:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45185,DS-6c9b990d-1b1b-4803-9ccd-afed9129144e,DISK], DatanodeInfoWithStorage[127.0.0.1:35112,DS-25b1363e-bfb7-4e8f-842b-7d198e891e92,DISK], DatanodeInfoWithStorage[127.0.0.1:33206,DS-1c035d7f-ab56-423e-ae6a-09569510f4d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39171,DS-9b728a78-4ba9-484b-b14a-502bb6478c8b,DISK], DatanodeInfoWithStorage[127.0.0.1:34398,DS-5b1cdb86-25e2-4b49-b288-90ec79d63b50,DISK], DatanodeInfoWithStorage[127.0.0.1:34407,DS-a1b0275f-b768-4d76-af9f-3c136630cb6d,DISK], DatanodeInfoWithStorage[127.0.0.1:44610,DS-9a5f6e79-ec93-42cb-8831-fb0c7f4f8caa,DISK], DatanodeInfoWithStorage[127.0.0.1:46600,DS-f2751d4a-7e60-4fbd-ae21-23ed1de0efaf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1036361570-172.17.0.16-1596987324342:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45185,DS-6c9b990d-1b1b-4803-9ccd-afed9129144e,DISK], DatanodeInfoWithStorage[127.0.0.1:35112,DS-25b1363e-bfb7-4e8f-842b-7d198e891e92,DISK], DatanodeInfoWithStorage[127.0.0.1:33206,DS-1c035d7f-ab56-423e-ae6a-09569510f4d1,DISK], DatanodeInfoWithStorage[127.0.0.1:39171,DS-9b728a78-4ba9-484b-b14a-502bb6478c8b,DISK], DatanodeInfoWithStorage[127.0.0.1:34398,DS-5b1cdb86-25e2-4b49-b288-90ec79d63b50,DISK], DatanodeInfoWithStorage[127.0.0.1:34407,DS-a1b0275f-b768-4d76-af9f-3c136630cb6d,DISK], DatanodeInfoWithStorage[127.0.0.1:44610,DS-9a5f6e79-ec93-42cb-8831-fb0c7f4f8caa,DISK], DatanodeInfoWithStorage[127.0.0.1:46600,DS-f2751d4a-7e60-4fbd-ae21-23ed1de0efaf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1717343493-172.17.0.16-1596987371462:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41123,DS-02418308-cafd-4fe1-8e51-411d46daed1a,DISK], DatanodeInfoWithStorage[127.0.0.1:42675,DS-d6342a55-253f-44e4-bd02-063972530f96,DISK], DatanodeInfoWithStorage[127.0.0.1:33564,DS-54568700-b0cb-428c-84e4-e4bc2404f1b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42010,DS-ab869d37-7cdb-44ec-a85a-0369ea3f8679,DISK], DatanodeInfoWithStorage[127.0.0.1:43200,DS-3a10c1ff-a231-4480-8cdb-bfae5bf69e59,DISK], DatanodeInfoWithStorage[127.0.0.1:38925,DS-130c76e2-63cc-43ea-a30f-be41c727c0bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33552,DS-d1ac404c-9eb9-4559-8373-4fd1bcf547e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37967,DS-ae77d4c0-ecfa-4190-9b75-e12f8be6aeee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1717343493-172.17.0.16-1596987371462:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41123,DS-02418308-cafd-4fe1-8e51-411d46daed1a,DISK], DatanodeInfoWithStorage[127.0.0.1:42675,DS-d6342a55-253f-44e4-bd02-063972530f96,DISK], DatanodeInfoWithStorage[127.0.0.1:33564,DS-54568700-b0cb-428c-84e4-e4bc2404f1b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42010,DS-ab869d37-7cdb-44ec-a85a-0369ea3f8679,DISK], DatanodeInfoWithStorage[127.0.0.1:43200,DS-3a10c1ff-a231-4480-8cdb-bfae5bf69e59,DISK], DatanodeInfoWithStorage[127.0.0.1:38925,DS-130c76e2-63cc-43ea-a30f-be41c727c0bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33552,DS-d1ac404c-9eb9-4559-8373-4fd1bcf547e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37967,DS-ae77d4c0-ecfa-4190-9b75-e12f8be6aeee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1124670612-172.17.0.16-1596987466180:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33255,DS-5903e30b-9819-4b63-ae39-f23569d06b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:45268,DS-4cbfe0ca-77c9-4b93-b2ce-efc9e0076452,DISK], DatanodeInfoWithStorage[127.0.0.1:35555,DS-c614e1ba-1909-4de1-b651-c998d891a3cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45673,DS-34dca2c3-8c09-4cf9-ba89-dae112b1a150,DISK], DatanodeInfoWithStorage[127.0.0.1:45609,DS-8f1b9d5f-ba82-4f9f-8a34-8ff299b5cd4e,DISK], DatanodeInfoWithStorage[127.0.0.1:45210,DS-cfea0b3d-16e0-4982-a2fc-eb5cb5132f6a,DISK], DatanodeInfoWithStorage[127.0.0.1:36340,DS-2ad3d079-2885-4c75-acc9-afc0bc4ef786,DISK], DatanodeInfoWithStorage[127.0.0.1:39043,DS-b48c18a9-e40e-4fc3-8660-52e7b7f53ca7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1124670612-172.17.0.16-1596987466180:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33255,DS-5903e30b-9819-4b63-ae39-f23569d06b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:45268,DS-4cbfe0ca-77c9-4b93-b2ce-efc9e0076452,DISK], DatanodeInfoWithStorage[127.0.0.1:35555,DS-c614e1ba-1909-4de1-b651-c998d891a3cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45673,DS-34dca2c3-8c09-4cf9-ba89-dae112b1a150,DISK], DatanodeInfoWithStorage[127.0.0.1:45609,DS-8f1b9d5f-ba82-4f9f-8a34-8ff299b5cd4e,DISK], DatanodeInfoWithStorage[127.0.0.1:45210,DS-cfea0b3d-16e0-4982-a2fc-eb5cb5132f6a,DISK], DatanodeInfoWithStorage[127.0.0.1:36340,DS-2ad3d079-2885-4c75-acc9-afc0bc4ef786,DISK], DatanodeInfoWithStorage[127.0.0.1:39043,DS-b48c18a9-e40e-4fc3-8660-52e7b7f53ca7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2015373504-172.17.0.16-1596987591680:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45802,DS-569d9747-86c6-4ee4-9463-48fe81961301,DISK], DatanodeInfoWithStorage[127.0.0.1:45247,DS-d0e8304a-52eb-4605-9846-aa687cdf1fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:42664,DS-d088dd69-c8b7-4260-9498-3e99bf8abfb6,DISK], DatanodeInfoWithStorage[127.0.0.1:44451,DS-55e5215e-4c43-4913-97fa-182150796e11,DISK], DatanodeInfoWithStorage[127.0.0.1:33472,DS-6bae81bc-fc32-47a8-b9d7-e6939798179b,DISK], DatanodeInfoWithStorage[127.0.0.1:39872,DS-e3c36342-fecf-47e6-b678-10e8fedb8f56,DISK], DatanodeInfoWithStorage[127.0.0.1:33701,DS-cc95260f-d790-4649-970e-052e0ce598c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42432,DS-bdfbfff6-378e-4614-925c-c765038dcafa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2015373504-172.17.0.16-1596987591680:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45802,DS-569d9747-86c6-4ee4-9463-48fe81961301,DISK], DatanodeInfoWithStorage[127.0.0.1:45247,DS-d0e8304a-52eb-4605-9846-aa687cdf1fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:42664,DS-d088dd69-c8b7-4260-9498-3e99bf8abfb6,DISK], DatanodeInfoWithStorage[127.0.0.1:44451,DS-55e5215e-4c43-4913-97fa-182150796e11,DISK], DatanodeInfoWithStorage[127.0.0.1:33472,DS-6bae81bc-fc32-47a8-b9d7-e6939798179b,DISK], DatanodeInfoWithStorage[127.0.0.1:39872,DS-e3c36342-fecf-47e6-b678-10e8fedb8f56,DISK], DatanodeInfoWithStorage[127.0.0.1:33701,DS-cc95260f-d790-4649-970e-052e0ce598c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42432,DS-bdfbfff6-378e-4614-925c-c765038dcafa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-641937916-172.17.0.16-1596987731581:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38059,DS-d01e3461-856b-40ae-bb66-c158928b3e90,DISK], DatanodeInfoWithStorage[127.0.0.1:42480,DS-5cb21eb1-1f1a-4830-a6eb-4715702b66a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40106,DS-abbed51e-c095-4a81-aab8-c5d523784b5b,DISK], DatanodeInfoWithStorage[127.0.0.1:33077,DS-78c64f82-e45a-4d45-8916-dc79f59ed55c,DISK], DatanodeInfoWithStorage[127.0.0.1:42247,DS-ee3a74db-b990-46e3-8cee-75d76f0845cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34765,DS-82130b09-3a0d-41d1-9c3f-7045a2b1b868,DISK], DatanodeInfoWithStorage[127.0.0.1:41849,DS-ddf0fc91-98d4-401e-8e44-c36c528e180d,DISK], DatanodeInfoWithStorage[127.0.0.1:46057,DS-0f1c8dd0-1cf5-45c7-864d-67685ca0a0bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-641937916-172.17.0.16-1596987731581:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38059,DS-d01e3461-856b-40ae-bb66-c158928b3e90,DISK], DatanodeInfoWithStorage[127.0.0.1:42480,DS-5cb21eb1-1f1a-4830-a6eb-4715702b66a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40106,DS-abbed51e-c095-4a81-aab8-c5d523784b5b,DISK], DatanodeInfoWithStorage[127.0.0.1:33077,DS-78c64f82-e45a-4d45-8916-dc79f59ed55c,DISK], DatanodeInfoWithStorage[127.0.0.1:42247,DS-ee3a74db-b990-46e3-8cee-75d76f0845cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34765,DS-82130b09-3a0d-41d1-9c3f-7045a2b1b868,DISK], DatanodeInfoWithStorage[127.0.0.1:41849,DS-ddf0fc91-98d4-401e-8e44-c36c528e180d,DISK], DatanodeInfoWithStorage[127.0.0.1:46057,DS-0f1c8dd0-1cf5-45c7-864d-67685ca0a0bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 3163
