reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1377108723-172.17.0.16-1596932205927:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44183,DS-0dc89f93-edc5-4e61-b8b6-2fd2038bb3b7,DISK], DatanodeInfoWithStorage[127.0.0.1:42033,DS-f743415c-b1d9-4b42-9011-7f786226a33c,DISK], DatanodeInfoWithStorage[127.0.0.1:32796,DS-d8758e14-0dac-408d-98c9-99410d3bb200,DISK], DatanodeInfoWithStorage[127.0.0.1:43576,DS-07500f6f-6bfd-4326-acb7-1d638bbf31ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40097,DS-57217f6f-76c6-4926-bef2-5eb92dca0d51,DISK], DatanodeInfoWithStorage[127.0.0.1:46229,DS-aa8db346-c362-401c-8434-792508dcd3e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43429,DS-c211d50e-3785-463e-9404-d4fb88d9bae4,DISK], DatanodeInfoWithStorage[127.0.0.1:36015,DS-29bdbe95-7b54-461b-a8d5-e92986b80037,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1377108723-172.17.0.16-1596932205927:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44183,DS-0dc89f93-edc5-4e61-b8b6-2fd2038bb3b7,DISK], DatanodeInfoWithStorage[127.0.0.1:42033,DS-f743415c-b1d9-4b42-9011-7f786226a33c,DISK], DatanodeInfoWithStorage[127.0.0.1:32796,DS-d8758e14-0dac-408d-98c9-99410d3bb200,DISK], DatanodeInfoWithStorage[127.0.0.1:43576,DS-07500f6f-6bfd-4326-acb7-1d638bbf31ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40097,DS-57217f6f-76c6-4926-bef2-5eb92dca0d51,DISK], DatanodeInfoWithStorage[127.0.0.1:46229,DS-aa8db346-c362-401c-8434-792508dcd3e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43429,DS-c211d50e-3785-463e-9404-d4fb88d9bae4,DISK], DatanodeInfoWithStorage[127.0.0.1:36015,DS-29bdbe95-7b54-461b-a8d5-e92986b80037,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-304490588-172.17.0.16-1596932605560:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45424,DS-162f2308-752a-4d12-90e9-7a600707dad3,DISK], DatanodeInfoWithStorage[127.0.0.1:46697,DS-25e7fd29-47c2-4b0d-bd5c-f8f7abb57659,DISK], DatanodeInfoWithStorage[127.0.0.1:36577,DS-69627404-9833-4347-822f-cdbf145f4bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:34157,DS-90309fc3-2afd-4291-9934-51a2eba63386,DISK], DatanodeInfoWithStorage[127.0.0.1:46404,DS-242ca526-dfb3-45d1-8f7b-489fddd0c296,DISK], DatanodeInfoWithStorage[127.0.0.1:33416,DS-a23cc742-cd58-4f37-9e49-faa02a4413e2,DISK], DatanodeInfoWithStorage[127.0.0.1:33396,DS-dcb9e64f-35f1-4db8-8cb5-49c29fea4ec2,DISK], DatanodeInfoWithStorage[127.0.0.1:44311,DS-25dd7701-9417-42a9-a00a-801a8fa223cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-304490588-172.17.0.16-1596932605560:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45424,DS-162f2308-752a-4d12-90e9-7a600707dad3,DISK], DatanodeInfoWithStorage[127.0.0.1:46697,DS-25e7fd29-47c2-4b0d-bd5c-f8f7abb57659,DISK], DatanodeInfoWithStorage[127.0.0.1:36577,DS-69627404-9833-4347-822f-cdbf145f4bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:34157,DS-90309fc3-2afd-4291-9934-51a2eba63386,DISK], DatanodeInfoWithStorage[127.0.0.1:46404,DS-242ca526-dfb3-45d1-8f7b-489fddd0c296,DISK], DatanodeInfoWithStorage[127.0.0.1:33416,DS-a23cc742-cd58-4f37-9e49-faa02a4413e2,DISK], DatanodeInfoWithStorage[127.0.0.1:33396,DS-dcb9e64f-35f1-4db8-8cb5-49c29fea4ec2,DISK], DatanodeInfoWithStorage[127.0.0.1:44311,DS-25dd7701-9417-42a9-a00a-801a8fa223cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2124221363-172.17.0.16-1596932781826:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38694,DS-f8fb8de8-7fbb-488e-be23-b4d5b1421e9b,DISK], DatanodeInfoWithStorage[127.0.0.1:39388,DS-c3350c73-b59f-4997-a956-b7f9b8cb4af3,DISK], DatanodeInfoWithStorage[127.0.0.1:35324,DS-bfa5d60e-035e-4adc-8bbb-1f5f174412e2,DISK], DatanodeInfoWithStorage[127.0.0.1:32876,DS-1f2649b3-838a-41a0-84f3-29d9cb087964,DISK], DatanodeInfoWithStorage[127.0.0.1:38516,DS-2da0975f-7ad2-4462-8687-970e5b541316,DISK], DatanodeInfoWithStorage[127.0.0.1:43920,DS-9ff70667-bed1-41d0-baf0-cb614a65b0bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41516,DS-266d365f-31c9-4f31-951b-ab78768f301c,DISK], DatanodeInfoWithStorage[127.0.0.1:43217,DS-f9f261fd-65d2-467b-a5a4-36532548c78f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2124221363-172.17.0.16-1596932781826:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38694,DS-f8fb8de8-7fbb-488e-be23-b4d5b1421e9b,DISK], DatanodeInfoWithStorage[127.0.0.1:39388,DS-c3350c73-b59f-4997-a956-b7f9b8cb4af3,DISK], DatanodeInfoWithStorage[127.0.0.1:35324,DS-bfa5d60e-035e-4adc-8bbb-1f5f174412e2,DISK], DatanodeInfoWithStorage[127.0.0.1:32876,DS-1f2649b3-838a-41a0-84f3-29d9cb087964,DISK], DatanodeInfoWithStorage[127.0.0.1:38516,DS-2da0975f-7ad2-4462-8687-970e5b541316,DISK], DatanodeInfoWithStorage[127.0.0.1:43920,DS-9ff70667-bed1-41d0-baf0-cb614a65b0bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41516,DS-266d365f-31c9-4f31-951b-ab78768f301c,DISK], DatanodeInfoWithStorage[127.0.0.1:43217,DS-f9f261fd-65d2-467b-a5a4-36532548c78f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2109515030-172.17.0.16-1596932985498:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36760,DS-4dce7239-56ca-445b-8beb-4a92825f13e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44802,DS-26b63f9e-7d18-48a3-a5a7-5a493ec570d2,DISK], DatanodeInfoWithStorage[127.0.0.1:33278,DS-12b76d47-d80c-4044-bf28-6215ccfd4cd3,DISK], DatanodeInfoWithStorage[127.0.0.1:39149,DS-a753fd12-ee24-4ff6-9936-44dc46dcce13,DISK], DatanodeInfoWithStorage[127.0.0.1:41177,DS-2ded97a3-b1ce-4ce9-9224-c9fdfe030862,DISK], DatanodeInfoWithStorage[127.0.0.1:44876,DS-97c01cc8-72ce-4b45-8342-b540a6abf02d,DISK], DatanodeInfoWithStorage[127.0.0.1:44902,DS-b91729d8-ad3a-4fb0-b7ae-5328786bad96,DISK], DatanodeInfoWithStorage[127.0.0.1:43728,DS-38a86157-b02f-400a-935b-4c3068c76228,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2109515030-172.17.0.16-1596932985498:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36760,DS-4dce7239-56ca-445b-8beb-4a92825f13e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44802,DS-26b63f9e-7d18-48a3-a5a7-5a493ec570d2,DISK], DatanodeInfoWithStorage[127.0.0.1:33278,DS-12b76d47-d80c-4044-bf28-6215ccfd4cd3,DISK], DatanodeInfoWithStorage[127.0.0.1:39149,DS-a753fd12-ee24-4ff6-9936-44dc46dcce13,DISK], DatanodeInfoWithStorage[127.0.0.1:41177,DS-2ded97a3-b1ce-4ce9-9224-c9fdfe030862,DISK], DatanodeInfoWithStorage[127.0.0.1:44876,DS-97c01cc8-72ce-4b45-8342-b540a6abf02d,DISK], DatanodeInfoWithStorage[127.0.0.1:44902,DS-b91729d8-ad3a-4fb0-b7ae-5328786bad96,DISK], DatanodeInfoWithStorage[127.0.0.1:43728,DS-38a86157-b02f-400a-935b-4c3068c76228,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-965436293-172.17.0.16-1596933957627:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41783,DS-e677d4d8-ce18-4a0a-b990-f8f84c343361,DISK], DatanodeInfoWithStorage[127.0.0.1:38825,DS-6d5ce5d2-651e-4a46-ad96-eb112804cc18,DISK], DatanodeInfoWithStorage[127.0.0.1:37195,DS-6cad1f77-66db-4c59-9034-3d8692a8a549,DISK], DatanodeInfoWithStorage[127.0.0.1:41567,DS-46a43042-6501-42c7-96be-c7b313c111bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36021,DS-a9006468-84a1-4f86-968b-88b0314d5b72,DISK], DatanodeInfoWithStorage[127.0.0.1:40422,DS-5ddff4a1-b24d-4c9e-b625-c590b66a1f14,DISK], DatanodeInfoWithStorage[127.0.0.1:40137,DS-53427e64-786a-4856-b913-e42b513f1c85,DISK], DatanodeInfoWithStorage[127.0.0.1:45327,DS-82804907-5e2b-4e74-ba4f-ec35f81a8bc3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-965436293-172.17.0.16-1596933957627:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41783,DS-e677d4d8-ce18-4a0a-b990-f8f84c343361,DISK], DatanodeInfoWithStorage[127.0.0.1:38825,DS-6d5ce5d2-651e-4a46-ad96-eb112804cc18,DISK], DatanodeInfoWithStorage[127.0.0.1:37195,DS-6cad1f77-66db-4c59-9034-3d8692a8a549,DISK], DatanodeInfoWithStorage[127.0.0.1:41567,DS-46a43042-6501-42c7-96be-c7b313c111bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36021,DS-a9006468-84a1-4f86-968b-88b0314d5b72,DISK], DatanodeInfoWithStorage[127.0.0.1:40422,DS-5ddff4a1-b24d-4c9e-b625-c590b66a1f14,DISK], DatanodeInfoWithStorage[127.0.0.1:40137,DS-53427e64-786a-4856-b913-e42b513f1c85,DISK], DatanodeInfoWithStorage[127.0.0.1:45327,DS-82804907-5e2b-4e74-ba4f-ec35f81a8bc3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2108173973-172.17.0.16-1596934338901:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37523,DS-3e4c8fb5-e4bf-40ab-ba3a-3c9a81db5b57,DISK], DatanodeInfoWithStorage[127.0.0.1:38050,DS-f5a0ff25-01cf-462e-bdc2-853a2bff9a90,DISK], DatanodeInfoWithStorage[127.0.0.1:39427,DS-8f8fa104-18a9-4aa6-a940-4dc86c3f1d1a,DISK], DatanodeInfoWithStorage[127.0.0.1:41003,DS-8538521c-7806-4a07-949d-0c257da52993,DISK], DatanodeInfoWithStorage[127.0.0.1:34939,DS-c57d1df5-bd2c-4df9-bca6-4201887916c4,DISK], DatanodeInfoWithStorage[127.0.0.1:34612,DS-50def75b-b1ab-4b25-87ac-7a63c3bae251,DISK], DatanodeInfoWithStorage[127.0.0.1:39680,DS-9eca361b-ca9e-486e-a608-1c4464e9fe5c,DISK], DatanodeInfoWithStorage[127.0.0.1:37502,DS-348657cb-2864-4401-b819-039ddad93494,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2108173973-172.17.0.16-1596934338901:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37523,DS-3e4c8fb5-e4bf-40ab-ba3a-3c9a81db5b57,DISK], DatanodeInfoWithStorage[127.0.0.1:38050,DS-f5a0ff25-01cf-462e-bdc2-853a2bff9a90,DISK], DatanodeInfoWithStorage[127.0.0.1:39427,DS-8f8fa104-18a9-4aa6-a940-4dc86c3f1d1a,DISK], DatanodeInfoWithStorage[127.0.0.1:41003,DS-8538521c-7806-4a07-949d-0c257da52993,DISK], DatanodeInfoWithStorage[127.0.0.1:34939,DS-c57d1df5-bd2c-4df9-bca6-4201887916c4,DISK], DatanodeInfoWithStorage[127.0.0.1:34612,DS-50def75b-b1ab-4b25-87ac-7a63c3bae251,DISK], DatanodeInfoWithStorage[127.0.0.1:39680,DS-9eca361b-ca9e-486e-a608-1c4464e9fe5c,DISK], DatanodeInfoWithStorage[127.0.0.1:37502,DS-348657cb-2864-4401-b819-039ddad93494,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-506403676-172.17.0.16-1596934717308:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38305,DS-9d49243a-8cb6-44cb-9ee2-9aaa1236f574,DISK], DatanodeInfoWithStorage[127.0.0.1:40528,DS-60ca852c-37b7-43a8-bdc1-4298d240e125,DISK], DatanodeInfoWithStorage[127.0.0.1:43828,DS-07c9898e-6e04-4d4d-9fb2-a7b94c48dc56,DISK], DatanodeInfoWithStorage[127.0.0.1:46567,DS-eef944b3-3cb4-49da-b821-b219bd88d54d,DISK], DatanodeInfoWithStorage[127.0.0.1:40818,DS-a3f18a35-6ce2-42af-ad6f-627baf224f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:35354,DS-508a36c7-5616-4635-a890-5d7c86c4f915,DISK], DatanodeInfoWithStorage[127.0.0.1:45481,DS-ad639473-2a16-408c-b912-97a6d67ba35c,DISK], DatanodeInfoWithStorage[127.0.0.1:45575,DS-7a3dc357-e080-408f-94aa-44105a7c4404,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-506403676-172.17.0.16-1596934717308:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38305,DS-9d49243a-8cb6-44cb-9ee2-9aaa1236f574,DISK], DatanodeInfoWithStorage[127.0.0.1:40528,DS-60ca852c-37b7-43a8-bdc1-4298d240e125,DISK], DatanodeInfoWithStorage[127.0.0.1:43828,DS-07c9898e-6e04-4d4d-9fb2-a7b94c48dc56,DISK], DatanodeInfoWithStorage[127.0.0.1:46567,DS-eef944b3-3cb4-49da-b821-b219bd88d54d,DISK], DatanodeInfoWithStorage[127.0.0.1:40818,DS-a3f18a35-6ce2-42af-ad6f-627baf224f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:35354,DS-508a36c7-5616-4635-a890-5d7c86c4f915,DISK], DatanodeInfoWithStorage[127.0.0.1:45481,DS-ad639473-2a16-408c-b912-97a6d67ba35c,DISK], DatanodeInfoWithStorage[127.0.0.1:45575,DS-7a3dc357-e080-408f-94aa-44105a7c4404,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-984075639-172.17.0.16-1596934756679:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34421,DS-440edf5c-22c2-485d-b321-d97ab0c61d09,DISK], DatanodeInfoWithStorage[127.0.0.1:40180,DS-3d08f391-2bd7-4233-a998-a9fa594e29e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43900,DS-ff81454c-936b-4382-911e-1908e317bee6,DISK], DatanodeInfoWithStorage[127.0.0.1:34531,DS-286e103c-bbfd-4bc6-9945-ce0f7ef26854,DISK], DatanodeInfoWithStorage[127.0.0.1:41307,DS-fe886ae9-666a-4b12-9f18-3d80f32a304d,DISK], DatanodeInfoWithStorage[127.0.0.1:40035,DS-f60cd5d7-9a0f-4e4a-847f-fa547c8e1106,DISK], DatanodeInfoWithStorage[127.0.0.1:46472,DS-f156f49f-b19c-4a20-9fc0-6d63fa803781,DISK], DatanodeInfoWithStorage[127.0.0.1:38184,DS-d8c4bdd1-1e12-4b44-b786-c682afd6890b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-984075639-172.17.0.16-1596934756679:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34421,DS-440edf5c-22c2-485d-b321-d97ab0c61d09,DISK], DatanodeInfoWithStorage[127.0.0.1:40180,DS-3d08f391-2bd7-4233-a998-a9fa594e29e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43900,DS-ff81454c-936b-4382-911e-1908e317bee6,DISK], DatanodeInfoWithStorage[127.0.0.1:34531,DS-286e103c-bbfd-4bc6-9945-ce0f7ef26854,DISK], DatanodeInfoWithStorage[127.0.0.1:41307,DS-fe886ae9-666a-4b12-9f18-3d80f32a304d,DISK], DatanodeInfoWithStorage[127.0.0.1:40035,DS-f60cd5d7-9a0f-4e4a-847f-fa547c8e1106,DISK], DatanodeInfoWithStorage[127.0.0.1:46472,DS-f156f49f-b19c-4a20-9fc0-6d63fa803781,DISK], DatanodeInfoWithStorage[127.0.0.1:38184,DS-d8c4bdd1-1e12-4b44-b786-c682afd6890b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1746861571-172.17.0.16-1596935265287:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44886,DS-cd8410bd-c4ce-4f97-a721-fbaf9756c59b,DISK], DatanodeInfoWithStorage[127.0.0.1:37971,DS-df7e92b1-5917-4f9d-a3e5-24007d9a3638,DISK], DatanodeInfoWithStorage[127.0.0.1:38009,DS-f535a82e-4190-43d9-a607-81484043c33f,DISK], DatanodeInfoWithStorage[127.0.0.1:40470,DS-75b69076-9cab-4ef1-aa93-2f29e0e9849d,DISK], DatanodeInfoWithStorage[127.0.0.1:39450,DS-14fba782-213d-4e53-ac7b-17a21b4df0b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41887,DS-e8c5cc1f-a60e-4231-8887-a30fa13246bb,DISK], DatanodeInfoWithStorage[127.0.0.1:32949,DS-e8b69499-f2b1-4cfc-9c24-75cc8b26d2ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34095,DS-0766eab6-f297-4e78-9ad3-e4c2e27cc03b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1746861571-172.17.0.16-1596935265287:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44886,DS-cd8410bd-c4ce-4f97-a721-fbaf9756c59b,DISK], DatanodeInfoWithStorage[127.0.0.1:37971,DS-df7e92b1-5917-4f9d-a3e5-24007d9a3638,DISK], DatanodeInfoWithStorage[127.0.0.1:38009,DS-f535a82e-4190-43d9-a607-81484043c33f,DISK], DatanodeInfoWithStorage[127.0.0.1:40470,DS-75b69076-9cab-4ef1-aa93-2f29e0e9849d,DISK], DatanodeInfoWithStorage[127.0.0.1:39450,DS-14fba782-213d-4e53-ac7b-17a21b4df0b6,DISK], DatanodeInfoWithStorage[127.0.0.1:41887,DS-e8c5cc1f-a60e-4231-8887-a30fa13246bb,DISK], DatanodeInfoWithStorage[127.0.0.1:32949,DS-e8b69499-f2b1-4cfc-9c24-75cc8b26d2ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34095,DS-0766eab6-f297-4e78-9ad3-e4c2e27cc03b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1916739158-172.17.0.16-1596935437692:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46280,DS-7b62a189-36bd-42df-b09d-97b17225b82d,DISK], DatanodeInfoWithStorage[127.0.0.1:36886,DS-3f2c72b0-5f45-4360-b02a-a5f9b2d0091a,DISK], DatanodeInfoWithStorage[127.0.0.1:41168,DS-a3aeea01-da81-4499-bd56-a60986c8e40a,DISK], DatanodeInfoWithStorage[127.0.0.1:43723,DS-9d900f8c-678d-479c-ace3-0993dd554731,DISK], DatanodeInfoWithStorage[127.0.0.1:46135,DS-45d6c5ca-f783-4216-a3d5-0a143e7ade2f,DISK], DatanodeInfoWithStorage[127.0.0.1:40112,DS-b51232a7-893e-4e3b-8c9d-2522e0a3fbf9,DISK], DatanodeInfoWithStorage[127.0.0.1:44862,DS-bb48e3d1-1f25-48db-9346-a64423fc3d78,DISK], DatanodeInfoWithStorage[127.0.0.1:43428,DS-a0ce023a-5e1f-4e8d-b912-3894bbe6b75a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1916739158-172.17.0.16-1596935437692:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46280,DS-7b62a189-36bd-42df-b09d-97b17225b82d,DISK], DatanodeInfoWithStorage[127.0.0.1:36886,DS-3f2c72b0-5f45-4360-b02a-a5f9b2d0091a,DISK], DatanodeInfoWithStorage[127.0.0.1:41168,DS-a3aeea01-da81-4499-bd56-a60986c8e40a,DISK], DatanodeInfoWithStorage[127.0.0.1:43723,DS-9d900f8c-678d-479c-ace3-0993dd554731,DISK], DatanodeInfoWithStorage[127.0.0.1:46135,DS-45d6c5ca-f783-4216-a3d5-0a143e7ade2f,DISK], DatanodeInfoWithStorage[127.0.0.1:40112,DS-b51232a7-893e-4e3b-8c9d-2522e0a3fbf9,DISK], DatanodeInfoWithStorage[127.0.0.1:44862,DS-bb48e3d1-1f25-48db-9346-a64423fc3d78,DISK], DatanodeInfoWithStorage[127.0.0.1:43428,DS-a0ce023a-5e1f-4e8d-b912-3894bbe6b75a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1270085636-172.17.0.16-1596935617979:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42493,DS-37706665-5369-40ab-b044-3d5465a18d3a,DISK], DatanodeInfoWithStorage[127.0.0.1:46170,DS-081303a9-9f14-4179-aad6-0b1ee2e50f61,DISK], DatanodeInfoWithStorage[127.0.0.1:41025,DS-a2f07815-f777-4650-82fd-9f4cbf713fb3,DISK], DatanodeInfoWithStorage[127.0.0.1:44056,DS-e5bae412-674f-48c8-a619-b647ed21fc8e,DISK], DatanodeInfoWithStorage[127.0.0.1:35248,DS-82bb791a-43aa-4b3d-9246-93fb160b0931,DISK], DatanodeInfoWithStorage[127.0.0.1:41115,DS-cef28cd0-48ba-4681-a827-e6190ad454b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34287,DS-e5f914e0-ca03-4499-a103-1cadb8c40f2f,DISK], DatanodeInfoWithStorage[127.0.0.1:39615,DS-53fbba53-2a46-4d64-bc6b-a3d13611cb2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1270085636-172.17.0.16-1596935617979:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42493,DS-37706665-5369-40ab-b044-3d5465a18d3a,DISK], DatanodeInfoWithStorage[127.0.0.1:46170,DS-081303a9-9f14-4179-aad6-0b1ee2e50f61,DISK], DatanodeInfoWithStorage[127.0.0.1:41025,DS-a2f07815-f777-4650-82fd-9f4cbf713fb3,DISK], DatanodeInfoWithStorage[127.0.0.1:44056,DS-e5bae412-674f-48c8-a619-b647ed21fc8e,DISK], DatanodeInfoWithStorage[127.0.0.1:35248,DS-82bb791a-43aa-4b3d-9246-93fb160b0931,DISK], DatanodeInfoWithStorage[127.0.0.1:41115,DS-cef28cd0-48ba-4681-a827-e6190ad454b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34287,DS-e5f914e0-ca03-4499-a103-1cadb8c40f2f,DISK], DatanodeInfoWithStorage[127.0.0.1:39615,DS-53fbba53-2a46-4d64-bc6b-a3d13611cb2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-684132530-172.17.0.16-1596935653363:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35122,DS-25e3c27f-6019-403d-b795-8db84debb1b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40925,DS-1dcdcd56-bd6f-476d-b7fc-d8b145bddb85,DISK], DatanodeInfoWithStorage[127.0.0.1:46657,DS-a0896521-0d2f-46d2-817c-5ce8cb83b9bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34715,DS-0255d614-a4a2-4ab5-955c-a9057bc562ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39814,DS-4bd671f8-278e-43ee-8e9b-4b9651199481,DISK], DatanodeInfoWithStorage[127.0.0.1:33805,DS-312bf3a2-29f5-4f1b-8b2b-70317cdf165f,DISK], DatanodeInfoWithStorage[127.0.0.1:34123,DS-dc3d9fbf-c558-4889-bbd9-fdc1165e03eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33868,DS-656a51f7-deb2-4e0a-bf45-a19130ad62e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-684132530-172.17.0.16-1596935653363:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35122,DS-25e3c27f-6019-403d-b795-8db84debb1b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40925,DS-1dcdcd56-bd6f-476d-b7fc-d8b145bddb85,DISK], DatanodeInfoWithStorage[127.0.0.1:46657,DS-a0896521-0d2f-46d2-817c-5ce8cb83b9bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34715,DS-0255d614-a4a2-4ab5-955c-a9057bc562ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39814,DS-4bd671f8-278e-43ee-8e9b-4b9651199481,DISK], DatanodeInfoWithStorage[127.0.0.1:33805,DS-312bf3a2-29f5-4f1b-8b2b-70317cdf165f,DISK], DatanodeInfoWithStorage[127.0.0.1:34123,DS-dc3d9fbf-c558-4889-bbd9-fdc1165e03eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33868,DS-656a51f7-deb2-4e0a-bf45-a19130ad62e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1889902486-172.17.0.16-1596936030010:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38836,DS-9548ff0b-7b3b-4fff-9b37-92e133a436a3,DISK], DatanodeInfoWithStorage[127.0.0.1:45340,DS-02f59dec-eeea-4f04-963c-e6b80a2b0922,DISK], DatanodeInfoWithStorage[127.0.0.1:36889,DS-7a597e20-51f7-4abb-90de-faa04d020c71,DISK], DatanodeInfoWithStorage[127.0.0.1:35528,DS-506d2d89-fb88-4982-9065-d590c578d5ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34874,DS-1bdbb27a-5af1-49f3-828a-6d69f0b39702,DISK], DatanodeInfoWithStorage[127.0.0.1:35930,DS-4f7f8415-34d1-425e-88d0-8367fa9f51c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38084,DS-dbcfc620-ac49-4468-b0af-d953935298c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43330,DS-4d124fa5-50f9-4a99-a9c1-a4048e6acbba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1889902486-172.17.0.16-1596936030010:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38836,DS-9548ff0b-7b3b-4fff-9b37-92e133a436a3,DISK], DatanodeInfoWithStorage[127.0.0.1:45340,DS-02f59dec-eeea-4f04-963c-e6b80a2b0922,DISK], DatanodeInfoWithStorage[127.0.0.1:36889,DS-7a597e20-51f7-4abb-90de-faa04d020c71,DISK], DatanodeInfoWithStorage[127.0.0.1:35528,DS-506d2d89-fb88-4982-9065-d590c578d5ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34874,DS-1bdbb27a-5af1-49f3-828a-6d69f0b39702,DISK], DatanodeInfoWithStorage[127.0.0.1:35930,DS-4f7f8415-34d1-425e-88d0-8367fa9f51c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38084,DS-dbcfc620-ac49-4468-b0af-d953935298c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43330,DS-4d124fa5-50f9-4a99-a9c1-a4048e6acbba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1637789940-172.17.0.16-1596936256750:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39042,DS-9ff68def-cd57-4388-942e-d8c14853739e,DISK], DatanodeInfoWithStorage[127.0.0.1:45290,DS-bed55703-718f-43f1-a11c-5f2d838139a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41701,DS-91cfe190-a5aa-4ef8-bcd5-0137e558b680,DISK], DatanodeInfoWithStorage[127.0.0.1:46066,DS-13cbd213-211f-432c-9a92-b93d61ebcf89,DISK], DatanodeInfoWithStorage[127.0.0.1:32882,DS-107f906a-2083-4efd-b9ea-68d4a61c2b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:36975,DS-9f8f0c87-cb09-4ce6-b20c-fe35e2c2c942,DISK], DatanodeInfoWithStorage[127.0.0.1:44242,DS-2ab38f5a-320b-45f7-8f02-8226ba920d35,DISK], DatanodeInfoWithStorage[127.0.0.1:41903,DS-15d54b1a-a64f-4fd5-a095-c6a44eb9f55f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1637789940-172.17.0.16-1596936256750:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39042,DS-9ff68def-cd57-4388-942e-d8c14853739e,DISK], DatanodeInfoWithStorage[127.0.0.1:45290,DS-bed55703-718f-43f1-a11c-5f2d838139a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41701,DS-91cfe190-a5aa-4ef8-bcd5-0137e558b680,DISK], DatanodeInfoWithStorage[127.0.0.1:46066,DS-13cbd213-211f-432c-9a92-b93d61ebcf89,DISK], DatanodeInfoWithStorage[127.0.0.1:32882,DS-107f906a-2083-4efd-b9ea-68d4a61c2b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:36975,DS-9f8f0c87-cb09-4ce6-b20c-fe35e2c2c942,DISK], DatanodeInfoWithStorage[127.0.0.1:44242,DS-2ab38f5a-320b-45f7-8f02-8226ba920d35,DISK], DatanodeInfoWithStorage[127.0.0.1:41903,DS-15d54b1a-a64f-4fd5-a095-c6a44eb9f55f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2029567125-172.17.0.16-1596936492167:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36805,DS-1f3c7ba3-4687-4ead-8ce4-eefca4153325,DISK], DatanodeInfoWithStorage[127.0.0.1:36185,DS-b4577259-d113-43de-b2c8-456e19b1da08,DISK], DatanodeInfoWithStorage[127.0.0.1:33777,DS-a4d005e1-809a-46c0-9325-77c5ddc7bf71,DISK], DatanodeInfoWithStorage[127.0.0.1:36554,DS-2cd18dda-965a-4865-83e3-b3abc809b3e6,DISK], DatanodeInfoWithStorage[127.0.0.1:43132,DS-737bf28c-7227-4661-9779-88d28627aced,DISK], DatanodeInfoWithStorage[127.0.0.1:33811,DS-73e0c2b0-97be-44fa-9a49-e8257ee04243,DISK], DatanodeInfoWithStorage[127.0.0.1:35426,DS-6eab4a7a-38db-4b6e-879d-a76629e233c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33844,DS-2f695594-4d2f-46d5-895f-1eea7d68ce00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2029567125-172.17.0.16-1596936492167:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36805,DS-1f3c7ba3-4687-4ead-8ce4-eefca4153325,DISK], DatanodeInfoWithStorage[127.0.0.1:36185,DS-b4577259-d113-43de-b2c8-456e19b1da08,DISK], DatanodeInfoWithStorage[127.0.0.1:33777,DS-a4d005e1-809a-46c0-9325-77c5ddc7bf71,DISK], DatanodeInfoWithStorage[127.0.0.1:36554,DS-2cd18dda-965a-4865-83e3-b3abc809b3e6,DISK], DatanodeInfoWithStorage[127.0.0.1:43132,DS-737bf28c-7227-4661-9779-88d28627aced,DISK], DatanodeInfoWithStorage[127.0.0.1:33811,DS-73e0c2b0-97be-44fa-9a49-e8257ee04243,DISK], DatanodeInfoWithStorage[127.0.0.1:35426,DS-6eab4a7a-38db-4b6e-879d-a76629e233c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33844,DS-2f695594-4d2f-46d5-895f-1eea7d68ce00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-826309363-172.17.0.16-1596936596927:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43447,DS-2b5a907b-db60-45fe-890e-135521af32fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45581,DS-1612a9e1-499c-45ce-849b-97542a45e643,DISK], DatanodeInfoWithStorage[127.0.0.1:42873,DS-b1e52ea3-3e53-4153-b2ea-fac38cba989c,DISK], DatanodeInfoWithStorage[127.0.0.1:39083,DS-0ad6ba2d-90e4-46d2-9071-e2cfa0b8aa88,DISK], DatanodeInfoWithStorage[127.0.0.1:42698,DS-08bd1ef8-275e-4a35-b394-59f7fbda56f4,DISK], DatanodeInfoWithStorage[127.0.0.1:32892,DS-89f63c77-8432-4efb-b63d-a2442c59f95d,DISK], DatanodeInfoWithStorage[127.0.0.1:40103,DS-62c38327-ddec-4858-8af8-d95d19003831,DISK], DatanodeInfoWithStorage[127.0.0.1:34925,DS-f48f5be7-1f7b-458b-b1ba-e9583a76e9c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-826309363-172.17.0.16-1596936596927:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43447,DS-2b5a907b-db60-45fe-890e-135521af32fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45581,DS-1612a9e1-499c-45ce-849b-97542a45e643,DISK], DatanodeInfoWithStorage[127.0.0.1:42873,DS-b1e52ea3-3e53-4153-b2ea-fac38cba989c,DISK], DatanodeInfoWithStorage[127.0.0.1:39083,DS-0ad6ba2d-90e4-46d2-9071-e2cfa0b8aa88,DISK], DatanodeInfoWithStorage[127.0.0.1:42698,DS-08bd1ef8-275e-4a35-b394-59f7fbda56f4,DISK], DatanodeInfoWithStorage[127.0.0.1:32892,DS-89f63c77-8432-4efb-b63d-a2442c59f95d,DISK], DatanodeInfoWithStorage[127.0.0.1:40103,DS-62c38327-ddec-4858-8af8-d95d19003831,DISK], DatanodeInfoWithStorage[127.0.0.1:34925,DS-f48f5be7-1f7b-458b-b1ba-e9583a76e9c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1871939706-172.17.0.16-1596936794101:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44570,DS-752ed401-5fdf-4e70-8657-0f488f79accc,DISK], DatanodeInfoWithStorage[127.0.0.1:36026,DS-d5313c33-2794-4f39-9e5a-7e07292fa232,DISK], DatanodeInfoWithStorage[127.0.0.1:41997,DS-3ee751f1-632b-4e6a-a5cd-7a96d41200b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39547,DS-1a6339fc-8451-4cff-a345-b898c47f0a86,DISK], DatanodeInfoWithStorage[127.0.0.1:46060,DS-a3ddc6e2-78a1-4249-9a86-45e91239a5ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41834,DS-8c49869e-3839-4d0f-8d3f-dbfb25069e2c,DISK], DatanodeInfoWithStorage[127.0.0.1:38573,DS-09ece3ec-8623-45ee-9a2a-8be6c2b75e60,DISK], DatanodeInfoWithStorage[127.0.0.1:34358,DS-17d6c489-b52b-43e9-8313-c92ddb81e778,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1871939706-172.17.0.16-1596936794101:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44570,DS-752ed401-5fdf-4e70-8657-0f488f79accc,DISK], DatanodeInfoWithStorage[127.0.0.1:36026,DS-d5313c33-2794-4f39-9e5a-7e07292fa232,DISK], DatanodeInfoWithStorage[127.0.0.1:41997,DS-3ee751f1-632b-4e6a-a5cd-7a96d41200b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39547,DS-1a6339fc-8451-4cff-a345-b898c47f0a86,DISK], DatanodeInfoWithStorage[127.0.0.1:46060,DS-a3ddc6e2-78a1-4249-9a86-45e91239a5ba,DISK], DatanodeInfoWithStorage[127.0.0.1:41834,DS-8c49869e-3839-4d0f-8d3f-dbfb25069e2c,DISK], DatanodeInfoWithStorage[127.0.0.1:38573,DS-09ece3ec-8623-45ee-9a2a-8be6c2b75e60,DISK], DatanodeInfoWithStorage[127.0.0.1:34358,DS-17d6c489-b52b-43e9-8313-c92ddb81e778,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5168
