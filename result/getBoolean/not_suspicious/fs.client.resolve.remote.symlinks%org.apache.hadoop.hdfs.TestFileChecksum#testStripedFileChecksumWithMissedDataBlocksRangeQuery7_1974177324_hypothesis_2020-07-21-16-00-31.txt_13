reconf_parameter: fs.client.resolve.remote.symlinks
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.client.resolve.remote.symlinks
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-545400153-172.17.0.2-1595347244417:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36457,DS-14fa3930-56d4-40d3-9791-396dbc834501,DISK], DatanodeInfoWithStorage[127.0.0.1:45593,DS-f541a4f1-2cd2-44e2-bd32-a09fe6dc077f,DISK], DatanodeInfoWithStorage[127.0.0.1:43958,DS-95d07b3b-8037-48b2-b9a4-6f6668b9496e,DISK], DatanodeInfoWithStorage[127.0.0.1:35190,DS-a9f703d9-15b8-48e7-85dd-e0da3bb2937b,DISK], DatanodeInfoWithStorage[127.0.0.1:43036,DS-1ed6e16a-4b27-43dd-9270-db06f6fcdb9e,DISK], DatanodeInfoWithStorage[127.0.0.1:44923,DS-ba7ef52a-557c-4f1b-9995-963cbb89a843,DISK], DatanodeInfoWithStorage[127.0.0.1:36853,DS-16f2b318-0f3f-4f72-aa9d-0d83811a1a80,DISK], DatanodeInfoWithStorage[127.0.0.1:43693,DS-1c19c97b-5e47-4651-949e-62cb3a4c9834,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-545400153-172.17.0.2-1595347244417:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36457,DS-14fa3930-56d4-40d3-9791-396dbc834501,DISK], DatanodeInfoWithStorage[127.0.0.1:45593,DS-f541a4f1-2cd2-44e2-bd32-a09fe6dc077f,DISK], DatanodeInfoWithStorage[127.0.0.1:43958,DS-95d07b3b-8037-48b2-b9a4-6f6668b9496e,DISK], DatanodeInfoWithStorage[127.0.0.1:35190,DS-a9f703d9-15b8-48e7-85dd-e0da3bb2937b,DISK], DatanodeInfoWithStorage[127.0.0.1:43036,DS-1ed6e16a-4b27-43dd-9270-db06f6fcdb9e,DISK], DatanodeInfoWithStorage[127.0.0.1:44923,DS-ba7ef52a-557c-4f1b-9995-963cbb89a843,DISK], DatanodeInfoWithStorage[127.0.0.1:36853,DS-16f2b318-0f3f-4f72-aa9d-0d83811a1a80,DISK], DatanodeInfoWithStorage[127.0.0.1:43693,DS-1c19c97b-5e47-4651-949e-62cb3a4c9834,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.client.resolve.remote.symlinks
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1848773736-172.17.0.2-1595347423247:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35670,DS-72bd4c83-122b-4e6a-8497-51359b1df157,DISK], DatanodeInfoWithStorage[127.0.0.1:36521,DS-2a224982-a02a-416b-ba02-e95b733f1eb5,DISK], DatanodeInfoWithStorage[127.0.0.1:45729,DS-1fba33e3-2a2a-46f7-8036-6efb516fc439,DISK], DatanodeInfoWithStorage[127.0.0.1:36462,DS-57f52318-2895-42f2-87ce-05d23f68d556,DISK], DatanodeInfoWithStorage[127.0.0.1:46517,DS-9729424b-b844-4a07-839b-1aa8f93b1a34,DISK], DatanodeInfoWithStorage[127.0.0.1:37127,DS-3fceb413-8975-499d-968c-939fafded14b,DISK], DatanodeInfoWithStorage[127.0.0.1:35543,DS-e1322658-74bc-4c00-8b13-3cf5e443ab65,DISK], DatanodeInfoWithStorage[127.0.0.1:38195,DS-6c8b0726-5763-46d3-949e-84c45e20b9bd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1848773736-172.17.0.2-1595347423247:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35670,DS-72bd4c83-122b-4e6a-8497-51359b1df157,DISK], DatanodeInfoWithStorage[127.0.0.1:36521,DS-2a224982-a02a-416b-ba02-e95b733f1eb5,DISK], DatanodeInfoWithStorage[127.0.0.1:45729,DS-1fba33e3-2a2a-46f7-8036-6efb516fc439,DISK], DatanodeInfoWithStorage[127.0.0.1:36462,DS-57f52318-2895-42f2-87ce-05d23f68d556,DISK], DatanodeInfoWithStorage[127.0.0.1:46517,DS-9729424b-b844-4a07-839b-1aa8f93b1a34,DISK], DatanodeInfoWithStorage[127.0.0.1:37127,DS-3fceb413-8975-499d-968c-939fafded14b,DISK], DatanodeInfoWithStorage[127.0.0.1:35543,DS-e1322658-74bc-4c00-8b13-3cf5e443ab65,DISK], DatanodeInfoWithStorage[127.0.0.1:38195,DS-6c8b0726-5763-46d3-949e-84c45e20b9bd,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.client.resolve.remote.symlinks
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1543247780-172.17.0.2-1595347569359:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36259,DS-282fa159-0af4-4cb3-b56b-04c30a70f50d,DISK], DatanodeInfoWithStorage[127.0.0.1:33324,DS-5aff71e1-f8b8-43d3-b7b9-ef3c3684e270,DISK], DatanodeInfoWithStorage[127.0.0.1:40969,DS-76559dd3-a8e2-4eb6-86d1-69c22a9c2310,DISK], DatanodeInfoWithStorage[127.0.0.1:43099,DS-9a48b06b-c408-48cc-a650-bae904ae3cc7,DISK], DatanodeInfoWithStorage[127.0.0.1:37125,DS-22c0fdad-71a5-439f-81f1-00bac0a3cd57,DISK], DatanodeInfoWithStorage[127.0.0.1:34954,DS-1365b69a-1157-401d-8655-18c91c8b14b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36729,DS-1bdb83f9-e7a4-43e7-a322-47d57ead2060,DISK], DatanodeInfoWithStorage[127.0.0.1:41556,DS-faf4e1b5-328f-4683-a0ee-c16b1cd3a16c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1543247780-172.17.0.2-1595347569359:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36259,DS-282fa159-0af4-4cb3-b56b-04c30a70f50d,DISK], DatanodeInfoWithStorage[127.0.0.1:33324,DS-5aff71e1-f8b8-43d3-b7b9-ef3c3684e270,DISK], DatanodeInfoWithStorage[127.0.0.1:40969,DS-76559dd3-a8e2-4eb6-86d1-69c22a9c2310,DISK], DatanodeInfoWithStorage[127.0.0.1:43099,DS-9a48b06b-c408-48cc-a650-bae904ae3cc7,DISK], DatanodeInfoWithStorage[127.0.0.1:37125,DS-22c0fdad-71a5-439f-81f1-00bac0a3cd57,DISK], DatanodeInfoWithStorage[127.0.0.1:34954,DS-1365b69a-1157-401d-8655-18c91c8b14b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36729,DS-1bdb83f9-e7a4-43e7-a322-47d57ead2060,DISK], DatanodeInfoWithStorage[127.0.0.1:41556,DS-faf4e1b5-328f-4683-a0ee-c16b1cd3a16c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.client.resolve.remote.symlinks
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-763395290-172.17.0.2-1595347699806:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45392,DS-1ea46e0b-b801-45f2-b48e-c8cb5072f9cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37795,DS-4807d5c3-4a8e-48fe-ae68-890f5e2f6beb,DISK], DatanodeInfoWithStorage[127.0.0.1:44702,DS-a3f48ae0-03f0-45cf-a147-aedc3092343f,DISK], DatanodeInfoWithStorage[127.0.0.1:43459,DS-c78338b2-3e6e-4dcd-813e-60ff391d3a8c,DISK], DatanodeInfoWithStorage[127.0.0.1:33452,DS-a3088bb1-a837-4668-a068-8f261289adbd,DISK], DatanodeInfoWithStorage[127.0.0.1:33678,DS-419dd473-5c16-4a93-aed7-7c3b9bef6e80,DISK], DatanodeInfoWithStorage[127.0.0.1:43722,DS-597a34e3-ae9e-4aa7-b7b6-191744341727,DISK], DatanodeInfoWithStorage[127.0.0.1:35190,DS-ca507935-de85-4ec5-bd93-1dc902bbc722,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-763395290-172.17.0.2-1595347699806:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45392,DS-1ea46e0b-b801-45f2-b48e-c8cb5072f9cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37795,DS-4807d5c3-4a8e-48fe-ae68-890f5e2f6beb,DISK], DatanodeInfoWithStorage[127.0.0.1:44702,DS-a3f48ae0-03f0-45cf-a147-aedc3092343f,DISK], DatanodeInfoWithStorage[127.0.0.1:43459,DS-c78338b2-3e6e-4dcd-813e-60ff391d3a8c,DISK], DatanodeInfoWithStorage[127.0.0.1:33452,DS-a3088bb1-a837-4668-a068-8f261289adbd,DISK], DatanodeInfoWithStorage[127.0.0.1:33678,DS-419dd473-5c16-4a93-aed7-7c3b9bef6e80,DISK], DatanodeInfoWithStorage[127.0.0.1:43722,DS-597a34e3-ae9e-4aa7-b7b6-191744341727,DISK], DatanodeInfoWithStorage[127.0.0.1:35190,DS-ca507935-de85-4ec5-bd93-1dc902bbc722,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.client.resolve.remote.symlinks
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-72607534-172.17.0.2-1595347891625:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42558,DS-83b1a676-a396-406a-ae70-cdc1edaec918,DISK], DatanodeInfoWithStorage[127.0.0.1:42525,DS-06354dfb-73ab-46f1-b462-ed377446ee0c,DISK], DatanodeInfoWithStorage[127.0.0.1:37363,DS-fd77c60f-dc2d-4eab-8696-9340589f9aae,DISK], DatanodeInfoWithStorage[127.0.0.1:34110,DS-5ecc142b-c68e-45b7-bb9f-8ae24ae11a32,DISK], DatanodeInfoWithStorage[127.0.0.1:34429,DS-9bfd80a9-0fff-4271-b5af-87ba88cabb55,DISK], DatanodeInfoWithStorage[127.0.0.1:39292,DS-2639cf94-1721-40ad-b177-ff8c48217908,DISK], DatanodeInfoWithStorage[127.0.0.1:40093,DS-19e1b563-677d-4cca-beaa-6ed7392ffd31,DISK], DatanodeInfoWithStorage[127.0.0.1:36206,DS-a1b6b125-cbf6-4fc7-80ce-7982a57979ec,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-72607534-172.17.0.2-1595347891625:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42558,DS-83b1a676-a396-406a-ae70-cdc1edaec918,DISK], DatanodeInfoWithStorage[127.0.0.1:42525,DS-06354dfb-73ab-46f1-b462-ed377446ee0c,DISK], DatanodeInfoWithStorage[127.0.0.1:37363,DS-fd77c60f-dc2d-4eab-8696-9340589f9aae,DISK], DatanodeInfoWithStorage[127.0.0.1:34110,DS-5ecc142b-c68e-45b7-bb9f-8ae24ae11a32,DISK], DatanodeInfoWithStorage[127.0.0.1:34429,DS-9bfd80a9-0fff-4271-b5af-87ba88cabb55,DISK], DatanodeInfoWithStorage[127.0.0.1:39292,DS-2639cf94-1721-40ad-b177-ff8c48217908,DISK], DatanodeInfoWithStorage[127.0.0.1:40093,DS-19e1b563-677d-4cca-beaa-6ed7392ffd31,DISK], DatanodeInfoWithStorage[127.0.0.1:36206,DS-a1b6b125-cbf6-4fc7-80ce-7982a57979ec,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.client.resolve.remote.symlinks
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1546532123-172.17.0.2-1595347972175:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40202,DS-77d27711-1ba6-4dc9-bea4-31deadcf6897,DISK], DatanodeInfoWithStorage[127.0.0.1:33152,DS-4f2b5658-cdaa-4dc9-ba99-2f20a6bfe982,DISK], DatanodeInfoWithStorage[127.0.0.1:44380,DS-f883164b-8703-4e8b-8d11-b0bb80aaa1ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42172,DS-3760716b-f950-4010-821b-20cae464b95a,DISK], DatanodeInfoWithStorage[127.0.0.1:33194,DS-2018c1c7-6da8-4bc7-b759-f7ec53c8c32c,DISK], DatanodeInfoWithStorage[127.0.0.1:44253,DS-17b7b750-da4b-4167-8dba-43a8d3799550,DISK], DatanodeInfoWithStorage[127.0.0.1:36169,DS-1a3c80de-02f1-4630-b2c4-3dd23b105dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:36968,DS-bb34bd6c-e50b-43cc-80d6-9360deb12761,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1546532123-172.17.0.2-1595347972175:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40202,DS-77d27711-1ba6-4dc9-bea4-31deadcf6897,DISK], DatanodeInfoWithStorage[127.0.0.1:33152,DS-4f2b5658-cdaa-4dc9-ba99-2f20a6bfe982,DISK], DatanodeInfoWithStorage[127.0.0.1:44380,DS-f883164b-8703-4e8b-8d11-b0bb80aaa1ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42172,DS-3760716b-f950-4010-821b-20cae464b95a,DISK], DatanodeInfoWithStorage[127.0.0.1:33194,DS-2018c1c7-6da8-4bc7-b759-f7ec53c8c32c,DISK], DatanodeInfoWithStorage[127.0.0.1:44253,DS-17b7b750-da4b-4167-8dba-43a8d3799550,DISK], DatanodeInfoWithStorage[127.0.0.1:36169,DS-1a3c80de-02f1-4630-b2c4-3dd23b105dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:36968,DS-bb34bd6c-e50b-43cc-80d6-9360deb12761,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.client.resolve.remote.symlinks
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1285411016-172.17.0.2-1595348010897:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44789,DS-d71ba94a-2a75-4915-a7e6-3d0a2b1db11f,DISK], DatanodeInfoWithStorage[127.0.0.1:46246,DS-e308c655-badf-4357-9224-de330833e43b,DISK], DatanodeInfoWithStorage[127.0.0.1:37293,DS-04ceb47e-b5b6-4895-ab33-c38b2336dcb0,DISK], DatanodeInfoWithStorage[127.0.0.1:42717,DS-fea763a8-8e9f-4873-94a1-1357f7451fb8,DISK], DatanodeInfoWithStorage[127.0.0.1:46812,DS-fe612ab4-b11e-4d1f-acf5-3bf51552b4ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35895,DS-3550d319-cf51-407d-a87b-a05ba6e8df89,DISK], DatanodeInfoWithStorage[127.0.0.1:39549,DS-6451bb16-b15e-4203-b35d-b51e500770eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36892,DS-f70daacc-0734-42b4-b11c-49d175184530,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1285411016-172.17.0.2-1595348010897:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44789,DS-d71ba94a-2a75-4915-a7e6-3d0a2b1db11f,DISK], DatanodeInfoWithStorage[127.0.0.1:46246,DS-e308c655-badf-4357-9224-de330833e43b,DISK], DatanodeInfoWithStorage[127.0.0.1:37293,DS-04ceb47e-b5b6-4895-ab33-c38b2336dcb0,DISK], DatanodeInfoWithStorage[127.0.0.1:42717,DS-fea763a8-8e9f-4873-94a1-1357f7451fb8,DISK], DatanodeInfoWithStorage[127.0.0.1:46812,DS-fe612ab4-b11e-4d1f-acf5-3bf51552b4ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35895,DS-3550d319-cf51-407d-a87b-a05ba6e8df89,DISK], DatanodeInfoWithStorage[127.0.0.1:39549,DS-6451bb16-b15e-4203-b35d-b51e500770eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36892,DS-f70daacc-0734-42b4-b11c-49d175184530,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.client.resolve.remote.symlinks
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1030270744-172.17.0.2-1595348044145:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43986,DS-66c88774-bbd4-4c3f-9706-fc1706767055,DISK], DatanodeInfoWithStorage[127.0.0.1:42998,DS-e160d2e3-ec5a-4723-88af-9a269966cc41,DISK], DatanodeInfoWithStorage[127.0.0.1:43846,DS-239b7770-d41d-4612-9f34-9ac96745473f,DISK], DatanodeInfoWithStorage[127.0.0.1:41934,DS-4fb14dcb-16e3-46da-a7c4-20e6b4485cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:45825,DS-f0e1594e-59fa-4f11-aa8a-301e85f8c1fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39802,DS-56b0f856-7c28-437b-abfd-e56fa977d37d,DISK], DatanodeInfoWithStorage[127.0.0.1:43840,DS-09282be6-0f96-48ec-8532-f20137c3cc5e,DISK], DatanodeInfoWithStorage[127.0.0.1:46625,DS-fd0abe2f-ecfe-4629-aea1-dc8419445dd3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1030270744-172.17.0.2-1595348044145:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43986,DS-66c88774-bbd4-4c3f-9706-fc1706767055,DISK], DatanodeInfoWithStorage[127.0.0.1:42998,DS-e160d2e3-ec5a-4723-88af-9a269966cc41,DISK], DatanodeInfoWithStorage[127.0.0.1:43846,DS-239b7770-d41d-4612-9f34-9ac96745473f,DISK], DatanodeInfoWithStorage[127.0.0.1:41934,DS-4fb14dcb-16e3-46da-a7c4-20e6b4485cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:45825,DS-f0e1594e-59fa-4f11-aa8a-301e85f8c1fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39802,DS-56b0f856-7c28-437b-abfd-e56fa977d37d,DISK], DatanodeInfoWithStorage[127.0.0.1:43840,DS-09282be6-0f96-48ec-8532-f20137c3cc5e,DISK], DatanodeInfoWithStorage[127.0.0.1:46625,DS-fd0abe2f-ecfe-4629-aea1-dc8419445dd3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.client.resolve.remote.symlinks
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-519746214-172.17.0.2-1595348214249:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41494,DS-f346dfa1-277d-40df-9cfd-4efaec666b83,DISK], DatanodeInfoWithStorage[127.0.0.1:42424,DS-14a77679-4ad5-46dd-acea-6f31bc93b002,DISK], DatanodeInfoWithStorage[127.0.0.1:35181,DS-d8901619-768d-4753-be6a-119076c6320c,DISK], DatanodeInfoWithStorage[127.0.0.1:44294,DS-929b7223-41fb-4c91-b000-f67b9a2d74c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35108,DS-dcb1182a-07ca-43eb-9623-da214c0f8b75,DISK], DatanodeInfoWithStorage[127.0.0.1:45738,DS-c827bb8f-6dae-4672-9105-9f7a5abc722d,DISK], DatanodeInfoWithStorage[127.0.0.1:45296,DS-80fae3e0-2208-4602-983e-3ed405a172fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44449,DS-68456458-3a0a-4ec2-81b6-d7c4620791be,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-519746214-172.17.0.2-1595348214249:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41494,DS-f346dfa1-277d-40df-9cfd-4efaec666b83,DISK], DatanodeInfoWithStorage[127.0.0.1:42424,DS-14a77679-4ad5-46dd-acea-6f31bc93b002,DISK], DatanodeInfoWithStorage[127.0.0.1:35181,DS-d8901619-768d-4753-be6a-119076c6320c,DISK], DatanodeInfoWithStorage[127.0.0.1:44294,DS-929b7223-41fb-4c91-b000-f67b9a2d74c0,DISK], DatanodeInfoWithStorage[127.0.0.1:35108,DS-dcb1182a-07ca-43eb-9623-da214c0f8b75,DISK], DatanodeInfoWithStorage[127.0.0.1:45738,DS-c827bb8f-6dae-4672-9105-9f7a5abc722d,DISK], DatanodeInfoWithStorage[127.0.0.1:45296,DS-80fae3e0-2208-4602-983e-3ed405a172fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44449,DS-68456458-3a0a-4ec2-81b6-d7c4620791be,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.client.resolve.remote.symlinks
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-797477333-172.17.0.2-1595348333681:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34020,DS-fddae42c-b7ed-4cd3-ada1-133e083a5375,DISK], DatanodeInfoWithStorage[127.0.0.1:43760,DS-4e4d67a9-4963-472e-b4d8-ca62a54134e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42312,DS-34de01b6-20a6-4e7e-9ecf-380658e9d842,DISK], DatanodeInfoWithStorage[127.0.0.1:44956,DS-2ed2a85d-1e97-4532-8ca3-bf9d2e78bdf1,DISK], DatanodeInfoWithStorage[127.0.0.1:38249,DS-54aa13ad-f3f9-49cd-979b-435cb18cfd77,DISK], DatanodeInfoWithStorage[127.0.0.1:34540,DS-6ad38cce-ead5-4b60-b544-11d2f4acd400,DISK], DatanodeInfoWithStorage[127.0.0.1:43263,DS-729b107c-5fa4-4506-8c17-2a1fdf5327b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42161,DS-574570e2-c282-4dfc-9189-94b2141c5057,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-797477333-172.17.0.2-1595348333681:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34020,DS-fddae42c-b7ed-4cd3-ada1-133e083a5375,DISK], DatanodeInfoWithStorage[127.0.0.1:43760,DS-4e4d67a9-4963-472e-b4d8-ca62a54134e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42312,DS-34de01b6-20a6-4e7e-9ecf-380658e9d842,DISK], DatanodeInfoWithStorage[127.0.0.1:44956,DS-2ed2a85d-1e97-4532-8ca3-bf9d2e78bdf1,DISK], DatanodeInfoWithStorage[127.0.0.1:38249,DS-54aa13ad-f3f9-49cd-979b-435cb18cfd77,DISK], DatanodeInfoWithStorage[127.0.0.1:34540,DS-6ad38cce-ead5-4b60-b544-11d2f4acd400,DISK], DatanodeInfoWithStorage[127.0.0.1:43263,DS-729b107c-5fa4-4506-8c17-2a1fdf5327b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42161,DS-574570e2-c282-4dfc-9189-94b2141c5057,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.client.resolve.remote.symlinks
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2116374851-172.17.0.2-1595348362690:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35205,DS-3092abc4-261c-4661-8ad3-6f015f03ccef,DISK], DatanodeInfoWithStorage[127.0.0.1:44737,DS-f4894d3a-1324-4d53-9ffa-653353643e1e,DISK], DatanodeInfoWithStorage[127.0.0.1:45368,DS-777cd877-b457-4d55-992f-43ceaff61c08,DISK], DatanodeInfoWithStorage[127.0.0.1:36930,DS-c7679ae0-6189-4654-b21e-7b0240b47cdc,DISK], DatanodeInfoWithStorage[127.0.0.1:46476,DS-f52b7594-8bc6-4b28-9bee-f67bdc579e70,DISK], DatanodeInfoWithStorage[127.0.0.1:34464,DS-7ae3390d-d625-44b2-9e34-9860a5590915,DISK], DatanodeInfoWithStorage[127.0.0.1:37970,DS-d776aefe-89bc-4654-a6b3-5969210e1802,DISK], DatanodeInfoWithStorage[127.0.0.1:40647,DS-baa34df5-ac35-4acc-9134-72d95e78b511,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2116374851-172.17.0.2-1595348362690:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35205,DS-3092abc4-261c-4661-8ad3-6f015f03ccef,DISK], DatanodeInfoWithStorage[127.0.0.1:44737,DS-f4894d3a-1324-4d53-9ffa-653353643e1e,DISK], DatanodeInfoWithStorage[127.0.0.1:45368,DS-777cd877-b457-4d55-992f-43ceaff61c08,DISK], DatanodeInfoWithStorage[127.0.0.1:36930,DS-c7679ae0-6189-4654-b21e-7b0240b47cdc,DISK], DatanodeInfoWithStorage[127.0.0.1:46476,DS-f52b7594-8bc6-4b28-9bee-f67bdc579e70,DISK], DatanodeInfoWithStorage[127.0.0.1:34464,DS-7ae3390d-d625-44b2-9e34-9860a5590915,DISK], DatanodeInfoWithStorage[127.0.0.1:37970,DS-d776aefe-89bc-4654-a6b3-5969210e1802,DISK], DatanodeInfoWithStorage[127.0.0.1:40647,DS-baa34df5-ac35-4acc-9134-72d95e78b511,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.client.resolve.remote.symlinks
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1767185012-172.17.0.2-1595348469308:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34206,DS-f6c24899-9344-4680-9110-b186b9454cbd,DISK], DatanodeInfoWithStorage[127.0.0.1:44386,DS-88a37f69-83bd-4aa0-bcf7-d403c059c163,DISK], DatanodeInfoWithStorage[127.0.0.1:36792,DS-b8501867-7e67-413b-b69d-4ec8d5c4ac2b,DISK], DatanodeInfoWithStorage[127.0.0.1:37986,DS-f7b56046-5d25-41ac-a519-e1ec4b3def2c,DISK], DatanodeInfoWithStorage[127.0.0.1:43029,DS-28bc1bae-ff54-44c4-9c4b-3972d07b66aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36758,DS-3dda7d55-7171-4785-b8fa-7d166dbb3904,DISK], DatanodeInfoWithStorage[127.0.0.1:35724,DS-de11c4b2-c745-4dc8-9066-fb4d5c8c2c24,DISK], DatanodeInfoWithStorage[127.0.0.1:34748,DS-954c1dd5-55a2-4973-af97-181ec8e8bc3a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1767185012-172.17.0.2-1595348469308:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34206,DS-f6c24899-9344-4680-9110-b186b9454cbd,DISK], DatanodeInfoWithStorage[127.0.0.1:44386,DS-88a37f69-83bd-4aa0-bcf7-d403c059c163,DISK], DatanodeInfoWithStorage[127.0.0.1:36792,DS-b8501867-7e67-413b-b69d-4ec8d5c4ac2b,DISK], DatanodeInfoWithStorage[127.0.0.1:37986,DS-f7b56046-5d25-41ac-a519-e1ec4b3def2c,DISK], DatanodeInfoWithStorage[127.0.0.1:43029,DS-28bc1bae-ff54-44c4-9c4b-3972d07b66aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36758,DS-3dda7d55-7171-4785-b8fa-7d166dbb3904,DISK], DatanodeInfoWithStorage[127.0.0.1:35724,DS-de11c4b2-c745-4dc8-9066-fb4d5c8c2c24,DISK], DatanodeInfoWithStorage[127.0.0.1:34748,DS-954c1dd5-55a2-4973-af97-181ec8e8bc3a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.client.resolve.remote.symlinks
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1543757542-172.17.0.2-1595348548118:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43703,DS-d4381fe0-e4ac-4ee1-9e09-80b3e4d219c3,DISK], DatanodeInfoWithStorage[127.0.0.1:45581,DS-6a406cf6-25c3-4fe6-a886-3bfa953ba926,DISK], DatanodeInfoWithStorage[127.0.0.1:36442,DS-652532ed-ce27-42ed-93cd-d39877ba4449,DISK], DatanodeInfoWithStorage[127.0.0.1:36783,DS-a5835ee5-d44c-40f3-a79c-46f4e9343e21,DISK], DatanodeInfoWithStorage[127.0.0.1:42948,DS-675a0b0a-7e6a-499b-89d0-1e3d70448c06,DISK], DatanodeInfoWithStorage[127.0.0.1:36225,DS-3d64c871-5791-4501-81b4-2a966bfbe36e,DISK], DatanodeInfoWithStorage[127.0.0.1:46611,DS-d0ed17b7-4648-447e-8198-fb8b07b83a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:38680,DS-f0aa7d5c-172f-44cf-9603-502adebec5a7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1543757542-172.17.0.2-1595348548118:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43703,DS-d4381fe0-e4ac-4ee1-9e09-80b3e4d219c3,DISK], DatanodeInfoWithStorage[127.0.0.1:45581,DS-6a406cf6-25c3-4fe6-a886-3bfa953ba926,DISK], DatanodeInfoWithStorage[127.0.0.1:36442,DS-652532ed-ce27-42ed-93cd-d39877ba4449,DISK], DatanodeInfoWithStorage[127.0.0.1:36783,DS-a5835ee5-d44c-40f3-a79c-46f4e9343e21,DISK], DatanodeInfoWithStorage[127.0.0.1:42948,DS-675a0b0a-7e6a-499b-89d0-1e3d70448c06,DISK], DatanodeInfoWithStorage[127.0.0.1:36225,DS-3d64c871-5791-4501-81b4-2a966bfbe36e,DISK], DatanodeInfoWithStorage[127.0.0.1:46611,DS-d0ed17b7-4648-447e-8198-fb8b07b83a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:38680,DS-f0aa7d5c-172f-44cf-9603-502adebec5a7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.client.resolve.remote.symlinks
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1022902448-172.17.0.2-1595348696770:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46480,DS-b89e0f85-f1db-4939-a969-4392e3026d4d,DISK], DatanodeInfoWithStorage[127.0.0.1:35649,DS-e57113a3-43db-4caf-94b5-254ea157154e,DISK], DatanodeInfoWithStorage[127.0.0.1:36103,DS-a9d219e7-4894-42ec-a276-5f381e69f6a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45118,DS-e241cd4f-855f-4e9c-8cd2-c73f83127849,DISK], DatanodeInfoWithStorage[127.0.0.1:39737,DS-ac2bd4f6-bee3-4ddc-94ad-b8fbaa917532,DISK], DatanodeInfoWithStorage[127.0.0.1:35713,DS-d190c0a0-e0ad-4699-8a49-8ef610671892,DISK], DatanodeInfoWithStorage[127.0.0.1:44057,DS-a3274c94-47df-47a1-ac9e-ae1f361d90fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41872,DS-fda3a267-27cc-411d-8ca3-47811112bf1f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1022902448-172.17.0.2-1595348696770:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46480,DS-b89e0f85-f1db-4939-a969-4392e3026d4d,DISK], DatanodeInfoWithStorage[127.0.0.1:35649,DS-e57113a3-43db-4caf-94b5-254ea157154e,DISK], DatanodeInfoWithStorage[127.0.0.1:36103,DS-a9d219e7-4894-42ec-a276-5f381e69f6a9,DISK], DatanodeInfoWithStorage[127.0.0.1:45118,DS-e241cd4f-855f-4e9c-8cd2-c73f83127849,DISK], DatanodeInfoWithStorage[127.0.0.1:39737,DS-ac2bd4f6-bee3-4ddc-94ad-b8fbaa917532,DISK], DatanodeInfoWithStorage[127.0.0.1:35713,DS-d190c0a0-e0ad-4699-8a49-8ef610671892,DISK], DatanodeInfoWithStorage[127.0.0.1:44057,DS-a3274c94-47df-47a1-ac9e-ae1f361d90fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41872,DS-fda3a267-27cc-411d-8ca3-47811112bf1f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.client.resolve.remote.symlinks
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2105071019-172.17.0.2-1595348772412:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41292,DS-0f6823c2-1535-4017-8645-1ebb8054daaa,DISK], DatanodeInfoWithStorage[127.0.0.1:43648,DS-90221a3e-2d60-4d7d-ac1f-d0bf45a77106,DISK], DatanodeInfoWithStorage[127.0.0.1:45625,DS-010620b4-8083-4819-8fc9-e60fbcfd5693,DISK], DatanodeInfoWithStorage[127.0.0.1:36790,DS-a5aeede3-8f65-4cec-a8c0-a166c46e0fc2,DISK], DatanodeInfoWithStorage[127.0.0.1:40555,DS-d0da38f5-fc04-4141-99aa-1dff15e4657d,DISK], DatanodeInfoWithStorage[127.0.0.1:34457,DS-93ffcd57-b53e-40ce-a178-671a15410fac,DISK], DatanodeInfoWithStorage[127.0.0.1:39042,DS-a6040f9a-cbf9-4741-8b7d-02d466e5b2cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45331,DS-eb34330d-e28d-4edb-af54-c415e659797d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2105071019-172.17.0.2-1595348772412:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41292,DS-0f6823c2-1535-4017-8645-1ebb8054daaa,DISK], DatanodeInfoWithStorage[127.0.0.1:43648,DS-90221a3e-2d60-4d7d-ac1f-d0bf45a77106,DISK], DatanodeInfoWithStorage[127.0.0.1:45625,DS-010620b4-8083-4819-8fc9-e60fbcfd5693,DISK], DatanodeInfoWithStorage[127.0.0.1:36790,DS-a5aeede3-8f65-4cec-a8c0-a166c46e0fc2,DISK], DatanodeInfoWithStorage[127.0.0.1:40555,DS-d0da38f5-fc04-4141-99aa-1dff15e4657d,DISK], DatanodeInfoWithStorage[127.0.0.1:34457,DS-93ffcd57-b53e-40ce-a178-671a15410fac,DISK], DatanodeInfoWithStorage[127.0.0.1:39042,DS-a6040f9a-cbf9-4741-8b7d-02d466e5b2cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45331,DS-eb34330d-e28d-4edb-af54-c415e659797d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.client.resolve.remote.symlinks
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1765252430-172.17.0.2-1595348979084:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36296,DS-3fa6a30e-6707-4c9b-8236-876c008640dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43553,DS-c148f20a-e657-436d-804e-036d2b34ccb8,DISK], DatanodeInfoWithStorage[127.0.0.1:36288,DS-ec48f4d0-e921-4dbb-826c-dff3f72410c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38657,DS-17d6a060-badc-4386-8b16-24f172a6e9d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40091,DS-0a0800a0-af80-4df4-97ce-ef144b3b9069,DISK], DatanodeInfoWithStorage[127.0.0.1:38088,DS-32cd5d9c-ae90-4492-8336-4bd554cf98fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36052,DS-00af0f82-1271-47d4-8bf9-044f77cef11a,DISK], DatanodeInfoWithStorage[127.0.0.1:42896,DS-d26ffc50-eb3d-47e3-8f44-793effedd244,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1765252430-172.17.0.2-1595348979084:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36296,DS-3fa6a30e-6707-4c9b-8236-876c008640dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43553,DS-c148f20a-e657-436d-804e-036d2b34ccb8,DISK], DatanodeInfoWithStorage[127.0.0.1:36288,DS-ec48f4d0-e921-4dbb-826c-dff3f72410c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38657,DS-17d6a060-badc-4386-8b16-24f172a6e9d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40091,DS-0a0800a0-af80-4df4-97ce-ef144b3b9069,DISK], DatanodeInfoWithStorage[127.0.0.1:38088,DS-32cd5d9c-ae90-4492-8336-4bd554cf98fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36052,DS-00af0f82-1271-47d4-8bf9-044f77cef11a,DISK], DatanodeInfoWithStorage[127.0.0.1:42896,DS-d26ffc50-eb3d-47e3-8f44-793effedd244,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.client.resolve.remote.symlinks
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1814503789-172.17.0.2-1595349013419:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43554,DS-3905f084-038f-4a5d-b46a-bf47538a6cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:46878,DS-91f0afa0-d876-42f6-a686-8eb23dc10ddc,DISK], DatanodeInfoWithStorage[127.0.0.1:45019,DS-430dda8c-bac9-46fa-b3c5-80c0e4734061,DISK], DatanodeInfoWithStorage[127.0.0.1:35506,DS-f9bc02d4-03d0-4f02-9aa3-86810b0cc409,DISK], DatanodeInfoWithStorage[127.0.0.1:36939,DS-f727fc99-e6ff-4288-b5db-04c9c973d60f,DISK], DatanodeInfoWithStorage[127.0.0.1:45826,DS-2e8bf7f6-aa40-4863-9cb8-ab337879cbe5,DISK], DatanodeInfoWithStorage[127.0.0.1:45410,DS-faf99a86-4837-4182-9bd1-62bae91ae2ff,DISK], DatanodeInfoWithStorage[127.0.0.1:46548,DS-6ed14efb-2ce7-436e-85dc-451026c8d1b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1814503789-172.17.0.2-1595349013419:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43554,DS-3905f084-038f-4a5d-b46a-bf47538a6cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:46878,DS-91f0afa0-d876-42f6-a686-8eb23dc10ddc,DISK], DatanodeInfoWithStorage[127.0.0.1:45019,DS-430dda8c-bac9-46fa-b3c5-80c0e4734061,DISK], DatanodeInfoWithStorage[127.0.0.1:35506,DS-f9bc02d4-03d0-4f02-9aa3-86810b0cc409,DISK], DatanodeInfoWithStorage[127.0.0.1:36939,DS-f727fc99-e6ff-4288-b5db-04c9c973d60f,DISK], DatanodeInfoWithStorage[127.0.0.1:45826,DS-2e8bf7f6-aa40-4863-9cb8-ab337879cbe5,DISK], DatanodeInfoWithStorage[127.0.0.1:45410,DS-faf99a86-4837-4182-9bd1-62bae91ae2ff,DISK], DatanodeInfoWithStorage[127.0.0.1:46548,DS-6ed14efb-2ce7-436e-85dc-451026c8d1b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.client.resolve.remote.symlinks
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-962263424-172.17.0.2-1595349269027:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34650,DS-9ee93f7d-ae44-4dcd-9ee0-3de58fa52234,DISK], DatanodeInfoWithStorage[127.0.0.1:35688,DS-a6fc3bf8-19e3-42cd-b70b-0a80f311fe7c,DISK], DatanodeInfoWithStorage[127.0.0.1:39341,DS-db8e4ee7-5277-4de4-86e8-9ca276c956d3,DISK], DatanodeInfoWithStorage[127.0.0.1:41961,DS-2857cd2f-42d1-4b24-a12e-39353a1eb3f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45904,DS-466e57ce-c75e-489c-a65f-4aa6808ea37c,DISK], DatanodeInfoWithStorage[127.0.0.1:41304,DS-95ccfa44-9455-45dc-ad97-fed395f288d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44048,DS-9cfd931a-8cf6-49ca-a8b4-26f9ac004449,DISK], DatanodeInfoWithStorage[127.0.0.1:32923,DS-821eb594-ca7b-419f-ba84-12919c6f3351,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-962263424-172.17.0.2-1595349269027:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34650,DS-9ee93f7d-ae44-4dcd-9ee0-3de58fa52234,DISK], DatanodeInfoWithStorage[127.0.0.1:35688,DS-a6fc3bf8-19e3-42cd-b70b-0a80f311fe7c,DISK], DatanodeInfoWithStorage[127.0.0.1:39341,DS-db8e4ee7-5277-4de4-86e8-9ca276c956d3,DISK], DatanodeInfoWithStorage[127.0.0.1:41961,DS-2857cd2f-42d1-4b24-a12e-39353a1eb3f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45904,DS-466e57ce-c75e-489c-a65f-4aa6808ea37c,DISK], DatanodeInfoWithStorage[127.0.0.1:41304,DS-95ccfa44-9455-45dc-ad97-fed395f288d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44048,DS-9cfd931a-8cf6-49ca-a8b4-26f9ac004449,DISK], DatanodeInfoWithStorage[127.0.0.1:32923,DS-821eb594-ca7b-419f-ba84-12919c6f3351,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.client.resolve.remote.symlinks
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1679727237-172.17.0.2-1595349305605:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38499,DS-19be4895-881c-4b33-95ef-c38d778d8442,DISK], DatanodeInfoWithStorage[127.0.0.1:37438,DS-1e04e469-e66b-423c-8c8a-a127fef16ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:39618,DS-b17a42f9-7ec8-4b2b-a20a-dce22257dfda,DISK], DatanodeInfoWithStorage[127.0.0.1:46306,DS-2204eeb4-ae40-4137-9e1e-6498c13195a8,DISK], DatanodeInfoWithStorage[127.0.0.1:33330,DS-ea5cd217-32d6-4bc8-bbc3-decacf3ecb44,DISK], DatanodeInfoWithStorage[127.0.0.1:45300,DS-2af18bf9-8276-419b-98c0-31e389a8caad,DISK], DatanodeInfoWithStorage[127.0.0.1:46585,DS-f4826c1f-449a-48dc-9a40-11c63a062e32,DISK], DatanodeInfoWithStorage[127.0.0.1:36858,DS-6e8915af-d096-430d-878c-43258d7cc4eb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1679727237-172.17.0.2-1595349305605:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38499,DS-19be4895-881c-4b33-95ef-c38d778d8442,DISK], DatanodeInfoWithStorage[127.0.0.1:37438,DS-1e04e469-e66b-423c-8c8a-a127fef16ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:39618,DS-b17a42f9-7ec8-4b2b-a20a-dce22257dfda,DISK], DatanodeInfoWithStorage[127.0.0.1:46306,DS-2204eeb4-ae40-4137-9e1e-6498c13195a8,DISK], DatanodeInfoWithStorage[127.0.0.1:33330,DS-ea5cd217-32d6-4bc8-bbc3-decacf3ecb44,DISK], DatanodeInfoWithStorage[127.0.0.1:45300,DS-2af18bf9-8276-419b-98c0-31e389a8caad,DISK], DatanodeInfoWithStorage[127.0.0.1:46585,DS-f4826c1f-449a-48dc-9a40-11c63a062e32,DISK], DatanodeInfoWithStorage[127.0.0.1:36858,DS-6e8915af-d096-430d-878c-43258d7cc4eb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.client.resolve.remote.symlinks
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1049440897-172.17.0.2-1595349374436:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36798,DS-f2a8bfcb-3a97-45ab-abf6-0a9584a993af,DISK], DatanodeInfoWithStorage[127.0.0.1:44802,DS-6e701e55-b023-47f9-9241-26ddf632216c,DISK], DatanodeInfoWithStorage[127.0.0.1:37941,DS-82c5f25a-593b-4cbd-86d8-cb53395d82e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43508,DS-08f7763f-5b72-4277-8acd-644c673f72d8,DISK], DatanodeInfoWithStorage[127.0.0.1:40105,DS-683eb95a-8dca-4f17-93ae-a8017dc4287a,DISK], DatanodeInfoWithStorage[127.0.0.1:34224,DS-eb4a2103-e91a-448b-9ee4-4f0e16899779,DISK], DatanodeInfoWithStorage[127.0.0.1:33543,DS-f3329ddc-e874-4151-b9d0-5d2601d46522,DISK], DatanodeInfoWithStorage[127.0.0.1:39400,DS-074e323d-1ca6-49d5-bbe9-1db419c5a707,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1049440897-172.17.0.2-1595349374436:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36798,DS-f2a8bfcb-3a97-45ab-abf6-0a9584a993af,DISK], DatanodeInfoWithStorage[127.0.0.1:44802,DS-6e701e55-b023-47f9-9241-26ddf632216c,DISK], DatanodeInfoWithStorage[127.0.0.1:37941,DS-82c5f25a-593b-4cbd-86d8-cb53395d82e0,DISK], DatanodeInfoWithStorage[127.0.0.1:43508,DS-08f7763f-5b72-4277-8acd-644c673f72d8,DISK], DatanodeInfoWithStorage[127.0.0.1:40105,DS-683eb95a-8dca-4f17-93ae-a8017dc4287a,DISK], DatanodeInfoWithStorage[127.0.0.1:34224,DS-eb4a2103-e91a-448b-9ee4-4f0e16899779,DISK], DatanodeInfoWithStorage[127.0.0.1:33543,DS-f3329ddc-e874-4151-b9d0-5d2601d46522,DISK], DatanodeInfoWithStorage[127.0.0.1:39400,DS-074e323d-1ca6-49d5-bbe9-1db419c5a707,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.client.resolve.remote.symlinks
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-72725231-172.17.0.2-1595349629258:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43413,DS-cd7d55f5-329f-454b-8f89-dc64dc981291,DISK], DatanodeInfoWithStorage[127.0.0.1:44239,DS-563d58f0-bbe2-40f6-88b6-77db8b96bd45,DISK], DatanodeInfoWithStorage[127.0.0.1:43498,DS-00c0a6cc-dc78-482e-9f5f-1040aab9c911,DISK], DatanodeInfoWithStorage[127.0.0.1:42973,DS-a28c1d39-c6ab-4ae3-ba4f-63afcda1d912,DISK], DatanodeInfoWithStorage[127.0.0.1:39623,DS-be53263a-393c-4544-8d6e-d037fede45d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33033,DS-9f8fef7a-8c5e-4454-807b-a81c139df9aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40942,DS-f3aedc0b-eba4-4e91-af58-49d1cb1ad50e,DISK], DatanodeInfoWithStorage[127.0.0.1:41147,DS-db274b9b-943b-444e-ba21-e4591446ff21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-72725231-172.17.0.2-1595349629258:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43413,DS-cd7d55f5-329f-454b-8f89-dc64dc981291,DISK], DatanodeInfoWithStorage[127.0.0.1:44239,DS-563d58f0-bbe2-40f6-88b6-77db8b96bd45,DISK], DatanodeInfoWithStorage[127.0.0.1:43498,DS-00c0a6cc-dc78-482e-9f5f-1040aab9c911,DISK], DatanodeInfoWithStorage[127.0.0.1:42973,DS-a28c1d39-c6ab-4ae3-ba4f-63afcda1d912,DISK], DatanodeInfoWithStorage[127.0.0.1:39623,DS-be53263a-393c-4544-8d6e-d037fede45d7,DISK], DatanodeInfoWithStorage[127.0.0.1:33033,DS-9f8fef7a-8c5e-4454-807b-a81c139df9aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40942,DS-f3aedc0b-eba4-4e91-af58-49d1cb1ad50e,DISK], DatanodeInfoWithStorage[127.0.0.1:41147,DS-db274b9b-943b-444e-ba21-e4591446ff21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.client.resolve.remote.symlinks
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1570485301-172.17.0.2-1595350190393:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40926,DS-c62475f0-36fe-45fb-8798-6a139e66530f,DISK], DatanodeInfoWithStorage[127.0.0.1:42475,DS-06c69ef3-7dea-4eea-8f51-5794f90441b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45084,DS-6bf110e6-2472-4386-a8a2-854ce30a7f25,DISK], DatanodeInfoWithStorage[127.0.0.1:38075,DS-ef9beeb3-a1d1-4afd-b2c3-7afda5805f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:46031,DS-c711def4-0ee2-4f9d-974b-703ee6cfd809,DISK], DatanodeInfoWithStorage[127.0.0.1:34606,DS-2f8a1201-31b8-4d43-9a74-d0f7a0f89f18,DISK], DatanodeInfoWithStorage[127.0.0.1:43308,DS-84627ec6-0976-41fd-b69d-3705032dbfe5,DISK], DatanodeInfoWithStorage[127.0.0.1:39116,DS-43f822b5-4ddc-4556-8bcb-17ac7974a837,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1570485301-172.17.0.2-1595350190393:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40926,DS-c62475f0-36fe-45fb-8798-6a139e66530f,DISK], DatanodeInfoWithStorage[127.0.0.1:42475,DS-06c69ef3-7dea-4eea-8f51-5794f90441b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45084,DS-6bf110e6-2472-4386-a8a2-854ce30a7f25,DISK], DatanodeInfoWithStorage[127.0.0.1:38075,DS-ef9beeb3-a1d1-4afd-b2c3-7afda5805f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:46031,DS-c711def4-0ee2-4f9d-974b-703ee6cfd809,DISK], DatanodeInfoWithStorage[127.0.0.1:34606,DS-2f8a1201-31b8-4d43-9a74-d0f7a0f89f18,DISK], DatanodeInfoWithStorage[127.0.0.1:43308,DS-84627ec6-0976-41fd-b69d-3705032dbfe5,DISK], DatanodeInfoWithStorage[127.0.0.1:39116,DS-43f822b5-4ddc-4556-8bcb-17ac7974a837,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.client.resolve.remote.symlinks
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1891125707-172.17.0.2-1595350308251:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42499,DS-42f52b42-b1ec-47c9-9050-cc8d4bb1e399,DISK], DatanodeInfoWithStorage[127.0.0.1:43893,DS-1554c6b4-b028-4f3c-82ba-7d384be264b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46631,DS-86dd14f5-5a24-4841-90a7-23bf7d36703c,DISK], DatanodeInfoWithStorage[127.0.0.1:43451,DS-521ee8ed-f9f8-472a-b976-3da770db55ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44894,DS-45b55925-655d-473c-966c-0c70cd1724c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40779,DS-bd06a1ab-8ffe-4e0d-9bc1-e5b7c210b17b,DISK], DatanodeInfoWithStorage[127.0.0.1:46674,DS-de3c72f9-3941-42b4-bdcd-0c7f2a33f798,DISK], DatanodeInfoWithStorage[127.0.0.1:35825,DS-9ff684a6-4410-47ba-8a3c-7bcba0f0217b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1891125707-172.17.0.2-1595350308251:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42499,DS-42f52b42-b1ec-47c9-9050-cc8d4bb1e399,DISK], DatanodeInfoWithStorage[127.0.0.1:43893,DS-1554c6b4-b028-4f3c-82ba-7d384be264b5,DISK], DatanodeInfoWithStorage[127.0.0.1:46631,DS-86dd14f5-5a24-4841-90a7-23bf7d36703c,DISK], DatanodeInfoWithStorage[127.0.0.1:43451,DS-521ee8ed-f9f8-472a-b976-3da770db55ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44894,DS-45b55925-655d-473c-966c-0c70cd1724c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40779,DS-bd06a1ab-8ffe-4e0d-9bc1-e5b7c210b17b,DISK], DatanodeInfoWithStorage[127.0.0.1:46674,DS-de3c72f9-3941-42b4-bdcd-0c7f2a33f798,DISK], DatanodeInfoWithStorage[127.0.0.1:35825,DS-9ff684a6-4410-47ba-8a3c-7bcba0f0217b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.client.resolve.remote.symlinks
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1506593794-172.17.0.2-1595350458090:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36977,DS-1ed84d04-c01f-494f-a1f2-ffb72378c386,DISK], DatanodeInfoWithStorage[127.0.0.1:44800,DS-bce291cb-dd0c-49e3-95c6-e050eab82cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:43351,DS-5406314c-a8f8-412b-af8b-3eef68c5ae56,DISK], DatanodeInfoWithStorage[127.0.0.1:35806,DS-37906e56-51a9-4980-a39b-8cf78773e732,DISK], DatanodeInfoWithStorage[127.0.0.1:45969,DS-0d10c47c-7910-46dd-a2ab-e81cf857b2c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46319,DS-98738fb8-d789-4a03-a71d-bfd7d00c0d96,DISK], DatanodeInfoWithStorage[127.0.0.1:43778,DS-60f52c5a-beb3-4583-8f9e-9638fea61ec1,DISK], DatanodeInfoWithStorage[127.0.0.1:42437,DS-ac86af33-5fdf-4049-9d6b-54daf55145c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1506593794-172.17.0.2-1595350458090:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36977,DS-1ed84d04-c01f-494f-a1f2-ffb72378c386,DISK], DatanodeInfoWithStorage[127.0.0.1:44800,DS-bce291cb-dd0c-49e3-95c6-e050eab82cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:43351,DS-5406314c-a8f8-412b-af8b-3eef68c5ae56,DISK], DatanodeInfoWithStorage[127.0.0.1:35806,DS-37906e56-51a9-4980-a39b-8cf78773e732,DISK], DatanodeInfoWithStorage[127.0.0.1:45969,DS-0d10c47c-7910-46dd-a2ab-e81cf857b2c4,DISK], DatanodeInfoWithStorage[127.0.0.1:46319,DS-98738fb8-d789-4a03-a71d-bfd7d00c0d96,DISK], DatanodeInfoWithStorage[127.0.0.1:43778,DS-60f52c5a-beb3-4583-8f9e-9638fea61ec1,DISK], DatanodeInfoWithStorage[127.0.0.1:42437,DS-ac86af33-5fdf-4049-9d6b-54daf55145c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.client.resolve.remote.symlinks
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1744692626-172.17.0.2-1595350610872:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41965,DS-ed14bbdc-8023-4f69-b48f-aa3c74d89dc5,DISK], DatanodeInfoWithStorage[127.0.0.1:44703,DS-252c8e8f-9a10-47ed-94da-c1ea55ec6c5a,DISK], DatanodeInfoWithStorage[127.0.0.1:38168,DS-b197d465-bbd5-4b5f-8e80-a450f6cfe8eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39116,DS-fd609c0e-10ca-445f-b5ec-1cd8350686ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36028,DS-2169380c-f693-4771-9e73-606ef12d356b,DISK], DatanodeInfoWithStorage[127.0.0.1:42460,DS-595f7696-c958-4736-a238-c596dd75678c,DISK], DatanodeInfoWithStorage[127.0.0.1:34843,DS-6c502e9b-733a-40c6-8efd-2afd65fa2cf7,DISK], DatanodeInfoWithStorage[127.0.0.1:33619,DS-c7626049-f20a-412a-9aab-24adab28619b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1744692626-172.17.0.2-1595350610872:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41965,DS-ed14bbdc-8023-4f69-b48f-aa3c74d89dc5,DISK], DatanodeInfoWithStorage[127.0.0.1:44703,DS-252c8e8f-9a10-47ed-94da-c1ea55ec6c5a,DISK], DatanodeInfoWithStorage[127.0.0.1:38168,DS-b197d465-bbd5-4b5f-8e80-a450f6cfe8eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39116,DS-fd609c0e-10ca-445f-b5ec-1cd8350686ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36028,DS-2169380c-f693-4771-9e73-606ef12d356b,DISK], DatanodeInfoWithStorage[127.0.0.1:42460,DS-595f7696-c958-4736-a238-c596dd75678c,DISK], DatanodeInfoWithStorage[127.0.0.1:34843,DS-6c502e9b-733a-40c6-8efd-2afd65fa2cf7,DISK], DatanodeInfoWithStorage[127.0.0.1:33619,DS-c7626049-f20a-412a-9aab-24adab28619b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.client.resolve.remote.symlinks
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1443856242-172.17.0.2-1595350721452:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35438,DS-458657eb-d9e0-4270-a984-7787b23d9621,DISK], DatanodeInfoWithStorage[127.0.0.1:36940,DS-aabdfa37-b11f-4cd4-9343-4fff1e9d6bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:45534,DS-f2a89edc-c15a-4d25-8b56-d0396a77350f,DISK], DatanodeInfoWithStorage[127.0.0.1:43748,DS-81c1db3f-4e3d-4d04-8b6b-cc25fe5cfadb,DISK], DatanodeInfoWithStorage[127.0.0.1:35908,DS-bce8c309-40c1-4710-bd0c-e1ae1b2c0ff4,DISK], DatanodeInfoWithStorage[127.0.0.1:39713,DS-74d76b2e-a5c2-4960-ba96-39ba2e42d2c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42262,DS-9c43c02c-ba3e-4734-9459-26fe2969c09e,DISK], DatanodeInfoWithStorage[127.0.0.1:44592,DS-16a87d86-4c4c-460c-a605-e8296afb2987,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1443856242-172.17.0.2-1595350721452:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35438,DS-458657eb-d9e0-4270-a984-7787b23d9621,DISK], DatanodeInfoWithStorage[127.0.0.1:36940,DS-aabdfa37-b11f-4cd4-9343-4fff1e9d6bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:45534,DS-f2a89edc-c15a-4d25-8b56-d0396a77350f,DISK], DatanodeInfoWithStorage[127.0.0.1:43748,DS-81c1db3f-4e3d-4d04-8b6b-cc25fe5cfadb,DISK], DatanodeInfoWithStorage[127.0.0.1:35908,DS-bce8c309-40c1-4710-bd0c-e1ae1b2c0ff4,DISK], DatanodeInfoWithStorage[127.0.0.1:39713,DS-74d76b2e-a5c2-4960-ba96-39ba2e42d2c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42262,DS-9c43c02c-ba3e-4734-9459-26fe2969c09e,DISK], DatanodeInfoWithStorage[127.0.0.1:44592,DS-16a87d86-4c4c-460c-a605-e8296afb2987,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.client.resolve.remote.symlinks
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-292890889-172.17.0.2-1595350794493:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44583,DS-c25535c7-82ae-4a89-af21-6b9818f7a35d,DISK], DatanodeInfoWithStorage[127.0.0.1:34636,DS-36774701-9800-4b6e-9c47-fa76eafa329e,DISK], DatanodeInfoWithStorage[127.0.0.1:38812,DS-d26c497c-6b45-4f99-904f-d028ede4d5dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45081,DS-f382957c-f167-46ef-b6ab-5455259e3bbc,DISK], DatanodeInfoWithStorage[127.0.0.1:45177,DS-5b9430cf-84a8-489c-82fc-b80393006ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:35998,DS-0b571e58-f153-49e7-86cb-4aa9a811f567,DISK], DatanodeInfoWithStorage[127.0.0.1:41128,DS-e9dbc570-f6bc-483f-81c9-6a662e864c8d,DISK], DatanodeInfoWithStorage[127.0.0.1:43487,DS-25113a48-95c4-4e0b-87df-d1051269cc84,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-292890889-172.17.0.2-1595350794493:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44583,DS-c25535c7-82ae-4a89-af21-6b9818f7a35d,DISK], DatanodeInfoWithStorage[127.0.0.1:34636,DS-36774701-9800-4b6e-9c47-fa76eafa329e,DISK], DatanodeInfoWithStorage[127.0.0.1:38812,DS-d26c497c-6b45-4f99-904f-d028ede4d5dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45081,DS-f382957c-f167-46ef-b6ab-5455259e3bbc,DISK], DatanodeInfoWithStorage[127.0.0.1:45177,DS-5b9430cf-84a8-489c-82fc-b80393006ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:35998,DS-0b571e58-f153-49e7-86cb-4aa9a811f567,DISK], DatanodeInfoWithStorage[127.0.0.1:41128,DS-e9dbc570-f6bc-483f-81c9-6a662e864c8d,DISK], DatanodeInfoWithStorage[127.0.0.1:43487,DS-25113a48-95c4-4e0b-87df-d1051269cc84,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.client.resolve.remote.symlinks
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1116735209-172.17.0.2-1595350829495:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41936,DS-681a3588-d01f-4c82-a52e-27d4695b2d66,DISK], DatanodeInfoWithStorage[127.0.0.1:36156,DS-0fd5ec1e-210d-474c-b862-a747bc30428e,DISK], DatanodeInfoWithStorage[127.0.0.1:37770,DS-5a7a5126-6733-4a0b-9062-957196559790,DISK], DatanodeInfoWithStorage[127.0.0.1:40050,DS-c7a357a8-86c3-49c7-8470-70bbd091ef7c,DISK], DatanodeInfoWithStorage[127.0.0.1:40347,DS-3fa7a5b8-73d4-4a79-a52f-fbfb8183acf5,DISK], DatanodeInfoWithStorage[127.0.0.1:46119,DS-f394fc78-887d-44bb-9b95-050457f69280,DISK], DatanodeInfoWithStorage[127.0.0.1:39548,DS-d1971b13-0325-4f1e-bb74-3d735c8396e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35410,DS-2903d2d4-bd30-4c34-bbc2-d1389ddb0330,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1116735209-172.17.0.2-1595350829495:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41936,DS-681a3588-d01f-4c82-a52e-27d4695b2d66,DISK], DatanodeInfoWithStorage[127.0.0.1:36156,DS-0fd5ec1e-210d-474c-b862-a747bc30428e,DISK], DatanodeInfoWithStorage[127.0.0.1:37770,DS-5a7a5126-6733-4a0b-9062-957196559790,DISK], DatanodeInfoWithStorage[127.0.0.1:40050,DS-c7a357a8-86c3-49c7-8470-70bbd091ef7c,DISK], DatanodeInfoWithStorage[127.0.0.1:40347,DS-3fa7a5b8-73d4-4a79-a52f-fbfb8183acf5,DISK], DatanodeInfoWithStorage[127.0.0.1:46119,DS-f394fc78-887d-44bb-9b95-050457f69280,DISK], DatanodeInfoWithStorage[127.0.0.1:39548,DS-d1971b13-0325-4f1e-bb74-3d735c8396e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35410,DS-2903d2d4-bd30-4c34-bbc2-d1389ddb0330,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.client.resolve.remote.symlinks
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1938539475-172.17.0.2-1595350868461:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45316,DS-891e1c7f-6843-4609-b3e9-7b4d8cac2266,DISK], DatanodeInfoWithStorage[127.0.0.1:44321,DS-1eb48082-6e86-41a4-ba7e-a1a416457b9b,DISK], DatanodeInfoWithStorage[127.0.0.1:39932,DS-6b52a1e5-49f6-4452-87e1-8f68d3e889c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37213,DS-75caed32-7bd8-44ea-8a72-6db05ea198c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37620,DS-02043b35-98c2-4473-bb47-aa54f99a04d1,DISK], DatanodeInfoWithStorage[127.0.0.1:32955,DS-181b3791-b248-4591-ba61-5a9899a88366,DISK], DatanodeInfoWithStorage[127.0.0.1:46384,DS-835a706f-e6ac-4c67-a250-be28659cd774,DISK], DatanodeInfoWithStorage[127.0.0.1:38271,DS-26139ef4-3c98-4cc8-9eb0-0f2522ade468,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1938539475-172.17.0.2-1595350868461:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45316,DS-891e1c7f-6843-4609-b3e9-7b4d8cac2266,DISK], DatanodeInfoWithStorage[127.0.0.1:44321,DS-1eb48082-6e86-41a4-ba7e-a1a416457b9b,DISK], DatanodeInfoWithStorage[127.0.0.1:39932,DS-6b52a1e5-49f6-4452-87e1-8f68d3e889c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37213,DS-75caed32-7bd8-44ea-8a72-6db05ea198c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37620,DS-02043b35-98c2-4473-bb47-aa54f99a04d1,DISK], DatanodeInfoWithStorage[127.0.0.1:32955,DS-181b3791-b248-4591-ba61-5a9899a88366,DISK], DatanodeInfoWithStorage[127.0.0.1:46384,DS-835a706f-e6ac-4c67-a250-be28659cd774,DISK], DatanodeInfoWithStorage[127.0.0.1:38271,DS-26139ef4-3c98-4cc8-9eb0-0f2522ade468,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.client.resolve.remote.symlinks
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1558175763-172.17.0.2-1595351016642:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43071,DS-22d438f2-8685-496b-9af1-f83fb364674d,DISK], DatanodeInfoWithStorage[127.0.0.1:40018,DS-192853f6-9770-47be-8967-511ff8dd22d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34844,DS-0810fda8-84dd-43da-af9a-65c8a0c3f184,DISK], DatanodeInfoWithStorage[127.0.0.1:43324,DS-2f0188a1-ffbe-46d9-af91-00ccf8bd38ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35051,DS-0f61f17d-f6ed-4e47-ae92-664aa4f8196c,DISK], DatanodeInfoWithStorage[127.0.0.1:35297,DS-e78ea018-209b-449f-91ab-2b4461d4aaaf,DISK], DatanodeInfoWithStorage[127.0.0.1:37382,DS-40f50151-0a46-4de2-8c3c-c919928eeb29,DISK], DatanodeInfoWithStorage[127.0.0.1:42916,DS-c4c597c1-312b-430b-8c0e-42e259f56ebe,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1558175763-172.17.0.2-1595351016642:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43071,DS-22d438f2-8685-496b-9af1-f83fb364674d,DISK], DatanodeInfoWithStorage[127.0.0.1:40018,DS-192853f6-9770-47be-8967-511ff8dd22d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34844,DS-0810fda8-84dd-43da-af9a-65c8a0c3f184,DISK], DatanodeInfoWithStorage[127.0.0.1:43324,DS-2f0188a1-ffbe-46d9-af91-00ccf8bd38ac,DISK], DatanodeInfoWithStorage[127.0.0.1:35051,DS-0f61f17d-f6ed-4e47-ae92-664aa4f8196c,DISK], DatanodeInfoWithStorage[127.0.0.1:35297,DS-e78ea018-209b-449f-91ab-2b4461d4aaaf,DISK], DatanodeInfoWithStorage[127.0.0.1:37382,DS-40f50151-0a46-4de2-8c3c-c919928eeb29,DISK], DatanodeInfoWithStorage[127.0.0.1:42916,DS-c4c597c1-312b-430b-8c0e-42e259f56ebe,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.client.resolve.remote.symlinks
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1872619414-172.17.0.2-1595351681006:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44315,DS-b4d01f53-9a1e-415e-ad91-c7244e084634,DISK], DatanodeInfoWithStorage[127.0.0.1:35620,DS-e59fcefe-325a-429a-85d5-df24a4e4a1e5,DISK], DatanodeInfoWithStorage[127.0.0.1:33811,DS-8f01023a-a49c-4289-bced-9e541f413e53,DISK], DatanodeInfoWithStorage[127.0.0.1:40729,DS-eabd7b59-b0b2-4906-a017-aa3e1fd0f962,DISK], DatanodeInfoWithStorage[127.0.0.1:42208,DS-795f8aed-0bfb-49e3-987e-e55187f5c71f,DISK], DatanodeInfoWithStorage[127.0.0.1:36035,DS-c05b8462-0a75-46e1-b85d-e3117a6634d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44376,DS-4518bfa1-b1b5-4cf6-bf8c-930c78bf2610,DISK], DatanodeInfoWithStorage[127.0.0.1:40274,DS-b6f45761-7a61-4066-bf58-fee8b6c6f46c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1872619414-172.17.0.2-1595351681006:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44315,DS-b4d01f53-9a1e-415e-ad91-c7244e084634,DISK], DatanodeInfoWithStorage[127.0.0.1:35620,DS-e59fcefe-325a-429a-85d5-df24a4e4a1e5,DISK], DatanodeInfoWithStorage[127.0.0.1:33811,DS-8f01023a-a49c-4289-bced-9e541f413e53,DISK], DatanodeInfoWithStorage[127.0.0.1:40729,DS-eabd7b59-b0b2-4906-a017-aa3e1fd0f962,DISK], DatanodeInfoWithStorage[127.0.0.1:42208,DS-795f8aed-0bfb-49e3-987e-e55187f5c71f,DISK], DatanodeInfoWithStorage[127.0.0.1:36035,DS-c05b8462-0a75-46e1-b85d-e3117a6634d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44376,DS-4518bfa1-b1b5-4cf6-bf8c-930c78bf2610,DISK], DatanodeInfoWithStorage[127.0.0.1:40274,DS-b6f45761-7a61-4066-bf58-fee8b6c6f46c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: fs.client.resolve.remote.symlinks
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-857185665-172.17.0.2-1595351722967:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41262,DS-bfe5c8e8-ef91-4281-9a31-e1215f8eb542,DISK], DatanodeInfoWithStorage[127.0.0.1:35550,DS-54d9999b-4bb2-4d57-994a-6608a0a3042e,DISK], DatanodeInfoWithStorage[127.0.0.1:45726,DS-64688596-1455-4fe4-9deb-1b8d1004ad2e,DISK], DatanodeInfoWithStorage[127.0.0.1:42766,DS-529e86f0-b893-499b-a020-c6556ef728b2,DISK], DatanodeInfoWithStorage[127.0.0.1:32825,DS-306544bd-fb30-43b4-aca4-63f4295ea30a,DISK], DatanodeInfoWithStorage[127.0.0.1:33044,DS-8da17584-2b2e-4b84-9653-165d4be29e8f,DISK], DatanodeInfoWithStorage[127.0.0.1:40641,DS-7a2f353c-cb27-4387-8ad4-f2984ad94d88,DISK], DatanodeInfoWithStorage[127.0.0.1:36160,DS-7a73fb74-2204-4299-bcfd-263be1989cce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-857185665-172.17.0.2-1595351722967:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41262,DS-bfe5c8e8-ef91-4281-9a31-e1215f8eb542,DISK], DatanodeInfoWithStorage[127.0.0.1:35550,DS-54d9999b-4bb2-4d57-994a-6608a0a3042e,DISK], DatanodeInfoWithStorage[127.0.0.1:45726,DS-64688596-1455-4fe4-9deb-1b8d1004ad2e,DISK], DatanodeInfoWithStorage[127.0.0.1:42766,DS-529e86f0-b893-499b-a020-c6556ef728b2,DISK], DatanodeInfoWithStorage[127.0.0.1:32825,DS-306544bd-fb30-43b4-aca4-63f4295ea30a,DISK], DatanodeInfoWithStorage[127.0.0.1:33044,DS-8da17584-2b2e-4b84-9653-165d4be29e8f,DISK], DatanodeInfoWithStorage[127.0.0.1:40641,DS-7a2f353c-cb27-4387-8ad4-f2984ad94d88,DISK], DatanodeInfoWithStorage[127.0.0.1:36160,DS-7a73fb74-2204-4299-bcfd-263be1989cce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.client.resolve.remote.symlinks
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-601055602-172.17.0.2-1595352302661:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46810,DS-042828e4-dd96-4ffb-866b-094b7f343201,DISK], DatanodeInfoWithStorage[127.0.0.1:36729,DS-623781e4-c8e0-4882-b8b4-f809f2ae6391,DISK], DatanodeInfoWithStorage[127.0.0.1:45574,DS-9c08108d-5a98-44ad-8b24-58c5f569ea7f,DISK], DatanodeInfoWithStorage[127.0.0.1:41141,DS-ba2424e6-6665-4f59-ad12-175694b88378,DISK], DatanodeInfoWithStorage[127.0.0.1:37292,DS-744c8b78-38d1-4017-ac55-828a3cfea5b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46472,DS-7ca0f1a6-bebb-4a93-809e-fe05b874911d,DISK], DatanodeInfoWithStorage[127.0.0.1:42566,DS-d9be79c8-cd53-4a4a-8255-d56a7bd9e805,DISK], DatanodeInfoWithStorage[127.0.0.1:35495,DS-5506ad41-cfb2-4ef7-b1d0-331ab731871d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-601055602-172.17.0.2-1595352302661:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46810,DS-042828e4-dd96-4ffb-866b-094b7f343201,DISK], DatanodeInfoWithStorage[127.0.0.1:36729,DS-623781e4-c8e0-4882-b8b4-f809f2ae6391,DISK], DatanodeInfoWithStorage[127.0.0.1:45574,DS-9c08108d-5a98-44ad-8b24-58c5f569ea7f,DISK], DatanodeInfoWithStorage[127.0.0.1:41141,DS-ba2424e6-6665-4f59-ad12-175694b88378,DISK], DatanodeInfoWithStorage[127.0.0.1:37292,DS-744c8b78-38d1-4017-ac55-828a3cfea5b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46472,DS-7ca0f1a6-bebb-4a93-809e-fe05b874911d,DISK], DatanodeInfoWithStorage[127.0.0.1:42566,DS-d9be79c8-cd53-4a4a-8255-d56a7bd9e805,DISK], DatanodeInfoWithStorage[127.0.0.1:35495,DS-5506ad41-cfb2-4ef7-b1d0-331ab731871d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.client.resolve.remote.symlinks
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1904815607-172.17.0.2-1595352377759:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42768,DS-d7e69180-1308-4d53-bae1-a6cf9d10cfb8,DISK], DatanodeInfoWithStorage[127.0.0.1:44319,DS-3de5b400-7722-47e2-93cc-45b8038050be,DISK], DatanodeInfoWithStorage[127.0.0.1:33607,DS-9fb952a6-83d1-4a1a-9fa5-1a3b4f7c47cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36216,DS-bf683add-e266-488f-abe2-cbb6d5c5c025,DISK], DatanodeInfoWithStorage[127.0.0.1:43572,DS-01482758-5c9a-45db-9873-65315ef02a00,DISK], DatanodeInfoWithStorage[127.0.0.1:44605,DS-8e9345ea-7687-46e1-9286-3daddfcef0d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42667,DS-f4d703fe-a045-4a56-99c0-1caaf98e622d,DISK], DatanodeInfoWithStorage[127.0.0.1:46397,DS-a1116557-a887-4256-9e67-78bc411f5ce1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1904815607-172.17.0.2-1595352377759:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42768,DS-d7e69180-1308-4d53-bae1-a6cf9d10cfb8,DISK], DatanodeInfoWithStorage[127.0.0.1:44319,DS-3de5b400-7722-47e2-93cc-45b8038050be,DISK], DatanodeInfoWithStorage[127.0.0.1:33607,DS-9fb952a6-83d1-4a1a-9fa5-1a3b4f7c47cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36216,DS-bf683add-e266-488f-abe2-cbb6d5c5c025,DISK], DatanodeInfoWithStorage[127.0.0.1:43572,DS-01482758-5c9a-45db-9873-65315ef02a00,DISK], DatanodeInfoWithStorage[127.0.0.1:44605,DS-8e9345ea-7687-46e1-9286-3daddfcef0d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42667,DS-f4d703fe-a045-4a56-99c0-1caaf98e622d,DISK], DatanodeInfoWithStorage[127.0.0.1:46397,DS-a1116557-a887-4256-9e67-78bc411f5ce1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.client.resolve.remote.symlinks
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-584715064-172.17.0.2-1595352491654:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39026,DS-b537a684-a45b-4efe-ad8b-f3d25b30d48a,DISK], DatanodeInfoWithStorage[127.0.0.1:35231,DS-5fe916a9-4cf3-4991-9a51-280737f78184,DISK], DatanodeInfoWithStorage[127.0.0.1:38041,DS-c18ea58a-5f21-48e7-a090-9d056e649792,DISK], DatanodeInfoWithStorage[127.0.0.1:32889,DS-431a8924-bb33-48f3-b62c-62e61bb295a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44576,DS-c6e2051c-2da2-4cea-8243-375c32d72294,DISK], DatanodeInfoWithStorage[127.0.0.1:43001,DS-4ea23705-e01b-4d46-9ac5-b98fbeb00b0a,DISK], DatanodeInfoWithStorage[127.0.0.1:46660,DS-eacc5b32-ef58-4ea1-8218-da30da5f7b04,DISK], DatanodeInfoWithStorage[127.0.0.1:41542,DS-3e2b065a-313f-4b1d-bfa1-d56cf2c91fa6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-584715064-172.17.0.2-1595352491654:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39026,DS-b537a684-a45b-4efe-ad8b-f3d25b30d48a,DISK], DatanodeInfoWithStorage[127.0.0.1:35231,DS-5fe916a9-4cf3-4991-9a51-280737f78184,DISK], DatanodeInfoWithStorage[127.0.0.1:38041,DS-c18ea58a-5f21-48e7-a090-9d056e649792,DISK], DatanodeInfoWithStorage[127.0.0.1:32889,DS-431a8924-bb33-48f3-b62c-62e61bb295a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44576,DS-c6e2051c-2da2-4cea-8243-375c32d72294,DISK], DatanodeInfoWithStorage[127.0.0.1:43001,DS-4ea23705-e01b-4d46-9ac5-b98fbeb00b0a,DISK], DatanodeInfoWithStorage[127.0.0.1:46660,DS-eacc5b32-ef58-4ea1-8218-da30da5f7b04,DISK], DatanodeInfoWithStorage[127.0.0.1:41542,DS-3e2b065a-313f-4b1d-bfa1-d56cf2c91fa6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.client.resolve.remote.symlinks
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1896372937-172.17.0.2-1595352728679:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46481,DS-ab504c81-09b6-4a7d-a8ba-8ddd3e8c6da4,DISK], DatanodeInfoWithStorage[127.0.0.1:39119,DS-fe36cc04-3f31-48ac-98dd-b689ece29475,DISK], DatanodeInfoWithStorage[127.0.0.1:33422,DS-7e40ea4d-717f-4842-bd8d-8aa2dd246866,DISK], DatanodeInfoWithStorage[127.0.0.1:36811,DS-1f546c32-03a0-4763-b66a-69e3bf1fd48a,DISK], DatanodeInfoWithStorage[127.0.0.1:37774,DS-c6039987-4cb0-4673-b878-27503ddeac49,DISK], DatanodeInfoWithStorage[127.0.0.1:46026,DS-19487289-78ff-45e6-b5d1-a170f86d1261,DISK], DatanodeInfoWithStorage[127.0.0.1:44197,DS-30988693-62ce-422f-a56b-4a91aec0ba4f,DISK], DatanodeInfoWithStorage[127.0.0.1:41844,DS-d38b89bf-04c9-49e4-889e-5cfaffb03fbe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1896372937-172.17.0.2-1595352728679:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46481,DS-ab504c81-09b6-4a7d-a8ba-8ddd3e8c6da4,DISK], DatanodeInfoWithStorage[127.0.0.1:39119,DS-fe36cc04-3f31-48ac-98dd-b689ece29475,DISK], DatanodeInfoWithStorage[127.0.0.1:33422,DS-7e40ea4d-717f-4842-bd8d-8aa2dd246866,DISK], DatanodeInfoWithStorage[127.0.0.1:36811,DS-1f546c32-03a0-4763-b66a-69e3bf1fd48a,DISK], DatanodeInfoWithStorage[127.0.0.1:37774,DS-c6039987-4cb0-4673-b878-27503ddeac49,DISK], DatanodeInfoWithStorage[127.0.0.1:46026,DS-19487289-78ff-45e6-b5d1-a170f86d1261,DISK], DatanodeInfoWithStorage[127.0.0.1:44197,DS-30988693-62ce-422f-a56b-4a91aec0ba4f,DISK], DatanodeInfoWithStorage[127.0.0.1:41844,DS-d38b89bf-04c9-49e4-889e-5cfaffb03fbe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 14 out of 50
v1v1v2v2 failed with probability 21 out of 50
result: false positive !!!
Total execution time in seconds : 5556
