reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1275367208-172.17.0.6-1595334610220:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33719,DS-a539376a-253f-47ed-a974-a7fddf45f62a,DISK], DatanodeInfoWithStorage[127.0.0.1:45910,DS-9bd6c982-fd0b-4744-94b7-92db7e01b203,DISK], DatanodeInfoWithStorage[127.0.0.1:33890,DS-a7cc7a2d-7fa8-4c67-90b3-8430ec1b4238,DISK], DatanodeInfoWithStorage[127.0.0.1:35284,DS-b84c8cac-30c8-46f0-81e0-7d0b75cdd74d,DISK], DatanodeInfoWithStorage[127.0.0.1:33112,DS-068e4948-b6a0-4fdb-aa4b-408eab48d2d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46550,DS-581d7a6d-aa5a-4d24-80f3-c366169760bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35882,DS-d101229b-a395-497f-83f7-5921b7b70d7a,DISK], DatanodeInfoWithStorage[127.0.0.1:43005,DS-81215544-ec49-4798-9870-dac28481d3d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1275367208-172.17.0.6-1595334610220:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33719,DS-a539376a-253f-47ed-a974-a7fddf45f62a,DISK], DatanodeInfoWithStorage[127.0.0.1:45910,DS-9bd6c982-fd0b-4744-94b7-92db7e01b203,DISK], DatanodeInfoWithStorage[127.0.0.1:33890,DS-a7cc7a2d-7fa8-4c67-90b3-8430ec1b4238,DISK], DatanodeInfoWithStorage[127.0.0.1:35284,DS-b84c8cac-30c8-46f0-81e0-7d0b75cdd74d,DISK], DatanodeInfoWithStorage[127.0.0.1:33112,DS-068e4948-b6a0-4fdb-aa4b-408eab48d2d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46550,DS-581d7a6d-aa5a-4d24-80f3-c366169760bd,DISK], DatanodeInfoWithStorage[127.0.0.1:35882,DS-d101229b-a395-497f-83f7-5921b7b70d7a,DISK], DatanodeInfoWithStorage[127.0.0.1:43005,DS-81215544-ec49-4798-9870-dac28481d3d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1775510175-172.17.0.6-1595334638635:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34806,DS-99cbf672-746e-4d3e-bdbb-16fc6a5c3415,DISK], DatanodeInfoWithStorage[127.0.0.1:35852,DS-94186093-977b-41e2-abc8-42cc0f326c31,DISK], DatanodeInfoWithStorage[127.0.0.1:40545,DS-427c8c4b-0cc4-41a8-8077-32867c72b611,DISK], DatanodeInfoWithStorage[127.0.0.1:42534,DS-57396b35-75bf-4154-a5f5-6fa5116f92f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36806,DS-9823c5f4-fc2f-4055-813e-21d2d7ec8c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:45927,DS-c57efb5c-7d5e-40d3-b3d6-124d2bd03fb7,DISK], DatanodeInfoWithStorage[127.0.0.1:45298,DS-09fb8a0f-5e24-46fd-bdcc-c8ab813205e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37969,DS-ff42874d-662e-43f6-bcb8-800848733623,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1775510175-172.17.0.6-1595334638635:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34806,DS-99cbf672-746e-4d3e-bdbb-16fc6a5c3415,DISK], DatanodeInfoWithStorage[127.0.0.1:35852,DS-94186093-977b-41e2-abc8-42cc0f326c31,DISK], DatanodeInfoWithStorage[127.0.0.1:40545,DS-427c8c4b-0cc4-41a8-8077-32867c72b611,DISK], DatanodeInfoWithStorage[127.0.0.1:42534,DS-57396b35-75bf-4154-a5f5-6fa5116f92f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36806,DS-9823c5f4-fc2f-4055-813e-21d2d7ec8c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:45927,DS-c57efb5c-7d5e-40d3-b3d6-124d2bd03fb7,DISK], DatanodeInfoWithStorage[127.0.0.1:45298,DS-09fb8a0f-5e24-46fd-bdcc-c8ab813205e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37969,DS-ff42874d-662e-43f6-bcb8-800848733623,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-877586566-172.17.0.6-1595334840639:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37253,DS-a655982a-9925-480e-8b3f-a693f1abaa0a,DISK], DatanodeInfoWithStorage[127.0.0.1:43952,DS-d11d5303-bc82-4387-8cb8-a7248658b158,DISK], DatanodeInfoWithStorage[127.0.0.1:41165,DS-46b25dad-41fd-480c-89b6-b5e6449d6425,DISK], DatanodeInfoWithStorage[127.0.0.1:42255,DS-0f41770e-d642-4cd2-a6a6-4c668c128d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:38192,DS-b7921d1d-7d43-4829-b369-e2af17d86afa,DISK], DatanodeInfoWithStorage[127.0.0.1:38059,DS-f2b154c0-974b-402e-ae4a-9099a5c4b355,DISK], DatanodeInfoWithStorage[127.0.0.1:40259,DS-30da36e2-4947-474e-89d9-43ed1f3552e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34650,DS-c3a6e9f6-fd69-4f0d-bf33-feba65df8af4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-877586566-172.17.0.6-1595334840639:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37253,DS-a655982a-9925-480e-8b3f-a693f1abaa0a,DISK], DatanodeInfoWithStorage[127.0.0.1:43952,DS-d11d5303-bc82-4387-8cb8-a7248658b158,DISK], DatanodeInfoWithStorage[127.0.0.1:41165,DS-46b25dad-41fd-480c-89b6-b5e6449d6425,DISK], DatanodeInfoWithStorage[127.0.0.1:42255,DS-0f41770e-d642-4cd2-a6a6-4c668c128d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:38192,DS-b7921d1d-7d43-4829-b369-e2af17d86afa,DISK], DatanodeInfoWithStorage[127.0.0.1:38059,DS-f2b154c0-974b-402e-ae4a-9099a5c4b355,DISK], DatanodeInfoWithStorage[127.0.0.1:40259,DS-30da36e2-4947-474e-89d9-43ed1f3552e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34650,DS-c3a6e9f6-fd69-4f0d-bf33-feba65df8af4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1584006368-172.17.0.6-1595335402377:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33183,DS-b1104725-88bd-4a97-850f-3d267dcf1291,DISK], DatanodeInfoWithStorage[127.0.0.1:44022,DS-63fc3537-a8ca-4acb-b6f3-06a3ac516e18,DISK], DatanodeInfoWithStorage[127.0.0.1:33859,DS-514a4872-363f-43d0-805b-5bd0a6b7a53f,DISK], DatanodeInfoWithStorage[127.0.0.1:39744,DS-7e5f31a7-4553-434d-aa06-4843e2d04d22,DISK], DatanodeInfoWithStorage[127.0.0.1:43999,DS-dc48a4f5-2227-4cb8-b763-309164e5c934,DISK], DatanodeInfoWithStorage[127.0.0.1:46862,DS-909bed47-e7f9-4ec2-b85d-b925c05b43bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42420,DS-b95423bf-ebaf-43a5-9137-47c40c9d588f,DISK], DatanodeInfoWithStorage[127.0.0.1:32844,DS-9927d45c-71f3-4efc-9257-01191265c984,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1584006368-172.17.0.6-1595335402377:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33183,DS-b1104725-88bd-4a97-850f-3d267dcf1291,DISK], DatanodeInfoWithStorage[127.0.0.1:44022,DS-63fc3537-a8ca-4acb-b6f3-06a3ac516e18,DISK], DatanodeInfoWithStorage[127.0.0.1:33859,DS-514a4872-363f-43d0-805b-5bd0a6b7a53f,DISK], DatanodeInfoWithStorage[127.0.0.1:39744,DS-7e5f31a7-4553-434d-aa06-4843e2d04d22,DISK], DatanodeInfoWithStorage[127.0.0.1:43999,DS-dc48a4f5-2227-4cb8-b763-309164e5c934,DISK], DatanodeInfoWithStorage[127.0.0.1:46862,DS-909bed47-e7f9-4ec2-b85d-b925c05b43bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42420,DS-b95423bf-ebaf-43a5-9137-47c40c9d588f,DISK], DatanodeInfoWithStorage[127.0.0.1:32844,DS-9927d45c-71f3-4efc-9257-01191265c984,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-408003834-172.17.0.6-1595335738259:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38878,DS-be3bdc35-178d-420d-b5b0-046e76eeb8c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35094,DS-6d9d0833-d9da-47f1-a35e-03cb258d3ee4,DISK], DatanodeInfoWithStorage[127.0.0.1:46305,DS-f613b907-1552-4ede-a178-7e0c689e9d99,DISK], DatanodeInfoWithStorage[127.0.0.1:40257,DS-1ff01d83-8ab6-4e83-b8fd-fcdff9570813,DISK], DatanodeInfoWithStorage[127.0.0.1:36750,DS-76c903e1-712f-4c56-b9a3-2bdc69644471,DISK], DatanodeInfoWithStorage[127.0.0.1:41312,DS-dc501a10-0d49-4ea3-a005-9481497fe749,DISK], DatanodeInfoWithStorage[127.0.0.1:36076,DS-b4bb2602-97c6-4377-8d28-218a44662908,DISK], DatanodeInfoWithStorage[127.0.0.1:37096,DS-e2bc8a51-d7bf-4140-91a5-700c7934ef1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-408003834-172.17.0.6-1595335738259:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38878,DS-be3bdc35-178d-420d-b5b0-046e76eeb8c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35094,DS-6d9d0833-d9da-47f1-a35e-03cb258d3ee4,DISK], DatanodeInfoWithStorage[127.0.0.1:46305,DS-f613b907-1552-4ede-a178-7e0c689e9d99,DISK], DatanodeInfoWithStorage[127.0.0.1:40257,DS-1ff01d83-8ab6-4e83-b8fd-fcdff9570813,DISK], DatanodeInfoWithStorage[127.0.0.1:36750,DS-76c903e1-712f-4c56-b9a3-2bdc69644471,DISK], DatanodeInfoWithStorage[127.0.0.1:41312,DS-dc501a10-0d49-4ea3-a005-9481497fe749,DISK], DatanodeInfoWithStorage[127.0.0.1:36076,DS-b4bb2602-97c6-4377-8d28-218a44662908,DISK], DatanodeInfoWithStorage[127.0.0.1:37096,DS-e2bc8a51-d7bf-4140-91a5-700c7934ef1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1121308759-172.17.0.6-1595335773986:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35188,DS-bad7fa94-a0b2-42ed-923d-da0dbdd300de,DISK], DatanodeInfoWithStorage[127.0.0.1:37824,DS-51871734-3c70-47a5-8933-d6cf0ee71d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:36490,DS-b7fd4d4a-ba2c-436f-b808-1c4db509a254,DISK], DatanodeInfoWithStorage[127.0.0.1:39649,DS-e16cd0ca-c6fe-45eb-8318-d7c21b09a048,DISK], DatanodeInfoWithStorage[127.0.0.1:37135,DS-7c49896e-f482-4f30-ab2a-7542f9e2375e,DISK], DatanodeInfoWithStorage[127.0.0.1:41497,DS-114d51f4-4410-45eb-9695-1d4309653494,DISK], DatanodeInfoWithStorage[127.0.0.1:43022,DS-c0961dcb-aeaf-468f-a2db-73986858691a,DISK], DatanodeInfoWithStorage[127.0.0.1:34951,DS-7d1f70d7-b6ce-429b-a178-f30296200fca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1121308759-172.17.0.6-1595335773986:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35188,DS-bad7fa94-a0b2-42ed-923d-da0dbdd300de,DISK], DatanodeInfoWithStorage[127.0.0.1:37824,DS-51871734-3c70-47a5-8933-d6cf0ee71d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:36490,DS-b7fd4d4a-ba2c-436f-b808-1c4db509a254,DISK], DatanodeInfoWithStorage[127.0.0.1:39649,DS-e16cd0ca-c6fe-45eb-8318-d7c21b09a048,DISK], DatanodeInfoWithStorage[127.0.0.1:37135,DS-7c49896e-f482-4f30-ab2a-7542f9e2375e,DISK], DatanodeInfoWithStorage[127.0.0.1:41497,DS-114d51f4-4410-45eb-9695-1d4309653494,DISK], DatanodeInfoWithStorage[127.0.0.1:43022,DS-c0961dcb-aeaf-468f-a2db-73986858691a,DISK], DatanodeInfoWithStorage[127.0.0.1:34951,DS-7d1f70d7-b6ce-429b-a178-f30296200fca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1150140818-172.17.0.6-1595335889367:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40454,DS-325f55e9-266a-46b2-a43d-02e24995220b,DISK], DatanodeInfoWithStorage[127.0.0.1:37989,DS-fd42c342-2d73-45a3-9622-d69a4574cccf,DISK], DatanodeInfoWithStorage[127.0.0.1:35662,DS-96c09b0d-9aa5-4869-9ae5-80bc84930d92,DISK], DatanodeInfoWithStorage[127.0.0.1:37915,DS-8f8f1a9c-1d36-48d3-82ae-a56ce79a08fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45574,DS-7a9ac02a-03e5-44d6-8ad5-bb69c5fc504b,DISK], DatanodeInfoWithStorage[127.0.0.1:46093,DS-80e90a26-f440-4a93-99b0-faeb4dadf58a,DISK], DatanodeInfoWithStorage[127.0.0.1:39789,DS-f4ff40cb-a711-44ca-ac7f-c8213139e170,DISK], DatanodeInfoWithStorage[127.0.0.1:43026,DS-6929f119-41c1-44cf-b5c7-8e10e4a88e0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1150140818-172.17.0.6-1595335889367:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40454,DS-325f55e9-266a-46b2-a43d-02e24995220b,DISK], DatanodeInfoWithStorage[127.0.0.1:37989,DS-fd42c342-2d73-45a3-9622-d69a4574cccf,DISK], DatanodeInfoWithStorage[127.0.0.1:35662,DS-96c09b0d-9aa5-4869-9ae5-80bc84930d92,DISK], DatanodeInfoWithStorage[127.0.0.1:37915,DS-8f8f1a9c-1d36-48d3-82ae-a56ce79a08fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45574,DS-7a9ac02a-03e5-44d6-8ad5-bb69c5fc504b,DISK], DatanodeInfoWithStorage[127.0.0.1:46093,DS-80e90a26-f440-4a93-99b0-faeb4dadf58a,DISK], DatanodeInfoWithStorage[127.0.0.1:39789,DS-f4ff40cb-a711-44ca-ac7f-c8213139e170,DISK], DatanodeInfoWithStorage[127.0.0.1:43026,DS-6929f119-41c1-44cf-b5c7-8e10e4a88e0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2104316391-172.17.0.6-1595336006079:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41969,DS-aa73ed4b-6a97-48c7-8c53-2f738379b2cb,DISK], DatanodeInfoWithStorage[127.0.0.1:44912,DS-09d2856e-9b0f-46ed-bec9-6c45a54dfbb7,DISK], DatanodeInfoWithStorage[127.0.0.1:40285,DS-b8a8b1a3-762e-4a9f-b45d-09c4adda210b,DISK], DatanodeInfoWithStorage[127.0.0.1:39305,DS-e637963e-4aaa-42a0-ae97-be554b31426e,DISK], DatanodeInfoWithStorage[127.0.0.1:46103,DS-6a5f07ec-5652-4bb8-a11b-2226c12bdb96,DISK], DatanodeInfoWithStorage[127.0.0.1:35630,DS-46e6fe5c-df45-42ba-bdf9-3d5a5798bde1,DISK], DatanodeInfoWithStorage[127.0.0.1:40498,DS-fc174346-cdf3-4586-92c9-013d07c608f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34553,DS-d5152a88-9ee0-4b16-aaa0-be5581891ff7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2104316391-172.17.0.6-1595336006079:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41969,DS-aa73ed4b-6a97-48c7-8c53-2f738379b2cb,DISK], DatanodeInfoWithStorage[127.0.0.1:44912,DS-09d2856e-9b0f-46ed-bec9-6c45a54dfbb7,DISK], DatanodeInfoWithStorage[127.0.0.1:40285,DS-b8a8b1a3-762e-4a9f-b45d-09c4adda210b,DISK], DatanodeInfoWithStorage[127.0.0.1:39305,DS-e637963e-4aaa-42a0-ae97-be554b31426e,DISK], DatanodeInfoWithStorage[127.0.0.1:46103,DS-6a5f07ec-5652-4bb8-a11b-2226c12bdb96,DISK], DatanodeInfoWithStorage[127.0.0.1:35630,DS-46e6fe5c-df45-42ba-bdf9-3d5a5798bde1,DISK], DatanodeInfoWithStorage[127.0.0.1:40498,DS-fc174346-cdf3-4586-92c9-013d07c608f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34553,DS-d5152a88-9ee0-4b16-aaa0-be5581891ff7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1081332919-172.17.0.6-1595336829142:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41473,DS-bf6f8c80-5dd2-4083-b41e-d7c35b18180b,DISK], DatanodeInfoWithStorage[127.0.0.1:38238,DS-3c20577c-44e0-40ca-a29f-0695604df570,DISK], DatanodeInfoWithStorage[127.0.0.1:38916,DS-b2f35d16-7ec2-428e-91c9-0b34bc77d665,DISK], DatanodeInfoWithStorage[127.0.0.1:41962,DS-8437247b-2019-42ab-bda4-e421c65b257b,DISK], DatanodeInfoWithStorage[127.0.0.1:35392,DS-484b8cdc-f7a2-4d13-864f-d91676474f13,DISK], DatanodeInfoWithStorage[127.0.0.1:34630,DS-269f9b41-bac5-4b83-bb07-a073d143e7d5,DISK], DatanodeInfoWithStorage[127.0.0.1:37480,DS-b04b568b-f9e2-4aa0-852f-14a74f03ff56,DISK], DatanodeInfoWithStorage[127.0.0.1:41572,DS-474256d8-000c-420a-b9db-af9c47803e0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1081332919-172.17.0.6-1595336829142:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41473,DS-bf6f8c80-5dd2-4083-b41e-d7c35b18180b,DISK], DatanodeInfoWithStorage[127.0.0.1:38238,DS-3c20577c-44e0-40ca-a29f-0695604df570,DISK], DatanodeInfoWithStorage[127.0.0.1:38916,DS-b2f35d16-7ec2-428e-91c9-0b34bc77d665,DISK], DatanodeInfoWithStorage[127.0.0.1:41962,DS-8437247b-2019-42ab-bda4-e421c65b257b,DISK], DatanodeInfoWithStorage[127.0.0.1:35392,DS-484b8cdc-f7a2-4d13-864f-d91676474f13,DISK], DatanodeInfoWithStorage[127.0.0.1:34630,DS-269f9b41-bac5-4b83-bb07-a073d143e7d5,DISK], DatanodeInfoWithStorage[127.0.0.1:37480,DS-b04b568b-f9e2-4aa0-852f-14a74f03ff56,DISK], DatanodeInfoWithStorage[127.0.0.1:41572,DS-474256d8-000c-420a-b9db-af9c47803e0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1749347882-172.17.0.6-1595337208381:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42138,DS-2b778340-9ffd-4691-a8dc-da916b3a18c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37832,DS-fa728a2e-a84c-42e7-aa52-3ee01e312281,DISK], DatanodeInfoWithStorage[127.0.0.1:34039,DS-bc60b1a4-364e-4f45-933f-36c8ae1f0731,DISK], DatanodeInfoWithStorage[127.0.0.1:43682,DS-c3fa3633-86b9-4301-a087-8444e1127943,DISK], DatanodeInfoWithStorage[127.0.0.1:35260,DS-bc3c3aff-f72d-4885-bcf5-e39ab56fe90e,DISK], DatanodeInfoWithStorage[127.0.0.1:39114,DS-cc010117-017e-401e-ab7f-5815f7fc12ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45116,DS-e08bbe6b-d9c9-4152-82c7-9626272b8785,DISK], DatanodeInfoWithStorage[127.0.0.1:39928,DS-aa3a8725-714a-41ce-a051-7b798ac0bccc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1749347882-172.17.0.6-1595337208381:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42138,DS-2b778340-9ffd-4691-a8dc-da916b3a18c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37832,DS-fa728a2e-a84c-42e7-aa52-3ee01e312281,DISK], DatanodeInfoWithStorage[127.0.0.1:34039,DS-bc60b1a4-364e-4f45-933f-36c8ae1f0731,DISK], DatanodeInfoWithStorage[127.0.0.1:43682,DS-c3fa3633-86b9-4301-a087-8444e1127943,DISK], DatanodeInfoWithStorage[127.0.0.1:35260,DS-bc3c3aff-f72d-4885-bcf5-e39ab56fe90e,DISK], DatanodeInfoWithStorage[127.0.0.1:39114,DS-cc010117-017e-401e-ab7f-5815f7fc12ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45116,DS-e08bbe6b-d9c9-4152-82c7-9626272b8785,DISK], DatanodeInfoWithStorage[127.0.0.1:39928,DS-aa3a8725-714a-41ce-a051-7b798ac0bccc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-929741402-172.17.0.6-1595337279863:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43807,DS-ffdea3fd-dcea-4950-a796-73401be0825c,DISK], DatanodeInfoWithStorage[127.0.0.1:38995,DS-a8054f8f-2b2a-40e9-9d4b-c0df9ad7f513,DISK], DatanodeInfoWithStorage[127.0.0.1:36120,DS-9440b2a3-4395-409f-8832-47b0c990c5ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41676,DS-0b04ea1e-f2d1-437c-a1ed-c640b3966ad0,DISK], DatanodeInfoWithStorage[127.0.0.1:39932,DS-ba4cc7e6-6c4f-4436-9c1b-a61a7eaa6a38,DISK], DatanodeInfoWithStorage[127.0.0.1:37707,DS-b8fb1e8a-e14e-4416-8cde-9fe6e7953fe9,DISK], DatanodeInfoWithStorage[127.0.0.1:40231,DS-1ba6928d-d39c-417f-a1db-773f79c259a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35126,DS-6f72bc02-a97c-461c-bf2a-c3d686a17021,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-929741402-172.17.0.6-1595337279863:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43807,DS-ffdea3fd-dcea-4950-a796-73401be0825c,DISK], DatanodeInfoWithStorage[127.0.0.1:38995,DS-a8054f8f-2b2a-40e9-9d4b-c0df9ad7f513,DISK], DatanodeInfoWithStorage[127.0.0.1:36120,DS-9440b2a3-4395-409f-8832-47b0c990c5ec,DISK], DatanodeInfoWithStorage[127.0.0.1:41676,DS-0b04ea1e-f2d1-437c-a1ed-c640b3966ad0,DISK], DatanodeInfoWithStorage[127.0.0.1:39932,DS-ba4cc7e6-6c4f-4436-9c1b-a61a7eaa6a38,DISK], DatanodeInfoWithStorage[127.0.0.1:37707,DS-b8fb1e8a-e14e-4416-8cde-9fe6e7953fe9,DISK], DatanodeInfoWithStorage[127.0.0.1:40231,DS-1ba6928d-d39c-417f-a1db-773f79c259a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35126,DS-6f72bc02-a97c-461c-bf2a-c3d686a17021,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1462911004-172.17.0.6-1595337428860:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41958,DS-31acf8fa-fb4d-4a70-b18e-b644174a2590,DISK], DatanodeInfoWithStorage[127.0.0.1:42708,DS-96782f86-77d0-4315-be17-523cb75263a4,DISK], DatanodeInfoWithStorage[127.0.0.1:46265,DS-64cdb00c-e63b-457e-bf45-1179d84f242d,DISK], DatanodeInfoWithStorage[127.0.0.1:44897,DS-ad7c241c-fa25-4d0e-a4b7-219d6d72fc8f,DISK], DatanodeInfoWithStorage[127.0.0.1:42576,DS-f91f6969-3643-434e-ab90-4e26f09bbe0e,DISK], DatanodeInfoWithStorage[127.0.0.1:46514,DS-7d5eca6c-69ec-4c18-9900-4c439d61c773,DISK], DatanodeInfoWithStorage[127.0.0.1:45533,DS-de6a51fe-f544-4c36-afcb-d169194a60bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34407,DS-aaac9985-0082-47a4-a725-cc7f434ef724,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1462911004-172.17.0.6-1595337428860:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41958,DS-31acf8fa-fb4d-4a70-b18e-b644174a2590,DISK], DatanodeInfoWithStorage[127.0.0.1:42708,DS-96782f86-77d0-4315-be17-523cb75263a4,DISK], DatanodeInfoWithStorage[127.0.0.1:46265,DS-64cdb00c-e63b-457e-bf45-1179d84f242d,DISK], DatanodeInfoWithStorage[127.0.0.1:44897,DS-ad7c241c-fa25-4d0e-a4b7-219d6d72fc8f,DISK], DatanodeInfoWithStorage[127.0.0.1:42576,DS-f91f6969-3643-434e-ab90-4e26f09bbe0e,DISK], DatanodeInfoWithStorage[127.0.0.1:46514,DS-7d5eca6c-69ec-4c18-9900-4c439d61c773,DISK], DatanodeInfoWithStorage[127.0.0.1:45533,DS-de6a51fe-f544-4c36-afcb-d169194a60bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34407,DS-aaac9985-0082-47a4-a725-cc7f434ef724,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1715555176-172.17.0.6-1595337916067:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39068,DS-d561d472-1420-4d30-bc23-1120786ff0a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36035,DS-d05a835e-7587-40e9-8c51-88ff7daf2b70,DISK], DatanodeInfoWithStorage[127.0.0.1:38737,DS-5289cbd7-3870-4835-8371-36ea11f9f382,DISK], DatanodeInfoWithStorage[127.0.0.1:39062,DS-37db2ef1-7dea-4888-b680-198f77bed42f,DISK], DatanodeInfoWithStorage[127.0.0.1:42959,DS-bc134e30-7c3b-426b-a213-583e09419b64,DISK], DatanodeInfoWithStorage[127.0.0.1:45311,DS-94903163-f503-471a-a5de-538930b643c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39057,DS-ca295616-9ede-4af3-b047-ab4038ed0c36,DISK], DatanodeInfoWithStorage[127.0.0.1:39957,DS-dba544c7-e518-4366-b51e-50991a9f0644,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1715555176-172.17.0.6-1595337916067:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39068,DS-d561d472-1420-4d30-bc23-1120786ff0a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36035,DS-d05a835e-7587-40e9-8c51-88ff7daf2b70,DISK], DatanodeInfoWithStorage[127.0.0.1:38737,DS-5289cbd7-3870-4835-8371-36ea11f9f382,DISK], DatanodeInfoWithStorage[127.0.0.1:39062,DS-37db2ef1-7dea-4888-b680-198f77bed42f,DISK], DatanodeInfoWithStorage[127.0.0.1:42959,DS-bc134e30-7c3b-426b-a213-583e09419b64,DISK], DatanodeInfoWithStorage[127.0.0.1:45311,DS-94903163-f503-471a-a5de-538930b643c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39057,DS-ca295616-9ede-4af3-b047-ab4038ed0c36,DISK], DatanodeInfoWithStorage[127.0.0.1:39957,DS-dba544c7-e518-4366-b51e-50991a9f0644,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1663580153-172.17.0.6-1595337949642:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37240,DS-89508d6d-390c-409a-a8b6-a6082f5b82ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45268,DS-877ef77b-eced-4e72-b40e-3703d2e76ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:38169,DS-fc1710e7-9ee0-46a9-91ff-05bc5275de37,DISK], DatanodeInfoWithStorage[127.0.0.1:45076,DS-0159d16d-182a-4f5d-a706-fa4b6fb1cf5a,DISK], DatanodeInfoWithStorage[127.0.0.1:38528,DS-70ce1c67-d8fa-4c86-a555-345275d3065a,DISK], DatanodeInfoWithStorage[127.0.0.1:41193,DS-b0702be7-d3d5-4904-8b17-efad52f6624a,DISK], DatanodeInfoWithStorage[127.0.0.1:44872,DS-36b56f31-5caa-4a44-9264-e2ec3142faf8,DISK], DatanodeInfoWithStorage[127.0.0.1:43692,DS-3865dd0c-7e8e-473a-973c-ebab982d5eff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1663580153-172.17.0.6-1595337949642:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37240,DS-89508d6d-390c-409a-a8b6-a6082f5b82ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45268,DS-877ef77b-eced-4e72-b40e-3703d2e76ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:38169,DS-fc1710e7-9ee0-46a9-91ff-05bc5275de37,DISK], DatanodeInfoWithStorage[127.0.0.1:45076,DS-0159d16d-182a-4f5d-a706-fa4b6fb1cf5a,DISK], DatanodeInfoWithStorage[127.0.0.1:38528,DS-70ce1c67-d8fa-4c86-a555-345275d3065a,DISK], DatanodeInfoWithStorage[127.0.0.1:41193,DS-b0702be7-d3d5-4904-8b17-efad52f6624a,DISK], DatanodeInfoWithStorage[127.0.0.1:44872,DS-36b56f31-5caa-4a44-9264-e2ec3142faf8,DISK], DatanodeInfoWithStorage[127.0.0.1:43692,DS-3865dd0c-7e8e-473a-973c-ebab982d5eff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1763305342-172.17.0.6-1595338320019:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38932,DS-0ea3d731-976d-4821-aec9-993aa16fb676,DISK], DatanodeInfoWithStorage[127.0.0.1:35892,DS-4fa7c9d8-aeef-42d9-a099-0b6ec571f1dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37187,DS-aa441f5c-fcf6-45b6-8fb6-15fce956fb73,DISK], DatanodeInfoWithStorage[127.0.0.1:43068,DS-75f1ec85-78e3-42b6-b67a-9ab90597b6f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44541,DS-ec17385d-d9ce-46c2-a517-4e53acbaf41c,DISK], DatanodeInfoWithStorage[127.0.0.1:42678,DS-e24ab3ce-b132-4799-a870-56d5ffcb3f22,DISK], DatanodeInfoWithStorage[127.0.0.1:37798,DS-df29c28f-fd63-4eed-94e1-831379199c13,DISK], DatanodeInfoWithStorage[127.0.0.1:44325,DS-acfa035f-b46a-475c-b9d8-1f56db48fc6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1763305342-172.17.0.6-1595338320019:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38932,DS-0ea3d731-976d-4821-aec9-993aa16fb676,DISK], DatanodeInfoWithStorage[127.0.0.1:35892,DS-4fa7c9d8-aeef-42d9-a099-0b6ec571f1dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37187,DS-aa441f5c-fcf6-45b6-8fb6-15fce956fb73,DISK], DatanodeInfoWithStorage[127.0.0.1:43068,DS-75f1ec85-78e3-42b6-b67a-9ab90597b6f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44541,DS-ec17385d-d9ce-46c2-a517-4e53acbaf41c,DISK], DatanodeInfoWithStorage[127.0.0.1:42678,DS-e24ab3ce-b132-4799-a870-56d5ffcb3f22,DISK], DatanodeInfoWithStorage[127.0.0.1:37798,DS-df29c28f-fd63-4eed-94e1-831379199c13,DISK], DatanodeInfoWithStorage[127.0.0.1:44325,DS-acfa035f-b46a-475c-b9d8-1f56db48fc6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1188200629-172.17.0.6-1595338854928:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42254,DS-bffd3bf6-1645-42c5-8e44-bd065d61772d,DISK], DatanodeInfoWithStorage[127.0.0.1:46571,DS-03ccf231-8cc6-4b6b-8ca7-97493e705850,DISK], DatanodeInfoWithStorage[127.0.0.1:32876,DS-fe87e3de-30b4-4a48-a834-5295cc1cf478,DISK], DatanodeInfoWithStorage[127.0.0.1:44556,DS-3876e765-bf74-4ef7-8447-dc3e76fdb7cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43268,DS-8b095e76-15dc-4745-bbc1-98d5a894f9a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44147,DS-9d2d802a-0ddb-46f7-8165-20a08b8e7961,DISK], DatanodeInfoWithStorage[127.0.0.1:41687,DS-cfdcddff-0bef-4323-a0cc-bf9aea9500ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41965,DS-b3da6832-0314-4943-9b39-a40bfda13891,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1188200629-172.17.0.6-1595338854928:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42254,DS-bffd3bf6-1645-42c5-8e44-bd065d61772d,DISK], DatanodeInfoWithStorage[127.0.0.1:46571,DS-03ccf231-8cc6-4b6b-8ca7-97493e705850,DISK], DatanodeInfoWithStorage[127.0.0.1:32876,DS-fe87e3de-30b4-4a48-a834-5295cc1cf478,DISK], DatanodeInfoWithStorage[127.0.0.1:44556,DS-3876e765-bf74-4ef7-8447-dc3e76fdb7cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43268,DS-8b095e76-15dc-4745-bbc1-98d5a894f9a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44147,DS-9d2d802a-0ddb-46f7-8165-20a08b8e7961,DISK], DatanodeInfoWithStorage[127.0.0.1:41687,DS-cfdcddff-0bef-4323-a0cc-bf9aea9500ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41965,DS-b3da6832-0314-4943-9b39-a40bfda13891,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1492600670-172.17.0.6-1595339127826:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35677,DS-6694d21c-63cf-4ad5-871e-43bf0b28f8d2,DISK], DatanodeInfoWithStorage[127.0.0.1:37003,DS-be9f711c-0e8b-463f-888b-c7d11f8febff,DISK], DatanodeInfoWithStorage[127.0.0.1:39812,DS-34085a5b-cba6-4bbe-9a2c-1cf8f54a7d7c,DISK], DatanodeInfoWithStorage[127.0.0.1:42320,DS-73bce611-e361-4d67-b024-5c23a429ff99,DISK], DatanodeInfoWithStorage[127.0.0.1:35360,DS-5c723d40-f5c9-44c6-832c-2a4a7a23084a,DISK], DatanodeInfoWithStorage[127.0.0.1:46664,DS-dcf450e2-eb7c-413c-ad63-4b2f157cffa4,DISK], DatanodeInfoWithStorage[127.0.0.1:33686,DS-2e3a24eb-c38f-45fd-b8be-7fbfb58c5576,DISK], DatanodeInfoWithStorage[127.0.0.1:34748,DS-405fb5b4-03e6-4af7-bad0-54c73d852d88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1492600670-172.17.0.6-1595339127826:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35677,DS-6694d21c-63cf-4ad5-871e-43bf0b28f8d2,DISK], DatanodeInfoWithStorage[127.0.0.1:37003,DS-be9f711c-0e8b-463f-888b-c7d11f8febff,DISK], DatanodeInfoWithStorage[127.0.0.1:39812,DS-34085a5b-cba6-4bbe-9a2c-1cf8f54a7d7c,DISK], DatanodeInfoWithStorage[127.0.0.1:42320,DS-73bce611-e361-4d67-b024-5c23a429ff99,DISK], DatanodeInfoWithStorage[127.0.0.1:35360,DS-5c723d40-f5c9-44c6-832c-2a4a7a23084a,DISK], DatanodeInfoWithStorage[127.0.0.1:46664,DS-dcf450e2-eb7c-413c-ad63-4b2f157cffa4,DISK], DatanodeInfoWithStorage[127.0.0.1:33686,DS-2e3a24eb-c38f-45fd-b8be-7fbfb58c5576,DISK], DatanodeInfoWithStorage[127.0.0.1:34748,DS-405fb5b4-03e6-4af7-bad0-54c73d852d88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5396
