reconf_parameter: dfs.namenode.edits.asynclogging
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.asynclogging
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1305077200-172.17.0.20-1595412487672:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32985,DS-a3b0efb0-a65f-4faa-9b32-24e0d208cb87,DISK], DatanodeInfoWithStorage[127.0.0.1:42993,DS-add6956f-f6f1-4669-b4aa-5b3923f4790d,DISK], DatanodeInfoWithStorage[127.0.0.1:36481,DS-8fdf015e-6e36-4c5a-88b9-816a1d964915,DISK], DatanodeInfoWithStorage[127.0.0.1:37204,DS-4d439aa7-111d-4911-87bb-5d78e6591ec7,DISK], DatanodeInfoWithStorage[127.0.0.1:44416,DS-80e5b617-193a-428f-a4c3-a033fb96cd5e,DISK], DatanodeInfoWithStorage[127.0.0.1:41183,DS-3de862a3-63d4-4b1a-8238-7955dc668a6f,DISK], DatanodeInfoWithStorage[127.0.0.1:36125,DS-ec40ef39-a7af-4a91-bab8-3d101948a23f,DISK], DatanodeInfoWithStorage[127.0.0.1:37837,DS-675c4a80-43fc-4d4d-a761-6b7536c4069c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1305077200-172.17.0.20-1595412487672:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32985,DS-a3b0efb0-a65f-4faa-9b32-24e0d208cb87,DISK], DatanodeInfoWithStorage[127.0.0.1:42993,DS-add6956f-f6f1-4669-b4aa-5b3923f4790d,DISK], DatanodeInfoWithStorage[127.0.0.1:36481,DS-8fdf015e-6e36-4c5a-88b9-816a1d964915,DISK], DatanodeInfoWithStorage[127.0.0.1:37204,DS-4d439aa7-111d-4911-87bb-5d78e6591ec7,DISK], DatanodeInfoWithStorage[127.0.0.1:44416,DS-80e5b617-193a-428f-a4c3-a033fb96cd5e,DISK], DatanodeInfoWithStorage[127.0.0.1:41183,DS-3de862a3-63d4-4b1a-8238-7955dc668a6f,DISK], DatanodeInfoWithStorage[127.0.0.1:36125,DS-ec40ef39-a7af-4a91-bab8-3d101948a23f,DISK], DatanodeInfoWithStorage[127.0.0.1:37837,DS-675c4a80-43fc-4d4d-a761-6b7536c4069c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.asynclogging
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-845670044-172.17.0.20-1595412811220:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34782,DS-d1d86d6a-13d1-4dd0-89d5-edc4ebd98a33,DISK], DatanodeInfoWithStorage[127.0.0.1:41507,DS-8756bbf6-51dd-42c7-9713-eff65f198e19,DISK], DatanodeInfoWithStorage[127.0.0.1:34468,DS-181bed57-4e0f-44d5-a2da-919a1a4da592,DISK], DatanodeInfoWithStorage[127.0.0.1:38364,DS-2cfad4e2-8731-4059-abe9-aae4ee080747,DISK], DatanodeInfoWithStorage[127.0.0.1:35041,DS-1eb44881-9de0-4e24-8711-d934d6ec71cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40397,DS-8815e6f1-376a-4631-9d7a-9f2ef0960812,DISK], DatanodeInfoWithStorage[127.0.0.1:40669,DS-62ce934d-f72a-460c-9a74-e59438418465,DISK], DatanodeInfoWithStorage[127.0.0.1:35471,DS-702dd7ce-abea-413c-8151-5b3a6531fb15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-845670044-172.17.0.20-1595412811220:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34782,DS-d1d86d6a-13d1-4dd0-89d5-edc4ebd98a33,DISK], DatanodeInfoWithStorage[127.0.0.1:41507,DS-8756bbf6-51dd-42c7-9713-eff65f198e19,DISK], DatanodeInfoWithStorage[127.0.0.1:34468,DS-181bed57-4e0f-44d5-a2da-919a1a4da592,DISK], DatanodeInfoWithStorage[127.0.0.1:38364,DS-2cfad4e2-8731-4059-abe9-aae4ee080747,DISK], DatanodeInfoWithStorage[127.0.0.1:35041,DS-1eb44881-9de0-4e24-8711-d934d6ec71cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40397,DS-8815e6f1-376a-4631-9d7a-9f2ef0960812,DISK], DatanodeInfoWithStorage[127.0.0.1:40669,DS-62ce934d-f72a-460c-9a74-e59438418465,DISK], DatanodeInfoWithStorage[127.0.0.1:35471,DS-702dd7ce-abea-413c-8151-5b3a6531fb15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.asynclogging
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-565394118-172.17.0.20-1595413433096:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38514,DS-bbc86bb2-7c8e-4f4a-b956-077f3bc71435,DISK], DatanodeInfoWithStorage[127.0.0.1:46097,DS-0b4b2347-4e67-4462-8d48-952a5ae2589d,DISK], DatanodeInfoWithStorage[127.0.0.1:35047,DS-98b4087b-f4b1-464d-9df5-b23f72edf774,DISK], DatanodeInfoWithStorage[127.0.0.1:35711,DS-87f6b78b-b332-470b-99d3-b52aa7fd50c8,DISK], DatanodeInfoWithStorage[127.0.0.1:46592,DS-a523acda-8e9d-45a1-b830-5accfe5189e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38526,DS-b7051b9c-7b24-4e1c-965c-8a6415a4b840,DISK], DatanodeInfoWithStorage[127.0.0.1:35124,DS-472567a5-1dd8-4b38-8389-ca2382a0309a,DISK], DatanodeInfoWithStorage[127.0.0.1:38737,DS-4e6a0185-3fe3-49b5-84cf-5574e1a0ca6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-565394118-172.17.0.20-1595413433096:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38514,DS-bbc86bb2-7c8e-4f4a-b956-077f3bc71435,DISK], DatanodeInfoWithStorage[127.0.0.1:46097,DS-0b4b2347-4e67-4462-8d48-952a5ae2589d,DISK], DatanodeInfoWithStorage[127.0.0.1:35047,DS-98b4087b-f4b1-464d-9df5-b23f72edf774,DISK], DatanodeInfoWithStorage[127.0.0.1:35711,DS-87f6b78b-b332-470b-99d3-b52aa7fd50c8,DISK], DatanodeInfoWithStorage[127.0.0.1:46592,DS-a523acda-8e9d-45a1-b830-5accfe5189e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38526,DS-b7051b9c-7b24-4e1c-965c-8a6415a4b840,DISK], DatanodeInfoWithStorage[127.0.0.1:35124,DS-472567a5-1dd8-4b38-8389-ca2382a0309a,DISK], DatanodeInfoWithStorage[127.0.0.1:38737,DS-4e6a0185-3fe3-49b5-84cf-5574e1a0ca6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.asynclogging
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-35317254-172.17.0.20-1595414012840:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36796,DS-06a5fb06-966e-409f-b968-a38d26799539,DISK], DatanodeInfoWithStorage[127.0.0.1:35985,DS-e4fcf0d5-b7ea-47a2-ba08-a36d5a3543da,DISK], DatanodeInfoWithStorage[127.0.0.1:40880,DS-1d66d2ae-1dfe-4708-80c5-e9acc75eb8a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35074,DS-24908843-adca-420f-be95-d8559506a6ba,DISK], DatanodeInfoWithStorage[127.0.0.1:37750,DS-f7c4f7d5-f285-4aef-8be1-39cf3f8d983e,DISK], DatanodeInfoWithStorage[127.0.0.1:39079,DS-601b0b54-2550-457e-9cb7-9d96f859083a,DISK], DatanodeInfoWithStorage[127.0.0.1:33793,DS-ed1b83d1-5129-4ba2-9688-57b368a03830,DISK], DatanodeInfoWithStorage[127.0.0.1:39959,DS-b77b6109-fa2a-425c-a7a5-2d24d99cdb50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-35317254-172.17.0.20-1595414012840:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36796,DS-06a5fb06-966e-409f-b968-a38d26799539,DISK], DatanodeInfoWithStorage[127.0.0.1:35985,DS-e4fcf0d5-b7ea-47a2-ba08-a36d5a3543da,DISK], DatanodeInfoWithStorage[127.0.0.1:40880,DS-1d66d2ae-1dfe-4708-80c5-e9acc75eb8a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35074,DS-24908843-adca-420f-be95-d8559506a6ba,DISK], DatanodeInfoWithStorage[127.0.0.1:37750,DS-f7c4f7d5-f285-4aef-8be1-39cf3f8d983e,DISK], DatanodeInfoWithStorage[127.0.0.1:39079,DS-601b0b54-2550-457e-9cb7-9d96f859083a,DISK], DatanodeInfoWithStorage[127.0.0.1:33793,DS-ed1b83d1-5129-4ba2-9688-57b368a03830,DISK], DatanodeInfoWithStorage[127.0.0.1:39959,DS-b77b6109-fa2a-425c-a7a5-2d24d99cdb50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.asynclogging
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-718803259-172.17.0.20-1595414121461:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44434,DS-b2e6ed55-332e-47e3-bf63-c91f3826007b,DISK], DatanodeInfoWithStorage[127.0.0.1:42508,DS-dd500dc7-54e2-4b36-846b-efcaf22393d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45313,DS-393325d1-796a-42d0-9505-27410a001275,DISK], DatanodeInfoWithStorage[127.0.0.1:36406,DS-961be691-8c88-4041-bc88-e038b3552e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:41940,DS-2e336ffc-452e-4124-b64a-4ab49db5b1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37888,DS-d9f91f83-e6ed-4e41-8e30-8c4ce58415c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33882,DS-7d4b27cf-1342-4c9d-a569-acc687db0788,DISK], DatanodeInfoWithStorage[127.0.0.1:40428,DS-de208c63-d779-4f49-a2cc-4acd84af2c22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-718803259-172.17.0.20-1595414121461:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44434,DS-b2e6ed55-332e-47e3-bf63-c91f3826007b,DISK], DatanodeInfoWithStorage[127.0.0.1:42508,DS-dd500dc7-54e2-4b36-846b-efcaf22393d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45313,DS-393325d1-796a-42d0-9505-27410a001275,DISK], DatanodeInfoWithStorage[127.0.0.1:36406,DS-961be691-8c88-4041-bc88-e038b3552e2f,DISK], DatanodeInfoWithStorage[127.0.0.1:41940,DS-2e336ffc-452e-4124-b64a-4ab49db5b1d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37888,DS-d9f91f83-e6ed-4e41-8e30-8c4ce58415c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33882,DS-7d4b27cf-1342-4c9d-a569-acc687db0788,DISK], DatanodeInfoWithStorage[127.0.0.1:40428,DS-de208c63-d779-4f49-a2cc-4acd84af2c22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.asynclogging
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2122890631-172.17.0.20-1595414152672:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35942,DS-56efefb0-d47b-40da-a27e-f3e830325195,DISK], DatanodeInfoWithStorage[127.0.0.1:39569,DS-7e41dca2-5552-4251-aed0-c1272c76ea47,DISK], DatanodeInfoWithStorage[127.0.0.1:35256,DS-923f0ccc-692e-438b-987e-f5e36212e4e9,DISK], DatanodeInfoWithStorage[127.0.0.1:39702,DS-164a237a-c4d2-41d1-991a-3fcfa70a6902,DISK], DatanodeInfoWithStorage[127.0.0.1:38401,DS-e7e9ee99-3c31-4d90-8b1a-97440f287871,DISK], DatanodeInfoWithStorage[127.0.0.1:42881,DS-d9afb274-7502-41b9-a538-5d7b059b2fb7,DISK], DatanodeInfoWithStorage[127.0.0.1:38768,DS-0e18a707-297b-4cc7-a56b-b21c3040d448,DISK], DatanodeInfoWithStorage[127.0.0.1:41312,DS-ee6827ce-50aa-46ec-957e-f3503027d74c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2122890631-172.17.0.20-1595414152672:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35942,DS-56efefb0-d47b-40da-a27e-f3e830325195,DISK], DatanodeInfoWithStorage[127.0.0.1:39569,DS-7e41dca2-5552-4251-aed0-c1272c76ea47,DISK], DatanodeInfoWithStorage[127.0.0.1:35256,DS-923f0ccc-692e-438b-987e-f5e36212e4e9,DISK], DatanodeInfoWithStorage[127.0.0.1:39702,DS-164a237a-c4d2-41d1-991a-3fcfa70a6902,DISK], DatanodeInfoWithStorage[127.0.0.1:38401,DS-e7e9ee99-3c31-4d90-8b1a-97440f287871,DISK], DatanodeInfoWithStorage[127.0.0.1:42881,DS-d9afb274-7502-41b9-a538-5d7b059b2fb7,DISK], DatanodeInfoWithStorage[127.0.0.1:38768,DS-0e18a707-297b-4cc7-a56b-b21c3040d448,DISK], DatanodeInfoWithStorage[127.0.0.1:41312,DS-ee6827ce-50aa-46ec-957e-f3503027d74c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.asynclogging
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-346996096-172.17.0.20-1595414341651:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36873,DS-73dab345-b4cf-4ab1-ba26-3d2fa280c5f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42915,DS-25c9fc00-7448-42ed-ae58-f08ea482301d,DISK], DatanodeInfoWithStorage[127.0.0.1:42566,DS-7f6e7593-d3c4-4576-814c-4e11003798e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41443,DS-5e2c34c0-5f9b-4e81-bc7c-9b358bb675fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41777,DS-d58387aa-12b6-42b2-b23b-ba4ef296285e,DISK], DatanodeInfoWithStorage[127.0.0.1:45364,DS-6790adbe-4ebe-4bff-885e-4a0508068641,DISK], DatanodeInfoWithStorage[127.0.0.1:45100,DS-5c5aa9d8-a47a-41c2-85a8-bf384d0f00eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40946,DS-3e7f483c-b7ba-4c6a-a09e-b8ea771e87fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-346996096-172.17.0.20-1595414341651:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36873,DS-73dab345-b4cf-4ab1-ba26-3d2fa280c5f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42915,DS-25c9fc00-7448-42ed-ae58-f08ea482301d,DISK], DatanodeInfoWithStorage[127.0.0.1:42566,DS-7f6e7593-d3c4-4576-814c-4e11003798e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41443,DS-5e2c34c0-5f9b-4e81-bc7c-9b358bb675fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41777,DS-d58387aa-12b6-42b2-b23b-ba4ef296285e,DISK], DatanodeInfoWithStorage[127.0.0.1:45364,DS-6790adbe-4ebe-4bff-885e-4a0508068641,DISK], DatanodeInfoWithStorage[127.0.0.1:45100,DS-5c5aa9d8-a47a-41c2-85a8-bf384d0f00eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40946,DS-3e7f483c-b7ba-4c6a-a09e-b8ea771e87fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.asynclogging
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-980993448-172.17.0.20-1595414420268:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34623,DS-1a807cfc-95b0-4d06-9083-97f3f9b7b73f,DISK], DatanodeInfoWithStorage[127.0.0.1:34693,DS-b894461c-4717-4a53-9693-dbdf7d865125,DISK], DatanodeInfoWithStorage[127.0.0.1:35913,DS-5892d6d9-084d-4c13-b1ab-26ced1df3aab,DISK], DatanodeInfoWithStorage[127.0.0.1:38559,DS-d3cb6714-fc3d-44fa-a388-64a6a93a81fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36311,DS-fd6affa9-66e6-48da-b9b4-bf95e27975ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42874,DS-fa4224f5-5217-4a52-8a32-21e8ce2d1044,DISK], DatanodeInfoWithStorage[127.0.0.1:42204,DS-941e940e-78e1-4cba-9fe2-a58cd5e4d6a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38184,DS-a1cfc3f3-982d-4058-9763-cf7d8a69bd7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-980993448-172.17.0.20-1595414420268:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34623,DS-1a807cfc-95b0-4d06-9083-97f3f9b7b73f,DISK], DatanodeInfoWithStorage[127.0.0.1:34693,DS-b894461c-4717-4a53-9693-dbdf7d865125,DISK], DatanodeInfoWithStorage[127.0.0.1:35913,DS-5892d6d9-084d-4c13-b1ab-26ced1df3aab,DISK], DatanodeInfoWithStorage[127.0.0.1:38559,DS-d3cb6714-fc3d-44fa-a388-64a6a93a81fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36311,DS-fd6affa9-66e6-48da-b9b4-bf95e27975ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42874,DS-fa4224f5-5217-4a52-8a32-21e8ce2d1044,DISK], DatanodeInfoWithStorage[127.0.0.1:42204,DS-941e940e-78e1-4cba-9fe2-a58cd5e4d6a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38184,DS-a1cfc3f3-982d-4058-9763-cf7d8a69bd7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.edits.asynclogging
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-693339558-172.17.0.20-1595414435482:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46058,DS-bbe6e078-7463-4427-80c2-560158876c1f,DISK], DatanodeInfoWithStorage[127.0.0.1:36138,DS-fb1f253b-e90f-4fb4-a968-b44cf1073755,DISK], DatanodeInfoWithStorage[127.0.0.1:34186,DS-f7298386-a637-4bc5-b440-133a624a98a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41612,DS-9ce90d04-924a-4965-b47f-9cb805f4763d,DISK], DatanodeInfoWithStorage[127.0.0.1:35520,DS-d4fa210d-d9fa-4950-bcd8-b0d89fc755f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44799,DS-bb8dc43d-6d12-4f75-bae8-6fe05cf7a0ca,DISK], DatanodeInfoWithStorage[127.0.0.1:46527,DS-501599ad-a635-4c51-a9d9-6d6974084a25,DISK], DatanodeInfoWithStorage[127.0.0.1:41964,DS-f764ae14-8b15-4ad9-9139-9484f1bc6dab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-693339558-172.17.0.20-1595414435482:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46058,DS-bbe6e078-7463-4427-80c2-560158876c1f,DISK], DatanodeInfoWithStorage[127.0.0.1:36138,DS-fb1f253b-e90f-4fb4-a968-b44cf1073755,DISK], DatanodeInfoWithStorage[127.0.0.1:34186,DS-f7298386-a637-4bc5-b440-133a624a98a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41612,DS-9ce90d04-924a-4965-b47f-9cb805f4763d,DISK], DatanodeInfoWithStorage[127.0.0.1:35520,DS-d4fa210d-d9fa-4950-bcd8-b0d89fc755f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44799,DS-bb8dc43d-6d12-4f75-bae8-6fe05cf7a0ca,DISK], DatanodeInfoWithStorage[127.0.0.1:46527,DS-501599ad-a635-4c51-a9d9-6d6974084a25,DISK], DatanodeInfoWithStorage[127.0.0.1:41964,DS-f764ae14-8b15-4ad9-9139-9484f1bc6dab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.asynclogging
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2018384273-172.17.0.20-1595414498280:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45903,DS-3f6607d1-f098-4aef-adc2-535fad0a91ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40431,DS-3e5ddc02-12bc-4020-8c64-942ab872d827,DISK], DatanodeInfoWithStorage[127.0.0.1:36094,DS-1ccf4e10-1e60-4fdd-b6f7-e42d755f111c,DISK], DatanodeInfoWithStorage[127.0.0.1:33519,DS-2e7d54cd-8266-4416-a58f-e19aed995da6,DISK], DatanodeInfoWithStorage[127.0.0.1:44520,DS-17a21700-ca57-476f-8bfa-f57f8f754994,DISK], DatanodeInfoWithStorage[127.0.0.1:44245,DS-ff768887-2576-4a4f-87eb-88185be26276,DISK], DatanodeInfoWithStorage[127.0.0.1:36555,DS-df5de385-0789-4d1b-b8ee-b0b4e397caa8,DISK], DatanodeInfoWithStorage[127.0.0.1:33131,DS-3ece12a5-5bed-4d90-994a-2779131f5222,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2018384273-172.17.0.20-1595414498280:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45903,DS-3f6607d1-f098-4aef-adc2-535fad0a91ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40431,DS-3e5ddc02-12bc-4020-8c64-942ab872d827,DISK], DatanodeInfoWithStorage[127.0.0.1:36094,DS-1ccf4e10-1e60-4fdd-b6f7-e42d755f111c,DISK], DatanodeInfoWithStorage[127.0.0.1:33519,DS-2e7d54cd-8266-4416-a58f-e19aed995da6,DISK], DatanodeInfoWithStorage[127.0.0.1:44520,DS-17a21700-ca57-476f-8bfa-f57f8f754994,DISK], DatanodeInfoWithStorage[127.0.0.1:44245,DS-ff768887-2576-4a4f-87eb-88185be26276,DISK], DatanodeInfoWithStorage[127.0.0.1:36555,DS-df5de385-0789-4d1b-b8ee-b0b4e397caa8,DISK], DatanodeInfoWithStorage[127.0.0.1:33131,DS-3ece12a5-5bed-4d90-994a-2779131f5222,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.asynclogging
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-452279495-172.17.0.20-1595414561132:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33575,DS-ef2cec69-0a67-4eb0-a6ba-fe158c268e6e,DISK], DatanodeInfoWithStorage[127.0.0.1:33074,DS-10df3670-8cf0-426a-a367-28fb71378faa,DISK], DatanodeInfoWithStorage[127.0.0.1:43179,DS-96e3a1be-ca71-4732-95d8-93ecfc7c6a4f,DISK], DatanodeInfoWithStorage[127.0.0.1:46210,DS-01358de3-3788-4b99-8935-521553baa096,DISK], DatanodeInfoWithStorage[127.0.0.1:39190,DS-7757eb11-df46-4ef3-9342-c0f172f291ea,DISK], DatanodeInfoWithStorage[127.0.0.1:32840,DS-d992d67c-2801-4e02-8167-8c1c1f3c500d,DISK], DatanodeInfoWithStorage[127.0.0.1:43696,DS-bde9d426-4616-43e2-b8ec-60e198e50837,DISK], DatanodeInfoWithStorage[127.0.0.1:44612,DS-2de9377b-7b65-425c-8e38-c4155ade6f3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-452279495-172.17.0.20-1595414561132:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33575,DS-ef2cec69-0a67-4eb0-a6ba-fe158c268e6e,DISK], DatanodeInfoWithStorage[127.0.0.1:33074,DS-10df3670-8cf0-426a-a367-28fb71378faa,DISK], DatanodeInfoWithStorage[127.0.0.1:43179,DS-96e3a1be-ca71-4732-95d8-93ecfc7c6a4f,DISK], DatanodeInfoWithStorage[127.0.0.1:46210,DS-01358de3-3788-4b99-8935-521553baa096,DISK], DatanodeInfoWithStorage[127.0.0.1:39190,DS-7757eb11-df46-4ef3-9342-c0f172f291ea,DISK], DatanodeInfoWithStorage[127.0.0.1:32840,DS-d992d67c-2801-4e02-8167-8c1c1f3c500d,DISK], DatanodeInfoWithStorage[127.0.0.1:43696,DS-bde9d426-4616-43e2-b8ec-60e198e50837,DISK], DatanodeInfoWithStorage[127.0.0.1:44612,DS-2de9377b-7b65-425c-8e38-c4155ade6f3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.asynclogging
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1613527628-172.17.0.20-1595414841862:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36436,DS-e16f8c62-9c87-4752-9840-b8dd07be32a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43234,DS-a88677ff-a7d4-4f74-9e6b-fe9557b761b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41092,DS-4fa8e781-c6f1-42e7-92f3-25cc49f4e61f,DISK], DatanodeInfoWithStorage[127.0.0.1:42867,DS-e1da7e74-9c8d-46db-b53f-ebac2a050be1,DISK], DatanodeInfoWithStorage[127.0.0.1:37825,DS-f17a8216-6489-4964-815a-2d3e9919f21c,DISK], DatanodeInfoWithStorage[127.0.0.1:40714,DS-7ef573b4-2277-4858-a3f2-dbfb517b83cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42827,DS-e506913f-89d1-4be5-a641-0fd18cb6af54,DISK], DatanodeInfoWithStorage[127.0.0.1:37437,DS-13331b1f-f3e8-4e93-8d4c-a015f30eeaea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1613527628-172.17.0.20-1595414841862:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36436,DS-e16f8c62-9c87-4752-9840-b8dd07be32a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43234,DS-a88677ff-a7d4-4f74-9e6b-fe9557b761b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41092,DS-4fa8e781-c6f1-42e7-92f3-25cc49f4e61f,DISK], DatanodeInfoWithStorage[127.0.0.1:42867,DS-e1da7e74-9c8d-46db-b53f-ebac2a050be1,DISK], DatanodeInfoWithStorage[127.0.0.1:37825,DS-f17a8216-6489-4964-815a-2d3e9919f21c,DISK], DatanodeInfoWithStorage[127.0.0.1:40714,DS-7ef573b4-2277-4858-a3f2-dbfb517b83cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42827,DS-e506913f-89d1-4be5-a641-0fd18cb6af54,DISK], DatanodeInfoWithStorage[127.0.0.1:37437,DS-13331b1f-f3e8-4e93-8d4c-a015f30eeaea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 3082
