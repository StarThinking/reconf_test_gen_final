reconf_parameter: fs.automatic.close
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.automatic.close
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1757472449-172.17.0.15-1595368230037:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45362,DS-ce1b8f83-8999-497e-8760-be05ca7621e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34574,DS-5e392d3b-93cd-4516-92df-da8f7ace5df1,DISK], DatanodeInfoWithStorage[127.0.0.1:33122,DS-77b11ee1-83d8-43b5-8628-ad2854576263,DISK], DatanodeInfoWithStorage[127.0.0.1:38815,DS-9cc1e0c9-1930-4c0f-9ecb-0a630c128b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:42256,DS-04634c99-83b2-4aa9-9502-d7f5bff45320,DISK], DatanodeInfoWithStorage[127.0.0.1:40560,DS-8953f887-4cfa-4d06-a447-8dfd68e68178,DISK], DatanodeInfoWithStorage[127.0.0.1:38884,DS-ee47b7dd-0cc3-4e0e-90a4-c683bd889fad,DISK], DatanodeInfoWithStorage[127.0.0.1:45783,DS-86efde53-fe86-49fa-a3f9-f8590006ccbb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1757472449-172.17.0.15-1595368230037:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45362,DS-ce1b8f83-8999-497e-8760-be05ca7621e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34574,DS-5e392d3b-93cd-4516-92df-da8f7ace5df1,DISK], DatanodeInfoWithStorage[127.0.0.1:33122,DS-77b11ee1-83d8-43b5-8628-ad2854576263,DISK], DatanodeInfoWithStorage[127.0.0.1:38815,DS-9cc1e0c9-1930-4c0f-9ecb-0a630c128b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:42256,DS-04634c99-83b2-4aa9-9502-d7f5bff45320,DISK], DatanodeInfoWithStorage[127.0.0.1:40560,DS-8953f887-4cfa-4d06-a447-8dfd68e68178,DISK], DatanodeInfoWithStorage[127.0.0.1:38884,DS-ee47b7dd-0cc3-4e0e-90a4-c683bd889fad,DISK], DatanodeInfoWithStorage[127.0.0.1:45783,DS-86efde53-fe86-49fa-a3f9-f8590006ccbb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.automatic.close
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-402055498-172.17.0.15-1595368286427:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40375,DS-e05b9b54-382f-40b4-a5c0-f043d4f3d4b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37266,DS-d8305f16-9b00-425b-af24-881dd394fe61,DISK], DatanodeInfoWithStorage[127.0.0.1:46779,DS-559676d4-a8c2-4e9b-97cf-06035ed973fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40388,DS-b690b70c-4350-4ed0-9ed2-57214d0f94db,DISK], DatanodeInfoWithStorage[127.0.0.1:40553,DS-0f81a8d2-8410-49d1-bfe3-360910385ce5,DISK], DatanodeInfoWithStorage[127.0.0.1:37169,DS-90ac459e-42eb-4320-b25c-f9068b5a2076,DISK], DatanodeInfoWithStorage[127.0.0.1:41675,DS-2897641f-2509-46e3-a107-a2914ae1c01a,DISK], DatanodeInfoWithStorage[127.0.0.1:39707,DS-15cf3c52-929b-44a9-ba27-d4c32536eb57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-402055498-172.17.0.15-1595368286427:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40375,DS-e05b9b54-382f-40b4-a5c0-f043d4f3d4b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37266,DS-d8305f16-9b00-425b-af24-881dd394fe61,DISK], DatanodeInfoWithStorage[127.0.0.1:46779,DS-559676d4-a8c2-4e9b-97cf-06035ed973fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40388,DS-b690b70c-4350-4ed0-9ed2-57214d0f94db,DISK], DatanodeInfoWithStorage[127.0.0.1:40553,DS-0f81a8d2-8410-49d1-bfe3-360910385ce5,DISK], DatanodeInfoWithStorage[127.0.0.1:37169,DS-90ac459e-42eb-4320-b25c-f9068b5a2076,DISK], DatanodeInfoWithStorage[127.0.0.1:41675,DS-2897641f-2509-46e3-a107-a2914ae1c01a,DISK], DatanodeInfoWithStorage[127.0.0.1:39707,DS-15cf3c52-929b-44a9-ba27-d4c32536eb57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.automatic.close
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1213643247-172.17.0.15-1595368447978:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36935,DS-4e64a811-6627-45a1-9ca7-9ca423e1f059,DISK], DatanodeInfoWithStorage[127.0.0.1:33936,DS-269227da-fcd7-45db-8b0d-0d081504553b,DISK], DatanodeInfoWithStorage[127.0.0.1:44164,DS-d8b2a1ff-3d81-4ec7-8e9d-e2161194a2af,DISK], DatanodeInfoWithStorage[127.0.0.1:42990,DS-13a083c4-8ca7-4fa4-8e1a-fa164cd7d1c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39111,DS-adabe82e-bf70-491e-a123-cd4aa8cf1a8f,DISK], DatanodeInfoWithStorage[127.0.0.1:36842,DS-26318e6b-b911-4edd-b5b4-8bbbdfcea099,DISK], DatanodeInfoWithStorage[127.0.0.1:45839,DS-7bd14fbd-d4c2-40f6-89de-fbc6f83dbd33,DISK], DatanodeInfoWithStorage[127.0.0.1:36266,DS-02d7e3cb-1649-4678-913a-48ab681298d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1213643247-172.17.0.15-1595368447978:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36935,DS-4e64a811-6627-45a1-9ca7-9ca423e1f059,DISK], DatanodeInfoWithStorage[127.0.0.1:33936,DS-269227da-fcd7-45db-8b0d-0d081504553b,DISK], DatanodeInfoWithStorage[127.0.0.1:44164,DS-d8b2a1ff-3d81-4ec7-8e9d-e2161194a2af,DISK], DatanodeInfoWithStorage[127.0.0.1:42990,DS-13a083c4-8ca7-4fa4-8e1a-fa164cd7d1c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39111,DS-adabe82e-bf70-491e-a123-cd4aa8cf1a8f,DISK], DatanodeInfoWithStorage[127.0.0.1:36842,DS-26318e6b-b911-4edd-b5b4-8bbbdfcea099,DISK], DatanodeInfoWithStorage[127.0.0.1:45839,DS-7bd14fbd-d4c2-40f6-89de-fbc6f83dbd33,DISK], DatanodeInfoWithStorage[127.0.0.1:36266,DS-02d7e3cb-1649-4678-913a-48ab681298d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.automatic.close
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1433177428-172.17.0.15-1595368524570:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45795,DS-07771fe6-1011-4746-b26a-f03198ef96db,DISK], DatanodeInfoWithStorage[127.0.0.1:40941,DS-2602598b-ea45-4ce6-a345-987a74ac7e70,DISK], DatanodeInfoWithStorage[127.0.0.1:33144,DS-f8bead02-700b-47e6-804e-01e7a988c8de,DISK], DatanodeInfoWithStorage[127.0.0.1:44456,DS-c5b281f8-7f75-4603-9442-5c8da5abd164,DISK], DatanodeInfoWithStorage[127.0.0.1:34906,DS-9be8dc1a-d940-40aa-be0b-1cb4758ca807,DISK], DatanodeInfoWithStorage[127.0.0.1:34565,DS-b1fb26d0-da8c-4f48-9fe7-3e8ffae9ce43,DISK], DatanodeInfoWithStorage[127.0.0.1:37516,DS-584c722d-9ae0-40a2-bf6e-24aa4e3f77bd,DISK], DatanodeInfoWithStorage[127.0.0.1:34093,DS-cff459b1-e551-4b9c-b573-ca60b887a359,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1433177428-172.17.0.15-1595368524570:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45795,DS-07771fe6-1011-4746-b26a-f03198ef96db,DISK], DatanodeInfoWithStorage[127.0.0.1:40941,DS-2602598b-ea45-4ce6-a345-987a74ac7e70,DISK], DatanodeInfoWithStorage[127.0.0.1:33144,DS-f8bead02-700b-47e6-804e-01e7a988c8de,DISK], DatanodeInfoWithStorage[127.0.0.1:44456,DS-c5b281f8-7f75-4603-9442-5c8da5abd164,DISK], DatanodeInfoWithStorage[127.0.0.1:34906,DS-9be8dc1a-d940-40aa-be0b-1cb4758ca807,DISK], DatanodeInfoWithStorage[127.0.0.1:34565,DS-b1fb26d0-da8c-4f48-9fe7-3e8ffae9ce43,DISK], DatanodeInfoWithStorage[127.0.0.1:37516,DS-584c722d-9ae0-40a2-bf6e-24aa4e3f77bd,DISK], DatanodeInfoWithStorage[127.0.0.1:34093,DS-cff459b1-e551-4b9c-b573-ca60b887a359,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.automatic.close
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-926356230-172.17.0.15-1595368825877:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45796,DS-af5f8528-0e57-4d44-80b5-c7d9f837d050,DISK], DatanodeInfoWithStorage[127.0.0.1:35276,DS-c63e3091-0d2a-49f7-9b8b-31e92cfa8179,DISK], DatanodeInfoWithStorage[127.0.0.1:34794,DS-d43bbba2-4282-45f3-a7d2-0303588a327d,DISK], DatanodeInfoWithStorage[127.0.0.1:33257,DS-bdba4c56-f00f-4be3-a4dc-6573f9393d8d,DISK], DatanodeInfoWithStorage[127.0.0.1:33526,DS-d622e1e9-2e32-4d1b-b021-f0690ecc2156,DISK], DatanodeInfoWithStorage[127.0.0.1:45704,DS-081b3288-9348-4ce3-a130-6bd23af6f23b,DISK], DatanodeInfoWithStorage[127.0.0.1:33551,DS-4189ead7-4138-4564-b743-9bad03239265,DISK], DatanodeInfoWithStorage[127.0.0.1:45420,DS-6ed92903-9c28-41a2-a0f3-3b0293e7f8fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-926356230-172.17.0.15-1595368825877:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45796,DS-af5f8528-0e57-4d44-80b5-c7d9f837d050,DISK], DatanodeInfoWithStorage[127.0.0.1:35276,DS-c63e3091-0d2a-49f7-9b8b-31e92cfa8179,DISK], DatanodeInfoWithStorage[127.0.0.1:34794,DS-d43bbba2-4282-45f3-a7d2-0303588a327d,DISK], DatanodeInfoWithStorage[127.0.0.1:33257,DS-bdba4c56-f00f-4be3-a4dc-6573f9393d8d,DISK], DatanodeInfoWithStorage[127.0.0.1:33526,DS-d622e1e9-2e32-4d1b-b021-f0690ecc2156,DISK], DatanodeInfoWithStorage[127.0.0.1:45704,DS-081b3288-9348-4ce3-a130-6bd23af6f23b,DISK], DatanodeInfoWithStorage[127.0.0.1:33551,DS-4189ead7-4138-4564-b743-9bad03239265,DISK], DatanodeInfoWithStorage[127.0.0.1:45420,DS-6ed92903-9c28-41a2-a0f3-3b0293e7f8fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.automatic.close
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2098715798-172.17.0.15-1595369200088:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37427,DS-3d378671-d2bf-438d-bdb7-4812f62e2448,DISK], DatanodeInfoWithStorage[127.0.0.1:41700,DS-281b6916-8d79-47da-86d0-28485c810501,DISK], DatanodeInfoWithStorage[127.0.0.1:42040,DS-037cbeeb-c386-4179-9ff2-648a9a45c47b,DISK], DatanodeInfoWithStorage[127.0.0.1:39719,DS-4df32240-0b23-4b4c-a896-f09dbee3d277,DISK], DatanodeInfoWithStorage[127.0.0.1:42145,DS-ee277a91-00cb-4c49-85d7-214be75c5982,DISK], DatanodeInfoWithStorage[127.0.0.1:33196,DS-e45fef93-0f35-4f4c-abd8-b83b12fbfa47,DISK], DatanodeInfoWithStorage[127.0.0.1:39064,DS-0f8cc9c2-bec1-49a1-92af-9b1c8cbacf90,DISK], DatanodeInfoWithStorage[127.0.0.1:35673,DS-493732eb-ae55-41f0-9bc3-50dacf34156d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2098715798-172.17.0.15-1595369200088:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37427,DS-3d378671-d2bf-438d-bdb7-4812f62e2448,DISK], DatanodeInfoWithStorage[127.0.0.1:41700,DS-281b6916-8d79-47da-86d0-28485c810501,DISK], DatanodeInfoWithStorage[127.0.0.1:42040,DS-037cbeeb-c386-4179-9ff2-648a9a45c47b,DISK], DatanodeInfoWithStorage[127.0.0.1:39719,DS-4df32240-0b23-4b4c-a896-f09dbee3d277,DISK], DatanodeInfoWithStorage[127.0.0.1:42145,DS-ee277a91-00cb-4c49-85d7-214be75c5982,DISK], DatanodeInfoWithStorage[127.0.0.1:33196,DS-e45fef93-0f35-4f4c-abd8-b83b12fbfa47,DISK], DatanodeInfoWithStorage[127.0.0.1:39064,DS-0f8cc9c2-bec1-49a1-92af-9b1c8cbacf90,DISK], DatanodeInfoWithStorage[127.0.0.1:35673,DS-493732eb-ae55-41f0-9bc3-50dacf34156d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.automatic.close
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-746431879-172.17.0.15-1595369272121:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40598,DS-efb2e43e-3579-43d3-b1c4-fe780113d20b,DISK], DatanodeInfoWithStorage[127.0.0.1:41992,DS-292045df-da15-42a9-8600-326420243f44,DISK], DatanodeInfoWithStorage[127.0.0.1:39253,DS-3cb56ac0-d4f4-499b-8336-5298567af878,DISK], DatanodeInfoWithStorage[127.0.0.1:40887,DS-b90882d0-dbb7-4ecf-8b3b-24d88b67224e,DISK], DatanodeInfoWithStorage[127.0.0.1:44407,DS-fb428873-4be3-4088-8b29-ff6751cfa9cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38282,DS-11483242-e446-43ea-a1c1-c67b9810aa8b,DISK], DatanodeInfoWithStorage[127.0.0.1:37835,DS-27d89092-f9ad-46ae-b321-f5e9e91fdf1f,DISK], DatanodeInfoWithStorage[127.0.0.1:37415,DS-e2eb7319-0540-4115-9ec4-185c9f46b6ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-746431879-172.17.0.15-1595369272121:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40598,DS-efb2e43e-3579-43d3-b1c4-fe780113d20b,DISK], DatanodeInfoWithStorage[127.0.0.1:41992,DS-292045df-da15-42a9-8600-326420243f44,DISK], DatanodeInfoWithStorage[127.0.0.1:39253,DS-3cb56ac0-d4f4-499b-8336-5298567af878,DISK], DatanodeInfoWithStorage[127.0.0.1:40887,DS-b90882d0-dbb7-4ecf-8b3b-24d88b67224e,DISK], DatanodeInfoWithStorage[127.0.0.1:44407,DS-fb428873-4be3-4088-8b29-ff6751cfa9cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38282,DS-11483242-e446-43ea-a1c1-c67b9810aa8b,DISK], DatanodeInfoWithStorage[127.0.0.1:37835,DS-27d89092-f9ad-46ae-b321-f5e9e91fdf1f,DISK], DatanodeInfoWithStorage[127.0.0.1:37415,DS-e2eb7319-0540-4115-9ec4-185c9f46b6ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.automatic.close
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-879698505-172.17.0.15-1595369746595:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44308,DS-0cdc2a2c-0b78-419f-a03e-ce92a219aa44,DISK], DatanodeInfoWithStorage[127.0.0.1:34505,DS-4d52f212-68ab-4a7d-ba24-d9c36cb20462,DISK], DatanodeInfoWithStorage[127.0.0.1:33633,DS-5b9c51a0-56d3-4920-995d-66e2d19dddcc,DISK], DatanodeInfoWithStorage[127.0.0.1:35898,DS-95dcee3e-c4e6-4cf4-bab8-36f89cd98ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:41671,DS-9e1f966e-ab4e-453e-abaf-f0b99fbd9073,DISK], DatanodeInfoWithStorage[127.0.0.1:34532,DS-365a984d-465d-42e9-a8fe-c5bc24aeb940,DISK], DatanodeInfoWithStorage[127.0.0.1:40028,DS-1accf08e-a25e-49d7-af01-d289f8cf3598,DISK], DatanodeInfoWithStorage[127.0.0.1:35542,DS-54c26b43-7145-4aa9-8de1-35288669c89f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-879698505-172.17.0.15-1595369746595:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44308,DS-0cdc2a2c-0b78-419f-a03e-ce92a219aa44,DISK], DatanodeInfoWithStorage[127.0.0.1:34505,DS-4d52f212-68ab-4a7d-ba24-d9c36cb20462,DISK], DatanodeInfoWithStorage[127.0.0.1:33633,DS-5b9c51a0-56d3-4920-995d-66e2d19dddcc,DISK], DatanodeInfoWithStorage[127.0.0.1:35898,DS-95dcee3e-c4e6-4cf4-bab8-36f89cd98ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:41671,DS-9e1f966e-ab4e-453e-abaf-f0b99fbd9073,DISK], DatanodeInfoWithStorage[127.0.0.1:34532,DS-365a984d-465d-42e9-a8fe-c5bc24aeb940,DISK], DatanodeInfoWithStorage[127.0.0.1:40028,DS-1accf08e-a25e-49d7-af01-d289f8cf3598,DISK], DatanodeInfoWithStorage[127.0.0.1:35542,DS-54c26b43-7145-4aa9-8de1-35288669c89f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.automatic.close
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1676266913-172.17.0.15-1595370849190:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45463,DS-9109cc54-bd83-462c-b63f-39a715328cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:38827,DS-62ba926e-0681-4a53-97e8-62d49d72655c,DISK], DatanodeInfoWithStorage[127.0.0.1:42899,DS-09aebd12-6fed-44f5-b336-2337d6a96a01,DISK], DatanodeInfoWithStorage[127.0.0.1:40567,DS-24bcdca4-a078-4b7f-abea-e3aad0e112e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41640,DS-2b8e21c8-3be2-477c-b70b-212266584774,DISK], DatanodeInfoWithStorage[127.0.0.1:46353,DS-b1fb2560-33a1-449a-a736-eb2ee49be48c,DISK], DatanodeInfoWithStorage[127.0.0.1:36362,DS-5e3d4c3d-98a9-4eba-bceb-b9a990bde7ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38160,DS-7aeee055-4437-4baa-bcd3-c1e12e208c82,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1676266913-172.17.0.15-1595370849190:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45463,DS-9109cc54-bd83-462c-b63f-39a715328cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:38827,DS-62ba926e-0681-4a53-97e8-62d49d72655c,DISK], DatanodeInfoWithStorage[127.0.0.1:42899,DS-09aebd12-6fed-44f5-b336-2337d6a96a01,DISK], DatanodeInfoWithStorage[127.0.0.1:40567,DS-24bcdca4-a078-4b7f-abea-e3aad0e112e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41640,DS-2b8e21c8-3be2-477c-b70b-212266584774,DISK], DatanodeInfoWithStorage[127.0.0.1:46353,DS-b1fb2560-33a1-449a-a736-eb2ee49be48c,DISK], DatanodeInfoWithStorage[127.0.0.1:36362,DS-5e3d4c3d-98a9-4eba-bceb-b9a990bde7ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38160,DS-7aeee055-4437-4baa-bcd3-c1e12e208c82,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.automatic.close
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-568030431-172.17.0.15-1595371616307:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37561,DS-ba09fff9-c105-4db0-ae3b-38452b2490fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33641,DS-e55fd540-5e8c-4503-9083-d844378ae26b,DISK], DatanodeInfoWithStorage[127.0.0.1:42537,DS-01068686-1733-4f33-82e5-c45db02c056f,DISK], DatanodeInfoWithStorage[127.0.0.1:44415,DS-02ea4cac-ca3e-4b12-b5f4-71b2b3c00d24,DISK], DatanodeInfoWithStorage[127.0.0.1:42829,DS-214bce6c-17ca-4b03-89ed-4ec12b777296,DISK], DatanodeInfoWithStorage[127.0.0.1:45136,DS-284d0f5e-5282-47dd-aaf2-1e37a5bde8a5,DISK], DatanodeInfoWithStorage[127.0.0.1:36585,DS-87682381-e199-4829-980b-db13eb598a04,DISK], DatanodeInfoWithStorage[127.0.0.1:37593,DS-7bd5047e-d26b-47c6-a331-e9bebf986aa4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-568030431-172.17.0.15-1595371616307:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37561,DS-ba09fff9-c105-4db0-ae3b-38452b2490fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33641,DS-e55fd540-5e8c-4503-9083-d844378ae26b,DISK], DatanodeInfoWithStorage[127.0.0.1:42537,DS-01068686-1733-4f33-82e5-c45db02c056f,DISK], DatanodeInfoWithStorage[127.0.0.1:44415,DS-02ea4cac-ca3e-4b12-b5f4-71b2b3c00d24,DISK], DatanodeInfoWithStorage[127.0.0.1:42829,DS-214bce6c-17ca-4b03-89ed-4ec12b777296,DISK], DatanodeInfoWithStorage[127.0.0.1:45136,DS-284d0f5e-5282-47dd-aaf2-1e37a5bde8a5,DISK], DatanodeInfoWithStorage[127.0.0.1:36585,DS-87682381-e199-4829-980b-db13eb598a04,DISK], DatanodeInfoWithStorage[127.0.0.1:37593,DS-7bd5047e-d26b-47c6-a331-e9bebf986aa4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.automatic.close
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2001827342-172.17.0.15-1595371972433:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41060,DS-de527b1d-0029-47e0-b3e8-fb04bfa82c81,DISK], DatanodeInfoWithStorage[127.0.0.1:46139,DS-e0db092d-f1c8-47f0-9e5a-d68a36214916,DISK], DatanodeInfoWithStorage[127.0.0.1:41419,DS-b0a93a18-3101-4e5e-b4f7-181157b2e20f,DISK], DatanodeInfoWithStorage[127.0.0.1:41426,DS-60bc321c-8178-47fd-b5e9-e934554d7daa,DISK], DatanodeInfoWithStorage[127.0.0.1:41333,DS-cfbd8de4-3396-4374-99cb-963430bea902,DISK], DatanodeInfoWithStorage[127.0.0.1:40790,DS-369d397a-4291-4033-a5cb-552f25cbc6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38751,DS-3a1821d2-f121-4e05-8ae1-69bef608a071,DISK], DatanodeInfoWithStorage[127.0.0.1:33343,DS-52e9c126-2c60-49f3-9a0e-ad9839fe0148,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2001827342-172.17.0.15-1595371972433:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41060,DS-de527b1d-0029-47e0-b3e8-fb04bfa82c81,DISK], DatanodeInfoWithStorage[127.0.0.1:46139,DS-e0db092d-f1c8-47f0-9e5a-d68a36214916,DISK], DatanodeInfoWithStorage[127.0.0.1:41419,DS-b0a93a18-3101-4e5e-b4f7-181157b2e20f,DISK], DatanodeInfoWithStorage[127.0.0.1:41426,DS-60bc321c-8178-47fd-b5e9-e934554d7daa,DISK], DatanodeInfoWithStorage[127.0.0.1:41333,DS-cfbd8de4-3396-4374-99cb-963430bea902,DISK], DatanodeInfoWithStorage[127.0.0.1:40790,DS-369d397a-4291-4033-a5cb-552f25cbc6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38751,DS-3a1821d2-f121-4e05-8ae1-69bef608a071,DISK], DatanodeInfoWithStorage[127.0.0.1:33343,DS-52e9c126-2c60-49f3-9a0e-ad9839fe0148,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.automatic.close
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2073055901-172.17.0.15-1595372204713:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45169,DS-4f6619c0-4723-47ad-9f10-d9bbddc8ecd6,DISK], DatanodeInfoWithStorage[127.0.0.1:40858,DS-8ebf9b6a-c861-4ffc-8a84-e9d452605ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:41525,DS-01e61283-6e63-49c3-9ff8-dafad21288af,DISK], DatanodeInfoWithStorage[127.0.0.1:35573,DS-1ee4f09e-c27a-4b44-9ef5-8c356da242bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34212,DS-8efd041e-a0bd-481f-939d-f15c43b3b170,DISK], DatanodeInfoWithStorage[127.0.0.1:40610,DS-4b45474c-9f4e-42ca-a0a9-3ded3041aca0,DISK], DatanodeInfoWithStorage[127.0.0.1:45636,DS-c9d9e54a-4026-46f3-b5cb-fd08c2d308b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36037,DS-4857c2da-3f8f-4bf8-ba03-16fb74793f20,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2073055901-172.17.0.15-1595372204713:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45169,DS-4f6619c0-4723-47ad-9f10-d9bbddc8ecd6,DISK], DatanodeInfoWithStorage[127.0.0.1:40858,DS-8ebf9b6a-c861-4ffc-8a84-e9d452605ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:41525,DS-01e61283-6e63-49c3-9ff8-dafad21288af,DISK], DatanodeInfoWithStorage[127.0.0.1:35573,DS-1ee4f09e-c27a-4b44-9ef5-8c356da242bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34212,DS-8efd041e-a0bd-481f-939d-f15c43b3b170,DISK], DatanodeInfoWithStorage[127.0.0.1:40610,DS-4b45474c-9f4e-42ca-a0a9-3ded3041aca0,DISK], DatanodeInfoWithStorage[127.0.0.1:45636,DS-c9d9e54a-4026-46f3-b5cb-fd08c2d308b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36037,DS-4857c2da-3f8f-4bf8-ba03-16fb74793f20,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.automatic.close
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-151080766-172.17.0.15-1595372592243:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39651,DS-6a3992d4-1bf2-4506-b319-b84c220ca526,DISK], DatanodeInfoWithStorage[127.0.0.1:36264,DS-ca51b30a-6bdf-4246-9013-c90040015d56,DISK], DatanodeInfoWithStorage[127.0.0.1:43269,DS-ca2b8012-5132-4c5c-92df-cfa591b4ae03,DISK], DatanodeInfoWithStorage[127.0.0.1:39381,DS-90b49f8e-d208-423f-aa02-03f652f6f618,DISK], DatanodeInfoWithStorage[127.0.0.1:41726,DS-33b45993-88d8-4eb6-951c-98d4a9e8561c,DISK], DatanodeInfoWithStorage[127.0.0.1:33970,DS-b1e79f6e-b5bc-4635-936a-2894670e4d3f,DISK], DatanodeInfoWithStorage[127.0.0.1:37714,DS-5cb0349b-354a-4b06-a2a3-9527babadff3,DISK], DatanodeInfoWithStorage[127.0.0.1:33509,DS-008474dd-1626-40dd-9e79-5c5aa3177211,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-151080766-172.17.0.15-1595372592243:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39651,DS-6a3992d4-1bf2-4506-b319-b84c220ca526,DISK], DatanodeInfoWithStorage[127.0.0.1:36264,DS-ca51b30a-6bdf-4246-9013-c90040015d56,DISK], DatanodeInfoWithStorage[127.0.0.1:43269,DS-ca2b8012-5132-4c5c-92df-cfa591b4ae03,DISK], DatanodeInfoWithStorage[127.0.0.1:39381,DS-90b49f8e-d208-423f-aa02-03f652f6f618,DISK], DatanodeInfoWithStorage[127.0.0.1:41726,DS-33b45993-88d8-4eb6-951c-98d4a9e8561c,DISK], DatanodeInfoWithStorage[127.0.0.1:33970,DS-b1e79f6e-b5bc-4635-936a-2894670e4d3f,DISK], DatanodeInfoWithStorage[127.0.0.1:37714,DS-5cb0349b-354a-4b06-a2a3-9527babadff3,DISK], DatanodeInfoWithStorage[127.0.0.1:33509,DS-008474dd-1626-40dd-9e79-5c5aa3177211,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.automatic.close
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-504398435-172.17.0.15-1595372771719:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35030,DS-a889e26f-8adc-4f7b-8b26-f77a274264ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42378,DS-66bb6bb1-e48c-4506-9c23-cdc49ae58a3f,DISK], DatanodeInfoWithStorage[127.0.0.1:36568,DS-1d413985-627f-4a12-a186-b60cd893f141,DISK], DatanodeInfoWithStorage[127.0.0.1:42795,DS-e04caeae-829b-41c0-a8e1-f68780fff507,DISK], DatanodeInfoWithStorage[127.0.0.1:40652,DS-9c38cf05-7b5b-451c-a3bb-62dd0c13e79a,DISK], DatanodeInfoWithStorage[127.0.0.1:34426,DS-510066e6-c26c-45d8-acad-24887627fda2,DISK], DatanodeInfoWithStorage[127.0.0.1:40870,DS-1e9e6313-b539-4934-ab4c-3081bf1d1e27,DISK], DatanodeInfoWithStorage[127.0.0.1:32799,DS-14862af6-dbbe-4a07-b583-b5d3cb01096a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-504398435-172.17.0.15-1595372771719:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35030,DS-a889e26f-8adc-4f7b-8b26-f77a274264ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42378,DS-66bb6bb1-e48c-4506-9c23-cdc49ae58a3f,DISK], DatanodeInfoWithStorage[127.0.0.1:36568,DS-1d413985-627f-4a12-a186-b60cd893f141,DISK], DatanodeInfoWithStorage[127.0.0.1:42795,DS-e04caeae-829b-41c0-a8e1-f68780fff507,DISK], DatanodeInfoWithStorage[127.0.0.1:40652,DS-9c38cf05-7b5b-451c-a3bb-62dd0c13e79a,DISK], DatanodeInfoWithStorage[127.0.0.1:34426,DS-510066e6-c26c-45d8-acad-24887627fda2,DISK], DatanodeInfoWithStorage[127.0.0.1:40870,DS-1e9e6313-b539-4934-ab4c-3081bf1d1e27,DISK], DatanodeInfoWithStorage[127.0.0.1:32799,DS-14862af6-dbbe-4a07-b583-b5d3cb01096a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5084
