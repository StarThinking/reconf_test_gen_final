reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-855945122-172.17.0.11-1595395296623:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39519,DS-d7807758-10bc-4721-958c-d4aa64503550,DISK], DatanodeInfoWithStorage[127.0.0.1:44725,DS-8295f73e-5f61-4623-a276-191cd6c8d0c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33351,DS-ed163fec-9d72-41ba-963b-f24f2f173b92,DISK], DatanodeInfoWithStorage[127.0.0.1:45648,DS-72227011-2d2d-447f-93df-0e7f9edc6d21,DISK], DatanodeInfoWithStorage[127.0.0.1:38315,DS-320677af-54f9-4ae4-b953-4f24a23a45e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46456,DS-062c7113-db0d-47a6-b444-4efba732b4e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37154,DS-629f4b61-8f71-4994-8ae0-a4ef2eb3f170,DISK], DatanodeInfoWithStorage[127.0.0.1:43062,DS-49ee6d08-6f30-4cb5-9ba1-7230ce1bc0b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-855945122-172.17.0.11-1595395296623:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39519,DS-d7807758-10bc-4721-958c-d4aa64503550,DISK], DatanodeInfoWithStorage[127.0.0.1:44725,DS-8295f73e-5f61-4623-a276-191cd6c8d0c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33351,DS-ed163fec-9d72-41ba-963b-f24f2f173b92,DISK], DatanodeInfoWithStorage[127.0.0.1:45648,DS-72227011-2d2d-447f-93df-0e7f9edc6d21,DISK], DatanodeInfoWithStorage[127.0.0.1:38315,DS-320677af-54f9-4ae4-b953-4f24a23a45e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46456,DS-062c7113-db0d-47a6-b444-4efba732b4e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37154,DS-629f4b61-8f71-4994-8ae0-a4ef2eb3f170,DISK], DatanodeInfoWithStorage[127.0.0.1:43062,DS-49ee6d08-6f30-4cb5-9ba1-7230ce1bc0b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1631033264-172.17.0.11-1595395947235:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34585,DS-fd8f838d-baa7-4066-ac6b-4a606e76d7bf,DISK], DatanodeInfoWithStorage[127.0.0.1:45540,DS-f7f9e485-f2f9-4a37-ae1b-805bfa0fe622,DISK], DatanodeInfoWithStorage[127.0.0.1:45660,DS-d1025c77-5c17-41e6-91eb-188649af979d,DISK], DatanodeInfoWithStorage[127.0.0.1:36271,DS-8240cd00-a28a-4446-9776-ce7b0dee4627,DISK], DatanodeInfoWithStorage[127.0.0.1:41581,DS-73de2e5d-6be3-45aa-a25e-f27fbef96702,DISK], DatanodeInfoWithStorage[127.0.0.1:36758,DS-abb55252-6447-4cb5-95ec-c01061496be6,DISK], DatanodeInfoWithStorage[127.0.0.1:37615,DS-9dddb237-3bbb-4d91-b37e-023f1921fa6e,DISK], DatanodeInfoWithStorage[127.0.0.1:44775,DS-7ed88ec4-71ef-488e-a4bb-ee2087dc0e89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1631033264-172.17.0.11-1595395947235:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34585,DS-fd8f838d-baa7-4066-ac6b-4a606e76d7bf,DISK], DatanodeInfoWithStorage[127.0.0.1:45540,DS-f7f9e485-f2f9-4a37-ae1b-805bfa0fe622,DISK], DatanodeInfoWithStorage[127.0.0.1:45660,DS-d1025c77-5c17-41e6-91eb-188649af979d,DISK], DatanodeInfoWithStorage[127.0.0.1:36271,DS-8240cd00-a28a-4446-9776-ce7b0dee4627,DISK], DatanodeInfoWithStorage[127.0.0.1:41581,DS-73de2e5d-6be3-45aa-a25e-f27fbef96702,DISK], DatanodeInfoWithStorage[127.0.0.1:36758,DS-abb55252-6447-4cb5-95ec-c01061496be6,DISK], DatanodeInfoWithStorage[127.0.0.1:37615,DS-9dddb237-3bbb-4d91-b37e-023f1921fa6e,DISK], DatanodeInfoWithStorage[127.0.0.1:44775,DS-7ed88ec4-71ef-488e-a4bb-ee2087dc0e89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-187737791-172.17.0.11-1595396203896:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42026,DS-c55d42fc-a05d-4125-a759-085f6c0500b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38354,DS-2d6f93fe-cf3b-4765-8fff-6ecbcdc23ec1,DISK], DatanodeInfoWithStorage[127.0.0.1:36884,DS-15f96cd9-61ec-4984-8112-a1c3abcddd17,DISK], DatanodeInfoWithStorage[127.0.0.1:39126,DS-4f0fdbf8-2c91-43ed-844f-651a3b335743,DISK], DatanodeInfoWithStorage[127.0.0.1:36581,DS-80125140-6446-4e2a-8633-ed810545e6d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36562,DS-b95252bd-3595-47c9-946d-82d003016a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:46201,DS-423adc89-1a63-4949-b33a-c08dad70116c,DISK], DatanodeInfoWithStorage[127.0.0.1:38887,DS-ee270a9f-8157-4d93-9bce-d51fcc3d1380,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-187737791-172.17.0.11-1595396203896:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42026,DS-c55d42fc-a05d-4125-a759-085f6c0500b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38354,DS-2d6f93fe-cf3b-4765-8fff-6ecbcdc23ec1,DISK], DatanodeInfoWithStorage[127.0.0.1:36884,DS-15f96cd9-61ec-4984-8112-a1c3abcddd17,DISK], DatanodeInfoWithStorage[127.0.0.1:39126,DS-4f0fdbf8-2c91-43ed-844f-651a3b335743,DISK], DatanodeInfoWithStorage[127.0.0.1:36581,DS-80125140-6446-4e2a-8633-ed810545e6d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36562,DS-b95252bd-3595-47c9-946d-82d003016a8e,DISK], DatanodeInfoWithStorage[127.0.0.1:46201,DS-423adc89-1a63-4949-b33a-c08dad70116c,DISK], DatanodeInfoWithStorage[127.0.0.1:38887,DS-ee270a9f-8157-4d93-9bce-d51fcc3d1380,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1404810392-172.17.0.11-1595396490976:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43509,DS-08c3db63-ae77-4b5b-8005-a15633732f42,DISK], DatanodeInfoWithStorage[127.0.0.1:32879,DS-a73cbb6c-d96d-4e90-b524-56a178ad4f19,DISK], DatanodeInfoWithStorage[127.0.0.1:35196,DS-afb0a69f-8552-436a-8f70-2ff3250eab7e,DISK], DatanodeInfoWithStorage[127.0.0.1:37730,DS-e3f68d92-6d77-4a5e-94fa-bfbeb9bd43b0,DISK], DatanodeInfoWithStorage[127.0.0.1:46497,DS-fe28a422-1198-4663-ae7f-05fee64e2ae5,DISK], DatanodeInfoWithStorage[127.0.0.1:36622,DS-9d52b46b-020c-4d59-bb88-7fc2bc3d469b,DISK], DatanodeInfoWithStorage[127.0.0.1:43449,DS-7a915c38-3ad8-461e-840a-b7868b4b1a89,DISK], DatanodeInfoWithStorage[127.0.0.1:37394,DS-42bdb78c-b7b9-441f-9815-d5c7012efed6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1404810392-172.17.0.11-1595396490976:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43509,DS-08c3db63-ae77-4b5b-8005-a15633732f42,DISK], DatanodeInfoWithStorage[127.0.0.1:32879,DS-a73cbb6c-d96d-4e90-b524-56a178ad4f19,DISK], DatanodeInfoWithStorage[127.0.0.1:35196,DS-afb0a69f-8552-436a-8f70-2ff3250eab7e,DISK], DatanodeInfoWithStorage[127.0.0.1:37730,DS-e3f68d92-6d77-4a5e-94fa-bfbeb9bd43b0,DISK], DatanodeInfoWithStorage[127.0.0.1:46497,DS-fe28a422-1198-4663-ae7f-05fee64e2ae5,DISK], DatanodeInfoWithStorage[127.0.0.1:36622,DS-9d52b46b-020c-4d59-bb88-7fc2bc3d469b,DISK], DatanodeInfoWithStorage[127.0.0.1:43449,DS-7a915c38-3ad8-461e-840a-b7868b4b1a89,DISK], DatanodeInfoWithStorage[127.0.0.1:37394,DS-42bdb78c-b7b9-441f-9815-d5c7012efed6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-785274862-172.17.0.11-1595396529797:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43444,DS-bcad9571-264f-4b03-a443-5494534d32f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37064,DS-a75d7fb0-6fc2-4f2b-b64a-d0740fedd806,DISK], DatanodeInfoWithStorage[127.0.0.1:34672,DS-55b1b2b0-0f71-4825-ae7c-c22e6929cca4,DISK], DatanodeInfoWithStorage[127.0.0.1:35107,DS-a99a01a0-58b4-4d06-b6a9-e176fcb17003,DISK], DatanodeInfoWithStorage[127.0.0.1:35604,DS-6e841f72-c95c-440a-a654-88af9da703f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44618,DS-ff0db6ee-5867-45e2-bb15-034d1d58dafc,DISK], DatanodeInfoWithStorage[127.0.0.1:45074,DS-1d10c13f-4e9f-4ed5-82f6-3d3db22e8451,DISK], DatanodeInfoWithStorage[127.0.0.1:39146,DS-bbc4e723-4a08-4420-82ae-4943ed2dc2b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-785274862-172.17.0.11-1595396529797:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43444,DS-bcad9571-264f-4b03-a443-5494534d32f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37064,DS-a75d7fb0-6fc2-4f2b-b64a-d0740fedd806,DISK], DatanodeInfoWithStorage[127.0.0.1:34672,DS-55b1b2b0-0f71-4825-ae7c-c22e6929cca4,DISK], DatanodeInfoWithStorage[127.0.0.1:35107,DS-a99a01a0-58b4-4d06-b6a9-e176fcb17003,DISK], DatanodeInfoWithStorage[127.0.0.1:35604,DS-6e841f72-c95c-440a-a654-88af9da703f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44618,DS-ff0db6ee-5867-45e2-bb15-034d1d58dafc,DISK], DatanodeInfoWithStorage[127.0.0.1:45074,DS-1d10c13f-4e9f-4ed5-82f6-3d3db22e8451,DISK], DatanodeInfoWithStorage[127.0.0.1:39146,DS-bbc4e723-4a08-4420-82ae-4943ed2dc2b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-224396141-172.17.0.11-1595396838470:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43430,DS-1c3ba4ef-a970-49d6-acb9-c2d20c24db30,DISK], DatanodeInfoWithStorage[127.0.0.1:39308,DS-99b3fc42-d2a3-4154-a006-454a100a8ab1,DISK], DatanodeInfoWithStorage[127.0.0.1:37052,DS-8109b94b-350b-4a09-aa6f-4b03127eaa2e,DISK], DatanodeInfoWithStorage[127.0.0.1:44126,DS-e61ad42b-d7ed-475b-b118-1730332f3ae6,DISK], DatanodeInfoWithStorage[127.0.0.1:45796,DS-0f0a7d9e-68da-4806-8133-a77d8305a142,DISK], DatanodeInfoWithStorage[127.0.0.1:34497,DS-58710e9a-0aca-4a31-b9cf-b15f1c97a364,DISK], DatanodeInfoWithStorage[127.0.0.1:39316,DS-c5ee6d27-a268-4d46-a3c4-05e9b570efc6,DISK], DatanodeInfoWithStorage[127.0.0.1:42729,DS-5a109e88-e75f-4cdf-b50a-7a0e2e686df9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-224396141-172.17.0.11-1595396838470:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43430,DS-1c3ba4ef-a970-49d6-acb9-c2d20c24db30,DISK], DatanodeInfoWithStorage[127.0.0.1:39308,DS-99b3fc42-d2a3-4154-a006-454a100a8ab1,DISK], DatanodeInfoWithStorage[127.0.0.1:37052,DS-8109b94b-350b-4a09-aa6f-4b03127eaa2e,DISK], DatanodeInfoWithStorage[127.0.0.1:44126,DS-e61ad42b-d7ed-475b-b118-1730332f3ae6,DISK], DatanodeInfoWithStorage[127.0.0.1:45796,DS-0f0a7d9e-68da-4806-8133-a77d8305a142,DISK], DatanodeInfoWithStorage[127.0.0.1:34497,DS-58710e9a-0aca-4a31-b9cf-b15f1c97a364,DISK], DatanodeInfoWithStorage[127.0.0.1:39316,DS-c5ee6d27-a268-4d46-a3c4-05e9b570efc6,DISK], DatanodeInfoWithStorage[127.0.0.1:42729,DS-5a109e88-e75f-4cdf-b50a-7a0e2e686df9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1052813924-172.17.0.11-1595397412234:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33158,DS-aa9a1aa1-baf4-4d13-9c2e-8a29cb852e28,DISK], DatanodeInfoWithStorage[127.0.0.1:38653,DS-e3859669-5330-4b05-8bd2-754177b8a8d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38080,DS-7379390e-104d-463a-af1e-76efac244d08,DISK], DatanodeInfoWithStorage[127.0.0.1:35970,DS-25d76370-1b62-4cd4-aa73-627dadf7c674,DISK], DatanodeInfoWithStorage[127.0.0.1:44844,DS-2cbfa7f8-6fae-4d7b-bad2-92f2006c86ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41927,DS-b8ef9898-e2b8-4fe7-997a-3763d38cb7d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36709,DS-c9b816aa-d42f-4e45-a99e-faf48a500f75,DISK], DatanodeInfoWithStorage[127.0.0.1:45088,DS-b54e6b26-d8be-4599-97d9-9d15cdf8c384,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1052813924-172.17.0.11-1595397412234:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33158,DS-aa9a1aa1-baf4-4d13-9c2e-8a29cb852e28,DISK], DatanodeInfoWithStorage[127.0.0.1:38653,DS-e3859669-5330-4b05-8bd2-754177b8a8d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38080,DS-7379390e-104d-463a-af1e-76efac244d08,DISK], DatanodeInfoWithStorage[127.0.0.1:35970,DS-25d76370-1b62-4cd4-aa73-627dadf7c674,DISK], DatanodeInfoWithStorage[127.0.0.1:44844,DS-2cbfa7f8-6fae-4d7b-bad2-92f2006c86ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41927,DS-b8ef9898-e2b8-4fe7-997a-3763d38cb7d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36709,DS-c9b816aa-d42f-4e45-a99e-faf48a500f75,DISK], DatanodeInfoWithStorage[127.0.0.1:45088,DS-b54e6b26-d8be-4599-97d9-9d15cdf8c384,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1879646562-172.17.0.11-1595397767343:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34431,DS-70b4c550-763f-45cd-8c56-b643bca578bc,DISK], DatanodeInfoWithStorage[127.0.0.1:36918,DS-4246669c-bfbf-4c4f-b859-0d802d07342a,DISK], DatanodeInfoWithStorage[127.0.0.1:43955,DS-e9c07d0c-c1ec-4699-9c58-49c8e6d19bba,DISK], DatanodeInfoWithStorage[127.0.0.1:41108,DS-852a874f-678c-46b5-9040-3a250e81b11b,DISK], DatanodeInfoWithStorage[127.0.0.1:33912,DS-2e0d3aed-9573-419c-89a7-3b46c9e814f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38291,DS-0a40a79d-bba4-4a8e-83ad-66e7e94d4ed3,DISK], DatanodeInfoWithStorage[127.0.0.1:39149,DS-8b728127-1a22-4915-a537-ae8d7bb4edeb,DISK], DatanodeInfoWithStorage[127.0.0.1:40057,DS-fa43f17b-599f-4921-86d0-e0b3fecbcf07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1879646562-172.17.0.11-1595397767343:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34431,DS-70b4c550-763f-45cd-8c56-b643bca578bc,DISK], DatanodeInfoWithStorage[127.0.0.1:36918,DS-4246669c-bfbf-4c4f-b859-0d802d07342a,DISK], DatanodeInfoWithStorage[127.0.0.1:43955,DS-e9c07d0c-c1ec-4699-9c58-49c8e6d19bba,DISK], DatanodeInfoWithStorage[127.0.0.1:41108,DS-852a874f-678c-46b5-9040-3a250e81b11b,DISK], DatanodeInfoWithStorage[127.0.0.1:33912,DS-2e0d3aed-9573-419c-89a7-3b46c9e814f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38291,DS-0a40a79d-bba4-4a8e-83ad-66e7e94d4ed3,DISK], DatanodeInfoWithStorage[127.0.0.1:39149,DS-8b728127-1a22-4915-a537-ae8d7bb4edeb,DISK], DatanodeInfoWithStorage[127.0.0.1:40057,DS-fa43f17b-599f-4921-86d0-e0b3fecbcf07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1424005824-172.17.0.11-1595398163255:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46865,DS-253e87d4-ebbe-4cf5-9648-70256ef97c41,DISK], DatanodeInfoWithStorage[127.0.0.1:36465,DS-40926dd1-72be-41fb-9002-e64ecf03011f,DISK], DatanodeInfoWithStorage[127.0.0.1:40007,DS-3b05825f-a736-4cd1-be3f-473778045bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:39583,DS-462ce892-c791-46e0-a3bb-9869e51ca355,DISK], DatanodeInfoWithStorage[127.0.0.1:38333,DS-7d4acf93-7dd7-418e-ad46-65bf06e5d0a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43876,DS-3c2400ec-3c86-4401-80b5-3df7c726cb98,DISK], DatanodeInfoWithStorage[127.0.0.1:34476,DS-01247fcf-a73c-4250-9a62-6a160399719d,DISK], DatanodeInfoWithStorage[127.0.0.1:36557,DS-0565eaa7-a5e9-442c-8297-445ffb01023b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1424005824-172.17.0.11-1595398163255:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46865,DS-253e87d4-ebbe-4cf5-9648-70256ef97c41,DISK], DatanodeInfoWithStorage[127.0.0.1:36465,DS-40926dd1-72be-41fb-9002-e64ecf03011f,DISK], DatanodeInfoWithStorage[127.0.0.1:40007,DS-3b05825f-a736-4cd1-be3f-473778045bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:39583,DS-462ce892-c791-46e0-a3bb-9869e51ca355,DISK], DatanodeInfoWithStorage[127.0.0.1:38333,DS-7d4acf93-7dd7-418e-ad46-65bf06e5d0a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43876,DS-3c2400ec-3c86-4401-80b5-3df7c726cb98,DISK], DatanodeInfoWithStorage[127.0.0.1:34476,DS-01247fcf-a73c-4250-9a62-6a160399719d,DISK], DatanodeInfoWithStorage[127.0.0.1:36557,DS-0565eaa7-a5e9-442c-8297-445ffb01023b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1957307274-172.17.0.11-1595398518507:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39524,DS-b3fead27-d322-41d4-af5a-79bdbe7c2f18,DISK], DatanodeInfoWithStorage[127.0.0.1:33779,DS-70ef3dd9-184a-42e6-b740-4426d0d3a1ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39928,DS-8fb4ffcf-2e49-4093-8c3b-56cd490e23a3,DISK], DatanodeInfoWithStorage[127.0.0.1:44363,DS-f3d44671-af14-4b61-b06f-c2adb6f52803,DISK], DatanodeInfoWithStorage[127.0.0.1:39594,DS-c321a7fa-acc7-4bc8-850c-fa9a322c9312,DISK], DatanodeInfoWithStorage[127.0.0.1:35751,DS-2196c17d-0c72-4e80-bf77-2964457f90a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37374,DS-29ddf8ac-2ec6-4306-9c91-55088a55d075,DISK], DatanodeInfoWithStorage[127.0.0.1:33838,DS-3347957e-ab90-4481-8321-85bdb9efd622,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1957307274-172.17.0.11-1595398518507:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39524,DS-b3fead27-d322-41d4-af5a-79bdbe7c2f18,DISK], DatanodeInfoWithStorage[127.0.0.1:33779,DS-70ef3dd9-184a-42e6-b740-4426d0d3a1ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39928,DS-8fb4ffcf-2e49-4093-8c3b-56cd490e23a3,DISK], DatanodeInfoWithStorage[127.0.0.1:44363,DS-f3d44671-af14-4b61-b06f-c2adb6f52803,DISK], DatanodeInfoWithStorage[127.0.0.1:39594,DS-c321a7fa-acc7-4bc8-850c-fa9a322c9312,DISK], DatanodeInfoWithStorage[127.0.0.1:35751,DS-2196c17d-0c72-4e80-bf77-2964457f90a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37374,DS-29ddf8ac-2ec6-4306-9c91-55088a55d075,DISK], DatanodeInfoWithStorage[127.0.0.1:33838,DS-3347957e-ab90-4481-8321-85bdb9efd622,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-131466855-172.17.0.11-1595398619672:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36430,DS-274d4d0f-bb21-4bbd-842e-9523d0f43ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:34764,DS-f58c06ff-4d2b-4936-9bcb-b7dd343c161f,DISK], DatanodeInfoWithStorage[127.0.0.1:38866,DS-a3c3d6b4-5d64-46e7-85e2-fc4f6dab8d73,DISK], DatanodeInfoWithStorage[127.0.0.1:37781,DS-434fd743-2a30-43cd-af7d-8173f31d8142,DISK], DatanodeInfoWithStorage[127.0.0.1:44987,DS-33fa4261-18b6-40e1-ab0b-9878d5b4542f,DISK], DatanodeInfoWithStorage[127.0.0.1:34763,DS-fcb30554-e812-435c-b6c7-ebd87336baae,DISK], DatanodeInfoWithStorage[127.0.0.1:39782,DS-258d520e-5217-4fea-86f8-4b50889b4e72,DISK], DatanodeInfoWithStorage[127.0.0.1:41189,DS-31c196e7-79a9-442e-ab51-1276a3ba0e6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-131466855-172.17.0.11-1595398619672:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36430,DS-274d4d0f-bb21-4bbd-842e-9523d0f43ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:34764,DS-f58c06ff-4d2b-4936-9bcb-b7dd343c161f,DISK], DatanodeInfoWithStorage[127.0.0.1:38866,DS-a3c3d6b4-5d64-46e7-85e2-fc4f6dab8d73,DISK], DatanodeInfoWithStorage[127.0.0.1:37781,DS-434fd743-2a30-43cd-af7d-8173f31d8142,DISK], DatanodeInfoWithStorage[127.0.0.1:44987,DS-33fa4261-18b6-40e1-ab0b-9878d5b4542f,DISK], DatanodeInfoWithStorage[127.0.0.1:34763,DS-fcb30554-e812-435c-b6c7-ebd87336baae,DISK], DatanodeInfoWithStorage[127.0.0.1:39782,DS-258d520e-5217-4fea-86f8-4b50889b4e72,DISK], DatanodeInfoWithStorage[127.0.0.1:41189,DS-31c196e7-79a9-442e-ab51-1276a3ba0e6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1142071742-172.17.0.11-1595399250528:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46221,DS-b034ea2d-d60f-4bda-9237-17850476d9d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38341,DS-e3588184-8cb1-4112-a5df-d653cf0e0db2,DISK], DatanodeInfoWithStorage[127.0.0.1:36359,DS-f5a7ef42-82fa-42f2-b2ab-a87db058eb0e,DISK], DatanodeInfoWithStorage[127.0.0.1:33422,DS-886ce36b-0301-43b7-ba99-2f1988106451,DISK], DatanodeInfoWithStorage[127.0.0.1:33294,DS-d96c69ea-07bb-47a9-9733-271cc02d0189,DISK], DatanodeInfoWithStorage[127.0.0.1:45760,DS-394ace5e-787a-493a-b392-95bea04843e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42077,DS-dd901057-6f8f-4964-a356-06cff27dc435,DISK], DatanodeInfoWithStorage[127.0.0.1:44642,DS-5603a877-eaa1-41cf-934f-3364a6f44c64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1142071742-172.17.0.11-1595399250528:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46221,DS-b034ea2d-d60f-4bda-9237-17850476d9d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38341,DS-e3588184-8cb1-4112-a5df-d653cf0e0db2,DISK], DatanodeInfoWithStorage[127.0.0.1:36359,DS-f5a7ef42-82fa-42f2-b2ab-a87db058eb0e,DISK], DatanodeInfoWithStorage[127.0.0.1:33422,DS-886ce36b-0301-43b7-ba99-2f1988106451,DISK], DatanodeInfoWithStorage[127.0.0.1:33294,DS-d96c69ea-07bb-47a9-9733-271cc02d0189,DISK], DatanodeInfoWithStorage[127.0.0.1:45760,DS-394ace5e-787a-493a-b392-95bea04843e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42077,DS-dd901057-6f8f-4964-a356-06cff27dc435,DISK], DatanodeInfoWithStorage[127.0.0.1:44642,DS-5603a877-eaa1-41cf-934f-3364a6f44c64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1089191406-172.17.0.11-1595399418259:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35513,DS-35c95d89-a093-4010-89f0-432dce0ad904,DISK], DatanodeInfoWithStorage[127.0.0.1:42795,DS-af05a35b-3d69-49ce-8791-04702481bccb,DISK], DatanodeInfoWithStorage[127.0.0.1:38384,DS-0968a4df-f750-4cc0-a547-dd31eae2e74b,DISK], DatanodeInfoWithStorage[127.0.0.1:44278,DS-9e503e09-3270-45ac-829a-945a9e0156ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36324,DS-250915bc-0211-4acf-b93e-6d311c7a6d5d,DISK], DatanodeInfoWithStorage[127.0.0.1:32904,DS-dce46a59-e264-43e1-aece-fa599e18d824,DISK], DatanodeInfoWithStorage[127.0.0.1:38498,DS-fe31e45d-cd94-4b70-b166-16bba414e85e,DISK], DatanodeInfoWithStorage[127.0.0.1:39938,DS-92dfefa2-2c28-4bf8-b1e5-257e77bb8905,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1089191406-172.17.0.11-1595399418259:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35513,DS-35c95d89-a093-4010-89f0-432dce0ad904,DISK], DatanodeInfoWithStorage[127.0.0.1:42795,DS-af05a35b-3d69-49ce-8791-04702481bccb,DISK], DatanodeInfoWithStorage[127.0.0.1:38384,DS-0968a4df-f750-4cc0-a547-dd31eae2e74b,DISK], DatanodeInfoWithStorage[127.0.0.1:44278,DS-9e503e09-3270-45ac-829a-945a9e0156ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36324,DS-250915bc-0211-4acf-b93e-6d311c7a6d5d,DISK], DatanodeInfoWithStorage[127.0.0.1:32904,DS-dce46a59-e264-43e1-aece-fa599e18d824,DISK], DatanodeInfoWithStorage[127.0.0.1:38498,DS-fe31e45d-cd94-4b70-b166-16bba414e85e,DISK], DatanodeInfoWithStorage[127.0.0.1:39938,DS-92dfefa2-2c28-4bf8-b1e5-257e77bb8905,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-293047398-172.17.0.11-1595399479860:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33948,DS-220dabd0-d3ef-427c-8db8-f6a1ffc1094c,DISK], DatanodeInfoWithStorage[127.0.0.1:33644,DS-c30d8b82-cd45-41ca-8edb-e23990c6dd27,DISK], DatanodeInfoWithStorage[127.0.0.1:39141,DS-b2b303ca-26ee-4b7b-87e0-fd70a114af0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38007,DS-5370816c-e48c-48de-a887-689c54af691f,DISK], DatanodeInfoWithStorage[127.0.0.1:36916,DS-17509c62-d6b4-4391-bc40-a9c6bf4bc932,DISK], DatanodeInfoWithStorage[127.0.0.1:34218,DS-d4a24003-8724-4d04-a9b2-7495ac85c595,DISK], DatanodeInfoWithStorage[127.0.0.1:44931,DS-b51bf3ac-13c7-4ab5-aa7c-d91fcea22a9e,DISK], DatanodeInfoWithStorage[127.0.0.1:33638,DS-93737f3f-bb2e-48c2-8ab6-ab5d2be10155,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-293047398-172.17.0.11-1595399479860:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33948,DS-220dabd0-d3ef-427c-8db8-f6a1ffc1094c,DISK], DatanodeInfoWithStorage[127.0.0.1:33644,DS-c30d8b82-cd45-41ca-8edb-e23990c6dd27,DISK], DatanodeInfoWithStorage[127.0.0.1:39141,DS-b2b303ca-26ee-4b7b-87e0-fd70a114af0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38007,DS-5370816c-e48c-48de-a887-689c54af691f,DISK], DatanodeInfoWithStorage[127.0.0.1:36916,DS-17509c62-d6b4-4391-bc40-a9c6bf4bc932,DISK], DatanodeInfoWithStorage[127.0.0.1:34218,DS-d4a24003-8724-4d04-a9b2-7495ac85c595,DISK], DatanodeInfoWithStorage[127.0.0.1:44931,DS-b51bf3ac-13c7-4ab5-aa7c-d91fcea22a9e,DISK], DatanodeInfoWithStorage[127.0.0.1:33638,DS-93737f3f-bb2e-48c2-8ab6-ab5d2be10155,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-319873225-172.17.0.11-1595399867925:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46452,DS-ebef5d6e-37af-4a29-ae45-f8823e2e9ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:36361,DS-8de2a576-14a3-4f02-88f6-da71781b91d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46771,DS-f9767103-a80e-4d81-a6eb-f5ae845e7410,DISK], DatanodeInfoWithStorage[127.0.0.1:35484,DS-a98255f5-a5ba-4e8e-8f54-865a4b331542,DISK], DatanodeInfoWithStorage[127.0.0.1:37061,DS-667e5fb7-8512-49ee-ab44-27ccccf313e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44553,DS-16f4e26b-5668-42cd-87b2-988edfb634d8,DISK], DatanodeInfoWithStorage[127.0.0.1:46132,DS-f2487a69-2a94-43ae-bfff-85e923206d28,DISK], DatanodeInfoWithStorage[127.0.0.1:44308,DS-2d8b19ae-838e-438d-9908-827c87979ae1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-319873225-172.17.0.11-1595399867925:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46452,DS-ebef5d6e-37af-4a29-ae45-f8823e2e9ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:36361,DS-8de2a576-14a3-4f02-88f6-da71781b91d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46771,DS-f9767103-a80e-4d81-a6eb-f5ae845e7410,DISK], DatanodeInfoWithStorage[127.0.0.1:35484,DS-a98255f5-a5ba-4e8e-8f54-865a4b331542,DISK], DatanodeInfoWithStorage[127.0.0.1:37061,DS-667e5fb7-8512-49ee-ab44-27ccccf313e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44553,DS-16f4e26b-5668-42cd-87b2-988edfb634d8,DISK], DatanodeInfoWithStorage[127.0.0.1:46132,DS-f2487a69-2a94-43ae-bfff-85e923206d28,DISK], DatanodeInfoWithStorage[127.0.0.1:44308,DS-2d8b19ae-838e-438d-9908-827c87979ae1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1430873288-172.17.0.11-1595400072853:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37500,DS-df5538ea-0d24-4341-a97d-a8da67548757,DISK], DatanodeInfoWithStorage[127.0.0.1:38661,DS-bbf8aba3-3b7a-46e0-95e6-c3899bbf7abd,DISK], DatanodeInfoWithStorage[127.0.0.1:41009,DS-8efbcebf-d428-48b7-aa9c-803ae5912040,DISK], DatanodeInfoWithStorage[127.0.0.1:44746,DS-8cc4f5d2-bcc3-4232-85c4-7de944e4997e,DISK], DatanodeInfoWithStorage[127.0.0.1:35016,DS-b6e260c2-fccd-4fd0-b239-f3255999d4d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38139,DS-7941bb61-c5d2-47b8-b8a4-66670dc0855a,DISK], DatanodeInfoWithStorage[127.0.0.1:34477,DS-c0e6e9ef-00c2-45da-9350-1e7fc11c68c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42917,DS-8dac03f2-c743-4c1d-9908-66a2be7dfc6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1430873288-172.17.0.11-1595400072853:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37500,DS-df5538ea-0d24-4341-a97d-a8da67548757,DISK], DatanodeInfoWithStorage[127.0.0.1:38661,DS-bbf8aba3-3b7a-46e0-95e6-c3899bbf7abd,DISK], DatanodeInfoWithStorage[127.0.0.1:41009,DS-8efbcebf-d428-48b7-aa9c-803ae5912040,DISK], DatanodeInfoWithStorage[127.0.0.1:44746,DS-8cc4f5d2-bcc3-4232-85c4-7de944e4997e,DISK], DatanodeInfoWithStorage[127.0.0.1:35016,DS-b6e260c2-fccd-4fd0-b239-f3255999d4d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38139,DS-7941bb61-c5d2-47b8-b8a4-66670dc0855a,DISK], DatanodeInfoWithStorage[127.0.0.1:34477,DS-c0e6e9ef-00c2-45da-9350-1e7fc11c68c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42917,DS-8dac03f2-c743-4c1d-9908-66a2be7dfc6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-297236464-172.17.0.11-1595400205727:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36841,DS-64ee5cf2-1f12-480c-848d-1b93c9d1d578,DISK], DatanodeInfoWithStorage[127.0.0.1:42071,DS-3f7cedcd-f1aa-4594-b59d-f2318afcb9b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41618,DS-bd300d57-b983-4815-a69f-28099df52a18,DISK], DatanodeInfoWithStorage[127.0.0.1:36837,DS-c4e6f8d9-7022-4293-a10e-e2adbce499eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37060,DS-1775fc9c-1a70-4bbb-937e-3cdbefce2639,DISK], DatanodeInfoWithStorage[127.0.0.1:44716,DS-2db4adf4-b5df-4aa9-8245-953cb202696b,DISK], DatanodeInfoWithStorage[127.0.0.1:44907,DS-bd253a7b-1f1e-4917-94b1-42941568f469,DISK], DatanodeInfoWithStorage[127.0.0.1:46820,DS-7368f0e2-04d2-4802-b566-40ee274fe898,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-297236464-172.17.0.11-1595400205727:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36841,DS-64ee5cf2-1f12-480c-848d-1b93c9d1d578,DISK], DatanodeInfoWithStorage[127.0.0.1:42071,DS-3f7cedcd-f1aa-4594-b59d-f2318afcb9b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41618,DS-bd300d57-b983-4815-a69f-28099df52a18,DISK], DatanodeInfoWithStorage[127.0.0.1:36837,DS-c4e6f8d9-7022-4293-a10e-e2adbce499eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37060,DS-1775fc9c-1a70-4bbb-937e-3cdbefce2639,DISK], DatanodeInfoWithStorage[127.0.0.1:44716,DS-2db4adf4-b5df-4aa9-8245-953cb202696b,DISK], DatanodeInfoWithStorage[127.0.0.1:44907,DS-bd253a7b-1f1e-4917-94b1-42941568f469,DISK], DatanodeInfoWithStorage[127.0.0.1:46820,DS-7368f0e2-04d2-4802-b566-40ee274fe898,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1170015865-172.17.0.11-1595400317072:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46113,DS-3457b25f-42f5-43da-b7be-03f7fb5b782f,DISK], DatanodeInfoWithStorage[127.0.0.1:34089,DS-0815f21b-a3d7-4b29-89d0-36269b24fc14,DISK], DatanodeInfoWithStorage[127.0.0.1:42552,DS-29e36888-e5db-4d96-a918-29785627d988,DISK], DatanodeInfoWithStorage[127.0.0.1:44274,DS-8973b998-431d-47ae-8491-20c8814caaa8,DISK], DatanodeInfoWithStorage[127.0.0.1:42031,DS-a4f08f7b-46b1-4299-a415-f8363dfa956e,DISK], DatanodeInfoWithStorage[127.0.0.1:44252,DS-af84eeb1-a092-4af7-a8ea-4102e6e4c961,DISK], DatanodeInfoWithStorage[127.0.0.1:33636,DS-996b2a95-2691-4a41-bcb4-fa7968dfa7bc,DISK], DatanodeInfoWithStorage[127.0.0.1:40370,DS-b184a7f5-fc0e-41bc-9710-ffbd2e69a5c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1170015865-172.17.0.11-1595400317072:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46113,DS-3457b25f-42f5-43da-b7be-03f7fb5b782f,DISK], DatanodeInfoWithStorage[127.0.0.1:34089,DS-0815f21b-a3d7-4b29-89d0-36269b24fc14,DISK], DatanodeInfoWithStorage[127.0.0.1:42552,DS-29e36888-e5db-4d96-a918-29785627d988,DISK], DatanodeInfoWithStorage[127.0.0.1:44274,DS-8973b998-431d-47ae-8491-20c8814caaa8,DISK], DatanodeInfoWithStorage[127.0.0.1:42031,DS-a4f08f7b-46b1-4299-a415-f8363dfa956e,DISK], DatanodeInfoWithStorage[127.0.0.1:44252,DS-af84eeb1-a092-4af7-a8ea-4102e6e4c961,DISK], DatanodeInfoWithStorage[127.0.0.1:33636,DS-996b2a95-2691-4a41-bcb4-fa7968dfa7bc,DISK], DatanodeInfoWithStorage[127.0.0.1:40370,DS-b184a7f5-fc0e-41bc-9710-ffbd2e69a5c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5209
