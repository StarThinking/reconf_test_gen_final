reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-878545056-172.17.0.8-1595298651713:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35155,DS-4fb2aa5f-9c58-47dd-a7a9-681c2359f582,DISK], DatanodeInfoWithStorage[127.0.0.1:44390,DS-bb94ba13-ef35-4af2-be75-4960bb9ddc04,DISK], DatanodeInfoWithStorage[127.0.0.1:32955,DS-8348df8a-a52e-4522-9007-db3ef0f9ee55,DISK], DatanodeInfoWithStorage[127.0.0.1:38762,DS-f15f7fbd-3876-42eb-b0fa-b0503dba8dab,DISK], DatanodeInfoWithStorage[127.0.0.1:32815,DS-974fa546-7d27-4fbb-8c5e-dbe279ad2419,DISK], DatanodeInfoWithStorage[127.0.0.1:42702,DS-0cc833b5-8b4b-4e81-a322-a93da924905a,DISK], DatanodeInfoWithStorage[127.0.0.1:39843,DS-b753e22e-6c4a-4846-b8bb-6ff4c3786796,DISK], DatanodeInfoWithStorage[127.0.0.1:34964,DS-1c1eec79-e21d-47a3-84d7-571061ac1fda,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-878545056-172.17.0.8-1595298651713:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35155,DS-4fb2aa5f-9c58-47dd-a7a9-681c2359f582,DISK], DatanodeInfoWithStorage[127.0.0.1:44390,DS-bb94ba13-ef35-4af2-be75-4960bb9ddc04,DISK], DatanodeInfoWithStorage[127.0.0.1:32955,DS-8348df8a-a52e-4522-9007-db3ef0f9ee55,DISK], DatanodeInfoWithStorage[127.0.0.1:38762,DS-f15f7fbd-3876-42eb-b0fa-b0503dba8dab,DISK], DatanodeInfoWithStorage[127.0.0.1:32815,DS-974fa546-7d27-4fbb-8c5e-dbe279ad2419,DISK], DatanodeInfoWithStorage[127.0.0.1:42702,DS-0cc833b5-8b4b-4e81-a322-a93da924905a,DISK], DatanodeInfoWithStorage[127.0.0.1:39843,DS-b753e22e-6c4a-4846-b8bb-6ff4c3786796,DISK], DatanodeInfoWithStorage[127.0.0.1:34964,DS-1c1eec79-e21d-47a3-84d7-571061ac1fda,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-715786382-172.17.0.8-1595298901740:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35561,DS-ec036900-23e2-49aa-8f89-c52e80dc4b25,DISK], DatanodeInfoWithStorage[127.0.0.1:39207,DS-ce09c88f-ed3c-43d8-8bc4-cdd90b63d192,DISK], DatanodeInfoWithStorage[127.0.0.1:37330,DS-b57a8854-316c-4a3c-a967-614460982959,DISK], DatanodeInfoWithStorage[127.0.0.1:40601,DS-1557ac26-8f4a-4e0c-a18e-1dbff9a9b58b,DISK], DatanodeInfoWithStorage[127.0.0.1:42432,DS-a161b178-4a19-4411-9fc6-8e4f4f1a28fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39614,DS-4a5717d1-5982-46c2-9122-16bb9fcee605,DISK], DatanodeInfoWithStorage[127.0.0.1:41201,DS-8bcb440d-635e-4df9-9df4-03735fc63c7a,DISK], DatanodeInfoWithStorage[127.0.0.1:39256,DS-5a070a1f-9b65-479a-82b5-ffd2f51d70c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-715786382-172.17.0.8-1595298901740:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35561,DS-ec036900-23e2-49aa-8f89-c52e80dc4b25,DISK], DatanodeInfoWithStorage[127.0.0.1:39207,DS-ce09c88f-ed3c-43d8-8bc4-cdd90b63d192,DISK], DatanodeInfoWithStorage[127.0.0.1:37330,DS-b57a8854-316c-4a3c-a967-614460982959,DISK], DatanodeInfoWithStorage[127.0.0.1:40601,DS-1557ac26-8f4a-4e0c-a18e-1dbff9a9b58b,DISK], DatanodeInfoWithStorage[127.0.0.1:42432,DS-a161b178-4a19-4411-9fc6-8e4f4f1a28fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39614,DS-4a5717d1-5982-46c2-9122-16bb9fcee605,DISK], DatanodeInfoWithStorage[127.0.0.1:41201,DS-8bcb440d-635e-4df9-9df4-03735fc63c7a,DISK], DatanodeInfoWithStorage[127.0.0.1:39256,DS-5a070a1f-9b65-479a-82b5-ffd2f51d70c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1005967643-172.17.0.8-1595299125667:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36710,DS-29c62bad-6137-4cca-80e9-a5c2b183bbbc,DISK], DatanodeInfoWithStorage[127.0.0.1:40086,DS-502ddcdc-2256-4409-bd93-a1398466de8d,DISK], DatanodeInfoWithStorage[127.0.0.1:44099,DS-93a79e13-ab04-40d1-9738-839f9b28b54b,DISK], DatanodeInfoWithStorage[127.0.0.1:41203,DS-9401f063-a39e-4a79-b5e3-595c4a774716,DISK], DatanodeInfoWithStorage[127.0.0.1:37062,DS-29a8b91a-ff8e-4a23-93b6-405969ccd062,DISK], DatanodeInfoWithStorage[127.0.0.1:42188,DS-f1ac1c4a-402f-42c0-a264-26b4bae784a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34387,DS-fc814163-043b-4cc6-b1f9-d85a9a181f43,DISK], DatanodeInfoWithStorage[127.0.0.1:36414,DS-94d32800-3e5f-44d1-9a91-2f95b71509b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1005967643-172.17.0.8-1595299125667:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36710,DS-29c62bad-6137-4cca-80e9-a5c2b183bbbc,DISK], DatanodeInfoWithStorage[127.0.0.1:40086,DS-502ddcdc-2256-4409-bd93-a1398466de8d,DISK], DatanodeInfoWithStorage[127.0.0.1:44099,DS-93a79e13-ab04-40d1-9738-839f9b28b54b,DISK], DatanodeInfoWithStorage[127.0.0.1:41203,DS-9401f063-a39e-4a79-b5e3-595c4a774716,DISK], DatanodeInfoWithStorage[127.0.0.1:37062,DS-29a8b91a-ff8e-4a23-93b6-405969ccd062,DISK], DatanodeInfoWithStorage[127.0.0.1:42188,DS-f1ac1c4a-402f-42c0-a264-26b4bae784a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34387,DS-fc814163-043b-4cc6-b1f9-d85a9a181f43,DISK], DatanodeInfoWithStorage[127.0.0.1:36414,DS-94d32800-3e5f-44d1-9a91-2f95b71509b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1968514659-172.17.0.8-1595299164395:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35096,DS-f3d87f92-a9e2-427a-ac82-0d5e3947fbdd,DISK], DatanodeInfoWithStorage[127.0.0.1:38345,DS-47aa220e-d85f-4fff-ae71-6ad428d8e3ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46452,DS-fbbb62dd-6fb0-4706-8cfd-0cb89f71f44a,DISK], DatanodeInfoWithStorage[127.0.0.1:40788,DS-9a883fca-8f5e-4b62-b80f-df9f10dfe9d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39543,DS-2e0d7229-c011-497c-89ff-a08f29a170a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36312,DS-ae7edec8-1bd0-432d-a74d-e210652c760f,DISK], DatanodeInfoWithStorage[127.0.0.1:45354,DS-99235a30-8c29-4564-b280-191e9d090b97,DISK], DatanodeInfoWithStorage[127.0.0.1:46221,DS-065183b2-9c6e-466c-9364-e081d8c5f13c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1968514659-172.17.0.8-1595299164395:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35096,DS-f3d87f92-a9e2-427a-ac82-0d5e3947fbdd,DISK], DatanodeInfoWithStorage[127.0.0.1:38345,DS-47aa220e-d85f-4fff-ae71-6ad428d8e3ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46452,DS-fbbb62dd-6fb0-4706-8cfd-0cb89f71f44a,DISK], DatanodeInfoWithStorage[127.0.0.1:40788,DS-9a883fca-8f5e-4b62-b80f-df9f10dfe9d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39543,DS-2e0d7229-c011-497c-89ff-a08f29a170a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36312,DS-ae7edec8-1bd0-432d-a74d-e210652c760f,DISK], DatanodeInfoWithStorage[127.0.0.1:45354,DS-99235a30-8c29-4564-b280-191e9d090b97,DISK], DatanodeInfoWithStorage[127.0.0.1:46221,DS-065183b2-9c6e-466c-9364-e081d8c5f13c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-355051627-172.17.0.8-1595299265308:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38818,DS-785618df-4e25-4a34-bd81-6c551bb8d17a,DISK], DatanodeInfoWithStorage[127.0.0.1:39228,DS-02791887-1835-4bf6-a6bf-fe09ce60ee84,DISK], DatanodeInfoWithStorage[127.0.0.1:45157,DS-c98d092b-f0f3-40cf-8423-43c0a7fb7646,DISK], DatanodeInfoWithStorage[127.0.0.1:43402,DS-2c297209-01f1-461d-b425-d5b58d67e83f,DISK], DatanodeInfoWithStorage[127.0.0.1:34444,DS-10be3fb7-cc80-4101-aca1-ff3f055f44df,DISK], DatanodeInfoWithStorage[127.0.0.1:45438,DS-0a4cc99b-10c2-4785-8a4a-04779179ac59,DISK], DatanodeInfoWithStorage[127.0.0.1:37055,DS-3b99b7da-3e9c-4ab7-aa65-c2159b7bc343,DISK], DatanodeInfoWithStorage[127.0.0.1:46152,DS-6167125b-947d-463c-a848-4d25e3f3c9b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-355051627-172.17.0.8-1595299265308:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38818,DS-785618df-4e25-4a34-bd81-6c551bb8d17a,DISK], DatanodeInfoWithStorage[127.0.0.1:39228,DS-02791887-1835-4bf6-a6bf-fe09ce60ee84,DISK], DatanodeInfoWithStorage[127.0.0.1:45157,DS-c98d092b-f0f3-40cf-8423-43c0a7fb7646,DISK], DatanodeInfoWithStorage[127.0.0.1:43402,DS-2c297209-01f1-461d-b425-d5b58d67e83f,DISK], DatanodeInfoWithStorage[127.0.0.1:34444,DS-10be3fb7-cc80-4101-aca1-ff3f055f44df,DISK], DatanodeInfoWithStorage[127.0.0.1:45438,DS-0a4cc99b-10c2-4785-8a4a-04779179ac59,DISK], DatanodeInfoWithStorage[127.0.0.1:37055,DS-3b99b7da-3e9c-4ab7-aa65-c2159b7bc343,DISK], DatanodeInfoWithStorage[127.0.0.1:46152,DS-6167125b-947d-463c-a848-4d25e3f3c9b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-325742098-172.17.0.8-1595299474331:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38382,DS-155cc49f-6f7c-4379-9ab6-e29499dd629f,DISK], DatanodeInfoWithStorage[127.0.0.1:44310,DS-0c5aeedf-3bb4-4d50-87fc-593766507bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:35316,DS-43b3955a-bfb2-4ea6-ac71-ae828e8b89e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41067,DS-a9acc2c1-d6b9-4ee3-873c-964184ae8006,DISK], DatanodeInfoWithStorage[127.0.0.1:39336,DS-a2a0c807-caa1-40ac-8442-716fbcd29e56,DISK], DatanodeInfoWithStorage[127.0.0.1:37635,DS-ad02eaaa-9963-45db-a659-fc2d922d9001,DISK], DatanodeInfoWithStorage[127.0.0.1:39987,DS-7e25470f-b8dd-4a02-a38c-6bdd1d81f595,DISK], DatanodeInfoWithStorage[127.0.0.1:33174,DS-7637bf66-dbba-4a38-b760-eed888e5b109,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-325742098-172.17.0.8-1595299474331:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38382,DS-155cc49f-6f7c-4379-9ab6-e29499dd629f,DISK], DatanodeInfoWithStorage[127.0.0.1:44310,DS-0c5aeedf-3bb4-4d50-87fc-593766507bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:35316,DS-43b3955a-bfb2-4ea6-ac71-ae828e8b89e6,DISK], DatanodeInfoWithStorage[127.0.0.1:41067,DS-a9acc2c1-d6b9-4ee3-873c-964184ae8006,DISK], DatanodeInfoWithStorage[127.0.0.1:39336,DS-a2a0c807-caa1-40ac-8442-716fbcd29e56,DISK], DatanodeInfoWithStorage[127.0.0.1:37635,DS-ad02eaaa-9963-45db-a659-fc2d922d9001,DISK], DatanodeInfoWithStorage[127.0.0.1:39987,DS-7e25470f-b8dd-4a02-a38c-6bdd1d81f595,DISK], DatanodeInfoWithStorage[127.0.0.1:33174,DS-7637bf66-dbba-4a38-b760-eed888e5b109,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-659221021-172.17.0.8-1595299651383:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36343,DS-c26df034-a351-42a0-bc85-8244644714a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40245,DS-30c872b1-156e-452d-b9d7-8fc37975856d,DISK], DatanodeInfoWithStorage[127.0.0.1:45911,DS-d19d162a-2412-4d80-9f08-a2e0fc25a52d,DISK], DatanodeInfoWithStorage[127.0.0.1:42977,DS-37bdc20a-52ce-4da5-a1b9-c5377e82c7fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42765,DS-27c55456-87a1-47ea-95c4-f300fb5ca921,DISK], DatanodeInfoWithStorage[127.0.0.1:42529,DS-3acccb22-ef0d-4197-a0bf-76dd2559193c,DISK], DatanodeInfoWithStorage[127.0.0.1:33166,DS-b3eb930a-f765-44aa-82dd-0e06b3d0277c,DISK], DatanodeInfoWithStorage[127.0.0.1:42242,DS-5bca9067-ab2e-46fa-a2f2-592f2568e9e9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-659221021-172.17.0.8-1595299651383:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36343,DS-c26df034-a351-42a0-bc85-8244644714a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40245,DS-30c872b1-156e-452d-b9d7-8fc37975856d,DISK], DatanodeInfoWithStorage[127.0.0.1:45911,DS-d19d162a-2412-4d80-9f08-a2e0fc25a52d,DISK], DatanodeInfoWithStorage[127.0.0.1:42977,DS-37bdc20a-52ce-4da5-a1b9-c5377e82c7fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42765,DS-27c55456-87a1-47ea-95c4-f300fb5ca921,DISK], DatanodeInfoWithStorage[127.0.0.1:42529,DS-3acccb22-ef0d-4197-a0bf-76dd2559193c,DISK], DatanodeInfoWithStorage[127.0.0.1:33166,DS-b3eb930a-f765-44aa-82dd-0e06b3d0277c,DISK], DatanodeInfoWithStorage[127.0.0.1:42242,DS-5bca9067-ab2e-46fa-a2f2-592f2568e9e9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2084079854-172.17.0.8-1595300249018:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43522,DS-a7039e21-a416-4c0d-86f3-629332d6981c,DISK], DatanodeInfoWithStorage[127.0.0.1:39243,DS-e2caa65d-91eb-4c3d-ba40-effbf0116671,DISK], DatanodeInfoWithStorage[127.0.0.1:37455,DS-43acd3b7-b39d-4207-8b04-d642ec7bdcd0,DISK], DatanodeInfoWithStorage[127.0.0.1:39219,DS-0065f56d-f7bb-46d6-9f45-8503bed81a2c,DISK], DatanodeInfoWithStorage[127.0.0.1:44507,DS-cafe2f1a-d89a-4f3b-b6c1-4339b328bdce,DISK], DatanodeInfoWithStorage[127.0.0.1:34559,DS-5d399c79-6bba-477b-89b5-6a2d03fdbdb6,DISK], DatanodeInfoWithStorage[127.0.0.1:43673,DS-89b30bff-cc49-45ed-bea1-1caa97dc9f67,DISK], DatanodeInfoWithStorage[127.0.0.1:37830,DS-314f4361-f931-4942-a08b-0cf0f4b94965,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2084079854-172.17.0.8-1595300249018:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43522,DS-a7039e21-a416-4c0d-86f3-629332d6981c,DISK], DatanodeInfoWithStorage[127.0.0.1:39243,DS-e2caa65d-91eb-4c3d-ba40-effbf0116671,DISK], DatanodeInfoWithStorage[127.0.0.1:37455,DS-43acd3b7-b39d-4207-8b04-d642ec7bdcd0,DISK], DatanodeInfoWithStorage[127.0.0.1:39219,DS-0065f56d-f7bb-46d6-9f45-8503bed81a2c,DISK], DatanodeInfoWithStorage[127.0.0.1:44507,DS-cafe2f1a-d89a-4f3b-b6c1-4339b328bdce,DISK], DatanodeInfoWithStorage[127.0.0.1:34559,DS-5d399c79-6bba-477b-89b5-6a2d03fdbdb6,DISK], DatanodeInfoWithStorage[127.0.0.1:43673,DS-89b30bff-cc49-45ed-bea1-1caa97dc9f67,DISK], DatanodeInfoWithStorage[127.0.0.1:37830,DS-314f4361-f931-4942-a08b-0cf0f4b94965,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1593452476-172.17.0.8-1595300506190:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46272,DS-c1247dc0-8631-4b9d-87e3-dca8deda7406,DISK], DatanodeInfoWithStorage[127.0.0.1:42608,DS-b411fef9-8bce-42f9-8de5-fdf7a3795d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:38297,DS-2c831c00-a67a-48e2-811e-4e6bdad642d6,DISK], DatanodeInfoWithStorage[127.0.0.1:41520,DS-8f1fa325-60fd-43d6-82a3-ba3c9bef18cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45536,DS-b7f50520-7934-4a80-b442-22c0963538b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37997,DS-7ea2d3dd-6e70-4887-b5fb-ae82755cac2b,DISK], DatanodeInfoWithStorage[127.0.0.1:44546,DS-eb8846d0-58e6-4298-91a1-299ed82e98b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44717,DS-88ef792d-6e38-430c-a191-3e97a687ff2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1593452476-172.17.0.8-1595300506190:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46272,DS-c1247dc0-8631-4b9d-87e3-dca8deda7406,DISK], DatanodeInfoWithStorage[127.0.0.1:42608,DS-b411fef9-8bce-42f9-8de5-fdf7a3795d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:38297,DS-2c831c00-a67a-48e2-811e-4e6bdad642d6,DISK], DatanodeInfoWithStorage[127.0.0.1:41520,DS-8f1fa325-60fd-43d6-82a3-ba3c9bef18cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45536,DS-b7f50520-7934-4a80-b442-22c0963538b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37997,DS-7ea2d3dd-6e70-4887-b5fb-ae82755cac2b,DISK], DatanodeInfoWithStorage[127.0.0.1:44546,DS-eb8846d0-58e6-4298-91a1-299ed82e98b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44717,DS-88ef792d-6e38-430c-a191-3e97a687ff2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1295859202-172.17.0.8-1595300541191:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44532,DS-1447ecba-caab-4274-8cb2-9e304d348fc9,DISK], DatanodeInfoWithStorage[127.0.0.1:41997,DS-b5ab38a2-fade-4cea-8e4c-546d1c6a60d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34579,DS-f35a033b-dd89-4f58-986a-68354691593a,DISK], DatanodeInfoWithStorage[127.0.0.1:44232,DS-c4c866ed-53d8-4f18-9d39-49f7b6977f71,DISK], DatanodeInfoWithStorage[127.0.0.1:41186,DS-81566384-9b91-4749-b99c-9936b1e442cd,DISK], DatanodeInfoWithStorage[127.0.0.1:44921,DS-80e6566d-efad-454a-afc9-ed84f2a4e3b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37648,DS-3aaba74d-a5fa-4dc6-8e8b-6ea6809c42b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34902,DS-f766aed1-57e3-4934-b253-3edc71fcf560,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1295859202-172.17.0.8-1595300541191:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44532,DS-1447ecba-caab-4274-8cb2-9e304d348fc9,DISK], DatanodeInfoWithStorage[127.0.0.1:41997,DS-b5ab38a2-fade-4cea-8e4c-546d1c6a60d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34579,DS-f35a033b-dd89-4f58-986a-68354691593a,DISK], DatanodeInfoWithStorage[127.0.0.1:44232,DS-c4c866ed-53d8-4f18-9d39-49f7b6977f71,DISK], DatanodeInfoWithStorage[127.0.0.1:41186,DS-81566384-9b91-4749-b99c-9936b1e442cd,DISK], DatanodeInfoWithStorage[127.0.0.1:44921,DS-80e6566d-efad-454a-afc9-ed84f2a4e3b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37648,DS-3aaba74d-a5fa-4dc6-8e8b-6ea6809c42b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34902,DS-f766aed1-57e3-4934-b253-3edc71fcf560,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1563457463-172.17.0.8-1595300680243:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33440,DS-5d68080e-0606-41cd-90ce-5fc0fef1f999,DISK], DatanodeInfoWithStorage[127.0.0.1:38728,DS-e619a05f-387f-43b8-b5b6-c77cc52f0e9b,DISK], DatanodeInfoWithStorage[127.0.0.1:43094,DS-a4468680-7045-4df8-bd21-bd179ce89f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:38805,DS-9e1d3567-be9a-4fdb-b0d6-dfc2dda3b77b,DISK], DatanodeInfoWithStorage[127.0.0.1:34194,DS-0194a11f-9bea-4626-a2c6-b175680df522,DISK], DatanodeInfoWithStorage[127.0.0.1:40926,DS-9e070dfe-b4a7-41e9-90fe-05d8fed4a76b,DISK], DatanodeInfoWithStorage[127.0.0.1:39586,DS-3d63e244-f3de-45c4-9995-d6f02aabfb25,DISK], DatanodeInfoWithStorage[127.0.0.1:44030,DS-27c52eb2-04ca-45e8-b876-e2919f746ecf,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1563457463-172.17.0.8-1595300680243:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33440,DS-5d68080e-0606-41cd-90ce-5fc0fef1f999,DISK], DatanodeInfoWithStorage[127.0.0.1:38728,DS-e619a05f-387f-43b8-b5b6-c77cc52f0e9b,DISK], DatanodeInfoWithStorage[127.0.0.1:43094,DS-a4468680-7045-4df8-bd21-bd179ce89f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:38805,DS-9e1d3567-be9a-4fdb-b0d6-dfc2dda3b77b,DISK], DatanodeInfoWithStorage[127.0.0.1:34194,DS-0194a11f-9bea-4626-a2c6-b175680df522,DISK], DatanodeInfoWithStorage[127.0.0.1:40926,DS-9e070dfe-b4a7-41e9-90fe-05d8fed4a76b,DISK], DatanodeInfoWithStorage[127.0.0.1:39586,DS-3d63e244-f3de-45c4-9995-d6f02aabfb25,DISK], DatanodeInfoWithStorage[127.0.0.1:44030,DS-27c52eb2-04ca-45e8-b876-e2919f746ecf,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-639628532-172.17.0.8-1595300837250:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37937,DS-24dbd358-d504-4397-ab31-dbf9618b7b26,DISK], DatanodeInfoWithStorage[127.0.0.1:36198,DS-df2c0ae5-0b03-463f-9308-bd9edbb0500f,DISK], DatanodeInfoWithStorage[127.0.0.1:37488,DS-9b257f02-ae70-44c5-8cab-58915a338170,DISK], DatanodeInfoWithStorage[127.0.0.1:40529,DS-7f71e366-f076-489e-a074-a9319d4c9923,DISK], DatanodeInfoWithStorage[127.0.0.1:38849,DS-94f2c06d-7b0c-4a87-9205-b6f3953c34b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40118,DS-8dd1e548-ab9a-4026-b39d-9cc921d99a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:45176,DS-153b878e-f38f-45e2-98d7-31b07e4fa6dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37223,DS-336ae30a-89ef-4d56-b2e6-04ac99310efb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-639628532-172.17.0.8-1595300837250:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37937,DS-24dbd358-d504-4397-ab31-dbf9618b7b26,DISK], DatanodeInfoWithStorage[127.0.0.1:36198,DS-df2c0ae5-0b03-463f-9308-bd9edbb0500f,DISK], DatanodeInfoWithStorage[127.0.0.1:37488,DS-9b257f02-ae70-44c5-8cab-58915a338170,DISK], DatanodeInfoWithStorage[127.0.0.1:40529,DS-7f71e366-f076-489e-a074-a9319d4c9923,DISK], DatanodeInfoWithStorage[127.0.0.1:38849,DS-94f2c06d-7b0c-4a87-9205-b6f3953c34b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40118,DS-8dd1e548-ab9a-4026-b39d-9cc921d99a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:45176,DS-153b878e-f38f-45e2-98d7-31b07e4fa6dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37223,DS-336ae30a-89ef-4d56-b2e6-04ac99310efb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1301342472-172.17.0.8-1595300971685:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43504,DS-792d1a09-d04b-4734-a998-95415a65e009,DISK], DatanodeInfoWithStorage[127.0.0.1:41721,DS-624520db-5a9b-4ccd-984d-f5c5d3d30d7f,DISK], DatanodeInfoWithStorage[127.0.0.1:34055,DS-88408bdb-0b86-418d-b5d2-a7bfb98c8c75,DISK], DatanodeInfoWithStorage[127.0.0.1:43297,DS-cd2fc001-35e2-46d2-b1b8-b4112d28f5b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37852,DS-99ddd9da-2f7c-4c41-a1fe-c510ff46a654,DISK], DatanodeInfoWithStorage[127.0.0.1:35537,DS-0f6c81e1-4ea0-4e0f-8688-41a58fe83622,DISK], DatanodeInfoWithStorage[127.0.0.1:33820,DS-b8f35321-0c04-467b-a777-539bc4379e4a,DISK], DatanodeInfoWithStorage[127.0.0.1:45873,DS-cd388cc3-547c-4780-ba97-9d6f14ad6f3e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1301342472-172.17.0.8-1595300971685:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43504,DS-792d1a09-d04b-4734-a998-95415a65e009,DISK], DatanodeInfoWithStorage[127.0.0.1:41721,DS-624520db-5a9b-4ccd-984d-f5c5d3d30d7f,DISK], DatanodeInfoWithStorage[127.0.0.1:34055,DS-88408bdb-0b86-418d-b5d2-a7bfb98c8c75,DISK], DatanodeInfoWithStorage[127.0.0.1:43297,DS-cd2fc001-35e2-46d2-b1b8-b4112d28f5b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37852,DS-99ddd9da-2f7c-4c41-a1fe-c510ff46a654,DISK], DatanodeInfoWithStorage[127.0.0.1:35537,DS-0f6c81e1-4ea0-4e0f-8688-41a58fe83622,DISK], DatanodeInfoWithStorage[127.0.0.1:33820,DS-b8f35321-0c04-467b-a777-539bc4379e4a,DISK], DatanodeInfoWithStorage[127.0.0.1:45873,DS-cd388cc3-547c-4780-ba97-9d6f14ad6f3e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-357817285-172.17.0.8-1595301073746:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37916,DS-9d23b822-c189-4088-ad33-67f38dd9e70c,DISK], DatanodeInfoWithStorage[127.0.0.1:46840,DS-00ed1550-5eb8-45a0-b532-1a5668148de0,DISK], DatanodeInfoWithStorage[127.0.0.1:43079,DS-0a257d55-9e0a-46d8-93b2-1167e9d8edb0,DISK], DatanodeInfoWithStorage[127.0.0.1:34349,DS-4b5473b3-bfa0-4ac1-a1a1-61a811df7ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:38203,DS-a6900088-fd26-4c59-b0e6-3769aaf52266,DISK], DatanodeInfoWithStorage[127.0.0.1:37206,DS-3905d0ce-da5f-480f-b4be-bb3c9f7d9285,DISK], DatanodeInfoWithStorage[127.0.0.1:33518,DS-f0d3e016-b0d5-44a0-940b-d8ae108be85b,DISK], DatanodeInfoWithStorage[127.0.0.1:45789,DS-c13437e8-b371-4715-b5db-657a007b1297,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-357817285-172.17.0.8-1595301073746:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37916,DS-9d23b822-c189-4088-ad33-67f38dd9e70c,DISK], DatanodeInfoWithStorage[127.0.0.1:46840,DS-00ed1550-5eb8-45a0-b532-1a5668148de0,DISK], DatanodeInfoWithStorage[127.0.0.1:43079,DS-0a257d55-9e0a-46d8-93b2-1167e9d8edb0,DISK], DatanodeInfoWithStorage[127.0.0.1:34349,DS-4b5473b3-bfa0-4ac1-a1a1-61a811df7ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:38203,DS-a6900088-fd26-4c59-b0e6-3769aaf52266,DISK], DatanodeInfoWithStorage[127.0.0.1:37206,DS-3905d0ce-da5f-480f-b4be-bb3c9f7d9285,DISK], DatanodeInfoWithStorage[127.0.0.1:33518,DS-f0d3e016-b0d5-44a0-940b-d8ae108be85b,DISK], DatanodeInfoWithStorage[127.0.0.1:45789,DS-c13437e8-b371-4715-b5db-657a007b1297,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1296046832-172.17.0.8-1595301108926:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33710,DS-8cbf90ca-30c6-4ed9-a0e3-5204c7ff2b1a,DISK], DatanodeInfoWithStorage[127.0.0.1:43304,DS-af4e7a78-5aa9-4378-b202-5abbec0218b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33472,DS-75e591a3-2fba-4e17-bfc6-dbf2e49996bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42145,DS-9e95c4ae-484b-42f0-81f7-3a51466a16f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44004,DS-a7207ae3-7ce5-4102-8456-342747a32833,DISK], DatanodeInfoWithStorage[127.0.0.1:35096,DS-b27a08da-10d8-4809-9981-3bd0d0fa21a5,DISK], DatanodeInfoWithStorage[127.0.0.1:45826,DS-488c9a92-eb9b-4588-89a9-1b0de043dc63,DISK], DatanodeInfoWithStorage[127.0.0.1:42087,DS-cecacb70-e3a7-484e-aa58-344bd79c92a1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1296046832-172.17.0.8-1595301108926:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33710,DS-8cbf90ca-30c6-4ed9-a0e3-5204c7ff2b1a,DISK], DatanodeInfoWithStorage[127.0.0.1:43304,DS-af4e7a78-5aa9-4378-b202-5abbec0218b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33472,DS-75e591a3-2fba-4e17-bfc6-dbf2e49996bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42145,DS-9e95c4ae-484b-42f0-81f7-3a51466a16f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44004,DS-a7207ae3-7ce5-4102-8456-342747a32833,DISK], DatanodeInfoWithStorage[127.0.0.1:35096,DS-b27a08da-10d8-4809-9981-3bd0d0fa21a5,DISK], DatanodeInfoWithStorage[127.0.0.1:45826,DS-488c9a92-eb9b-4588-89a9-1b0de043dc63,DISK], DatanodeInfoWithStorage[127.0.0.1:42087,DS-cecacb70-e3a7-484e-aa58-344bd79c92a1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1260563619-172.17.0.8-1595301209876:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39996,DS-e948df9c-24fd-4495-a48f-a95dca9dae25,DISK], DatanodeInfoWithStorage[127.0.0.1:34195,DS-53226425-f36e-40b0-9585-c59406d5831b,DISK], DatanodeInfoWithStorage[127.0.0.1:39851,DS-b1a6fd33-8dd6-4e71-a416-476a10ab02af,DISK], DatanodeInfoWithStorage[127.0.0.1:34889,DS-64fcfcd9-28bb-4341-915a-c9cd3d29643f,DISK], DatanodeInfoWithStorage[127.0.0.1:40071,DS-ba8e2c06-138c-4717-9031-0bd873dea238,DISK], DatanodeInfoWithStorage[127.0.0.1:44098,DS-3069ba7f-2977-48a1-ac15-ffb45c0ec309,DISK], DatanodeInfoWithStorage[127.0.0.1:43676,DS-e660d188-7d1d-487f-8d84-7a89691e4a71,DISK], DatanodeInfoWithStorage[127.0.0.1:39988,DS-fd75ed97-1f4e-46f0-af72-7429a9977d36,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1260563619-172.17.0.8-1595301209876:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39996,DS-e948df9c-24fd-4495-a48f-a95dca9dae25,DISK], DatanodeInfoWithStorage[127.0.0.1:34195,DS-53226425-f36e-40b0-9585-c59406d5831b,DISK], DatanodeInfoWithStorage[127.0.0.1:39851,DS-b1a6fd33-8dd6-4e71-a416-476a10ab02af,DISK], DatanodeInfoWithStorage[127.0.0.1:34889,DS-64fcfcd9-28bb-4341-915a-c9cd3d29643f,DISK], DatanodeInfoWithStorage[127.0.0.1:40071,DS-ba8e2c06-138c-4717-9031-0bd873dea238,DISK], DatanodeInfoWithStorage[127.0.0.1:44098,DS-3069ba7f-2977-48a1-ac15-ffb45c0ec309,DISK], DatanodeInfoWithStorage[127.0.0.1:43676,DS-e660d188-7d1d-487f-8d84-7a89691e4a71,DISK], DatanodeInfoWithStorage[127.0.0.1:39988,DS-fd75ed97-1f4e-46f0-af72-7429a9977d36,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1278815816-172.17.0.8-1595301391627:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40481,DS-4097e1b2-f813-49d8-b88c-bc08696f6142,DISK], DatanodeInfoWithStorage[127.0.0.1:39040,DS-1f3c7076-4372-4544-b1b6-9ecad8e8e898,DISK], DatanodeInfoWithStorage[127.0.0.1:40567,DS-3922247d-7072-44f4-b6b9-bd3585839de4,DISK], DatanodeInfoWithStorage[127.0.0.1:32785,DS-51852196-c126-49bc-af38-5b0a841ed356,DISK], DatanodeInfoWithStorage[127.0.0.1:41913,DS-cb5e7e46-e4e7-48c8-8780-095704b94724,DISK], DatanodeInfoWithStorage[127.0.0.1:36939,DS-f8419834-cd30-4d87-985a-b2b53bbe2bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:44617,DS-d5c6ec38-9541-4005-8bfa-b4b7cff9692c,DISK], DatanodeInfoWithStorage[127.0.0.1:45542,DS-8597cd62-aad6-4413-b088-ad75260f9386,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1278815816-172.17.0.8-1595301391627:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40481,DS-4097e1b2-f813-49d8-b88c-bc08696f6142,DISK], DatanodeInfoWithStorage[127.0.0.1:39040,DS-1f3c7076-4372-4544-b1b6-9ecad8e8e898,DISK], DatanodeInfoWithStorage[127.0.0.1:40567,DS-3922247d-7072-44f4-b6b9-bd3585839de4,DISK], DatanodeInfoWithStorage[127.0.0.1:32785,DS-51852196-c126-49bc-af38-5b0a841ed356,DISK], DatanodeInfoWithStorage[127.0.0.1:41913,DS-cb5e7e46-e4e7-48c8-8780-095704b94724,DISK], DatanodeInfoWithStorage[127.0.0.1:36939,DS-f8419834-cd30-4d87-985a-b2b53bbe2bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:44617,DS-d5c6ec38-9541-4005-8bfa-b4b7cff9692c,DISK], DatanodeInfoWithStorage[127.0.0.1:45542,DS-8597cd62-aad6-4413-b088-ad75260f9386,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1953012817-172.17.0.8-1595301635644:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39659,DS-dd320640-c775-451d-8107-42c3234b57b2,DISK], DatanodeInfoWithStorage[127.0.0.1:39010,DS-1ff267a2-fc14-4166-b0fb-a429a94b3595,DISK], DatanodeInfoWithStorage[127.0.0.1:46606,DS-04d02d6f-fadb-4a17-89f7-a0dafcde3f2a,DISK], DatanodeInfoWithStorage[127.0.0.1:39369,DS-9eaf0382-e673-4cb1-885c-4ce8e5e4cd75,DISK], DatanodeInfoWithStorage[127.0.0.1:40750,DS-cc09bc25-30d3-4d32-a5f4-5e79a39c223f,DISK], DatanodeInfoWithStorage[127.0.0.1:36113,DS-52499334-4369-4c01-8981-d8f481ac4e00,DISK], DatanodeInfoWithStorage[127.0.0.1:33839,DS-78d034d4-a8b5-4328-a6a3-55b9d4aa82fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38754,DS-5e6448b9-b8d8-4c1a-9e42-a10748bf5075,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1953012817-172.17.0.8-1595301635644:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39659,DS-dd320640-c775-451d-8107-42c3234b57b2,DISK], DatanodeInfoWithStorage[127.0.0.1:39010,DS-1ff267a2-fc14-4166-b0fb-a429a94b3595,DISK], DatanodeInfoWithStorage[127.0.0.1:46606,DS-04d02d6f-fadb-4a17-89f7-a0dafcde3f2a,DISK], DatanodeInfoWithStorage[127.0.0.1:39369,DS-9eaf0382-e673-4cb1-885c-4ce8e5e4cd75,DISK], DatanodeInfoWithStorage[127.0.0.1:40750,DS-cc09bc25-30d3-4d32-a5f4-5e79a39c223f,DISK], DatanodeInfoWithStorage[127.0.0.1:36113,DS-52499334-4369-4c01-8981-d8f481ac4e00,DISK], DatanodeInfoWithStorage[127.0.0.1:33839,DS-78d034d4-a8b5-4328-a6a3-55b9d4aa82fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38754,DS-5e6448b9-b8d8-4c1a-9e42-a10748bf5075,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-851460348-172.17.0.8-1595301897238:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34239,DS-89886207-1599-484e-bf35-b0f4c2d8b09d,DISK], DatanodeInfoWithStorage[127.0.0.1:44428,DS-05a25d37-cb59-4061-ac25-e56adbe868fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34612,DS-33c49f23-5bfd-4ba7-bf69-a39e3224a3b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44612,DS-61590f28-25b5-4a39-8c8c-21c4c6240827,DISK], DatanodeInfoWithStorage[127.0.0.1:39700,DS-54fecb40-cf67-4696-a396-8cd2710a44ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38728,DS-0f794e01-eb7d-48e8-bd9e-d894133a8ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:44806,DS-bd7cb229-5ccb-4011-9a31-149635e536cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35621,DS-74962850-ca34-4db0-b6ee-a585a5371269,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-851460348-172.17.0.8-1595301897238:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34239,DS-89886207-1599-484e-bf35-b0f4c2d8b09d,DISK], DatanodeInfoWithStorage[127.0.0.1:44428,DS-05a25d37-cb59-4061-ac25-e56adbe868fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34612,DS-33c49f23-5bfd-4ba7-bf69-a39e3224a3b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44612,DS-61590f28-25b5-4a39-8c8c-21c4c6240827,DISK], DatanodeInfoWithStorage[127.0.0.1:39700,DS-54fecb40-cf67-4696-a396-8cd2710a44ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38728,DS-0f794e01-eb7d-48e8-bd9e-d894133a8ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:44806,DS-bd7cb229-5ccb-4011-9a31-149635e536cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35621,DS-74962850-ca34-4db0-b6ee-a585a5371269,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1961824717-172.17.0.8-1595301924289:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41432,DS-3f7b04a2-ecb9-46c3-8ed9-88a9cc0e9808,DISK], DatanodeInfoWithStorage[127.0.0.1:44975,DS-1f0a5d1d-7042-45b0-804e-1bb53c2b6318,DISK], DatanodeInfoWithStorage[127.0.0.1:35396,DS-f8ed43c2-677b-463b-bb55-0ef232efacbf,DISK], DatanodeInfoWithStorage[127.0.0.1:33926,DS-6304a698-1209-424c-8f87-5986d41e474a,DISK], DatanodeInfoWithStorage[127.0.0.1:46469,DS-bd312f76-1f39-4f35-b123-7e8f961ac4b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45798,DS-aac5904e-1e7f-425f-adde-48851c7aec74,DISK], DatanodeInfoWithStorage[127.0.0.1:44553,DS-0487839d-4862-4cc7-878b-c1c29c6f1540,DISK], DatanodeInfoWithStorage[127.0.0.1:33693,DS-9a098f2d-1281-49da-9dd4-4b815efb8269,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1961824717-172.17.0.8-1595301924289:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41432,DS-3f7b04a2-ecb9-46c3-8ed9-88a9cc0e9808,DISK], DatanodeInfoWithStorage[127.0.0.1:44975,DS-1f0a5d1d-7042-45b0-804e-1bb53c2b6318,DISK], DatanodeInfoWithStorage[127.0.0.1:35396,DS-f8ed43c2-677b-463b-bb55-0ef232efacbf,DISK], DatanodeInfoWithStorage[127.0.0.1:33926,DS-6304a698-1209-424c-8f87-5986d41e474a,DISK], DatanodeInfoWithStorage[127.0.0.1:46469,DS-bd312f76-1f39-4f35-b123-7e8f961ac4b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45798,DS-aac5904e-1e7f-425f-adde-48851c7aec74,DISK], DatanodeInfoWithStorage[127.0.0.1:44553,DS-0487839d-4862-4cc7-878b-c1c29c6f1540,DISK], DatanodeInfoWithStorage[127.0.0.1:33693,DS-9a098f2d-1281-49da-9dd4-4b815efb8269,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1742184284-172.17.0.8-1595301957432:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38881,DS-76afbd6d-0246-4068-b258-4456a0b13444,DISK], DatanodeInfoWithStorage[127.0.0.1:32888,DS-a7136bc0-771d-4556-8a22-1fc03fd469d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45251,DS-51316015-1c97-49d7-bfdb-770cf6a65c99,DISK], DatanodeInfoWithStorage[127.0.0.1:41773,DS-3be02ea9-39bf-4d62-9216-491416fcad3f,DISK], DatanodeInfoWithStorage[127.0.0.1:43984,DS-bf432f12-5309-4687-a45f-64fb29c5252d,DISK], DatanodeInfoWithStorage[127.0.0.1:46000,DS-bd36c2b7-2c71-4312-afa7-0f5176e6ec56,DISK], DatanodeInfoWithStorage[127.0.0.1:43644,DS-404ced7c-26a9-4731-801c-55adeed9fc4e,DISK], DatanodeInfoWithStorage[127.0.0.1:41293,DS-2ecd6ac4-b4f1-4ccf-8f05-327094fad24d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1742184284-172.17.0.8-1595301957432:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38881,DS-76afbd6d-0246-4068-b258-4456a0b13444,DISK], DatanodeInfoWithStorage[127.0.0.1:32888,DS-a7136bc0-771d-4556-8a22-1fc03fd469d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45251,DS-51316015-1c97-49d7-bfdb-770cf6a65c99,DISK], DatanodeInfoWithStorage[127.0.0.1:41773,DS-3be02ea9-39bf-4d62-9216-491416fcad3f,DISK], DatanodeInfoWithStorage[127.0.0.1:43984,DS-bf432f12-5309-4687-a45f-64fb29c5252d,DISK], DatanodeInfoWithStorage[127.0.0.1:46000,DS-bd36c2b7-2c71-4312-afa7-0f5176e6ec56,DISK], DatanodeInfoWithStorage[127.0.0.1:43644,DS-404ced7c-26a9-4731-801c-55adeed9fc4e,DISK], DatanodeInfoWithStorage[127.0.0.1:41293,DS-2ecd6ac4-b4f1-4ccf-8f05-327094fad24d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-130832702-172.17.0.8-1595302216852:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45676,DS-8c995041-9b1d-49f9-b5e7-c0637c57ee79,DISK], DatanodeInfoWithStorage[127.0.0.1:38499,DS-5621c2e6-2e5f-480a-944f-95f746e53c16,DISK], DatanodeInfoWithStorage[127.0.0.1:42315,DS-3bf9aadf-ad8d-48d3-a7dc-f5b8f233f186,DISK], DatanodeInfoWithStorage[127.0.0.1:39317,DS-d81bd595-ed8b-4f98-ad2d-27507915b84d,DISK], DatanodeInfoWithStorage[127.0.0.1:38712,DS-8836428c-8089-499b-b81a-5adc2536de00,DISK], DatanodeInfoWithStorage[127.0.0.1:38571,DS-2161a54d-58f0-4bea-a369-17b7be9527b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36176,DS-cc933901-58e7-4a4e-89e1-0cef3a8a7772,DISK], DatanodeInfoWithStorage[127.0.0.1:36737,DS-3bafb128-fc37-4530-b8ea-4d616c954194,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-130832702-172.17.0.8-1595302216852:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45676,DS-8c995041-9b1d-49f9-b5e7-c0637c57ee79,DISK], DatanodeInfoWithStorage[127.0.0.1:38499,DS-5621c2e6-2e5f-480a-944f-95f746e53c16,DISK], DatanodeInfoWithStorage[127.0.0.1:42315,DS-3bf9aadf-ad8d-48d3-a7dc-f5b8f233f186,DISK], DatanodeInfoWithStorage[127.0.0.1:39317,DS-d81bd595-ed8b-4f98-ad2d-27507915b84d,DISK], DatanodeInfoWithStorage[127.0.0.1:38712,DS-8836428c-8089-499b-b81a-5adc2536de00,DISK], DatanodeInfoWithStorage[127.0.0.1:38571,DS-2161a54d-58f0-4bea-a369-17b7be9527b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36176,DS-cc933901-58e7-4a4e-89e1-0cef3a8a7772,DISK], DatanodeInfoWithStorage[127.0.0.1:36737,DS-3bafb128-fc37-4530-b8ea-4d616c954194,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-392545443-172.17.0.8-1595302541732:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41363,DS-014ecc3b-46a4-4575-b37a-ce2df8333cc3,DISK], DatanodeInfoWithStorage[127.0.0.1:42059,DS-4d66c81a-5369-484f-b46e-272dde30cd4b,DISK], DatanodeInfoWithStorage[127.0.0.1:34462,DS-960ddcf0-1aa3-4166-a228-be9b38bc3e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:43606,DS-f1e71bb9-f484-4e3b-a8d9-9e90246314b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39951,DS-8acb5274-ec26-49da-9cc3-8238198ac63e,DISK], DatanodeInfoWithStorage[127.0.0.1:37227,DS-91400601-4d1e-4dde-a126-790d9097e889,DISK], DatanodeInfoWithStorage[127.0.0.1:33308,DS-a07e6b73-849c-4d41-bfeb-a66ca4ad67cc,DISK], DatanodeInfoWithStorage[127.0.0.1:41841,DS-4e155e24-a43e-4ec5-a915-7cc158efe2ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-392545443-172.17.0.8-1595302541732:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41363,DS-014ecc3b-46a4-4575-b37a-ce2df8333cc3,DISK], DatanodeInfoWithStorage[127.0.0.1:42059,DS-4d66c81a-5369-484f-b46e-272dde30cd4b,DISK], DatanodeInfoWithStorage[127.0.0.1:34462,DS-960ddcf0-1aa3-4166-a228-be9b38bc3e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:43606,DS-f1e71bb9-f484-4e3b-a8d9-9e90246314b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39951,DS-8acb5274-ec26-49da-9cc3-8238198ac63e,DISK], DatanodeInfoWithStorage[127.0.0.1:37227,DS-91400601-4d1e-4dde-a126-790d9097e889,DISK], DatanodeInfoWithStorage[127.0.0.1:33308,DS-a07e6b73-849c-4d41-bfeb-a66ca4ad67cc,DISK], DatanodeInfoWithStorage[127.0.0.1:41841,DS-4e155e24-a43e-4ec5-a915-7cc158efe2ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1183347972-172.17.0.8-1595302639838:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39919,DS-5b21777b-1445-43ac-b687-f7d611f8cf5e,DISK], DatanodeInfoWithStorage[127.0.0.1:42705,DS-566e95bf-6f58-4f08-9084-b9fea5936c31,DISK], DatanodeInfoWithStorage[127.0.0.1:41614,DS-6810eadf-a690-41a0-9fe8-bfa9167ac969,DISK], DatanodeInfoWithStorage[127.0.0.1:46555,DS-3f859545-200b-401d-92b2-8cf3f2f19039,DISK], DatanodeInfoWithStorage[127.0.0.1:44089,DS-64ac5453-8b3d-463a-a674-823d90b0636c,DISK], DatanodeInfoWithStorage[127.0.0.1:44952,DS-364c28d0-16f5-4d3f-8a97-e54536b5b13a,DISK], DatanodeInfoWithStorage[127.0.0.1:43298,DS-cfbff878-b24a-487b-bbf0-e5f2f99346de,DISK], DatanodeInfoWithStorage[127.0.0.1:42110,DS-8e9f1a55-6b1c-45d5-8636-d1127f5c2561,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1183347972-172.17.0.8-1595302639838:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39919,DS-5b21777b-1445-43ac-b687-f7d611f8cf5e,DISK], DatanodeInfoWithStorage[127.0.0.1:42705,DS-566e95bf-6f58-4f08-9084-b9fea5936c31,DISK], DatanodeInfoWithStorage[127.0.0.1:41614,DS-6810eadf-a690-41a0-9fe8-bfa9167ac969,DISK], DatanodeInfoWithStorage[127.0.0.1:46555,DS-3f859545-200b-401d-92b2-8cf3f2f19039,DISK], DatanodeInfoWithStorage[127.0.0.1:44089,DS-64ac5453-8b3d-463a-a674-823d90b0636c,DISK], DatanodeInfoWithStorage[127.0.0.1:44952,DS-364c28d0-16f5-4d3f-8a97-e54536b5b13a,DISK], DatanodeInfoWithStorage[127.0.0.1:43298,DS-cfbff878-b24a-487b-bbf0-e5f2f99346de,DISK], DatanodeInfoWithStorage[127.0.0.1:42110,DS-8e9f1a55-6b1c-45d5-8636-d1127f5c2561,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-512205205-172.17.0.8-1595302776829:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46491,DS-66786f08-2f3b-48c1-8339-04ec0ec237e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41554,DS-488fe112-f965-4f25-8718-d5070a47938a,DISK], DatanodeInfoWithStorage[127.0.0.1:36743,DS-a17553e1-0845-4e42-9f49-65390be8d5f9,DISK], DatanodeInfoWithStorage[127.0.0.1:40697,DS-d0496fb9-2905-45c7-a007-23a2042f3b63,DISK], DatanodeInfoWithStorage[127.0.0.1:37516,DS-d44dbd9f-356f-4d7f-8a5d-803897fc1fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:40095,DS-1cfc7e9a-4095-4b0c-bd3f-875a4768e2a3,DISK], DatanodeInfoWithStorage[127.0.0.1:46630,DS-224349b5-a13b-4f03-a6a7-49305b885e72,DISK], DatanodeInfoWithStorage[127.0.0.1:45592,DS-6f9662b1-fda0-49fa-8eef-295e7e548343,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-512205205-172.17.0.8-1595302776829:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46491,DS-66786f08-2f3b-48c1-8339-04ec0ec237e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41554,DS-488fe112-f965-4f25-8718-d5070a47938a,DISK], DatanodeInfoWithStorage[127.0.0.1:36743,DS-a17553e1-0845-4e42-9f49-65390be8d5f9,DISK], DatanodeInfoWithStorage[127.0.0.1:40697,DS-d0496fb9-2905-45c7-a007-23a2042f3b63,DISK], DatanodeInfoWithStorage[127.0.0.1:37516,DS-d44dbd9f-356f-4d7f-8a5d-803897fc1fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:40095,DS-1cfc7e9a-4095-4b0c-bd3f-875a4768e2a3,DISK], DatanodeInfoWithStorage[127.0.0.1:46630,DS-224349b5-a13b-4f03-a6a7-49305b885e72,DISK], DatanodeInfoWithStorage[127.0.0.1:45592,DS-6f9662b1-fda0-49fa-8eef-295e7e548343,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1883204879-172.17.0.8-1595303207266:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46398,DS-ffaa38d8-f9d4-4230-8c02-3bbaa5bd254e,DISK], DatanodeInfoWithStorage[127.0.0.1:40070,DS-1004010a-e725-48ff-a89c-f703aeb1ce29,DISK], DatanodeInfoWithStorage[127.0.0.1:37128,DS-fad3a811-c1da-451b-a5df-a0bf7b0a1856,DISK], DatanodeInfoWithStorage[127.0.0.1:32790,DS-75f79ec7-4be3-4b87-8618-136368aabdbf,DISK], DatanodeInfoWithStorage[127.0.0.1:39656,DS-b1fe8ca2-a500-4f99-8828-b4a301861591,DISK], DatanodeInfoWithStorage[127.0.0.1:46649,DS-7a74296b-1058-48d5-bac0-7d053273bdc6,DISK], DatanodeInfoWithStorage[127.0.0.1:39987,DS-99768bf1-78a2-43fe-b3d6-faa6d6346716,DISK], DatanodeInfoWithStorage[127.0.0.1:32964,DS-316e7e7c-e819-41f3-bddc-c503d186ec06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1883204879-172.17.0.8-1595303207266:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46398,DS-ffaa38d8-f9d4-4230-8c02-3bbaa5bd254e,DISK], DatanodeInfoWithStorage[127.0.0.1:40070,DS-1004010a-e725-48ff-a89c-f703aeb1ce29,DISK], DatanodeInfoWithStorage[127.0.0.1:37128,DS-fad3a811-c1da-451b-a5df-a0bf7b0a1856,DISK], DatanodeInfoWithStorage[127.0.0.1:32790,DS-75f79ec7-4be3-4b87-8618-136368aabdbf,DISK], DatanodeInfoWithStorage[127.0.0.1:39656,DS-b1fe8ca2-a500-4f99-8828-b4a301861591,DISK], DatanodeInfoWithStorage[127.0.0.1:46649,DS-7a74296b-1058-48d5-bac0-7d053273bdc6,DISK], DatanodeInfoWithStorage[127.0.0.1:39987,DS-99768bf1-78a2-43fe-b3d6-faa6d6346716,DISK], DatanodeInfoWithStorage[127.0.0.1:32964,DS-316e7e7c-e819-41f3-bddc-c503d186ec06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1443808510-172.17.0.8-1595303252621:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43601,DS-e0f76333-0584-4596-bb6a-063ec9de3a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:41362,DS-c1431a61-2ef2-4388-8543-14bf266eece3,DISK], DatanodeInfoWithStorage[127.0.0.1:43874,DS-7d1b0525-f9cf-4b82-a1ca-08d1a378ca1f,DISK], DatanodeInfoWithStorage[127.0.0.1:42827,DS-e8710c3e-31cf-4a43-8d04-63de94a817ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45691,DS-8d12e82a-b491-4d79-8e10-9a7f01f2b30f,DISK], DatanodeInfoWithStorage[127.0.0.1:40129,DS-40bcf413-9412-4218-b2d4-c5de0f7b2e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:45667,DS-eb33bce4-aca3-4ea3-911a-dff05ced1d26,DISK], DatanodeInfoWithStorage[127.0.0.1:41923,DS-88cddbfd-2c95-4a1e-8753-e9f30c54c15a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1443808510-172.17.0.8-1595303252621:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43601,DS-e0f76333-0584-4596-bb6a-063ec9de3a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:41362,DS-c1431a61-2ef2-4388-8543-14bf266eece3,DISK], DatanodeInfoWithStorage[127.0.0.1:43874,DS-7d1b0525-f9cf-4b82-a1ca-08d1a378ca1f,DISK], DatanodeInfoWithStorage[127.0.0.1:42827,DS-e8710c3e-31cf-4a43-8d04-63de94a817ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45691,DS-8d12e82a-b491-4d79-8e10-9a7f01f2b30f,DISK], DatanodeInfoWithStorage[127.0.0.1:40129,DS-40bcf413-9412-4218-b2d4-c5de0f7b2e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:45667,DS-eb33bce4-aca3-4ea3-911a-dff05ced1d26,DISK], DatanodeInfoWithStorage[127.0.0.1:41923,DS-88cddbfd-2c95-4a1e-8753-e9f30c54c15a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-498395422-172.17.0.8-1595303327208:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44769,DS-f1657ecc-b507-4cf7-8082-a187d8e33311,DISK], DatanodeInfoWithStorage[127.0.0.1:40479,DS-a5cfd111-1612-44d9-82ec-b0f5e1b40c72,DISK], DatanodeInfoWithStorage[127.0.0.1:43391,DS-78e9f53f-9733-41b5-adc5-433f5dfe1461,DISK], DatanodeInfoWithStorage[127.0.0.1:37759,DS-d7bcb720-8513-4595-9065-e5ec3d1c08c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34506,DS-c091c8ca-f06c-4837-b177-2effd081a1a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35405,DS-cdf990af-3b90-45c5-bb89-e82d9256d6aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40937,DS-df1371b1-283d-4c22-8e12-cb0f087bfd54,DISK], DatanodeInfoWithStorage[127.0.0.1:39433,DS-668e2042-1624-4b99-8b67-be4352e4d64e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-498395422-172.17.0.8-1595303327208:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44769,DS-f1657ecc-b507-4cf7-8082-a187d8e33311,DISK], DatanodeInfoWithStorage[127.0.0.1:40479,DS-a5cfd111-1612-44d9-82ec-b0f5e1b40c72,DISK], DatanodeInfoWithStorage[127.0.0.1:43391,DS-78e9f53f-9733-41b5-adc5-433f5dfe1461,DISK], DatanodeInfoWithStorage[127.0.0.1:37759,DS-d7bcb720-8513-4595-9065-e5ec3d1c08c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34506,DS-c091c8ca-f06c-4837-b177-2effd081a1a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35405,DS-cdf990af-3b90-45c5-bb89-e82d9256d6aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40937,DS-df1371b1-283d-4c22-8e12-cb0f087bfd54,DISK], DatanodeInfoWithStorage[127.0.0.1:39433,DS-668e2042-1624-4b99-8b67-be4352e4d64e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-801322494-172.17.0.8-1595303369589:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42330,DS-9b6bfa49-9805-46f1-812c-68650f012ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:39566,DS-cf1a5031-99c8-4714-a38a-1a593c2c4ffb,DISK], DatanodeInfoWithStorage[127.0.0.1:36689,DS-4bc97c77-9a68-4afe-8e83-d05c5236be82,DISK], DatanodeInfoWithStorage[127.0.0.1:44640,DS-2a332194-b541-44b9-a18c-63fb52c79880,DISK], DatanodeInfoWithStorage[127.0.0.1:44581,DS-23032fce-5427-46f0-aa83-f46cb07761c3,DISK], DatanodeInfoWithStorage[127.0.0.1:39091,DS-d849758a-82ae-40f0-9786-6c065a340066,DISK], DatanodeInfoWithStorage[127.0.0.1:36469,DS-6ace4fa8-8eb8-452b-af51-5199017032e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40470,DS-65987895-08f4-419c-becd-c38683effc6e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-801322494-172.17.0.8-1595303369589:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42330,DS-9b6bfa49-9805-46f1-812c-68650f012ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:39566,DS-cf1a5031-99c8-4714-a38a-1a593c2c4ffb,DISK], DatanodeInfoWithStorage[127.0.0.1:36689,DS-4bc97c77-9a68-4afe-8e83-d05c5236be82,DISK], DatanodeInfoWithStorage[127.0.0.1:44640,DS-2a332194-b541-44b9-a18c-63fb52c79880,DISK], DatanodeInfoWithStorage[127.0.0.1:44581,DS-23032fce-5427-46f0-aa83-f46cb07761c3,DISK], DatanodeInfoWithStorage[127.0.0.1:39091,DS-d849758a-82ae-40f0-9786-6c065a340066,DISK], DatanodeInfoWithStorage[127.0.0.1:36469,DS-6ace4fa8-8eb8-452b-af51-5199017032e1,DISK], DatanodeInfoWithStorage[127.0.0.1:40470,DS-65987895-08f4-419c-becd-c38683effc6e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1832302891-172.17.0.8-1595303442383:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43986,DS-d7c39a3c-9831-4383-a156-415c4b4588fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46579,DS-3bdda5ec-cc26-4d74-8317-3bf56685c018,DISK], DatanodeInfoWithStorage[127.0.0.1:39345,DS-8103b799-bf63-4589-bfd4-4aa9ae489f68,DISK], DatanodeInfoWithStorage[127.0.0.1:41050,DS-8e13c311-3feb-470a-beb5-31a8d0200d01,DISK], DatanodeInfoWithStorage[127.0.0.1:46823,DS-9a9e6380-6ea6-4359-99fd-4db65ee668b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42062,DS-5a182c54-3ce3-4897-a4ae-c323ee732988,DISK], DatanodeInfoWithStorage[127.0.0.1:37242,DS-376b53e2-fe97-4c80-bf64-71813dc79d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:38670,DS-c0bc8c7a-9abc-48a4-96dd-601380606845,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1832302891-172.17.0.8-1595303442383:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43986,DS-d7c39a3c-9831-4383-a156-415c4b4588fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46579,DS-3bdda5ec-cc26-4d74-8317-3bf56685c018,DISK], DatanodeInfoWithStorage[127.0.0.1:39345,DS-8103b799-bf63-4589-bfd4-4aa9ae489f68,DISK], DatanodeInfoWithStorage[127.0.0.1:41050,DS-8e13c311-3feb-470a-beb5-31a8d0200d01,DISK], DatanodeInfoWithStorage[127.0.0.1:46823,DS-9a9e6380-6ea6-4359-99fd-4db65ee668b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42062,DS-5a182c54-3ce3-4897-a4ae-c323ee732988,DISK], DatanodeInfoWithStorage[127.0.0.1:37242,DS-376b53e2-fe97-4c80-bf64-71813dc79d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:38670,DS-c0bc8c7a-9abc-48a4-96dd-601380606845,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 17 out of 50
result: false positive !!!
Total execution time in seconds : 5188
