reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-431967959-172.17.0.4-1595404732847:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33749,DS-f26f5043-80d3-4b10-ba11-0c37dfafe8ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37969,DS-d1aa0468-b18f-4020-a713-6edf120f7f34,DISK], DatanodeInfoWithStorage[127.0.0.1:43298,DS-4af85b45-8e9b-4756-8e91-0c87f4d4f43b,DISK], DatanodeInfoWithStorage[127.0.0.1:38939,DS-769204b2-34fe-4ed4-a064-0f9ab6f7acec,DISK], DatanodeInfoWithStorage[127.0.0.1:33858,DS-875beb45-bcdd-4218-b5cb-335939bc3651,DISK], DatanodeInfoWithStorage[127.0.0.1:43360,DS-5cb51465-cb1d-48fe-8976-50c5881bf9af,DISK], DatanodeInfoWithStorage[127.0.0.1:39750,DS-e9aa356b-5769-4464-91aa-66c335c09e17,DISK], DatanodeInfoWithStorage[127.0.0.1:46194,DS-e77bba5d-c6c5-4cb1-a1f7-91918b0405f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-431967959-172.17.0.4-1595404732847:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33749,DS-f26f5043-80d3-4b10-ba11-0c37dfafe8ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37969,DS-d1aa0468-b18f-4020-a713-6edf120f7f34,DISK], DatanodeInfoWithStorage[127.0.0.1:43298,DS-4af85b45-8e9b-4756-8e91-0c87f4d4f43b,DISK], DatanodeInfoWithStorage[127.0.0.1:38939,DS-769204b2-34fe-4ed4-a064-0f9ab6f7acec,DISK], DatanodeInfoWithStorage[127.0.0.1:33858,DS-875beb45-bcdd-4218-b5cb-335939bc3651,DISK], DatanodeInfoWithStorage[127.0.0.1:43360,DS-5cb51465-cb1d-48fe-8976-50c5881bf9af,DISK], DatanodeInfoWithStorage[127.0.0.1:39750,DS-e9aa356b-5769-4464-91aa-66c335c09e17,DISK], DatanodeInfoWithStorage[127.0.0.1:46194,DS-e77bba5d-c6c5-4cb1-a1f7-91918b0405f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2052696981-172.17.0.4-1595404772435:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34276,DS-201071ce-21f5-47d2-8ecc-b72117bd3f35,DISK], DatanodeInfoWithStorage[127.0.0.1:39905,DS-d3c78c47-19aa-4d30-b90a-72af433fbaa2,DISK], DatanodeInfoWithStorage[127.0.0.1:43938,DS-b7a5aabe-dae3-4ba9-ad4f-7c778e81a09d,DISK], DatanodeInfoWithStorage[127.0.0.1:33338,DS-bfabe11b-96b4-4bc8-a374-898944aef15f,DISK], DatanodeInfoWithStorage[127.0.0.1:44389,DS-284033e7-5019-4a08-a1a6-140a254d6ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:43367,DS-24849a97-dd70-4ead-ad1b-30da38ed2d49,DISK], DatanodeInfoWithStorage[127.0.0.1:46808,DS-19cf8c49-08a4-42cf-9c51-8dc28f22b603,DISK], DatanodeInfoWithStorage[127.0.0.1:41350,DS-cb157003-e5f4-4e94-a128-dcbaed65dcac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2052696981-172.17.0.4-1595404772435:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34276,DS-201071ce-21f5-47d2-8ecc-b72117bd3f35,DISK], DatanodeInfoWithStorage[127.0.0.1:39905,DS-d3c78c47-19aa-4d30-b90a-72af433fbaa2,DISK], DatanodeInfoWithStorage[127.0.0.1:43938,DS-b7a5aabe-dae3-4ba9-ad4f-7c778e81a09d,DISK], DatanodeInfoWithStorage[127.0.0.1:33338,DS-bfabe11b-96b4-4bc8-a374-898944aef15f,DISK], DatanodeInfoWithStorage[127.0.0.1:44389,DS-284033e7-5019-4a08-a1a6-140a254d6ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:43367,DS-24849a97-dd70-4ead-ad1b-30da38ed2d49,DISK], DatanodeInfoWithStorage[127.0.0.1:46808,DS-19cf8c49-08a4-42cf-9c51-8dc28f22b603,DISK], DatanodeInfoWithStorage[127.0.0.1:41350,DS-cb157003-e5f4-4e94-a128-dcbaed65dcac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1749254229-172.17.0.4-1595405087194:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43375,DS-405d3e9f-3fd2-40b9-9c9b-9ed6f2f6614d,DISK], DatanodeInfoWithStorage[127.0.0.1:46330,DS-0cac8df3-ec38-4196-8e84-1706722038b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37533,DS-f0f3ff3c-0726-45bc-ab02-00eb6b49f6dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45165,DS-98ddc746-3c22-4f07-9a3c-e33d7f461205,DISK], DatanodeInfoWithStorage[127.0.0.1:37494,DS-5dfa48b9-83ae-4e5e-9b17-4a074f7876ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39502,DS-5c8c739d-322c-4d5f-a991-f3b6188d4eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:39961,DS-e900a1a6-ccd2-4bc4-b49c-1488d1ffd11e,DISK], DatanodeInfoWithStorage[127.0.0.1:44334,DS-e3f4b7b1-142b-4a7f-8fac-00f34efbdd66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1749254229-172.17.0.4-1595405087194:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43375,DS-405d3e9f-3fd2-40b9-9c9b-9ed6f2f6614d,DISK], DatanodeInfoWithStorage[127.0.0.1:46330,DS-0cac8df3-ec38-4196-8e84-1706722038b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37533,DS-f0f3ff3c-0726-45bc-ab02-00eb6b49f6dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45165,DS-98ddc746-3c22-4f07-9a3c-e33d7f461205,DISK], DatanodeInfoWithStorage[127.0.0.1:37494,DS-5dfa48b9-83ae-4e5e-9b17-4a074f7876ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39502,DS-5c8c739d-322c-4d5f-a991-f3b6188d4eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:39961,DS-e900a1a6-ccd2-4bc4-b49c-1488d1ffd11e,DISK], DatanodeInfoWithStorage[127.0.0.1:44334,DS-e3f4b7b1-142b-4a7f-8fac-00f34efbdd66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2017057643-172.17.0.4-1595405316630:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43152,DS-1bb8ae39-b3aa-41ac-8616-33cba4938c52,DISK], DatanodeInfoWithStorage[127.0.0.1:33545,DS-29b7f219-ec11-412c-b3dd-0df7c1cf89e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34581,DS-09197d71-d3bb-4d6d-9165-ca07275a1c71,DISK], DatanodeInfoWithStorage[127.0.0.1:44088,DS-111b847c-6e83-499a-b262-3f0c4ccc664f,DISK], DatanodeInfoWithStorage[127.0.0.1:37316,DS-7a56a7e7-78ca-4fe0-8ce7-f74931ac976a,DISK], DatanodeInfoWithStorage[127.0.0.1:33632,DS-fc783b31-24f9-4a40-891f-55386b88c43d,DISK], DatanodeInfoWithStorage[127.0.0.1:42881,DS-ce3c705e-2a4f-4be0-a08e-a1c20d7dc842,DISK], DatanodeInfoWithStorage[127.0.0.1:41529,DS-a902c00b-cc5d-4b10-836b-4746114a6001,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2017057643-172.17.0.4-1595405316630:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43152,DS-1bb8ae39-b3aa-41ac-8616-33cba4938c52,DISK], DatanodeInfoWithStorage[127.0.0.1:33545,DS-29b7f219-ec11-412c-b3dd-0df7c1cf89e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34581,DS-09197d71-d3bb-4d6d-9165-ca07275a1c71,DISK], DatanodeInfoWithStorage[127.0.0.1:44088,DS-111b847c-6e83-499a-b262-3f0c4ccc664f,DISK], DatanodeInfoWithStorage[127.0.0.1:37316,DS-7a56a7e7-78ca-4fe0-8ce7-f74931ac976a,DISK], DatanodeInfoWithStorage[127.0.0.1:33632,DS-fc783b31-24f9-4a40-891f-55386b88c43d,DISK], DatanodeInfoWithStorage[127.0.0.1:42881,DS-ce3c705e-2a4f-4be0-a08e-a1c20d7dc842,DISK], DatanodeInfoWithStorage[127.0.0.1:41529,DS-a902c00b-cc5d-4b10-836b-4746114a6001,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-52634889-172.17.0.4-1595406146809:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36250,DS-a481568b-0e78-4950-81af-dafa98987c8b,DISK], DatanodeInfoWithStorage[127.0.0.1:46392,DS-6ee8539a-3bf9-48fa-8a66-a8b1ff96f7fb,DISK], DatanodeInfoWithStorage[127.0.0.1:32888,DS-18a630aa-4226-4e63-a519-84589d3300d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35600,DS-d55bade0-5e6a-4d27-abe6-2f1b0b7ec102,DISK], DatanodeInfoWithStorage[127.0.0.1:34629,DS-951790f5-2dbf-4179-bc00-45ed3cc86ef0,DISK], DatanodeInfoWithStorage[127.0.0.1:33449,DS-4129fc95-8c86-4b04-844c-9794e7f8971e,DISK], DatanodeInfoWithStorage[127.0.0.1:34725,DS-f6918ff2-b79d-4a5c-ba8a-1bb299247597,DISK], DatanodeInfoWithStorage[127.0.0.1:40027,DS-2909f225-85ae-46e9-9693-f6dc383fc5bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-52634889-172.17.0.4-1595406146809:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36250,DS-a481568b-0e78-4950-81af-dafa98987c8b,DISK], DatanodeInfoWithStorage[127.0.0.1:46392,DS-6ee8539a-3bf9-48fa-8a66-a8b1ff96f7fb,DISK], DatanodeInfoWithStorage[127.0.0.1:32888,DS-18a630aa-4226-4e63-a519-84589d3300d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35600,DS-d55bade0-5e6a-4d27-abe6-2f1b0b7ec102,DISK], DatanodeInfoWithStorage[127.0.0.1:34629,DS-951790f5-2dbf-4179-bc00-45ed3cc86ef0,DISK], DatanodeInfoWithStorage[127.0.0.1:33449,DS-4129fc95-8c86-4b04-844c-9794e7f8971e,DISK], DatanodeInfoWithStorage[127.0.0.1:34725,DS-f6918ff2-b79d-4a5c-ba8a-1bb299247597,DISK], DatanodeInfoWithStorage[127.0.0.1:40027,DS-2909f225-85ae-46e9-9693-f6dc383fc5bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1998115269-172.17.0.4-1595406434618:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34555,DS-80c7d6b7-1b7d-4026-ac09-ef1240f87a4c,DISK], DatanodeInfoWithStorage[127.0.0.1:35654,DS-ce555e84-cd65-41de-92d9-8801baf9a172,DISK], DatanodeInfoWithStorage[127.0.0.1:39700,DS-86ef29fd-44b6-4bad-b6fb-fb56a7e4e6e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39641,DS-3857a088-065e-4eed-b7d5-2e949fbfac73,DISK], DatanodeInfoWithStorage[127.0.0.1:45816,DS-8823f104-f7b3-4751-95e6-592bcd3395eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42725,DS-432eb435-0f36-4a0a-9e25-881fc574df7b,DISK], DatanodeInfoWithStorage[127.0.0.1:34987,DS-991fd6c8-ca66-4e6f-92cc-3f0f6f48a261,DISK], DatanodeInfoWithStorage[127.0.0.1:38595,DS-fb490b6f-89c9-4952-9c1f-d2d0972466b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1998115269-172.17.0.4-1595406434618:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34555,DS-80c7d6b7-1b7d-4026-ac09-ef1240f87a4c,DISK], DatanodeInfoWithStorage[127.0.0.1:35654,DS-ce555e84-cd65-41de-92d9-8801baf9a172,DISK], DatanodeInfoWithStorage[127.0.0.1:39700,DS-86ef29fd-44b6-4bad-b6fb-fb56a7e4e6e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39641,DS-3857a088-065e-4eed-b7d5-2e949fbfac73,DISK], DatanodeInfoWithStorage[127.0.0.1:45816,DS-8823f104-f7b3-4751-95e6-592bcd3395eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42725,DS-432eb435-0f36-4a0a-9e25-881fc574df7b,DISK], DatanodeInfoWithStorage[127.0.0.1:34987,DS-991fd6c8-ca66-4e6f-92cc-3f0f6f48a261,DISK], DatanodeInfoWithStorage[127.0.0.1:38595,DS-fb490b6f-89c9-4952-9c1f-d2d0972466b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1883951664-172.17.0.4-1595406475183:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37897,DS-4650fa71-7b89-45f7-a638-9323d66ce7b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33647,DS-17010953-d667-4091-b1ac-8ecfddf5c5f1,DISK], DatanodeInfoWithStorage[127.0.0.1:45085,DS-bad83a67-3242-48e0-b3f9-4a56e54c5827,DISK], DatanodeInfoWithStorage[127.0.0.1:46651,DS-51ea869a-f5c0-418e-919d-ba7c899cb8d8,DISK], DatanodeInfoWithStorage[127.0.0.1:34237,DS-d0feea2d-c30e-4903-a9ac-e74e3b76f504,DISK], DatanodeInfoWithStorage[127.0.0.1:32886,DS-73a0402f-e2eb-44a8-9703-a7125ed97adc,DISK], DatanodeInfoWithStorage[127.0.0.1:35872,DS-aa4a1f43-a6bb-47f6-9432-458c35784ddc,DISK], DatanodeInfoWithStorage[127.0.0.1:45364,DS-250fb0fe-cd52-481f-b386-0fd615cacc89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1883951664-172.17.0.4-1595406475183:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37897,DS-4650fa71-7b89-45f7-a638-9323d66ce7b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33647,DS-17010953-d667-4091-b1ac-8ecfddf5c5f1,DISK], DatanodeInfoWithStorage[127.0.0.1:45085,DS-bad83a67-3242-48e0-b3f9-4a56e54c5827,DISK], DatanodeInfoWithStorage[127.0.0.1:46651,DS-51ea869a-f5c0-418e-919d-ba7c899cb8d8,DISK], DatanodeInfoWithStorage[127.0.0.1:34237,DS-d0feea2d-c30e-4903-a9ac-e74e3b76f504,DISK], DatanodeInfoWithStorage[127.0.0.1:32886,DS-73a0402f-e2eb-44a8-9703-a7125ed97adc,DISK], DatanodeInfoWithStorage[127.0.0.1:35872,DS-aa4a1f43-a6bb-47f6-9432-458c35784ddc,DISK], DatanodeInfoWithStorage[127.0.0.1:45364,DS-250fb0fe-cd52-481f-b386-0fd615cacc89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-336765317-172.17.0.4-1595406884844:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39664,DS-a0269f89-fafc-4080-bd36-b0b0af8be91b,DISK], DatanodeInfoWithStorage[127.0.0.1:38668,DS-e0c31fdb-df8a-440c-ad37-49c82d4e186d,DISK], DatanodeInfoWithStorage[127.0.0.1:43654,DS-eac2c08d-e640-4f5d-a58a-cbff8129044f,DISK], DatanodeInfoWithStorage[127.0.0.1:35273,DS-e6195731-ce9f-4ecc-a20a-c18d96924ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:34268,DS-e55f82ce-1e6e-4dc1-928c-b91423b34fbb,DISK], DatanodeInfoWithStorage[127.0.0.1:33702,DS-c5552171-eef7-4816-99d0-89221410ab3d,DISK], DatanodeInfoWithStorage[127.0.0.1:44620,DS-85789039-f0bb-4325-8647-a8862191bb41,DISK], DatanodeInfoWithStorage[127.0.0.1:32864,DS-ed6baf84-0d81-409a-98c4-b18fb1ca98eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-336765317-172.17.0.4-1595406884844:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39664,DS-a0269f89-fafc-4080-bd36-b0b0af8be91b,DISK], DatanodeInfoWithStorage[127.0.0.1:38668,DS-e0c31fdb-df8a-440c-ad37-49c82d4e186d,DISK], DatanodeInfoWithStorage[127.0.0.1:43654,DS-eac2c08d-e640-4f5d-a58a-cbff8129044f,DISK], DatanodeInfoWithStorage[127.0.0.1:35273,DS-e6195731-ce9f-4ecc-a20a-c18d96924ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:34268,DS-e55f82ce-1e6e-4dc1-928c-b91423b34fbb,DISK], DatanodeInfoWithStorage[127.0.0.1:33702,DS-c5552171-eef7-4816-99d0-89221410ab3d,DISK], DatanodeInfoWithStorage[127.0.0.1:44620,DS-85789039-f0bb-4325-8647-a8862191bb41,DISK], DatanodeInfoWithStorage[127.0.0.1:32864,DS-ed6baf84-0d81-409a-98c4-b18fb1ca98eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1251126060-172.17.0.4-1595407249619:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44151,DS-e6f7ba2a-b186-47fb-aea8-87212e8df0ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40798,DS-2290b1b6-87fb-4c8f-b5aa-038057db465f,DISK], DatanodeInfoWithStorage[127.0.0.1:46008,DS-5c94a58f-1774-471f-a80b-27f1fc508591,DISK], DatanodeInfoWithStorage[127.0.0.1:40123,DS-b25d6c9b-48a7-4d59-aa4c-4653b5e9e23c,DISK], DatanodeInfoWithStorage[127.0.0.1:34419,DS-511d4d77-b46f-4254-8ae0-f31a3174c44e,DISK], DatanodeInfoWithStorage[127.0.0.1:45581,DS-31881806-7942-476e-ab2a-be20cd06061f,DISK], DatanodeInfoWithStorage[127.0.0.1:46323,DS-de73d95b-1e27-4cfc-a90e-f072ec3db4c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37557,DS-e4824816-ac1e-44f3-aa7f-3cd2a2baf843,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1251126060-172.17.0.4-1595407249619:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44151,DS-e6f7ba2a-b186-47fb-aea8-87212e8df0ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40798,DS-2290b1b6-87fb-4c8f-b5aa-038057db465f,DISK], DatanodeInfoWithStorage[127.0.0.1:46008,DS-5c94a58f-1774-471f-a80b-27f1fc508591,DISK], DatanodeInfoWithStorage[127.0.0.1:40123,DS-b25d6c9b-48a7-4d59-aa4c-4653b5e9e23c,DISK], DatanodeInfoWithStorage[127.0.0.1:34419,DS-511d4d77-b46f-4254-8ae0-f31a3174c44e,DISK], DatanodeInfoWithStorage[127.0.0.1:45581,DS-31881806-7942-476e-ab2a-be20cd06061f,DISK], DatanodeInfoWithStorage[127.0.0.1:46323,DS-de73d95b-1e27-4cfc-a90e-f072ec3db4c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37557,DS-e4824816-ac1e-44f3-aa7f-3cd2a2baf843,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1428407102-172.17.0.4-1595407689749:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39015,DS-7fe43247-5071-4ec2-9e05-df84a9e6809d,DISK], DatanodeInfoWithStorage[127.0.0.1:38126,DS-037824ec-76d9-4881-a027-0dc414849b46,DISK], DatanodeInfoWithStorage[127.0.0.1:38613,DS-d40f601e-bc94-4d1a-ab05-036889b31a93,DISK], DatanodeInfoWithStorage[127.0.0.1:46239,DS-82ca280a-28af-4a19-848b-131645594c79,DISK], DatanodeInfoWithStorage[127.0.0.1:38863,DS-25f66ab2-b801-4d3f-8353-40b8c436c1a9,DISK], DatanodeInfoWithStorage[127.0.0.1:32903,DS-1a128900-45ac-4347-aa89-9f5cb0cb3d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:37770,DS-fb22335b-ed9a-4c23-ad09-970d47f05403,DISK], DatanodeInfoWithStorage[127.0.0.1:40952,DS-e10f3f2d-62d8-4951-b627-eecf1a15fd4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1428407102-172.17.0.4-1595407689749:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39015,DS-7fe43247-5071-4ec2-9e05-df84a9e6809d,DISK], DatanodeInfoWithStorage[127.0.0.1:38126,DS-037824ec-76d9-4881-a027-0dc414849b46,DISK], DatanodeInfoWithStorage[127.0.0.1:38613,DS-d40f601e-bc94-4d1a-ab05-036889b31a93,DISK], DatanodeInfoWithStorage[127.0.0.1:46239,DS-82ca280a-28af-4a19-848b-131645594c79,DISK], DatanodeInfoWithStorage[127.0.0.1:38863,DS-25f66ab2-b801-4d3f-8353-40b8c436c1a9,DISK], DatanodeInfoWithStorage[127.0.0.1:32903,DS-1a128900-45ac-4347-aa89-9f5cb0cb3d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:37770,DS-fb22335b-ed9a-4c23-ad09-970d47f05403,DISK], DatanodeInfoWithStorage[127.0.0.1:40952,DS-e10f3f2d-62d8-4951-b627-eecf1a15fd4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1050657554-172.17.0.4-1595408179184:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40430,DS-e7ae9140-7583-4d17-b71d-3a3455dcf5ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38072,DS-e3099ceb-c747-4f0b-8f28-d81b818b580b,DISK], DatanodeInfoWithStorage[127.0.0.1:44302,DS-703a4495-34d8-49b7-9237-9c24788de09c,DISK], DatanodeInfoWithStorage[127.0.0.1:40336,DS-0d1be502-6d6b-4b48-b345-5236bcc522ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38131,DS-d7608dad-a357-4edd-a0f6-0fd18566376d,DISK], DatanodeInfoWithStorage[127.0.0.1:45825,DS-14426831-918c-41e3-bae3-6b9304ff4a07,DISK], DatanodeInfoWithStorage[127.0.0.1:44912,DS-af8bd46d-d0c9-4e48-ba06-9fb55a001d46,DISK], DatanodeInfoWithStorage[127.0.0.1:46879,DS-073b85c0-2dfe-4a64-ae97-0a5e21126c5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1050657554-172.17.0.4-1595408179184:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40430,DS-e7ae9140-7583-4d17-b71d-3a3455dcf5ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38072,DS-e3099ceb-c747-4f0b-8f28-d81b818b580b,DISK], DatanodeInfoWithStorage[127.0.0.1:44302,DS-703a4495-34d8-49b7-9237-9c24788de09c,DISK], DatanodeInfoWithStorage[127.0.0.1:40336,DS-0d1be502-6d6b-4b48-b345-5236bcc522ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38131,DS-d7608dad-a357-4edd-a0f6-0fd18566376d,DISK], DatanodeInfoWithStorage[127.0.0.1:45825,DS-14426831-918c-41e3-bae3-6b9304ff4a07,DISK], DatanodeInfoWithStorage[127.0.0.1:44912,DS-af8bd46d-d0c9-4e48-ba06-9fb55a001d46,DISK], DatanodeInfoWithStorage[127.0.0.1:46879,DS-073b85c0-2dfe-4a64-ae97-0a5e21126c5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-858039098-172.17.0.4-1595408396303:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32810,DS-1a7d1bbc-00a4-4f43-876a-e3b53055c1fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33030,DS-e215d34e-bc20-4480-9107-13dbc6cd9f64,DISK], DatanodeInfoWithStorage[127.0.0.1:34111,DS-ef0c0351-6856-463d-b51b-8e75b3960c8c,DISK], DatanodeInfoWithStorage[127.0.0.1:43672,DS-5c8577b7-920b-4315-8d5c-51900a479acd,DISK], DatanodeInfoWithStorage[127.0.0.1:41914,DS-de48fe41-b868-455b-85b8-3dd7f387f8e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35947,DS-9b0a8636-121a-4958-a13e-3836c0f758b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38443,DS-f92a37a0-a8bc-43c4-b14f-cf7809087394,DISK], DatanodeInfoWithStorage[127.0.0.1:40665,DS-42b98a06-572a-4f7a-8cb9-5c7104c3545f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-858039098-172.17.0.4-1595408396303:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32810,DS-1a7d1bbc-00a4-4f43-876a-e3b53055c1fa,DISK], DatanodeInfoWithStorage[127.0.0.1:33030,DS-e215d34e-bc20-4480-9107-13dbc6cd9f64,DISK], DatanodeInfoWithStorage[127.0.0.1:34111,DS-ef0c0351-6856-463d-b51b-8e75b3960c8c,DISK], DatanodeInfoWithStorage[127.0.0.1:43672,DS-5c8577b7-920b-4315-8d5c-51900a479acd,DISK], DatanodeInfoWithStorage[127.0.0.1:41914,DS-de48fe41-b868-455b-85b8-3dd7f387f8e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35947,DS-9b0a8636-121a-4958-a13e-3836c0f758b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38443,DS-f92a37a0-a8bc-43c4-b14f-cf7809087394,DISK], DatanodeInfoWithStorage[127.0.0.1:40665,DS-42b98a06-572a-4f7a-8cb9-5c7104c3545f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1239946275-172.17.0.4-1595409250318:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34126,DS-758f1d18-1a78-4fa9-ab1c-d14145f088d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37426,DS-c55807d6-971a-49ae-ab36-fa59e3fa069f,DISK], DatanodeInfoWithStorage[127.0.0.1:45865,DS-3233f824-6066-4538-9696-1a4433a2f289,DISK], DatanodeInfoWithStorage[127.0.0.1:45693,DS-85e5c0d3-bd27-447c-8715-199f35e27583,DISK], DatanodeInfoWithStorage[127.0.0.1:39157,DS-3cd98cc4-b80c-4de8-9839-4d30f47875aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36768,DS-6718d41d-c946-4333-b7be-a10a7f67f96e,DISK], DatanodeInfoWithStorage[127.0.0.1:43192,DS-7619d74c-805b-4e7c-ac9e-9e742a8e38e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43170,DS-4162aaf6-4e6d-4d31-bcec-b85c1413706d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1239946275-172.17.0.4-1595409250318:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34126,DS-758f1d18-1a78-4fa9-ab1c-d14145f088d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37426,DS-c55807d6-971a-49ae-ab36-fa59e3fa069f,DISK], DatanodeInfoWithStorage[127.0.0.1:45865,DS-3233f824-6066-4538-9696-1a4433a2f289,DISK], DatanodeInfoWithStorage[127.0.0.1:45693,DS-85e5c0d3-bd27-447c-8715-199f35e27583,DISK], DatanodeInfoWithStorage[127.0.0.1:39157,DS-3cd98cc4-b80c-4de8-9839-4d30f47875aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36768,DS-6718d41d-c946-4333-b7be-a10a7f67f96e,DISK], DatanodeInfoWithStorage[127.0.0.1:43192,DS-7619d74c-805b-4e7c-ac9e-9e742a8e38e4,DISK], DatanodeInfoWithStorage[127.0.0.1:43170,DS-4162aaf6-4e6d-4d31-bcec-b85c1413706d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1969823890-172.17.0.4-1595409898812:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44067,DS-f5b21815-028e-42a0-8567-1e1faa1053aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37916,DS-2a8a87a7-103d-465f-a518-8659138db21d,DISK], DatanodeInfoWithStorage[127.0.0.1:44871,DS-16e46543-62b0-44a3-9d87-d6994d32aa06,DISK], DatanodeInfoWithStorage[127.0.0.1:37395,DS-1af59931-ad97-4c22-acc8-424a31829343,DISK], DatanodeInfoWithStorage[127.0.0.1:37734,DS-37332bec-5615-43ec-8064-f4ca33ae8df9,DISK], DatanodeInfoWithStorage[127.0.0.1:34718,DS-fa14a24b-7c01-4964-81e2-4ea655439c27,DISK], DatanodeInfoWithStorage[127.0.0.1:43019,DS-29e780ff-b83a-44eb-a87e-9dbf8bdad881,DISK], DatanodeInfoWithStorage[127.0.0.1:33686,DS-f9b54889-1299-4bba-8fd9-948f089dc11e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1969823890-172.17.0.4-1595409898812:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44067,DS-f5b21815-028e-42a0-8567-1e1faa1053aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37916,DS-2a8a87a7-103d-465f-a518-8659138db21d,DISK], DatanodeInfoWithStorage[127.0.0.1:44871,DS-16e46543-62b0-44a3-9d87-d6994d32aa06,DISK], DatanodeInfoWithStorage[127.0.0.1:37395,DS-1af59931-ad97-4c22-acc8-424a31829343,DISK], DatanodeInfoWithStorage[127.0.0.1:37734,DS-37332bec-5615-43ec-8064-f4ca33ae8df9,DISK], DatanodeInfoWithStorage[127.0.0.1:34718,DS-fa14a24b-7c01-4964-81e2-4ea655439c27,DISK], DatanodeInfoWithStorage[127.0.0.1:43019,DS-29e780ff-b83a-44eb-a87e-9dbf8bdad881,DISK], DatanodeInfoWithStorage[127.0.0.1:33686,DS-f9b54889-1299-4bba-8fd9-948f089dc11e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1011695402-172.17.0.4-1595409967536:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39670,DS-cf866c7f-8f7d-4f58-a980-8a0689a4907a,DISK], DatanodeInfoWithStorage[127.0.0.1:40257,DS-0379e64e-bc19-47c4-9264-14180fbeb4de,DISK], DatanodeInfoWithStorage[127.0.0.1:40272,DS-a3ea4a24-367f-425b-84d6-f59e7c35c6ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36710,DS-c0d18fcc-2e65-4f7c-a8e4-6a50dba6a25c,DISK], DatanodeInfoWithStorage[127.0.0.1:34672,DS-1f02c17b-4977-4436-9774-08875e72282c,DISK], DatanodeInfoWithStorage[127.0.0.1:44985,DS-acc5943f-6a77-492b-ba5e-37d998de9dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:39349,DS-b9ad22a6-8e54-40a2-98c3-5d0c9e38f5da,DISK], DatanodeInfoWithStorage[127.0.0.1:44298,DS-f23b0067-841b-45f0-b320-6c1ab02896e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1011695402-172.17.0.4-1595409967536:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39670,DS-cf866c7f-8f7d-4f58-a980-8a0689a4907a,DISK], DatanodeInfoWithStorage[127.0.0.1:40257,DS-0379e64e-bc19-47c4-9264-14180fbeb4de,DISK], DatanodeInfoWithStorage[127.0.0.1:40272,DS-a3ea4a24-367f-425b-84d6-f59e7c35c6ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36710,DS-c0d18fcc-2e65-4f7c-a8e4-6a50dba6a25c,DISK], DatanodeInfoWithStorage[127.0.0.1:34672,DS-1f02c17b-4977-4436-9774-08875e72282c,DISK], DatanodeInfoWithStorage[127.0.0.1:44985,DS-acc5943f-6a77-492b-ba5e-37d998de9dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:39349,DS-b9ad22a6-8e54-40a2-98c3-5d0c9e38f5da,DISK], DatanodeInfoWithStorage[127.0.0.1:44298,DS-f23b0067-841b-45f0-b320-6c1ab02896e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-279978740-172.17.0.4-1595409998276:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43550,DS-d0d89681-06e3-4cb4-97ae-b15df389fb47,DISK], DatanodeInfoWithStorage[127.0.0.1:46352,DS-0bccd563-873d-48cf-8715-40f02a55139f,DISK], DatanodeInfoWithStorage[127.0.0.1:33510,DS-5b66e6d5-ca7c-4a62-9b7c-3386f73a69a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35687,DS-351a3788-0dcd-4e80-a018-5598c8556ea4,DISK], DatanodeInfoWithStorage[127.0.0.1:36167,DS-55dd027a-f982-4d1a-aed2-102a6f6605c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40925,DS-2c048ed0-6dee-4e8d-81cb-49da594b25ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42916,DS-89086f51-63ba-4aba-9db6-8a57452cba13,DISK], DatanodeInfoWithStorage[127.0.0.1:41974,DS-646b5207-162c-455f-895a-8e17873f9638,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-279978740-172.17.0.4-1595409998276:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43550,DS-d0d89681-06e3-4cb4-97ae-b15df389fb47,DISK], DatanodeInfoWithStorage[127.0.0.1:46352,DS-0bccd563-873d-48cf-8715-40f02a55139f,DISK], DatanodeInfoWithStorage[127.0.0.1:33510,DS-5b66e6d5-ca7c-4a62-9b7c-3386f73a69a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35687,DS-351a3788-0dcd-4e80-a018-5598c8556ea4,DISK], DatanodeInfoWithStorage[127.0.0.1:36167,DS-55dd027a-f982-4d1a-aed2-102a6f6605c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40925,DS-2c048ed0-6dee-4e8d-81cb-49da594b25ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42916,DS-89086f51-63ba-4aba-9db6-8a57452cba13,DISK], DatanodeInfoWithStorage[127.0.0.1:41974,DS-646b5207-162c-455f-895a-8e17873f9638,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5439
