reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1160056440-172.17.0.21-1596916330023:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35496,DS-df1eabd3-2daf-4b88-9459-96a2b407e741,DISK], DatanodeInfoWithStorage[127.0.0.1:43429,DS-3a1a1aea-7390-40f6-8a2b-d755602b4a2a,DISK], DatanodeInfoWithStorage[127.0.0.1:35307,DS-b35cc87b-b15e-4e14-baa7-ea2509881acf,DISK], DatanodeInfoWithStorage[127.0.0.1:34995,DS-7bcfcbf8-479f-4860-b887-984fa197c58a,DISK], DatanodeInfoWithStorage[127.0.0.1:37606,DS-964964aa-e215-4569-b40e-37d8d6f917b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45354,DS-cf641aae-2230-4e2a-8207-0eb0b73b5655,DISK], DatanodeInfoWithStorage[127.0.0.1:40852,DS-d317d7b7-cc52-4c9f-8a19-ab9dea4cf107,DISK], DatanodeInfoWithStorage[127.0.0.1:40947,DS-ca9d9e40-353f-49eb-bf9c-424338ef167c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1160056440-172.17.0.21-1596916330023:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35496,DS-df1eabd3-2daf-4b88-9459-96a2b407e741,DISK], DatanodeInfoWithStorage[127.0.0.1:43429,DS-3a1a1aea-7390-40f6-8a2b-d755602b4a2a,DISK], DatanodeInfoWithStorage[127.0.0.1:35307,DS-b35cc87b-b15e-4e14-baa7-ea2509881acf,DISK], DatanodeInfoWithStorage[127.0.0.1:34995,DS-7bcfcbf8-479f-4860-b887-984fa197c58a,DISK], DatanodeInfoWithStorage[127.0.0.1:37606,DS-964964aa-e215-4569-b40e-37d8d6f917b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45354,DS-cf641aae-2230-4e2a-8207-0eb0b73b5655,DISK], DatanodeInfoWithStorage[127.0.0.1:40852,DS-d317d7b7-cc52-4c9f-8a19-ab9dea4cf107,DISK], DatanodeInfoWithStorage[127.0.0.1:40947,DS-ca9d9e40-353f-49eb-bf9c-424338ef167c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1531665689-172.17.0.21-1596916564430:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42143,DS-5d7000a0-a0f3-45f3-836b-3f8b8f398176,DISK], DatanodeInfoWithStorage[127.0.0.1:40131,DS-fcd3d7d9-5694-447a-94fb-0e17d23610fd,DISK], DatanodeInfoWithStorage[127.0.0.1:32885,DS-f7435502-8b87-44d9-a02d-14d01b250839,DISK], DatanodeInfoWithStorage[127.0.0.1:42389,DS-dda4820f-50aa-4cae-83f5-99246e7e3b72,DISK], DatanodeInfoWithStorage[127.0.0.1:37593,DS-af4cbe6c-568a-4cb6-bbfd-82e2839f708f,DISK], DatanodeInfoWithStorage[127.0.0.1:34459,DS-9e77540f-e9ab-4bbd-bc91-3784146e18bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35028,DS-1c4be3c5-ecc0-49b8-b8da-3d23b5c532d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44981,DS-a235ce44-e078-4641-8904-fa881a771b30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1531665689-172.17.0.21-1596916564430:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42143,DS-5d7000a0-a0f3-45f3-836b-3f8b8f398176,DISK], DatanodeInfoWithStorage[127.0.0.1:40131,DS-fcd3d7d9-5694-447a-94fb-0e17d23610fd,DISK], DatanodeInfoWithStorage[127.0.0.1:32885,DS-f7435502-8b87-44d9-a02d-14d01b250839,DISK], DatanodeInfoWithStorage[127.0.0.1:42389,DS-dda4820f-50aa-4cae-83f5-99246e7e3b72,DISK], DatanodeInfoWithStorage[127.0.0.1:37593,DS-af4cbe6c-568a-4cb6-bbfd-82e2839f708f,DISK], DatanodeInfoWithStorage[127.0.0.1:34459,DS-9e77540f-e9ab-4bbd-bc91-3784146e18bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35028,DS-1c4be3c5-ecc0-49b8-b8da-3d23b5c532d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44981,DS-a235ce44-e078-4641-8904-fa881a771b30,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1356706837-172.17.0.21-1596917375110:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40898,DS-cbe35fa3-a191-45e5-b31b-c4d50a34ede7,DISK], DatanodeInfoWithStorage[127.0.0.1:43181,DS-b697dee9-7231-4842-bb20-7c7c5a1d4fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:39303,DS-a2856344-6abc-4966-8750-65146db81711,DISK], DatanodeInfoWithStorage[127.0.0.1:38642,DS-0dd389cf-e6a6-4be3-88f2-3ce4160e6e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:37928,DS-330e2290-5de2-4316-937e-43f8e9fb58ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40721,DS-afaa0197-f467-429d-8861-2d6d46c4a8ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36080,DS-c1e84d2c-f9ad-40b8-9245-9d67872d1925,DISK], DatanodeInfoWithStorage[127.0.0.1:34434,DS-ba5e0660-6e62-4e9e-9208-86c4b6ce57d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1356706837-172.17.0.21-1596917375110:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40898,DS-cbe35fa3-a191-45e5-b31b-c4d50a34ede7,DISK], DatanodeInfoWithStorage[127.0.0.1:43181,DS-b697dee9-7231-4842-bb20-7c7c5a1d4fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:39303,DS-a2856344-6abc-4966-8750-65146db81711,DISK], DatanodeInfoWithStorage[127.0.0.1:38642,DS-0dd389cf-e6a6-4be3-88f2-3ce4160e6e6a,DISK], DatanodeInfoWithStorage[127.0.0.1:37928,DS-330e2290-5de2-4316-937e-43f8e9fb58ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40721,DS-afaa0197-f467-429d-8861-2d6d46c4a8ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36080,DS-c1e84d2c-f9ad-40b8-9245-9d67872d1925,DISK], DatanodeInfoWithStorage[127.0.0.1:34434,DS-ba5e0660-6e62-4e9e-9208-86c4b6ce57d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-854076325-172.17.0.21-1596918261045:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37556,DS-ff2cbdd3-8be6-4ceb-a4d1-81542de562e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38225,DS-2debc722-cc7c-4b16-97c0-d6da72f849d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42381,DS-a80f53bd-13a3-49bb-b7c6-409d2adca130,DISK], DatanodeInfoWithStorage[127.0.0.1:42522,DS-15c2b5f1-7f52-44fe-8604-90c9cca9d196,DISK], DatanodeInfoWithStorage[127.0.0.1:43674,DS-b738ec1b-66ff-4bdb-8626-abac8ed3b271,DISK], DatanodeInfoWithStorage[127.0.0.1:35125,DS-2946655b-6e3f-40ad-9fdb-e9c57347c909,DISK], DatanodeInfoWithStorage[127.0.0.1:44061,DS-b199acf6-51c5-4bed-b1f6-f6d6c2bb7290,DISK], DatanodeInfoWithStorage[127.0.0.1:34099,DS-bb03b89f-2b0b-4b79-9e1e-5a60a5bc523d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-854076325-172.17.0.21-1596918261045:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37556,DS-ff2cbdd3-8be6-4ceb-a4d1-81542de562e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38225,DS-2debc722-cc7c-4b16-97c0-d6da72f849d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42381,DS-a80f53bd-13a3-49bb-b7c6-409d2adca130,DISK], DatanodeInfoWithStorage[127.0.0.1:42522,DS-15c2b5f1-7f52-44fe-8604-90c9cca9d196,DISK], DatanodeInfoWithStorage[127.0.0.1:43674,DS-b738ec1b-66ff-4bdb-8626-abac8ed3b271,DISK], DatanodeInfoWithStorage[127.0.0.1:35125,DS-2946655b-6e3f-40ad-9fdb-e9c57347c909,DISK], DatanodeInfoWithStorage[127.0.0.1:44061,DS-b199acf6-51c5-4bed-b1f6-f6d6c2bb7290,DISK], DatanodeInfoWithStorage[127.0.0.1:34099,DS-bb03b89f-2b0b-4b79-9e1e-5a60a5bc523d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-48932025-172.17.0.21-1596919099474:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37541,DS-78e1f49f-41cc-4677-98ea-7bbff1b6cc8a,DISK], DatanodeInfoWithStorage[127.0.0.1:46175,DS-709f61e5-efa5-4cc4-a903-3c11a42196ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40224,DS-f7ad8f6b-5270-48bd-a178-6402c95542b2,DISK], DatanodeInfoWithStorage[127.0.0.1:39257,DS-ff9f98ec-7b99-4c59-b1c4-bd1c537d928c,DISK], DatanodeInfoWithStorage[127.0.0.1:33009,DS-e77ee42d-1f55-4c52-9f0f-73a1fbb7c923,DISK], DatanodeInfoWithStorage[127.0.0.1:39894,DS-3f21f7eb-b2e8-4ddc-8e00-47f66c63dd5a,DISK], DatanodeInfoWithStorage[127.0.0.1:46270,DS-857389e4-6c85-492e-a145-6e351c1417ae,DISK], DatanodeInfoWithStorage[127.0.0.1:46763,DS-43608cf1-a3fc-464e-98f4-7280763dae2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-48932025-172.17.0.21-1596919099474:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37541,DS-78e1f49f-41cc-4677-98ea-7bbff1b6cc8a,DISK], DatanodeInfoWithStorage[127.0.0.1:46175,DS-709f61e5-efa5-4cc4-a903-3c11a42196ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40224,DS-f7ad8f6b-5270-48bd-a178-6402c95542b2,DISK], DatanodeInfoWithStorage[127.0.0.1:39257,DS-ff9f98ec-7b99-4c59-b1c4-bd1c537d928c,DISK], DatanodeInfoWithStorage[127.0.0.1:33009,DS-e77ee42d-1f55-4c52-9f0f-73a1fbb7c923,DISK], DatanodeInfoWithStorage[127.0.0.1:39894,DS-3f21f7eb-b2e8-4ddc-8e00-47f66c63dd5a,DISK], DatanodeInfoWithStorage[127.0.0.1:46270,DS-857389e4-6c85-492e-a145-6e351c1417ae,DISK], DatanodeInfoWithStorage[127.0.0.1:46763,DS-43608cf1-a3fc-464e-98f4-7280763dae2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-236323540-172.17.0.21-1596919230813:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37369,DS-bafd9b51-edf7-4a4f-a72d-ec51e8f8d4e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45217,DS-bdaf040b-6ebe-493d-84b0-ba8bd6bd6e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:45918,DS-ea413845-1153-408b-952d-6ec0ef377def,DISK], DatanodeInfoWithStorage[127.0.0.1:35447,DS-1a1b0734-98a4-4480-b4f0-d3fb51ef7d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:37910,DS-c3b87f10-f8fd-441e-9942-34150f83f485,DISK], DatanodeInfoWithStorage[127.0.0.1:42138,DS-9bea9164-5c77-4e9a-8bbb-08068984197f,DISK], DatanodeInfoWithStorage[127.0.0.1:39247,DS-29c6cdb1-f8bf-45e2-b9c4-99e676130d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:34290,DS-4678646f-c085-428b-82f0-5a3ea0e02c23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-236323540-172.17.0.21-1596919230813:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37369,DS-bafd9b51-edf7-4a4f-a72d-ec51e8f8d4e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45217,DS-bdaf040b-6ebe-493d-84b0-ba8bd6bd6e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:45918,DS-ea413845-1153-408b-952d-6ec0ef377def,DISK], DatanodeInfoWithStorage[127.0.0.1:35447,DS-1a1b0734-98a4-4480-b4f0-d3fb51ef7d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:37910,DS-c3b87f10-f8fd-441e-9942-34150f83f485,DISK], DatanodeInfoWithStorage[127.0.0.1:42138,DS-9bea9164-5c77-4e9a-8bbb-08068984197f,DISK], DatanodeInfoWithStorage[127.0.0.1:39247,DS-29c6cdb1-f8bf-45e2-b9c4-99e676130d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:34290,DS-4678646f-c085-428b-82f0-5a3ea0e02c23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-199555022-172.17.0.21-1596919690344:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37748,DS-2dd29e40-937f-4e4a-ac2f-859a44223db5,DISK], DatanodeInfoWithStorage[127.0.0.1:41176,DS-95764f2a-ff6a-40db-9c9b-4a8f00358cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:39120,DS-4893087f-b29f-4521-8cb7-d30e8cf04aac,DISK], DatanodeInfoWithStorage[127.0.0.1:40049,DS-3a9e52bf-beff-43c7-a6b5-d8678fd17ad0,DISK], DatanodeInfoWithStorage[127.0.0.1:39383,DS-06f40bf1-9122-4dd7-8f92-9d7d4fc39476,DISK], DatanodeInfoWithStorage[127.0.0.1:44004,DS-8d8bca13-781c-46b7-9624-52418f6d1751,DISK], DatanodeInfoWithStorage[127.0.0.1:35272,DS-2d10fda7-4480-4305-8ecf-70ab8f9fdb8e,DISK], DatanodeInfoWithStorage[127.0.0.1:35049,DS-dcc70fee-6039-4d0f-b121-314312ce6068,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-199555022-172.17.0.21-1596919690344:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37748,DS-2dd29e40-937f-4e4a-ac2f-859a44223db5,DISK], DatanodeInfoWithStorage[127.0.0.1:41176,DS-95764f2a-ff6a-40db-9c9b-4a8f00358cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:39120,DS-4893087f-b29f-4521-8cb7-d30e8cf04aac,DISK], DatanodeInfoWithStorage[127.0.0.1:40049,DS-3a9e52bf-beff-43c7-a6b5-d8678fd17ad0,DISK], DatanodeInfoWithStorage[127.0.0.1:39383,DS-06f40bf1-9122-4dd7-8f92-9d7d4fc39476,DISK], DatanodeInfoWithStorage[127.0.0.1:44004,DS-8d8bca13-781c-46b7-9624-52418f6d1751,DISK], DatanodeInfoWithStorage[127.0.0.1:35272,DS-2d10fda7-4480-4305-8ecf-70ab8f9fdb8e,DISK], DatanodeInfoWithStorage[127.0.0.1:35049,DS-dcc70fee-6039-4d0f-b121-314312ce6068,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-353097173-172.17.0.21-1596920038252:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36166,DS-f2dfed15-431e-4eb0-adc1-45ebf44dc0fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36932,DS-74aeb63a-554b-4dfe-bad0-cefca0cd6466,DISK], DatanodeInfoWithStorage[127.0.0.1:40846,DS-95ee952e-c232-4988-ba05-577eed7f7ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:37988,DS-2faaab05-5962-47e4-aa24-d9db101e9a18,DISK], DatanodeInfoWithStorage[127.0.0.1:34352,DS-fc88ed32-a9ac-44bb-ba82-2950cc0eee78,DISK], DatanodeInfoWithStorage[127.0.0.1:35570,DS-62134bd5-31a4-4966-aa97-00db96741de8,DISK], DatanodeInfoWithStorage[127.0.0.1:34271,DS-ec6bfce6-b32f-4e59-8d99-6a8510cf6470,DISK], DatanodeInfoWithStorage[127.0.0.1:35673,DS-b728e0ff-c825-4201-a728-36457d686d0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-353097173-172.17.0.21-1596920038252:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36166,DS-f2dfed15-431e-4eb0-adc1-45ebf44dc0fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36932,DS-74aeb63a-554b-4dfe-bad0-cefca0cd6466,DISK], DatanodeInfoWithStorage[127.0.0.1:40846,DS-95ee952e-c232-4988-ba05-577eed7f7ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:37988,DS-2faaab05-5962-47e4-aa24-d9db101e9a18,DISK], DatanodeInfoWithStorage[127.0.0.1:34352,DS-fc88ed32-a9ac-44bb-ba82-2950cc0eee78,DISK], DatanodeInfoWithStorage[127.0.0.1:35570,DS-62134bd5-31a4-4966-aa97-00db96741de8,DISK], DatanodeInfoWithStorage[127.0.0.1:34271,DS-ec6bfce6-b32f-4e59-8d99-6a8510cf6470,DISK], DatanodeInfoWithStorage[127.0.0.1:35673,DS-b728e0ff-c825-4201-a728-36457d686d0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1125143196-172.17.0.21-1596920207834:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40137,DS-a6e6e1b0-678b-42f2-a2eb-d522599804e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37196,DS-4376b939-ce73-4113-b802-6fe293f23294,DISK], DatanodeInfoWithStorage[127.0.0.1:36804,DS-b549db00-fd4b-4d3e-866a-00280ad52081,DISK], DatanodeInfoWithStorage[127.0.0.1:46392,DS-5685c5d2-f486-4e79-8a6f-b60acf2dd480,DISK], DatanodeInfoWithStorage[127.0.0.1:38999,DS-2076e0c0-f3ca-4ad4-ba2c-f6f3bfe590a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33555,DS-8bd56e3a-bf61-4fea-aef1-17d188d2ea68,DISK], DatanodeInfoWithStorage[127.0.0.1:38289,DS-83e8bdee-6e48-4f84-aef3-f84da8bff4e3,DISK], DatanodeInfoWithStorage[127.0.0.1:33779,DS-4cb0f6a9-2dab-4760-8c0b-edd2d11d4714,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1125143196-172.17.0.21-1596920207834:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40137,DS-a6e6e1b0-678b-42f2-a2eb-d522599804e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37196,DS-4376b939-ce73-4113-b802-6fe293f23294,DISK], DatanodeInfoWithStorage[127.0.0.1:36804,DS-b549db00-fd4b-4d3e-866a-00280ad52081,DISK], DatanodeInfoWithStorage[127.0.0.1:46392,DS-5685c5d2-f486-4e79-8a6f-b60acf2dd480,DISK], DatanodeInfoWithStorage[127.0.0.1:38999,DS-2076e0c0-f3ca-4ad4-ba2c-f6f3bfe590a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33555,DS-8bd56e3a-bf61-4fea-aef1-17d188d2ea68,DISK], DatanodeInfoWithStorage[127.0.0.1:38289,DS-83e8bdee-6e48-4f84-aef3-f84da8bff4e3,DISK], DatanodeInfoWithStorage[127.0.0.1:33779,DS-4cb0f6a9-2dab-4760-8c0b-edd2d11d4714,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-887422181-172.17.0.21-1596920272791:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35263,DS-410db33d-ef79-4846-9a3b-576b5a5d1325,DISK], DatanodeInfoWithStorage[127.0.0.1:39863,DS-1c384ee4-d891-4a4f-9e89-27030b82fd1f,DISK], DatanodeInfoWithStorage[127.0.0.1:41707,DS-134e06ec-6804-4f9b-8a9c-5b4db92a361b,DISK], DatanodeInfoWithStorage[127.0.0.1:34019,DS-905e7cdb-7660-4c29-8fd7-9c5425e9c737,DISK], DatanodeInfoWithStorage[127.0.0.1:42627,DS-05ec60d4-8fdc-47c3-a64e-a6a65cb6c92a,DISK], DatanodeInfoWithStorage[127.0.0.1:38954,DS-64343835-898a-4ef9-b5a4-59a533474914,DISK], DatanodeInfoWithStorage[127.0.0.1:46378,DS-2ff5f26d-22ef-4fa6-9182-4427d8ef55a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43817,DS-5db53dfd-c5dc-472a-9d57-882e7b8205d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-887422181-172.17.0.21-1596920272791:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35263,DS-410db33d-ef79-4846-9a3b-576b5a5d1325,DISK], DatanodeInfoWithStorage[127.0.0.1:39863,DS-1c384ee4-d891-4a4f-9e89-27030b82fd1f,DISK], DatanodeInfoWithStorage[127.0.0.1:41707,DS-134e06ec-6804-4f9b-8a9c-5b4db92a361b,DISK], DatanodeInfoWithStorage[127.0.0.1:34019,DS-905e7cdb-7660-4c29-8fd7-9c5425e9c737,DISK], DatanodeInfoWithStorage[127.0.0.1:42627,DS-05ec60d4-8fdc-47c3-a64e-a6a65cb6c92a,DISK], DatanodeInfoWithStorage[127.0.0.1:38954,DS-64343835-898a-4ef9-b5a4-59a533474914,DISK], DatanodeInfoWithStorage[127.0.0.1:46378,DS-2ff5f26d-22ef-4fa6-9182-4427d8ef55a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43817,DS-5db53dfd-c5dc-472a-9d57-882e7b8205d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-112608144-172.17.0.21-1596920481919:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42607,DS-dbc49c3e-80d3-43e3-9a0b-ba1fe277c34a,DISK], DatanodeInfoWithStorage[127.0.0.1:34882,DS-79af836a-3cd0-445a-bf2b-b1a5d3c5c87a,DISK], DatanodeInfoWithStorage[127.0.0.1:43419,DS-86796ab3-36e8-4bf9-9dba-7e16339fbf32,DISK], DatanodeInfoWithStorage[127.0.0.1:38960,DS-06b37022-42cf-455b-92f5-94c50e655acc,DISK], DatanodeInfoWithStorage[127.0.0.1:35886,DS-2276d842-1949-4bba-a655-8b4221fed61a,DISK], DatanodeInfoWithStorage[127.0.0.1:43708,DS-f12db12c-4629-437c-802b-f47fd7f600e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33749,DS-38e7f0ec-9f89-4e43-ba1f-414963d99dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:40028,DS-f3fdfc53-e861-44c2-8a7e-6d1e86efcd2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-112608144-172.17.0.21-1596920481919:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42607,DS-dbc49c3e-80d3-43e3-9a0b-ba1fe277c34a,DISK], DatanodeInfoWithStorage[127.0.0.1:34882,DS-79af836a-3cd0-445a-bf2b-b1a5d3c5c87a,DISK], DatanodeInfoWithStorage[127.0.0.1:43419,DS-86796ab3-36e8-4bf9-9dba-7e16339fbf32,DISK], DatanodeInfoWithStorage[127.0.0.1:38960,DS-06b37022-42cf-455b-92f5-94c50e655acc,DISK], DatanodeInfoWithStorage[127.0.0.1:35886,DS-2276d842-1949-4bba-a655-8b4221fed61a,DISK], DatanodeInfoWithStorage[127.0.0.1:43708,DS-f12db12c-4629-437c-802b-f47fd7f600e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33749,DS-38e7f0ec-9f89-4e43-ba1f-414963d99dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:40028,DS-f3fdfc53-e861-44c2-8a7e-6d1e86efcd2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-393184166-172.17.0.21-1596921710221:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33402,DS-f2cbbe0d-402c-4c8f-af83-ea6d091c5d5a,DISK], DatanodeInfoWithStorage[127.0.0.1:41064,DS-9b53586c-588c-49a6-bd47-6ddd44425d83,DISK], DatanodeInfoWithStorage[127.0.0.1:39715,DS-b729c072-c7a8-4fb2-a732-d912ba4b5c0a,DISK], DatanodeInfoWithStorage[127.0.0.1:42735,DS-68cfd84b-54a6-4504-84ce-0a2f62d97c0f,DISK], DatanodeInfoWithStorage[127.0.0.1:39221,DS-75f2e611-24fa-4cbc-8f6b-7b53b1315c9f,DISK], DatanodeInfoWithStorage[127.0.0.1:45502,DS-51ee0246-a442-43c5-a6df-1e22fede04d3,DISK], DatanodeInfoWithStorage[127.0.0.1:36387,DS-986a49ce-ebe7-49d4-84a9-32c733d7c35a,DISK], DatanodeInfoWithStorage[127.0.0.1:41635,DS-cf73c5cc-488b-41ae-b488-4b5ade081365,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-393184166-172.17.0.21-1596921710221:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33402,DS-f2cbbe0d-402c-4c8f-af83-ea6d091c5d5a,DISK], DatanodeInfoWithStorage[127.0.0.1:41064,DS-9b53586c-588c-49a6-bd47-6ddd44425d83,DISK], DatanodeInfoWithStorage[127.0.0.1:39715,DS-b729c072-c7a8-4fb2-a732-d912ba4b5c0a,DISK], DatanodeInfoWithStorage[127.0.0.1:42735,DS-68cfd84b-54a6-4504-84ce-0a2f62d97c0f,DISK], DatanodeInfoWithStorage[127.0.0.1:39221,DS-75f2e611-24fa-4cbc-8f6b-7b53b1315c9f,DISK], DatanodeInfoWithStorage[127.0.0.1:45502,DS-51ee0246-a442-43c5-a6df-1e22fede04d3,DISK], DatanodeInfoWithStorage[127.0.0.1:36387,DS-986a49ce-ebe7-49d4-84a9-32c733d7c35a,DISK], DatanodeInfoWithStorage[127.0.0.1:41635,DS-cf73c5cc-488b-41ae-b488-4b5ade081365,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1245822755-172.17.0.21-1596922050888:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39881,DS-4bb6396c-0c5d-47b2-8a48-37d8ed526e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:46458,DS-f28bfa1b-adc2-4fa0-8c59-0af9591cc3fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34767,DS-efe9c754-bdbe-4ffb-b7b3-2d71f17ad409,DISK], DatanodeInfoWithStorage[127.0.0.1:42241,DS-e0802f8a-94b3-45e6-b916-00c8893f4a62,DISK], DatanodeInfoWithStorage[127.0.0.1:36538,DS-b5f6ec45-5e16-40d2-afb0-7a5aae03ceae,DISK], DatanodeInfoWithStorage[127.0.0.1:34356,DS-61d35d35-549b-49e8-a4b0-3d0b878f2249,DISK], DatanodeInfoWithStorage[127.0.0.1:33269,DS-d8fd2d2f-2428-425a-8dff-40a1d1b8e3f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43106,DS-20e84652-74c4-4d5b-8b69-5106301ee0e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1245822755-172.17.0.21-1596922050888:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39881,DS-4bb6396c-0c5d-47b2-8a48-37d8ed526e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:46458,DS-f28bfa1b-adc2-4fa0-8c59-0af9591cc3fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34767,DS-efe9c754-bdbe-4ffb-b7b3-2d71f17ad409,DISK], DatanodeInfoWithStorage[127.0.0.1:42241,DS-e0802f8a-94b3-45e6-b916-00c8893f4a62,DISK], DatanodeInfoWithStorage[127.0.0.1:36538,DS-b5f6ec45-5e16-40d2-afb0-7a5aae03ceae,DISK], DatanodeInfoWithStorage[127.0.0.1:34356,DS-61d35d35-549b-49e8-a4b0-3d0b878f2249,DISK], DatanodeInfoWithStorage[127.0.0.1:33269,DS-d8fd2d2f-2428-425a-8dff-40a1d1b8e3f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43106,DS-20e84652-74c4-4d5b-8b69-5106301ee0e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-993596659-172.17.0.21-1596922128147:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39073,DS-0887d575-9e65-4415-b00b-a0b548f2dd8a,DISK], DatanodeInfoWithStorage[127.0.0.1:33688,DS-ca0d59f8-ec5c-43b0-8f86-b043d860a7d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34954,DS-97c2ad7b-82c5-404c-851d-b4a02598362f,DISK], DatanodeInfoWithStorage[127.0.0.1:39037,DS-0a9f9aea-9b46-4590-be69-4ba829c6345f,DISK], DatanodeInfoWithStorage[127.0.0.1:38927,DS-5a0c93c8-5708-4d1b-ac0a-0145ba4db97b,DISK], DatanodeInfoWithStorage[127.0.0.1:32784,DS-596aa24c-9630-49e8-bd91-525cf8386ba3,DISK], DatanodeInfoWithStorage[127.0.0.1:39845,DS-9564173c-90fc-41c9-9645-8a6ad8068540,DISK], DatanodeInfoWithStorage[127.0.0.1:36203,DS-0e657b10-8c71-4a7f-ab1d-3a078a696b8f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-993596659-172.17.0.21-1596922128147:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39073,DS-0887d575-9e65-4415-b00b-a0b548f2dd8a,DISK], DatanodeInfoWithStorage[127.0.0.1:33688,DS-ca0d59f8-ec5c-43b0-8f86-b043d860a7d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34954,DS-97c2ad7b-82c5-404c-851d-b4a02598362f,DISK], DatanodeInfoWithStorage[127.0.0.1:39037,DS-0a9f9aea-9b46-4590-be69-4ba829c6345f,DISK], DatanodeInfoWithStorage[127.0.0.1:38927,DS-5a0c93c8-5708-4d1b-ac0a-0145ba4db97b,DISK], DatanodeInfoWithStorage[127.0.0.1:32784,DS-596aa24c-9630-49e8-bd91-525cf8386ba3,DISK], DatanodeInfoWithStorage[127.0.0.1:39845,DS-9564173c-90fc-41c9-9645-8a6ad8068540,DISK], DatanodeInfoWithStorage[127.0.0.1:36203,DS-0e657b10-8c71-4a7f-ab1d-3a078a696b8f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 6432
