reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-88712424-172.17.0.9-1595331145120:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33280,DS-f612cc66-6e98-47c3-8bb9-d93762ec5d93,DISK], DatanodeInfoWithStorage[127.0.0.1:38717,DS-b354f50a-230c-4d11-be70-0f9e24d38eac,DISK], DatanodeInfoWithStorage[127.0.0.1:38678,DS-39c938b9-93de-4a7c-afc9-83632f54e47c,DISK], DatanodeInfoWithStorage[127.0.0.1:46668,DS-495f5979-2f34-4c4d-9fd3-4e886a95a1bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34659,DS-3bee7c4c-77b1-4c6c-9427-b2847d3c6ec4,DISK], DatanodeInfoWithStorage[127.0.0.1:42029,DS-7b299aff-0da3-4df9-8cf2-cc4cbff1f917,DISK], DatanodeInfoWithStorage[127.0.0.1:45200,DS-9911b590-669f-4810-b1ab-023a85ec13a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34854,DS-af9baf78-9013-4f70-9df7-1fec3366cddd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-88712424-172.17.0.9-1595331145120:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33280,DS-f612cc66-6e98-47c3-8bb9-d93762ec5d93,DISK], DatanodeInfoWithStorage[127.0.0.1:38717,DS-b354f50a-230c-4d11-be70-0f9e24d38eac,DISK], DatanodeInfoWithStorage[127.0.0.1:38678,DS-39c938b9-93de-4a7c-afc9-83632f54e47c,DISK], DatanodeInfoWithStorage[127.0.0.1:46668,DS-495f5979-2f34-4c4d-9fd3-4e886a95a1bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34659,DS-3bee7c4c-77b1-4c6c-9427-b2847d3c6ec4,DISK], DatanodeInfoWithStorage[127.0.0.1:42029,DS-7b299aff-0da3-4df9-8cf2-cc4cbff1f917,DISK], DatanodeInfoWithStorage[127.0.0.1:45200,DS-9911b590-669f-4810-b1ab-023a85ec13a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34854,DS-af9baf78-9013-4f70-9df7-1fec3366cddd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1694695731-172.17.0.9-1595331445379:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45647,DS-b7c3a4a6-443e-482e-8a49-5b4c48f082e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46036,DS-3b75fa72-e55b-47e7-a6c7-bda0fee2a28f,DISK], DatanodeInfoWithStorage[127.0.0.1:46414,DS-eabcb394-e9e0-43e7-87f1-a0dfba592ef2,DISK], DatanodeInfoWithStorage[127.0.0.1:38905,DS-600666de-e7ca-4281-8573-10fdaf0855f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45412,DS-05435e9a-31c8-40c7-9c83-cbccbdaafd28,DISK], DatanodeInfoWithStorage[127.0.0.1:45881,DS-53b46b61-dde9-45b9-8acd-0464afd8e9db,DISK], DatanodeInfoWithStorage[127.0.0.1:44954,DS-1ae16335-08d3-4a55-8a7b-adebcbfdcf26,DISK], DatanodeInfoWithStorage[127.0.0.1:34450,DS-4ff4e0d8-7637-4340-bfb0-ccbc313a8d07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1694695731-172.17.0.9-1595331445379:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45647,DS-b7c3a4a6-443e-482e-8a49-5b4c48f082e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46036,DS-3b75fa72-e55b-47e7-a6c7-bda0fee2a28f,DISK], DatanodeInfoWithStorage[127.0.0.1:46414,DS-eabcb394-e9e0-43e7-87f1-a0dfba592ef2,DISK], DatanodeInfoWithStorage[127.0.0.1:38905,DS-600666de-e7ca-4281-8573-10fdaf0855f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45412,DS-05435e9a-31c8-40c7-9c83-cbccbdaafd28,DISK], DatanodeInfoWithStorage[127.0.0.1:45881,DS-53b46b61-dde9-45b9-8acd-0464afd8e9db,DISK], DatanodeInfoWithStorage[127.0.0.1:44954,DS-1ae16335-08d3-4a55-8a7b-adebcbfdcf26,DISK], DatanodeInfoWithStorage[127.0.0.1:34450,DS-4ff4e0d8-7637-4340-bfb0-ccbc313a8d07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1507798067-172.17.0.9-1595331580641:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38178,DS-258bdbb1-e792-47e8-88c1-6eb17d3caaf3,DISK], DatanodeInfoWithStorage[127.0.0.1:32950,DS-4a0cf07f-0eb1-4bf9-9686-ef03cf5cdf7e,DISK], DatanodeInfoWithStorage[127.0.0.1:40354,DS-117e5bbc-7024-4609-af23-8c58c933a502,DISK], DatanodeInfoWithStorage[127.0.0.1:40026,DS-6f694dc4-3461-4ecf-ac3b-2bcffb396d30,DISK], DatanodeInfoWithStorage[127.0.0.1:43163,DS-ba64c53a-75f9-4ad1-bd63-c739766fe018,DISK], DatanodeInfoWithStorage[127.0.0.1:44361,DS-56d66359-e7c6-44ec-ae5c-7944530f2f69,DISK], DatanodeInfoWithStorage[127.0.0.1:42139,DS-dac080e8-11d8-49d4-a4d4-8c383880e952,DISK], DatanodeInfoWithStorage[127.0.0.1:42961,DS-ef701b43-a859-4d31-9419-db49e8828225,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1507798067-172.17.0.9-1595331580641:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38178,DS-258bdbb1-e792-47e8-88c1-6eb17d3caaf3,DISK], DatanodeInfoWithStorage[127.0.0.1:32950,DS-4a0cf07f-0eb1-4bf9-9686-ef03cf5cdf7e,DISK], DatanodeInfoWithStorage[127.0.0.1:40354,DS-117e5bbc-7024-4609-af23-8c58c933a502,DISK], DatanodeInfoWithStorage[127.0.0.1:40026,DS-6f694dc4-3461-4ecf-ac3b-2bcffb396d30,DISK], DatanodeInfoWithStorage[127.0.0.1:43163,DS-ba64c53a-75f9-4ad1-bd63-c739766fe018,DISK], DatanodeInfoWithStorage[127.0.0.1:44361,DS-56d66359-e7c6-44ec-ae5c-7944530f2f69,DISK], DatanodeInfoWithStorage[127.0.0.1:42139,DS-dac080e8-11d8-49d4-a4d4-8c383880e952,DISK], DatanodeInfoWithStorage[127.0.0.1:42961,DS-ef701b43-a859-4d31-9419-db49e8828225,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-499189944-172.17.0.9-1595331802482:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34322,DS-e9128bf0-d876-47d1-87d7-549c0a406f2f,DISK], DatanodeInfoWithStorage[127.0.0.1:37041,DS-fdae5676-f29e-4ccb-8f28-39902271baea,DISK], DatanodeInfoWithStorage[127.0.0.1:44358,DS-b9e38905-f9b4-4bc6-be0e-613e46b45d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:34931,DS-c61ca24c-2ee4-4621-9557-aa24276e1203,DISK], DatanodeInfoWithStorage[127.0.0.1:36733,DS-25d85551-38fd-4803-bba0-c423de421db0,DISK], DatanodeInfoWithStorage[127.0.0.1:46339,DS-04225cb6-1508-4cf7-8f99-ba0b35f9ae0a,DISK], DatanodeInfoWithStorage[127.0.0.1:39860,DS-4c684758-481b-42c8-b092-8b15c7ec8317,DISK], DatanodeInfoWithStorage[127.0.0.1:36456,DS-f085c337-6608-4c1c-af00-b8cc700a01c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-499189944-172.17.0.9-1595331802482:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34322,DS-e9128bf0-d876-47d1-87d7-549c0a406f2f,DISK], DatanodeInfoWithStorage[127.0.0.1:37041,DS-fdae5676-f29e-4ccb-8f28-39902271baea,DISK], DatanodeInfoWithStorage[127.0.0.1:44358,DS-b9e38905-f9b4-4bc6-be0e-613e46b45d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:34931,DS-c61ca24c-2ee4-4621-9557-aa24276e1203,DISK], DatanodeInfoWithStorage[127.0.0.1:36733,DS-25d85551-38fd-4803-bba0-c423de421db0,DISK], DatanodeInfoWithStorage[127.0.0.1:46339,DS-04225cb6-1508-4cf7-8f99-ba0b35f9ae0a,DISK], DatanodeInfoWithStorage[127.0.0.1:39860,DS-4c684758-481b-42c8-b092-8b15c7ec8317,DISK], DatanodeInfoWithStorage[127.0.0.1:36456,DS-f085c337-6608-4c1c-af00-b8cc700a01c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1860482130-172.17.0.9-1595332082227:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40295,DS-074721ae-fed0-4033-a1b4-ebfb4f61e875,DISK], DatanodeInfoWithStorage[127.0.0.1:39242,DS-3348ec58-ac26-45ea-9dc9-42a43511cd79,DISK], DatanodeInfoWithStorage[127.0.0.1:45740,DS-edefcc4c-613e-4f70-a0e5-69a2f39e9a2c,DISK], DatanodeInfoWithStorage[127.0.0.1:39713,DS-03795951-b39d-4d2a-aa40-2506b7a75b7b,DISK], DatanodeInfoWithStorage[127.0.0.1:44114,DS-4e7396a3-a270-4f1e-a0e7-7954acc0af56,DISK], DatanodeInfoWithStorage[127.0.0.1:39417,DS-b69ded2f-3886-44e7-8c6b-dcff9b10a0b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39256,DS-95f535af-e4ca-4be3-abc7-c94dd6444462,DISK], DatanodeInfoWithStorage[127.0.0.1:36162,DS-20491d79-5bfc-46a6-b345-5989c6b4c52c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1860482130-172.17.0.9-1595332082227:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40295,DS-074721ae-fed0-4033-a1b4-ebfb4f61e875,DISK], DatanodeInfoWithStorage[127.0.0.1:39242,DS-3348ec58-ac26-45ea-9dc9-42a43511cd79,DISK], DatanodeInfoWithStorage[127.0.0.1:45740,DS-edefcc4c-613e-4f70-a0e5-69a2f39e9a2c,DISK], DatanodeInfoWithStorage[127.0.0.1:39713,DS-03795951-b39d-4d2a-aa40-2506b7a75b7b,DISK], DatanodeInfoWithStorage[127.0.0.1:44114,DS-4e7396a3-a270-4f1e-a0e7-7954acc0af56,DISK], DatanodeInfoWithStorage[127.0.0.1:39417,DS-b69ded2f-3886-44e7-8c6b-dcff9b10a0b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39256,DS-95f535af-e4ca-4be3-abc7-c94dd6444462,DISK], DatanodeInfoWithStorage[127.0.0.1:36162,DS-20491d79-5bfc-46a6-b345-5989c6b4c52c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-399285204-172.17.0.9-1595332174447:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38554,DS-0b638d12-1b5f-4f68-ae53-3ee424dc5e19,DISK], DatanodeInfoWithStorage[127.0.0.1:34108,DS-dff3fce0-7a04-4482-b4b9-3c78cc6a201f,DISK], DatanodeInfoWithStorage[127.0.0.1:42286,DS-6d8f2d51-9501-40ea-9a6d-aa946ca309a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34387,DS-64fbd661-8ee1-4c37-b874-3a54f621ccc5,DISK], DatanodeInfoWithStorage[127.0.0.1:45817,DS-d8c85e2a-82ac-41c5-a60e-0bbe8c568d28,DISK], DatanodeInfoWithStorage[127.0.0.1:39448,DS-f3adf1dd-8bd8-4146-b68b-62a67eebccaa,DISK], DatanodeInfoWithStorage[127.0.0.1:46164,DS-8ec4d022-a33d-4c61-bc0d-297a93df84ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36940,DS-90fcb451-a313-481a-956d-d29d2a7f3175,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-399285204-172.17.0.9-1595332174447:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38554,DS-0b638d12-1b5f-4f68-ae53-3ee424dc5e19,DISK], DatanodeInfoWithStorage[127.0.0.1:34108,DS-dff3fce0-7a04-4482-b4b9-3c78cc6a201f,DISK], DatanodeInfoWithStorage[127.0.0.1:42286,DS-6d8f2d51-9501-40ea-9a6d-aa946ca309a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34387,DS-64fbd661-8ee1-4c37-b874-3a54f621ccc5,DISK], DatanodeInfoWithStorage[127.0.0.1:45817,DS-d8c85e2a-82ac-41c5-a60e-0bbe8c568d28,DISK], DatanodeInfoWithStorage[127.0.0.1:39448,DS-f3adf1dd-8bd8-4146-b68b-62a67eebccaa,DISK], DatanodeInfoWithStorage[127.0.0.1:46164,DS-8ec4d022-a33d-4c61-bc0d-297a93df84ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36940,DS-90fcb451-a313-481a-956d-d29d2a7f3175,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1450834259-172.17.0.9-1595332221790:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34559,DS-dbb9ade4-76ab-4716-b785-adc96a8038b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33559,DS-dd4d5390-a687-4e78-99d6-4dfd442accff,DISK], DatanodeInfoWithStorage[127.0.0.1:44292,DS-39769a3f-10d9-4149-8e8c-2914c74e5567,DISK], DatanodeInfoWithStorage[127.0.0.1:45113,DS-b17e3223-df56-456c-8bea-7b23dd51bca4,DISK], DatanodeInfoWithStorage[127.0.0.1:42969,DS-7b181895-a9ae-4d46-b6c5-a124e01110d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44084,DS-c0be7801-96a7-4bf0-8f74-5b813fd07c75,DISK], DatanodeInfoWithStorage[127.0.0.1:35321,DS-15ef6c0f-bfb2-4599-ab77-6bebd6885bb3,DISK], DatanodeInfoWithStorage[127.0.0.1:45605,DS-49a247d8-77c8-446c-b1ba-c9512eadff2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1450834259-172.17.0.9-1595332221790:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34559,DS-dbb9ade4-76ab-4716-b785-adc96a8038b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33559,DS-dd4d5390-a687-4e78-99d6-4dfd442accff,DISK], DatanodeInfoWithStorage[127.0.0.1:44292,DS-39769a3f-10d9-4149-8e8c-2914c74e5567,DISK], DatanodeInfoWithStorage[127.0.0.1:45113,DS-b17e3223-df56-456c-8bea-7b23dd51bca4,DISK], DatanodeInfoWithStorage[127.0.0.1:42969,DS-7b181895-a9ae-4d46-b6c5-a124e01110d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44084,DS-c0be7801-96a7-4bf0-8f74-5b813fd07c75,DISK], DatanodeInfoWithStorage[127.0.0.1:35321,DS-15ef6c0f-bfb2-4599-ab77-6bebd6885bb3,DISK], DatanodeInfoWithStorage[127.0.0.1:45605,DS-49a247d8-77c8-446c-b1ba-c9512eadff2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-222827543-172.17.0.9-1595332309525:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35701,DS-536d1c4b-fb5e-4421-bf4b-5f5722afa401,DISK], DatanodeInfoWithStorage[127.0.0.1:38625,DS-09164418-6511-481e-96fd-bdc149fc8e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:36152,DS-dedc32c0-8e8d-40dd-894f-e1a02407495d,DISK], DatanodeInfoWithStorage[127.0.0.1:33270,DS-c5f11d0e-023a-44f0-bfe7-4e9e87099746,DISK], DatanodeInfoWithStorage[127.0.0.1:37029,DS-83717966-ffdc-4e0c-931f-b0616c2e65ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45495,DS-1dd832bc-a086-4e83-9f02-980a23f983b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37596,DS-7ad6d13e-21a1-4e04-a4f0-f1d2fd28a9b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36965,DS-5860ab72-4f80-4d15-9ad9-6814e0ddf55a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-222827543-172.17.0.9-1595332309525:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35701,DS-536d1c4b-fb5e-4421-bf4b-5f5722afa401,DISK], DatanodeInfoWithStorage[127.0.0.1:38625,DS-09164418-6511-481e-96fd-bdc149fc8e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:36152,DS-dedc32c0-8e8d-40dd-894f-e1a02407495d,DISK], DatanodeInfoWithStorage[127.0.0.1:33270,DS-c5f11d0e-023a-44f0-bfe7-4e9e87099746,DISK], DatanodeInfoWithStorage[127.0.0.1:37029,DS-83717966-ffdc-4e0c-931f-b0616c2e65ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45495,DS-1dd832bc-a086-4e83-9f02-980a23f983b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37596,DS-7ad6d13e-21a1-4e04-a4f0-f1d2fd28a9b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36965,DS-5860ab72-4f80-4d15-9ad9-6814e0ddf55a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-378090126-172.17.0.9-1595332538696:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33610,DS-370d83ac-690a-404b-9296-83a8dee7c2e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45962,DS-10b67e01-3b35-4d10-8f91-1076d1655443,DISK], DatanodeInfoWithStorage[127.0.0.1:43304,DS-431774a4-b68c-4806-8c1d-ad24d034c0f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38604,DS-551e2dfa-c12e-49b8-8ef4-7b022860b308,DISK], DatanodeInfoWithStorage[127.0.0.1:42266,DS-c50c04d2-5839-47cd-92df-7344188f1099,DISK], DatanodeInfoWithStorage[127.0.0.1:46764,DS-5b1b27d6-bfaf-4ac4-b522-b46cec86631e,DISK], DatanodeInfoWithStorage[127.0.0.1:39506,DS-a2383505-69f1-4fdb-bacc-a60ecc5a628b,DISK], DatanodeInfoWithStorage[127.0.0.1:33106,DS-c4237488-5827-4dce-9e1b-237aaeb7b03d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-378090126-172.17.0.9-1595332538696:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33610,DS-370d83ac-690a-404b-9296-83a8dee7c2e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45962,DS-10b67e01-3b35-4d10-8f91-1076d1655443,DISK], DatanodeInfoWithStorage[127.0.0.1:43304,DS-431774a4-b68c-4806-8c1d-ad24d034c0f6,DISK], DatanodeInfoWithStorage[127.0.0.1:38604,DS-551e2dfa-c12e-49b8-8ef4-7b022860b308,DISK], DatanodeInfoWithStorage[127.0.0.1:42266,DS-c50c04d2-5839-47cd-92df-7344188f1099,DISK], DatanodeInfoWithStorage[127.0.0.1:46764,DS-5b1b27d6-bfaf-4ac4-b522-b46cec86631e,DISK], DatanodeInfoWithStorage[127.0.0.1:39506,DS-a2383505-69f1-4fdb-bacc-a60ecc5a628b,DISK], DatanodeInfoWithStorage[127.0.0.1:33106,DS-c4237488-5827-4dce-9e1b-237aaeb7b03d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1076246102-172.17.0.9-1595332696306:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34476,DS-18f03ecf-c7f8-4edd-9f0f-5eb3eed967e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42078,DS-2c3f5b58-30c7-467d-a6fc-b9603d457d54,DISK], DatanodeInfoWithStorage[127.0.0.1:43608,DS-1885890c-0edc-4be9-b7e0-bf2b852cf1e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45293,DS-7df7133a-9250-42af-b085-77f40012eda9,DISK], DatanodeInfoWithStorage[127.0.0.1:33281,DS-0d14a484-ad17-4058-bc80-e4e96a170252,DISK], DatanodeInfoWithStorage[127.0.0.1:34969,DS-c9b2dffe-8eb5-40ba-b475-6c5310fedab9,DISK], DatanodeInfoWithStorage[127.0.0.1:41371,DS-b9199a97-2289-43b9-aa86-4e0bfa23b37b,DISK], DatanodeInfoWithStorage[127.0.0.1:35595,DS-47dc5688-a4df-43d7-8370-59efe4a86b85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1076246102-172.17.0.9-1595332696306:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34476,DS-18f03ecf-c7f8-4edd-9f0f-5eb3eed967e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42078,DS-2c3f5b58-30c7-467d-a6fc-b9603d457d54,DISK], DatanodeInfoWithStorage[127.0.0.1:43608,DS-1885890c-0edc-4be9-b7e0-bf2b852cf1e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45293,DS-7df7133a-9250-42af-b085-77f40012eda9,DISK], DatanodeInfoWithStorage[127.0.0.1:33281,DS-0d14a484-ad17-4058-bc80-e4e96a170252,DISK], DatanodeInfoWithStorage[127.0.0.1:34969,DS-c9b2dffe-8eb5-40ba-b475-6c5310fedab9,DISK], DatanodeInfoWithStorage[127.0.0.1:41371,DS-b9199a97-2289-43b9-aa86-4e0bfa23b37b,DISK], DatanodeInfoWithStorage[127.0.0.1:35595,DS-47dc5688-a4df-43d7-8370-59efe4a86b85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-475578892-172.17.0.9-1595332984116:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42288,DS-47c186d6-9610-4009-90a2-46857b631e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:43267,DS-3f930cac-4ba1-4643-ab9a-03e764a2a5f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34939,DS-4388f95a-51d3-4f15-8ff0-10d3c5f04df4,DISK], DatanodeInfoWithStorage[127.0.0.1:46151,DS-8663c1c2-b8ab-4fe1-8e82-c529c09794fb,DISK], DatanodeInfoWithStorage[127.0.0.1:43055,DS-b1faee5b-3868-4297-bb10-ca1b36e8526d,DISK], DatanodeInfoWithStorage[127.0.0.1:40616,DS-5ad91940-035e-4aa7-acbf-bebe23ffe7e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40369,DS-2c80eb0a-602b-421f-bb2a-639f0431fae7,DISK], DatanodeInfoWithStorage[127.0.0.1:42280,DS-79d3743b-c388-44ef-84d8-1d3baa19f2ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-475578892-172.17.0.9-1595332984116:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42288,DS-47c186d6-9610-4009-90a2-46857b631e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:43267,DS-3f930cac-4ba1-4643-ab9a-03e764a2a5f4,DISK], DatanodeInfoWithStorage[127.0.0.1:34939,DS-4388f95a-51d3-4f15-8ff0-10d3c5f04df4,DISK], DatanodeInfoWithStorage[127.0.0.1:46151,DS-8663c1c2-b8ab-4fe1-8e82-c529c09794fb,DISK], DatanodeInfoWithStorage[127.0.0.1:43055,DS-b1faee5b-3868-4297-bb10-ca1b36e8526d,DISK], DatanodeInfoWithStorage[127.0.0.1:40616,DS-5ad91940-035e-4aa7-acbf-bebe23ffe7e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40369,DS-2c80eb0a-602b-421f-bb2a-639f0431fae7,DISK], DatanodeInfoWithStorage[127.0.0.1:42280,DS-79d3743b-c388-44ef-84d8-1d3baa19f2ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1267340945-172.17.0.9-1595333027629:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32874,DS-1c8195f6-9ea4-44de-8aad-3fea8b96a0d3,DISK], DatanodeInfoWithStorage[127.0.0.1:43624,DS-c1f8b159-53e0-4c3f-8f0c-e80c9337b791,DISK], DatanodeInfoWithStorage[127.0.0.1:43015,DS-27a7aec1-d325-473f-bc6f-2163619d2b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:35024,DS-94b3e233-da5a-468c-a43e-e3f7d1d336c5,DISK], DatanodeInfoWithStorage[127.0.0.1:46687,DS-e73bbf04-26b8-4ff1-823d-5cab972e143c,DISK], DatanodeInfoWithStorage[127.0.0.1:34065,DS-edbcb1fd-579d-4d1d-b033-e4337fe680ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38366,DS-04934599-05b7-49d6-991d-426b4bca92fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34931,DS-1379dea8-a3fb-4cd0-a16a-6344bb201038,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1267340945-172.17.0.9-1595333027629:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32874,DS-1c8195f6-9ea4-44de-8aad-3fea8b96a0d3,DISK], DatanodeInfoWithStorage[127.0.0.1:43624,DS-c1f8b159-53e0-4c3f-8f0c-e80c9337b791,DISK], DatanodeInfoWithStorage[127.0.0.1:43015,DS-27a7aec1-d325-473f-bc6f-2163619d2b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:35024,DS-94b3e233-da5a-468c-a43e-e3f7d1d336c5,DISK], DatanodeInfoWithStorage[127.0.0.1:46687,DS-e73bbf04-26b8-4ff1-823d-5cab972e143c,DISK], DatanodeInfoWithStorage[127.0.0.1:34065,DS-edbcb1fd-579d-4d1d-b033-e4337fe680ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38366,DS-04934599-05b7-49d6-991d-426b4bca92fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34931,DS-1379dea8-a3fb-4cd0-a16a-6344bb201038,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-745148637-172.17.0.9-1595333203590:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43995,DS-0c270851-d947-458a-87ee-4a42c40bed42,DISK], DatanodeInfoWithStorage[127.0.0.1:34167,DS-1986b0d3-4010-430e-a54d-093e723f6a17,DISK], DatanodeInfoWithStorage[127.0.0.1:38027,DS-2e6f935a-8abf-43b7-87c2-4ef1e441e839,DISK], DatanodeInfoWithStorage[127.0.0.1:43150,DS-2cd0f9e5-1caf-4c0e-840f-6859e7e2ac90,DISK], DatanodeInfoWithStorage[127.0.0.1:40768,DS-6d266cf3-0e2d-4e85-97c5-5f105a7fb44b,DISK], DatanodeInfoWithStorage[127.0.0.1:45499,DS-253c97a2-1487-406e-9053-79d96248678b,DISK], DatanodeInfoWithStorage[127.0.0.1:44991,DS-67790bbf-05ed-42a4-a988-3fe9585b386d,DISK], DatanodeInfoWithStorage[127.0.0.1:39147,DS-4c75a24d-3b64-4c9c-b14a-f655dee9aa00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-745148637-172.17.0.9-1595333203590:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43995,DS-0c270851-d947-458a-87ee-4a42c40bed42,DISK], DatanodeInfoWithStorage[127.0.0.1:34167,DS-1986b0d3-4010-430e-a54d-093e723f6a17,DISK], DatanodeInfoWithStorage[127.0.0.1:38027,DS-2e6f935a-8abf-43b7-87c2-4ef1e441e839,DISK], DatanodeInfoWithStorage[127.0.0.1:43150,DS-2cd0f9e5-1caf-4c0e-840f-6859e7e2ac90,DISK], DatanodeInfoWithStorage[127.0.0.1:40768,DS-6d266cf3-0e2d-4e85-97c5-5f105a7fb44b,DISK], DatanodeInfoWithStorage[127.0.0.1:45499,DS-253c97a2-1487-406e-9053-79d96248678b,DISK], DatanodeInfoWithStorage[127.0.0.1:44991,DS-67790bbf-05ed-42a4-a988-3fe9585b386d,DISK], DatanodeInfoWithStorage[127.0.0.1:39147,DS-4c75a24d-3b64-4c9c-b14a-f655dee9aa00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1289799526-172.17.0.9-1595333243583:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36803,DS-31243a25-f4c7-417b-a6b5-bdd0a2e900ce,DISK], DatanodeInfoWithStorage[127.0.0.1:43518,DS-3eb0a5f6-edc9-44a8-8c93-12eb66ac3622,DISK], DatanodeInfoWithStorage[127.0.0.1:41365,DS-d0e3e736-8b57-4498-ad9a-2df3c2e4e6bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41189,DS-611f75aa-9597-401a-a165-ad9f00c0fd3e,DISK], DatanodeInfoWithStorage[127.0.0.1:42834,DS-148dc80a-56cc-4935-8b57-72deb54d1992,DISK], DatanodeInfoWithStorage[127.0.0.1:32986,DS-b9b8e9ab-0e95-44e3-b257-4eb35db4d610,DISK], DatanodeInfoWithStorage[127.0.0.1:40707,DS-fa1b1f74-4c1c-4b29-a9ad-ad413ab9bdbe,DISK], DatanodeInfoWithStorage[127.0.0.1:44087,DS-b35cb5a9-5540-4aee-b4e5-9d090b797918,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1289799526-172.17.0.9-1595333243583:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36803,DS-31243a25-f4c7-417b-a6b5-bdd0a2e900ce,DISK], DatanodeInfoWithStorage[127.0.0.1:43518,DS-3eb0a5f6-edc9-44a8-8c93-12eb66ac3622,DISK], DatanodeInfoWithStorage[127.0.0.1:41365,DS-d0e3e736-8b57-4498-ad9a-2df3c2e4e6bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41189,DS-611f75aa-9597-401a-a165-ad9f00c0fd3e,DISK], DatanodeInfoWithStorage[127.0.0.1:42834,DS-148dc80a-56cc-4935-8b57-72deb54d1992,DISK], DatanodeInfoWithStorage[127.0.0.1:32986,DS-b9b8e9ab-0e95-44e3-b257-4eb35db4d610,DISK], DatanodeInfoWithStorage[127.0.0.1:40707,DS-fa1b1f74-4c1c-4b29-a9ad-ad413ab9bdbe,DISK], DatanodeInfoWithStorage[127.0.0.1:44087,DS-b35cb5a9-5540-4aee-b4e5-9d090b797918,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1151735666-172.17.0.9-1595335334894:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45084,DS-fc2b494c-dd3e-46ce-811e-a73a1d21aca7,DISK], DatanodeInfoWithStorage[127.0.0.1:36690,DS-13268742-8fe5-4c97-8220-61e5fb3480b4,DISK], DatanodeInfoWithStorage[127.0.0.1:33568,DS-9652dd38-207e-4617-87c2-56ba9f9bf539,DISK], DatanodeInfoWithStorage[127.0.0.1:43606,DS-e5179601-bc12-41eb-8941-8914dd8a46b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34954,DS-a9faa573-4275-482c-8eb1-41f35fdffa6b,DISK], DatanodeInfoWithStorage[127.0.0.1:35141,DS-0940c3c1-af91-45fd-a14b-f6d12bdd76eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37241,DS-acc84580-6aa9-4374-bd8e-c5e2c8ecead8,DISK], DatanodeInfoWithStorage[127.0.0.1:38698,DS-cda38d88-848f-4867-aa0b-63959ccf7e5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1151735666-172.17.0.9-1595335334894:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45084,DS-fc2b494c-dd3e-46ce-811e-a73a1d21aca7,DISK], DatanodeInfoWithStorage[127.0.0.1:36690,DS-13268742-8fe5-4c97-8220-61e5fb3480b4,DISK], DatanodeInfoWithStorage[127.0.0.1:33568,DS-9652dd38-207e-4617-87c2-56ba9f9bf539,DISK], DatanodeInfoWithStorage[127.0.0.1:43606,DS-e5179601-bc12-41eb-8941-8914dd8a46b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34954,DS-a9faa573-4275-482c-8eb1-41f35fdffa6b,DISK], DatanodeInfoWithStorage[127.0.0.1:35141,DS-0940c3c1-af91-45fd-a14b-f6d12bdd76eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37241,DS-acc84580-6aa9-4374-bd8e-c5e2c8ecead8,DISK], DatanodeInfoWithStorage[127.0.0.1:38698,DS-cda38d88-848f-4867-aa0b-63959ccf7e5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-689420524-172.17.0.9-1595335480143:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34761,DS-0c287661-ebe7-4c5e-b05d-884999c694b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38419,DS-303388fe-b763-412a-8700-890b6ddad0c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45893,DS-43071859-e910-469d-b272-3bbd91856c43,DISK], DatanodeInfoWithStorage[127.0.0.1:40183,DS-ee990a5c-17eb-4820-b4f3-4410487eecdb,DISK], DatanodeInfoWithStorage[127.0.0.1:40291,DS-af3086ae-1d1b-413c-88be-816475da3b2a,DISK], DatanodeInfoWithStorage[127.0.0.1:45701,DS-d5e5106e-e992-4e0d-9d04-a5e4fda6637e,DISK], DatanodeInfoWithStorage[127.0.0.1:37992,DS-64660ccb-44bc-45f7-ae81-2c7c9555c18d,DISK], DatanodeInfoWithStorage[127.0.0.1:35328,DS-da8f414f-4a9f-49dc-a6f6-cd077f54b25a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-689420524-172.17.0.9-1595335480143:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34761,DS-0c287661-ebe7-4c5e-b05d-884999c694b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38419,DS-303388fe-b763-412a-8700-890b6ddad0c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45893,DS-43071859-e910-469d-b272-3bbd91856c43,DISK], DatanodeInfoWithStorage[127.0.0.1:40183,DS-ee990a5c-17eb-4820-b4f3-4410487eecdb,DISK], DatanodeInfoWithStorage[127.0.0.1:40291,DS-af3086ae-1d1b-413c-88be-816475da3b2a,DISK], DatanodeInfoWithStorage[127.0.0.1:45701,DS-d5e5106e-e992-4e0d-9d04-a5e4fda6637e,DISK], DatanodeInfoWithStorage[127.0.0.1:37992,DS-64660ccb-44bc-45f7-ae81-2c7c9555c18d,DISK], DatanodeInfoWithStorage[127.0.0.1:35328,DS-da8f414f-4a9f-49dc-a6f6-cd077f54b25a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-164743351-172.17.0.9-1595335648396:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33201,DS-c4de6672-99f3-4292-8d39-0c45f8087280,DISK], DatanodeInfoWithStorage[127.0.0.1:44890,DS-a4674f80-6347-4ef8-b85c-a38ccbe413ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34827,DS-6410c803-ed41-4d54-821d-5589c8f5e302,DISK], DatanodeInfoWithStorage[127.0.0.1:44756,DS-093bac4e-e098-493d-9344-86ede74309a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42205,DS-617343cc-f42a-4d56-a4dd-7e08cddfce79,DISK], DatanodeInfoWithStorage[127.0.0.1:45377,DS-fbf4b12e-6eee-4e62-bc8e-24198551a5b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33873,DS-98a6e041-05e2-408f-b4e1-e723a26cce1b,DISK], DatanodeInfoWithStorage[127.0.0.1:40931,DS-a5222773-5a89-4211-ae09-5df93c28fa6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-164743351-172.17.0.9-1595335648396:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33201,DS-c4de6672-99f3-4292-8d39-0c45f8087280,DISK], DatanodeInfoWithStorage[127.0.0.1:44890,DS-a4674f80-6347-4ef8-b85c-a38ccbe413ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34827,DS-6410c803-ed41-4d54-821d-5589c8f5e302,DISK], DatanodeInfoWithStorage[127.0.0.1:44756,DS-093bac4e-e098-493d-9344-86ede74309a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42205,DS-617343cc-f42a-4d56-a4dd-7e08cddfce79,DISK], DatanodeInfoWithStorage[127.0.0.1:45377,DS-fbf4b12e-6eee-4e62-bc8e-24198551a5b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33873,DS-98a6e041-05e2-408f-b4e1-e723a26cce1b,DISK], DatanodeInfoWithStorage[127.0.0.1:40931,DS-a5222773-5a89-4211-ae09-5df93c28fa6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 6510
