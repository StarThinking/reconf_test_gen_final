reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1665297042-172.17.0.19-1596876441602:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39628,DS-43522d26-e76e-4d23-8faf-3e1615d8335a,DISK], DatanodeInfoWithStorage[127.0.0.1:34698,DS-d1e0fb74-7306-4056-8f02-95143515ecc3,DISK], DatanodeInfoWithStorage[127.0.0.1:43440,DS-1096ece9-af64-4c30-b5aa-7e3e9db0fba0,DISK], DatanodeInfoWithStorage[127.0.0.1:36504,DS-f96a1ba4-967b-46fa-a6e2-00db2cfddc98,DISK], DatanodeInfoWithStorage[127.0.0.1:34819,DS-368a5125-c350-46fc-821c-7f0fc459c4a2,DISK], DatanodeInfoWithStorage[127.0.0.1:32883,DS-720544f2-b248-4b07-8caa-0dcc6d53ea6d,DISK], DatanodeInfoWithStorage[127.0.0.1:37400,DS-3939e0b3-6eb6-4ee7-95fd-490bfecfe87b,DISK], DatanodeInfoWithStorage[127.0.0.1:37410,DS-b4d94c6b-9e44-4186-adab-5652a123e3ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1665297042-172.17.0.19-1596876441602:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39628,DS-43522d26-e76e-4d23-8faf-3e1615d8335a,DISK], DatanodeInfoWithStorage[127.0.0.1:34698,DS-d1e0fb74-7306-4056-8f02-95143515ecc3,DISK], DatanodeInfoWithStorage[127.0.0.1:43440,DS-1096ece9-af64-4c30-b5aa-7e3e9db0fba0,DISK], DatanodeInfoWithStorage[127.0.0.1:36504,DS-f96a1ba4-967b-46fa-a6e2-00db2cfddc98,DISK], DatanodeInfoWithStorage[127.0.0.1:34819,DS-368a5125-c350-46fc-821c-7f0fc459c4a2,DISK], DatanodeInfoWithStorage[127.0.0.1:32883,DS-720544f2-b248-4b07-8caa-0dcc6d53ea6d,DISK], DatanodeInfoWithStorage[127.0.0.1:37400,DS-3939e0b3-6eb6-4ee7-95fd-490bfecfe87b,DISK], DatanodeInfoWithStorage[127.0.0.1:37410,DS-b4d94c6b-9e44-4186-adab-5652a123e3ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1490292998-172.17.0.19-1596876921816:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33180,DS-f08ff340-8048-41ac-b53f-94749014fb45,DISK], DatanodeInfoWithStorage[127.0.0.1:45102,DS-f10f3603-a279-4006-8b7a-30bcd4435a2c,DISK], DatanodeInfoWithStorage[127.0.0.1:42452,DS-7558f3e9-ee00-4319-977b-a41fa86084a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41581,DS-f9803361-2217-45fe-86dd-737e9ff70e38,DISK], DatanodeInfoWithStorage[127.0.0.1:40561,DS-2ebbbfa4-8687-47f5-b5b7-8bb8e62b5780,DISK], DatanodeInfoWithStorage[127.0.0.1:45578,DS-8a4c9085-5809-4c5d-af50-12c472a2bc07,DISK], DatanodeInfoWithStorage[127.0.0.1:42253,DS-9c519ae6-04c3-462b-a6b0-e080b417b960,DISK], DatanodeInfoWithStorage[127.0.0.1:32849,DS-34f45493-69d9-4011-9947-0a3035b9f9a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1490292998-172.17.0.19-1596876921816:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33180,DS-f08ff340-8048-41ac-b53f-94749014fb45,DISK], DatanodeInfoWithStorage[127.0.0.1:45102,DS-f10f3603-a279-4006-8b7a-30bcd4435a2c,DISK], DatanodeInfoWithStorage[127.0.0.1:42452,DS-7558f3e9-ee00-4319-977b-a41fa86084a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41581,DS-f9803361-2217-45fe-86dd-737e9ff70e38,DISK], DatanodeInfoWithStorage[127.0.0.1:40561,DS-2ebbbfa4-8687-47f5-b5b7-8bb8e62b5780,DISK], DatanodeInfoWithStorage[127.0.0.1:45578,DS-8a4c9085-5809-4c5d-af50-12c472a2bc07,DISK], DatanodeInfoWithStorage[127.0.0.1:42253,DS-9c519ae6-04c3-462b-a6b0-e080b417b960,DISK], DatanodeInfoWithStorage[127.0.0.1:32849,DS-34f45493-69d9-4011-9947-0a3035b9f9a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-467932018-172.17.0.19-1596877166414:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41754,DS-f77a655c-6094-4abf-8c7b-35dc4f03e2b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39594,DS-bc5f38da-51a7-45d5-8321-034f69071ae7,DISK], DatanodeInfoWithStorage[127.0.0.1:42793,DS-1761474c-3935-4804-bf16-490a2f2aeb9a,DISK], DatanodeInfoWithStorage[127.0.0.1:37779,DS-080dd700-cc0c-4708-8f16-2993e66fe699,DISK], DatanodeInfoWithStorage[127.0.0.1:44887,DS-0c36b3ce-a2e1-4678-b835-7711885838d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38346,DS-8426294c-1284-47de-9e32-53a13106a252,DISK], DatanodeInfoWithStorage[127.0.0.1:35715,DS-919b475b-dad9-4ef1-9e15-367ea82ca52e,DISK], DatanodeInfoWithStorage[127.0.0.1:39784,DS-e8a343e4-b7fe-4ec5-ad8f-7b875d18efa3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-467932018-172.17.0.19-1596877166414:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41754,DS-f77a655c-6094-4abf-8c7b-35dc4f03e2b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39594,DS-bc5f38da-51a7-45d5-8321-034f69071ae7,DISK], DatanodeInfoWithStorage[127.0.0.1:42793,DS-1761474c-3935-4804-bf16-490a2f2aeb9a,DISK], DatanodeInfoWithStorage[127.0.0.1:37779,DS-080dd700-cc0c-4708-8f16-2993e66fe699,DISK], DatanodeInfoWithStorage[127.0.0.1:44887,DS-0c36b3ce-a2e1-4678-b835-7711885838d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38346,DS-8426294c-1284-47de-9e32-53a13106a252,DISK], DatanodeInfoWithStorage[127.0.0.1:35715,DS-919b475b-dad9-4ef1-9e15-367ea82ca52e,DISK], DatanodeInfoWithStorage[127.0.0.1:39784,DS-e8a343e4-b7fe-4ec5-ad8f-7b875d18efa3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1815162464-172.17.0.19-1596877807830:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40899,DS-b77e49bd-d73b-424e-89cc-074beee3c8e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45578,DS-7fb0f3b5-8bab-4602-89c3-66fb02ab5bde,DISK], DatanodeInfoWithStorage[127.0.0.1:35079,DS-eb9d4d0c-4c37-4151-85b9-9705def82318,DISK], DatanodeInfoWithStorage[127.0.0.1:42291,DS-93cea7c6-6bd9-4257-a250-85ddd1eccf4c,DISK], DatanodeInfoWithStorage[127.0.0.1:42280,DS-c00e8fd6-f91b-44c3-b7a2-ca32faf17e54,DISK], DatanodeInfoWithStorage[127.0.0.1:38097,DS-16e2c81e-b6c5-468f-8f61-2c72026bf56e,DISK], DatanodeInfoWithStorage[127.0.0.1:39638,DS-46ea6fce-c86e-4190-a5bb-96d07a0e3ae6,DISK], DatanodeInfoWithStorage[127.0.0.1:45898,DS-9f6cf23e-c7cb-4762-86d2-54902dd0d733,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1815162464-172.17.0.19-1596877807830:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40899,DS-b77e49bd-d73b-424e-89cc-074beee3c8e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45578,DS-7fb0f3b5-8bab-4602-89c3-66fb02ab5bde,DISK], DatanodeInfoWithStorage[127.0.0.1:35079,DS-eb9d4d0c-4c37-4151-85b9-9705def82318,DISK], DatanodeInfoWithStorage[127.0.0.1:42291,DS-93cea7c6-6bd9-4257-a250-85ddd1eccf4c,DISK], DatanodeInfoWithStorage[127.0.0.1:42280,DS-c00e8fd6-f91b-44c3-b7a2-ca32faf17e54,DISK], DatanodeInfoWithStorage[127.0.0.1:38097,DS-16e2c81e-b6c5-468f-8f61-2c72026bf56e,DISK], DatanodeInfoWithStorage[127.0.0.1:39638,DS-46ea6fce-c86e-4190-a5bb-96d07a0e3ae6,DISK], DatanodeInfoWithStorage[127.0.0.1:45898,DS-9f6cf23e-c7cb-4762-86d2-54902dd0d733,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1091156663-172.17.0.19-1596877986008:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33656,DS-830fc61d-3b57-4307-8b11-141a6e28fc41,DISK], DatanodeInfoWithStorage[127.0.0.1:40158,DS-da1f3709-39e1-415c-be80-0845eb0cdc90,DISK], DatanodeInfoWithStorage[127.0.0.1:39083,DS-cf952331-4688-4192-895d-3ed97409c1a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36060,DS-203be6ab-6fdf-434c-81af-32f796cca7ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37751,DS-4dea95f9-6e64-4a84-952f-10331391cd69,DISK], DatanodeInfoWithStorage[127.0.0.1:38102,DS-25354fbe-35b4-4b93-b51c-59087ce8ef41,DISK], DatanodeInfoWithStorage[127.0.0.1:46357,DS-9cec6924-2645-4a6a-b3f6-13e8ffa0f5cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40568,DS-7beec233-8c05-4f3e-bb12-829f9636f0a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1091156663-172.17.0.19-1596877986008:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33656,DS-830fc61d-3b57-4307-8b11-141a6e28fc41,DISK], DatanodeInfoWithStorage[127.0.0.1:40158,DS-da1f3709-39e1-415c-be80-0845eb0cdc90,DISK], DatanodeInfoWithStorage[127.0.0.1:39083,DS-cf952331-4688-4192-895d-3ed97409c1a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36060,DS-203be6ab-6fdf-434c-81af-32f796cca7ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37751,DS-4dea95f9-6e64-4a84-952f-10331391cd69,DISK], DatanodeInfoWithStorage[127.0.0.1:38102,DS-25354fbe-35b4-4b93-b51c-59087ce8ef41,DISK], DatanodeInfoWithStorage[127.0.0.1:46357,DS-9cec6924-2645-4a6a-b3f6-13e8ffa0f5cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40568,DS-7beec233-8c05-4f3e-bb12-829f9636f0a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-648097722-172.17.0.19-1596878072376:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46377,DS-2769dbb3-d019-4606-84c0-ecaa2397c8bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39678,DS-8c2933a8-0e2e-4e3c-b69c-38115157a4d8,DISK], DatanodeInfoWithStorage[127.0.0.1:32912,DS-e1d24a9e-5fb1-47a3-ad8d-b650f65cde5f,DISK], DatanodeInfoWithStorage[127.0.0.1:35713,DS-49845d7a-1a42-43e0-b647-44b769b42088,DISK], DatanodeInfoWithStorage[127.0.0.1:35471,DS-6a61e045-fef4-4fc0-85d4-42b1b13e01ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44199,DS-c191aa61-c1a9-4b05-9b73-d0259e895519,DISK], DatanodeInfoWithStorage[127.0.0.1:45071,DS-23519ab2-6eab-4ee1-a969-0f674a25db82,DISK], DatanodeInfoWithStorage[127.0.0.1:35915,DS-7b53526f-3927-4901-b212-89de44b20e1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-648097722-172.17.0.19-1596878072376:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46377,DS-2769dbb3-d019-4606-84c0-ecaa2397c8bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39678,DS-8c2933a8-0e2e-4e3c-b69c-38115157a4d8,DISK], DatanodeInfoWithStorage[127.0.0.1:32912,DS-e1d24a9e-5fb1-47a3-ad8d-b650f65cde5f,DISK], DatanodeInfoWithStorage[127.0.0.1:35713,DS-49845d7a-1a42-43e0-b647-44b769b42088,DISK], DatanodeInfoWithStorage[127.0.0.1:35471,DS-6a61e045-fef4-4fc0-85d4-42b1b13e01ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44199,DS-c191aa61-c1a9-4b05-9b73-d0259e895519,DISK], DatanodeInfoWithStorage[127.0.0.1:45071,DS-23519ab2-6eab-4ee1-a969-0f674a25db82,DISK], DatanodeInfoWithStorage[127.0.0.1:35915,DS-7b53526f-3927-4901-b212-89de44b20e1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1134774235-172.17.0.19-1596878419875:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36503,DS-9086c362-1c66-4708-a9c9-246a2d5c7544,DISK], DatanodeInfoWithStorage[127.0.0.1:34051,DS-077f1207-ef3b-4423-81b1-250fd82de48f,DISK], DatanodeInfoWithStorage[127.0.0.1:36068,DS-54b6bb87-04a7-4f42-8ed5-f5be70d8a022,DISK], DatanodeInfoWithStorage[127.0.0.1:36802,DS-87b3586e-7db0-4c91-9482-43484a79e53f,DISK], DatanodeInfoWithStorage[127.0.0.1:39467,DS-ec5ce88b-5688-4a98-8575-0b72df9c8f15,DISK], DatanodeInfoWithStorage[127.0.0.1:35097,DS-06019f18-2577-4429-870f-88967bbcffef,DISK], DatanodeInfoWithStorage[127.0.0.1:38780,DS-7a6b3397-8753-4695-889c-b71eda0388c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39459,DS-da93b310-8eea-4241-a1a3-9129f61f2c97,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1134774235-172.17.0.19-1596878419875:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36503,DS-9086c362-1c66-4708-a9c9-246a2d5c7544,DISK], DatanodeInfoWithStorage[127.0.0.1:34051,DS-077f1207-ef3b-4423-81b1-250fd82de48f,DISK], DatanodeInfoWithStorage[127.0.0.1:36068,DS-54b6bb87-04a7-4f42-8ed5-f5be70d8a022,DISK], DatanodeInfoWithStorage[127.0.0.1:36802,DS-87b3586e-7db0-4c91-9482-43484a79e53f,DISK], DatanodeInfoWithStorage[127.0.0.1:39467,DS-ec5ce88b-5688-4a98-8575-0b72df9c8f15,DISK], DatanodeInfoWithStorage[127.0.0.1:35097,DS-06019f18-2577-4429-870f-88967bbcffef,DISK], DatanodeInfoWithStorage[127.0.0.1:38780,DS-7a6b3397-8753-4695-889c-b71eda0388c9,DISK], DatanodeInfoWithStorage[127.0.0.1:39459,DS-da93b310-8eea-4241-a1a3-9129f61f2c97,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2088060058-172.17.0.19-1596878556159:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43489,DS-c5385622-3879-4231-b7d4-1290dab67263,DISK], DatanodeInfoWithStorage[127.0.0.1:45149,DS-b8a3f87b-0d9b-435b-87c8-1a713fda03a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41630,DS-97243f81-dc6e-4832-b4e4-5d76940caa39,DISK], DatanodeInfoWithStorage[127.0.0.1:38340,DS-80ca9312-0fd7-4498-90cf-1619eb475645,DISK], DatanodeInfoWithStorage[127.0.0.1:45086,DS-f7f59bb2-830f-406a-a99a-d3ae558f1d44,DISK], DatanodeInfoWithStorage[127.0.0.1:38079,DS-bc04ec94-ec9b-4bcb-a0d1-6d428a3f384d,DISK], DatanodeInfoWithStorage[127.0.0.1:33824,DS-8ea87d7f-6d6d-4cad-8576-3b6167f6391f,DISK], DatanodeInfoWithStorage[127.0.0.1:46641,DS-03e969f7-b5a2-45c0-9c19-0b20ba6cc621,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2088060058-172.17.0.19-1596878556159:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43489,DS-c5385622-3879-4231-b7d4-1290dab67263,DISK], DatanodeInfoWithStorage[127.0.0.1:45149,DS-b8a3f87b-0d9b-435b-87c8-1a713fda03a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41630,DS-97243f81-dc6e-4832-b4e4-5d76940caa39,DISK], DatanodeInfoWithStorage[127.0.0.1:38340,DS-80ca9312-0fd7-4498-90cf-1619eb475645,DISK], DatanodeInfoWithStorage[127.0.0.1:45086,DS-f7f59bb2-830f-406a-a99a-d3ae558f1d44,DISK], DatanodeInfoWithStorage[127.0.0.1:38079,DS-bc04ec94-ec9b-4bcb-a0d1-6d428a3f384d,DISK], DatanodeInfoWithStorage[127.0.0.1:33824,DS-8ea87d7f-6d6d-4cad-8576-3b6167f6391f,DISK], DatanodeInfoWithStorage[127.0.0.1:46641,DS-03e969f7-b5a2-45c0-9c19-0b20ba6cc621,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-648033562-172.17.0.19-1596878840938:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43306,DS-6a7c766e-21bf-4b22-a527-eabfcfda7994,DISK], DatanodeInfoWithStorage[127.0.0.1:38384,DS-388c3e6b-98b8-4eed-8f0f-dc51d968fbe6,DISK], DatanodeInfoWithStorage[127.0.0.1:35791,DS-cdeb263f-9059-4b31-a11f-d97ecd2d71df,DISK], DatanodeInfoWithStorage[127.0.0.1:40364,DS-35a09ca4-6590-4f91-ac29-f2241a1160c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45346,DS-24234bbe-f7eb-4531-b628-24cb4e159994,DISK], DatanodeInfoWithStorage[127.0.0.1:45032,DS-deab31c2-0407-430c-813c-5b5a1eff2394,DISK], DatanodeInfoWithStorage[127.0.0.1:42621,DS-f968bd8d-ba64-4322-82e9-593428b9052e,DISK], DatanodeInfoWithStorage[127.0.0.1:43231,DS-42a78028-b7e6-497e-888c-78052eb47083,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-648033562-172.17.0.19-1596878840938:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43306,DS-6a7c766e-21bf-4b22-a527-eabfcfda7994,DISK], DatanodeInfoWithStorage[127.0.0.1:38384,DS-388c3e6b-98b8-4eed-8f0f-dc51d968fbe6,DISK], DatanodeInfoWithStorage[127.0.0.1:35791,DS-cdeb263f-9059-4b31-a11f-d97ecd2d71df,DISK], DatanodeInfoWithStorage[127.0.0.1:40364,DS-35a09ca4-6590-4f91-ac29-f2241a1160c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45346,DS-24234bbe-f7eb-4531-b628-24cb4e159994,DISK], DatanodeInfoWithStorage[127.0.0.1:45032,DS-deab31c2-0407-430c-813c-5b5a1eff2394,DISK], DatanodeInfoWithStorage[127.0.0.1:42621,DS-f968bd8d-ba64-4322-82e9-593428b9052e,DISK], DatanodeInfoWithStorage[127.0.0.1:43231,DS-42a78028-b7e6-497e-888c-78052eb47083,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-781900157-172.17.0.19-1596879205704:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33323,DS-a00700dd-b8f8-40ae-82ef-d9ff8cc04c55,DISK], DatanodeInfoWithStorage[127.0.0.1:34932,DS-96c1b906-a5a4-42d5-ad78-2ce46ba81899,DISK], DatanodeInfoWithStorage[127.0.0.1:45844,DS-cb7021e5-2042-4189-902e-9a68a9521f80,DISK], DatanodeInfoWithStorage[127.0.0.1:37124,DS-3de3bda7-e736-457c-9c6a-8305ed6ba170,DISK], DatanodeInfoWithStorage[127.0.0.1:35460,DS-0d87af83-34ff-4e4b-999e-8f3a21f0e698,DISK], DatanodeInfoWithStorage[127.0.0.1:39019,DS-048c166c-11dc-4df9-ad61-6228c12a76f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38403,DS-0d35d939-e4f1-40bb-9fbf-b8a2fd79ee28,DISK], DatanodeInfoWithStorage[127.0.0.1:38321,DS-8936eea3-9781-49af-bb0a-d3b6df866dc7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-781900157-172.17.0.19-1596879205704:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33323,DS-a00700dd-b8f8-40ae-82ef-d9ff8cc04c55,DISK], DatanodeInfoWithStorage[127.0.0.1:34932,DS-96c1b906-a5a4-42d5-ad78-2ce46ba81899,DISK], DatanodeInfoWithStorage[127.0.0.1:45844,DS-cb7021e5-2042-4189-902e-9a68a9521f80,DISK], DatanodeInfoWithStorage[127.0.0.1:37124,DS-3de3bda7-e736-457c-9c6a-8305ed6ba170,DISK], DatanodeInfoWithStorage[127.0.0.1:35460,DS-0d87af83-34ff-4e4b-999e-8f3a21f0e698,DISK], DatanodeInfoWithStorage[127.0.0.1:39019,DS-048c166c-11dc-4df9-ad61-6228c12a76f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38403,DS-0d35d939-e4f1-40bb-9fbf-b8a2fd79ee28,DISK], DatanodeInfoWithStorage[127.0.0.1:38321,DS-8936eea3-9781-49af-bb0a-d3b6df866dc7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-47957951-172.17.0.19-1596879800390:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44360,DS-9b7b9137-1ae3-427f-bde4-6735d766a780,DISK], DatanodeInfoWithStorage[127.0.0.1:40573,DS-23d67ea6-6973-4dd1-a89a-c3fb3f51b17e,DISK], DatanodeInfoWithStorage[127.0.0.1:33819,DS-78cb7c8c-ded3-4ae4-9242-a348b25a6464,DISK], DatanodeInfoWithStorage[127.0.0.1:40582,DS-bf152240-0cb3-4f51-a64e-c27fb09c1f2a,DISK], DatanodeInfoWithStorage[127.0.0.1:46823,DS-b8d93dfb-fe44-46f7-8d2c-379f80e2e17d,DISK], DatanodeInfoWithStorage[127.0.0.1:41220,DS-ecbd9b93-d53b-4920-99c3-d8bc3ec96a14,DISK], DatanodeInfoWithStorage[127.0.0.1:37786,DS-a0ce8267-2003-4803-af61-0358d2910aee,DISK], DatanodeInfoWithStorage[127.0.0.1:33942,DS-4d57f333-40b5-4f90-a9fc-bac55a4692ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-47957951-172.17.0.19-1596879800390:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44360,DS-9b7b9137-1ae3-427f-bde4-6735d766a780,DISK], DatanodeInfoWithStorage[127.0.0.1:40573,DS-23d67ea6-6973-4dd1-a89a-c3fb3f51b17e,DISK], DatanodeInfoWithStorage[127.0.0.1:33819,DS-78cb7c8c-ded3-4ae4-9242-a348b25a6464,DISK], DatanodeInfoWithStorage[127.0.0.1:40582,DS-bf152240-0cb3-4f51-a64e-c27fb09c1f2a,DISK], DatanodeInfoWithStorage[127.0.0.1:46823,DS-b8d93dfb-fe44-46f7-8d2c-379f80e2e17d,DISK], DatanodeInfoWithStorage[127.0.0.1:41220,DS-ecbd9b93-d53b-4920-99c3-d8bc3ec96a14,DISK], DatanodeInfoWithStorage[127.0.0.1:37786,DS-a0ce8267-2003-4803-af61-0358d2910aee,DISK], DatanodeInfoWithStorage[127.0.0.1:33942,DS-4d57f333-40b5-4f90-a9fc-bac55a4692ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1575942192-172.17.0.19-1596879929097:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45544,DS-d0733d63-8260-4f8a-95ae-d4a41caa6be4,DISK], DatanodeInfoWithStorage[127.0.0.1:42166,DS-99c3d0dd-1ea7-4c2a-a622-ad554844980e,DISK], DatanodeInfoWithStorage[127.0.0.1:40185,DS-e1845aa9-2c90-4156-8c74-aef76ea5cf4f,DISK], DatanodeInfoWithStorage[127.0.0.1:39989,DS-3ca7f226-4288-4325-ba4b-097cc553662d,DISK], DatanodeInfoWithStorage[127.0.0.1:36369,DS-bb616153-4a16-4ec6-af0d-00d7d588c12c,DISK], DatanodeInfoWithStorage[127.0.0.1:41700,DS-5c1caac1-6b9d-4f51-80cc-13ce1c9c08ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43221,DS-48b01375-b28e-4d30-8314-c993243c8e59,DISK], DatanodeInfoWithStorage[127.0.0.1:33308,DS-bdf7016e-5ef2-4855-9f3a-dfee9e956676,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1575942192-172.17.0.19-1596879929097:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45544,DS-d0733d63-8260-4f8a-95ae-d4a41caa6be4,DISK], DatanodeInfoWithStorage[127.0.0.1:42166,DS-99c3d0dd-1ea7-4c2a-a622-ad554844980e,DISK], DatanodeInfoWithStorage[127.0.0.1:40185,DS-e1845aa9-2c90-4156-8c74-aef76ea5cf4f,DISK], DatanodeInfoWithStorage[127.0.0.1:39989,DS-3ca7f226-4288-4325-ba4b-097cc553662d,DISK], DatanodeInfoWithStorage[127.0.0.1:36369,DS-bb616153-4a16-4ec6-af0d-00d7d588c12c,DISK], DatanodeInfoWithStorage[127.0.0.1:41700,DS-5c1caac1-6b9d-4f51-80cc-13ce1c9c08ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43221,DS-48b01375-b28e-4d30-8314-c993243c8e59,DISK], DatanodeInfoWithStorage[127.0.0.1:33308,DS-bdf7016e-5ef2-4855-9f3a-dfee9e956676,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1171097943-172.17.0.19-1596880183861:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44539,DS-24df94b1-de1b-41b3-912e-dddf7e5f8c18,DISK], DatanodeInfoWithStorage[127.0.0.1:38215,DS-231cbced-7139-4b5b-8647-aacecb34b9b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33680,DS-af4c90a8-c034-475f-b858-156d08a4acb8,DISK], DatanodeInfoWithStorage[127.0.0.1:36318,DS-450e4a54-60ac-49dd-abe5-e101a9ea697f,DISK], DatanodeInfoWithStorage[127.0.0.1:36854,DS-99ee1f44-ba5c-4ca3-a717-18bc89ea1630,DISK], DatanodeInfoWithStorage[127.0.0.1:41775,DS-eefd8968-79cf-404e-a9d6-5281e1a74567,DISK], DatanodeInfoWithStorage[127.0.0.1:35358,DS-ebc1e07a-3123-40b7-8ad6-f54a5dabea1f,DISK], DatanodeInfoWithStorage[127.0.0.1:33450,DS-840d2d59-8cf4-4ed0-8e26-26d81a3486c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1171097943-172.17.0.19-1596880183861:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44539,DS-24df94b1-de1b-41b3-912e-dddf7e5f8c18,DISK], DatanodeInfoWithStorage[127.0.0.1:38215,DS-231cbced-7139-4b5b-8647-aacecb34b9b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33680,DS-af4c90a8-c034-475f-b858-156d08a4acb8,DISK], DatanodeInfoWithStorage[127.0.0.1:36318,DS-450e4a54-60ac-49dd-abe5-e101a9ea697f,DISK], DatanodeInfoWithStorage[127.0.0.1:36854,DS-99ee1f44-ba5c-4ca3-a717-18bc89ea1630,DISK], DatanodeInfoWithStorage[127.0.0.1:41775,DS-eefd8968-79cf-404e-a9d6-5281e1a74567,DISK], DatanodeInfoWithStorage[127.0.0.1:35358,DS-ebc1e07a-3123-40b7-8ad6-f54a5dabea1f,DISK], DatanodeInfoWithStorage[127.0.0.1:33450,DS-840d2d59-8cf4-4ed0-8e26-26d81a3486c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1130095955-172.17.0.19-1596880278376:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35741,DS-842c8622-cfc3-4489-8f48-2f8119605447,DISK], DatanodeInfoWithStorage[127.0.0.1:37347,DS-782e28f1-5588-4369-850c-5bb37ba8e5fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45274,DS-19afea13-dbbb-4090-bbdb-1e35b41dbb7b,DISK], DatanodeInfoWithStorage[127.0.0.1:44265,DS-75953551-5b6e-4a75-a6b0-5e07e3743f8c,DISK], DatanodeInfoWithStorage[127.0.0.1:46674,DS-63669ce3-12b0-4ad4-b931-dfc449c4935a,DISK], DatanodeInfoWithStorage[127.0.0.1:46669,DS-3d160f13-02ac-474a-9f6e-434c91b8b693,DISK], DatanodeInfoWithStorage[127.0.0.1:40193,DS-74d39336-16ca-4148-b4b2-5dc096d4037b,DISK], DatanodeInfoWithStorage[127.0.0.1:35961,DS-dcbcae8c-37f2-4097-a77a-b8843e1a9017,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1130095955-172.17.0.19-1596880278376:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35741,DS-842c8622-cfc3-4489-8f48-2f8119605447,DISK], DatanodeInfoWithStorage[127.0.0.1:37347,DS-782e28f1-5588-4369-850c-5bb37ba8e5fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45274,DS-19afea13-dbbb-4090-bbdb-1e35b41dbb7b,DISK], DatanodeInfoWithStorage[127.0.0.1:44265,DS-75953551-5b6e-4a75-a6b0-5e07e3743f8c,DISK], DatanodeInfoWithStorage[127.0.0.1:46674,DS-63669ce3-12b0-4ad4-b931-dfc449c4935a,DISK], DatanodeInfoWithStorage[127.0.0.1:46669,DS-3d160f13-02ac-474a-9f6e-434c91b8b693,DISK], DatanodeInfoWithStorage[127.0.0.1:40193,DS-74d39336-16ca-4148-b4b2-5dc096d4037b,DISK], DatanodeInfoWithStorage[127.0.0.1:35961,DS-dcbcae8c-37f2-4097-a77a-b8843e1a9017,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2048749580-172.17.0.19-1596880312794:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46828,DS-d092a343-2e61-4f51-b678-afc622f48528,DISK], DatanodeInfoWithStorage[127.0.0.1:33309,DS-f35ce8e0-b359-4ccc-8e88-54582c76de7d,DISK], DatanodeInfoWithStorage[127.0.0.1:42319,DS-ef96cbf4-57bc-4c19-b882-728f3e36f5bb,DISK], DatanodeInfoWithStorage[127.0.0.1:46019,DS-4113986c-ba0f-4ab4-82a4-23fe8eb1c627,DISK], DatanodeInfoWithStorage[127.0.0.1:35412,DS-51b93d1a-4144-4805-a3e7-d504971e5cea,DISK], DatanodeInfoWithStorage[127.0.0.1:42099,DS-45d84981-7e2a-4cf1-b2b8-4fc25212f250,DISK], DatanodeInfoWithStorage[127.0.0.1:45535,DS-c255b845-15ba-41ae-80ee-8d23d5d7b418,DISK], DatanodeInfoWithStorage[127.0.0.1:36202,DS-7ce0da04-b094-4b3e-866c-eb653ad7cfbf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2048749580-172.17.0.19-1596880312794:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46828,DS-d092a343-2e61-4f51-b678-afc622f48528,DISK], DatanodeInfoWithStorage[127.0.0.1:33309,DS-f35ce8e0-b359-4ccc-8e88-54582c76de7d,DISK], DatanodeInfoWithStorage[127.0.0.1:42319,DS-ef96cbf4-57bc-4c19-b882-728f3e36f5bb,DISK], DatanodeInfoWithStorage[127.0.0.1:46019,DS-4113986c-ba0f-4ab4-82a4-23fe8eb1c627,DISK], DatanodeInfoWithStorage[127.0.0.1:35412,DS-51b93d1a-4144-4805-a3e7-d504971e5cea,DISK], DatanodeInfoWithStorage[127.0.0.1:42099,DS-45d84981-7e2a-4cf1-b2b8-4fc25212f250,DISK], DatanodeInfoWithStorage[127.0.0.1:45535,DS-c255b845-15ba-41ae-80ee-8d23d5d7b418,DISK], DatanodeInfoWithStorage[127.0.0.1:36202,DS-7ce0da04-b094-4b3e-866c-eb653ad7cfbf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-133267870-172.17.0.19-1596881023391:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46538,DS-d519d4cf-4ea7-4b96-987a-8c4f29dba2e5,DISK], DatanodeInfoWithStorage[127.0.0.1:39673,DS-16f597b3-95a1-4f75-9b81-07eae965cf8d,DISK], DatanodeInfoWithStorage[127.0.0.1:36012,DS-5b5370ec-aaf7-448a-bea2-e1fa263fbdc7,DISK], DatanodeInfoWithStorage[127.0.0.1:35019,DS-73edc59b-20dd-4da4-bf58-c9fd5f082217,DISK], DatanodeInfoWithStorage[127.0.0.1:43315,DS-4432f813-cf35-47f2-9f93-c5b9a543ac0d,DISK], DatanodeInfoWithStorage[127.0.0.1:43931,DS-3f2c0beb-4607-4391-8f6d-94114930030b,DISK], DatanodeInfoWithStorage[127.0.0.1:34335,DS-3fa931b8-f6ce-4b70-a20c-ddf7ddf89799,DISK], DatanodeInfoWithStorage[127.0.0.1:42912,DS-53061d42-fe7f-4982-b11d-7cf191450247,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-133267870-172.17.0.19-1596881023391:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46538,DS-d519d4cf-4ea7-4b96-987a-8c4f29dba2e5,DISK], DatanodeInfoWithStorage[127.0.0.1:39673,DS-16f597b3-95a1-4f75-9b81-07eae965cf8d,DISK], DatanodeInfoWithStorage[127.0.0.1:36012,DS-5b5370ec-aaf7-448a-bea2-e1fa263fbdc7,DISK], DatanodeInfoWithStorage[127.0.0.1:35019,DS-73edc59b-20dd-4da4-bf58-c9fd5f082217,DISK], DatanodeInfoWithStorage[127.0.0.1:43315,DS-4432f813-cf35-47f2-9f93-c5b9a543ac0d,DISK], DatanodeInfoWithStorage[127.0.0.1:43931,DS-3f2c0beb-4607-4391-8f6d-94114930030b,DISK], DatanodeInfoWithStorage[127.0.0.1:34335,DS-3fa931b8-f6ce-4b70-a20c-ddf7ddf89799,DISK], DatanodeInfoWithStorage[127.0.0.1:42912,DS-53061d42-fe7f-4982-b11d-7cf191450247,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1764705771-172.17.0.19-1596881157894:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41040,DS-ba3336c7-0425-4066-9069-fecd98b46e46,DISK], DatanodeInfoWithStorage[127.0.0.1:46445,DS-4b561de7-d720-469e-ac43-102ae6907700,DISK], DatanodeInfoWithStorage[127.0.0.1:42442,DS-15b287b9-7acd-4f64-b039-eea1c8527f16,DISK], DatanodeInfoWithStorage[127.0.0.1:37215,DS-b2277803-8aa8-426b-9cc3-efaac85ab586,DISK], DatanodeInfoWithStorage[127.0.0.1:46132,DS-d8bbc01a-1605-4a9d-9cbe-8a1ee947126c,DISK], DatanodeInfoWithStorage[127.0.0.1:40132,DS-36b931db-1872-4796-9ad3-c4c5a20f7983,DISK], DatanodeInfoWithStorage[127.0.0.1:44335,DS-e5a9b486-e154-4296-b90a-764914a04ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:37424,DS-317317e3-6ceb-46b3-8148-2e1b621d3f52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1764705771-172.17.0.19-1596881157894:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41040,DS-ba3336c7-0425-4066-9069-fecd98b46e46,DISK], DatanodeInfoWithStorage[127.0.0.1:46445,DS-4b561de7-d720-469e-ac43-102ae6907700,DISK], DatanodeInfoWithStorage[127.0.0.1:42442,DS-15b287b9-7acd-4f64-b039-eea1c8527f16,DISK], DatanodeInfoWithStorage[127.0.0.1:37215,DS-b2277803-8aa8-426b-9cc3-efaac85ab586,DISK], DatanodeInfoWithStorage[127.0.0.1:46132,DS-d8bbc01a-1605-4a9d-9cbe-8a1ee947126c,DISK], DatanodeInfoWithStorage[127.0.0.1:40132,DS-36b931db-1872-4796-9ad3-c4c5a20f7983,DISK], DatanodeInfoWithStorage[127.0.0.1:44335,DS-e5a9b486-e154-4296-b90a-764914a04ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:37424,DS-317317e3-6ceb-46b3-8148-2e1b621d3f52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-157328929-172.17.0.19-1596881637570:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37418,DS-8cb7fe6b-d230-48a7-966c-7fd808a84740,DISK], DatanodeInfoWithStorage[127.0.0.1:34019,DS-65afb1e9-4094-4c4e-abc7-a11c25b53e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:43527,DS-68780bc5-bfc0-4d99-966f-e21a88ed002a,DISK], DatanodeInfoWithStorage[127.0.0.1:36905,DS-b19e3599-8a93-487a-bf35-3049e586669c,DISK], DatanodeInfoWithStorage[127.0.0.1:45226,DS-b9846b06-4098-497c-9a09-cf0ee121f01a,DISK], DatanodeInfoWithStorage[127.0.0.1:33090,DS-a22a06e2-6adc-4a20-ad67-7a36b61bf521,DISK], DatanodeInfoWithStorage[127.0.0.1:39943,DS-2626ba94-afe2-4a2d-9cbf-971728995c3e,DISK], DatanodeInfoWithStorage[127.0.0.1:33334,DS-d40e321f-cc23-4f5c-9006-cad509e1bd81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-157328929-172.17.0.19-1596881637570:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37418,DS-8cb7fe6b-d230-48a7-966c-7fd808a84740,DISK], DatanodeInfoWithStorage[127.0.0.1:34019,DS-65afb1e9-4094-4c4e-abc7-a11c25b53e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:43527,DS-68780bc5-bfc0-4d99-966f-e21a88ed002a,DISK], DatanodeInfoWithStorage[127.0.0.1:36905,DS-b19e3599-8a93-487a-bf35-3049e586669c,DISK], DatanodeInfoWithStorage[127.0.0.1:45226,DS-b9846b06-4098-497c-9a09-cf0ee121f01a,DISK], DatanodeInfoWithStorage[127.0.0.1:33090,DS-a22a06e2-6adc-4a20-ad67-7a36b61bf521,DISK], DatanodeInfoWithStorage[127.0.0.1:39943,DS-2626ba94-afe2-4a2d-9cbf-971728995c3e,DISK], DatanodeInfoWithStorage[127.0.0.1:33334,DS-d40e321f-cc23-4f5c-9006-cad509e1bd81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-711927518-172.17.0.19-1596882401069:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38038,DS-6389fec9-cf87-454c-bd06-3c77c1c9bc75,DISK], DatanodeInfoWithStorage[127.0.0.1:36751,DS-e2b810c9-920a-4051-a30d-f31b1195f63c,DISK], DatanodeInfoWithStorage[127.0.0.1:33635,DS-5d903598-fd9a-4a73-a09d-2417efc14d76,DISK], DatanodeInfoWithStorage[127.0.0.1:37134,DS-11b17cf5-487b-4a92-8be3-4e130abc901e,DISK], DatanodeInfoWithStorage[127.0.0.1:46198,DS-e7469acc-701c-43a4-a613-fac8ae4582c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38178,DS-3dbce953-6e7d-42bc-a6b6-f568f65fe836,DISK], DatanodeInfoWithStorage[127.0.0.1:42365,DS-7e6e3ebd-f4c6-437d-bbed-4e8153661eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:43483,DS-8178186d-d9fa-418e-b93b-6cd8f35184c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-711927518-172.17.0.19-1596882401069:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38038,DS-6389fec9-cf87-454c-bd06-3c77c1c9bc75,DISK], DatanodeInfoWithStorage[127.0.0.1:36751,DS-e2b810c9-920a-4051-a30d-f31b1195f63c,DISK], DatanodeInfoWithStorage[127.0.0.1:33635,DS-5d903598-fd9a-4a73-a09d-2417efc14d76,DISK], DatanodeInfoWithStorage[127.0.0.1:37134,DS-11b17cf5-487b-4a92-8be3-4e130abc901e,DISK], DatanodeInfoWithStorage[127.0.0.1:46198,DS-e7469acc-701c-43a4-a613-fac8ae4582c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38178,DS-3dbce953-6e7d-42bc-a6b6-f568f65fe836,DISK], DatanodeInfoWithStorage[127.0.0.1:42365,DS-7e6e3ebd-f4c6-437d-bbed-4e8153661eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:43483,DS-8178186d-d9fa-418e-b93b-6cd8f35184c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 6590
