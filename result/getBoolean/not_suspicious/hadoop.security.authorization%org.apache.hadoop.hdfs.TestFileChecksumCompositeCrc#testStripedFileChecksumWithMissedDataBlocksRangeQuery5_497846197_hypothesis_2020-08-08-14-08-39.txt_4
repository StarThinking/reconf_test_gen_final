reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-946986805-172.17.0.11-1596895871999:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45539,DS-400ee950-aea9-4ba2-8ee5-b383c97e5281,DISK], DatanodeInfoWithStorage[127.0.0.1:39820,DS-d9995089-944b-4f5d-bdac-5b3651b58203,DISK], DatanodeInfoWithStorage[127.0.0.1:37343,DS-90aac694-0e1e-4a26-9772-4798ae9b0d43,DISK], DatanodeInfoWithStorage[127.0.0.1:32825,DS-73a1763f-ca9e-4475-8ce8-f55f9aeac341,DISK], DatanodeInfoWithStorage[127.0.0.1:38032,DS-ffb4334b-cf6f-486d-bb26-67d026bdeabe,DISK], DatanodeInfoWithStorage[127.0.0.1:44255,DS-a47bac8d-7e32-470c-b887-5b37600c9cd0,DISK], DatanodeInfoWithStorage[127.0.0.1:45611,DS-4437ccb0-7b56-4d4f-b4d8-d1b017db46d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33067,DS-3e8fcc0f-fde5-4e15-a610-e6d7082a3db9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-946986805-172.17.0.11-1596895871999:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45539,DS-400ee950-aea9-4ba2-8ee5-b383c97e5281,DISK], DatanodeInfoWithStorage[127.0.0.1:39820,DS-d9995089-944b-4f5d-bdac-5b3651b58203,DISK], DatanodeInfoWithStorage[127.0.0.1:37343,DS-90aac694-0e1e-4a26-9772-4798ae9b0d43,DISK], DatanodeInfoWithStorage[127.0.0.1:32825,DS-73a1763f-ca9e-4475-8ce8-f55f9aeac341,DISK], DatanodeInfoWithStorage[127.0.0.1:38032,DS-ffb4334b-cf6f-486d-bb26-67d026bdeabe,DISK], DatanodeInfoWithStorage[127.0.0.1:44255,DS-a47bac8d-7e32-470c-b887-5b37600c9cd0,DISK], DatanodeInfoWithStorage[127.0.0.1:45611,DS-4437ccb0-7b56-4d4f-b4d8-d1b017db46d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33067,DS-3e8fcc0f-fde5-4e15-a610-e6d7082a3db9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-628750807-172.17.0.11-1596896250437:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42260,DS-6f7717fe-e4a2-403e-976b-1fa4eda8686c,DISK], DatanodeInfoWithStorage[127.0.0.1:42660,DS-7d0006bc-b057-40da-80f5-805a9bdfe0b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35067,DS-0e730cec-a720-467e-a89e-48a6c3db1db2,DISK], DatanodeInfoWithStorage[127.0.0.1:37004,DS-b978f281-de8f-4771-9d2c-329355e7dd61,DISK], DatanodeInfoWithStorage[127.0.0.1:41701,DS-d3ac3814-1ce7-467c-a42b-1c2a5ab72244,DISK], DatanodeInfoWithStorage[127.0.0.1:46550,DS-6b907e93-d402-4f14-aa75-d521a332d821,DISK], DatanodeInfoWithStorage[127.0.0.1:40627,DS-ff75af9d-165c-45cf-9f1a-29689d8c5043,DISK], DatanodeInfoWithStorage[127.0.0.1:37379,DS-9f1469fa-959f-46e7-ac70-6e3849bd66c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-628750807-172.17.0.11-1596896250437:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42260,DS-6f7717fe-e4a2-403e-976b-1fa4eda8686c,DISK], DatanodeInfoWithStorage[127.0.0.1:42660,DS-7d0006bc-b057-40da-80f5-805a9bdfe0b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35067,DS-0e730cec-a720-467e-a89e-48a6c3db1db2,DISK], DatanodeInfoWithStorage[127.0.0.1:37004,DS-b978f281-de8f-4771-9d2c-329355e7dd61,DISK], DatanodeInfoWithStorage[127.0.0.1:41701,DS-d3ac3814-1ce7-467c-a42b-1c2a5ab72244,DISK], DatanodeInfoWithStorage[127.0.0.1:46550,DS-6b907e93-d402-4f14-aa75-d521a332d821,DISK], DatanodeInfoWithStorage[127.0.0.1:40627,DS-ff75af9d-165c-45cf-9f1a-29689d8c5043,DISK], DatanodeInfoWithStorage[127.0.0.1:37379,DS-9f1469fa-959f-46e7-ac70-6e3849bd66c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-482229747-172.17.0.11-1596896489104:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39863,DS-66dcb882-6022-4c50-93d2-87fcd05d3ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:44296,DS-215e0b68-45b7-436c-bd8d-77ac6cc8b563,DISK], DatanodeInfoWithStorage[127.0.0.1:37179,DS-c02ab34b-b72d-4614-a1ad-8e75cfe5110f,DISK], DatanodeInfoWithStorage[127.0.0.1:46566,DS-9aa43b9e-2883-483a-bc6b-38a7a79d2563,DISK], DatanodeInfoWithStorage[127.0.0.1:33306,DS-043b295c-8340-48ba-9e12-766979524fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:33681,DS-00ffba36-c7f5-4c93-8012-ae7376bba84b,DISK], DatanodeInfoWithStorage[127.0.0.1:36282,DS-7de07bdb-0055-4612-af07-6fb0106e1b1a,DISK], DatanodeInfoWithStorage[127.0.0.1:34536,DS-3a392947-d641-4548-ae16-8ffe2a82404b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-482229747-172.17.0.11-1596896489104:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39863,DS-66dcb882-6022-4c50-93d2-87fcd05d3ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:44296,DS-215e0b68-45b7-436c-bd8d-77ac6cc8b563,DISK], DatanodeInfoWithStorage[127.0.0.1:37179,DS-c02ab34b-b72d-4614-a1ad-8e75cfe5110f,DISK], DatanodeInfoWithStorage[127.0.0.1:46566,DS-9aa43b9e-2883-483a-bc6b-38a7a79d2563,DISK], DatanodeInfoWithStorage[127.0.0.1:33306,DS-043b295c-8340-48ba-9e12-766979524fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:33681,DS-00ffba36-c7f5-4c93-8012-ae7376bba84b,DISK], DatanodeInfoWithStorage[127.0.0.1:36282,DS-7de07bdb-0055-4612-af07-6fb0106e1b1a,DISK], DatanodeInfoWithStorage[127.0.0.1:34536,DS-3a392947-d641-4548-ae16-8ffe2a82404b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-36244165-172.17.0.11-1596896937257:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44918,DS-86a70c91-f073-4293-a1fe-0e3ab318afff,DISK], DatanodeInfoWithStorage[127.0.0.1:33892,DS-f2de4e61-89e0-4ad4-ac6d-513010e213ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34520,DS-a0a827ad-dd05-4701-a45e-ba3f20988f6b,DISK], DatanodeInfoWithStorage[127.0.0.1:41152,DS-ef5056e4-c1bc-4c13-867c-174f72036967,DISK], DatanodeInfoWithStorage[127.0.0.1:33478,DS-8b0f3b82-963b-4c9d-a164-784426744e04,DISK], DatanodeInfoWithStorage[127.0.0.1:39535,DS-576692f7-0687-451a-b77a-e7189cc486bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40375,DS-f8edfb37-e1e5-46e5-a461-db820879eb71,DISK], DatanodeInfoWithStorage[127.0.0.1:37299,DS-e195b31f-8bbe-471b-9680-befea8b27f6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-36244165-172.17.0.11-1596896937257:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44918,DS-86a70c91-f073-4293-a1fe-0e3ab318afff,DISK], DatanodeInfoWithStorage[127.0.0.1:33892,DS-f2de4e61-89e0-4ad4-ac6d-513010e213ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34520,DS-a0a827ad-dd05-4701-a45e-ba3f20988f6b,DISK], DatanodeInfoWithStorage[127.0.0.1:41152,DS-ef5056e4-c1bc-4c13-867c-174f72036967,DISK], DatanodeInfoWithStorage[127.0.0.1:33478,DS-8b0f3b82-963b-4c9d-a164-784426744e04,DISK], DatanodeInfoWithStorage[127.0.0.1:39535,DS-576692f7-0687-451a-b77a-e7189cc486bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40375,DS-f8edfb37-e1e5-46e5-a461-db820879eb71,DISK], DatanodeInfoWithStorage[127.0.0.1:37299,DS-e195b31f-8bbe-471b-9680-befea8b27f6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1871955167-172.17.0.11-1596897080209:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42358,DS-8edf6c40-ae77-43e6-b42a-d26e0bb54415,DISK], DatanodeInfoWithStorage[127.0.0.1:46693,DS-8c0d1f8c-9dae-4446-a050-38b483b77711,DISK], DatanodeInfoWithStorage[127.0.0.1:45895,DS-5f8839a3-a961-481f-918b-23ea997d5812,DISK], DatanodeInfoWithStorage[127.0.0.1:39179,DS-c23015e0-1d50-470e-8e77-53d179a75093,DISK], DatanodeInfoWithStorage[127.0.0.1:33765,DS-aa020ec1-0a1f-477c-8229-2d76df399ee4,DISK], DatanodeInfoWithStorage[127.0.0.1:41088,DS-bf00c2ac-83b1-4ab9-b2cc-968a3c3308c2,DISK], DatanodeInfoWithStorage[127.0.0.1:41977,DS-f2e87e3b-3242-4e84-88b1-c5395154745c,DISK], DatanodeInfoWithStorage[127.0.0.1:46673,DS-6568d16f-6552-44b8-8896-a9211fd0f3b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1871955167-172.17.0.11-1596897080209:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42358,DS-8edf6c40-ae77-43e6-b42a-d26e0bb54415,DISK], DatanodeInfoWithStorage[127.0.0.1:46693,DS-8c0d1f8c-9dae-4446-a050-38b483b77711,DISK], DatanodeInfoWithStorage[127.0.0.1:45895,DS-5f8839a3-a961-481f-918b-23ea997d5812,DISK], DatanodeInfoWithStorage[127.0.0.1:39179,DS-c23015e0-1d50-470e-8e77-53d179a75093,DISK], DatanodeInfoWithStorage[127.0.0.1:33765,DS-aa020ec1-0a1f-477c-8229-2d76df399ee4,DISK], DatanodeInfoWithStorage[127.0.0.1:41088,DS-bf00c2ac-83b1-4ab9-b2cc-968a3c3308c2,DISK], DatanodeInfoWithStorage[127.0.0.1:41977,DS-f2e87e3b-3242-4e84-88b1-c5395154745c,DISK], DatanodeInfoWithStorage[127.0.0.1:46673,DS-6568d16f-6552-44b8-8896-a9211fd0f3b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-187867229-172.17.0.11-1596897247460:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39972,DS-af111b09-2085-4ebd-acc4-778654562f07,DISK], DatanodeInfoWithStorage[127.0.0.1:41769,DS-5e6d0866-a6ca-424f-95d6-029e61650f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:41612,DS-347cee6b-1056-49f7-b92e-4cfe5f86073d,DISK], DatanodeInfoWithStorage[127.0.0.1:36384,DS-b49d6f4f-d121-439c-b45c-71e231ad0cd7,DISK], DatanodeInfoWithStorage[127.0.0.1:45074,DS-185b7618-269b-4b55-b7e0-3bbbcab0df44,DISK], DatanodeInfoWithStorage[127.0.0.1:40689,DS-eccdc0e7-ec3f-420e-8e94-932b758f8c66,DISK], DatanodeInfoWithStorage[127.0.0.1:43019,DS-f7029607-76cc-4749-9747-c92e7a70b955,DISK], DatanodeInfoWithStorage[127.0.0.1:35117,DS-3f557326-dd5f-4646-8720-ff4a2863b681,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-187867229-172.17.0.11-1596897247460:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39972,DS-af111b09-2085-4ebd-acc4-778654562f07,DISK], DatanodeInfoWithStorage[127.0.0.1:41769,DS-5e6d0866-a6ca-424f-95d6-029e61650f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:41612,DS-347cee6b-1056-49f7-b92e-4cfe5f86073d,DISK], DatanodeInfoWithStorage[127.0.0.1:36384,DS-b49d6f4f-d121-439c-b45c-71e231ad0cd7,DISK], DatanodeInfoWithStorage[127.0.0.1:45074,DS-185b7618-269b-4b55-b7e0-3bbbcab0df44,DISK], DatanodeInfoWithStorage[127.0.0.1:40689,DS-eccdc0e7-ec3f-420e-8e94-932b758f8c66,DISK], DatanodeInfoWithStorage[127.0.0.1:43019,DS-f7029607-76cc-4749-9747-c92e7a70b955,DISK], DatanodeInfoWithStorage[127.0.0.1:35117,DS-3f557326-dd5f-4646-8720-ff4a2863b681,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-102065252-172.17.0.11-1596897385131:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33614,DS-f6bf13f4-1bce-4f23-84ed-232742a0dbb6,DISK], DatanodeInfoWithStorage[127.0.0.1:45920,DS-3df0a98c-c901-424a-b7a8-4e41c0490cf2,DISK], DatanodeInfoWithStorage[127.0.0.1:36256,DS-bc908cac-e04b-4d12-a295-eda16810e3a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40876,DS-db57575c-189a-4f02-b9a7-c62d7f674dc5,DISK], DatanodeInfoWithStorage[127.0.0.1:43943,DS-4919ba1b-3534-4d32-afc8-806a6627fe4c,DISK], DatanodeInfoWithStorage[127.0.0.1:43903,DS-dbc7cc05-50d9-4e28-90e6-deef70357b2e,DISK], DatanodeInfoWithStorage[127.0.0.1:46199,DS-9ee3a4af-3095-4042-89d6-02c1a069cd4d,DISK], DatanodeInfoWithStorage[127.0.0.1:41051,DS-70198fba-9d15-41d5-b5d5-b4b5c5e6093f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-102065252-172.17.0.11-1596897385131:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33614,DS-f6bf13f4-1bce-4f23-84ed-232742a0dbb6,DISK], DatanodeInfoWithStorage[127.0.0.1:45920,DS-3df0a98c-c901-424a-b7a8-4e41c0490cf2,DISK], DatanodeInfoWithStorage[127.0.0.1:36256,DS-bc908cac-e04b-4d12-a295-eda16810e3a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40876,DS-db57575c-189a-4f02-b9a7-c62d7f674dc5,DISK], DatanodeInfoWithStorage[127.0.0.1:43943,DS-4919ba1b-3534-4d32-afc8-806a6627fe4c,DISK], DatanodeInfoWithStorage[127.0.0.1:43903,DS-dbc7cc05-50d9-4e28-90e6-deef70357b2e,DISK], DatanodeInfoWithStorage[127.0.0.1:46199,DS-9ee3a4af-3095-4042-89d6-02c1a069cd4d,DISK], DatanodeInfoWithStorage[127.0.0.1:41051,DS-70198fba-9d15-41d5-b5d5-b4b5c5e6093f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-721165364-172.17.0.11-1596898588869:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35578,DS-eaa49f48-a7d2-453f-80ec-9b15cbed7fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:40893,DS-2a8b3d5a-46d9-47ef-a3c2-e640847a8f49,DISK], DatanodeInfoWithStorage[127.0.0.1:44506,DS-3f8017df-106e-4839-a474-d813304e7d63,DISK], DatanodeInfoWithStorage[127.0.0.1:42437,DS-4eb534a6-646e-43d8-a895-a9465b2cb37b,DISK], DatanodeInfoWithStorage[127.0.0.1:40798,DS-45f6dfce-c432-4947-97a5-20baeab95994,DISK], DatanodeInfoWithStorage[127.0.0.1:43259,DS-6282c6ce-ab94-4622-8eb6-be81fd2fb150,DISK], DatanodeInfoWithStorage[127.0.0.1:46599,DS-687bc721-be29-43d2-8ef5-480f16427edf,DISK], DatanodeInfoWithStorage[127.0.0.1:35335,DS-ebf8bfc8-ebc5-4c51-aea8-d51047943748,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-721165364-172.17.0.11-1596898588869:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35578,DS-eaa49f48-a7d2-453f-80ec-9b15cbed7fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:40893,DS-2a8b3d5a-46d9-47ef-a3c2-e640847a8f49,DISK], DatanodeInfoWithStorage[127.0.0.1:44506,DS-3f8017df-106e-4839-a474-d813304e7d63,DISK], DatanodeInfoWithStorage[127.0.0.1:42437,DS-4eb534a6-646e-43d8-a895-a9465b2cb37b,DISK], DatanodeInfoWithStorage[127.0.0.1:40798,DS-45f6dfce-c432-4947-97a5-20baeab95994,DISK], DatanodeInfoWithStorage[127.0.0.1:43259,DS-6282c6ce-ab94-4622-8eb6-be81fd2fb150,DISK], DatanodeInfoWithStorage[127.0.0.1:46599,DS-687bc721-be29-43d2-8ef5-480f16427edf,DISK], DatanodeInfoWithStorage[127.0.0.1:35335,DS-ebf8bfc8-ebc5-4c51-aea8-d51047943748,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1674741040-172.17.0.11-1596899885594:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46483,DS-667beb70-7cc9-4caa-bce5-497073a3065b,DISK], DatanodeInfoWithStorage[127.0.0.1:37067,DS-ecc6b6bc-ad56-43cb-b439-bee62775df51,DISK], DatanodeInfoWithStorage[127.0.0.1:41217,DS-ade30160-a333-4b56-ba9f-dd051823cd34,DISK], DatanodeInfoWithStorage[127.0.0.1:36134,DS-1da760c0-6ec5-4156-a700-1b05499cd769,DISK], DatanodeInfoWithStorage[127.0.0.1:36430,DS-c1c1054d-fde2-42f1-8fb4-458ea698cabd,DISK], DatanodeInfoWithStorage[127.0.0.1:46315,DS-49f002b6-7661-40fd-bd08-a402ba41623d,DISK], DatanodeInfoWithStorage[127.0.0.1:45666,DS-f7cd719f-228a-4b31-8015-c1b5b2f00f16,DISK], DatanodeInfoWithStorage[127.0.0.1:37839,DS-4afaefcf-15ad-4aea-9523-138d8c70976e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1674741040-172.17.0.11-1596899885594:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46483,DS-667beb70-7cc9-4caa-bce5-497073a3065b,DISK], DatanodeInfoWithStorage[127.0.0.1:37067,DS-ecc6b6bc-ad56-43cb-b439-bee62775df51,DISK], DatanodeInfoWithStorage[127.0.0.1:41217,DS-ade30160-a333-4b56-ba9f-dd051823cd34,DISK], DatanodeInfoWithStorage[127.0.0.1:36134,DS-1da760c0-6ec5-4156-a700-1b05499cd769,DISK], DatanodeInfoWithStorage[127.0.0.1:36430,DS-c1c1054d-fde2-42f1-8fb4-458ea698cabd,DISK], DatanodeInfoWithStorage[127.0.0.1:46315,DS-49f002b6-7661-40fd-bd08-a402ba41623d,DISK], DatanodeInfoWithStorage[127.0.0.1:45666,DS-f7cd719f-228a-4b31-8015-c1b5b2f00f16,DISK], DatanodeInfoWithStorage[127.0.0.1:37839,DS-4afaefcf-15ad-4aea-9523-138d8c70976e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1137440464-172.17.0.11-1596899923127:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36151,DS-e8fc2434-6556-48d6-9226-52f4f48e7aff,DISK], DatanodeInfoWithStorage[127.0.0.1:34117,DS-8a09e3cf-6c04-41e8-93b0-224dea0c2bf5,DISK], DatanodeInfoWithStorage[127.0.0.1:44645,DS-ad6b31e3-ef30-43ac-8cd8-0bd2e1f46366,DISK], DatanodeInfoWithStorage[127.0.0.1:35467,DS-7e6c16da-26d5-4646-8896-19aadaa91653,DISK], DatanodeInfoWithStorage[127.0.0.1:41348,DS-5501eee1-6b87-4da8-b2b6-7eec3f8fd579,DISK], DatanodeInfoWithStorage[127.0.0.1:40832,DS-41e20cfe-f46c-48b0-9f6e-f6aa5adb96d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38623,DS-fe967e9a-3ae5-49fd-9d88-716052bbcb2b,DISK], DatanodeInfoWithStorage[127.0.0.1:46410,DS-3fb9e38f-8693-4736-9f84-f1ed6ed32714,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1137440464-172.17.0.11-1596899923127:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36151,DS-e8fc2434-6556-48d6-9226-52f4f48e7aff,DISK], DatanodeInfoWithStorage[127.0.0.1:34117,DS-8a09e3cf-6c04-41e8-93b0-224dea0c2bf5,DISK], DatanodeInfoWithStorage[127.0.0.1:44645,DS-ad6b31e3-ef30-43ac-8cd8-0bd2e1f46366,DISK], DatanodeInfoWithStorage[127.0.0.1:35467,DS-7e6c16da-26d5-4646-8896-19aadaa91653,DISK], DatanodeInfoWithStorage[127.0.0.1:41348,DS-5501eee1-6b87-4da8-b2b6-7eec3f8fd579,DISK], DatanodeInfoWithStorage[127.0.0.1:40832,DS-41e20cfe-f46c-48b0-9f6e-f6aa5adb96d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38623,DS-fe967e9a-3ae5-49fd-9d88-716052bbcb2b,DISK], DatanodeInfoWithStorage[127.0.0.1:46410,DS-3fb9e38f-8693-4736-9f84-f1ed6ed32714,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1294217370-172.17.0.11-1596899989063:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33077,DS-7b450484-3a12-448c-bea8-b82125b93ad5,DISK], DatanodeInfoWithStorage[127.0.0.1:41724,DS-4318126c-824c-4211-8434-35294878c5c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34014,DS-8d88c2ce-41bc-423a-9b6f-c7ab1dbe6ed6,DISK], DatanodeInfoWithStorage[127.0.0.1:43956,DS-9b6fe532-fe07-4933-909e-ace68515f945,DISK], DatanodeInfoWithStorage[127.0.0.1:34441,DS-271daae2-ad41-459d-91cd-739adddfe36b,DISK], DatanodeInfoWithStorage[127.0.0.1:38676,DS-980fb80c-8509-496f-84a3-05da5296fdd7,DISK], DatanodeInfoWithStorage[127.0.0.1:33108,DS-d7c2befd-c64e-4bb0-9892-0bfcaf9b4ed2,DISK], DatanodeInfoWithStorage[127.0.0.1:35934,DS-92021c0a-8915-4a84-9dff-cd4f8117ef56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1294217370-172.17.0.11-1596899989063:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33077,DS-7b450484-3a12-448c-bea8-b82125b93ad5,DISK], DatanodeInfoWithStorage[127.0.0.1:41724,DS-4318126c-824c-4211-8434-35294878c5c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34014,DS-8d88c2ce-41bc-423a-9b6f-c7ab1dbe6ed6,DISK], DatanodeInfoWithStorage[127.0.0.1:43956,DS-9b6fe532-fe07-4933-909e-ace68515f945,DISK], DatanodeInfoWithStorage[127.0.0.1:34441,DS-271daae2-ad41-459d-91cd-739adddfe36b,DISK], DatanodeInfoWithStorage[127.0.0.1:38676,DS-980fb80c-8509-496f-84a3-05da5296fdd7,DISK], DatanodeInfoWithStorage[127.0.0.1:33108,DS-d7c2befd-c64e-4bb0-9892-0bfcaf9b4ed2,DISK], DatanodeInfoWithStorage[127.0.0.1:35934,DS-92021c0a-8915-4a84-9dff-cd4f8117ef56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-780307493-172.17.0.11-1596900056181:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40474,DS-53fdb24a-31ce-4145-8e70-6c49f09bc6ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35803,DS-ed2e7828-5dd5-415f-9a48-36668a0b21a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35416,DS-12ab8294-21eb-4db3-ae46-005a8bbf0e07,DISK], DatanodeInfoWithStorage[127.0.0.1:45941,DS-50cc9fc9-2934-4091-addf-a5d65d35b04a,DISK], DatanodeInfoWithStorage[127.0.0.1:37795,DS-0054fa86-5a06-4354-9a59-b71bcc741834,DISK], DatanodeInfoWithStorage[127.0.0.1:38441,DS-1cae1507-4dfb-4820-b7bb-7e624a57c821,DISK], DatanodeInfoWithStorage[127.0.0.1:43159,DS-978f6388-761d-4143-939b-44da2bc17164,DISK], DatanodeInfoWithStorage[127.0.0.1:35995,DS-661813a2-18a9-4fff-a0a8-393b6f2dbb58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-780307493-172.17.0.11-1596900056181:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40474,DS-53fdb24a-31ce-4145-8e70-6c49f09bc6ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35803,DS-ed2e7828-5dd5-415f-9a48-36668a0b21a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35416,DS-12ab8294-21eb-4db3-ae46-005a8bbf0e07,DISK], DatanodeInfoWithStorage[127.0.0.1:45941,DS-50cc9fc9-2934-4091-addf-a5d65d35b04a,DISK], DatanodeInfoWithStorage[127.0.0.1:37795,DS-0054fa86-5a06-4354-9a59-b71bcc741834,DISK], DatanodeInfoWithStorage[127.0.0.1:38441,DS-1cae1507-4dfb-4820-b7bb-7e624a57c821,DISK], DatanodeInfoWithStorage[127.0.0.1:43159,DS-978f6388-761d-4143-939b-44da2bc17164,DISK], DatanodeInfoWithStorage[127.0.0.1:35995,DS-661813a2-18a9-4fff-a0a8-393b6f2dbb58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-304918231-172.17.0.11-1596900481676:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44185,DS-b16dc98f-0b44-49c8-aa19-95043b29c2aa,DISK], DatanodeInfoWithStorage[127.0.0.1:39016,DS-c2431178-d6f4-4094-9425-5be033d912b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37331,DS-b7d4320d-0845-48c9-9631-02e8a63542db,DISK], DatanodeInfoWithStorage[127.0.0.1:41312,DS-9c994869-68b1-4d4e-b59a-abbfa33b494e,DISK], DatanodeInfoWithStorage[127.0.0.1:44778,DS-01956e7c-7717-4d5d-bca0-ed914687dde0,DISK], DatanodeInfoWithStorage[127.0.0.1:35882,DS-78e40c3a-c19b-472a-be48-9df31e36821a,DISK], DatanodeInfoWithStorage[127.0.0.1:36021,DS-df1c757e-dcd0-4521-8cd2-b0eb89b04b0e,DISK], DatanodeInfoWithStorage[127.0.0.1:35277,DS-5840d9a1-b7d7-4fc4-8921-326941c355c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-304918231-172.17.0.11-1596900481676:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44185,DS-b16dc98f-0b44-49c8-aa19-95043b29c2aa,DISK], DatanodeInfoWithStorage[127.0.0.1:39016,DS-c2431178-d6f4-4094-9425-5be033d912b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37331,DS-b7d4320d-0845-48c9-9631-02e8a63542db,DISK], DatanodeInfoWithStorage[127.0.0.1:41312,DS-9c994869-68b1-4d4e-b59a-abbfa33b494e,DISK], DatanodeInfoWithStorage[127.0.0.1:44778,DS-01956e7c-7717-4d5d-bca0-ed914687dde0,DISK], DatanodeInfoWithStorage[127.0.0.1:35882,DS-78e40c3a-c19b-472a-be48-9df31e36821a,DISK], DatanodeInfoWithStorage[127.0.0.1:36021,DS-df1c757e-dcd0-4521-8cd2-b0eb89b04b0e,DISK], DatanodeInfoWithStorage[127.0.0.1:35277,DS-5840d9a1-b7d7-4fc4-8921-326941c355c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5173
