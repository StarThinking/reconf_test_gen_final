reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1627625300-172.17.0.2-1595385663138:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39397,DS-859425d7-cbd0-4b3d-b036-5e496e51b194,DISK], DatanodeInfoWithStorage[127.0.0.1:42467,DS-068a6155-be27-4eff-8926-e6353613f8bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40151,DS-27380352-17c6-4de8-b4f4-72840afc933e,DISK], DatanodeInfoWithStorage[127.0.0.1:42846,DS-a52b4543-5688-4817-8154-3b67c014aca9,DISK], DatanodeInfoWithStorage[127.0.0.1:33410,DS-71ce6752-36a4-40c8-9a16-0a0caa179fe8,DISK], DatanodeInfoWithStorage[127.0.0.1:44136,DS-06aa816b-927d-4189-b866-523db70e783a,DISK], DatanodeInfoWithStorage[127.0.0.1:37547,DS-1f776289-c7b1-46af-b09c-603c53f8e095,DISK], DatanodeInfoWithStorage[127.0.0.1:38650,DS-4cba1b12-a18d-4910-ab52-3d3e3e62c0da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1627625300-172.17.0.2-1595385663138:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39397,DS-859425d7-cbd0-4b3d-b036-5e496e51b194,DISK], DatanodeInfoWithStorage[127.0.0.1:42467,DS-068a6155-be27-4eff-8926-e6353613f8bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40151,DS-27380352-17c6-4de8-b4f4-72840afc933e,DISK], DatanodeInfoWithStorage[127.0.0.1:42846,DS-a52b4543-5688-4817-8154-3b67c014aca9,DISK], DatanodeInfoWithStorage[127.0.0.1:33410,DS-71ce6752-36a4-40c8-9a16-0a0caa179fe8,DISK], DatanodeInfoWithStorage[127.0.0.1:44136,DS-06aa816b-927d-4189-b866-523db70e783a,DISK], DatanodeInfoWithStorage[127.0.0.1:37547,DS-1f776289-c7b1-46af-b09c-603c53f8e095,DISK], DatanodeInfoWithStorage[127.0.0.1:38650,DS-4cba1b12-a18d-4910-ab52-3d3e3e62c0da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-920414368-172.17.0.2-1595386178021:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41661,DS-fbb051e9-da73-4620-9548-b3d0e9920e59,DISK], DatanodeInfoWithStorage[127.0.0.1:45079,DS-7121754a-c771-4612-b4e8-9acbb6b84c98,DISK], DatanodeInfoWithStorage[127.0.0.1:39602,DS-01151e6c-eec9-4412-8632-4288b7d4bb1d,DISK], DatanodeInfoWithStorage[127.0.0.1:44784,DS-8b048b15-38da-4b5e-b1f5-27ad19788a36,DISK], DatanodeInfoWithStorage[127.0.0.1:42359,DS-560235c7-5dc1-433a-a212-1849868932a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33256,DS-97ca76ee-f0e9-4384-baf8-33d709da72d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38580,DS-143e7ff3-7f5f-485d-beb6-385400c46606,DISK], DatanodeInfoWithStorage[127.0.0.1:35304,DS-ac7dd77d-cdd9-49d2-a988-cd51499a0a7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-920414368-172.17.0.2-1595386178021:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41661,DS-fbb051e9-da73-4620-9548-b3d0e9920e59,DISK], DatanodeInfoWithStorage[127.0.0.1:45079,DS-7121754a-c771-4612-b4e8-9acbb6b84c98,DISK], DatanodeInfoWithStorage[127.0.0.1:39602,DS-01151e6c-eec9-4412-8632-4288b7d4bb1d,DISK], DatanodeInfoWithStorage[127.0.0.1:44784,DS-8b048b15-38da-4b5e-b1f5-27ad19788a36,DISK], DatanodeInfoWithStorage[127.0.0.1:42359,DS-560235c7-5dc1-433a-a212-1849868932a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33256,DS-97ca76ee-f0e9-4384-baf8-33d709da72d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38580,DS-143e7ff3-7f5f-485d-beb6-385400c46606,DISK], DatanodeInfoWithStorage[127.0.0.1:35304,DS-ac7dd77d-cdd9-49d2-a988-cd51499a0a7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-466567033-172.17.0.2-1595387546735:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44611,DS-39a20d14-04d2-4a2d-b2ea-a417b5c6155c,DISK], DatanodeInfoWithStorage[127.0.0.1:35112,DS-0bef6e4c-8a7f-437d-a06d-602f8b7fbee4,DISK], DatanodeInfoWithStorage[127.0.0.1:43130,DS-46883507-7371-4071-ae9f-f8e9ccae926d,DISK], DatanodeInfoWithStorage[127.0.0.1:32949,DS-cca825b4-0c2b-4cf5-ba2c-00e830a575ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39856,DS-ce58eb00-b397-4c8c-a75a-91f68b001ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:39608,DS-9803640e-bbfa-4243-b997-299e1522156c,DISK], DatanodeInfoWithStorage[127.0.0.1:45829,DS-8a557c15-b601-4360-90e5-58f4151a8fba,DISK], DatanodeInfoWithStorage[127.0.0.1:45326,DS-f99f3e5d-79fe-4c4d-8b98-f045c15c7585,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-466567033-172.17.0.2-1595387546735:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44611,DS-39a20d14-04d2-4a2d-b2ea-a417b5c6155c,DISK], DatanodeInfoWithStorage[127.0.0.1:35112,DS-0bef6e4c-8a7f-437d-a06d-602f8b7fbee4,DISK], DatanodeInfoWithStorage[127.0.0.1:43130,DS-46883507-7371-4071-ae9f-f8e9ccae926d,DISK], DatanodeInfoWithStorage[127.0.0.1:32949,DS-cca825b4-0c2b-4cf5-ba2c-00e830a575ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39856,DS-ce58eb00-b397-4c8c-a75a-91f68b001ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:39608,DS-9803640e-bbfa-4243-b997-299e1522156c,DISK], DatanodeInfoWithStorage[127.0.0.1:45829,DS-8a557c15-b601-4360-90e5-58f4151a8fba,DISK], DatanodeInfoWithStorage[127.0.0.1:45326,DS-f99f3e5d-79fe-4c4d-8b98-f045c15c7585,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-485337053-172.17.0.2-1595387806718:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42333,DS-42de44b1-31ac-4fa4-b9fc-e00247e46d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:41746,DS-55f890e9-ff72-497e-aa4e-475fc97bca76,DISK], DatanodeInfoWithStorage[127.0.0.1:38310,DS-52dd5378-5ba7-4dfe-9e9e-bafadfbf99f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33921,DS-3570d0df-245e-43df-9a07-e65ef6a37e77,DISK], DatanodeInfoWithStorage[127.0.0.1:39256,DS-05ac7c69-9f11-4a75-a0b0-07c86ae07673,DISK], DatanodeInfoWithStorage[127.0.0.1:42155,DS-942a6f17-2249-4868-b205-14d952cdd8c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40590,DS-36397f25-5ebe-4c3d-8129-bbbe668b1c72,DISK], DatanodeInfoWithStorage[127.0.0.1:39555,DS-d6aa6520-9472-468a-bb09-4764674c1e8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-485337053-172.17.0.2-1595387806718:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42333,DS-42de44b1-31ac-4fa4-b9fc-e00247e46d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:41746,DS-55f890e9-ff72-497e-aa4e-475fc97bca76,DISK], DatanodeInfoWithStorage[127.0.0.1:38310,DS-52dd5378-5ba7-4dfe-9e9e-bafadfbf99f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33921,DS-3570d0df-245e-43df-9a07-e65ef6a37e77,DISK], DatanodeInfoWithStorage[127.0.0.1:39256,DS-05ac7c69-9f11-4a75-a0b0-07c86ae07673,DISK], DatanodeInfoWithStorage[127.0.0.1:42155,DS-942a6f17-2249-4868-b205-14d952cdd8c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40590,DS-36397f25-5ebe-4c3d-8129-bbbe668b1c72,DISK], DatanodeInfoWithStorage[127.0.0.1:39555,DS-d6aa6520-9472-468a-bb09-4764674c1e8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1616303332-172.17.0.2-1595387840363:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35717,DS-2eece28c-22c7-4d88-ae68-d1dddfc7b651,DISK], DatanodeInfoWithStorage[127.0.0.1:41249,DS-17779d5b-43ee-42da-846f-820462d15e46,DISK], DatanodeInfoWithStorage[127.0.0.1:38892,DS-3adca9c7-c087-45c6-9b7f-64bc09739d6e,DISK], DatanodeInfoWithStorage[127.0.0.1:32937,DS-0e2623fd-1a1d-4e9d-bd66-0a4943db83ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36467,DS-f1e8369a-1a40-42f1-9af0-a6953b59b85f,DISK], DatanodeInfoWithStorage[127.0.0.1:37748,DS-aea18677-7fd7-4927-abc9-802178f50158,DISK], DatanodeInfoWithStorage[127.0.0.1:41517,DS-425e8f16-67e1-492c-a6c2-53b81c6432db,DISK], DatanodeInfoWithStorage[127.0.0.1:45850,DS-032ba5c5-debf-477c-8d81-258fddbd3b3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1616303332-172.17.0.2-1595387840363:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35717,DS-2eece28c-22c7-4d88-ae68-d1dddfc7b651,DISK], DatanodeInfoWithStorage[127.0.0.1:41249,DS-17779d5b-43ee-42da-846f-820462d15e46,DISK], DatanodeInfoWithStorage[127.0.0.1:38892,DS-3adca9c7-c087-45c6-9b7f-64bc09739d6e,DISK], DatanodeInfoWithStorage[127.0.0.1:32937,DS-0e2623fd-1a1d-4e9d-bd66-0a4943db83ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36467,DS-f1e8369a-1a40-42f1-9af0-a6953b59b85f,DISK], DatanodeInfoWithStorage[127.0.0.1:37748,DS-aea18677-7fd7-4927-abc9-802178f50158,DISK], DatanodeInfoWithStorage[127.0.0.1:41517,DS-425e8f16-67e1-492c-a6c2-53b81c6432db,DISK], DatanodeInfoWithStorage[127.0.0.1:45850,DS-032ba5c5-debf-477c-8d81-258fddbd3b3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-112063449-172.17.0.2-1595388002806:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35697,DS-26b3051d-d37b-4a55-a68c-14c8fafe8d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:43423,DS-fb8d40c5-7b19-41e5-92ae-c626f08c070f,DISK], DatanodeInfoWithStorage[127.0.0.1:37253,DS-c2fdf7b9-1a6e-423d-b8bf-21bd0624422e,DISK], DatanodeInfoWithStorage[127.0.0.1:35820,DS-745fca5b-f993-400c-9930-11647dc28b37,DISK], DatanodeInfoWithStorage[127.0.0.1:45941,DS-9a60d143-c875-43a3-ab11-be01343ee5cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36564,DS-7670736a-c2f4-4fc4-ba89-476ce64a0310,DISK], DatanodeInfoWithStorage[127.0.0.1:33112,DS-b32837db-91ec-4dad-af4f-8b2821e5350c,DISK], DatanodeInfoWithStorage[127.0.0.1:43282,DS-98984ca8-197c-43e5-a59c-0c8e0db485fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-112063449-172.17.0.2-1595388002806:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35697,DS-26b3051d-d37b-4a55-a68c-14c8fafe8d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:43423,DS-fb8d40c5-7b19-41e5-92ae-c626f08c070f,DISK], DatanodeInfoWithStorage[127.0.0.1:37253,DS-c2fdf7b9-1a6e-423d-b8bf-21bd0624422e,DISK], DatanodeInfoWithStorage[127.0.0.1:35820,DS-745fca5b-f993-400c-9930-11647dc28b37,DISK], DatanodeInfoWithStorage[127.0.0.1:45941,DS-9a60d143-c875-43a3-ab11-be01343ee5cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36564,DS-7670736a-c2f4-4fc4-ba89-476ce64a0310,DISK], DatanodeInfoWithStorage[127.0.0.1:33112,DS-b32837db-91ec-4dad-af4f-8b2821e5350c,DISK], DatanodeInfoWithStorage[127.0.0.1:43282,DS-98984ca8-197c-43e5-a59c-0c8e0db485fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1212907979-172.17.0.2-1595388146704:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42132,DS-dfb72a3f-3c37-4b03-a574-aaf36ca56aa4,DISK], DatanodeInfoWithStorage[127.0.0.1:36376,DS-1b2bf6f6-799e-4889-acdc-20bbe3c2b6d2,DISK], DatanodeInfoWithStorage[127.0.0.1:44151,DS-8a75e1d6-d387-4b21-a57d-b245debcaf98,DISK], DatanodeInfoWithStorage[127.0.0.1:46450,DS-d5d1015d-bad2-4f28-89e3-cd75644f60cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35988,DS-9fd52b19-f8ae-4273-81eb-a1161c9a4fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:38752,DS-e2f204d2-d19a-4c28-a40b-62b0dad061ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34928,DS-d6ffa16e-1e7b-4f84-b6fd-e9b12513effa,DISK], DatanodeInfoWithStorage[127.0.0.1:38211,DS-d70ae836-5294-4e32-a07d-be79666375da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1212907979-172.17.0.2-1595388146704:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42132,DS-dfb72a3f-3c37-4b03-a574-aaf36ca56aa4,DISK], DatanodeInfoWithStorage[127.0.0.1:36376,DS-1b2bf6f6-799e-4889-acdc-20bbe3c2b6d2,DISK], DatanodeInfoWithStorage[127.0.0.1:44151,DS-8a75e1d6-d387-4b21-a57d-b245debcaf98,DISK], DatanodeInfoWithStorage[127.0.0.1:46450,DS-d5d1015d-bad2-4f28-89e3-cd75644f60cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35988,DS-9fd52b19-f8ae-4273-81eb-a1161c9a4fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:38752,DS-e2f204d2-d19a-4c28-a40b-62b0dad061ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34928,DS-d6ffa16e-1e7b-4f84-b6fd-e9b12513effa,DISK], DatanodeInfoWithStorage[127.0.0.1:38211,DS-d70ae836-5294-4e32-a07d-be79666375da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1679374428-172.17.0.2-1595388616311:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39999,DS-ce1b3f26-8abf-4a23-999d-7da3e69fe315,DISK], DatanodeInfoWithStorage[127.0.0.1:40823,DS-bd1e3809-1b0f-430b-b927-4031b160710c,DISK], DatanodeInfoWithStorage[127.0.0.1:39988,DS-41cae783-84f7-4a87-9402-c0cd17ccfb25,DISK], DatanodeInfoWithStorage[127.0.0.1:39471,DS-565d2881-d731-42e1-9444-0c46657fbbe0,DISK], DatanodeInfoWithStorage[127.0.0.1:45942,DS-79daa0ca-21c4-44c5-90e4-d3723ce8d522,DISK], DatanodeInfoWithStorage[127.0.0.1:42504,DS-63262aef-a71d-4bd2-b0b4-8fc704d3a401,DISK], DatanodeInfoWithStorage[127.0.0.1:40848,DS-b03247b1-2284-4e21-bc31-8ed9e7219d81,DISK], DatanodeInfoWithStorage[127.0.0.1:38703,DS-e6c3507d-977d-4e16-ba88-828b3cb6a9c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1679374428-172.17.0.2-1595388616311:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39999,DS-ce1b3f26-8abf-4a23-999d-7da3e69fe315,DISK], DatanodeInfoWithStorage[127.0.0.1:40823,DS-bd1e3809-1b0f-430b-b927-4031b160710c,DISK], DatanodeInfoWithStorage[127.0.0.1:39988,DS-41cae783-84f7-4a87-9402-c0cd17ccfb25,DISK], DatanodeInfoWithStorage[127.0.0.1:39471,DS-565d2881-d731-42e1-9444-0c46657fbbe0,DISK], DatanodeInfoWithStorage[127.0.0.1:45942,DS-79daa0ca-21c4-44c5-90e4-d3723ce8d522,DISK], DatanodeInfoWithStorage[127.0.0.1:42504,DS-63262aef-a71d-4bd2-b0b4-8fc704d3a401,DISK], DatanodeInfoWithStorage[127.0.0.1:40848,DS-b03247b1-2284-4e21-bc31-8ed9e7219d81,DISK], DatanodeInfoWithStorage[127.0.0.1:38703,DS-e6c3507d-977d-4e16-ba88-828b3cb6a9c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-867547923-172.17.0.2-1595388795233:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40570,DS-a24678d2-9c28-4373-98a0-c9195131ec62,DISK], DatanodeInfoWithStorage[127.0.0.1:44285,DS-1f5d790d-9613-4b4d-a2c5-df5f10962906,DISK], DatanodeInfoWithStorage[127.0.0.1:42995,DS-1637fa43-6133-46e8-a6e8-eae84a6abd73,DISK], DatanodeInfoWithStorage[127.0.0.1:34318,DS-579d65dc-94f5-446b-8b70-c70ce9a4e417,DISK], DatanodeInfoWithStorage[127.0.0.1:33611,DS-273893f9-41f0-4230-9bf0-0124a8dc7617,DISK], DatanodeInfoWithStorage[127.0.0.1:37459,DS-dfe529ef-b4d5-45ab-8e5b-30b03d455f89,DISK], DatanodeInfoWithStorage[127.0.0.1:43219,DS-f20953b5-451d-4a34-b41a-c127d4dbd5e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41686,DS-f58ae3c5-4c0b-4fac-bdd0-cbdb08350d06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-867547923-172.17.0.2-1595388795233:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40570,DS-a24678d2-9c28-4373-98a0-c9195131ec62,DISK], DatanodeInfoWithStorage[127.0.0.1:44285,DS-1f5d790d-9613-4b4d-a2c5-df5f10962906,DISK], DatanodeInfoWithStorage[127.0.0.1:42995,DS-1637fa43-6133-46e8-a6e8-eae84a6abd73,DISK], DatanodeInfoWithStorage[127.0.0.1:34318,DS-579d65dc-94f5-446b-8b70-c70ce9a4e417,DISK], DatanodeInfoWithStorage[127.0.0.1:33611,DS-273893f9-41f0-4230-9bf0-0124a8dc7617,DISK], DatanodeInfoWithStorage[127.0.0.1:37459,DS-dfe529ef-b4d5-45ab-8e5b-30b03d455f89,DISK], DatanodeInfoWithStorage[127.0.0.1:43219,DS-f20953b5-451d-4a34-b41a-c127d4dbd5e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41686,DS-f58ae3c5-4c0b-4fac-bdd0-cbdb08350d06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1157829211-172.17.0.2-1595389001041:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36935,DS-7c1368a0-2a83-428a-9141-8a343b4475ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40061,DS-1168b0f3-fa6c-46f7-8451-92e92becb35c,DISK], DatanodeInfoWithStorage[127.0.0.1:40224,DS-f6c59bce-81bb-453d-93bc-19b61af3b0cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37432,DS-9b1e81d2-c484-4a98-a1f5-f04f66aa003f,DISK], DatanodeInfoWithStorage[127.0.0.1:41781,DS-28583fca-c2ae-4fbb-83a9-a34708175e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:39602,DS-4d8e98c9-0a13-46f7-8897-9c1ded60ce00,DISK], DatanodeInfoWithStorage[127.0.0.1:45787,DS-9629ddb2-4b4f-406a-85d7-6ea1b909d24c,DISK], DatanodeInfoWithStorage[127.0.0.1:33542,DS-8c03f161-5b57-4e5e-8608-d8f54953cf8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1157829211-172.17.0.2-1595389001041:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36935,DS-7c1368a0-2a83-428a-9141-8a343b4475ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40061,DS-1168b0f3-fa6c-46f7-8451-92e92becb35c,DISK], DatanodeInfoWithStorage[127.0.0.1:40224,DS-f6c59bce-81bb-453d-93bc-19b61af3b0cd,DISK], DatanodeInfoWithStorage[127.0.0.1:37432,DS-9b1e81d2-c484-4a98-a1f5-f04f66aa003f,DISK], DatanodeInfoWithStorage[127.0.0.1:41781,DS-28583fca-c2ae-4fbb-83a9-a34708175e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:39602,DS-4d8e98c9-0a13-46f7-8897-9c1ded60ce00,DISK], DatanodeInfoWithStorage[127.0.0.1:45787,DS-9629ddb2-4b4f-406a-85d7-6ea1b909d24c,DISK], DatanodeInfoWithStorage[127.0.0.1:33542,DS-8c03f161-5b57-4e5e-8608-d8f54953cf8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2072647927-172.17.0.2-1595389213403:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39477,DS-9bf65608-1360-4287-b30a-bb15ea484689,DISK], DatanodeInfoWithStorage[127.0.0.1:36952,DS-55f60681-95ef-4330-ac6a-2b37487837bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41077,DS-b99b02ea-c31e-48a9-b68d-6a0817f77937,DISK], DatanodeInfoWithStorage[127.0.0.1:39543,DS-7b5b19b8-d5f4-4371-a6ea-2a0de997db24,DISK], DatanodeInfoWithStorage[127.0.0.1:35150,DS-5a9f41d2-4f3f-4bd8-a4ff-d365629a18e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34148,DS-3914b9ab-6900-431f-8ff7-9286ce148d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:39890,DS-c73ced2b-80f7-49c7-b87f-c0d6556864ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38010,DS-cf7e8ad1-8e5e-4905-b72c-93815b238901,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2072647927-172.17.0.2-1595389213403:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39477,DS-9bf65608-1360-4287-b30a-bb15ea484689,DISK], DatanodeInfoWithStorage[127.0.0.1:36952,DS-55f60681-95ef-4330-ac6a-2b37487837bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41077,DS-b99b02ea-c31e-48a9-b68d-6a0817f77937,DISK], DatanodeInfoWithStorage[127.0.0.1:39543,DS-7b5b19b8-d5f4-4371-a6ea-2a0de997db24,DISK], DatanodeInfoWithStorage[127.0.0.1:35150,DS-5a9f41d2-4f3f-4bd8-a4ff-d365629a18e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34148,DS-3914b9ab-6900-431f-8ff7-9286ce148d6b,DISK], DatanodeInfoWithStorage[127.0.0.1:39890,DS-c73ced2b-80f7-49c7-b87f-c0d6556864ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38010,DS-cf7e8ad1-8e5e-4905-b72c-93815b238901,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-479593754-172.17.0.2-1595389283416:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42890,DS-988e9a98-394f-4b19-aa04-c50c337dba4f,DISK], DatanodeInfoWithStorage[127.0.0.1:35501,DS-09cfc2ae-b413-49c1-959b-232c9dc019c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42256,DS-75969bcb-9e35-4689-87a7-ec81c390c424,DISK], DatanodeInfoWithStorage[127.0.0.1:33813,DS-3f368cbd-04a9-45d6-80c9-f5f9e2526c69,DISK], DatanodeInfoWithStorage[127.0.0.1:32911,DS-0d02488f-c26c-490e-9cc6-de54b6e5e118,DISK], DatanodeInfoWithStorage[127.0.0.1:35111,DS-906733b4-fa6a-4914-9b49-b7b8e79a9840,DISK], DatanodeInfoWithStorage[127.0.0.1:35644,DS-01301574-d99e-423e-abd5-c704eeff8581,DISK], DatanodeInfoWithStorage[127.0.0.1:40250,DS-f521e1ac-28c5-49b2-a418-b87069d86b3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-479593754-172.17.0.2-1595389283416:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42890,DS-988e9a98-394f-4b19-aa04-c50c337dba4f,DISK], DatanodeInfoWithStorage[127.0.0.1:35501,DS-09cfc2ae-b413-49c1-959b-232c9dc019c9,DISK], DatanodeInfoWithStorage[127.0.0.1:42256,DS-75969bcb-9e35-4689-87a7-ec81c390c424,DISK], DatanodeInfoWithStorage[127.0.0.1:33813,DS-3f368cbd-04a9-45d6-80c9-f5f9e2526c69,DISK], DatanodeInfoWithStorage[127.0.0.1:32911,DS-0d02488f-c26c-490e-9cc6-de54b6e5e118,DISK], DatanodeInfoWithStorage[127.0.0.1:35111,DS-906733b4-fa6a-4914-9b49-b7b8e79a9840,DISK], DatanodeInfoWithStorage[127.0.0.1:35644,DS-01301574-d99e-423e-abd5-c704eeff8581,DISK], DatanodeInfoWithStorage[127.0.0.1:40250,DS-f521e1ac-28c5-49b2-a418-b87069d86b3d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-697282563-172.17.0.2-1595389417266:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36055,DS-c2b9f442-a74c-4964-bad2-c808e45ac830,DISK], DatanodeInfoWithStorage[127.0.0.1:38386,DS-7865c08a-d426-4bd2-a565-8717f176b695,DISK], DatanodeInfoWithStorage[127.0.0.1:37210,DS-bf860f36-3b80-4cc1-9542-7b216b5061ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37149,DS-d24af3cb-2ea4-4d7e-b933-6b5a5a617720,DISK], DatanodeInfoWithStorage[127.0.0.1:38830,DS-2b004913-b843-4e5a-80d3-79512ad3a294,DISK], DatanodeInfoWithStorage[127.0.0.1:33802,DS-30f36fb8-9c33-4189-b7bc-642ed19fc32e,DISK], DatanodeInfoWithStorage[127.0.0.1:35260,DS-c60a7ce4-fcee-442c-9a4d-837828e327bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43267,DS-65889fd1-fe79-4d13-a545-8f3d37c294fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-697282563-172.17.0.2-1595389417266:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36055,DS-c2b9f442-a74c-4964-bad2-c808e45ac830,DISK], DatanodeInfoWithStorage[127.0.0.1:38386,DS-7865c08a-d426-4bd2-a565-8717f176b695,DISK], DatanodeInfoWithStorage[127.0.0.1:37210,DS-bf860f36-3b80-4cc1-9542-7b216b5061ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37149,DS-d24af3cb-2ea4-4d7e-b933-6b5a5a617720,DISK], DatanodeInfoWithStorage[127.0.0.1:38830,DS-2b004913-b843-4e5a-80d3-79512ad3a294,DISK], DatanodeInfoWithStorage[127.0.0.1:33802,DS-30f36fb8-9c33-4189-b7bc-642ed19fc32e,DISK], DatanodeInfoWithStorage[127.0.0.1:35260,DS-c60a7ce4-fcee-442c-9a4d-837828e327bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43267,DS-65889fd1-fe79-4d13-a545-8f3d37c294fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-234980541-172.17.0.2-1595389541741:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43223,DS-a2598beb-012d-48d5-81c0-e8ab0b15dec2,DISK], DatanodeInfoWithStorage[127.0.0.1:35270,DS-10a175a4-6326-41ee-9f8a-be2ddf70de72,DISK], DatanodeInfoWithStorage[127.0.0.1:39450,DS-da5db81c-82ac-4ad1-b27e-acb1c6e83cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:33329,DS-b4651afd-a1fc-4b97-b1fa-02fe45c6056b,DISK], DatanodeInfoWithStorage[127.0.0.1:40307,DS-3ff606e0-e8ae-4a40-839f-246b0f0be377,DISK], DatanodeInfoWithStorage[127.0.0.1:43548,DS-ca1bcd2d-7cbe-4bd1-812e-a47381ee6645,DISK], DatanodeInfoWithStorage[127.0.0.1:38700,DS-c9a897aa-1945-4a47-9433-746eea3628ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44806,DS-a98ad898-3f58-4a64-a788-b535938b9ad8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-234980541-172.17.0.2-1595389541741:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43223,DS-a2598beb-012d-48d5-81c0-e8ab0b15dec2,DISK], DatanodeInfoWithStorage[127.0.0.1:35270,DS-10a175a4-6326-41ee-9f8a-be2ddf70de72,DISK], DatanodeInfoWithStorage[127.0.0.1:39450,DS-da5db81c-82ac-4ad1-b27e-acb1c6e83cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:33329,DS-b4651afd-a1fc-4b97-b1fa-02fe45c6056b,DISK], DatanodeInfoWithStorage[127.0.0.1:40307,DS-3ff606e0-e8ae-4a40-839f-246b0f0be377,DISK], DatanodeInfoWithStorage[127.0.0.1:43548,DS-ca1bcd2d-7cbe-4bd1-812e-a47381ee6645,DISK], DatanodeInfoWithStorage[127.0.0.1:38700,DS-c9a897aa-1945-4a47-9433-746eea3628ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44806,DS-a98ad898-3f58-4a64-a788-b535938b9ad8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2086245772-172.17.0.2-1595389575082:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34521,DS-1ae2fde1-aaf6-4516-94b0-05369a5f75e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40976,DS-da772cd3-e40e-4ca5-8cc1-fa18b9b3a8af,DISK], DatanodeInfoWithStorage[127.0.0.1:37751,DS-b7e9e53a-eb0a-499a-a361-ba545a50ac81,DISK], DatanodeInfoWithStorage[127.0.0.1:41710,DS-9894a507-db46-4bb9-999a-a83aa5f37060,DISK], DatanodeInfoWithStorage[127.0.0.1:34766,DS-b9c0fba5-8bb7-4ada-a3cc-05770a7c36c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34008,DS-8efc01fe-4860-42e5-be55-b99a4dce4db4,DISK], DatanodeInfoWithStorage[127.0.0.1:44553,DS-8d8cdded-b9cb-4aeb-ba4e-5327000223df,DISK], DatanodeInfoWithStorage[127.0.0.1:35591,DS-25ec6917-b978-41f4-9544-498abf83bdfe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2086245772-172.17.0.2-1595389575082:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34521,DS-1ae2fde1-aaf6-4516-94b0-05369a5f75e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40976,DS-da772cd3-e40e-4ca5-8cc1-fa18b9b3a8af,DISK], DatanodeInfoWithStorage[127.0.0.1:37751,DS-b7e9e53a-eb0a-499a-a361-ba545a50ac81,DISK], DatanodeInfoWithStorage[127.0.0.1:41710,DS-9894a507-db46-4bb9-999a-a83aa5f37060,DISK], DatanodeInfoWithStorage[127.0.0.1:34766,DS-b9c0fba5-8bb7-4ada-a3cc-05770a7c36c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34008,DS-8efc01fe-4860-42e5-be55-b99a4dce4db4,DISK], DatanodeInfoWithStorage[127.0.0.1:44553,DS-8d8cdded-b9cb-4aeb-ba4e-5327000223df,DISK], DatanodeInfoWithStorage[127.0.0.1:35591,DS-25ec6917-b978-41f4-9544-498abf83bdfe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-751623758-172.17.0.2-1595389650774:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35216,DS-5b3985d3-93f5-4933-a656-4cb197c535a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46719,DS-211788da-112e-494a-9001-c31e4b6f1195,DISK], DatanodeInfoWithStorage[127.0.0.1:42608,DS-eb2c0d0c-9938-4b01-841f-e0be848fda24,DISK], DatanodeInfoWithStorage[127.0.0.1:36389,DS-ba86088c-ca14-4384-84dd-d576d7acd3c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33527,DS-5c403845-8f5c-48e1-b844-c92793876aea,DISK], DatanodeInfoWithStorage[127.0.0.1:37813,DS-a85f58f3-79e4-44bb-a1d5-5dcde9cc7c3d,DISK], DatanodeInfoWithStorage[127.0.0.1:44539,DS-856aba92-61a0-45dc-a0be-adbd9d31571f,DISK], DatanodeInfoWithStorage[127.0.0.1:46503,DS-ab693813-7d70-4766-8199-63adcac31dbb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-751623758-172.17.0.2-1595389650774:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35216,DS-5b3985d3-93f5-4933-a656-4cb197c535a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46719,DS-211788da-112e-494a-9001-c31e4b6f1195,DISK], DatanodeInfoWithStorage[127.0.0.1:42608,DS-eb2c0d0c-9938-4b01-841f-e0be848fda24,DISK], DatanodeInfoWithStorage[127.0.0.1:36389,DS-ba86088c-ca14-4384-84dd-d576d7acd3c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33527,DS-5c403845-8f5c-48e1-b844-c92793876aea,DISK], DatanodeInfoWithStorage[127.0.0.1:37813,DS-a85f58f3-79e4-44bb-a1d5-5dcde9cc7c3d,DISK], DatanodeInfoWithStorage[127.0.0.1:44539,DS-856aba92-61a0-45dc-a0be-adbd9d31571f,DISK], DatanodeInfoWithStorage[127.0.0.1:46503,DS-ab693813-7d70-4766-8199-63adcac31dbb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2136251227-172.17.0.2-1595389899148:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44946,DS-c14af3c9-1691-427d-a926-e7f066c500c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38537,DS-c3d21600-1e1f-498d-9cbd-135af6fb451d,DISK], DatanodeInfoWithStorage[127.0.0.1:43757,DS-90f373df-4dea-4c97-952e-0039d45df1c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45463,DS-b96207bd-d9e2-4efd-b4ef-bd0f2b8b218a,DISK], DatanodeInfoWithStorage[127.0.0.1:37735,DS-5fd68bde-5304-47d5-9f1b-5e35dede423e,DISK], DatanodeInfoWithStorage[127.0.0.1:40112,DS-6000adc2-77a5-49e3-a8ba-b3803ae07c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:34635,DS-e785c31a-eae2-492a-b19b-4c96ff23de52,DISK], DatanodeInfoWithStorage[127.0.0.1:33927,DS-ddd0a785-9ab0-4379-9eea-3155081e5f71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2136251227-172.17.0.2-1595389899148:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44946,DS-c14af3c9-1691-427d-a926-e7f066c500c4,DISK], DatanodeInfoWithStorage[127.0.0.1:38537,DS-c3d21600-1e1f-498d-9cbd-135af6fb451d,DISK], DatanodeInfoWithStorage[127.0.0.1:43757,DS-90f373df-4dea-4c97-952e-0039d45df1c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45463,DS-b96207bd-d9e2-4efd-b4ef-bd0f2b8b218a,DISK], DatanodeInfoWithStorage[127.0.0.1:37735,DS-5fd68bde-5304-47d5-9f1b-5e35dede423e,DISK], DatanodeInfoWithStorage[127.0.0.1:40112,DS-6000adc2-77a5-49e3-a8ba-b3803ae07c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:34635,DS-e785c31a-eae2-492a-b19b-4c96ff23de52,DISK], DatanodeInfoWithStorage[127.0.0.1:33927,DS-ddd0a785-9ab0-4379-9eea-3155081e5f71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5168
