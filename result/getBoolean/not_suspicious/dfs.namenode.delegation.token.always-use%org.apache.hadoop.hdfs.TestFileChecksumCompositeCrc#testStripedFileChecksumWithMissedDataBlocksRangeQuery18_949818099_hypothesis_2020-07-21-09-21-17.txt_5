reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-346497091-172.17.0.20-1595323359047:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34273,DS-6100d1f1-9c73-40f0-9f2f-c7823d0cc162,DISK], DatanodeInfoWithStorage[127.0.0.1:43787,DS-d9217391-bc99-438a-9e8e-8be8ebe0d62d,DISK], DatanodeInfoWithStorage[127.0.0.1:38891,DS-d3fa5e9f-edc1-40a9-ade0-045f102a7e9c,DISK], DatanodeInfoWithStorage[127.0.0.1:46108,DS-675ca947-7ef4-49e3-81f7-6e6c6f507930,DISK], DatanodeInfoWithStorage[127.0.0.1:36485,DS-23439ff7-ca26-4de7-9630-af5694e321fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36658,DS-670903b2-88a3-474a-aee8-2fa3fada631f,DISK], DatanodeInfoWithStorage[127.0.0.1:35292,DS-8e27ff5b-323f-4692-8fc4-25b69f493865,DISK], DatanodeInfoWithStorage[127.0.0.1:37452,DS-63f5cbbe-430f-4cc1-9251-9b7ac1284635,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-346497091-172.17.0.20-1595323359047:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34273,DS-6100d1f1-9c73-40f0-9f2f-c7823d0cc162,DISK], DatanodeInfoWithStorage[127.0.0.1:43787,DS-d9217391-bc99-438a-9e8e-8be8ebe0d62d,DISK], DatanodeInfoWithStorage[127.0.0.1:38891,DS-d3fa5e9f-edc1-40a9-ade0-045f102a7e9c,DISK], DatanodeInfoWithStorage[127.0.0.1:46108,DS-675ca947-7ef4-49e3-81f7-6e6c6f507930,DISK], DatanodeInfoWithStorage[127.0.0.1:36485,DS-23439ff7-ca26-4de7-9630-af5694e321fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36658,DS-670903b2-88a3-474a-aee8-2fa3fada631f,DISK], DatanodeInfoWithStorage[127.0.0.1:35292,DS-8e27ff5b-323f-4692-8fc4-25b69f493865,DISK], DatanodeInfoWithStorage[127.0.0.1:37452,DS-63f5cbbe-430f-4cc1-9251-9b7ac1284635,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-365679780-172.17.0.20-1595323432741:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41881,DS-9d9e572b-23d8-46c0-9282-57cb087cabea,DISK], DatanodeInfoWithStorage[127.0.0.1:40536,DS-c87b9ede-f94e-49b4-a70d-d5793b268af2,DISK], DatanodeInfoWithStorage[127.0.0.1:36560,DS-e547a01b-ecc7-4f95-bf4d-26e23a5be67e,DISK], DatanodeInfoWithStorage[127.0.0.1:34437,DS-e7687f48-031c-4976-a878-d6ead3386f86,DISK], DatanodeInfoWithStorage[127.0.0.1:39945,DS-831de53f-a245-4e90-bba4-da19eb204c03,DISK], DatanodeInfoWithStorage[127.0.0.1:41746,DS-c7dc9061-7d22-421b-be19-9ca2479ff16f,DISK], DatanodeInfoWithStorage[127.0.0.1:37407,DS-387c91e5-196a-4580-a2c6-43eb197c2ccf,DISK], DatanodeInfoWithStorage[127.0.0.1:34364,DS-7cd0640b-318d-4719-b960-e4541f957cb2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-365679780-172.17.0.20-1595323432741:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41881,DS-9d9e572b-23d8-46c0-9282-57cb087cabea,DISK], DatanodeInfoWithStorage[127.0.0.1:40536,DS-c87b9ede-f94e-49b4-a70d-d5793b268af2,DISK], DatanodeInfoWithStorage[127.0.0.1:36560,DS-e547a01b-ecc7-4f95-bf4d-26e23a5be67e,DISK], DatanodeInfoWithStorage[127.0.0.1:34437,DS-e7687f48-031c-4976-a878-d6ead3386f86,DISK], DatanodeInfoWithStorage[127.0.0.1:39945,DS-831de53f-a245-4e90-bba4-da19eb204c03,DISK], DatanodeInfoWithStorage[127.0.0.1:41746,DS-c7dc9061-7d22-421b-be19-9ca2479ff16f,DISK], DatanodeInfoWithStorage[127.0.0.1:37407,DS-387c91e5-196a-4580-a2c6-43eb197c2ccf,DISK], DatanodeInfoWithStorage[127.0.0.1:34364,DS-7cd0640b-318d-4719-b960-e4541f957cb2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1009055567-172.17.0.20-1595323691817:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43300,DS-e5236b12-3b50-4470-b1c0-262a7954a887,DISK], DatanodeInfoWithStorage[127.0.0.1:36046,DS-db54c0f0-923d-4df7-a1f2-4dded8ca0c71,DISK], DatanodeInfoWithStorage[127.0.0.1:42835,DS-d0e8fd26-85bb-489a-9d59-586d44283d26,DISK], DatanodeInfoWithStorage[127.0.0.1:44142,DS-f65bddbf-83cd-4f81-b802-4378f605163b,DISK], DatanodeInfoWithStorage[127.0.0.1:38859,DS-eba33f5b-82c6-4214-ac8a-62ed7300d312,DISK], DatanodeInfoWithStorage[127.0.0.1:45584,DS-ab14a59c-1f88-4f9b-8eaf-0a4b3c20c800,DISK], DatanodeInfoWithStorage[127.0.0.1:46054,DS-fcdd5376-7c17-4cb5-8b32-56c8213e7729,DISK], DatanodeInfoWithStorage[127.0.0.1:35332,DS-bd96926b-6c5a-4638-b73a-dec67260792c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1009055567-172.17.0.20-1595323691817:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43300,DS-e5236b12-3b50-4470-b1c0-262a7954a887,DISK], DatanodeInfoWithStorage[127.0.0.1:36046,DS-db54c0f0-923d-4df7-a1f2-4dded8ca0c71,DISK], DatanodeInfoWithStorage[127.0.0.1:42835,DS-d0e8fd26-85bb-489a-9d59-586d44283d26,DISK], DatanodeInfoWithStorage[127.0.0.1:44142,DS-f65bddbf-83cd-4f81-b802-4378f605163b,DISK], DatanodeInfoWithStorage[127.0.0.1:38859,DS-eba33f5b-82c6-4214-ac8a-62ed7300d312,DISK], DatanodeInfoWithStorage[127.0.0.1:45584,DS-ab14a59c-1f88-4f9b-8eaf-0a4b3c20c800,DISK], DatanodeInfoWithStorage[127.0.0.1:46054,DS-fcdd5376-7c17-4cb5-8b32-56c8213e7729,DISK], DatanodeInfoWithStorage[127.0.0.1:35332,DS-bd96926b-6c5a-4638-b73a-dec67260792c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-534796796-172.17.0.20-1595324024804:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34321,DS-5f3f7f87-32d7-4692-9865-7627eebdf6d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39082,DS-8fdb97d3-fe74-42eb-a30b-c2eacc31a85a,DISK], DatanodeInfoWithStorage[127.0.0.1:41620,DS-cbecf3c1-9d8a-4493-a6d2-36cbf8c33445,DISK], DatanodeInfoWithStorage[127.0.0.1:45396,DS-6ab490a5-987a-4920-9813-17b0ff47b46d,DISK], DatanodeInfoWithStorage[127.0.0.1:36975,DS-4d5d5d71-6838-4af5-b73c-16ad4ba55523,DISK], DatanodeInfoWithStorage[127.0.0.1:32925,DS-b0e5ac58-88dd-464c-9cf6-00eae990bc3e,DISK], DatanodeInfoWithStorage[127.0.0.1:42067,DS-a8a044d5-3376-43ca-80dc-c23ed2b51d8b,DISK], DatanodeInfoWithStorage[127.0.0.1:42487,DS-4830cf3f-747c-4926-b318-97e76716a1cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-534796796-172.17.0.20-1595324024804:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34321,DS-5f3f7f87-32d7-4692-9865-7627eebdf6d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39082,DS-8fdb97d3-fe74-42eb-a30b-c2eacc31a85a,DISK], DatanodeInfoWithStorage[127.0.0.1:41620,DS-cbecf3c1-9d8a-4493-a6d2-36cbf8c33445,DISK], DatanodeInfoWithStorage[127.0.0.1:45396,DS-6ab490a5-987a-4920-9813-17b0ff47b46d,DISK], DatanodeInfoWithStorage[127.0.0.1:36975,DS-4d5d5d71-6838-4af5-b73c-16ad4ba55523,DISK], DatanodeInfoWithStorage[127.0.0.1:32925,DS-b0e5ac58-88dd-464c-9cf6-00eae990bc3e,DISK], DatanodeInfoWithStorage[127.0.0.1:42067,DS-a8a044d5-3376-43ca-80dc-c23ed2b51d8b,DISK], DatanodeInfoWithStorage[127.0.0.1:42487,DS-4830cf3f-747c-4926-b318-97e76716a1cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1728150818-172.17.0.20-1595324501527:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46020,DS-619077b4-123b-4e78-8a2b-00c902d8af83,DISK], DatanodeInfoWithStorage[127.0.0.1:39266,DS-ad5613e3-0644-4696-81c9-7e942a8ac2c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46602,DS-236ffeca-2cef-479e-8425-41e5ba77e830,DISK], DatanodeInfoWithStorage[127.0.0.1:36382,DS-5f459e89-9126-4667-b675-73912efc3127,DISK], DatanodeInfoWithStorage[127.0.0.1:43444,DS-cfa149c0-5c63-40b8-a79a-3f290666883a,DISK], DatanodeInfoWithStorage[127.0.0.1:33877,DS-b90ed21d-a71a-4fc2-8a6a-5abbc9e64ac5,DISK], DatanodeInfoWithStorage[127.0.0.1:38215,DS-60fc3d39-6727-4b51-be53-61bf9a128218,DISK], DatanodeInfoWithStorage[127.0.0.1:35424,DS-a7a0d0f6-6417-4cad-8ce7-bc307320944a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1728150818-172.17.0.20-1595324501527:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46020,DS-619077b4-123b-4e78-8a2b-00c902d8af83,DISK], DatanodeInfoWithStorage[127.0.0.1:39266,DS-ad5613e3-0644-4696-81c9-7e942a8ac2c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46602,DS-236ffeca-2cef-479e-8425-41e5ba77e830,DISK], DatanodeInfoWithStorage[127.0.0.1:36382,DS-5f459e89-9126-4667-b675-73912efc3127,DISK], DatanodeInfoWithStorage[127.0.0.1:43444,DS-cfa149c0-5c63-40b8-a79a-3f290666883a,DISK], DatanodeInfoWithStorage[127.0.0.1:33877,DS-b90ed21d-a71a-4fc2-8a6a-5abbc9e64ac5,DISK], DatanodeInfoWithStorage[127.0.0.1:38215,DS-60fc3d39-6727-4b51-be53-61bf9a128218,DISK], DatanodeInfoWithStorage[127.0.0.1:35424,DS-a7a0d0f6-6417-4cad-8ce7-bc307320944a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-372700646-172.17.0.20-1595324633162:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41809,DS-8c97d035-a254-4ad3-bd7a-8cd563e3f6a5,DISK], DatanodeInfoWithStorage[127.0.0.1:32996,DS-127c6f2f-42b5-4d01-a65d-7ad5f256950c,DISK], DatanodeInfoWithStorage[127.0.0.1:39299,DS-e9762e5f-72d1-4a99-a8fd-0c3b87a9bb55,DISK], DatanodeInfoWithStorage[127.0.0.1:44819,DS-1cdf2202-f6c4-4e2c-a786-af41ae15d5b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45004,DS-a233cb82-c836-4efe-8ad3-c09fbeaf0b41,DISK], DatanodeInfoWithStorage[127.0.0.1:38656,DS-1b3fa0eb-1293-415f-bbde-0f552cc82345,DISK], DatanodeInfoWithStorage[127.0.0.1:42734,DS-9ad12bdf-e0b9-4002-9be8-ea0c195d69c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43859,DS-f675aea4-9b2d-4977-8d3a-7cf4c1d6f7ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-372700646-172.17.0.20-1595324633162:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41809,DS-8c97d035-a254-4ad3-bd7a-8cd563e3f6a5,DISK], DatanodeInfoWithStorage[127.0.0.1:32996,DS-127c6f2f-42b5-4d01-a65d-7ad5f256950c,DISK], DatanodeInfoWithStorage[127.0.0.1:39299,DS-e9762e5f-72d1-4a99-a8fd-0c3b87a9bb55,DISK], DatanodeInfoWithStorage[127.0.0.1:44819,DS-1cdf2202-f6c4-4e2c-a786-af41ae15d5b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45004,DS-a233cb82-c836-4efe-8ad3-c09fbeaf0b41,DISK], DatanodeInfoWithStorage[127.0.0.1:38656,DS-1b3fa0eb-1293-415f-bbde-0f552cc82345,DISK], DatanodeInfoWithStorage[127.0.0.1:42734,DS-9ad12bdf-e0b9-4002-9be8-ea0c195d69c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43859,DS-f675aea4-9b2d-4977-8d3a-7cf4c1d6f7ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-580062622-172.17.0.20-1595324983980:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39226,DS-98d5a03b-0fde-4c29-91a7-5dc77032ac8b,DISK], DatanodeInfoWithStorage[127.0.0.1:34280,DS-6a9b034d-c45a-462c-bf1d-adae79777c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:39774,DS-930ea566-ff15-479a-914f-850de542273e,DISK], DatanodeInfoWithStorage[127.0.0.1:43500,DS-f5b9f9e0-52f3-4184-bc5c-6f0e6aab34f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39324,DS-e75c5459-4eeb-4285-b7cd-a84faec3cd04,DISK], DatanodeInfoWithStorage[127.0.0.1:37353,DS-4cd4ab53-8610-4141-b8c9-221f231d10f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40769,DS-b8a62d83-147c-4bba-9e2e-9659e3d7fee3,DISK], DatanodeInfoWithStorage[127.0.0.1:33001,DS-554c8777-4f5f-4475-ab55-de7b18407af5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-580062622-172.17.0.20-1595324983980:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39226,DS-98d5a03b-0fde-4c29-91a7-5dc77032ac8b,DISK], DatanodeInfoWithStorage[127.0.0.1:34280,DS-6a9b034d-c45a-462c-bf1d-adae79777c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:39774,DS-930ea566-ff15-479a-914f-850de542273e,DISK], DatanodeInfoWithStorage[127.0.0.1:43500,DS-f5b9f9e0-52f3-4184-bc5c-6f0e6aab34f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39324,DS-e75c5459-4eeb-4285-b7cd-a84faec3cd04,DISK], DatanodeInfoWithStorage[127.0.0.1:37353,DS-4cd4ab53-8610-4141-b8c9-221f231d10f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40769,DS-b8a62d83-147c-4bba-9e2e-9659e3d7fee3,DISK], DatanodeInfoWithStorage[127.0.0.1:33001,DS-554c8777-4f5f-4475-ab55-de7b18407af5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1896048262-172.17.0.20-1595325736613:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42133,DS-c0fe906b-29c8-428c-bd9f-1c910bca8177,DISK], DatanodeInfoWithStorage[127.0.0.1:40382,DS-f11f1f75-1ab8-417b-834e-abe9254ea8d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40312,DS-a5e8a4b6-e348-42fb-80de-dc5f8dc1ffab,DISK], DatanodeInfoWithStorage[127.0.0.1:37786,DS-110436dc-b104-456e-a351-dc4edbb2eedd,DISK], DatanodeInfoWithStorage[127.0.0.1:43654,DS-8052a655-924a-46f9-8dae-b9e1587893bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44818,DS-1743d6f4-7bdb-4afa-a3a8-12da8ea97b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:35450,DS-a586afce-7589-4f0a-8ae7-8276f05f3e54,DISK], DatanodeInfoWithStorage[127.0.0.1:43900,DS-01d0a04c-35af-4c95-ba01-3decdb57441f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1896048262-172.17.0.20-1595325736613:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42133,DS-c0fe906b-29c8-428c-bd9f-1c910bca8177,DISK], DatanodeInfoWithStorage[127.0.0.1:40382,DS-f11f1f75-1ab8-417b-834e-abe9254ea8d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40312,DS-a5e8a4b6-e348-42fb-80de-dc5f8dc1ffab,DISK], DatanodeInfoWithStorage[127.0.0.1:37786,DS-110436dc-b104-456e-a351-dc4edbb2eedd,DISK], DatanodeInfoWithStorage[127.0.0.1:43654,DS-8052a655-924a-46f9-8dae-b9e1587893bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44818,DS-1743d6f4-7bdb-4afa-a3a8-12da8ea97b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:35450,DS-a586afce-7589-4f0a-8ae7-8276f05f3e54,DISK], DatanodeInfoWithStorage[127.0.0.1:43900,DS-01d0a04c-35af-4c95-ba01-3decdb57441f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1072924557-172.17.0.20-1595325808800:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34527,DS-55f26959-a7e8-496d-a820-0bb7a5779b54,DISK], DatanodeInfoWithStorage[127.0.0.1:41135,DS-3e9a889e-b939-42de-82d5-6f78413e074a,DISK], DatanodeInfoWithStorage[127.0.0.1:37335,DS-6d581e5d-9631-41bf-81c6-30a0470f2ccc,DISK], DatanodeInfoWithStorage[127.0.0.1:34294,DS-dd9100dc-2b20-4802-95f8-a3edb9eee22d,DISK], DatanodeInfoWithStorage[127.0.0.1:37353,DS-1d426218-133a-4712-855f-9a906a8bf4d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34100,DS-6da5b454-d9a5-4315-bd78-01d50cc4baeb,DISK], DatanodeInfoWithStorage[127.0.0.1:43930,DS-e19169da-b35d-4302-b7bc-530e60b0a89d,DISK], DatanodeInfoWithStorage[127.0.0.1:43453,DS-630b32b4-444e-444f-923b-8316ca2eb50d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1072924557-172.17.0.20-1595325808800:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34527,DS-55f26959-a7e8-496d-a820-0bb7a5779b54,DISK], DatanodeInfoWithStorage[127.0.0.1:41135,DS-3e9a889e-b939-42de-82d5-6f78413e074a,DISK], DatanodeInfoWithStorage[127.0.0.1:37335,DS-6d581e5d-9631-41bf-81c6-30a0470f2ccc,DISK], DatanodeInfoWithStorage[127.0.0.1:34294,DS-dd9100dc-2b20-4802-95f8-a3edb9eee22d,DISK], DatanodeInfoWithStorage[127.0.0.1:37353,DS-1d426218-133a-4712-855f-9a906a8bf4d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34100,DS-6da5b454-d9a5-4315-bd78-01d50cc4baeb,DISK], DatanodeInfoWithStorage[127.0.0.1:43930,DS-e19169da-b35d-4302-b7bc-530e60b0a89d,DISK], DatanodeInfoWithStorage[127.0.0.1:43453,DS-630b32b4-444e-444f-923b-8316ca2eb50d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1240282413-172.17.0.20-1595326240129:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38315,DS-fea789f5-c84b-4587-9cbb-b885430191d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41539,DS-eb3346ca-79de-408d-a1f1-925890cd0c4b,DISK], DatanodeInfoWithStorage[127.0.0.1:38656,DS-7024bf57-a1f5-4058-8f69-e58ba4b92055,DISK], DatanodeInfoWithStorage[127.0.0.1:35616,DS-e50d78b0-f45c-4ccf-8bb9-8954988d5801,DISK], DatanodeInfoWithStorage[127.0.0.1:44367,DS-23cc1b44-44cb-4f1e-82cb-bc3419ef4afa,DISK], DatanodeInfoWithStorage[127.0.0.1:35567,DS-65654dd8-709f-4ea4-8600-2fa43aa9a559,DISK], DatanodeInfoWithStorage[127.0.0.1:34012,DS-59c722c7-4a3f-4ff8-84bf-7b4ab35cc524,DISK], DatanodeInfoWithStorage[127.0.0.1:39501,DS-896fc70b-9caa-4882-adee-0c0ee0d9c81e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1240282413-172.17.0.20-1595326240129:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38315,DS-fea789f5-c84b-4587-9cbb-b885430191d5,DISK], DatanodeInfoWithStorage[127.0.0.1:41539,DS-eb3346ca-79de-408d-a1f1-925890cd0c4b,DISK], DatanodeInfoWithStorage[127.0.0.1:38656,DS-7024bf57-a1f5-4058-8f69-e58ba4b92055,DISK], DatanodeInfoWithStorage[127.0.0.1:35616,DS-e50d78b0-f45c-4ccf-8bb9-8954988d5801,DISK], DatanodeInfoWithStorage[127.0.0.1:44367,DS-23cc1b44-44cb-4f1e-82cb-bc3419ef4afa,DISK], DatanodeInfoWithStorage[127.0.0.1:35567,DS-65654dd8-709f-4ea4-8600-2fa43aa9a559,DISK], DatanodeInfoWithStorage[127.0.0.1:34012,DS-59c722c7-4a3f-4ff8-84bf-7b4ab35cc524,DISK], DatanodeInfoWithStorage[127.0.0.1:39501,DS-896fc70b-9caa-4882-adee-0c0ee0d9c81e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1057092832-172.17.0.20-1595326345180:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38937,DS-890d4b11-9a45-43ef-9eeb-f9f95a5f8d82,DISK], DatanodeInfoWithStorage[127.0.0.1:40773,DS-be778b23-bc9d-492b-93fd-8212a3f2ca42,DISK], DatanodeInfoWithStorage[127.0.0.1:34775,DS-e0a85c81-bf15-4acd-89d2-181d8efcbe31,DISK], DatanodeInfoWithStorage[127.0.0.1:41969,DS-542b10f2-0235-4945-8d5e-d387af3eb761,DISK], DatanodeInfoWithStorage[127.0.0.1:43271,DS-c3525e92-00f4-46ca-a9dc-2612dc2e70f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37781,DS-144946c9-65a7-48f1-ac33-e750eb4a613c,DISK], DatanodeInfoWithStorage[127.0.0.1:38574,DS-9b718387-b7c9-4c49-9218-c00e60389da3,DISK], DatanodeInfoWithStorage[127.0.0.1:32940,DS-c610413f-1bfd-45a5-b2c9-bf9233ea0350,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1057092832-172.17.0.20-1595326345180:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38937,DS-890d4b11-9a45-43ef-9eeb-f9f95a5f8d82,DISK], DatanodeInfoWithStorage[127.0.0.1:40773,DS-be778b23-bc9d-492b-93fd-8212a3f2ca42,DISK], DatanodeInfoWithStorage[127.0.0.1:34775,DS-e0a85c81-bf15-4acd-89d2-181d8efcbe31,DISK], DatanodeInfoWithStorage[127.0.0.1:41969,DS-542b10f2-0235-4945-8d5e-d387af3eb761,DISK], DatanodeInfoWithStorage[127.0.0.1:43271,DS-c3525e92-00f4-46ca-a9dc-2612dc2e70f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37781,DS-144946c9-65a7-48f1-ac33-e750eb4a613c,DISK], DatanodeInfoWithStorage[127.0.0.1:38574,DS-9b718387-b7c9-4c49-9218-c00e60389da3,DISK], DatanodeInfoWithStorage[127.0.0.1:32940,DS-c610413f-1bfd-45a5-b2c9-bf9233ea0350,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1306152333-172.17.0.20-1595326381737:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39671,DS-6af0a4b9-3de5-479b-a99b-cd57431418e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33183,DS-9edc2f51-0c07-4890-9430-225f81c48e63,DISK], DatanodeInfoWithStorage[127.0.0.1:38445,DS-6d04df4b-cd28-4414-8eb7-0adfddab26d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46459,DS-59ee2fe9-6fb3-4ccb-9385-0ad5b17fdfa8,DISK], DatanodeInfoWithStorage[127.0.0.1:33315,DS-20e61be5-ffe3-4b88-a809-90fdd4df62cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38055,DS-dfb811cb-9bdc-486f-aa95-1d15eb6aa8e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42904,DS-e80ec8b7-6d84-44ac-822c-d2df5bb0715a,DISK], DatanodeInfoWithStorage[127.0.0.1:32782,DS-b591678c-afb4-4bef-92f4-e4ff714aed38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1306152333-172.17.0.20-1595326381737:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39671,DS-6af0a4b9-3de5-479b-a99b-cd57431418e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33183,DS-9edc2f51-0c07-4890-9430-225f81c48e63,DISK], DatanodeInfoWithStorage[127.0.0.1:38445,DS-6d04df4b-cd28-4414-8eb7-0adfddab26d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46459,DS-59ee2fe9-6fb3-4ccb-9385-0ad5b17fdfa8,DISK], DatanodeInfoWithStorage[127.0.0.1:33315,DS-20e61be5-ffe3-4b88-a809-90fdd4df62cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38055,DS-dfb811cb-9bdc-486f-aa95-1d15eb6aa8e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42904,DS-e80ec8b7-6d84-44ac-822c-d2df5bb0715a,DISK], DatanodeInfoWithStorage[127.0.0.1:32782,DS-b591678c-afb4-4bef-92f4-e4ff714aed38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2039801959-172.17.0.20-1595326567612:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42025,DS-ffa29a34-eba1-40d7-8805-71eb4133d5e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42984,DS-1b0ca065-7de0-4910-8751-6bf07b6160eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39555,DS-97d16bd4-7d7b-4151-8ee3-4171760ccef3,DISK], DatanodeInfoWithStorage[127.0.0.1:34512,DS-a6fc7bf1-6111-47d6-aaa8-29c60ee0e5d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46194,DS-93881d49-726b-4931-b0f5-2a5ddf57a4ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40884,DS-856bd880-c859-4ac7-87b1-2fa4b971a628,DISK], DatanodeInfoWithStorage[127.0.0.1:44511,DS-6ae6db6c-9f70-4c1d-b3bb-7a8e854bcec7,DISK], DatanodeInfoWithStorage[127.0.0.1:39841,DS-c8aab28e-afd7-4a54-8d01-01ed4237c1a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2039801959-172.17.0.20-1595326567612:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42025,DS-ffa29a34-eba1-40d7-8805-71eb4133d5e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42984,DS-1b0ca065-7de0-4910-8751-6bf07b6160eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39555,DS-97d16bd4-7d7b-4151-8ee3-4171760ccef3,DISK], DatanodeInfoWithStorage[127.0.0.1:34512,DS-a6fc7bf1-6111-47d6-aaa8-29c60ee0e5d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46194,DS-93881d49-726b-4931-b0f5-2a5ddf57a4ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40884,DS-856bd880-c859-4ac7-87b1-2fa4b971a628,DISK], DatanodeInfoWithStorage[127.0.0.1:44511,DS-6ae6db6c-9f70-4c1d-b3bb-7a8e854bcec7,DISK], DatanodeInfoWithStorage[127.0.0.1:39841,DS-c8aab28e-afd7-4a54-8d01-01ed4237c1a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1543004398-172.17.0.20-1595326803252:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38617,DS-57e7173e-d92e-4e08-adc9-f02029849dab,DISK], DatanodeInfoWithStorage[127.0.0.1:39923,DS-00811a04-af38-4a91-9e23-4a21260731b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33133,DS-36b928cd-ecf9-42dc-9116-0226f6229e02,DISK], DatanodeInfoWithStorage[127.0.0.1:35292,DS-533cd137-7f8d-46ce-9cf9-4fc5d01fd630,DISK], DatanodeInfoWithStorage[127.0.0.1:34638,DS-2d9bda5e-12ed-47d2-9790-1f2fd33079f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41738,DS-eb1efbdd-db6b-4855-8a0e-b0c287b84ec2,DISK], DatanodeInfoWithStorage[127.0.0.1:38796,DS-d9eb75ba-74e5-4440-8776-d4fa85e8c773,DISK], DatanodeInfoWithStorage[127.0.0.1:43070,DS-fa075dca-9ead-473b-90ab-9c7ed1bd9d34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1543004398-172.17.0.20-1595326803252:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38617,DS-57e7173e-d92e-4e08-adc9-f02029849dab,DISK], DatanodeInfoWithStorage[127.0.0.1:39923,DS-00811a04-af38-4a91-9e23-4a21260731b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33133,DS-36b928cd-ecf9-42dc-9116-0226f6229e02,DISK], DatanodeInfoWithStorage[127.0.0.1:35292,DS-533cd137-7f8d-46ce-9cf9-4fc5d01fd630,DISK], DatanodeInfoWithStorage[127.0.0.1:34638,DS-2d9bda5e-12ed-47d2-9790-1f2fd33079f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41738,DS-eb1efbdd-db6b-4855-8a0e-b0c287b84ec2,DISK], DatanodeInfoWithStorage[127.0.0.1:38796,DS-d9eb75ba-74e5-4440-8776-d4fa85e8c773,DISK], DatanodeInfoWithStorage[127.0.0.1:43070,DS-fa075dca-9ead-473b-90ab-9c7ed1bd9d34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1012045780-172.17.0.20-1595326994582:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40506,DS-eaed25c6-17db-417d-bbca-f8972d1e2baa,DISK], DatanodeInfoWithStorage[127.0.0.1:40064,DS-f7e3f5a3-c4ba-4738-935f-fbfcccea7e94,DISK], DatanodeInfoWithStorage[127.0.0.1:43889,DS-5ef79a22-1755-42f0-b4ea-7953276ed011,DISK], DatanodeInfoWithStorage[127.0.0.1:38982,DS-829695be-8a8d-47ae-b03c-4e77bd49bca7,DISK], DatanodeInfoWithStorage[127.0.0.1:43129,DS-7c47bf6e-5358-4cda-abb1-a24cad2ddbb6,DISK], DatanodeInfoWithStorage[127.0.0.1:40071,DS-93eaa245-bee6-494e-8762-5a843ffce2ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45885,DS-59aabd4e-4369-434f-ac55-6edec40d3390,DISK], DatanodeInfoWithStorage[127.0.0.1:33202,DS-2177c60f-86cf-477d-b8dd-779f5e942f31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1012045780-172.17.0.20-1595326994582:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40506,DS-eaed25c6-17db-417d-bbca-f8972d1e2baa,DISK], DatanodeInfoWithStorage[127.0.0.1:40064,DS-f7e3f5a3-c4ba-4738-935f-fbfcccea7e94,DISK], DatanodeInfoWithStorage[127.0.0.1:43889,DS-5ef79a22-1755-42f0-b4ea-7953276ed011,DISK], DatanodeInfoWithStorage[127.0.0.1:38982,DS-829695be-8a8d-47ae-b03c-4e77bd49bca7,DISK], DatanodeInfoWithStorage[127.0.0.1:43129,DS-7c47bf6e-5358-4cda-abb1-a24cad2ddbb6,DISK], DatanodeInfoWithStorage[127.0.0.1:40071,DS-93eaa245-bee6-494e-8762-5a843ffce2ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45885,DS-59aabd4e-4369-434f-ac55-6edec40d3390,DISK], DatanodeInfoWithStorage[127.0.0.1:33202,DS-2177c60f-86cf-477d-b8dd-779f5e942f31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1009310228-172.17.0.20-1595327032871:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38399,DS-e5889ce2-4559-4a45-bdd4-3d4488eadc56,DISK], DatanodeInfoWithStorage[127.0.0.1:42007,DS-3cee7e79-470e-47ca-9ea6-68bfc2549ef3,DISK], DatanodeInfoWithStorage[127.0.0.1:44759,DS-78e286cb-4fed-4cc0-bdb2-f97fb4555781,DISK], DatanodeInfoWithStorage[127.0.0.1:36304,DS-9b3f0681-f541-478d-8093-d728e8d627dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39860,DS-3ae1328f-0a7c-460f-a22b-950f58e2d59e,DISK], DatanodeInfoWithStorage[127.0.0.1:34785,DS-7744882d-5103-40cb-b369-f7fa73b5394b,DISK], DatanodeInfoWithStorage[127.0.0.1:46549,DS-9a4a4cde-1742-4a90-b5dc-dcf8446e9975,DISK], DatanodeInfoWithStorage[127.0.0.1:43120,DS-2fe54d4f-38b6-489d-86ab-ee4ab37df9ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1009310228-172.17.0.20-1595327032871:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38399,DS-e5889ce2-4559-4a45-bdd4-3d4488eadc56,DISK], DatanodeInfoWithStorage[127.0.0.1:42007,DS-3cee7e79-470e-47ca-9ea6-68bfc2549ef3,DISK], DatanodeInfoWithStorage[127.0.0.1:44759,DS-78e286cb-4fed-4cc0-bdb2-f97fb4555781,DISK], DatanodeInfoWithStorage[127.0.0.1:36304,DS-9b3f0681-f541-478d-8093-d728e8d627dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39860,DS-3ae1328f-0a7c-460f-a22b-950f58e2d59e,DISK], DatanodeInfoWithStorage[127.0.0.1:34785,DS-7744882d-5103-40cb-b369-f7fa73b5394b,DISK], DatanodeInfoWithStorage[127.0.0.1:46549,DS-9a4a4cde-1742-4a90-b5dc-dcf8446e9975,DISK], DatanodeInfoWithStorage[127.0.0.1:43120,DS-2fe54d4f-38b6-489d-86ab-ee4ab37df9ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1739296462-172.17.0.20-1595327111351:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38960,DS-786e27f4-cad6-4d7c-8edd-333a422e64fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34214,DS-fd343825-db17-431d-9fec-f5b51a60c826,DISK], DatanodeInfoWithStorage[127.0.0.1:46370,DS-e2ab71d4-ffa2-4860-8dbb-96b88df66a2a,DISK], DatanodeInfoWithStorage[127.0.0.1:33354,DS-a7742e78-2520-494c-9a59-186f13363366,DISK], DatanodeInfoWithStorage[127.0.0.1:36277,DS-c6a3df58-4c80-49ff-a31a-842509f68c52,DISK], DatanodeInfoWithStorage[127.0.0.1:36161,DS-628c3f27-82ec-44af-9b88-8903af0e037a,DISK], DatanodeInfoWithStorage[127.0.0.1:38817,DS-2bd3866f-2267-4e24-8dc7-dc726fd01900,DISK], DatanodeInfoWithStorage[127.0.0.1:34957,DS-f4df3000-5329-448c-8ba9-29f9ab58aa94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1739296462-172.17.0.20-1595327111351:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38960,DS-786e27f4-cad6-4d7c-8edd-333a422e64fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34214,DS-fd343825-db17-431d-9fec-f5b51a60c826,DISK], DatanodeInfoWithStorage[127.0.0.1:46370,DS-e2ab71d4-ffa2-4860-8dbb-96b88df66a2a,DISK], DatanodeInfoWithStorage[127.0.0.1:33354,DS-a7742e78-2520-494c-9a59-186f13363366,DISK], DatanodeInfoWithStorage[127.0.0.1:36277,DS-c6a3df58-4c80-49ff-a31a-842509f68c52,DISK], DatanodeInfoWithStorage[127.0.0.1:36161,DS-628c3f27-82ec-44af-9b88-8903af0e037a,DISK], DatanodeInfoWithStorage[127.0.0.1:38817,DS-2bd3866f-2267-4e24-8dc7-dc726fd01900,DISK], DatanodeInfoWithStorage[127.0.0.1:34957,DS-f4df3000-5329-448c-8ba9-29f9ab58aa94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-764785694-172.17.0.20-1595327292558:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37949,DS-c564b94e-81f5-4bb9-a989-b3d4718bbfa4,DISK], DatanodeInfoWithStorage[127.0.0.1:38806,DS-7a151c42-c27a-4b43-9c5c-4c3bcba86d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:42330,DS-e15bbc49-638a-4b81-8d2a-602ea86006c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42114,DS-570b3e4d-7809-479a-8348-9f21fac8bc43,DISK], DatanodeInfoWithStorage[127.0.0.1:46186,DS-6cecd846-5c92-41fd-b702-0314afece3af,DISK], DatanodeInfoWithStorage[127.0.0.1:42259,DS-d5f1cdf0-de6d-4a5f-a79f-dbfcbbf4d8bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39013,DS-b5779737-b3f9-4c3d-b85a-c3105acc3f56,DISK], DatanodeInfoWithStorage[127.0.0.1:42567,DS-f66c8403-3970-4cd8-9c5a-23aecc0371b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-764785694-172.17.0.20-1595327292558:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37949,DS-c564b94e-81f5-4bb9-a989-b3d4718bbfa4,DISK], DatanodeInfoWithStorage[127.0.0.1:38806,DS-7a151c42-c27a-4b43-9c5c-4c3bcba86d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:42330,DS-e15bbc49-638a-4b81-8d2a-602ea86006c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42114,DS-570b3e4d-7809-479a-8348-9f21fac8bc43,DISK], DatanodeInfoWithStorage[127.0.0.1:46186,DS-6cecd846-5c92-41fd-b702-0314afece3af,DISK], DatanodeInfoWithStorage[127.0.0.1:42259,DS-d5f1cdf0-de6d-4a5f-a79f-dbfcbbf4d8bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39013,DS-b5779737-b3f9-4c3d-b85a-c3105acc3f56,DISK], DatanodeInfoWithStorage[127.0.0.1:42567,DS-f66c8403-3970-4cd8-9c5a-23aecc0371b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1627530377-172.17.0.20-1595327601041:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38213,DS-61eac3a5-0f21-4d2b-be20-dae39d6def2c,DISK], DatanodeInfoWithStorage[127.0.0.1:44507,DS-c2d1d5fa-96b9-4144-9869-dac4b438cf8f,DISK], DatanodeInfoWithStorage[127.0.0.1:40675,DS-38b4fb88-a05e-4c13-ac6e-51dbb10f949d,DISK], DatanodeInfoWithStorage[127.0.0.1:39537,DS-6c3cc23e-8a1e-4a04-97b4-c073fc724f7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36574,DS-c066ebb2-1782-48b9-a0d7-fc453d275d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:39570,DS-f18167af-0891-48e5-8e29-4e4a423e4ebe,DISK], DatanodeInfoWithStorage[127.0.0.1:44914,DS-d7dc83ac-4f89-4cb3-a2c1-dff851a6aa27,DISK], DatanodeInfoWithStorage[127.0.0.1:39075,DS-1e3ef7f8-8c05-4cba-9f62-57c8ce8333ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1627530377-172.17.0.20-1595327601041:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38213,DS-61eac3a5-0f21-4d2b-be20-dae39d6def2c,DISK], DatanodeInfoWithStorage[127.0.0.1:44507,DS-c2d1d5fa-96b9-4144-9869-dac4b438cf8f,DISK], DatanodeInfoWithStorage[127.0.0.1:40675,DS-38b4fb88-a05e-4c13-ac6e-51dbb10f949d,DISK], DatanodeInfoWithStorage[127.0.0.1:39537,DS-6c3cc23e-8a1e-4a04-97b4-c073fc724f7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36574,DS-c066ebb2-1782-48b9-a0d7-fc453d275d4e,DISK], DatanodeInfoWithStorage[127.0.0.1:39570,DS-f18167af-0891-48e5-8e29-4e4a423e4ebe,DISK], DatanodeInfoWithStorage[127.0.0.1:44914,DS-d7dc83ac-4f89-4cb3-a2c1-dff851a6aa27,DISK], DatanodeInfoWithStorage[127.0.0.1:39075,DS-1e3ef7f8-8c05-4cba-9f62-57c8ce8333ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-506761270-172.17.0.20-1595328014655:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39717,DS-a83167a8-6b10-4d4e-bc5c-6cb5a7fe18ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42669,DS-9c1dd93e-155a-4e15-a943-a3b0254a1712,DISK], DatanodeInfoWithStorage[127.0.0.1:42357,DS-0ab424a5-03cb-4469-8b12-a21827b5f424,DISK], DatanodeInfoWithStorage[127.0.0.1:42859,DS-5b077603-a0b2-4c02-942e-e09cd67cadb9,DISK], DatanodeInfoWithStorage[127.0.0.1:44586,DS-a3d0c88d-136c-4b6d-b9b2-3f57021fcf56,DISK], DatanodeInfoWithStorage[127.0.0.1:39813,DS-f73f1b2e-904a-430f-9e88-55bd54ab070f,DISK], DatanodeInfoWithStorage[127.0.0.1:44752,DS-810d95fb-c0ec-4399-8461-08bb9434f067,DISK], DatanodeInfoWithStorage[127.0.0.1:42612,DS-f4493951-65db-465c-8527-1325dfcd61ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-506761270-172.17.0.20-1595328014655:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39717,DS-a83167a8-6b10-4d4e-bc5c-6cb5a7fe18ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42669,DS-9c1dd93e-155a-4e15-a943-a3b0254a1712,DISK], DatanodeInfoWithStorage[127.0.0.1:42357,DS-0ab424a5-03cb-4469-8b12-a21827b5f424,DISK], DatanodeInfoWithStorage[127.0.0.1:42859,DS-5b077603-a0b2-4c02-942e-e09cd67cadb9,DISK], DatanodeInfoWithStorage[127.0.0.1:44586,DS-a3d0c88d-136c-4b6d-b9b2-3f57021fcf56,DISK], DatanodeInfoWithStorage[127.0.0.1:39813,DS-f73f1b2e-904a-430f-9e88-55bd54ab070f,DISK], DatanodeInfoWithStorage[127.0.0.1:44752,DS-810d95fb-c0ec-4399-8461-08bb9434f067,DISK], DatanodeInfoWithStorage[127.0.0.1:42612,DS-f4493951-65db-465c-8527-1325dfcd61ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-306449784-172.17.0.20-1595328236094:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37318,DS-1d7136eb-877a-4089-8787-bf90271d4dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:44362,DS-0f6ecbc2-fe9d-49c0-a620-dd20fbe829d2,DISK], DatanodeInfoWithStorage[127.0.0.1:37049,DS-1aabe19e-6659-47dd-83e6-7d7251a28a88,DISK], DatanodeInfoWithStorage[127.0.0.1:37519,DS-561c0d9b-06bd-43de-a526-95ef26d1c175,DISK], DatanodeInfoWithStorage[127.0.0.1:45902,DS-66e42bb2-9724-4447-a9d3-ed8e74bcae1d,DISK], DatanodeInfoWithStorage[127.0.0.1:33011,DS-d4fe6761-0203-4a34-b161-b4c8d9e8cca4,DISK], DatanodeInfoWithStorage[127.0.0.1:36066,DS-fb407daf-5c80-4c3d-9cd4-cabc11024eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:36329,DS-b2811438-eab9-4c9a-a609-afc822329c87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-306449784-172.17.0.20-1595328236094:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37318,DS-1d7136eb-877a-4089-8787-bf90271d4dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:44362,DS-0f6ecbc2-fe9d-49c0-a620-dd20fbe829d2,DISK], DatanodeInfoWithStorage[127.0.0.1:37049,DS-1aabe19e-6659-47dd-83e6-7d7251a28a88,DISK], DatanodeInfoWithStorage[127.0.0.1:37519,DS-561c0d9b-06bd-43de-a526-95ef26d1c175,DISK], DatanodeInfoWithStorage[127.0.0.1:45902,DS-66e42bb2-9724-4447-a9d3-ed8e74bcae1d,DISK], DatanodeInfoWithStorage[127.0.0.1:33011,DS-d4fe6761-0203-4a34-b161-b4c8d9e8cca4,DISK], DatanodeInfoWithStorage[127.0.0.1:36066,DS-fb407daf-5c80-4c3d-9cd4-cabc11024eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:36329,DS-b2811438-eab9-4c9a-a609-afc822329c87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1589585389-172.17.0.20-1595328280882:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37106,DS-8825459d-007c-49b2-af40-e6b3fcdcad7c,DISK], DatanodeInfoWithStorage[127.0.0.1:34219,DS-2b3b8317-1ed1-44ab-bb5f-d10ab4c80cc9,DISK], DatanodeInfoWithStorage[127.0.0.1:45802,DS-18392b01-a9c1-4116-a9dc-82cbd5134e00,DISK], DatanodeInfoWithStorage[127.0.0.1:41832,DS-2cc39c7a-b982-4a85-a337-b9acb8d9e42e,DISK], DatanodeInfoWithStorage[127.0.0.1:41380,DS-7e73cf0b-fc85-4aa0-b3c2-4323b657c592,DISK], DatanodeInfoWithStorage[127.0.0.1:42672,DS-cc5f1a5c-c7f8-451e-bd6a-5f264a1c41c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33450,DS-6c721050-54bd-4166-a844-4459e823f714,DISK], DatanodeInfoWithStorage[127.0.0.1:42949,DS-2ebc8a2f-561d-4cbc-9dda-d992b0b1058a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1589585389-172.17.0.20-1595328280882:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37106,DS-8825459d-007c-49b2-af40-e6b3fcdcad7c,DISK], DatanodeInfoWithStorage[127.0.0.1:34219,DS-2b3b8317-1ed1-44ab-bb5f-d10ab4c80cc9,DISK], DatanodeInfoWithStorage[127.0.0.1:45802,DS-18392b01-a9c1-4116-a9dc-82cbd5134e00,DISK], DatanodeInfoWithStorage[127.0.0.1:41832,DS-2cc39c7a-b982-4a85-a337-b9acb8d9e42e,DISK], DatanodeInfoWithStorage[127.0.0.1:41380,DS-7e73cf0b-fc85-4aa0-b3c2-4323b657c592,DISK], DatanodeInfoWithStorage[127.0.0.1:42672,DS-cc5f1a5c-c7f8-451e-bd6a-5f264a1c41c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33450,DS-6c721050-54bd-4166-a844-4459e823f714,DISK], DatanodeInfoWithStorage[127.0.0.1:42949,DS-2ebc8a2f-561d-4cbc-9dda-d992b0b1058a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.delegation.token.always-use
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-970255119-172.17.0.20-1595328575374:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39028,DS-6f7d6d70-d4cb-406a-bf7a-9449272e0071,DISK], DatanodeInfoWithStorage[127.0.0.1:38745,DS-8f34a50f-5164-470e-ba79-d80c6829302e,DISK], DatanodeInfoWithStorage[127.0.0.1:38932,DS-e8618d04-618e-468a-8509-3827668c170b,DISK], DatanodeInfoWithStorage[127.0.0.1:44715,DS-1721b374-22db-41e8-b61a-2b769a94317d,DISK], DatanodeInfoWithStorage[127.0.0.1:46714,DS-15e0589e-52ba-4754-88e7-6d1842950720,DISK], DatanodeInfoWithStorage[127.0.0.1:37670,DS-0b2ab185-e1eb-4e45-8fb4-1eccfc14055e,DISK], DatanodeInfoWithStorage[127.0.0.1:36325,DS-ceeca175-242f-4cf9-a4df-56d9118d0778,DISK], DatanodeInfoWithStorage[127.0.0.1:41985,DS-229bcc67-c1ca-461d-881c-aefce08aeb51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-970255119-172.17.0.20-1595328575374:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39028,DS-6f7d6d70-d4cb-406a-bf7a-9449272e0071,DISK], DatanodeInfoWithStorage[127.0.0.1:38745,DS-8f34a50f-5164-470e-ba79-d80c6829302e,DISK], DatanodeInfoWithStorage[127.0.0.1:38932,DS-e8618d04-618e-468a-8509-3827668c170b,DISK], DatanodeInfoWithStorage[127.0.0.1:44715,DS-1721b374-22db-41e8-b61a-2b769a94317d,DISK], DatanodeInfoWithStorage[127.0.0.1:46714,DS-15e0589e-52ba-4754-88e7-6d1842950720,DISK], DatanodeInfoWithStorage[127.0.0.1:37670,DS-0b2ab185-e1eb-4e45-8fb4-1eccfc14055e,DISK], DatanodeInfoWithStorage[127.0.0.1:36325,DS-ceeca175-242f-4cf9-a4df-56d9118d0778,DISK], DatanodeInfoWithStorage[127.0.0.1:41985,DS-229bcc67-c1ca-461d-881c-aefce08aeb51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 5391
