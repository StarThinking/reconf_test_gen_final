reconf_parameter: dfs.namenode.name.dir.restore
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.name.dir.restore
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-156397674-172.17.0.2-1595356200839:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32990,DS-4c8ad5af-dc43-4961-9be3-0134c060108f,DISK], DatanodeInfoWithStorage[127.0.0.1:44641,DS-e8dc631e-2830-4d89-93ba-0ac09cf839cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43279,DS-3003dd47-48f2-44cd-addf-7974cd033cff,DISK], DatanodeInfoWithStorage[127.0.0.1:34148,DS-0ef3de6b-9534-4719-8d8b-52397fbbeba1,DISK], DatanodeInfoWithStorage[127.0.0.1:40953,DS-3461892f-8345-4425-a8cc-837feacb654c,DISK], DatanodeInfoWithStorage[127.0.0.1:43941,DS-d1337ffc-4726-457a-893d-84b0af90d72b,DISK], DatanodeInfoWithStorage[127.0.0.1:44924,DS-e2b2d593-4137-42a1-acc6-6004c1f09d43,DISK], DatanodeInfoWithStorage[127.0.0.1:44354,DS-d36d7605-67f8-4357-9eae-c9c6e4c88a05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-156397674-172.17.0.2-1595356200839:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32990,DS-4c8ad5af-dc43-4961-9be3-0134c060108f,DISK], DatanodeInfoWithStorage[127.0.0.1:44641,DS-e8dc631e-2830-4d89-93ba-0ac09cf839cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43279,DS-3003dd47-48f2-44cd-addf-7974cd033cff,DISK], DatanodeInfoWithStorage[127.0.0.1:34148,DS-0ef3de6b-9534-4719-8d8b-52397fbbeba1,DISK], DatanodeInfoWithStorage[127.0.0.1:40953,DS-3461892f-8345-4425-a8cc-837feacb654c,DISK], DatanodeInfoWithStorage[127.0.0.1:43941,DS-d1337ffc-4726-457a-893d-84b0af90d72b,DISK], DatanodeInfoWithStorage[127.0.0.1:44924,DS-e2b2d593-4137-42a1-acc6-6004c1f09d43,DISK], DatanodeInfoWithStorage[127.0.0.1:44354,DS-d36d7605-67f8-4357-9eae-c9c6e4c88a05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.name.dir.restore
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1975774636-172.17.0.2-1595356434627:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46113,DS-60aed540-7318-48e1-b812-76ba546fac3e,DISK], DatanodeInfoWithStorage[127.0.0.1:38352,DS-af0a7c78-5db1-4528-8cd5-150c7f4c7fb3,DISK], DatanodeInfoWithStorage[127.0.0.1:42429,DS-937a2047-c840-455d-85b4-afb6ece2d3b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41103,DS-67b76db0-577b-4966-b7d3-3df29c7c9623,DISK], DatanodeInfoWithStorage[127.0.0.1:41050,DS-94ad7b8e-0552-4249-ac57-fd152afe4394,DISK], DatanodeInfoWithStorage[127.0.0.1:41667,DS-726d00a4-9e7a-4c4f-ba47-d74433981980,DISK], DatanodeInfoWithStorage[127.0.0.1:37446,DS-9503865f-d226-414c-96cf-3c4412140360,DISK], DatanodeInfoWithStorage[127.0.0.1:35280,DS-fd05fc74-35c3-4971-bc93-03d48f6e814d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1975774636-172.17.0.2-1595356434627:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46113,DS-60aed540-7318-48e1-b812-76ba546fac3e,DISK], DatanodeInfoWithStorage[127.0.0.1:38352,DS-af0a7c78-5db1-4528-8cd5-150c7f4c7fb3,DISK], DatanodeInfoWithStorage[127.0.0.1:42429,DS-937a2047-c840-455d-85b4-afb6ece2d3b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41103,DS-67b76db0-577b-4966-b7d3-3df29c7c9623,DISK], DatanodeInfoWithStorage[127.0.0.1:41050,DS-94ad7b8e-0552-4249-ac57-fd152afe4394,DISK], DatanodeInfoWithStorage[127.0.0.1:41667,DS-726d00a4-9e7a-4c4f-ba47-d74433981980,DISK], DatanodeInfoWithStorage[127.0.0.1:37446,DS-9503865f-d226-414c-96cf-3c4412140360,DISK], DatanodeInfoWithStorage[127.0.0.1:35280,DS-fd05fc74-35c3-4971-bc93-03d48f6e814d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.name.dir.restore
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2047303830-172.17.0.2-1595356576262:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35872,DS-9b254bc6-c9ea-4b41-ae2d-57559bb8e1a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46591,DS-d04d9687-0fb9-4481-93b8-0c9d09074860,DISK], DatanodeInfoWithStorage[127.0.0.1:32920,DS-b1b0b182-f3f8-4bdd-98f6-d1ac6d9dc6ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33572,DS-1e0ab771-90b0-4d94-a9a4-fbb4693c0d49,DISK], DatanodeInfoWithStorage[127.0.0.1:34135,DS-cfcd9f4e-c27c-4a8b-ab8d-f8c017b280bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41946,DS-648e39f9-6d9d-4a29-af0b-4cbca015e77d,DISK], DatanodeInfoWithStorage[127.0.0.1:41885,DS-8626bf6a-8589-4103-b321-8b449b6f5f54,DISK], DatanodeInfoWithStorage[127.0.0.1:36486,DS-88e205c7-357c-41a6-8ec6-aa5623172254,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2047303830-172.17.0.2-1595356576262:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35872,DS-9b254bc6-c9ea-4b41-ae2d-57559bb8e1a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46591,DS-d04d9687-0fb9-4481-93b8-0c9d09074860,DISK], DatanodeInfoWithStorage[127.0.0.1:32920,DS-b1b0b182-f3f8-4bdd-98f6-d1ac6d9dc6ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33572,DS-1e0ab771-90b0-4d94-a9a4-fbb4693c0d49,DISK], DatanodeInfoWithStorage[127.0.0.1:34135,DS-cfcd9f4e-c27c-4a8b-ab8d-f8c017b280bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41946,DS-648e39f9-6d9d-4a29-af0b-4cbca015e77d,DISK], DatanodeInfoWithStorage[127.0.0.1:41885,DS-8626bf6a-8589-4103-b321-8b449b6f5f54,DISK], DatanodeInfoWithStorage[127.0.0.1:36486,DS-88e205c7-357c-41a6-8ec6-aa5623172254,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.name.dir.restore
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-749247270-172.17.0.2-1595356611104:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46102,DS-3aea4960-1904-421b-8fb5-f937845be0b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34598,DS-7ebafaa2-ff3d-4327-8d10-71e9aab5423d,DISK], DatanodeInfoWithStorage[127.0.0.1:34383,DS-047b95f2-8cea-414e-a085-99e701532573,DISK], DatanodeInfoWithStorage[127.0.0.1:34263,DS-d046b8e3-fc07-4fd3-9170-62d3d8172eff,DISK], DatanodeInfoWithStorage[127.0.0.1:41468,DS-84e2b484-c701-4130-9818-dfccd3e382ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41035,DS-caef19c6-4786-4bb0-a976-e201dc1be228,DISK], DatanodeInfoWithStorage[127.0.0.1:40514,DS-b6f99128-b789-4179-adf3-949233bf1ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:41504,DS-4cf7eb8f-62dc-434b-9538-84a586b6ea78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-749247270-172.17.0.2-1595356611104:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46102,DS-3aea4960-1904-421b-8fb5-f937845be0b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34598,DS-7ebafaa2-ff3d-4327-8d10-71e9aab5423d,DISK], DatanodeInfoWithStorage[127.0.0.1:34383,DS-047b95f2-8cea-414e-a085-99e701532573,DISK], DatanodeInfoWithStorage[127.0.0.1:34263,DS-d046b8e3-fc07-4fd3-9170-62d3d8172eff,DISK], DatanodeInfoWithStorage[127.0.0.1:41468,DS-84e2b484-c701-4130-9818-dfccd3e382ca,DISK], DatanodeInfoWithStorage[127.0.0.1:41035,DS-caef19c6-4786-4bb0-a976-e201dc1be228,DISK], DatanodeInfoWithStorage[127.0.0.1:40514,DS-b6f99128-b789-4179-adf3-949233bf1ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:41504,DS-4cf7eb8f-62dc-434b-9538-84a586b6ea78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.name.dir.restore
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1315959615-172.17.0.2-1595357313246:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40721,DS-2e7d68f3-fa8a-424c-9e23-0a11f3c38851,DISK], DatanodeInfoWithStorage[127.0.0.1:41002,DS-54ad949a-2c17-4c94-8f45-1d75bb2e69f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33596,DS-e313b430-ebe6-4eb9-b114-55cd6ff83418,DISK], DatanodeInfoWithStorage[127.0.0.1:40305,DS-ab399bf6-b100-4f63-ac84-411bf9ceaede,DISK], DatanodeInfoWithStorage[127.0.0.1:42971,DS-7840a563-1040-4854-bde6-19591d9b432c,DISK], DatanodeInfoWithStorage[127.0.0.1:35606,DS-34a4f610-d27c-4555-9519-210c7337c0f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40476,DS-00398222-e22b-4968-b793-7f9a6bdf8132,DISK], DatanodeInfoWithStorage[127.0.0.1:43155,DS-9b603fe0-28b2-441a-b556-2d2f2460443d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1315959615-172.17.0.2-1595357313246:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40721,DS-2e7d68f3-fa8a-424c-9e23-0a11f3c38851,DISK], DatanodeInfoWithStorage[127.0.0.1:41002,DS-54ad949a-2c17-4c94-8f45-1d75bb2e69f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33596,DS-e313b430-ebe6-4eb9-b114-55cd6ff83418,DISK], DatanodeInfoWithStorage[127.0.0.1:40305,DS-ab399bf6-b100-4f63-ac84-411bf9ceaede,DISK], DatanodeInfoWithStorage[127.0.0.1:42971,DS-7840a563-1040-4854-bde6-19591d9b432c,DISK], DatanodeInfoWithStorage[127.0.0.1:35606,DS-34a4f610-d27c-4555-9519-210c7337c0f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40476,DS-00398222-e22b-4968-b793-7f9a6bdf8132,DISK], DatanodeInfoWithStorage[127.0.0.1:43155,DS-9b603fe0-28b2-441a-b556-2d2f2460443d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.name.dir.restore
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1235188795-172.17.0.2-1595357688685:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41978,DS-1de657d5-161e-4c41-9304-841cd4696acf,DISK], DatanodeInfoWithStorage[127.0.0.1:45130,DS-33ee48d0-afcd-4310-9f7a-b9a0dd3b2cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:45934,DS-71a215d4-0ff5-46e3-b131-734d294c805a,DISK], DatanodeInfoWithStorage[127.0.0.1:39420,DS-6fca5d6c-3fc1-429f-831b-7ad527736d98,DISK], DatanodeInfoWithStorage[127.0.0.1:44405,DS-f14967d5-3cc2-48b6-b55f-6b8dabc8f335,DISK], DatanodeInfoWithStorage[127.0.0.1:38882,DS-21898d72-d1bb-4ab1-9b2a-9b6b9b117725,DISK], DatanodeInfoWithStorage[127.0.0.1:39730,DS-fdf83e74-d0d3-40c8-99be-8b3f5325a139,DISK], DatanodeInfoWithStorage[127.0.0.1:45656,DS-2fb6be66-f0eb-43b0-8be6-934a6eba5cb6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1235188795-172.17.0.2-1595357688685:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41978,DS-1de657d5-161e-4c41-9304-841cd4696acf,DISK], DatanodeInfoWithStorage[127.0.0.1:45130,DS-33ee48d0-afcd-4310-9f7a-b9a0dd3b2cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:45934,DS-71a215d4-0ff5-46e3-b131-734d294c805a,DISK], DatanodeInfoWithStorage[127.0.0.1:39420,DS-6fca5d6c-3fc1-429f-831b-7ad527736d98,DISK], DatanodeInfoWithStorage[127.0.0.1:44405,DS-f14967d5-3cc2-48b6-b55f-6b8dabc8f335,DISK], DatanodeInfoWithStorage[127.0.0.1:38882,DS-21898d72-d1bb-4ab1-9b2a-9b6b9b117725,DISK], DatanodeInfoWithStorage[127.0.0.1:39730,DS-fdf83e74-d0d3-40c8-99be-8b3f5325a139,DISK], DatanodeInfoWithStorage[127.0.0.1:45656,DS-2fb6be66-f0eb-43b0-8be6-934a6eba5cb6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.name.dir.restore
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-485260912-172.17.0.2-1595359242441:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38156,DS-34af8fa7-05d9-411f-8b20-d8ad868269d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35542,DS-ab90cf05-3da3-447d-aad3-0c708a6b726b,DISK], DatanodeInfoWithStorage[127.0.0.1:38487,DS-d6ed7c3f-b0cd-42ab-9fb1-7043562be4ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33440,DS-b6bcd892-70f3-4e6e-950d-3a10e27af215,DISK], DatanodeInfoWithStorage[127.0.0.1:34904,DS-86f57a71-fbf7-4d87-8947-ceffac3419f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40681,DS-83796c82-bddc-493b-a494-dbc0340d8645,DISK], DatanodeInfoWithStorage[127.0.0.1:37132,DS-7e1184a5-f6cd-4d87-a61d-85e031d288db,DISK], DatanodeInfoWithStorage[127.0.0.1:38816,DS-0c01609a-85ec-4e0a-84f3-2bc735be59cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-485260912-172.17.0.2-1595359242441:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38156,DS-34af8fa7-05d9-411f-8b20-d8ad868269d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35542,DS-ab90cf05-3da3-447d-aad3-0c708a6b726b,DISK], DatanodeInfoWithStorage[127.0.0.1:38487,DS-d6ed7c3f-b0cd-42ab-9fb1-7043562be4ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33440,DS-b6bcd892-70f3-4e6e-950d-3a10e27af215,DISK], DatanodeInfoWithStorage[127.0.0.1:34904,DS-86f57a71-fbf7-4d87-8947-ceffac3419f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40681,DS-83796c82-bddc-493b-a494-dbc0340d8645,DISK], DatanodeInfoWithStorage[127.0.0.1:37132,DS-7e1184a5-f6cd-4d87-a61d-85e031d288db,DISK], DatanodeInfoWithStorage[127.0.0.1:38816,DS-0c01609a-85ec-4e0a-84f3-2bc735be59cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.name.dir.restore
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1076734174-172.17.0.2-1595359315566:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44247,DS-171842bd-9967-4ed0-925c-4913fcbd3c96,DISK], DatanodeInfoWithStorage[127.0.0.1:42594,DS-71406355-5674-4cc3-8a3c-754308fd2498,DISK], DatanodeInfoWithStorage[127.0.0.1:40579,DS-027d14c7-749f-409b-9616-ef24d66c154e,DISK], DatanodeInfoWithStorage[127.0.0.1:38355,DS-7c09c9ec-934b-4b92-8f3b-dc9a6a9a8a42,DISK], DatanodeInfoWithStorage[127.0.0.1:40193,DS-361c2caf-d659-409e-924f-035ded214716,DISK], DatanodeInfoWithStorage[127.0.0.1:36738,DS-d6ce9ddc-ffeb-49d5-b2a1-ff8556e0a3f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42357,DS-7a1094be-74e8-4caa-a6d8-d81ec5fb4e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:33002,DS-c0bf3125-e2b8-46f1-8dd0-56adf4203789,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1076734174-172.17.0.2-1595359315566:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44247,DS-171842bd-9967-4ed0-925c-4913fcbd3c96,DISK], DatanodeInfoWithStorage[127.0.0.1:42594,DS-71406355-5674-4cc3-8a3c-754308fd2498,DISK], DatanodeInfoWithStorage[127.0.0.1:40579,DS-027d14c7-749f-409b-9616-ef24d66c154e,DISK], DatanodeInfoWithStorage[127.0.0.1:38355,DS-7c09c9ec-934b-4b92-8f3b-dc9a6a9a8a42,DISK], DatanodeInfoWithStorage[127.0.0.1:40193,DS-361c2caf-d659-409e-924f-035ded214716,DISK], DatanodeInfoWithStorage[127.0.0.1:36738,DS-d6ce9ddc-ffeb-49d5-b2a1-ff8556e0a3f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42357,DS-7a1094be-74e8-4caa-a6d8-d81ec5fb4e2b,DISK], DatanodeInfoWithStorage[127.0.0.1:33002,DS-c0bf3125-e2b8-46f1-8dd0-56adf4203789,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.name.dir.restore
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1740102997-172.17.0.2-1595359351006:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39509,DS-20eda1b0-162b-4c18-804b-a0d23d9eed57,DISK], DatanodeInfoWithStorage[127.0.0.1:39290,DS-194f0e6f-ca3c-455e-8c2a-ee26053beb4b,DISK], DatanodeInfoWithStorage[127.0.0.1:38713,DS-e6882d6a-1457-46b0-95c7-4b43680d0c00,DISK], DatanodeInfoWithStorage[127.0.0.1:42063,DS-63868384-f8fa-4e08-a257-e68555e89923,DISK], DatanodeInfoWithStorage[127.0.0.1:40247,DS-ca1c664a-cb40-4beb-91ed-9abf34aefa4d,DISK], DatanodeInfoWithStorage[127.0.0.1:45964,DS-2fe9294a-ba9e-48d0-a50b-26a504bef4dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36207,DS-e7fd1105-e2f9-4f45-baaa-3a16035080fb,DISK], DatanodeInfoWithStorage[127.0.0.1:43978,DS-5d6e3a0a-a97c-41fd-9782-b525be3e1885,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1740102997-172.17.0.2-1595359351006:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39509,DS-20eda1b0-162b-4c18-804b-a0d23d9eed57,DISK], DatanodeInfoWithStorage[127.0.0.1:39290,DS-194f0e6f-ca3c-455e-8c2a-ee26053beb4b,DISK], DatanodeInfoWithStorage[127.0.0.1:38713,DS-e6882d6a-1457-46b0-95c7-4b43680d0c00,DISK], DatanodeInfoWithStorage[127.0.0.1:42063,DS-63868384-f8fa-4e08-a257-e68555e89923,DISK], DatanodeInfoWithStorage[127.0.0.1:40247,DS-ca1c664a-cb40-4beb-91ed-9abf34aefa4d,DISK], DatanodeInfoWithStorage[127.0.0.1:45964,DS-2fe9294a-ba9e-48d0-a50b-26a504bef4dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36207,DS-e7fd1105-e2f9-4f45-baaa-3a16035080fb,DISK], DatanodeInfoWithStorage[127.0.0.1:43978,DS-5d6e3a0a-a97c-41fd-9782-b525be3e1885,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.name.dir.restore
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-3816574-172.17.0.2-1595359557240:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40330,DS-f828a4a9-8b54-49ff-898f-04d44b193177,DISK], DatanodeInfoWithStorage[127.0.0.1:34918,DS-95b28017-d7f1-4ffe-838c-f1bd329a7b60,DISK], DatanodeInfoWithStorage[127.0.0.1:36671,DS-d16a0c7f-79e5-4ba2-8e20-69b63eaa77d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35426,DS-9cefcba7-cb1d-4afc-a788-04f60b1ec7f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36580,DS-9f03c0e7-8c25-4cf5-b6e1-94b715a5897e,DISK], DatanodeInfoWithStorage[127.0.0.1:41152,DS-f5f5f748-6743-4b39-aa64-02cb97c556e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41067,DS-ead7431d-3cab-4c34-99ff-fd6f73a55c63,DISK], DatanodeInfoWithStorage[127.0.0.1:38143,DS-54b0e704-bcae-4d10-a0c8-4e8a10adf74f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-3816574-172.17.0.2-1595359557240:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40330,DS-f828a4a9-8b54-49ff-898f-04d44b193177,DISK], DatanodeInfoWithStorage[127.0.0.1:34918,DS-95b28017-d7f1-4ffe-838c-f1bd329a7b60,DISK], DatanodeInfoWithStorage[127.0.0.1:36671,DS-d16a0c7f-79e5-4ba2-8e20-69b63eaa77d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35426,DS-9cefcba7-cb1d-4afc-a788-04f60b1ec7f6,DISK], DatanodeInfoWithStorage[127.0.0.1:36580,DS-9f03c0e7-8c25-4cf5-b6e1-94b715a5897e,DISK], DatanodeInfoWithStorage[127.0.0.1:41152,DS-f5f5f748-6743-4b39-aa64-02cb97c556e0,DISK], DatanodeInfoWithStorage[127.0.0.1:41067,DS-ead7431d-3cab-4c34-99ff-fd6f73a55c63,DISK], DatanodeInfoWithStorage[127.0.0.1:38143,DS-54b0e704-bcae-4d10-a0c8-4e8a10adf74f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.name.dir.restore
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2011797591-172.17.0.2-1595359632759:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39257,DS-3387ac60-89c5-4eae-a28c-b72ad51b945b,DISK], DatanodeInfoWithStorage[127.0.0.1:35949,DS-36cc4f62-1dde-48ef-8a0e-2099802824ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39833,DS-3958778d-4f66-4f7c-be5b-80ca2927fda0,DISK], DatanodeInfoWithStorage[127.0.0.1:41563,DS-e670aef9-4c1a-4270-8437-599e9cf3907d,DISK], DatanodeInfoWithStorage[127.0.0.1:32868,DS-a7998660-94d3-476e-825d-baf6032cd995,DISK], DatanodeInfoWithStorage[127.0.0.1:41807,DS-9b56eae2-a036-4493-a68a-ed4e81b26f4f,DISK], DatanodeInfoWithStorage[127.0.0.1:37322,DS-0c43106e-aea4-49fb-819f-9db0eefd8aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:41576,DS-77e1aafc-cf96-455a-b9bb-45a360927a05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2011797591-172.17.0.2-1595359632759:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39257,DS-3387ac60-89c5-4eae-a28c-b72ad51b945b,DISK], DatanodeInfoWithStorage[127.0.0.1:35949,DS-36cc4f62-1dde-48ef-8a0e-2099802824ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39833,DS-3958778d-4f66-4f7c-be5b-80ca2927fda0,DISK], DatanodeInfoWithStorage[127.0.0.1:41563,DS-e670aef9-4c1a-4270-8437-599e9cf3907d,DISK], DatanodeInfoWithStorage[127.0.0.1:32868,DS-a7998660-94d3-476e-825d-baf6032cd995,DISK], DatanodeInfoWithStorage[127.0.0.1:41807,DS-9b56eae2-a036-4493-a68a-ed4e81b26f4f,DISK], DatanodeInfoWithStorage[127.0.0.1:37322,DS-0c43106e-aea4-49fb-819f-9db0eefd8aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:41576,DS-77e1aafc-cf96-455a-b9bb-45a360927a05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.name.dir.restore
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1965683088-172.17.0.2-1595359976460:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37406,DS-50fd885b-3042-4206-adad-ef398bb48bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:39283,DS-bb7c5478-39e6-4b80-ad83-0a61606ba70c,DISK], DatanodeInfoWithStorage[127.0.0.1:35213,DS-e21d3fdb-6807-47c1-a3c5-de4bf105f178,DISK], DatanodeInfoWithStorage[127.0.0.1:45100,DS-1defb50a-9b93-485d-94ec-130126df8bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:37991,DS-3900ab1d-d761-4d0b-ad37-2c9639c35751,DISK], DatanodeInfoWithStorage[127.0.0.1:42321,DS-8e21f556-c863-41f1-80b3-9be0fd7ad590,DISK], DatanodeInfoWithStorage[127.0.0.1:43751,DS-922fde13-c213-4b3e-9126-6b1cb655f27d,DISK], DatanodeInfoWithStorage[127.0.0.1:42214,DS-8443c43b-30cf-46a9-ac24-a9e5f39d546e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1965683088-172.17.0.2-1595359976460:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37406,DS-50fd885b-3042-4206-adad-ef398bb48bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:39283,DS-bb7c5478-39e6-4b80-ad83-0a61606ba70c,DISK], DatanodeInfoWithStorage[127.0.0.1:35213,DS-e21d3fdb-6807-47c1-a3c5-de4bf105f178,DISK], DatanodeInfoWithStorage[127.0.0.1:45100,DS-1defb50a-9b93-485d-94ec-130126df8bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:37991,DS-3900ab1d-d761-4d0b-ad37-2c9639c35751,DISK], DatanodeInfoWithStorage[127.0.0.1:42321,DS-8e21f556-c863-41f1-80b3-9be0fd7ad590,DISK], DatanodeInfoWithStorage[127.0.0.1:43751,DS-922fde13-c213-4b3e-9126-6b1cb655f27d,DISK], DatanodeInfoWithStorage[127.0.0.1:42214,DS-8443c43b-30cf-46a9-ac24-a9e5f39d546e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.name.dir.restore
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1582094816-172.17.0.2-1595360188963:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33154,DS-f5df9332-6d04-4048-bcb7-2cd0244d786b,DISK], DatanodeInfoWithStorage[127.0.0.1:39515,DS-4124bb28-94ab-4eee-adad-29a04cff1b9a,DISK], DatanodeInfoWithStorage[127.0.0.1:35158,DS-68a7f103-e321-4b21-bc91-84391eaf5d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:37344,DS-90a6923a-700f-4993-b263-d9a786a5c83b,DISK], DatanodeInfoWithStorage[127.0.0.1:39549,DS-6df77fa4-d8d5-45a5-b986-65d3a04696cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40637,DS-a50f9863-0eb5-49b9-81a3-531afdfc2ec5,DISK], DatanodeInfoWithStorage[127.0.0.1:38155,DS-d0e347ba-273f-4ff8-9164-1373a1e10a3f,DISK], DatanodeInfoWithStorage[127.0.0.1:45897,DS-c44baeed-d3c9-4dd6-abf7-9b8db4b3a7cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1582094816-172.17.0.2-1595360188963:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33154,DS-f5df9332-6d04-4048-bcb7-2cd0244d786b,DISK], DatanodeInfoWithStorage[127.0.0.1:39515,DS-4124bb28-94ab-4eee-adad-29a04cff1b9a,DISK], DatanodeInfoWithStorage[127.0.0.1:35158,DS-68a7f103-e321-4b21-bc91-84391eaf5d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:37344,DS-90a6923a-700f-4993-b263-d9a786a5c83b,DISK], DatanodeInfoWithStorage[127.0.0.1:39549,DS-6df77fa4-d8d5-45a5-b986-65d3a04696cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40637,DS-a50f9863-0eb5-49b9-81a3-531afdfc2ec5,DISK], DatanodeInfoWithStorage[127.0.0.1:38155,DS-d0e347ba-273f-4ff8-9164-1373a1e10a3f,DISK], DatanodeInfoWithStorage[127.0.0.1:45897,DS-c44baeed-d3c9-4dd6-abf7-9b8db4b3a7cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.name.dir.restore
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-553291059-172.17.0.2-1595360221855:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35136,DS-bace7c23-efed-4b29-bd97-cc62e2376185,DISK], DatanodeInfoWithStorage[127.0.0.1:44435,DS-beb145bb-ff46-4b4d-a7dc-ce2f597d2e17,DISK], DatanodeInfoWithStorage[127.0.0.1:43778,DS-016c8ad3-045b-460e-993f-63ff2856c93c,DISK], DatanodeInfoWithStorage[127.0.0.1:36359,DS-4459e381-c1a7-4dae-8fb0-c50c92cc896e,DISK], DatanodeInfoWithStorage[127.0.0.1:36377,DS-011f2024-af22-4078-bdf5-de0733f6db68,DISK], DatanodeInfoWithStorage[127.0.0.1:43522,DS-4847cc7c-085d-47ca-afd1-89f8e40ef98b,DISK], DatanodeInfoWithStorage[127.0.0.1:34130,DS-4d8b2ab7-99c7-49a2-8201-928d244ed4b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39079,DS-7cc18017-fc89-4acc-b4bb-8cc0085cb9fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-553291059-172.17.0.2-1595360221855:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35136,DS-bace7c23-efed-4b29-bd97-cc62e2376185,DISK], DatanodeInfoWithStorage[127.0.0.1:44435,DS-beb145bb-ff46-4b4d-a7dc-ce2f597d2e17,DISK], DatanodeInfoWithStorage[127.0.0.1:43778,DS-016c8ad3-045b-460e-993f-63ff2856c93c,DISK], DatanodeInfoWithStorage[127.0.0.1:36359,DS-4459e381-c1a7-4dae-8fb0-c50c92cc896e,DISK], DatanodeInfoWithStorage[127.0.0.1:36377,DS-011f2024-af22-4078-bdf5-de0733f6db68,DISK], DatanodeInfoWithStorage[127.0.0.1:43522,DS-4847cc7c-085d-47ca-afd1-89f8e40ef98b,DISK], DatanodeInfoWithStorage[127.0.0.1:34130,DS-4d8b2ab7-99c7-49a2-8201-928d244ed4b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39079,DS-7cc18017-fc89-4acc-b4bb-8cc0085cb9fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.name.dir.restore
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-667562453-172.17.0.2-1595360432844:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34613,DS-a81ec991-7a35-44cf-875e-9c328f1d1a7e,DISK], DatanodeInfoWithStorage[127.0.0.1:40699,DS-e4dab949-ad6b-426f-a70e-62df7209a6bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37237,DS-cc8aa5bd-1eca-4ad1-b08a-8ca7c08c1fea,DISK], DatanodeInfoWithStorage[127.0.0.1:45703,DS-6fc46741-f033-4cbd-870e-55490879d5d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36822,DS-07d3a09d-fdd2-4e6d-a97e-413fedd84382,DISK], DatanodeInfoWithStorage[127.0.0.1:43374,DS-2b26819c-f6bc-4080-939b-55404db98cb1,DISK], DatanodeInfoWithStorage[127.0.0.1:36199,DS-1e284632-9b09-4068-9d23-2b33e5feeb1f,DISK], DatanodeInfoWithStorage[127.0.0.1:35375,DS-44507a27-2a56-478c-9229-93007cd83c08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-667562453-172.17.0.2-1595360432844:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34613,DS-a81ec991-7a35-44cf-875e-9c328f1d1a7e,DISK], DatanodeInfoWithStorage[127.0.0.1:40699,DS-e4dab949-ad6b-426f-a70e-62df7209a6bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37237,DS-cc8aa5bd-1eca-4ad1-b08a-8ca7c08c1fea,DISK], DatanodeInfoWithStorage[127.0.0.1:45703,DS-6fc46741-f033-4cbd-870e-55490879d5d2,DISK], DatanodeInfoWithStorage[127.0.0.1:36822,DS-07d3a09d-fdd2-4e6d-a97e-413fedd84382,DISK], DatanodeInfoWithStorage[127.0.0.1:43374,DS-2b26819c-f6bc-4080-939b-55404db98cb1,DISK], DatanodeInfoWithStorage[127.0.0.1:36199,DS-1e284632-9b09-4068-9d23-2b33e5feeb1f,DISK], DatanodeInfoWithStorage[127.0.0.1:35375,DS-44507a27-2a56-478c-9229-93007cd83c08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.name.dir.restore
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1138313231-172.17.0.2-1595360813665:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45247,DS-bbd64b93-6eec-4a6b-8bec-9d7c83792e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:36360,DS-628c2bc5-89ac-4822-bd5b-160f45ab75df,DISK], DatanodeInfoWithStorage[127.0.0.1:36221,DS-6fd634e6-5809-42f7-903b-00ae6f6b1204,DISK], DatanodeInfoWithStorage[127.0.0.1:40040,DS-0b60a007-caa9-45c5-ae87-bfdfb65828e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43272,DS-9c2a15c5-39a5-4205-a0e9-404cee63320f,DISK], DatanodeInfoWithStorage[127.0.0.1:33470,DS-000b9fee-93f9-40d2-9591-53d44caf9de2,DISK], DatanodeInfoWithStorage[127.0.0.1:35059,DS-2057564a-9b3b-436f-8c12-89b2ec91b17d,DISK], DatanodeInfoWithStorage[127.0.0.1:39798,DS-f5b4758d-44d6-4d1f-b824-9b9d4786000f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1138313231-172.17.0.2-1595360813665:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45247,DS-bbd64b93-6eec-4a6b-8bec-9d7c83792e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:36360,DS-628c2bc5-89ac-4822-bd5b-160f45ab75df,DISK], DatanodeInfoWithStorage[127.0.0.1:36221,DS-6fd634e6-5809-42f7-903b-00ae6f6b1204,DISK], DatanodeInfoWithStorage[127.0.0.1:40040,DS-0b60a007-caa9-45c5-ae87-bfdfb65828e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43272,DS-9c2a15c5-39a5-4205-a0e9-404cee63320f,DISK], DatanodeInfoWithStorage[127.0.0.1:33470,DS-000b9fee-93f9-40d2-9591-53d44caf9de2,DISK], DatanodeInfoWithStorage[127.0.0.1:35059,DS-2057564a-9b3b-436f-8c12-89b2ec91b17d,DISK], DatanodeInfoWithStorage[127.0.0.1:39798,DS-f5b4758d-44d6-4d1f-b824-9b9d4786000f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5265
