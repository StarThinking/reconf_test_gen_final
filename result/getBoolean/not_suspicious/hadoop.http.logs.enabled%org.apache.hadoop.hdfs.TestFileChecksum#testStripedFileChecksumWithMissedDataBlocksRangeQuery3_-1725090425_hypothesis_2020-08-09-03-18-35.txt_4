reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1646254560-172.17.0.19-1596943701832:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40529,DS-d61e1993-0a27-4ac6-8398-9f052ddf22c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35822,DS-2a6872cc-72f9-400d-8d6b-d2ff5d5ae40a,DISK], DatanodeInfoWithStorage[127.0.0.1:46746,DS-f44d462b-b217-4c99-b20a-6ddd73e9e350,DISK], DatanodeInfoWithStorage[127.0.0.1:41219,DS-9f81097a-2565-4836-9bb4-e63e8a9bd09c,DISK], DatanodeInfoWithStorage[127.0.0.1:39597,DS-3e4c20c2-5da8-42f2-9807-a81b7b046ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:36511,DS-98e3f3a4-2615-4ac3-ab9e-084aeb42cb3f,DISK], DatanodeInfoWithStorage[127.0.0.1:42231,DS-c9438a8d-732a-4fe6-976d-4831082f09a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37460,DS-dd1dc1e9-9dea-4e46-85c4-dba9189c221c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1646254560-172.17.0.19-1596943701832:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40529,DS-d61e1993-0a27-4ac6-8398-9f052ddf22c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35822,DS-2a6872cc-72f9-400d-8d6b-d2ff5d5ae40a,DISK], DatanodeInfoWithStorage[127.0.0.1:46746,DS-f44d462b-b217-4c99-b20a-6ddd73e9e350,DISK], DatanodeInfoWithStorage[127.0.0.1:41219,DS-9f81097a-2565-4836-9bb4-e63e8a9bd09c,DISK], DatanodeInfoWithStorage[127.0.0.1:39597,DS-3e4c20c2-5da8-42f2-9807-a81b7b046ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:36511,DS-98e3f3a4-2615-4ac3-ab9e-084aeb42cb3f,DISK], DatanodeInfoWithStorage[127.0.0.1:42231,DS-c9438a8d-732a-4fe6-976d-4831082f09a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37460,DS-dd1dc1e9-9dea-4e46-85c4-dba9189c221c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1002381858-172.17.0.19-1596943784135:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46712,DS-e3f53920-7987-4e9a-bc30-859aed26da6a,DISK], DatanodeInfoWithStorage[127.0.0.1:44301,DS-3e8aed8d-df54-46ad-96e7-ffaa024b490d,DISK], DatanodeInfoWithStorage[127.0.0.1:39216,DS-d9bb7011-d82c-462d-948a-480e2774d4c7,DISK], DatanodeInfoWithStorage[127.0.0.1:44822,DS-aadaf0bb-fe4e-4abc-8ba7-0ec5e30cd017,DISK], DatanodeInfoWithStorage[127.0.0.1:32900,DS-9ece5e9f-6bdf-4a2d-9c2c-b1ec338ccd89,DISK], DatanodeInfoWithStorage[127.0.0.1:41690,DS-488712ac-979b-4be4-8356-42a6708897f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42140,DS-f3cddcd1-81df-43d3-bac9-ea2f3e23bc58,DISK], DatanodeInfoWithStorage[127.0.0.1:41980,DS-b95edc12-743d-44f6-aa09-6eeef207447e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1002381858-172.17.0.19-1596943784135:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46712,DS-e3f53920-7987-4e9a-bc30-859aed26da6a,DISK], DatanodeInfoWithStorage[127.0.0.1:44301,DS-3e8aed8d-df54-46ad-96e7-ffaa024b490d,DISK], DatanodeInfoWithStorage[127.0.0.1:39216,DS-d9bb7011-d82c-462d-948a-480e2774d4c7,DISK], DatanodeInfoWithStorage[127.0.0.1:44822,DS-aadaf0bb-fe4e-4abc-8ba7-0ec5e30cd017,DISK], DatanodeInfoWithStorage[127.0.0.1:32900,DS-9ece5e9f-6bdf-4a2d-9c2c-b1ec338ccd89,DISK], DatanodeInfoWithStorage[127.0.0.1:41690,DS-488712ac-979b-4be4-8356-42a6708897f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42140,DS-f3cddcd1-81df-43d3-bac9-ea2f3e23bc58,DISK], DatanodeInfoWithStorage[127.0.0.1:41980,DS-b95edc12-743d-44f6-aa09-6eeef207447e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1631830524-172.17.0.19-1596943851969:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37897,DS-eae32574-71f6-491c-8949-39ca2be45310,DISK], DatanodeInfoWithStorage[127.0.0.1:44745,DS-4adee14e-c14f-4832-be57-cd65caaac501,DISK], DatanodeInfoWithStorage[127.0.0.1:34260,DS-215c6a7a-abc7-436d-864d-8b610760cec7,DISK], DatanodeInfoWithStorage[127.0.0.1:36393,DS-586d4a31-ee6f-4293-b7da-be0c2cde44f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45969,DS-f5ff9891-8d90-413b-a373-d820c514da42,DISK], DatanodeInfoWithStorage[127.0.0.1:35515,DS-46a7e5fe-391a-4375-a529-22efe1149840,DISK], DatanodeInfoWithStorage[127.0.0.1:46472,DS-d2c44106-9547-43dd-98b0-47187fc8a7e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35443,DS-3a2a857a-a398-431c-80be-4d8e9f063b5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1631830524-172.17.0.19-1596943851969:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37897,DS-eae32574-71f6-491c-8949-39ca2be45310,DISK], DatanodeInfoWithStorage[127.0.0.1:44745,DS-4adee14e-c14f-4832-be57-cd65caaac501,DISK], DatanodeInfoWithStorage[127.0.0.1:34260,DS-215c6a7a-abc7-436d-864d-8b610760cec7,DISK], DatanodeInfoWithStorage[127.0.0.1:36393,DS-586d4a31-ee6f-4293-b7da-be0c2cde44f7,DISK], DatanodeInfoWithStorage[127.0.0.1:45969,DS-f5ff9891-8d90-413b-a373-d820c514da42,DISK], DatanodeInfoWithStorage[127.0.0.1:35515,DS-46a7e5fe-391a-4375-a529-22efe1149840,DISK], DatanodeInfoWithStorage[127.0.0.1:46472,DS-d2c44106-9547-43dd-98b0-47187fc8a7e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35443,DS-3a2a857a-a398-431c-80be-4d8e9f063b5a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2146130885-172.17.0.19-1596944141113:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32986,DS-8346bd8c-756e-4826-b24d-649a433c2852,DISK], DatanodeInfoWithStorage[127.0.0.1:44240,DS-e1469cc7-1859-4075-80ed-1dfa4d8e9c70,DISK], DatanodeInfoWithStorage[127.0.0.1:33152,DS-9b7f7fd0-6def-4271-8e2e-dfe0c8b007f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46585,DS-5bd2794c-0d45-4657-b37f-1e4b97a2c6b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39041,DS-300d05b6-7138-48cb-9c2a-a1fac9e352e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37202,DS-d60d9fc2-9915-4f22-89cb-036cdbbc2ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:44618,DS-01ba896d-b715-4f80-9752-80a9d89bdd3f,DISK], DatanodeInfoWithStorage[127.0.0.1:42475,DS-4cabc325-19fe-4a4d-807e-25a29c790d81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2146130885-172.17.0.19-1596944141113:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32986,DS-8346bd8c-756e-4826-b24d-649a433c2852,DISK], DatanodeInfoWithStorage[127.0.0.1:44240,DS-e1469cc7-1859-4075-80ed-1dfa4d8e9c70,DISK], DatanodeInfoWithStorage[127.0.0.1:33152,DS-9b7f7fd0-6def-4271-8e2e-dfe0c8b007f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46585,DS-5bd2794c-0d45-4657-b37f-1e4b97a2c6b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39041,DS-300d05b6-7138-48cb-9c2a-a1fac9e352e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37202,DS-d60d9fc2-9915-4f22-89cb-036cdbbc2ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:44618,DS-01ba896d-b715-4f80-9752-80a9d89bdd3f,DISK], DatanodeInfoWithStorage[127.0.0.1:42475,DS-4cabc325-19fe-4a4d-807e-25a29c790d81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-4061843-172.17.0.19-1596944172883:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36424,DS-827d6980-15d9-43b4-9304-a5ce67dbac04,DISK], DatanodeInfoWithStorage[127.0.0.1:43736,DS-322c721a-7eec-468f-ba33-d3436ba529a3,DISK], DatanodeInfoWithStorage[127.0.0.1:45634,DS-3382a091-155a-4278-8002-d424accf8d92,DISK], DatanodeInfoWithStorage[127.0.0.1:42254,DS-77f6fb8c-7e91-4234-bcf8-dc779c56bdac,DISK], DatanodeInfoWithStorage[127.0.0.1:41572,DS-61ea4685-52df-4693-95af-391b0d6c7063,DISK], DatanodeInfoWithStorage[127.0.0.1:33656,DS-ace43aad-120b-4f7b-be88-cda8c30ba2e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36126,DS-88cea076-72d3-409c-a1ff-430904c07bda,DISK], DatanodeInfoWithStorage[127.0.0.1:40048,DS-fa215c39-df9a-4ebe-b4d6-5e4ee53ec2a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-4061843-172.17.0.19-1596944172883:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36424,DS-827d6980-15d9-43b4-9304-a5ce67dbac04,DISK], DatanodeInfoWithStorage[127.0.0.1:43736,DS-322c721a-7eec-468f-ba33-d3436ba529a3,DISK], DatanodeInfoWithStorage[127.0.0.1:45634,DS-3382a091-155a-4278-8002-d424accf8d92,DISK], DatanodeInfoWithStorage[127.0.0.1:42254,DS-77f6fb8c-7e91-4234-bcf8-dc779c56bdac,DISK], DatanodeInfoWithStorage[127.0.0.1:41572,DS-61ea4685-52df-4693-95af-391b0d6c7063,DISK], DatanodeInfoWithStorage[127.0.0.1:33656,DS-ace43aad-120b-4f7b-be88-cda8c30ba2e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36126,DS-88cea076-72d3-409c-a1ff-430904c07bda,DISK], DatanodeInfoWithStorage[127.0.0.1:40048,DS-fa215c39-df9a-4ebe-b4d6-5e4ee53ec2a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-790282577-172.17.0.19-1596944703008:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36414,DS-3a1596a7-1b1c-4776-845d-d36ca13dad06,DISK], DatanodeInfoWithStorage[127.0.0.1:42770,DS-564b074c-f8a2-4f83-83a7-308894ca0295,DISK], DatanodeInfoWithStorage[127.0.0.1:45674,DS-a973c41a-f979-410e-baa8-9d318587a793,DISK], DatanodeInfoWithStorage[127.0.0.1:38206,DS-fc4dc89d-d537-4a6a-bada-484c3e28372f,DISK], DatanodeInfoWithStorage[127.0.0.1:34664,DS-3cd16de4-6c58-4a32-9894-b819f3984b3f,DISK], DatanodeInfoWithStorage[127.0.0.1:33170,DS-b533c52d-39eb-42a0-9a1b-227239deeb1c,DISK], DatanodeInfoWithStorage[127.0.0.1:39602,DS-cbb44247-4e66-478d-8a48-b63c3984dab0,DISK], DatanodeInfoWithStorage[127.0.0.1:33417,DS-ad92e4ac-ba77-4fdd-8f17-906550dd7eb7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-790282577-172.17.0.19-1596944703008:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36414,DS-3a1596a7-1b1c-4776-845d-d36ca13dad06,DISK], DatanodeInfoWithStorage[127.0.0.1:42770,DS-564b074c-f8a2-4f83-83a7-308894ca0295,DISK], DatanodeInfoWithStorage[127.0.0.1:45674,DS-a973c41a-f979-410e-baa8-9d318587a793,DISK], DatanodeInfoWithStorage[127.0.0.1:38206,DS-fc4dc89d-d537-4a6a-bada-484c3e28372f,DISK], DatanodeInfoWithStorage[127.0.0.1:34664,DS-3cd16de4-6c58-4a32-9894-b819f3984b3f,DISK], DatanodeInfoWithStorage[127.0.0.1:33170,DS-b533c52d-39eb-42a0-9a1b-227239deeb1c,DISK], DatanodeInfoWithStorage[127.0.0.1:39602,DS-cbb44247-4e66-478d-8a48-b63c3984dab0,DISK], DatanodeInfoWithStorage[127.0.0.1:33417,DS-ad92e4ac-ba77-4fdd-8f17-906550dd7eb7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1984938479-172.17.0.19-1596945246510:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35797,DS-b4a3e8f3-99ed-4db2-bf16-4e0472c583fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45668,DS-1bb3cb58-5e47-47e6-aa00-b16682462e45,DISK], DatanodeInfoWithStorage[127.0.0.1:36622,DS-dfd55b9d-6bea-4b41-b5b8-95eb31151d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:34807,DS-b4de1faf-070f-40b8-b058-c2159c390461,DISK], DatanodeInfoWithStorage[127.0.0.1:44660,DS-716cbf4c-00de-4ae9-8a20-6fc270c92863,DISK], DatanodeInfoWithStorage[127.0.0.1:36198,DS-3d9a6138-9d80-4c22-a5ff-a46daaafe9bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39885,DS-18ccf6f1-abd1-4d1f-b2b6-ce337e9bbb28,DISK], DatanodeInfoWithStorage[127.0.0.1:39600,DS-1dcd04e1-36ce-4078-9f24-bf3b83577fbd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1984938479-172.17.0.19-1596945246510:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35797,DS-b4a3e8f3-99ed-4db2-bf16-4e0472c583fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45668,DS-1bb3cb58-5e47-47e6-aa00-b16682462e45,DISK], DatanodeInfoWithStorage[127.0.0.1:36622,DS-dfd55b9d-6bea-4b41-b5b8-95eb31151d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:34807,DS-b4de1faf-070f-40b8-b058-c2159c390461,DISK], DatanodeInfoWithStorage[127.0.0.1:44660,DS-716cbf4c-00de-4ae9-8a20-6fc270c92863,DISK], DatanodeInfoWithStorage[127.0.0.1:36198,DS-3d9a6138-9d80-4c22-a5ff-a46daaafe9bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39885,DS-18ccf6f1-abd1-4d1f-b2b6-ce337e9bbb28,DISK], DatanodeInfoWithStorage[127.0.0.1:39600,DS-1dcd04e1-36ce-4078-9f24-bf3b83577fbd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-994284987-172.17.0.19-1596945765041:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38741,DS-0fc8aa45-5102-4b8f-ad81-20a4ec3efaff,DISK], DatanodeInfoWithStorage[127.0.0.1:43777,DS-44844718-67ad-4594-a6ed-d6096fa0da12,DISK], DatanodeInfoWithStorage[127.0.0.1:38418,DS-89d61748-faa2-4996-9860-d237ec4eb0ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35337,DS-a2fe281b-d8ec-477c-a8ff-c2aff5f3f2a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43978,DS-ca4d95ea-dbb8-4835-a71f-f8f095736f6a,DISK], DatanodeInfoWithStorage[127.0.0.1:45449,DS-38888e97-698b-4356-b6e2-f92451546d89,DISK], DatanodeInfoWithStorage[127.0.0.1:38690,DS-43a610fb-7f63-49bc-b845-b31261e60bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:44742,DS-4684fe70-6a04-477e-86df-3d3dd0560365,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-994284987-172.17.0.19-1596945765041:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38741,DS-0fc8aa45-5102-4b8f-ad81-20a4ec3efaff,DISK], DatanodeInfoWithStorage[127.0.0.1:43777,DS-44844718-67ad-4594-a6ed-d6096fa0da12,DISK], DatanodeInfoWithStorage[127.0.0.1:38418,DS-89d61748-faa2-4996-9860-d237ec4eb0ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35337,DS-a2fe281b-d8ec-477c-a8ff-c2aff5f3f2a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43978,DS-ca4d95ea-dbb8-4835-a71f-f8f095736f6a,DISK], DatanodeInfoWithStorage[127.0.0.1:45449,DS-38888e97-698b-4356-b6e2-f92451546d89,DISK], DatanodeInfoWithStorage[127.0.0.1:38690,DS-43a610fb-7f63-49bc-b845-b31261e60bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:44742,DS-4684fe70-6a04-477e-86df-3d3dd0560365,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-779251094-172.17.0.19-1596946170339:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45270,DS-da969387-67d1-4d63-90b5-2bddfffdf82e,DISK], DatanodeInfoWithStorage[127.0.0.1:37448,DS-5f7f5973-aa95-4ae6-b117-74d8c10c1318,DISK], DatanodeInfoWithStorage[127.0.0.1:41648,DS-02f9f8e2-fc05-42ce-b320-70c7b06d928f,DISK], DatanodeInfoWithStorage[127.0.0.1:35690,DS-6628ea48-4fa5-470a-a8b9-a76fd0afed12,DISK], DatanodeInfoWithStorage[127.0.0.1:37648,DS-ef990fe5-2f64-4210-80bf-554e3f113638,DISK], DatanodeInfoWithStorage[127.0.0.1:33392,DS-f4497bb6-83b0-41c8-8ce1-a896d1b4c0da,DISK], DatanodeInfoWithStorage[127.0.0.1:39445,DS-65e14c11-4ecf-4f98-afd9-cef1ea64072f,DISK], DatanodeInfoWithStorage[127.0.0.1:36144,DS-e0702dad-ba80-4567-9bfa-ac323f8c0d7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-779251094-172.17.0.19-1596946170339:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45270,DS-da969387-67d1-4d63-90b5-2bddfffdf82e,DISK], DatanodeInfoWithStorage[127.0.0.1:37448,DS-5f7f5973-aa95-4ae6-b117-74d8c10c1318,DISK], DatanodeInfoWithStorage[127.0.0.1:41648,DS-02f9f8e2-fc05-42ce-b320-70c7b06d928f,DISK], DatanodeInfoWithStorage[127.0.0.1:35690,DS-6628ea48-4fa5-470a-a8b9-a76fd0afed12,DISK], DatanodeInfoWithStorage[127.0.0.1:37648,DS-ef990fe5-2f64-4210-80bf-554e3f113638,DISK], DatanodeInfoWithStorage[127.0.0.1:33392,DS-f4497bb6-83b0-41c8-8ce1-a896d1b4c0da,DISK], DatanodeInfoWithStorage[127.0.0.1:39445,DS-65e14c11-4ecf-4f98-afd9-cef1ea64072f,DISK], DatanodeInfoWithStorage[127.0.0.1:36144,DS-e0702dad-ba80-4567-9bfa-ac323f8c0d7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1861670702-172.17.0.19-1596946514215:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34068,DS-16ced247-f6f1-49c8-9c87-729bf72a8de4,DISK], DatanodeInfoWithStorage[127.0.0.1:35098,DS-a0a3ac75-309c-4755-8d07-bd619df7db66,DISK], DatanodeInfoWithStorage[127.0.0.1:45227,DS-cfc13988-f9b6-4ce4-af1b-93447c58626f,DISK], DatanodeInfoWithStorage[127.0.0.1:43721,DS-b36dab63-10a9-4ba2-97bd-2403cfa2ab76,DISK], DatanodeInfoWithStorage[127.0.0.1:43043,DS-f0b5c737-1e47-47c5-b1c1-d58079313c1d,DISK], DatanodeInfoWithStorage[127.0.0.1:39221,DS-f038bfe0-6523-4a97-a292-a7c3ab6965a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46489,DS-69d2b6bd-4e47-4ef1-98fe-658ee9e361f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38328,DS-783d9acf-4204-48d4-b696-ebd1539cc0f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1861670702-172.17.0.19-1596946514215:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34068,DS-16ced247-f6f1-49c8-9c87-729bf72a8de4,DISK], DatanodeInfoWithStorage[127.0.0.1:35098,DS-a0a3ac75-309c-4755-8d07-bd619df7db66,DISK], DatanodeInfoWithStorage[127.0.0.1:45227,DS-cfc13988-f9b6-4ce4-af1b-93447c58626f,DISK], DatanodeInfoWithStorage[127.0.0.1:43721,DS-b36dab63-10a9-4ba2-97bd-2403cfa2ab76,DISK], DatanodeInfoWithStorage[127.0.0.1:43043,DS-f0b5c737-1e47-47c5-b1c1-d58079313c1d,DISK], DatanodeInfoWithStorage[127.0.0.1:39221,DS-f038bfe0-6523-4a97-a292-a7c3ab6965a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46489,DS-69d2b6bd-4e47-4ef1-98fe-658ee9e361f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38328,DS-783d9acf-4204-48d4-b696-ebd1539cc0f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1570636721-172.17.0.19-1596946584177:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33828,DS-c50d7273-f416-4703-8b8e-ea14f9a8c210,DISK], DatanodeInfoWithStorage[127.0.0.1:40986,DS-749005b0-eadf-4988-8b35-3498ec35dcc2,DISK], DatanodeInfoWithStorage[127.0.0.1:34089,DS-3f188ebf-dd92-4c01-acb7-85409c64226c,DISK], DatanodeInfoWithStorage[127.0.0.1:46793,DS-94aa6979-766e-4c7a-8916-c04a6c612381,DISK], DatanodeInfoWithStorage[127.0.0.1:33585,DS-467ec32b-993d-4ba0-bbcd-550067062a0c,DISK], DatanodeInfoWithStorage[127.0.0.1:42807,DS-c8955322-a189-4847-a71d-3f352d110e99,DISK], DatanodeInfoWithStorage[127.0.0.1:37382,DS-39aa092f-3b07-4589-a393-f19633a9c4df,DISK], DatanodeInfoWithStorage[127.0.0.1:45592,DS-eb17a88c-5806-4508-91b4-fe9d5308c392,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1570636721-172.17.0.19-1596946584177:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33828,DS-c50d7273-f416-4703-8b8e-ea14f9a8c210,DISK], DatanodeInfoWithStorage[127.0.0.1:40986,DS-749005b0-eadf-4988-8b35-3498ec35dcc2,DISK], DatanodeInfoWithStorage[127.0.0.1:34089,DS-3f188ebf-dd92-4c01-acb7-85409c64226c,DISK], DatanodeInfoWithStorage[127.0.0.1:46793,DS-94aa6979-766e-4c7a-8916-c04a6c612381,DISK], DatanodeInfoWithStorage[127.0.0.1:33585,DS-467ec32b-993d-4ba0-bbcd-550067062a0c,DISK], DatanodeInfoWithStorage[127.0.0.1:42807,DS-c8955322-a189-4847-a71d-3f352d110e99,DISK], DatanodeInfoWithStorage[127.0.0.1:37382,DS-39aa092f-3b07-4589-a393-f19633a9c4df,DISK], DatanodeInfoWithStorage[127.0.0.1:45592,DS-eb17a88c-5806-4508-91b4-fe9d5308c392,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-400280395-172.17.0.19-1596946939531:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36493,DS-1dd57546-75d9-40b1-af8b-a9c287bab228,DISK], DatanodeInfoWithStorage[127.0.0.1:36175,DS-cfc95993-9a84-4ded-87af-70335e7f52a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42222,DS-5f10ce07-bd57-4088-93f5-d8bacb19604d,DISK], DatanodeInfoWithStorage[127.0.0.1:33960,DS-65f0f5e6-e572-41d5-8e52-b0b73a1c30cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40196,DS-ddd3de80-6202-4b4c-b6fa-1c6d8f13136c,DISK], DatanodeInfoWithStorage[127.0.0.1:46468,DS-c00d109d-89a4-4b3b-bdba-8e5609cab54b,DISK], DatanodeInfoWithStorage[127.0.0.1:42953,DS-7daf10ab-e52b-434a-b65f-a4ea29efa104,DISK], DatanodeInfoWithStorage[127.0.0.1:37202,DS-85373900-41f0-4d50-b4b7-8bf9466404c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-400280395-172.17.0.19-1596946939531:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36493,DS-1dd57546-75d9-40b1-af8b-a9c287bab228,DISK], DatanodeInfoWithStorage[127.0.0.1:36175,DS-cfc95993-9a84-4ded-87af-70335e7f52a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42222,DS-5f10ce07-bd57-4088-93f5-d8bacb19604d,DISK], DatanodeInfoWithStorage[127.0.0.1:33960,DS-65f0f5e6-e572-41d5-8e52-b0b73a1c30cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40196,DS-ddd3de80-6202-4b4c-b6fa-1c6d8f13136c,DISK], DatanodeInfoWithStorage[127.0.0.1:46468,DS-c00d109d-89a4-4b3b-bdba-8e5609cab54b,DISK], DatanodeInfoWithStorage[127.0.0.1:42953,DS-7daf10ab-e52b-434a-b65f-a4ea29efa104,DISK], DatanodeInfoWithStorage[127.0.0.1:37202,DS-85373900-41f0-4d50-b4b7-8bf9466404c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-170153084-172.17.0.19-1596947154524:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35065,DS-108675d2-348f-4a76-a826-c4ebbe5585e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37159,DS-1dc2e9e4-ac58-4e12-9eb5-85c18df4b479,DISK], DatanodeInfoWithStorage[127.0.0.1:42627,DS-ec4b1a53-a3d1-4f04-a125-178f4e1c8dad,DISK], DatanodeInfoWithStorage[127.0.0.1:36433,DS-08b09c73-751a-4e8c-8e97-3e2ac1379d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:38947,DS-8cb796bf-3455-4505-82c7-91c3e91f8a28,DISK], DatanodeInfoWithStorage[127.0.0.1:40499,DS-2b3511fa-a33c-41a8-b41f-bf3b45e996c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41938,DS-53fbe4f6-8b18-4d30-a751-866cfd2df3fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42551,DS-8e9b1a18-fd18-4042-9877-5d3b2450862c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-170153084-172.17.0.19-1596947154524:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35065,DS-108675d2-348f-4a76-a826-c4ebbe5585e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37159,DS-1dc2e9e4-ac58-4e12-9eb5-85c18df4b479,DISK], DatanodeInfoWithStorage[127.0.0.1:42627,DS-ec4b1a53-a3d1-4f04-a125-178f4e1c8dad,DISK], DatanodeInfoWithStorage[127.0.0.1:36433,DS-08b09c73-751a-4e8c-8e97-3e2ac1379d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:38947,DS-8cb796bf-3455-4505-82c7-91c3e91f8a28,DISK], DatanodeInfoWithStorage[127.0.0.1:40499,DS-2b3511fa-a33c-41a8-b41f-bf3b45e996c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41938,DS-53fbe4f6-8b18-4d30-a751-866cfd2df3fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42551,DS-8e9b1a18-fd18-4042-9877-5d3b2450862c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-221257498-172.17.0.19-1596947230673:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45172,DS-05772f50-86b0-4cff-b400-c8caee822538,DISK], DatanodeInfoWithStorage[127.0.0.1:42628,DS-34fa98eb-386a-4977-87cd-39c78f5909ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43472,DS-8ab64ceb-ed09-44a1-9fb5-3e46c6199606,DISK], DatanodeInfoWithStorage[127.0.0.1:36981,DS-77363fb2-e243-442d-b157-cb9a979cc783,DISK], DatanodeInfoWithStorage[127.0.0.1:46763,DS-cfd7ca60-03eb-4f73-be3a-72e137083764,DISK], DatanodeInfoWithStorage[127.0.0.1:36997,DS-17c4278a-5633-4c1f-9c5c-2e5f973e53d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35296,DS-72ebffc4-af82-46ec-9a48-87188fee18aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40765,DS-5f19172c-e0f4-4fea-8dd0-b4fac830ad88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-221257498-172.17.0.19-1596947230673:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45172,DS-05772f50-86b0-4cff-b400-c8caee822538,DISK], DatanodeInfoWithStorage[127.0.0.1:42628,DS-34fa98eb-386a-4977-87cd-39c78f5909ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43472,DS-8ab64ceb-ed09-44a1-9fb5-3e46c6199606,DISK], DatanodeInfoWithStorage[127.0.0.1:36981,DS-77363fb2-e243-442d-b157-cb9a979cc783,DISK], DatanodeInfoWithStorage[127.0.0.1:46763,DS-cfd7ca60-03eb-4f73-be3a-72e137083764,DISK], DatanodeInfoWithStorage[127.0.0.1:36997,DS-17c4278a-5633-4c1f-9c5c-2e5f973e53d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35296,DS-72ebffc4-af82-46ec-9a48-87188fee18aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40765,DS-5f19172c-e0f4-4fea-8dd0-b4fac830ad88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1313887293-172.17.0.19-1596947524480:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37903,DS-ebfcd019-412a-44e5-b2ab-8f0b49da94e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41284,DS-8568ba2c-d821-4c0a-b10b-12bffa189544,DISK], DatanodeInfoWithStorage[127.0.0.1:33157,DS-defb0da9-57d3-4f4b-8922-8a9d6bdeac7d,DISK], DatanodeInfoWithStorage[127.0.0.1:34718,DS-e8c39d60-092c-4b90-a521-5cb492aea312,DISK], DatanodeInfoWithStorage[127.0.0.1:46317,DS-6b1c4643-2d60-48a4-a7d5-f54e051dc55a,DISK], DatanodeInfoWithStorage[127.0.0.1:37269,DS-c02da489-be56-4637-b77d-3bd2836c4495,DISK], DatanodeInfoWithStorage[127.0.0.1:43605,DS-70c48341-4ea2-4031-9d6a-0135fa4cf060,DISK], DatanodeInfoWithStorage[127.0.0.1:37870,DS-aa4b7012-bcb8-4459-b66b-d02897a23d2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1313887293-172.17.0.19-1596947524480:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37903,DS-ebfcd019-412a-44e5-b2ab-8f0b49da94e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41284,DS-8568ba2c-d821-4c0a-b10b-12bffa189544,DISK], DatanodeInfoWithStorage[127.0.0.1:33157,DS-defb0da9-57d3-4f4b-8922-8a9d6bdeac7d,DISK], DatanodeInfoWithStorage[127.0.0.1:34718,DS-e8c39d60-092c-4b90-a521-5cb492aea312,DISK], DatanodeInfoWithStorage[127.0.0.1:46317,DS-6b1c4643-2d60-48a4-a7d5-f54e051dc55a,DISK], DatanodeInfoWithStorage[127.0.0.1:37269,DS-c02da489-be56-4637-b77d-3bd2836c4495,DISK], DatanodeInfoWithStorage[127.0.0.1:43605,DS-70c48341-4ea2-4031-9d6a-0135fa4cf060,DISK], DatanodeInfoWithStorage[127.0.0.1:37870,DS-aa4b7012-bcb8-4459-b66b-d02897a23d2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-885785996-172.17.0.19-1596947921718:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44664,DS-3a521862-639f-4d2e-a892-ac7dacf45abc,DISK], DatanodeInfoWithStorage[127.0.0.1:33581,DS-9a215ae7-75e8-4d3a-904f-9428fe112da6,DISK], DatanodeInfoWithStorage[127.0.0.1:43732,DS-f0182637-ec9f-4c16-b14e-2ef74f8f6ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:36585,DS-6e298d80-6069-4975-8ed2-a8e8732e72ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33680,DS-19997f13-081c-4153-a233-3e4aa65b5023,DISK], DatanodeInfoWithStorage[127.0.0.1:33132,DS-7cccab18-abb4-4424-9b86-e862bae5457f,DISK], DatanodeInfoWithStorage[127.0.0.1:33392,DS-0314e897-eb34-451e-94c3-3bc4294bcf4f,DISK], DatanodeInfoWithStorage[127.0.0.1:38966,DS-da74cd6a-e389-4425-b00e-a59e423e9162,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-885785996-172.17.0.19-1596947921718:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44664,DS-3a521862-639f-4d2e-a892-ac7dacf45abc,DISK], DatanodeInfoWithStorage[127.0.0.1:33581,DS-9a215ae7-75e8-4d3a-904f-9428fe112da6,DISK], DatanodeInfoWithStorage[127.0.0.1:43732,DS-f0182637-ec9f-4c16-b14e-2ef74f8f6ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:36585,DS-6e298d80-6069-4975-8ed2-a8e8732e72ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33680,DS-19997f13-081c-4153-a233-3e4aa65b5023,DISK], DatanodeInfoWithStorage[127.0.0.1:33132,DS-7cccab18-abb4-4424-9b86-e862bae5457f,DISK], DatanodeInfoWithStorage[127.0.0.1:33392,DS-0314e897-eb34-451e-94c3-3bc4294bcf4f,DISK], DatanodeInfoWithStorage[127.0.0.1:38966,DS-da74cd6a-e389-4425-b00e-a59e423e9162,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-347177753-172.17.0.19-1596947949788:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43598,DS-282cb8d0-8734-4e57-9d1b-353863e3bf11,DISK], DatanodeInfoWithStorage[127.0.0.1:37883,DS-5938ceef-4579-4ff2-8857-3ac4ec95e85f,DISK], DatanodeInfoWithStorage[127.0.0.1:39852,DS-6d248078-520e-4061-9d77-86967975d158,DISK], DatanodeInfoWithStorage[127.0.0.1:39407,DS-bf31a3ee-a866-4d89-8d4d-de50adc34f4a,DISK], DatanodeInfoWithStorage[127.0.0.1:46056,DS-1e8b1667-580e-4ae8-a8f6-9c5bf44c1358,DISK], DatanodeInfoWithStorage[127.0.0.1:39518,DS-9d514996-26d5-4356-b80d-7f3c7e7917c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41648,DS-a7ed5068-c65e-4431-8218-b0db3afad9d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38724,DS-a0a93db8-8db2-4782-b39c-c0ee1e0b755d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-347177753-172.17.0.19-1596947949788:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43598,DS-282cb8d0-8734-4e57-9d1b-353863e3bf11,DISK], DatanodeInfoWithStorage[127.0.0.1:37883,DS-5938ceef-4579-4ff2-8857-3ac4ec95e85f,DISK], DatanodeInfoWithStorage[127.0.0.1:39852,DS-6d248078-520e-4061-9d77-86967975d158,DISK], DatanodeInfoWithStorage[127.0.0.1:39407,DS-bf31a3ee-a866-4d89-8d4d-de50adc34f4a,DISK], DatanodeInfoWithStorage[127.0.0.1:46056,DS-1e8b1667-580e-4ae8-a8f6-9c5bf44c1358,DISK], DatanodeInfoWithStorage[127.0.0.1:39518,DS-9d514996-26d5-4356-b80d-7f3c7e7917c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41648,DS-a7ed5068-c65e-4431-8218-b0db3afad9d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38724,DS-a0a93db8-8db2-4782-b39c-c0ee1e0b755d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1797367040-172.17.0.19-1596948391807:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44979,DS-30172ef6-52f3-40eb-a173-03e3ee6e5650,DISK], DatanodeInfoWithStorage[127.0.0.1:35698,DS-11ea382e-3a69-4dd2-877b-54cb1b44e2b9,DISK], DatanodeInfoWithStorage[127.0.0.1:40519,DS-5bf739fc-74a5-423a-9bb5-6e7bfe46d4c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46284,DS-8ac2af44-cddd-4fe5-82b1-2207c7ccc5b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38608,DS-8b517cce-e7ad-4a01-af4a-296cda3bbed3,DISK], DatanodeInfoWithStorage[127.0.0.1:44365,DS-30aefd40-6fcd-49cb-b047-46c80bf55e48,DISK], DatanodeInfoWithStorage[127.0.0.1:42214,DS-bd06d3f2-438d-4c2b-aa80-c6a50cc00fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:33904,DS-c149f9a5-8003-48af-9555-89c90cfaea71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1797367040-172.17.0.19-1596948391807:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44979,DS-30172ef6-52f3-40eb-a173-03e3ee6e5650,DISK], DatanodeInfoWithStorage[127.0.0.1:35698,DS-11ea382e-3a69-4dd2-877b-54cb1b44e2b9,DISK], DatanodeInfoWithStorage[127.0.0.1:40519,DS-5bf739fc-74a5-423a-9bb5-6e7bfe46d4c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46284,DS-8ac2af44-cddd-4fe5-82b1-2207c7ccc5b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38608,DS-8b517cce-e7ad-4a01-af4a-296cda3bbed3,DISK], DatanodeInfoWithStorage[127.0.0.1:44365,DS-30aefd40-6fcd-49cb-b047-46c80bf55e48,DISK], DatanodeInfoWithStorage[127.0.0.1:42214,DS-bd06d3f2-438d-4c2b-aa80-c6a50cc00fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:33904,DS-c149f9a5-8003-48af-9555-89c90cfaea71,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5453
