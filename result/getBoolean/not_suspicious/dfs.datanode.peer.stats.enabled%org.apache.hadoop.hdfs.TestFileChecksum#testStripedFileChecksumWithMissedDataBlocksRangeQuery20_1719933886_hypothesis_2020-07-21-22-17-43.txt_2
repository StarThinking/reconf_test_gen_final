reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1649992919-172.17.0.6-1595370097737:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37747,DS-708fa126-abe1-4414-9b90-3182fbf8e772,DISK], DatanodeInfoWithStorage[127.0.0.1:45791,DS-7bc06960-3013-47a9-8a01-ebf540a6847a,DISK], DatanodeInfoWithStorage[127.0.0.1:33517,DS-cdc8ad8b-f1da-46f9-8315-8ff751d17a86,DISK], DatanodeInfoWithStorage[127.0.0.1:42804,DS-a76d34f5-4c31-46d3-8f8a-936f9c4237d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46455,DS-a50ef860-fe6e-486b-9534-e39d37cbc7ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42073,DS-26abbb44-7171-47fa-bd0c-ec9ac299c0be,DISK], DatanodeInfoWithStorage[127.0.0.1:38715,DS-5f2d1139-0eb6-4c7c-90c2-2df53167f5c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45705,DS-47d2a0e4-5eb0-4ca9-8ba1-375806609518,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1649992919-172.17.0.6-1595370097737:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37747,DS-708fa126-abe1-4414-9b90-3182fbf8e772,DISK], DatanodeInfoWithStorage[127.0.0.1:45791,DS-7bc06960-3013-47a9-8a01-ebf540a6847a,DISK], DatanodeInfoWithStorage[127.0.0.1:33517,DS-cdc8ad8b-f1da-46f9-8315-8ff751d17a86,DISK], DatanodeInfoWithStorage[127.0.0.1:42804,DS-a76d34f5-4c31-46d3-8f8a-936f9c4237d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46455,DS-a50ef860-fe6e-486b-9534-e39d37cbc7ff,DISK], DatanodeInfoWithStorage[127.0.0.1:42073,DS-26abbb44-7171-47fa-bd0c-ec9ac299c0be,DISK], DatanodeInfoWithStorage[127.0.0.1:38715,DS-5f2d1139-0eb6-4c7c-90c2-2df53167f5c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45705,DS-47d2a0e4-5eb0-4ca9-8ba1-375806609518,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1953934106-172.17.0.6-1595370770055:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38116,DS-f623be2d-8c9f-45e9-9382-a3e0647a6866,DISK], DatanodeInfoWithStorage[127.0.0.1:36313,DS-23039856-a443-496b-b518-dc0a11f7b516,DISK], DatanodeInfoWithStorage[127.0.0.1:43126,DS-f7f30653-04b6-466a-99d5-0e1eb6f36d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:36731,DS-f71e60bb-c551-49c0-a180-dedaf599e5f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42336,DS-e7374ae0-423c-4d6a-9cee-537db60ad974,DISK], DatanodeInfoWithStorage[127.0.0.1:35329,DS-c707f15f-f450-4628-a9f0-0c4f1d22096b,DISK], DatanodeInfoWithStorage[127.0.0.1:46719,DS-aec73ecb-69e6-4a74-bdb2-0a271f3cf360,DISK], DatanodeInfoWithStorage[127.0.0.1:41811,DS-f3578902-c6bc-4fb1-9867-dc5c08a21e1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1953934106-172.17.0.6-1595370770055:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38116,DS-f623be2d-8c9f-45e9-9382-a3e0647a6866,DISK], DatanodeInfoWithStorage[127.0.0.1:36313,DS-23039856-a443-496b-b518-dc0a11f7b516,DISK], DatanodeInfoWithStorage[127.0.0.1:43126,DS-f7f30653-04b6-466a-99d5-0e1eb6f36d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:36731,DS-f71e60bb-c551-49c0-a180-dedaf599e5f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42336,DS-e7374ae0-423c-4d6a-9cee-537db60ad974,DISK], DatanodeInfoWithStorage[127.0.0.1:35329,DS-c707f15f-f450-4628-a9f0-0c4f1d22096b,DISK], DatanodeInfoWithStorage[127.0.0.1:46719,DS-aec73ecb-69e6-4a74-bdb2-0a271f3cf360,DISK], DatanodeInfoWithStorage[127.0.0.1:41811,DS-f3578902-c6bc-4fb1-9867-dc5c08a21e1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-601296108-172.17.0.6-1595371347228:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42395,DS-e0da2d56-2b05-44c7-98c6-84506c417b09,DISK], DatanodeInfoWithStorage[127.0.0.1:45412,DS-51245e22-a88d-4ba5-9b40-d442f1b963ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43034,DS-c453e3ac-71ef-4f0e-85d5-b0a8e0bab5c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46762,DS-0cbb5466-c813-436c-870e-9c821b26cc13,DISK], DatanodeInfoWithStorage[127.0.0.1:39370,DS-6ed09461-edca-4e65-bdba-6ee3d903bd25,DISK], DatanodeInfoWithStorage[127.0.0.1:38431,DS-66316762-2d6f-44b5-a891-e468b94d2dc4,DISK], DatanodeInfoWithStorage[127.0.0.1:43121,DS-c7c7867e-6229-41b7-a6aa-a8acccac752d,DISK], DatanodeInfoWithStorage[127.0.0.1:34264,DS-71222be1-53d6-4ae6-bfa5-1245fcf8fe15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-601296108-172.17.0.6-1595371347228:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42395,DS-e0da2d56-2b05-44c7-98c6-84506c417b09,DISK], DatanodeInfoWithStorage[127.0.0.1:45412,DS-51245e22-a88d-4ba5-9b40-d442f1b963ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43034,DS-c453e3ac-71ef-4f0e-85d5-b0a8e0bab5c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46762,DS-0cbb5466-c813-436c-870e-9c821b26cc13,DISK], DatanodeInfoWithStorage[127.0.0.1:39370,DS-6ed09461-edca-4e65-bdba-6ee3d903bd25,DISK], DatanodeInfoWithStorage[127.0.0.1:38431,DS-66316762-2d6f-44b5-a891-e468b94d2dc4,DISK], DatanodeInfoWithStorage[127.0.0.1:43121,DS-c7c7867e-6229-41b7-a6aa-a8acccac752d,DISK], DatanodeInfoWithStorage[127.0.0.1:34264,DS-71222be1-53d6-4ae6-bfa5-1245fcf8fe15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1544905120-172.17.0.6-1595371471283:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35726,DS-6b2d8519-2e51-41e5-b15f-78c7a8a3baa1,DISK], DatanodeInfoWithStorage[127.0.0.1:36885,DS-ad1231b4-ae00-42e5-a713-fb2a32a8da29,DISK], DatanodeInfoWithStorage[127.0.0.1:43908,DS-67785198-3bcc-4b9b-8db6-935bd56607ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33347,DS-70c6b65f-3954-48bb-8753-b1e89fa81995,DISK], DatanodeInfoWithStorage[127.0.0.1:46375,DS-df527931-5c99-4a35-b4b1-57670421000a,DISK], DatanodeInfoWithStorage[127.0.0.1:38975,DS-a732ace9-760c-44b0-8d2d-6e47cc804288,DISK], DatanodeInfoWithStorage[127.0.0.1:35190,DS-230d1a15-30d3-4d98-b0ad-82a10f005f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:43349,DS-61f1712a-8898-482d-881b-35410a6374d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1544905120-172.17.0.6-1595371471283:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35726,DS-6b2d8519-2e51-41e5-b15f-78c7a8a3baa1,DISK], DatanodeInfoWithStorage[127.0.0.1:36885,DS-ad1231b4-ae00-42e5-a713-fb2a32a8da29,DISK], DatanodeInfoWithStorage[127.0.0.1:43908,DS-67785198-3bcc-4b9b-8db6-935bd56607ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33347,DS-70c6b65f-3954-48bb-8753-b1e89fa81995,DISK], DatanodeInfoWithStorage[127.0.0.1:46375,DS-df527931-5c99-4a35-b4b1-57670421000a,DISK], DatanodeInfoWithStorage[127.0.0.1:38975,DS-a732ace9-760c-44b0-8d2d-6e47cc804288,DISK], DatanodeInfoWithStorage[127.0.0.1:35190,DS-230d1a15-30d3-4d98-b0ad-82a10f005f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:43349,DS-61f1712a-8898-482d-881b-35410a6374d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-421512061-172.17.0.6-1595371773021:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41235,DS-21c4c6bb-1e7f-417a-a751-227a6524f0ac,DISK], DatanodeInfoWithStorage[127.0.0.1:33674,DS-db320f6a-8b47-4df8-aa9e-5e61a394f5e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46739,DS-76a4d10b-68fb-405a-8998-34519aeeb018,DISK], DatanodeInfoWithStorage[127.0.0.1:44224,DS-b4cce7f7-ee0f-4989-909e-b36320a6d240,DISK], DatanodeInfoWithStorage[127.0.0.1:46733,DS-99eb4e0c-70f9-4b09-8a75-03f95b00d1d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40011,DS-aaa8dd3f-7389-4ab2-83eb-ff6a9f931afa,DISK], DatanodeInfoWithStorage[127.0.0.1:40773,DS-a2f438b0-8d88-4fbe-9e58-706d373fdab2,DISK], DatanodeInfoWithStorage[127.0.0.1:35581,DS-08bdd19f-21c2-4f3c-993f-7eec6fd29c8f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-421512061-172.17.0.6-1595371773021:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41235,DS-21c4c6bb-1e7f-417a-a751-227a6524f0ac,DISK], DatanodeInfoWithStorage[127.0.0.1:33674,DS-db320f6a-8b47-4df8-aa9e-5e61a394f5e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46739,DS-76a4d10b-68fb-405a-8998-34519aeeb018,DISK], DatanodeInfoWithStorage[127.0.0.1:44224,DS-b4cce7f7-ee0f-4989-909e-b36320a6d240,DISK], DatanodeInfoWithStorage[127.0.0.1:46733,DS-99eb4e0c-70f9-4b09-8a75-03f95b00d1d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40011,DS-aaa8dd3f-7389-4ab2-83eb-ff6a9f931afa,DISK], DatanodeInfoWithStorage[127.0.0.1:40773,DS-a2f438b0-8d88-4fbe-9e58-706d373fdab2,DISK], DatanodeInfoWithStorage[127.0.0.1:35581,DS-08bdd19f-21c2-4f3c-993f-7eec6fd29c8f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1424252363-172.17.0.6-1595371991728:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44088,DS-85a40062-c813-46c8-977e-d1ab09383e67,DISK], DatanodeInfoWithStorage[127.0.0.1:33378,DS-d7e14e8d-e174-4d14-9e79-1a2d0a03d935,DISK], DatanodeInfoWithStorage[127.0.0.1:39383,DS-a2398c1d-55b0-4a56-a480-342c20f286fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37870,DS-5ea8885b-5333-45a0-a0e1-03926484283a,DISK], DatanodeInfoWithStorage[127.0.0.1:40576,DS-e47e9dc6-65ea-4e2f-9b33-9784e11bf738,DISK], DatanodeInfoWithStorage[127.0.0.1:45321,DS-3471d098-6d42-4fd8-b6d5-575babf17541,DISK], DatanodeInfoWithStorage[127.0.0.1:36781,DS-a23c191d-18cf-4d10-a986-b54708eee156,DISK], DatanodeInfoWithStorage[127.0.0.1:37159,DS-7856d017-5436-4f51-94d4-4ccdef83cf57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1424252363-172.17.0.6-1595371991728:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44088,DS-85a40062-c813-46c8-977e-d1ab09383e67,DISK], DatanodeInfoWithStorage[127.0.0.1:33378,DS-d7e14e8d-e174-4d14-9e79-1a2d0a03d935,DISK], DatanodeInfoWithStorage[127.0.0.1:39383,DS-a2398c1d-55b0-4a56-a480-342c20f286fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37870,DS-5ea8885b-5333-45a0-a0e1-03926484283a,DISK], DatanodeInfoWithStorage[127.0.0.1:40576,DS-e47e9dc6-65ea-4e2f-9b33-9784e11bf738,DISK], DatanodeInfoWithStorage[127.0.0.1:45321,DS-3471d098-6d42-4fd8-b6d5-575babf17541,DISK], DatanodeInfoWithStorage[127.0.0.1:36781,DS-a23c191d-18cf-4d10-a986-b54708eee156,DISK], DatanodeInfoWithStorage[127.0.0.1:37159,DS-7856d017-5436-4f51-94d4-4ccdef83cf57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-199617000-172.17.0.6-1595372830106:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40294,DS-d7dc80d4-cfec-40b9-a970-7eb6f8297f09,DISK], DatanodeInfoWithStorage[127.0.0.1:44970,DS-e891120f-fe9d-47f2-a671-b41f77981d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:36237,DS-2b4f94bb-09ff-43ce-9087-b0b69302e8d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40968,DS-2f882d65-5551-45b7-8c67-379f79aca7be,DISK], DatanodeInfoWithStorage[127.0.0.1:41669,DS-63be4505-a9d9-494f-8ef6-30041fc76b8b,DISK], DatanodeInfoWithStorage[127.0.0.1:33057,DS-e31e03f2-1c38-4850-83e9-7da510b5ada8,DISK], DatanodeInfoWithStorage[127.0.0.1:37052,DS-9f647bad-ef54-4b3d-a3c2-26867e0cf082,DISK], DatanodeInfoWithStorage[127.0.0.1:36062,DS-746ae152-e92e-4edf-bd5e-68849d8476ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-199617000-172.17.0.6-1595372830106:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40294,DS-d7dc80d4-cfec-40b9-a970-7eb6f8297f09,DISK], DatanodeInfoWithStorage[127.0.0.1:44970,DS-e891120f-fe9d-47f2-a671-b41f77981d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:36237,DS-2b4f94bb-09ff-43ce-9087-b0b69302e8d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40968,DS-2f882d65-5551-45b7-8c67-379f79aca7be,DISK], DatanodeInfoWithStorage[127.0.0.1:41669,DS-63be4505-a9d9-494f-8ef6-30041fc76b8b,DISK], DatanodeInfoWithStorage[127.0.0.1:33057,DS-e31e03f2-1c38-4850-83e9-7da510b5ada8,DISK], DatanodeInfoWithStorage[127.0.0.1:37052,DS-9f647bad-ef54-4b3d-a3c2-26867e0cf082,DISK], DatanodeInfoWithStorage[127.0.0.1:36062,DS-746ae152-e92e-4edf-bd5e-68849d8476ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-879783159-172.17.0.6-1595374112156:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46812,DS-7ec58abd-1add-4cfe-bd45-eac9a2d018eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36658,DS-ccb0d612-e5f1-4cb9-ae68-76dab418e5c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39604,DS-4fa931ff-c401-4efc-a812-9f749e6eb01f,DISK], DatanodeInfoWithStorage[127.0.0.1:34895,DS-5dad5b66-9b70-4c82-b5b1-60709088f142,DISK], DatanodeInfoWithStorage[127.0.0.1:46224,DS-3a5d82f3-9e0b-45f5-8abb-970ce156adc7,DISK], DatanodeInfoWithStorage[127.0.0.1:36883,DS-59406bbd-2555-4bf3-a604-d3984c57d0eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44656,DS-4fbe0261-5e1d-4dc2-96e1-fb6663276550,DISK], DatanodeInfoWithStorage[127.0.0.1:40400,DS-f822c29d-10be-4ce4-baa0-495de69514df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-879783159-172.17.0.6-1595374112156:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46812,DS-7ec58abd-1add-4cfe-bd45-eac9a2d018eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36658,DS-ccb0d612-e5f1-4cb9-ae68-76dab418e5c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39604,DS-4fa931ff-c401-4efc-a812-9f749e6eb01f,DISK], DatanodeInfoWithStorage[127.0.0.1:34895,DS-5dad5b66-9b70-4c82-b5b1-60709088f142,DISK], DatanodeInfoWithStorage[127.0.0.1:46224,DS-3a5d82f3-9e0b-45f5-8abb-970ce156adc7,DISK], DatanodeInfoWithStorage[127.0.0.1:36883,DS-59406bbd-2555-4bf3-a604-d3984c57d0eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44656,DS-4fbe0261-5e1d-4dc2-96e1-fb6663276550,DISK], DatanodeInfoWithStorage[127.0.0.1:40400,DS-f822c29d-10be-4ce4-baa0-495de69514df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1877090049-172.17.0.6-1595374661195:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38766,DS-071ae26f-99fa-4e7b-8e60-e9d45f7387e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34561,DS-67bc7e6f-bc54-40de-8347-6e1fb1252972,DISK], DatanodeInfoWithStorage[127.0.0.1:40614,DS-de2c1610-1153-4e27-a112-c8cec05fd1b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37969,DS-d911c4bc-5d04-485e-9fd1-66a3d829bf26,DISK], DatanodeInfoWithStorage[127.0.0.1:44665,DS-68d296bc-8024-48c1-9981-be42d548a002,DISK], DatanodeInfoWithStorage[127.0.0.1:41183,DS-e371a2b0-797c-4fc4-900f-4a0aa06efbbf,DISK], DatanodeInfoWithStorage[127.0.0.1:38748,DS-8113aee1-c7ad-4554-9353-702ba4c48fe6,DISK], DatanodeInfoWithStorage[127.0.0.1:38463,DS-de5e88fb-0bdb-4195-823f-bb7dd71b2752,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1877090049-172.17.0.6-1595374661195:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38766,DS-071ae26f-99fa-4e7b-8e60-e9d45f7387e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34561,DS-67bc7e6f-bc54-40de-8347-6e1fb1252972,DISK], DatanodeInfoWithStorage[127.0.0.1:40614,DS-de2c1610-1153-4e27-a112-c8cec05fd1b1,DISK], DatanodeInfoWithStorage[127.0.0.1:37969,DS-d911c4bc-5d04-485e-9fd1-66a3d829bf26,DISK], DatanodeInfoWithStorage[127.0.0.1:44665,DS-68d296bc-8024-48c1-9981-be42d548a002,DISK], DatanodeInfoWithStorage[127.0.0.1:41183,DS-e371a2b0-797c-4fc4-900f-4a0aa06efbbf,DISK], DatanodeInfoWithStorage[127.0.0.1:38748,DS-8113aee1-c7ad-4554-9353-702ba4c48fe6,DISK], DatanodeInfoWithStorage[127.0.0.1:38463,DS-de5e88fb-0bdb-4195-823f-bb7dd71b2752,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-653809323-172.17.0.6-1595375140542:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43687,DS-dc03a7de-713e-4e88-88ec-336f966bf976,DISK], DatanodeInfoWithStorage[127.0.0.1:40296,DS-1505fffb-4647-45f1-b627-5270bc347114,DISK], DatanodeInfoWithStorage[127.0.0.1:40999,DS-9a4bd052-c070-4a8a-9d5f-e22a88c8b319,DISK], DatanodeInfoWithStorage[127.0.0.1:33341,DS-b7b69269-cfa2-45f6-a8a0-18980dbe5252,DISK], DatanodeInfoWithStorage[127.0.0.1:37868,DS-06298fc9-c7dc-4db7-81ee-bd91a181eea3,DISK], DatanodeInfoWithStorage[127.0.0.1:34836,DS-7e997f07-30c8-42da-8fc2-825219ee8100,DISK], DatanodeInfoWithStorage[127.0.0.1:37885,DS-e3a56b92-80c1-432a-9df5-e63696a8d37f,DISK], DatanodeInfoWithStorage[127.0.0.1:44172,DS-c7f0ede1-fd39-49d6-bd9b-6964d0f8bbd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-653809323-172.17.0.6-1595375140542:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43687,DS-dc03a7de-713e-4e88-88ec-336f966bf976,DISK], DatanodeInfoWithStorage[127.0.0.1:40296,DS-1505fffb-4647-45f1-b627-5270bc347114,DISK], DatanodeInfoWithStorage[127.0.0.1:40999,DS-9a4bd052-c070-4a8a-9d5f-e22a88c8b319,DISK], DatanodeInfoWithStorage[127.0.0.1:33341,DS-b7b69269-cfa2-45f6-a8a0-18980dbe5252,DISK], DatanodeInfoWithStorage[127.0.0.1:37868,DS-06298fc9-c7dc-4db7-81ee-bd91a181eea3,DISK], DatanodeInfoWithStorage[127.0.0.1:34836,DS-7e997f07-30c8-42da-8fc2-825219ee8100,DISK], DatanodeInfoWithStorage[127.0.0.1:37885,DS-e3a56b92-80c1-432a-9df5-e63696a8d37f,DISK], DatanodeInfoWithStorage[127.0.0.1:44172,DS-c7f0ede1-fd39-49d6-bd9b-6964d0f8bbd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-280062512-172.17.0.6-1595375230001:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38799,DS-b5abe32e-7155-4914-8f5e-bd5ad2db52ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33717,DS-ba9df291-c2fc-4fe8-b311-33f095553c95,DISK], DatanodeInfoWithStorage[127.0.0.1:44167,DS-6a17c4af-4cb5-4df1-a0e2-f135ceb19a07,DISK], DatanodeInfoWithStorage[127.0.0.1:34824,DS-e6c336a0-af00-4805-9dce-ddd47fec361e,DISK], DatanodeInfoWithStorage[127.0.0.1:35562,DS-e060af21-8edf-4d4b-973b-d4dadc78649d,DISK], DatanodeInfoWithStorage[127.0.0.1:33308,DS-520ea357-73fd-4024-97dd-c45d3929e260,DISK], DatanodeInfoWithStorage[127.0.0.1:33288,DS-d0644ffc-4f79-41fb-b8d2-dadd0f18941e,DISK], DatanodeInfoWithStorage[127.0.0.1:37937,DS-919db2cd-a02b-4828-b7c8-5f9e3c31789f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-280062512-172.17.0.6-1595375230001:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38799,DS-b5abe32e-7155-4914-8f5e-bd5ad2db52ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33717,DS-ba9df291-c2fc-4fe8-b311-33f095553c95,DISK], DatanodeInfoWithStorage[127.0.0.1:44167,DS-6a17c4af-4cb5-4df1-a0e2-f135ceb19a07,DISK], DatanodeInfoWithStorage[127.0.0.1:34824,DS-e6c336a0-af00-4805-9dce-ddd47fec361e,DISK], DatanodeInfoWithStorage[127.0.0.1:35562,DS-e060af21-8edf-4d4b-973b-d4dadc78649d,DISK], DatanodeInfoWithStorage[127.0.0.1:33308,DS-520ea357-73fd-4024-97dd-c45d3929e260,DISK], DatanodeInfoWithStorage[127.0.0.1:33288,DS-d0644ffc-4f79-41fb-b8d2-dadd0f18941e,DISK], DatanodeInfoWithStorage[127.0.0.1:37937,DS-919db2cd-a02b-4828-b7c8-5f9e3c31789f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5530
