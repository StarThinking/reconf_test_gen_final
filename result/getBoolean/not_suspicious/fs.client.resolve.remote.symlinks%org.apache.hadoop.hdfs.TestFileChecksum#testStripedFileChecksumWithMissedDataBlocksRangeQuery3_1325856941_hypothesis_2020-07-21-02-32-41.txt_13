reconf_parameter: fs.client.resolve.remote.symlinks
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.client.resolve.remote.symlinks
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-166797001-172.17.0.12-1595298871474:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38532,DS-0c7d36b3-6907-436f-a591-d7808cc8a31c,DISK], DatanodeInfoWithStorage[127.0.0.1:40807,DS-be60406e-18cd-4995-8edb-488c1c2b37b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37004,DS-30853f20-b3e6-4803-b7e5-46f3ecf76111,DISK], DatanodeInfoWithStorage[127.0.0.1:46462,DS-76252c25-6715-4013-8d39-6c023f6b984b,DISK], DatanodeInfoWithStorage[127.0.0.1:39648,DS-b0d80f38-9636-45b3-a356-6249a60961e7,DISK], DatanodeInfoWithStorage[127.0.0.1:41600,DS-0649cfe7-94c5-4584-9770-49c084959176,DISK], DatanodeInfoWithStorage[127.0.0.1:35114,DS-fd49defb-a67e-48c1-94c3-f6eb601718e2,DISK], DatanodeInfoWithStorage[127.0.0.1:35606,DS-948e744c-44c8-4213-83bc-41b3f2d78b6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-166797001-172.17.0.12-1595298871474:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38532,DS-0c7d36b3-6907-436f-a591-d7808cc8a31c,DISK], DatanodeInfoWithStorage[127.0.0.1:40807,DS-be60406e-18cd-4995-8edb-488c1c2b37b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37004,DS-30853f20-b3e6-4803-b7e5-46f3ecf76111,DISK], DatanodeInfoWithStorage[127.0.0.1:46462,DS-76252c25-6715-4013-8d39-6c023f6b984b,DISK], DatanodeInfoWithStorage[127.0.0.1:39648,DS-b0d80f38-9636-45b3-a356-6249a60961e7,DISK], DatanodeInfoWithStorage[127.0.0.1:41600,DS-0649cfe7-94c5-4584-9770-49c084959176,DISK], DatanodeInfoWithStorage[127.0.0.1:35114,DS-fd49defb-a67e-48c1-94c3-f6eb601718e2,DISK], DatanodeInfoWithStorage[127.0.0.1:35606,DS-948e744c-44c8-4213-83bc-41b3f2d78b6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.client.resolve.remote.symlinks
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-235339359-172.17.0.12-1595299051376:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44450,DS-97db2989-19de-48a5-a2c3-7a98b824d5d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39123,DS-4c84f940-7f93-4415-964c-8e0ff61db543,DISK], DatanodeInfoWithStorage[127.0.0.1:43565,DS-553af7f2-51b8-4cde-8b31-7ada14991632,DISK], DatanodeInfoWithStorage[127.0.0.1:42940,DS-05280666-ca7c-4f6b-9b85-da0515089b51,DISK], DatanodeInfoWithStorage[127.0.0.1:38731,DS-04fb84a1-7ec6-48d6-b71d-8b89d66bd4a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34009,DS-0da22931-58f3-4aed-89b5-803c6fc7b6ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43542,DS-da6fc052-a171-4580-819f-7c45c41f6ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:46420,DS-1cb62337-36a9-48e3-9862-3a6a952b9952,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-235339359-172.17.0.12-1595299051376:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44450,DS-97db2989-19de-48a5-a2c3-7a98b824d5d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39123,DS-4c84f940-7f93-4415-964c-8e0ff61db543,DISK], DatanodeInfoWithStorage[127.0.0.1:43565,DS-553af7f2-51b8-4cde-8b31-7ada14991632,DISK], DatanodeInfoWithStorage[127.0.0.1:42940,DS-05280666-ca7c-4f6b-9b85-da0515089b51,DISK], DatanodeInfoWithStorage[127.0.0.1:38731,DS-04fb84a1-7ec6-48d6-b71d-8b89d66bd4a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34009,DS-0da22931-58f3-4aed-89b5-803c6fc7b6ed,DISK], DatanodeInfoWithStorage[127.0.0.1:43542,DS-da6fc052-a171-4580-819f-7c45c41f6ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:46420,DS-1cb62337-36a9-48e3-9862-3a6a952b9952,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.client.resolve.remote.symlinks
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-679842829-172.17.0.12-1595299706585:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35727,DS-559ca6a4-8c60-4b96-b7d4-a9d1ba691a39,DISK], DatanodeInfoWithStorage[127.0.0.1:38875,DS-f1e8062b-0209-4d5c-a839-7b20b9b91901,DISK], DatanodeInfoWithStorage[127.0.0.1:44147,DS-0fe1e6f3-7b15-4e0c-99e0-c450770bd6de,DISK], DatanodeInfoWithStorage[127.0.0.1:43420,DS-8d4fd56d-04bd-48c3-a33b-aba2dc751833,DISK], DatanodeInfoWithStorage[127.0.0.1:33449,DS-a4f24ede-e0c6-433c-a675-cfcc6283802a,DISK], DatanodeInfoWithStorage[127.0.0.1:38809,DS-caca1bc3-96d9-4ebf-9a79-4baf056d33da,DISK], DatanodeInfoWithStorage[127.0.0.1:36774,DS-c4c9484d-ff70-4a9d-ad36-462073b7b99d,DISK], DatanodeInfoWithStorage[127.0.0.1:43719,DS-f2f52346-1961-43ee-80ee-88d51dbe19fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-679842829-172.17.0.12-1595299706585:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35727,DS-559ca6a4-8c60-4b96-b7d4-a9d1ba691a39,DISK], DatanodeInfoWithStorage[127.0.0.1:38875,DS-f1e8062b-0209-4d5c-a839-7b20b9b91901,DISK], DatanodeInfoWithStorage[127.0.0.1:44147,DS-0fe1e6f3-7b15-4e0c-99e0-c450770bd6de,DISK], DatanodeInfoWithStorage[127.0.0.1:43420,DS-8d4fd56d-04bd-48c3-a33b-aba2dc751833,DISK], DatanodeInfoWithStorage[127.0.0.1:33449,DS-a4f24ede-e0c6-433c-a675-cfcc6283802a,DISK], DatanodeInfoWithStorage[127.0.0.1:38809,DS-caca1bc3-96d9-4ebf-9a79-4baf056d33da,DISK], DatanodeInfoWithStorage[127.0.0.1:36774,DS-c4c9484d-ff70-4a9d-ad36-462073b7b99d,DISK], DatanodeInfoWithStorage[127.0.0.1:43719,DS-f2f52346-1961-43ee-80ee-88d51dbe19fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.client.resolve.remote.symlinks
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-933855895-172.17.0.12-1595299849061:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43320,DS-fa1de522-d1e3-4a09-a019-4377575acc9a,DISK], DatanodeInfoWithStorage[127.0.0.1:46420,DS-c5c4ae42-daef-4a0b-b7b4-1780648bf3bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40897,DS-bc721ccc-862b-4440-9018-95794b08206c,DISK], DatanodeInfoWithStorage[127.0.0.1:37113,DS-cbfa6d4f-1882-429e-ae35-d34b814f1c59,DISK], DatanodeInfoWithStorage[127.0.0.1:35749,DS-3d5d48e4-6362-4492-9875-765844cf541a,DISK], DatanodeInfoWithStorage[127.0.0.1:43700,DS-8c572850-676f-4696-8fae-df50f25d9374,DISK], DatanodeInfoWithStorage[127.0.0.1:38324,DS-19b4d5ee-267a-4041-8e2d-5fd99b9904da,DISK], DatanodeInfoWithStorage[127.0.0.1:38284,DS-94a05d82-15b4-4708-81ff-28976a146f9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-933855895-172.17.0.12-1595299849061:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43320,DS-fa1de522-d1e3-4a09-a019-4377575acc9a,DISK], DatanodeInfoWithStorage[127.0.0.1:46420,DS-c5c4ae42-daef-4a0b-b7b4-1780648bf3bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40897,DS-bc721ccc-862b-4440-9018-95794b08206c,DISK], DatanodeInfoWithStorage[127.0.0.1:37113,DS-cbfa6d4f-1882-429e-ae35-d34b814f1c59,DISK], DatanodeInfoWithStorage[127.0.0.1:35749,DS-3d5d48e4-6362-4492-9875-765844cf541a,DISK], DatanodeInfoWithStorage[127.0.0.1:43700,DS-8c572850-676f-4696-8fae-df50f25d9374,DISK], DatanodeInfoWithStorage[127.0.0.1:38324,DS-19b4d5ee-267a-4041-8e2d-5fd99b9904da,DISK], DatanodeInfoWithStorage[127.0.0.1:38284,DS-94a05d82-15b4-4708-81ff-28976a146f9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.client.resolve.remote.symlinks
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-302994210-172.17.0.12-1595300016106:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46719,DS-20bc8e1b-6ecd-44be-b878-6fa0519b6ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:43649,DS-4ca32cde-13a9-42d9-bcd7-b79c5039740d,DISK], DatanodeInfoWithStorage[127.0.0.1:39126,DS-afbab8fb-1797-49b7-b84f-57dfc6d08fd4,DISK], DatanodeInfoWithStorage[127.0.0.1:37012,DS-23ee358e-982a-4720-a44b-a33afae67bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:34184,DS-208299bd-b09d-4db3-bb48-ff1bd8312ceb,DISK], DatanodeInfoWithStorage[127.0.0.1:38248,DS-aa5bdc0b-dedb-4d60-960c-110401caa3c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42728,DS-9ee49ef4-729a-4e7b-98f9-22b48c211cac,DISK], DatanodeInfoWithStorage[127.0.0.1:32983,DS-7988e972-930e-45e8-802a-a2d241ba19ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-302994210-172.17.0.12-1595300016106:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46719,DS-20bc8e1b-6ecd-44be-b878-6fa0519b6ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:43649,DS-4ca32cde-13a9-42d9-bcd7-b79c5039740d,DISK], DatanodeInfoWithStorage[127.0.0.1:39126,DS-afbab8fb-1797-49b7-b84f-57dfc6d08fd4,DISK], DatanodeInfoWithStorage[127.0.0.1:37012,DS-23ee358e-982a-4720-a44b-a33afae67bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:34184,DS-208299bd-b09d-4db3-bb48-ff1bd8312ceb,DISK], DatanodeInfoWithStorage[127.0.0.1:38248,DS-aa5bdc0b-dedb-4d60-960c-110401caa3c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42728,DS-9ee49ef4-729a-4e7b-98f9-22b48c211cac,DISK], DatanodeInfoWithStorage[127.0.0.1:32983,DS-7988e972-930e-45e8-802a-a2d241ba19ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.client.resolve.remote.symlinks
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1531450241-172.17.0.12-1595300181856:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33126,DS-f5205013-af28-45b7-b1be-54d358d13b01,DISK], DatanodeInfoWithStorage[127.0.0.1:45808,DS-c28b2531-117f-4fee-990b-2fd77886f2a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33040,DS-3a87a1ff-49bc-4926-8694-de494b755c29,DISK], DatanodeInfoWithStorage[127.0.0.1:41014,DS-22e088dd-8d18-4173-affd-853eb552ef2b,DISK], DatanodeInfoWithStorage[127.0.0.1:46836,DS-1b0501e7-9695-4fa1-a2c0-cf137839f256,DISK], DatanodeInfoWithStorage[127.0.0.1:46226,DS-0df1070d-0f3a-4f28-94b8-7c8f8fa974e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45841,DS-df7b5461-9ee6-4c57-95ff-0b4a85f69f39,DISK], DatanodeInfoWithStorage[127.0.0.1:38315,DS-45bdcbc8-07d9-4d82-9252-c13222faa550,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1531450241-172.17.0.12-1595300181856:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33126,DS-f5205013-af28-45b7-b1be-54d358d13b01,DISK], DatanodeInfoWithStorage[127.0.0.1:45808,DS-c28b2531-117f-4fee-990b-2fd77886f2a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33040,DS-3a87a1ff-49bc-4926-8694-de494b755c29,DISK], DatanodeInfoWithStorage[127.0.0.1:41014,DS-22e088dd-8d18-4173-affd-853eb552ef2b,DISK], DatanodeInfoWithStorage[127.0.0.1:46836,DS-1b0501e7-9695-4fa1-a2c0-cf137839f256,DISK], DatanodeInfoWithStorage[127.0.0.1:46226,DS-0df1070d-0f3a-4f28-94b8-7c8f8fa974e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45841,DS-df7b5461-9ee6-4c57-95ff-0b4a85f69f39,DISK], DatanodeInfoWithStorage[127.0.0.1:38315,DS-45bdcbc8-07d9-4d82-9252-c13222faa550,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.client.resolve.remote.symlinks
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1557098959-172.17.0.12-1595300603767:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45601,DS-53976e96-092a-4f98-85b4-a55d3bab3a1f,DISK], DatanodeInfoWithStorage[127.0.0.1:43370,DS-eabb570b-36ce-4838-82c2-d460fff612bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45896,DS-8522770b-29bd-4bb8-9b6c-2184bc0056c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41310,DS-5e3e36c3-f1d5-4a45-8780-8743f3db8529,DISK], DatanodeInfoWithStorage[127.0.0.1:36571,DS-edfbf105-1fc8-4b7c-997e-807f8ade0a55,DISK], DatanodeInfoWithStorage[127.0.0.1:39953,DS-5087f294-c901-45c1-8fef-4f32d3efb631,DISK], DatanodeInfoWithStorage[127.0.0.1:37440,DS-03ca0518-9a41-4c7c-b702-9ccb7179f81c,DISK], DatanodeInfoWithStorage[127.0.0.1:35398,DS-ed06dffa-26de-4cf4-bc21-df934166e2c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1557098959-172.17.0.12-1595300603767:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45601,DS-53976e96-092a-4f98-85b4-a55d3bab3a1f,DISK], DatanodeInfoWithStorage[127.0.0.1:43370,DS-eabb570b-36ce-4838-82c2-d460fff612bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45896,DS-8522770b-29bd-4bb8-9b6c-2184bc0056c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41310,DS-5e3e36c3-f1d5-4a45-8780-8743f3db8529,DISK], DatanodeInfoWithStorage[127.0.0.1:36571,DS-edfbf105-1fc8-4b7c-997e-807f8ade0a55,DISK], DatanodeInfoWithStorage[127.0.0.1:39953,DS-5087f294-c901-45c1-8fef-4f32d3efb631,DISK], DatanodeInfoWithStorage[127.0.0.1:37440,DS-03ca0518-9a41-4c7c-b702-9ccb7179f81c,DISK], DatanodeInfoWithStorage[127.0.0.1:35398,DS-ed06dffa-26de-4cf4-bc21-df934166e2c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.client.resolve.remote.symlinks
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-753368665-172.17.0.12-1595300821554:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38207,DS-034fc20f-db4b-4220-884f-71340216f47e,DISK], DatanodeInfoWithStorage[127.0.0.1:33426,DS-6ef2345d-0974-4c85-a463-e46daa3b2a35,DISK], DatanodeInfoWithStorage[127.0.0.1:41825,DS-277bc693-867e-4785-89c7-cb18143c8caa,DISK], DatanodeInfoWithStorage[127.0.0.1:40711,DS-fcd6fe7c-f661-4eda-b34e-b6e62c639628,DISK], DatanodeInfoWithStorage[127.0.0.1:43058,DS-c33cfae3-05d2-44dd-8266-b28fd0342c98,DISK], DatanodeInfoWithStorage[127.0.0.1:44258,DS-fab803a3-da81-4628-a4e2-08dfb9011d19,DISK], DatanodeInfoWithStorage[127.0.0.1:37911,DS-b511686f-fcca-4194-9b3a-0c8f590bf32d,DISK], DatanodeInfoWithStorage[127.0.0.1:36027,DS-e5875420-4790-4daf-a629-b91393799c47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-753368665-172.17.0.12-1595300821554:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38207,DS-034fc20f-db4b-4220-884f-71340216f47e,DISK], DatanodeInfoWithStorage[127.0.0.1:33426,DS-6ef2345d-0974-4c85-a463-e46daa3b2a35,DISK], DatanodeInfoWithStorage[127.0.0.1:41825,DS-277bc693-867e-4785-89c7-cb18143c8caa,DISK], DatanodeInfoWithStorage[127.0.0.1:40711,DS-fcd6fe7c-f661-4eda-b34e-b6e62c639628,DISK], DatanodeInfoWithStorage[127.0.0.1:43058,DS-c33cfae3-05d2-44dd-8266-b28fd0342c98,DISK], DatanodeInfoWithStorage[127.0.0.1:44258,DS-fab803a3-da81-4628-a4e2-08dfb9011d19,DISK], DatanodeInfoWithStorage[127.0.0.1:37911,DS-b511686f-fcca-4194-9b3a-0c8f590bf32d,DISK], DatanodeInfoWithStorage[127.0.0.1:36027,DS-e5875420-4790-4daf-a629-b91393799c47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.client.resolve.remote.symlinks
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1810265361-172.17.0.12-1595300912027:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39990,DS-f8b1eb16-2ecd-46e3-9c25-de7980a3b7b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45781,DS-1eaa02f4-eb3f-44a1-b2bf-90da6dee358a,DISK], DatanodeInfoWithStorage[127.0.0.1:43248,DS-51b4eb9f-7ad1-44e9-9d25-8b47b52ef50c,DISK], DatanodeInfoWithStorage[127.0.0.1:34375,DS-67c97eff-026f-41bf-80aa-8ab50eaa77f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43529,DS-e040dd78-7e4d-4752-994c-9b7f5b9ddca4,DISK], DatanodeInfoWithStorage[127.0.0.1:46453,DS-75ba9dfd-3b62-44f6-99ea-aa4bd6438023,DISK], DatanodeInfoWithStorage[127.0.0.1:41298,DS-84500502-1583-43d7-a281-c93306bcf817,DISK], DatanodeInfoWithStorage[127.0.0.1:46857,DS-1b8a6263-79eb-4487-aece-5c6240325b3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1810265361-172.17.0.12-1595300912027:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39990,DS-f8b1eb16-2ecd-46e3-9c25-de7980a3b7b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45781,DS-1eaa02f4-eb3f-44a1-b2bf-90da6dee358a,DISK], DatanodeInfoWithStorage[127.0.0.1:43248,DS-51b4eb9f-7ad1-44e9-9d25-8b47b52ef50c,DISK], DatanodeInfoWithStorage[127.0.0.1:34375,DS-67c97eff-026f-41bf-80aa-8ab50eaa77f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43529,DS-e040dd78-7e4d-4752-994c-9b7f5b9ddca4,DISK], DatanodeInfoWithStorage[127.0.0.1:46453,DS-75ba9dfd-3b62-44f6-99ea-aa4bd6438023,DISK], DatanodeInfoWithStorage[127.0.0.1:41298,DS-84500502-1583-43d7-a281-c93306bcf817,DISK], DatanodeInfoWithStorage[127.0.0.1:46857,DS-1b8a6263-79eb-4487-aece-5c6240325b3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.client.resolve.remote.symlinks
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1351177296-172.17.0.12-1595301087543:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45737,DS-7c303218-0f27-4fba-9cc4-6a511b509db6,DISK], DatanodeInfoWithStorage[127.0.0.1:39762,DS-3ce31050-7235-4c74-a6e8-b06d6b2a3bf5,DISK], DatanodeInfoWithStorage[127.0.0.1:43321,DS-e532184e-176c-4a37-ba2f-8b4897c91646,DISK], DatanodeInfoWithStorage[127.0.0.1:44040,DS-3432bb18-906e-4cf0-ad59-0d31b4a89170,DISK], DatanodeInfoWithStorage[127.0.0.1:38393,DS-dc154618-608c-4a60-bbb7-ad4bd00a65ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35001,DS-e2f6ed47-5190-4d4e-a311-42e8aee41849,DISK], DatanodeInfoWithStorage[127.0.0.1:45815,DS-819d3570-16c5-45f3-a7c0-cc65b19ce63f,DISK], DatanodeInfoWithStorage[127.0.0.1:44934,DS-b5fc17f7-3b7c-4d98-9269-8393d061fb13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1351177296-172.17.0.12-1595301087543:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45737,DS-7c303218-0f27-4fba-9cc4-6a511b509db6,DISK], DatanodeInfoWithStorage[127.0.0.1:39762,DS-3ce31050-7235-4c74-a6e8-b06d6b2a3bf5,DISK], DatanodeInfoWithStorage[127.0.0.1:43321,DS-e532184e-176c-4a37-ba2f-8b4897c91646,DISK], DatanodeInfoWithStorage[127.0.0.1:44040,DS-3432bb18-906e-4cf0-ad59-0d31b4a89170,DISK], DatanodeInfoWithStorage[127.0.0.1:38393,DS-dc154618-608c-4a60-bbb7-ad4bd00a65ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35001,DS-e2f6ed47-5190-4d4e-a311-42e8aee41849,DISK], DatanodeInfoWithStorage[127.0.0.1:45815,DS-819d3570-16c5-45f3-a7c0-cc65b19ce63f,DISK], DatanodeInfoWithStorage[127.0.0.1:44934,DS-b5fc17f7-3b7c-4d98-9269-8393d061fb13,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.client.resolve.remote.symlinks
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1695373983-172.17.0.12-1595301676849:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34031,DS-2d35a06d-cc3c-49e3-a4ba-d784697db35c,DISK], DatanodeInfoWithStorage[127.0.0.1:38223,DS-cf930b69-9b0a-49a4-a9c9-16267e2beb43,DISK], DatanodeInfoWithStorage[127.0.0.1:35864,DS-bdb0b01f-ba09-4709-9896-37232f282e48,DISK], DatanodeInfoWithStorage[127.0.0.1:46769,DS-d3084cfc-24de-4ddc-bd6b-7840baf06334,DISK], DatanodeInfoWithStorage[127.0.0.1:43794,DS-1351612c-6f30-46df-a3fa-f7ca5bff5ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:43201,DS-d7bfedc7-443a-455a-9c28-13ed20726453,DISK], DatanodeInfoWithStorage[127.0.0.1:33073,DS-0220d2f5-b9a9-4d9d-aa3c-cf6002dc14f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43797,DS-6ed7bb82-f706-42ce-8157-28dbd8d7ad39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1695373983-172.17.0.12-1595301676849:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34031,DS-2d35a06d-cc3c-49e3-a4ba-d784697db35c,DISK], DatanodeInfoWithStorage[127.0.0.1:38223,DS-cf930b69-9b0a-49a4-a9c9-16267e2beb43,DISK], DatanodeInfoWithStorage[127.0.0.1:35864,DS-bdb0b01f-ba09-4709-9896-37232f282e48,DISK], DatanodeInfoWithStorage[127.0.0.1:46769,DS-d3084cfc-24de-4ddc-bd6b-7840baf06334,DISK], DatanodeInfoWithStorage[127.0.0.1:43794,DS-1351612c-6f30-46df-a3fa-f7ca5bff5ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:43201,DS-d7bfedc7-443a-455a-9c28-13ed20726453,DISK], DatanodeInfoWithStorage[127.0.0.1:33073,DS-0220d2f5-b9a9-4d9d-aa3c-cf6002dc14f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43797,DS-6ed7bb82-f706-42ce-8157-28dbd8d7ad39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.client.resolve.remote.symlinks
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1220875742-172.17.0.12-1595301894963:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34625,DS-e9f061df-b61e-4a1e-9031-53dfdab46f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:33770,DS-8c80b709-6ec8-4b59-8c91-b865727930b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37043,DS-f77c93f2-b967-4f06-96f7-88ecf1d9a644,DISK], DatanodeInfoWithStorage[127.0.0.1:43708,DS-21b14607-08e1-44d0-9f8a-1a0c52db3346,DISK], DatanodeInfoWithStorage[127.0.0.1:42929,DS-c8efcbaf-0f08-4c9c-986e-bf1752de72a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36140,DS-7e0c14dd-78e0-4302-9a8c-17d96b4cd192,DISK], DatanodeInfoWithStorage[127.0.0.1:35662,DS-04fdb412-986d-444b-8c25-7abe0c8637f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40881,DS-e8a19f33-be1d-483f-90a8-5f39b84080a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1220875742-172.17.0.12-1595301894963:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34625,DS-e9f061df-b61e-4a1e-9031-53dfdab46f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:33770,DS-8c80b709-6ec8-4b59-8c91-b865727930b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37043,DS-f77c93f2-b967-4f06-96f7-88ecf1d9a644,DISK], DatanodeInfoWithStorage[127.0.0.1:43708,DS-21b14607-08e1-44d0-9f8a-1a0c52db3346,DISK], DatanodeInfoWithStorage[127.0.0.1:42929,DS-c8efcbaf-0f08-4c9c-986e-bf1752de72a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36140,DS-7e0c14dd-78e0-4302-9a8c-17d96b4cd192,DISK], DatanodeInfoWithStorage[127.0.0.1:35662,DS-04fdb412-986d-444b-8c25-7abe0c8637f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40881,DS-e8a19f33-be1d-483f-90a8-5f39b84080a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.client.resolve.remote.symlinks
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2026943907-172.17.0.12-1595302474301:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37800,DS-9b7e4e78-cffa-450a-92aa-6dbaabdc9bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:36119,DS-567cabd7-7e54-4680-a200-93d2e8036ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:40480,DS-b7102a50-b239-4052-9cba-f91179380a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:36601,DS-af91d22d-c202-4111-bd46-78c9e4f2b203,DISK], DatanodeInfoWithStorage[127.0.0.1:40264,DS-12ef82e1-6252-44b2-85a9-16cd34a25da2,DISK], DatanodeInfoWithStorage[127.0.0.1:40110,DS-cd2306a6-4b2a-4450-93ab-ffc711480148,DISK], DatanodeInfoWithStorage[127.0.0.1:37438,DS-84192551-8fd1-40b0-b937-86b5fe07dcd4,DISK], DatanodeInfoWithStorage[127.0.0.1:32823,DS-49e24495-d263-4903-ab74-1cc3dc8b59fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2026943907-172.17.0.12-1595302474301:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37800,DS-9b7e4e78-cffa-450a-92aa-6dbaabdc9bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:36119,DS-567cabd7-7e54-4680-a200-93d2e8036ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:40480,DS-b7102a50-b239-4052-9cba-f91179380a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:36601,DS-af91d22d-c202-4111-bd46-78c9e4f2b203,DISK], DatanodeInfoWithStorage[127.0.0.1:40264,DS-12ef82e1-6252-44b2-85a9-16cd34a25da2,DISK], DatanodeInfoWithStorage[127.0.0.1:40110,DS-cd2306a6-4b2a-4450-93ab-ffc711480148,DISK], DatanodeInfoWithStorage[127.0.0.1:37438,DS-84192551-8fd1-40b0-b937-86b5fe07dcd4,DISK], DatanodeInfoWithStorage[127.0.0.1:32823,DS-49e24495-d263-4903-ab74-1cc3dc8b59fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.client.resolve.remote.symlinks
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1848252132-172.17.0.12-1595302524229:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42726,DS-0b798b45-bee4-47ee-a431-b044d657f335,DISK], DatanodeInfoWithStorage[127.0.0.1:46575,DS-081fe794-9ef7-4cf0-b214-02a908f97fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:36606,DS-ad08a59c-73a1-411a-b42a-b537e757264e,DISK], DatanodeInfoWithStorage[127.0.0.1:41576,DS-c7f29408-dfb4-4b4a-a7fb-823393fb1561,DISK], DatanodeInfoWithStorage[127.0.0.1:35325,DS-9889c309-d86e-443d-8f69-fee294dfbd88,DISK], DatanodeInfoWithStorage[127.0.0.1:35677,DS-2494b72a-3ff3-4c64-80c2-809a8b5101fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42920,DS-0647c9cd-4db7-4fe1-91dd-82d16c1b6aae,DISK], DatanodeInfoWithStorage[127.0.0.1:41534,DS-234e4bd1-3fc3-4318-a90d-0689694ed79e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1848252132-172.17.0.12-1595302524229:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42726,DS-0b798b45-bee4-47ee-a431-b044d657f335,DISK], DatanodeInfoWithStorage[127.0.0.1:46575,DS-081fe794-9ef7-4cf0-b214-02a908f97fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:36606,DS-ad08a59c-73a1-411a-b42a-b537e757264e,DISK], DatanodeInfoWithStorage[127.0.0.1:41576,DS-c7f29408-dfb4-4b4a-a7fb-823393fb1561,DISK], DatanodeInfoWithStorage[127.0.0.1:35325,DS-9889c309-d86e-443d-8f69-fee294dfbd88,DISK], DatanodeInfoWithStorage[127.0.0.1:35677,DS-2494b72a-3ff3-4c64-80c2-809a8b5101fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42920,DS-0647c9cd-4db7-4fe1-91dd-82d16c1b6aae,DISK], DatanodeInfoWithStorage[127.0.0.1:41534,DS-234e4bd1-3fc3-4318-a90d-0689694ed79e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.client.resolve.remote.symlinks
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1930079485-172.17.0.12-1595302845140:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35275,DS-f79ba7a3-2e9f-4a73-95e4-b060143dc654,DISK], DatanodeInfoWithStorage[127.0.0.1:43732,DS-de064595-6f3a-4dee-a782-bc9f10bc44bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33179,DS-054f1bb6-fa85-47ff-b4a1-f69e4c7f3a6f,DISK], DatanodeInfoWithStorage[127.0.0.1:34527,DS-be23e7bb-231c-4e23-9ddc-aa3850a7e8b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46447,DS-06378e30-85e8-46d1-bf5a-57b52c8983fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39562,DS-6749f7e3-18f1-4c22-9ef4-00f33a9ec172,DISK], DatanodeInfoWithStorage[127.0.0.1:44783,DS-d0b77753-1cf5-42cb-b272-41edb2adb14c,DISK], DatanodeInfoWithStorage[127.0.0.1:34800,DS-f5b7d701-02c4-4d83-90c9-b3392d9f78ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1930079485-172.17.0.12-1595302845140:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35275,DS-f79ba7a3-2e9f-4a73-95e4-b060143dc654,DISK], DatanodeInfoWithStorage[127.0.0.1:43732,DS-de064595-6f3a-4dee-a782-bc9f10bc44bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33179,DS-054f1bb6-fa85-47ff-b4a1-f69e4c7f3a6f,DISK], DatanodeInfoWithStorage[127.0.0.1:34527,DS-be23e7bb-231c-4e23-9ddc-aa3850a7e8b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46447,DS-06378e30-85e8-46d1-bf5a-57b52c8983fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39562,DS-6749f7e3-18f1-4c22-9ef4-00f33a9ec172,DISK], DatanodeInfoWithStorage[127.0.0.1:44783,DS-d0b77753-1cf5-42cb-b272-41edb2adb14c,DISK], DatanodeInfoWithStorage[127.0.0.1:34800,DS-f5b7d701-02c4-4d83-90c9-b3392d9f78ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.client.resolve.remote.symlinks
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1892673590-172.17.0.12-1595303276894:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35411,DS-599d8933-6a5e-484d-8ef6-3e68ea2b39a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38717,DS-6e2f91bf-f237-4c6f-820e-e0bd47ccf872,DISK], DatanodeInfoWithStorage[127.0.0.1:46371,DS-0d18599d-d2b7-4a63-a3e3-e5271c34cec5,DISK], DatanodeInfoWithStorage[127.0.0.1:35310,DS-cbf313ae-17eb-4469-8817-7323d4f166c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44142,DS-46370ead-1755-465c-b6f9-7536c3969db8,DISK], DatanodeInfoWithStorage[127.0.0.1:44861,DS-58e6c5e6-91ea-4c67-a499-acca76cb180b,DISK], DatanodeInfoWithStorage[127.0.0.1:35784,DS-61cb9e20-e606-4c9d-830b-74714d92915a,DISK], DatanodeInfoWithStorage[127.0.0.1:40769,DS-4e570620-29bc-4cda-8c7f-7297bc7bfa1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1892673590-172.17.0.12-1595303276894:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35411,DS-599d8933-6a5e-484d-8ef6-3e68ea2b39a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38717,DS-6e2f91bf-f237-4c6f-820e-e0bd47ccf872,DISK], DatanodeInfoWithStorage[127.0.0.1:46371,DS-0d18599d-d2b7-4a63-a3e3-e5271c34cec5,DISK], DatanodeInfoWithStorage[127.0.0.1:35310,DS-cbf313ae-17eb-4469-8817-7323d4f166c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44142,DS-46370ead-1755-465c-b6f9-7536c3969db8,DISK], DatanodeInfoWithStorage[127.0.0.1:44861,DS-58e6c5e6-91ea-4c67-a499-acca76cb180b,DISK], DatanodeInfoWithStorage[127.0.0.1:35784,DS-61cb9e20-e606-4c9d-830b-74714d92915a,DISK], DatanodeInfoWithStorage[127.0.0.1:40769,DS-4e570620-29bc-4cda-8c7f-7297bc7bfa1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.client.resolve.remote.symlinks
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-956559767-172.17.0.12-1595303567080:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33482,DS-976541f0-4238-4aea-83f4-7e60e21d5acb,DISK], DatanodeInfoWithStorage[127.0.0.1:43968,DS-c6b9c83c-352f-40c1-898a-6375003b7c0c,DISK], DatanodeInfoWithStorage[127.0.0.1:44689,DS-120ff7bd-9e35-40fe-92e6-519b190902eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42100,DS-0107960a-1650-4735-8ef2-274cdf137a74,DISK], DatanodeInfoWithStorage[127.0.0.1:34498,DS-b9bf4411-148c-40b2-8a70-bd5af06af649,DISK], DatanodeInfoWithStorage[127.0.0.1:38952,DS-91fee853-9262-4aa9-9d07-a627d7361afe,DISK], DatanodeInfoWithStorage[127.0.0.1:36208,DS-66a6c0db-3c0c-439e-834b-ae5a34c4061b,DISK], DatanodeInfoWithStorage[127.0.0.1:38134,DS-1fed5b20-bb5a-408c-a4f6-68653646f3be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-956559767-172.17.0.12-1595303567080:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33482,DS-976541f0-4238-4aea-83f4-7e60e21d5acb,DISK], DatanodeInfoWithStorage[127.0.0.1:43968,DS-c6b9c83c-352f-40c1-898a-6375003b7c0c,DISK], DatanodeInfoWithStorage[127.0.0.1:44689,DS-120ff7bd-9e35-40fe-92e6-519b190902eb,DISK], DatanodeInfoWithStorage[127.0.0.1:42100,DS-0107960a-1650-4735-8ef2-274cdf137a74,DISK], DatanodeInfoWithStorage[127.0.0.1:34498,DS-b9bf4411-148c-40b2-8a70-bd5af06af649,DISK], DatanodeInfoWithStorage[127.0.0.1:38952,DS-91fee853-9262-4aa9-9d07-a627d7361afe,DISK], DatanodeInfoWithStorage[127.0.0.1:36208,DS-66a6c0db-3c0c-439e-834b-ae5a34c4061b,DISK], DatanodeInfoWithStorage[127.0.0.1:38134,DS-1fed5b20-bb5a-408c-a4f6-68653646f3be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.client.resolve.remote.symlinks
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-650513158-172.17.0.12-1595303828050:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33839,DS-80b4b0a8-f1f5-4378-b19e-1bf959d83b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:38141,DS-31356bfe-d154-41ba-9461-c733d52b6df8,DISK], DatanodeInfoWithStorage[127.0.0.1:41754,DS-3f7768e3-fa98-42d7-b63c-14ae7ae45a89,DISK], DatanodeInfoWithStorage[127.0.0.1:39285,DS-86a032a9-75c4-45af-b16d-ba7e4d2f0b29,DISK], DatanodeInfoWithStorage[127.0.0.1:36185,DS-123f8542-a62c-4980-8f0e-9d90b545fcb3,DISK], DatanodeInfoWithStorage[127.0.0.1:41429,DS-e65ed507-f25c-44cc-8953-7cbeae7bbf90,DISK], DatanodeInfoWithStorage[127.0.0.1:37097,DS-0ea4f5d8-32f3-45b8-aa45-b33ec0e66861,DISK], DatanodeInfoWithStorage[127.0.0.1:36413,DS-a9c1b685-5d66-49e7-b891-645d4a94683c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-650513158-172.17.0.12-1595303828050:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33839,DS-80b4b0a8-f1f5-4378-b19e-1bf959d83b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:38141,DS-31356bfe-d154-41ba-9461-c733d52b6df8,DISK], DatanodeInfoWithStorage[127.0.0.1:41754,DS-3f7768e3-fa98-42d7-b63c-14ae7ae45a89,DISK], DatanodeInfoWithStorage[127.0.0.1:39285,DS-86a032a9-75c4-45af-b16d-ba7e4d2f0b29,DISK], DatanodeInfoWithStorage[127.0.0.1:36185,DS-123f8542-a62c-4980-8f0e-9d90b545fcb3,DISK], DatanodeInfoWithStorage[127.0.0.1:41429,DS-e65ed507-f25c-44cc-8953-7cbeae7bbf90,DISK], DatanodeInfoWithStorage[127.0.0.1:37097,DS-0ea4f5d8-32f3-45b8-aa45-b33ec0e66861,DISK], DatanodeInfoWithStorage[127.0.0.1:36413,DS-a9c1b685-5d66-49e7-b891-645d4a94683c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.client.resolve.remote.symlinks
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1126908652-172.17.0.12-1595303955959:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42868,DS-a84c3c1b-cc82-45f5-8310-91767fc63b9c,DISK], DatanodeInfoWithStorage[127.0.0.1:35952,DS-795aa6a1-2723-45b6-9200-b9b29eef1e35,DISK], DatanodeInfoWithStorage[127.0.0.1:37653,DS-8b227a38-d6de-4f6e-a9ca-401604830e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:37454,DS-f82a62a2-d511-4b1c-8d34-6cadb0ec9582,DISK], DatanodeInfoWithStorage[127.0.0.1:42439,DS-9faf3239-4936-47ce-8234-68202ec56d7e,DISK], DatanodeInfoWithStorage[127.0.0.1:44020,DS-3afa77aa-e409-4978-a635-c1603004fa2f,DISK], DatanodeInfoWithStorage[127.0.0.1:38671,DS-12f4357b-ae45-4f98-ae7d-95ff7edcc76d,DISK], DatanodeInfoWithStorage[127.0.0.1:43078,DS-4f983e80-1505-4da6-8da2-5e8aca99ca9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1126908652-172.17.0.12-1595303955959:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42868,DS-a84c3c1b-cc82-45f5-8310-91767fc63b9c,DISK], DatanodeInfoWithStorage[127.0.0.1:35952,DS-795aa6a1-2723-45b6-9200-b9b29eef1e35,DISK], DatanodeInfoWithStorage[127.0.0.1:37653,DS-8b227a38-d6de-4f6e-a9ca-401604830e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:37454,DS-f82a62a2-d511-4b1c-8d34-6cadb0ec9582,DISK], DatanodeInfoWithStorage[127.0.0.1:42439,DS-9faf3239-4936-47ce-8234-68202ec56d7e,DISK], DatanodeInfoWithStorage[127.0.0.1:44020,DS-3afa77aa-e409-4978-a635-c1603004fa2f,DISK], DatanodeInfoWithStorage[127.0.0.1:38671,DS-12f4357b-ae45-4f98-ae7d-95ff7edcc76d,DISK], DatanodeInfoWithStorage[127.0.0.1:43078,DS-4f983e80-1505-4da6-8da2-5e8aca99ca9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.client.resolve.remote.symlinks
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1797467524-172.17.0.12-1595304301592:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40380,DS-29463ca4-cde6-4d9c-b71e-ad1fd1c59fb5,DISK], DatanodeInfoWithStorage[127.0.0.1:46185,DS-c658d4ab-b7a2-428a-8286-4e33967e7d7a,DISK], DatanodeInfoWithStorage[127.0.0.1:34201,DS-a77f5580-4969-4ed9-84dd-f390ffb70d7d,DISK], DatanodeInfoWithStorage[127.0.0.1:33331,DS-f4d67f41-e54f-4ebf-addf-a535ca6e5262,DISK], DatanodeInfoWithStorage[127.0.0.1:32878,DS-5e39890c-dc59-43c8-b84a-bdab2e6e798c,DISK], DatanodeInfoWithStorage[127.0.0.1:35921,DS-83543c23-6e97-4589-8aa6-67295734318f,DISK], DatanodeInfoWithStorage[127.0.0.1:44697,DS-88f1bf2e-a0a9-4165-a8f7-d59a3ad77e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:45729,DS-67c70e09-94ac-4008-a8ed-fb5ffede5aaa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1797467524-172.17.0.12-1595304301592:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40380,DS-29463ca4-cde6-4d9c-b71e-ad1fd1c59fb5,DISK], DatanodeInfoWithStorage[127.0.0.1:46185,DS-c658d4ab-b7a2-428a-8286-4e33967e7d7a,DISK], DatanodeInfoWithStorage[127.0.0.1:34201,DS-a77f5580-4969-4ed9-84dd-f390ffb70d7d,DISK], DatanodeInfoWithStorage[127.0.0.1:33331,DS-f4d67f41-e54f-4ebf-addf-a535ca6e5262,DISK], DatanodeInfoWithStorage[127.0.0.1:32878,DS-5e39890c-dc59-43c8-b84a-bdab2e6e798c,DISK], DatanodeInfoWithStorage[127.0.0.1:35921,DS-83543c23-6e97-4589-8aa6-67295734318f,DISK], DatanodeInfoWithStorage[127.0.0.1:44697,DS-88f1bf2e-a0a9-4165-a8f7-d59a3ad77e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:45729,DS-67c70e09-94ac-4008-a8ed-fb5ffede5aaa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.client.resolve.remote.symlinks
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1606641119-172.17.0.12-1595304388014:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35929,DS-3ed8893d-5c85-454c-801e-c85cec05d331,DISK], DatanodeInfoWithStorage[127.0.0.1:37802,DS-97bd5a7d-ad74-4ed5-aee9-1cb7283734e5,DISK], DatanodeInfoWithStorage[127.0.0.1:33261,DS-5e6931e6-b58b-44d7-a72a-551f9e149332,DISK], DatanodeInfoWithStorage[127.0.0.1:43713,DS-665bfcb5-ad2c-4eaf-907d-89dee20c84fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40990,DS-8cf90c01-681c-4360-b88c-5507e1c8b98c,DISK], DatanodeInfoWithStorage[127.0.0.1:43451,DS-b6883569-9598-48ab-bcf7-a1b816dd1877,DISK], DatanodeInfoWithStorage[127.0.0.1:43579,DS-81b4ddf8-3e74-431a-83dc-bdaf6545cc17,DISK], DatanodeInfoWithStorage[127.0.0.1:34935,DS-b95fd34e-41b2-4973-aa4f-d9ae53c3f4ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1606641119-172.17.0.12-1595304388014:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35929,DS-3ed8893d-5c85-454c-801e-c85cec05d331,DISK], DatanodeInfoWithStorage[127.0.0.1:37802,DS-97bd5a7d-ad74-4ed5-aee9-1cb7283734e5,DISK], DatanodeInfoWithStorage[127.0.0.1:33261,DS-5e6931e6-b58b-44d7-a72a-551f9e149332,DISK], DatanodeInfoWithStorage[127.0.0.1:43713,DS-665bfcb5-ad2c-4eaf-907d-89dee20c84fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40990,DS-8cf90c01-681c-4360-b88c-5507e1c8b98c,DISK], DatanodeInfoWithStorage[127.0.0.1:43451,DS-b6883569-9598-48ab-bcf7-a1b816dd1877,DISK], DatanodeInfoWithStorage[127.0.0.1:43579,DS-81b4ddf8-3e74-431a-83dc-bdaf6545cc17,DISK], DatanodeInfoWithStorage[127.0.0.1:34935,DS-b95fd34e-41b2-4973-aa4f-d9ae53c3f4ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.client.resolve.remote.symlinks
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-775260209-172.17.0.12-1595304623890:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33307,DS-cbe41223-991b-441d-99c2-e171d8418326,DISK], DatanodeInfoWithStorage[127.0.0.1:34520,DS-89bdccc0-a6e6-4562-a2ed-ed458bc816fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36389,DS-038a149d-d22d-4101-806e-a7df22dc02f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41995,DS-1896b775-b537-4c70-8ab3-8ac75a9741b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36471,DS-c2e140dd-f530-4edd-8e3c-c1c3e8ecfcbe,DISK], DatanodeInfoWithStorage[127.0.0.1:38466,DS-2877492b-29c9-42a0-a303-c7a55007de47,DISK], DatanodeInfoWithStorage[127.0.0.1:35246,DS-ff4475af-cd73-4667-9d8b-dbcc72dc765c,DISK], DatanodeInfoWithStorage[127.0.0.1:42758,DS-ab767ca5-e684-487b-8f7f-53015b16abbf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-775260209-172.17.0.12-1595304623890:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33307,DS-cbe41223-991b-441d-99c2-e171d8418326,DISK], DatanodeInfoWithStorage[127.0.0.1:34520,DS-89bdccc0-a6e6-4562-a2ed-ed458bc816fc,DISK], DatanodeInfoWithStorage[127.0.0.1:36389,DS-038a149d-d22d-4101-806e-a7df22dc02f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41995,DS-1896b775-b537-4c70-8ab3-8ac75a9741b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36471,DS-c2e140dd-f530-4edd-8e3c-c1c3e8ecfcbe,DISK], DatanodeInfoWithStorage[127.0.0.1:38466,DS-2877492b-29c9-42a0-a303-c7a55007de47,DISK], DatanodeInfoWithStorage[127.0.0.1:35246,DS-ff4475af-cd73-4667-9d8b-dbcc72dc765c,DISK], DatanodeInfoWithStorage[127.0.0.1:42758,DS-ab767ca5-e684-487b-8f7f-53015b16abbf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.client.resolve.remote.symlinks
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1250068238-172.17.0.12-1595305214588:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45439,DS-c4f703cf-fbdc-4a88-b1de-1f1e509a9811,DISK], DatanodeInfoWithStorage[127.0.0.1:43773,DS-7e18d228-84af-4aa3-b9f0-8c6929e3f00f,DISK], DatanodeInfoWithStorage[127.0.0.1:33131,DS-93855243-1f4a-4828-a9fe-95d53c4a4dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:34130,DS-0d737431-83e5-434a-b027-e161deea2224,DISK], DatanodeInfoWithStorage[127.0.0.1:35260,DS-4d062dea-d9eb-4586-bc9e-c0c248747063,DISK], DatanodeInfoWithStorage[127.0.0.1:44978,DS-0d7aa534-0ff3-4d59-bd6e-f7845ff90e45,DISK], DatanodeInfoWithStorage[127.0.0.1:39551,DS-d60c7524-7f3d-4331-ad3b-314f995c5090,DISK], DatanodeInfoWithStorage[127.0.0.1:34938,DS-b784f616-6982-4e1c-bd7a-f076f83993ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1250068238-172.17.0.12-1595305214588:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45439,DS-c4f703cf-fbdc-4a88-b1de-1f1e509a9811,DISK], DatanodeInfoWithStorage[127.0.0.1:43773,DS-7e18d228-84af-4aa3-b9f0-8c6929e3f00f,DISK], DatanodeInfoWithStorage[127.0.0.1:33131,DS-93855243-1f4a-4828-a9fe-95d53c4a4dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:34130,DS-0d737431-83e5-434a-b027-e161deea2224,DISK], DatanodeInfoWithStorage[127.0.0.1:35260,DS-4d062dea-d9eb-4586-bc9e-c0c248747063,DISK], DatanodeInfoWithStorage[127.0.0.1:44978,DS-0d7aa534-0ff3-4d59-bd6e-f7845ff90e45,DISK], DatanodeInfoWithStorage[127.0.0.1:39551,DS-d60c7524-7f3d-4331-ad3b-314f995c5090,DISK], DatanodeInfoWithStorage[127.0.0.1:34938,DS-b784f616-6982-4e1c-bd7a-f076f83993ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.client.resolve.remote.symlinks
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-177073314-172.17.0.12-1595305247474:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37671,DS-912dee5a-063f-4bf8-81e6-5f2d8ef17efd,DISK], DatanodeInfoWithStorage[127.0.0.1:45393,DS-fe8410ed-5258-444f-ab7f-3351243e413f,DISK], DatanodeInfoWithStorage[127.0.0.1:43192,DS-345cc702-8ea4-4748-870a-6962e421221d,DISK], DatanodeInfoWithStorage[127.0.0.1:44495,DS-028cf2d8-678e-4f2c-bc8e-f7576b5ec867,DISK], DatanodeInfoWithStorage[127.0.0.1:41395,DS-889ef028-1a0a-4f66-9040-83c67de73ef1,DISK], DatanodeInfoWithStorage[127.0.0.1:33036,DS-c289ddac-72e3-4cbc-9d17-da129b258abc,DISK], DatanodeInfoWithStorage[127.0.0.1:36564,DS-a36595e7-495e-4f36-8706-c92ab1201d8c,DISK], DatanodeInfoWithStorage[127.0.0.1:38100,DS-44fece9e-af6e-424c-ae6a-73c3fdd0a005,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-177073314-172.17.0.12-1595305247474:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37671,DS-912dee5a-063f-4bf8-81e6-5f2d8ef17efd,DISK], DatanodeInfoWithStorage[127.0.0.1:45393,DS-fe8410ed-5258-444f-ab7f-3351243e413f,DISK], DatanodeInfoWithStorage[127.0.0.1:43192,DS-345cc702-8ea4-4748-870a-6962e421221d,DISK], DatanodeInfoWithStorage[127.0.0.1:44495,DS-028cf2d8-678e-4f2c-bc8e-f7576b5ec867,DISK], DatanodeInfoWithStorage[127.0.0.1:41395,DS-889ef028-1a0a-4f66-9040-83c67de73ef1,DISK], DatanodeInfoWithStorage[127.0.0.1:33036,DS-c289ddac-72e3-4cbc-9d17-da129b258abc,DISK], DatanodeInfoWithStorage[127.0.0.1:36564,DS-a36595e7-495e-4f36-8706-c92ab1201d8c,DISK], DatanodeInfoWithStorage[127.0.0.1:38100,DS-44fece9e-af6e-424c-ae6a-73c3fdd0a005,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 6557
