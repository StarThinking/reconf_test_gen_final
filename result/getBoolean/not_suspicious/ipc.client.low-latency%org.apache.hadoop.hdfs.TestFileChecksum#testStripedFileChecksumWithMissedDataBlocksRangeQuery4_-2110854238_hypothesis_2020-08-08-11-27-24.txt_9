reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1656829719-172.17.0.3-1596886095614:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33110,DS-61c7ef16-bb87-4edd-ac3b-2ac988a0f8f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39265,DS-a1d72842-0884-4a01-9d51-70bbe3459506,DISK], DatanodeInfoWithStorage[127.0.0.1:41149,DS-72919184-782d-4898-97cf-a27311909c20,DISK], DatanodeInfoWithStorage[127.0.0.1:38042,DS-b2436b90-19d0-414b-a097-062abc69ca8b,DISK], DatanodeInfoWithStorage[127.0.0.1:38198,DS-633e5230-46ca-442c-8193-46c7736398af,DISK], DatanodeInfoWithStorage[127.0.0.1:37786,DS-bc81653c-633b-417b-aec9-a7f62cab8570,DISK], DatanodeInfoWithStorage[127.0.0.1:37014,DS-9e05e2f7-33b6-4cb5-a64a-d86609656520,DISK], DatanodeInfoWithStorage[127.0.0.1:44763,DS-3a60acbd-c64b-4784-96f6-28031a2ab381,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1656829719-172.17.0.3-1596886095614:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33110,DS-61c7ef16-bb87-4edd-ac3b-2ac988a0f8f4,DISK], DatanodeInfoWithStorage[127.0.0.1:39265,DS-a1d72842-0884-4a01-9d51-70bbe3459506,DISK], DatanodeInfoWithStorage[127.0.0.1:41149,DS-72919184-782d-4898-97cf-a27311909c20,DISK], DatanodeInfoWithStorage[127.0.0.1:38042,DS-b2436b90-19d0-414b-a097-062abc69ca8b,DISK], DatanodeInfoWithStorage[127.0.0.1:38198,DS-633e5230-46ca-442c-8193-46c7736398af,DISK], DatanodeInfoWithStorage[127.0.0.1:37786,DS-bc81653c-633b-417b-aec9-a7f62cab8570,DISK], DatanodeInfoWithStorage[127.0.0.1:37014,DS-9e05e2f7-33b6-4cb5-a64a-d86609656520,DISK], DatanodeInfoWithStorage[127.0.0.1:44763,DS-3a60acbd-c64b-4784-96f6-28031a2ab381,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-610239452-172.17.0.3-1596886472199:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41338,DS-748f8d8e-26a3-461a-835d-85d96b4de78c,DISK], DatanodeInfoWithStorage[127.0.0.1:45965,DS-fa145dc4-eeb0-42b4-8b6a-c231e8515720,DISK], DatanodeInfoWithStorage[127.0.0.1:32812,DS-7aeb470a-69c7-4d91-95b2-572c2806d782,DISK], DatanodeInfoWithStorage[127.0.0.1:45332,DS-2733cf57-82a6-4729-b889-bb8d71a68eac,DISK], DatanodeInfoWithStorage[127.0.0.1:45772,DS-49993c98-d22d-4057-b2c3-c29abb568e20,DISK], DatanodeInfoWithStorage[127.0.0.1:37587,DS-b8b345e6-3350-4458-af48-eddc31d624d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44652,DS-8c4c9f7f-e38f-4403-9124-6c6a7aba01b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44050,DS-854befd9-42a6-4a1e-88a9-851cd1a84afe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-610239452-172.17.0.3-1596886472199:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41338,DS-748f8d8e-26a3-461a-835d-85d96b4de78c,DISK], DatanodeInfoWithStorage[127.0.0.1:45965,DS-fa145dc4-eeb0-42b4-8b6a-c231e8515720,DISK], DatanodeInfoWithStorage[127.0.0.1:32812,DS-7aeb470a-69c7-4d91-95b2-572c2806d782,DISK], DatanodeInfoWithStorage[127.0.0.1:45332,DS-2733cf57-82a6-4729-b889-bb8d71a68eac,DISK], DatanodeInfoWithStorage[127.0.0.1:45772,DS-49993c98-d22d-4057-b2c3-c29abb568e20,DISK], DatanodeInfoWithStorage[127.0.0.1:37587,DS-b8b345e6-3350-4458-af48-eddc31d624d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44652,DS-8c4c9f7f-e38f-4403-9124-6c6a7aba01b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44050,DS-854befd9-42a6-4a1e-88a9-851cd1a84afe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-506966419-172.17.0.3-1596886725339:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34772,DS-757a7449-0422-417a-a32a-e08265e37926,DISK], DatanodeInfoWithStorage[127.0.0.1:36507,DS-479f7c07-1830-44b5-84b2-07d811f8e2bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35798,DS-36878169-ec17-44f5-b8b4-ffee06202752,DISK], DatanodeInfoWithStorage[127.0.0.1:41854,DS-eea22526-f9f1-4d7a-8455-5851ef43f740,DISK], DatanodeInfoWithStorage[127.0.0.1:40419,DS-b78b7dc7-014a-4446-a4b3-95084e59999a,DISK], DatanodeInfoWithStorage[127.0.0.1:37637,DS-fd5968d7-72eb-47dc-b368-2de367e06e40,DISK], DatanodeInfoWithStorage[127.0.0.1:36459,DS-67cfccc6-2270-4813-ab62-500db692416a,DISK], DatanodeInfoWithStorage[127.0.0.1:43489,DS-7dbaf681-69af-4dc6-8b45-15808d6ed042,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-506966419-172.17.0.3-1596886725339:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34772,DS-757a7449-0422-417a-a32a-e08265e37926,DISK], DatanodeInfoWithStorage[127.0.0.1:36507,DS-479f7c07-1830-44b5-84b2-07d811f8e2bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35798,DS-36878169-ec17-44f5-b8b4-ffee06202752,DISK], DatanodeInfoWithStorage[127.0.0.1:41854,DS-eea22526-f9f1-4d7a-8455-5851ef43f740,DISK], DatanodeInfoWithStorage[127.0.0.1:40419,DS-b78b7dc7-014a-4446-a4b3-95084e59999a,DISK], DatanodeInfoWithStorage[127.0.0.1:37637,DS-fd5968d7-72eb-47dc-b368-2de367e06e40,DISK], DatanodeInfoWithStorage[127.0.0.1:36459,DS-67cfccc6-2270-4813-ab62-500db692416a,DISK], DatanodeInfoWithStorage[127.0.0.1:43489,DS-7dbaf681-69af-4dc6-8b45-15808d6ed042,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-939139964-172.17.0.3-1596887521524:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39966,DS-1f9c0c9f-82ea-429a-b73e-0a7331bcdb77,DISK], DatanodeInfoWithStorage[127.0.0.1:35307,DS-97e6055c-20a0-4373-bc11-7d59a2ecdcda,DISK], DatanodeInfoWithStorage[127.0.0.1:38740,DS-a0db40a3-941d-43ad-81fb-90142b4add40,DISK], DatanodeInfoWithStorage[127.0.0.1:39605,DS-44b66a89-da3b-4846-a24e-de5b6e68ab89,DISK], DatanodeInfoWithStorage[127.0.0.1:44814,DS-06bc05d2-a702-4e0d-a6ed-5b9105be618a,DISK], DatanodeInfoWithStorage[127.0.0.1:45197,DS-41418bdd-363b-4df8-8fb6-c35b414675a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34052,DS-af09153c-2675-4399-8a6d-c3432545526b,DISK], DatanodeInfoWithStorage[127.0.0.1:36643,DS-c6e47f74-19c9-4a85-81b0-db62fd3bb2c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-939139964-172.17.0.3-1596887521524:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39966,DS-1f9c0c9f-82ea-429a-b73e-0a7331bcdb77,DISK], DatanodeInfoWithStorage[127.0.0.1:35307,DS-97e6055c-20a0-4373-bc11-7d59a2ecdcda,DISK], DatanodeInfoWithStorage[127.0.0.1:38740,DS-a0db40a3-941d-43ad-81fb-90142b4add40,DISK], DatanodeInfoWithStorage[127.0.0.1:39605,DS-44b66a89-da3b-4846-a24e-de5b6e68ab89,DISK], DatanodeInfoWithStorage[127.0.0.1:44814,DS-06bc05d2-a702-4e0d-a6ed-5b9105be618a,DISK], DatanodeInfoWithStorage[127.0.0.1:45197,DS-41418bdd-363b-4df8-8fb6-c35b414675a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34052,DS-af09153c-2675-4399-8a6d-c3432545526b,DISK], DatanodeInfoWithStorage[127.0.0.1:36643,DS-c6e47f74-19c9-4a85-81b0-db62fd3bb2c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1040255323-172.17.0.3-1596888961352:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38778,DS-568efe38-5bfe-4cd2-9548-ed1ddffaa7d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45505,DS-67374869-dbd1-4825-9d83-80abbcddaa36,DISK], DatanodeInfoWithStorage[127.0.0.1:41051,DS-e99d3a39-adc7-4662-91f7-f54d58f7ad7d,DISK], DatanodeInfoWithStorage[127.0.0.1:33766,DS-3012d680-72ba-47a6-b7a9-fb3b889ab8f8,DISK], DatanodeInfoWithStorage[127.0.0.1:43398,DS-d7f6fcbb-3438-4357-9d77-e9509b9fac7b,DISK], DatanodeInfoWithStorage[127.0.0.1:46225,DS-99f957ef-c0df-4679-8ee4-4801ab3c634b,DISK], DatanodeInfoWithStorage[127.0.0.1:42276,DS-e1f7c90c-f687-4012-b6be-02f101893859,DISK], DatanodeInfoWithStorage[127.0.0.1:42127,DS-b2774ba1-1364-4916-8c0a-b9166c0ba5e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1040255323-172.17.0.3-1596888961352:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38778,DS-568efe38-5bfe-4cd2-9548-ed1ddffaa7d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45505,DS-67374869-dbd1-4825-9d83-80abbcddaa36,DISK], DatanodeInfoWithStorage[127.0.0.1:41051,DS-e99d3a39-adc7-4662-91f7-f54d58f7ad7d,DISK], DatanodeInfoWithStorage[127.0.0.1:33766,DS-3012d680-72ba-47a6-b7a9-fb3b889ab8f8,DISK], DatanodeInfoWithStorage[127.0.0.1:43398,DS-d7f6fcbb-3438-4357-9d77-e9509b9fac7b,DISK], DatanodeInfoWithStorage[127.0.0.1:46225,DS-99f957ef-c0df-4679-8ee4-4801ab3c634b,DISK], DatanodeInfoWithStorage[127.0.0.1:42276,DS-e1f7c90c-f687-4012-b6be-02f101893859,DISK], DatanodeInfoWithStorage[127.0.0.1:42127,DS-b2774ba1-1364-4916-8c0a-b9166c0ba5e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-125663471-172.17.0.3-1596889216812:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39906,DS-ae6c6a5a-3d82-4947-b462-1f6c2e205a6d,DISK], DatanodeInfoWithStorage[127.0.0.1:34505,DS-16f8a264-765c-49cd-be6e-1608e9de40ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42903,DS-bcea130a-4bc5-4d8b-ac14-415eda0d7334,DISK], DatanodeInfoWithStorage[127.0.0.1:40696,DS-afa2cf7b-a87c-41dc-8a49-9110d34b3938,DISK], DatanodeInfoWithStorage[127.0.0.1:44688,DS-60b3169b-dc52-4a51-81f0-d81b996a4213,DISK], DatanodeInfoWithStorage[127.0.0.1:45299,DS-9709e465-2f44-4cfa-b709-f666085a06a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35686,DS-8b771cee-47ac-4e5e-89a3-ab223f1dce0a,DISK], DatanodeInfoWithStorage[127.0.0.1:39049,DS-0eaf8dde-d149-4d22-862b-7b0434a6eddc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-125663471-172.17.0.3-1596889216812:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39906,DS-ae6c6a5a-3d82-4947-b462-1f6c2e205a6d,DISK], DatanodeInfoWithStorage[127.0.0.1:34505,DS-16f8a264-765c-49cd-be6e-1608e9de40ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42903,DS-bcea130a-4bc5-4d8b-ac14-415eda0d7334,DISK], DatanodeInfoWithStorage[127.0.0.1:40696,DS-afa2cf7b-a87c-41dc-8a49-9110d34b3938,DISK], DatanodeInfoWithStorage[127.0.0.1:44688,DS-60b3169b-dc52-4a51-81f0-d81b996a4213,DISK], DatanodeInfoWithStorage[127.0.0.1:45299,DS-9709e465-2f44-4cfa-b709-f666085a06a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35686,DS-8b771cee-47ac-4e5e-89a3-ab223f1dce0a,DISK], DatanodeInfoWithStorage[127.0.0.1:39049,DS-0eaf8dde-d149-4d22-862b-7b0434a6eddc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1743741097-172.17.0.3-1596889956270:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44180,DS-7a4880ca-cdcf-4004-a71f-6f131fb84153,DISK], DatanodeInfoWithStorage[127.0.0.1:40898,DS-c72fe65f-dec7-4694-b9fd-2b7fec459e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:43748,DS-7e9773ee-efbf-49a2-ae7b-8a3c972e3aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:36928,DS-70176208-f509-40d4-891b-447212fd5bfb,DISK], DatanodeInfoWithStorage[127.0.0.1:34352,DS-f522e6df-c988-4127-b16c-9953a63186b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41155,DS-89f693a9-5bcd-43ac-ad21-184613d99ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:32947,DS-9c29fc77-6245-4340-ac11-1bf24844b894,DISK], DatanodeInfoWithStorage[127.0.0.1:34167,DS-da7d6841-ffe2-4f19-b04e-761c00e8a911,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1743741097-172.17.0.3-1596889956270:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44180,DS-7a4880ca-cdcf-4004-a71f-6f131fb84153,DISK], DatanodeInfoWithStorage[127.0.0.1:40898,DS-c72fe65f-dec7-4694-b9fd-2b7fec459e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:43748,DS-7e9773ee-efbf-49a2-ae7b-8a3c972e3aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:36928,DS-70176208-f509-40d4-891b-447212fd5bfb,DISK], DatanodeInfoWithStorage[127.0.0.1:34352,DS-f522e6df-c988-4127-b16c-9953a63186b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41155,DS-89f693a9-5bcd-43ac-ad21-184613d99ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:32947,DS-9c29fc77-6245-4340-ac11-1bf24844b894,DISK], DatanodeInfoWithStorage[127.0.0.1:34167,DS-da7d6841-ffe2-4f19-b04e-761c00e8a911,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2049624823-172.17.0.3-1596890473899:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43891,DS-8fdd1c32-3b06-4bc8-a40e-a8b41fea45af,DISK], DatanodeInfoWithStorage[127.0.0.1:43136,DS-2f727405-4fc3-4ef4-9d83-55dd2cbe868a,DISK], DatanodeInfoWithStorage[127.0.0.1:38481,DS-7cb337cf-f886-4823-90b1-d90fbdcef160,DISK], DatanodeInfoWithStorage[127.0.0.1:34106,DS-679c1c07-3808-4fe8-8dd6-356be536d67c,DISK], DatanodeInfoWithStorage[127.0.0.1:42145,DS-376f026e-972a-4a3f-81d6-c1248ab72597,DISK], DatanodeInfoWithStorage[127.0.0.1:40671,DS-018fe199-4561-422c-b8ff-8f4699b9cec1,DISK], DatanodeInfoWithStorage[127.0.0.1:36844,DS-a25b8e6e-0dfd-4ce0-9aef-ba4222170cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:36518,DS-cc5d5b7a-4a94-4f66-8022-f40b92415966,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2049624823-172.17.0.3-1596890473899:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43891,DS-8fdd1c32-3b06-4bc8-a40e-a8b41fea45af,DISK], DatanodeInfoWithStorage[127.0.0.1:43136,DS-2f727405-4fc3-4ef4-9d83-55dd2cbe868a,DISK], DatanodeInfoWithStorage[127.0.0.1:38481,DS-7cb337cf-f886-4823-90b1-d90fbdcef160,DISK], DatanodeInfoWithStorage[127.0.0.1:34106,DS-679c1c07-3808-4fe8-8dd6-356be536d67c,DISK], DatanodeInfoWithStorage[127.0.0.1:42145,DS-376f026e-972a-4a3f-81d6-c1248ab72597,DISK], DatanodeInfoWithStorage[127.0.0.1:40671,DS-018fe199-4561-422c-b8ff-8f4699b9cec1,DISK], DatanodeInfoWithStorage[127.0.0.1:36844,DS-a25b8e6e-0dfd-4ce0-9aef-ba4222170cc6,DISK], DatanodeInfoWithStorage[127.0.0.1:36518,DS-cc5d5b7a-4a94-4f66-8022-f40b92415966,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1510758922-172.17.0.3-1596890776801:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44292,DS-760ae976-d868-4123-8b74-bd4991fae4f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39644,DS-7137fa97-4692-4ede-9cfc-69f1997bb9e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33942,DS-050aaf17-7c4c-436e-92b9-d4b6dfab8590,DISK], DatanodeInfoWithStorage[127.0.0.1:35259,DS-d18631fd-5526-4d59-adb5-922e453c6d88,DISK], DatanodeInfoWithStorage[127.0.0.1:36419,DS-a614dced-1406-4293-94c7-db2264aebfbe,DISK], DatanodeInfoWithStorage[127.0.0.1:35175,DS-c5b25482-ad75-459f-8ae3-5ff412cc9c85,DISK], DatanodeInfoWithStorage[127.0.0.1:41752,DS-beb9bd87-d5fd-4b06-9dcd-016ce54ede6d,DISK], DatanodeInfoWithStorage[127.0.0.1:37388,DS-187c9ded-1a00-4d1f-91af-4496db18a3ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1510758922-172.17.0.3-1596890776801:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44292,DS-760ae976-d868-4123-8b74-bd4991fae4f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39644,DS-7137fa97-4692-4ede-9cfc-69f1997bb9e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33942,DS-050aaf17-7c4c-436e-92b9-d4b6dfab8590,DISK], DatanodeInfoWithStorage[127.0.0.1:35259,DS-d18631fd-5526-4d59-adb5-922e453c6d88,DISK], DatanodeInfoWithStorage[127.0.0.1:36419,DS-a614dced-1406-4293-94c7-db2264aebfbe,DISK], DatanodeInfoWithStorage[127.0.0.1:35175,DS-c5b25482-ad75-459f-8ae3-5ff412cc9c85,DISK], DatanodeInfoWithStorage[127.0.0.1:41752,DS-beb9bd87-d5fd-4b06-9dcd-016ce54ede6d,DISK], DatanodeInfoWithStorage[127.0.0.1:37388,DS-187c9ded-1a00-4d1f-91af-4496db18a3ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1379337725-172.17.0.3-1596890931827:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46571,DS-4c6c43dd-b660-4135-847f-75c3ae489790,DISK], DatanodeInfoWithStorage[127.0.0.1:40486,DS-0fcb3bde-f01a-4ca0-b016-9cb6931bab80,DISK], DatanodeInfoWithStorage[127.0.0.1:41484,DS-bf66a049-7b34-4acb-bb91-14ce77be2751,DISK], DatanodeInfoWithStorage[127.0.0.1:43221,DS-40c096a5-429d-4ab3-b7cf-fcbf02223cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:35822,DS-28558cd7-ab6e-452a-95cc-e2069bdd5067,DISK], DatanodeInfoWithStorage[127.0.0.1:42985,DS-102fdd84-5a8a-498d-a20c-3e1ef18793e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42222,DS-3ef0673d-0175-4158-8d7a-0a99a8d88171,DISK], DatanodeInfoWithStorage[127.0.0.1:41007,DS-74d812e2-1596-471b-b35d-936bab741eba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1379337725-172.17.0.3-1596890931827:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46571,DS-4c6c43dd-b660-4135-847f-75c3ae489790,DISK], DatanodeInfoWithStorage[127.0.0.1:40486,DS-0fcb3bde-f01a-4ca0-b016-9cb6931bab80,DISK], DatanodeInfoWithStorage[127.0.0.1:41484,DS-bf66a049-7b34-4acb-bb91-14ce77be2751,DISK], DatanodeInfoWithStorage[127.0.0.1:43221,DS-40c096a5-429d-4ab3-b7cf-fcbf02223cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:35822,DS-28558cd7-ab6e-452a-95cc-e2069bdd5067,DISK], DatanodeInfoWithStorage[127.0.0.1:42985,DS-102fdd84-5a8a-498d-a20c-3e1ef18793e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42222,DS-3ef0673d-0175-4158-8d7a-0a99a8d88171,DISK], DatanodeInfoWithStorage[127.0.0.1:41007,DS-74d812e2-1596-471b-b35d-936bab741eba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5436
