reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1496521707-172.17.0.7-1596985949387:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43705,DS-5c65ff33-1d1c-4f5c-b8ee-08706c885a28,DISK], DatanodeInfoWithStorage[127.0.0.1:36316,DS-359bf296-d90a-4d20-a0bd-904d11cf0ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:41412,DS-80dd5764-c3b7-46b1-826c-53310b6dd5d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45633,DS-a2ee49b5-d5b6-4006-add5-464ca3dd3f73,DISK], DatanodeInfoWithStorage[127.0.0.1:33193,DS-9ef10589-6ab7-42ae-b838-184b149a244e,DISK], DatanodeInfoWithStorage[127.0.0.1:43274,DS-795d8d66-f114-4842-9cd2-6a6b7937a972,DISK], DatanodeInfoWithStorage[127.0.0.1:43344,DS-c692ea9a-cb57-47f1-a991-c862d7297ae6,DISK], DatanodeInfoWithStorage[127.0.0.1:40529,DS-a9d8ce55-f7a9-4859-9820-86969c4fd646,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1496521707-172.17.0.7-1596985949387:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43705,DS-5c65ff33-1d1c-4f5c-b8ee-08706c885a28,DISK], DatanodeInfoWithStorage[127.0.0.1:36316,DS-359bf296-d90a-4d20-a0bd-904d11cf0ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:41412,DS-80dd5764-c3b7-46b1-826c-53310b6dd5d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45633,DS-a2ee49b5-d5b6-4006-add5-464ca3dd3f73,DISK], DatanodeInfoWithStorage[127.0.0.1:33193,DS-9ef10589-6ab7-42ae-b838-184b149a244e,DISK], DatanodeInfoWithStorage[127.0.0.1:43274,DS-795d8d66-f114-4842-9cd2-6a6b7937a972,DISK], DatanodeInfoWithStorage[127.0.0.1:43344,DS-c692ea9a-cb57-47f1-a991-c862d7297ae6,DISK], DatanodeInfoWithStorage[127.0.0.1:40529,DS-a9d8ce55-f7a9-4859-9820-86969c4fd646,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-408871977-172.17.0.7-1596986181925:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43487,DS-241f728f-e0ff-4488-a013-ab5b98ae0b85,DISK], DatanodeInfoWithStorage[127.0.0.1:41090,DS-caf598aa-c46f-4716-85ff-c0dd13a31e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:37465,DS-bd794d51-6012-42d6-af36-645a079d1908,DISK], DatanodeInfoWithStorage[127.0.0.1:44428,DS-ae291310-0045-4a22-8eee-583e0ede139a,DISK], DatanodeInfoWithStorage[127.0.0.1:36817,DS-15fbe666-4d58-41ac-ba09-47da4c77f880,DISK], DatanodeInfoWithStorage[127.0.0.1:40327,DS-375c10f1-807e-4cce-8ca6-67cdf0d140d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39600,DS-ec2745aa-211a-4fc3-9276-11d4604fd314,DISK], DatanodeInfoWithStorage[127.0.0.1:40499,DS-ab21093a-92ff-462c-a980-c49d4f13dfb7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-408871977-172.17.0.7-1596986181925:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43487,DS-241f728f-e0ff-4488-a013-ab5b98ae0b85,DISK], DatanodeInfoWithStorage[127.0.0.1:41090,DS-caf598aa-c46f-4716-85ff-c0dd13a31e0d,DISK], DatanodeInfoWithStorage[127.0.0.1:37465,DS-bd794d51-6012-42d6-af36-645a079d1908,DISK], DatanodeInfoWithStorage[127.0.0.1:44428,DS-ae291310-0045-4a22-8eee-583e0ede139a,DISK], DatanodeInfoWithStorage[127.0.0.1:36817,DS-15fbe666-4d58-41ac-ba09-47da4c77f880,DISK], DatanodeInfoWithStorage[127.0.0.1:40327,DS-375c10f1-807e-4cce-8ca6-67cdf0d140d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39600,DS-ec2745aa-211a-4fc3-9276-11d4604fd314,DISK], DatanodeInfoWithStorage[127.0.0.1:40499,DS-ab21093a-92ff-462c-a980-c49d4f13dfb7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-523673583-172.17.0.7-1596986432252:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42595,DS-31838cd6-bb66-4630-92f9-fd85ba6dd2e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39105,DS-0ed6e883-9852-4ef8-b95c-b4bfb74eaabe,DISK], DatanodeInfoWithStorage[127.0.0.1:36599,DS-91ca777f-0f2d-4f87-861d-21babd8d7a33,DISK], DatanodeInfoWithStorage[127.0.0.1:38992,DS-ea66ad16-0437-4ddc-b10d-21a766a72253,DISK], DatanodeInfoWithStorage[127.0.0.1:33774,DS-7676175e-28cf-4653-b42d-6b04ccc57227,DISK], DatanodeInfoWithStorage[127.0.0.1:38826,DS-c1609c70-8129-4666-a341-762608ab92ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46074,DS-59e698d7-6ec0-4eda-a8e3-2c22d9c655bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41051,DS-9d39985f-47ab-4baf-b351-24f24e36b462,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-523673583-172.17.0.7-1596986432252:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42595,DS-31838cd6-bb66-4630-92f9-fd85ba6dd2e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39105,DS-0ed6e883-9852-4ef8-b95c-b4bfb74eaabe,DISK], DatanodeInfoWithStorage[127.0.0.1:36599,DS-91ca777f-0f2d-4f87-861d-21babd8d7a33,DISK], DatanodeInfoWithStorage[127.0.0.1:38992,DS-ea66ad16-0437-4ddc-b10d-21a766a72253,DISK], DatanodeInfoWithStorage[127.0.0.1:33774,DS-7676175e-28cf-4653-b42d-6b04ccc57227,DISK], DatanodeInfoWithStorage[127.0.0.1:38826,DS-c1609c70-8129-4666-a341-762608ab92ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46074,DS-59e698d7-6ec0-4eda-a8e3-2c22d9c655bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41051,DS-9d39985f-47ab-4baf-b351-24f24e36b462,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-813511313-172.17.0.7-1596987217556:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45609,DS-600e7a4e-7252-4d21-bf99-f963ca6a3e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:43565,DS-d347f9f3-00c5-431c-a7ba-2872811332c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41919,DS-95c54c8f-dcf4-4312-8a93-8af36df97fbc,DISK], DatanodeInfoWithStorage[127.0.0.1:34924,DS-5670dc81-c27f-4c0f-a146-29ee3e7911d8,DISK], DatanodeInfoWithStorage[127.0.0.1:34597,DS-44617274-b472-4a5b-8637-9347a46c7620,DISK], DatanodeInfoWithStorage[127.0.0.1:38143,DS-98c09bb9-12af-452d-869f-f6a14079ca4c,DISK], DatanodeInfoWithStorage[127.0.0.1:45558,DS-511a0686-5b65-4ab5-86ee-ae6a4a7af33e,DISK], DatanodeInfoWithStorage[127.0.0.1:46140,DS-85010892-4942-405c-99a2-575cbcc57286,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-813511313-172.17.0.7-1596987217556:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45609,DS-600e7a4e-7252-4d21-bf99-f963ca6a3e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:43565,DS-d347f9f3-00c5-431c-a7ba-2872811332c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41919,DS-95c54c8f-dcf4-4312-8a93-8af36df97fbc,DISK], DatanodeInfoWithStorage[127.0.0.1:34924,DS-5670dc81-c27f-4c0f-a146-29ee3e7911d8,DISK], DatanodeInfoWithStorage[127.0.0.1:34597,DS-44617274-b472-4a5b-8637-9347a46c7620,DISK], DatanodeInfoWithStorage[127.0.0.1:38143,DS-98c09bb9-12af-452d-869f-f6a14079ca4c,DISK], DatanodeInfoWithStorage[127.0.0.1:45558,DS-511a0686-5b65-4ab5-86ee-ae6a4a7af33e,DISK], DatanodeInfoWithStorage[127.0.0.1:46140,DS-85010892-4942-405c-99a2-575cbcc57286,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1796645801-172.17.0.7-1596987258447:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37315,DS-03c4c174-d482-403a-a30b-dfb6d70f088e,DISK], DatanodeInfoWithStorage[127.0.0.1:43930,DS-1c38d008-c2d7-4119-b142-6d7c06d6d265,DISK], DatanodeInfoWithStorage[127.0.0.1:37353,DS-23c253b5-b127-48b8-98a3-2e55d71637a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41655,DS-983be11d-5732-46c8-8d7c-7f189ebd8e53,DISK], DatanodeInfoWithStorage[127.0.0.1:33474,DS-f4afca10-7046-48ca-bcc9-27d53dd41efd,DISK], DatanodeInfoWithStorage[127.0.0.1:44642,DS-2bb51537-b0e8-4d49-9270-53f89a5a0a32,DISK], DatanodeInfoWithStorage[127.0.0.1:45530,DS-18a5c771-f6a6-410b-a1c6-50902674ab4d,DISK], DatanodeInfoWithStorage[127.0.0.1:40079,DS-85660b28-bde5-4560-9327-5ebbced45107,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1796645801-172.17.0.7-1596987258447:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37315,DS-03c4c174-d482-403a-a30b-dfb6d70f088e,DISK], DatanodeInfoWithStorage[127.0.0.1:43930,DS-1c38d008-c2d7-4119-b142-6d7c06d6d265,DISK], DatanodeInfoWithStorage[127.0.0.1:37353,DS-23c253b5-b127-48b8-98a3-2e55d71637a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41655,DS-983be11d-5732-46c8-8d7c-7f189ebd8e53,DISK], DatanodeInfoWithStorage[127.0.0.1:33474,DS-f4afca10-7046-48ca-bcc9-27d53dd41efd,DISK], DatanodeInfoWithStorage[127.0.0.1:44642,DS-2bb51537-b0e8-4d49-9270-53f89a5a0a32,DISK], DatanodeInfoWithStorage[127.0.0.1:45530,DS-18a5c771-f6a6-410b-a1c6-50902674ab4d,DISK], DatanodeInfoWithStorage[127.0.0.1:40079,DS-85660b28-bde5-4560-9327-5ebbced45107,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1168790267-172.17.0.7-1596988170038:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45558,DS-248f6279-9f34-44af-b96a-9a6bdc2f12a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38564,DS-7106a622-4302-4705-a878-8c3f0bdd0efb,DISK], DatanodeInfoWithStorage[127.0.0.1:44741,DS-a4a4dc86-d94c-4c98-b903-e3ba00581111,DISK], DatanodeInfoWithStorage[127.0.0.1:38063,DS-18f6a3a4-3c3e-4770-ad36-8e953caad75a,DISK], DatanodeInfoWithStorage[127.0.0.1:34242,DS-5c8134c6-133d-4140-b97f-ef7cf12b1c0a,DISK], DatanodeInfoWithStorage[127.0.0.1:37628,DS-3f17521e-527a-4792-9602-8cf6478b0c45,DISK], DatanodeInfoWithStorage[127.0.0.1:33057,DS-a70728f0-2af6-4c09-818e-c986b3e71906,DISK], DatanodeInfoWithStorage[127.0.0.1:46801,DS-93adfe87-50f1-4725-8d66-d5b53933f8c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1168790267-172.17.0.7-1596988170038:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45558,DS-248f6279-9f34-44af-b96a-9a6bdc2f12a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38564,DS-7106a622-4302-4705-a878-8c3f0bdd0efb,DISK], DatanodeInfoWithStorage[127.0.0.1:44741,DS-a4a4dc86-d94c-4c98-b903-e3ba00581111,DISK], DatanodeInfoWithStorage[127.0.0.1:38063,DS-18f6a3a4-3c3e-4770-ad36-8e953caad75a,DISK], DatanodeInfoWithStorage[127.0.0.1:34242,DS-5c8134c6-133d-4140-b97f-ef7cf12b1c0a,DISK], DatanodeInfoWithStorage[127.0.0.1:37628,DS-3f17521e-527a-4792-9602-8cf6478b0c45,DISK], DatanodeInfoWithStorage[127.0.0.1:33057,DS-a70728f0-2af6-4c09-818e-c986b3e71906,DISK], DatanodeInfoWithStorage[127.0.0.1:46801,DS-93adfe87-50f1-4725-8d66-d5b53933f8c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-309956015-172.17.0.7-1596988187552:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45531,DS-b8c82e3b-d9bf-4069-a9cd-2c87ba2e464c,DISK], DatanodeInfoWithStorage[127.0.0.1:35633,DS-68784712-2eca-45cf-aea4-d3d5097cdb65,DISK], DatanodeInfoWithStorage[127.0.0.1:40261,DS-14b0e29f-1218-4c26-af9d-c14f02db8bef,DISK], DatanodeInfoWithStorage[127.0.0.1:45386,DS-af97f33d-43f2-442e-b46f-859a794e8f81,DISK], DatanodeInfoWithStorage[127.0.0.1:41276,DS-b7a8774b-db3c-4cd0-9751-310e405cd526,DISK], DatanodeInfoWithStorage[127.0.0.1:45472,DS-ee3f884f-6257-4b1a-b262-afaae958ff41,DISK], DatanodeInfoWithStorage[127.0.0.1:40873,DS-f4b05737-f710-4325-8e72-1d7b2ad6300c,DISK], DatanodeInfoWithStorage[127.0.0.1:40797,DS-7779f7b8-1ee7-43aa-a41f-39020dd8713b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-309956015-172.17.0.7-1596988187552:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45531,DS-b8c82e3b-d9bf-4069-a9cd-2c87ba2e464c,DISK], DatanodeInfoWithStorage[127.0.0.1:35633,DS-68784712-2eca-45cf-aea4-d3d5097cdb65,DISK], DatanodeInfoWithStorage[127.0.0.1:40261,DS-14b0e29f-1218-4c26-af9d-c14f02db8bef,DISK], DatanodeInfoWithStorage[127.0.0.1:45386,DS-af97f33d-43f2-442e-b46f-859a794e8f81,DISK], DatanodeInfoWithStorage[127.0.0.1:41276,DS-b7a8774b-db3c-4cd0-9751-310e405cd526,DISK], DatanodeInfoWithStorage[127.0.0.1:45472,DS-ee3f884f-6257-4b1a-b262-afaae958ff41,DISK], DatanodeInfoWithStorage[127.0.0.1:40873,DS-f4b05737-f710-4325-8e72-1d7b2ad6300c,DISK], DatanodeInfoWithStorage[127.0.0.1:40797,DS-7779f7b8-1ee7-43aa-a41f-39020dd8713b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1642893144-172.17.0.7-1596988220365:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35610,DS-4066160e-f5f9-4b84-8069-9fc173ad95aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33537,DS-0c6aeea8-375f-4e63-bf89-ebb1b228458b,DISK], DatanodeInfoWithStorage[127.0.0.1:36678,DS-0745ceef-5f19-47a5-8ee3-c0f28160d548,DISK], DatanodeInfoWithStorage[127.0.0.1:38691,DS-153cf183-6a6e-4758-a161-57ec66af617f,DISK], DatanodeInfoWithStorage[127.0.0.1:40354,DS-2cf1b714-0583-4ae0-aa22-fe9135408861,DISK], DatanodeInfoWithStorage[127.0.0.1:42276,DS-fddfe972-50ec-4a70-a18c-a8acf597e4e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40828,DS-c23b13f9-427e-4f6a-a9bb-1ee241777d65,DISK], DatanodeInfoWithStorage[127.0.0.1:35071,DS-b1d1de3e-737f-4e4f-b8c1-c90b825454b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1642893144-172.17.0.7-1596988220365:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35610,DS-4066160e-f5f9-4b84-8069-9fc173ad95aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33537,DS-0c6aeea8-375f-4e63-bf89-ebb1b228458b,DISK], DatanodeInfoWithStorage[127.0.0.1:36678,DS-0745ceef-5f19-47a5-8ee3-c0f28160d548,DISK], DatanodeInfoWithStorage[127.0.0.1:38691,DS-153cf183-6a6e-4758-a161-57ec66af617f,DISK], DatanodeInfoWithStorage[127.0.0.1:40354,DS-2cf1b714-0583-4ae0-aa22-fe9135408861,DISK], DatanodeInfoWithStorage[127.0.0.1:42276,DS-fddfe972-50ec-4a70-a18c-a8acf597e4e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40828,DS-c23b13f9-427e-4f6a-a9bb-1ee241777d65,DISK], DatanodeInfoWithStorage[127.0.0.1:35071,DS-b1d1de3e-737f-4e4f-b8c1-c90b825454b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1032178822-172.17.0.7-1596988353909:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37863,DS-c665772b-a222-49e8-bc7b-06f9c04e5d4b,DISK], DatanodeInfoWithStorage[127.0.0.1:35594,DS-51f215e8-0f0c-49f4-8be0-c37c1cd248cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41472,DS-bf78f8f2-01d1-40c3-8642-ae187feb5c25,DISK], DatanodeInfoWithStorage[127.0.0.1:33857,DS-01ff8527-db6f-484a-af81-ef3347be7a64,DISK], DatanodeInfoWithStorage[127.0.0.1:42860,DS-41d80f45-1dd2-4f30-b01a-4b02efad6586,DISK], DatanodeInfoWithStorage[127.0.0.1:35544,DS-352b314b-dbbd-40ff-9021-38583ecbfbe7,DISK], DatanodeInfoWithStorage[127.0.0.1:40301,DS-259b51dc-15f5-4981-95e8-5b16a301b6f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36052,DS-9b93ffea-bde8-4c3b-9c41-d5d2d05c6d1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1032178822-172.17.0.7-1596988353909:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37863,DS-c665772b-a222-49e8-bc7b-06f9c04e5d4b,DISK], DatanodeInfoWithStorage[127.0.0.1:35594,DS-51f215e8-0f0c-49f4-8be0-c37c1cd248cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41472,DS-bf78f8f2-01d1-40c3-8642-ae187feb5c25,DISK], DatanodeInfoWithStorage[127.0.0.1:33857,DS-01ff8527-db6f-484a-af81-ef3347be7a64,DISK], DatanodeInfoWithStorage[127.0.0.1:42860,DS-41d80f45-1dd2-4f30-b01a-4b02efad6586,DISK], DatanodeInfoWithStorage[127.0.0.1:35544,DS-352b314b-dbbd-40ff-9021-38583ecbfbe7,DISK], DatanodeInfoWithStorage[127.0.0.1:40301,DS-259b51dc-15f5-4981-95e8-5b16a301b6f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36052,DS-9b93ffea-bde8-4c3b-9c41-d5d2d05c6d1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1315017527-172.17.0.7-1596988403298:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37952,DS-188e8260-81fd-4b7a-9d1f-c66f5d1bcd73,DISK], DatanodeInfoWithStorage[127.0.0.1:37509,DS-513f12fc-31f9-4e53-a3ba-ca8de8a87486,DISK], DatanodeInfoWithStorage[127.0.0.1:42728,DS-302acadc-d2ec-45c4-9b84-bc07eb44cf37,DISK], DatanodeInfoWithStorage[127.0.0.1:44976,DS-150601fa-bcbb-49d8-8745-2ae3f5d632d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33551,DS-cf78bc27-43ed-4911-8452-8b6bb9447193,DISK], DatanodeInfoWithStorage[127.0.0.1:41527,DS-1e987229-6a38-4f32-9b7d-938108e02045,DISK], DatanodeInfoWithStorage[127.0.0.1:45230,DS-49a27a6b-d859-491e-a9b4-9b116377dee1,DISK], DatanodeInfoWithStorage[127.0.0.1:40809,DS-754fe1f7-b145-4607-b5f8-b9bc2da316c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1315017527-172.17.0.7-1596988403298:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37952,DS-188e8260-81fd-4b7a-9d1f-c66f5d1bcd73,DISK], DatanodeInfoWithStorage[127.0.0.1:37509,DS-513f12fc-31f9-4e53-a3ba-ca8de8a87486,DISK], DatanodeInfoWithStorage[127.0.0.1:42728,DS-302acadc-d2ec-45c4-9b84-bc07eb44cf37,DISK], DatanodeInfoWithStorage[127.0.0.1:44976,DS-150601fa-bcbb-49d8-8745-2ae3f5d632d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33551,DS-cf78bc27-43ed-4911-8452-8b6bb9447193,DISK], DatanodeInfoWithStorage[127.0.0.1:41527,DS-1e987229-6a38-4f32-9b7d-938108e02045,DISK], DatanodeInfoWithStorage[127.0.0.1:45230,DS-49a27a6b-d859-491e-a9b4-9b116377dee1,DISK], DatanodeInfoWithStorage[127.0.0.1:40809,DS-754fe1f7-b145-4607-b5f8-b9bc2da316c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-386998835-172.17.0.7-1596988435651:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39113,DS-a09acccc-e57f-42e0-9217-0a30ecdfa5cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43319,DS-018d8113-01f2-4171-8a36-88138a320d13,DISK], DatanodeInfoWithStorage[127.0.0.1:34000,DS-3a73ab3f-049b-42bd-8ec7-5014ec9f5107,DISK], DatanodeInfoWithStorage[127.0.0.1:43087,DS-3ef84da8-411a-4325-be65-5b924a69ad98,DISK], DatanodeInfoWithStorage[127.0.0.1:32949,DS-d099b669-c396-4cc7-b79a-c38d94b005e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39771,DS-16033536-d14e-4a6c-b71c-36f4ea1ca0b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36213,DS-535364c7-b01a-476b-9abd-bbcd61a0c223,DISK], DatanodeInfoWithStorage[127.0.0.1:43099,DS-3827a1ae-1da0-4e6b-8ae2-ce1a47bc7b1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-386998835-172.17.0.7-1596988435651:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39113,DS-a09acccc-e57f-42e0-9217-0a30ecdfa5cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43319,DS-018d8113-01f2-4171-8a36-88138a320d13,DISK], DatanodeInfoWithStorage[127.0.0.1:34000,DS-3a73ab3f-049b-42bd-8ec7-5014ec9f5107,DISK], DatanodeInfoWithStorage[127.0.0.1:43087,DS-3ef84da8-411a-4325-be65-5b924a69ad98,DISK], DatanodeInfoWithStorage[127.0.0.1:32949,DS-d099b669-c396-4cc7-b79a-c38d94b005e3,DISK], DatanodeInfoWithStorage[127.0.0.1:39771,DS-16033536-d14e-4a6c-b71c-36f4ea1ca0b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36213,DS-535364c7-b01a-476b-9abd-bbcd61a0c223,DISK], DatanodeInfoWithStorage[127.0.0.1:43099,DS-3827a1ae-1da0-4e6b-8ae2-ce1a47bc7b1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1578996600-172.17.0.7-1596988635680:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36931,DS-ea61ce09-fd1a-459a-a3d5-ff35b55b4601,DISK], DatanodeInfoWithStorage[127.0.0.1:44930,DS-5638f697-808b-4795-b4c1-cdbd7eedeb10,DISK], DatanodeInfoWithStorage[127.0.0.1:44106,DS-4f938db9-bf45-4192-a0f2-afa6b4dbc75c,DISK], DatanodeInfoWithStorage[127.0.0.1:36179,DS-9b26e13a-238c-4efe-8a22-b864e96aaee9,DISK], DatanodeInfoWithStorage[127.0.0.1:43268,DS-1e8b7257-17dc-4395-9137-c0edc79e4888,DISK], DatanodeInfoWithStorage[127.0.0.1:32994,DS-218f8038-34e4-4465-8e87-c1eae7f3e587,DISK], DatanodeInfoWithStorage[127.0.0.1:33090,DS-255ca5fa-5aa7-4180-9c1d-758392f8c8a3,DISK], DatanodeInfoWithStorage[127.0.0.1:45712,DS-12ea9bc8-b737-4254-81c1-ba8d94e03083,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1578996600-172.17.0.7-1596988635680:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36931,DS-ea61ce09-fd1a-459a-a3d5-ff35b55b4601,DISK], DatanodeInfoWithStorage[127.0.0.1:44930,DS-5638f697-808b-4795-b4c1-cdbd7eedeb10,DISK], DatanodeInfoWithStorage[127.0.0.1:44106,DS-4f938db9-bf45-4192-a0f2-afa6b4dbc75c,DISK], DatanodeInfoWithStorage[127.0.0.1:36179,DS-9b26e13a-238c-4efe-8a22-b864e96aaee9,DISK], DatanodeInfoWithStorage[127.0.0.1:43268,DS-1e8b7257-17dc-4395-9137-c0edc79e4888,DISK], DatanodeInfoWithStorage[127.0.0.1:32994,DS-218f8038-34e4-4465-8e87-c1eae7f3e587,DISK], DatanodeInfoWithStorage[127.0.0.1:33090,DS-255ca5fa-5aa7-4180-9c1d-758392f8c8a3,DISK], DatanodeInfoWithStorage[127.0.0.1:45712,DS-12ea9bc8-b737-4254-81c1-ba8d94e03083,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2048944648-172.17.0.7-1596988652433:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39375,DS-8de63713-7eca-4945-a298-1f5a1b5f1c20,DISK], DatanodeInfoWithStorage[127.0.0.1:37574,DS-bad37c4f-c564-4bc3-81cf-c4c4716463b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34238,DS-ba3b17e8-f6f9-4e2a-8e00-a34ab70944ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39461,DS-7602b248-4933-4a3b-a871-aab6111069f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39014,DS-c398e63b-2e26-4deb-aa18-5f3ddc276a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:33537,DS-1b9a6c65-c55a-46b8-ba41-c9811828486b,DISK], DatanodeInfoWithStorage[127.0.0.1:41493,DS-5581a631-f4df-4311-9ba9-276173958082,DISK], DatanodeInfoWithStorage[127.0.0.1:45793,DS-2fbe8703-2a02-4d6d-9405-77084a54b6ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2048944648-172.17.0.7-1596988652433:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39375,DS-8de63713-7eca-4945-a298-1f5a1b5f1c20,DISK], DatanodeInfoWithStorage[127.0.0.1:37574,DS-bad37c4f-c564-4bc3-81cf-c4c4716463b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34238,DS-ba3b17e8-f6f9-4e2a-8e00-a34ab70944ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39461,DS-7602b248-4933-4a3b-a871-aab6111069f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39014,DS-c398e63b-2e26-4deb-aa18-5f3ddc276a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:33537,DS-1b9a6c65-c55a-46b8-ba41-c9811828486b,DISK], DatanodeInfoWithStorage[127.0.0.1:41493,DS-5581a631-f4df-4311-9ba9-276173958082,DISK], DatanodeInfoWithStorage[127.0.0.1:45793,DS-2fbe8703-2a02-4d6d-9405-77084a54b6ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1811215716-172.17.0.7-1596988849586:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39878,DS-4ff15804-031f-42f2-a0d1-a0622313b560,DISK], DatanodeInfoWithStorage[127.0.0.1:36469,DS-78dce155-7854-4269-b769-0fe1a8b0e05b,DISK], DatanodeInfoWithStorage[127.0.0.1:37790,DS-2743e680-2acc-46a4-a879-e431b68e9145,DISK], DatanodeInfoWithStorage[127.0.0.1:36571,DS-a2f2540d-48b4-4b48-a738-b2c9e8fc4e30,DISK], DatanodeInfoWithStorage[127.0.0.1:45397,DS-ff4f7df0-2e6a-4057-b1a3-10082068a517,DISK], DatanodeInfoWithStorage[127.0.0.1:35666,DS-f3dca0fa-4d35-40a2-8ac6-1d1563fc3c39,DISK], DatanodeInfoWithStorage[127.0.0.1:43091,DS-48c65b2a-6f9f-4e19-9dd4-83b3e1469f78,DISK], DatanodeInfoWithStorage[127.0.0.1:39736,DS-c21fe512-e567-4330-a3e5-febd977c8ebd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1811215716-172.17.0.7-1596988849586:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39878,DS-4ff15804-031f-42f2-a0d1-a0622313b560,DISK], DatanodeInfoWithStorage[127.0.0.1:36469,DS-78dce155-7854-4269-b769-0fe1a8b0e05b,DISK], DatanodeInfoWithStorage[127.0.0.1:37790,DS-2743e680-2acc-46a4-a879-e431b68e9145,DISK], DatanodeInfoWithStorage[127.0.0.1:36571,DS-a2f2540d-48b4-4b48-a738-b2c9e8fc4e30,DISK], DatanodeInfoWithStorage[127.0.0.1:45397,DS-ff4f7df0-2e6a-4057-b1a3-10082068a517,DISK], DatanodeInfoWithStorage[127.0.0.1:35666,DS-f3dca0fa-4d35-40a2-8ac6-1d1563fc3c39,DISK], DatanodeInfoWithStorage[127.0.0.1:43091,DS-48c65b2a-6f9f-4e19-9dd4-83b3e1469f78,DISK], DatanodeInfoWithStorage[127.0.0.1:39736,DS-c21fe512-e567-4330-a3e5-febd977c8ebd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-530244081-172.17.0.7-1596988916081:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34368,DS-74904f5e-c89b-4384-a3de-286e4ea8c664,DISK], DatanodeInfoWithStorage[127.0.0.1:35384,DS-eada2b4a-05fe-4e15-8ffd-926be477b57e,DISK], DatanodeInfoWithStorage[127.0.0.1:38457,DS-0e64591d-c4aa-4fef-806f-9a4cb79c9657,DISK], DatanodeInfoWithStorage[127.0.0.1:38881,DS-fd87faed-f41d-4b43-878f-9c47324ded2f,DISK], DatanodeInfoWithStorage[127.0.0.1:34195,DS-7d555183-117c-47dc-97c5-ef22b7f7c41a,DISK], DatanodeInfoWithStorage[127.0.0.1:40683,DS-e8209171-a6dd-4749-b725-a923584bb50c,DISK], DatanodeInfoWithStorage[127.0.0.1:46627,DS-97541c65-5465-44cd-9ab8-b6e7c0f968fe,DISK], DatanodeInfoWithStorage[127.0.0.1:44038,DS-92dc94ed-5377-4304-920c-3d0b14cb54ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-530244081-172.17.0.7-1596988916081:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34368,DS-74904f5e-c89b-4384-a3de-286e4ea8c664,DISK], DatanodeInfoWithStorage[127.0.0.1:35384,DS-eada2b4a-05fe-4e15-8ffd-926be477b57e,DISK], DatanodeInfoWithStorage[127.0.0.1:38457,DS-0e64591d-c4aa-4fef-806f-9a4cb79c9657,DISK], DatanodeInfoWithStorage[127.0.0.1:38881,DS-fd87faed-f41d-4b43-878f-9c47324ded2f,DISK], DatanodeInfoWithStorage[127.0.0.1:34195,DS-7d555183-117c-47dc-97c5-ef22b7f7c41a,DISK], DatanodeInfoWithStorage[127.0.0.1:40683,DS-e8209171-a6dd-4749-b725-a923584bb50c,DISK], DatanodeInfoWithStorage[127.0.0.1:46627,DS-97541c65-5465-44cd-9ab8-b6e7c0f968fe,DISK], DatanodeInfoWithStorage[127.0.0.1:44038,DS-92dc94ed-5377-4304-920c-3d0b14cb54ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2088548677-172.17.0.7-1596989099565:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39989,DS-f4a01bcf-1553-4b8a-b1b4-948cfe17e5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44024,DS-7028f148-fa17-433c-ad1b-b69b8210ceee,DISK], DatanodeInfoWithStorage[127.0.0.1:35469,DS-0c2fd702-c5fe-4c6e-99d6-63c6077af0eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39815,DS-ad54d846-3919-4f6f-b698-5692222e90f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38618,DS-0cc92e43-03dc-4e51-b656-ef85cf764ee8,DISK], DatanodeInfoWithStorage[127.0.0.1:41119,DS-f3f7afdf-1414-498a-9073-57a013972caf,DISK], DatanodeInfoWithStorage[127.0.0.1:44187,DS-fb1c4a92-62fd-452e-9c37-5aecd5bfc1ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36701,DS-7261d7c0-3850-4231-88a4-d195db80cb85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2088548677-172.17.0.7-1596989099565:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39989,DS-f4a01bcf-1553-4b8a-b1b4-948cfe17e5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44024,DS-7028f148-fa17-433c-ad1b-b69b8210ceee,DISK], DatanodeInfoWithStorage[127.0.0.1:35469,DS-0c2fd702-c5fe-4c6e-99d6-63c6077af0eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39815,DS-ad54d846-3919-4f6f-b698-5692222e90f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38618,DS-0cc92e43-03dc-4e51-b656-ef85cf764ee8,DISK], DatanodeInfoWithStorage[127.0.0.1:41119,DS-f3f7afdf-1414-498a-9073-57a013972caf,DISK], DatanodeInfoWithStorage[127.0.0.1:44187,DS-fb1c4a92-62fd-452e-9c37-5aecd5bfc1ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36701,DS-7261d7c0-3850-4231-88a4-d195db80cb85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-448522722-172.17.0.7-1596989166592:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46645,DS-19287af8-5172-4cd1-9fc9-51492249a07c,DISK], DatanodeInfoWithStorage[127.0.0.1:41889,DS-f69462c9-6322-4394-b3c5-3f2adf007b23,DISK], DatanodeInfoWithStorage[127.0.0.1:37421,DS-a108f6b8-cf2f-4396-b69a-f3619019c54e,DISK], DatanodeInfoWithStorage[127.0.0.1:46759,DS-7fbd669f-bf3e-4b81-91ba-9bf784216ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:44004,DS-f09b5e9c-845c-4233-ab1b-964ce4917bc6,DISK], DatanodeInfoWithStorage[127.0.0.1:37983,DS-f1d1d083-005d-4c57-8fbf-955376a8458d,DISK], DatanodeInfoWithStorage[127.0.0.1:37446,DS-2014af94-4fa7-46a8-a125-1c0e90c65ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:46419,DS-051549d4-5d69-4c21-be32-bdbe628f3e12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-448522722-172.17.0.7-1596989166592:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46645,DS-19287af8-5172-4cd1-9fc9-51492249a07c,DISK], DatanodeInfoWithStorage[127.0.0.1:41889,DS-f69462c9-6322-4394-b3c5-3f2adf007b23,DISK], DatanodeInfoWithStorage[127.0.0.1:37421,DS-a108f6b8-cf2f-4396-b69a-f3619019c54e,DISK], DatanodeInfoWithStorage[127.0.0.1:46759,DS-7fbd669f-bf3e-4b81-91ba-9bf784216ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:44004,DS-f09b5e9c-845c-4233-ab1b-964ce4917bc6,DISK], DatanodeInfoWithStorage[127.0.0.1:37983,DS-f1d1d083-005d-4c57-8fbf-955376a8458d,DISK], DatanodeInfoWithStorage[127.0.0.1:37446,DS-2014af94-4fa7-46a8-a125-1c0e90c65ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:46419,DS-051549d4-5d69-4c21-be32-bdbe628f3e12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 3543
