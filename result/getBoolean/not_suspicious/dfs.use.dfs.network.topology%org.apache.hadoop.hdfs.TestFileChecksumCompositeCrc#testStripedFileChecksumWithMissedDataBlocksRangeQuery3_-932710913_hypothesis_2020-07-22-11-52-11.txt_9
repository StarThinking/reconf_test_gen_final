reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-929008575-172.17.0.7-1595418783271:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36306,DS-7cb9cb1d-0c72-4335-9e39-aad332af783c,DISK], DatanodeInfoWithStorage[127.0.0.1:32993,DS-8b680a8f-944d-4e73-b2c5-17cc6791ce19,DISK], DatanodeInfoWithStorage[127.0.0.1:35870,DS-009ee7c5-309b-4c44-b485-6aba8b75947c,DISK], DatanodeInfoWithStorage[127.0.0.1:35410,DS-19a77243-22ed-4b44-8dfc-c31adef366aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37432,DS-b1db2774-b323-4fd4-b9c2-8b5b4aef1d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:35908,DS-eaedf667-1eb5-4671-81a4-049e609cd7d8,DISK], DatanodeInfoWithStorage[127.0.0.1:46510,DS-7f74bec9-c65f-42fb-a476-3d1824523074,DISK], DatanodeInfoWithStorage[127.0.0.1:35956,DS-05a6e812-60b8-47e2-a6bb-a123f3f8e004,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-929008575-172.17.0.7-1595418783271:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36306,DS-7cb9cb1d-0c72-4335-9e39-aad332af783c,DISK], DatanodeInfoWithStorage[127.0.0.1:32993,DS-8b680a8f-944d-4e73-b2c5-17cc6791ce19,DISK], DatanodeInfoWithStorage[127.0.0.1:35870,DS-009ee7c5-309b-4c44-b485-6aba8b75947c,DISK], DatanodeInfoWithStorage[127.0.0.1:35410,DS-19a77243-22ed-4b44-8dfc-c31adef366aa,DISK], DatanodeInfoWithStorage[127.0.0.1:37432,DS-b1db2774-b323-4fd4-b9c2-8b5b4aef1d1c,DISK], DatanodeInfoWithStorage[127.0.0.1:35908,DS-eaedf667-1eb5-4671-81a4-049e609cd7d8,DISK], DatanodeInfoWithStorage[127.0.0.1:46510,DS-7f74bec9-c65f-42fb-a476-3d1824523074,DISK], DatanodeInfoWithStorage[127.0.0.1:35956,DS-05a6e812-60b8-47e2-a6bb-a123f3f8e004,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1504163308-172.17.0.7-1595418973830:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36806,DS-57273507-e537-42a0-9001-4a27bbf59c55,DISK], DatanodeInfoWithStorage[127.0.0.1:34132,DS-c19c520b-809a-4b5c-a9d0-dd625034596a,DISK], DatanodeInfoWithStorage[127.0.0.1:40352,DS-fef1551f-36c1-46b9-96fc-e7843652b97b,DISK], DatanodeInfoWithStorage[127.0.0.1:34850,DS-cc75e90f-4921-4a7b-8199-7c523eddca3f,DISK], DatanodeInfoWithStorage[127.0.0.1:35800,DS-64f90498-850e-4ec9-8d9b-01a368106553,DISK], DatanodeInfoWithStorage[127.0.0.1:39271,DS-7fdb8308-6e06-4ebd-acc0-17ecb228c491,DISK], DatanodeInfoWithStorage[127.0.0.1:37851,DS-6de562e5-3b92-47ba-8b57-d8f3b3c0a031,DISK], DatanodeInfoWithStorage[127.0.0.1:34870,DS-45406b6d-cff9-470b-b763-4e994ea81667,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1504163308-172.17.0.7-1595418973830:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36806,DS-57273507-e537-42a0-9001-4a27bbf59c55,DISK], DatanodeInfoWithStorage[127.0.0.1:34132,DS-c19c520b-809a-4b5c-a9d0-dd625034596a,DISK], DatanodeInfoWithStorage[127.0.0.1:40352,DS-fef1551f-36c1-46b9-96fc-e7843652b97b,DISK], DatanodeInfoWithStorage[127.0.0.1:34850,DS-cc75e90f-4921-4a7b-8199-7c523eddca3f,DISK], DatanodeInfoWithStorage[127.0.0.1:35800,DS-64f90498-850e-4ec9-8d9b-01a368106553,DISK], DatanodeInfoWithStorage[127.0.0.1:39271,DS-7fdb8308-6e06-4ebd-acc0-17ecb228c491,DISK], DatanodeInfoWithStorage[127.0.0.1:37851,DS-6de562e5-3b92-47ba-8b57-d8f3b3c0a031,DISK], DatanodeInfoWithStorage[127.0.0.1:34870,DS-45406b6d-cff9-470b-b763-4e994ea81667,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2069628099-172.17.0.7-1595419731514:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33056,DS-bc472f16-e023-4d88-8d2c-c0311598766b,DISK], DatanodeInfoWithStorage[127.0.0.1:35860,DS-585c8a89-b8eb-4f27-8330-aa4fb90ec578,DISK], DatanodeInfoWithStorage[127.0.0.1:42099,DS-305939b6-4e59-4273-abc7-f72b7f5d1bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:39661,DS-7655f279-ec32-4926-b82b-6293505f9671,DISK], DatanodeInfoWithStorage[127.0.0.1:37441,DS-43a8244e-5b5e-41c0-9276-63c05afb32cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42096,DS-fd65da14-bd82-46a7-8f16-1e4e5bd8753b,DISK], DatanodeInfoWithStorage[127.0.0.1:38912,DS-7de39e84-f89f-48ec-9bfa-48e677e2613f,DISK], DatanodeInfoWithStorage[127.0.0.1:41175,DS-49264642-04ca-42bc-bc78-071213cf4d31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2069628099-172.17.0.7-1595419731514:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33056,DS-bc472f16-e023-4d88-8d2c-c0311598766b,DISK], DatanodeInfoWithStorage[127.0.0.1:35860,DS-585c8a89-b8eb-4f27-8330-aa4fb90ec578,DISK], DatanodeInfoWithStorage[127.0.0.1:42099,DS-305939b6-4e59-4273-abc7-f72b7f5d1bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:39661,DS-7655f279-ec32-4926-b82b-6293505f9671,DISK], DatanodeInfoWithStorage[127.0.0.1:37441,DS-43a8244e-5b5e-41c0-9276-63c05afb32cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42096,DS-fd65da14-bd82-46a7-8f16-1e4e5bd8753b,DISK], DatanodeInfoWithStorage[127.0.0.1:38912,DS-7de39e84-f89f-48ec-9bfa-48e677e2613f,DISK], DatanodeInfoWithStorage[127.0.0.1:41175,DS-49264642-04ca-42bc-bc78-071213cf4d31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1336782949-172.17.0.7-1595419838468:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35210,DS-80713fb8-da9a-4ab4-987a-1362cbaa498a,DISK], DatanodeInfoWithStorage[127.0.0.1:40363,DS-b26d4714-d2c7-4df5-86de-5843c114754c,DISK], DatanodeInfoWithStorage[127.0.0.1:41069,DS-491e0e48-4ea4-4238-b2d2-7d467d8bc53a,DISK], DatanodeInfoWithStorage[127.0.0.1:45131,DS-9ebf18dc-185e-4a3c-8e5b-762684635865,DISK], DatanodeInfoWithStorage[127.0.0.1:38096,DS-3d951190-424c-40c0-a7c1-e57706c34121,DISK], DatanodeInfoWithStorage[127.0.0.1:32920,DS-34b376c4-82d5-490a-aacd-41087acc0e06,DISK], DatanodeInfoWithStorage[127.0.0.1:34703,DS-64c214dd-f938-4aab-a19f-d8e95613c12c,DISK], DatanodeInfoWithStorage[127.0.0.1:37925,DS-3d62d8d6-2ab7-4f08-ac1b-876537a78221,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1336782949-172.17.0.7-1595419838468:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35210,DS-80713fb8-da9a-4ab4-987a-1362cbaa498a,DISK], DatanodeInfoWithStorage[127.0.0.1:40363,DS-b26d4714-d2c7-4df5-86de-5843c114754c,DISK], DatanodeInfoWithStorage[127.0.0.1:41069,DS-491e0e48-4ea4-4238-b2d2-7d467d8bc53a,DISK], DatanodeInfoWithStorage[127.0.0.1:45131,DS-9ebf18dc-185e-4a3c-8e5b-762684635865,DISK], DatanodeInfoWithStorage[127.0.0.1:38096,DS-3d951190-424c-40c0-a7c1-e57706c34121,DISK], DatanodeInfoWithStorage[127.0.0.1:32920,DS-34b376c4-82d5-490a-aacd-41087acc0e06,DISK], DatanodeInfoWithStorage[127.0.0.1:34703,DS-64c214dd-f938-4aab-a19f-d8e95613c12c,DISK], DatanodeInfoWithStorage[127.0.0.1:37925,DS-3d62d8d6-2ab7-4f08-ac1b-876537a78221,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-854363939-172.17.0.7-1595420508372:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38564,DS-084878fe-1c29-40b3-ad4d-dbb95da31425,DISK], DatanodeInfoWithStorage[127.0.0.1:41608,DS-b32266f0-77de-4a5a-935c-f67be35ba597,DISK], DatanodeInfoWithStorage[127.0.0.1:46643,DS-ddddbad1-88c0-47b6-bdd7-7313f2f2b355,DISK], DatanodeInfoWithStorage[127.0.0.1:41228,DS-b2283775-15c7-481c-8102-de93a3e1aee3,DISK], DatanodeInfoWithStorage[127.0.0.1:38830,DS-01ce0254-26e1-4e38-85d9-4511d68b1d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:41936,DS-937c3e07-036f-4993-895a-3043f758221b,DISK], DatanodeInfoWithStorage[127.0.0.1:36034,DS-cbc4dcd5-d9e9-4dcc-af81-179d6d9290e6,DISK], DatanodeInfoWithStorage[127.0.0.1:34429,DS-4b637faf-cc3f-4d9c-86ba-0e20b212c5a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-854363939-172.17.0.7-1595420508372:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38564,DS-084878fe-1c29-40b3-ad4d-dbb95da31425,DISK], DatanodeInfoWithStorage[127.0.0.1:41608,DS-b32266f0-77de-4a5a-935c-f67be35ba597,DISK], DatanodeInfoWithStorage[127.0.0.1:46643,DS-ddddbad1-88c0-47b6-bdd7-7313f2f2b355,DISK], DatanodeInfoWithStorage[127.0.0.1:41228,DS-b2283775-15c7-481c-8102-de93a3e1aee3,DISK], DatanodeInfoWithStorage[127.0.0.1:38830,DS-01ce0254-26e1-4e38-85d9-4511d68b1d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:41936,DS-937c3e07-036f-4993-895a-3043f758221b,DISK], DatanodeInfoWithStorage[127.0.0.1:36034,DS-cbc4dcd5-d9e9-4dcc-af81-179d6d9290e6,DISK], DatanodeInfoWithStorage[127.0.0.1:34429,DS-4b637faf-cc3f-4d9c-86ba-0e20b212c5a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-955820520-172.17.0.7-1595421027602:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42067,DS-9eeeb39b-33aa-446d-ba2f-d5a81e332c2d,DISK], DatanodeInfoWithStorage[127.0.0.1:35849,DS-e13fce39-c2d2-42d9-8719-0742cb0b5035,DISK], DatanodeInfoWithStorage[127.0.0.1:40098,DS-24528a4d-e663-4261-86e2-53184fa7fb52,DISK], DatanodeInfoWithStorage[127.0.0.1:34080,DS-646619e3-3205-4953-8946-971f8ffadb7e,DISK], DatanodeInfoWithStorage[127.0.0.1:39253,DS-040d2d6c-5e11-4bee-b099-de818f35735e,DISK], DatanodeInfoWithStorage[127.0.0.1:45454,DS-caedc228-079f-4f33-b939-234a52f7979f,DISK], DatanodeInfoWithStorage[127.0.0.1:43722,DS-ab801a6c-b048-4522-9769-58c81bdd829e,DISK], DatanodeInfoWithStorage[127.0.0.1:45178,DS-30959e24-c2ed-4717-a91b-a6cc0ac00cff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-955820520-172.17.0.7-1595421027602:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42067,DS-9eeeb39b-33aa-446d-ba2f-d5a81e332c2d,DISK], DatanodeInfoWithStorage[127.0.0.1:35849,DS-e13fce39-c2d2-42d9-8719-0742cb0b5035,DISK], DatanodeInfoWithStorage[127.0.0.1:40098,DS-24528a4d-e663-4261-86e2-53184fa7fb52,DISK], DatanodeInfoWithStorage[127.0.0.1:34080,DS-646619e3-3205-4953-8946-971f8ffadb7e,DISK], DatanodeInfoWithStorage[127.0.0.1:39253,DS-040d2d6c-5e11-4bee-b099-de818f35735e,DISK], DatanodeInfoWithStorage[127.0.0.1:45454,DS-caedc228-079f-4f33-b939-234a52f7979f,DISK], DatanodeInfoWithStorage[127.0.0.1:43722,DS-ab801a6c-b048-4522-9769-58c81bdd829e,DISK], DatanodeInfoWithStorage[127.0.0.1:45178,DS-30959e24-c2ed-4717-a91b-a6cc0ac00cff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1044173319-172.17.0.7-1595421328361:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42719,DS-d16a813f-1fab-439a-86e1-f013ed404730,DISK], DatanodeInfoWithStorage[127.0.0.1:35207,DS-a6c53057-bf8e-44bd-a89d-e3f420e915de,DISK], DatanodeInfoWithStorage[127.0.0.1:32885,DS-965be49f-9903-4744-a1c4-a28fd38e7661,DISK], DatanodeInfoWithStorage[127.0.0.1:42023,DS-44f5634c-cb6e-42e3-a9e0-e0d4904a0912,DISK], DatanodeInfoWithStorage[127.0.0.1:38327,DS-fcb8bdf7-989a-4342-bfff-c0fd31b85591,DISK], DatanodeInfoWithStorage[127.0.0.1:39931,DS-0464a71e-0984-405e-9692-28e3cbf49b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:38657,DS-838aeeaa-bbf6-4a12-94bc-35ea01e687a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39231,DS-4af7fddb-3317-4553-9ade-b08b12fa11d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1044173319-172.17.0.7-1595421328361:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42719,DS-d16a813f-1fab-439a-86e1-f013ed404730,DISK], DatanodeInfoWithStorage[127.0.0.1:35207,DS-a6c53057-bf8e-44bd-a89d-e3f420e915de,DISK], DatanodeInfoWithStorage[127.0.0.1:32885,DS-965be49f-9903-4744-a1c4-a28fd38e7661,DISK], DatanodeInfoWithStorage[127.0.0.1:42023,DS-44f5634c-cb6e-42e3-a9e0-e0d4904a0912,DISK], DatanodeInfoWithStorage[127.0.0.1:38327,DS-fcb8bdf7-989a-4342-bfff-c0fd31b85591,DISK], DatanodeInfoWithStorage[127.0.0.1:39931,DS-0464a71e-0984-405e-9692-28e3cbf49b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:38657,DS-838aeeaa-bbf6-4a12-94bc-35ea01e687a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39231,DS-4af7fddb-3317-4553-9ade-b08b12fa11d2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2021020168-172.17.0.7-1595421446162:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41382,DS-32ae1009-8fbc-419d-8c67-69bdfd130560,DISK], DatanodeInfoWithStorage[127.0.0.1:34546,DS-7988bb8e-9107-411a-9ca2-fb21cf3232d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34107,DS-7446a1fa-118e-46d6-8ee1-98c804fd730d,DISK], DatanodeInfoWithStorage[127.0.0.1:44680,DS-b9a70b2b-52a5-47dc-b077-2cde841a17d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43851,DS-18d5e599-8274-4834-aa3c-c16cf1566c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:46261,DS-3ed51a4e-0ac9-440e-8f35-8244030926d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34174,DS-5f77b13c-798e-46ef-9073-5a24b6942bee,DISK], DatanodeInfoWithStorage[127.0.0.1:38778,DS-10e7e797-c828-46e0-82b2-d8debbab42e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2021020168-172.17.0.7-1595421446162:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41382,DS-32ae1009-8fbc-419d-8c67-69bdfd130560,DISK], DatanodeInfoWithStorage[127.0.0.1:34546,DS-7988bb8e-9107-411a-9ca2-fb21cf3232d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34107,DS-7446a1fa-118e-46d6-8ee1-98c804fd730d,DISK], DatanodeInfoWithStorage[127.0.0.1:44680,DS-b9a70b2b-52a5-47dc-b077-2cde841a17d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43851,DS-18d5e599-8274-4834-aa3c-c16cf1566c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:46261,DS-3ed51a4e-0ac9-440e-8f35-8244030926d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34174,DS-5f77b13c-798e-46ef-9073-5a24b6942bee,DISK], DatanodeInfoWithStorage[127.0.0.1:38778,DS-10e7e797-c828-46e0-82b2-d8debbab42e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-927975061-172.17.0.7-1595421462444:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39299,DS-684e629d-deaf-41a8-a16e-0b7c0183f2d5,DISK], DatanodeInfoWithStorage[127.0.0.1:37864,DS-c1af3f20-9463-484c-a9d2-4d6e1aa9fc44,DISK], DatanodeInfoWithStorage[127.0.0.1:36586,DS-1f8b30e8-1437-423e-aee7-1f6901357dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:41850,DS-aba19012-0d39-45ee-834c-f81e5b717009,DISK], DatanodeInfoWithStorage[127.0.0.1:46558,DS-b7f08721-90ef-4145-9d12-634cc37f25fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36416,DS-bbbdaf86-26bb-496b-acf0-b46cbc11ad43,DISK], DatanodeInfoWithStorage[127.0.0.1:45463,DS-70bf75ae-1569-448e-abfd-28313cf5e0e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38697,DS-38a5c7bd-7751-48f2-bdfa-fb4a0de2b953,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-927975061-172.17.0.7-1595421462444:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39299,DS-684e629d-deaf-41a8-a16e-0b7c0183f2d5,DISK], DatanodeInfoWithStorage[127.0.0.1:37864,DS-c1af3f20-9463-484c-a9d2-4d6e1aa9fc44,DISK], DatanodeInfoWithStorage[127.0.0.1:36586,DS-1f8b30e8-1437-423e-aee7-1f6901357dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:41850,DS-aba19012-0d39-45ee-834c-f81e5b717009,DISK], DatanodeInfoWithStorage[127.0.0.1:46558,DS-b7f08721-90ef-4145-9d12-634cc37f25fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36416,DS-bbbdaf86-26bb-496b-acf0-b46cbc11ad43,DISK], DatanodeInfoWithStorage[127.0.0.1:45463,DS-70bf75ae-1569-448e-abfd-28313cf5e0e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38697,DS-38a5c7bd-7751-48f2-bdfa-fb4a0de2b953,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-382545470-172.17.0.7-1595421541456:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33103,DS-18209fac-fe2d-43d1-a223-757e08638918,DISK], DatanodeInfoWithStorage[127.0.0.1:39285,DS-973cb0f4-3834-49ae-ae8f-54cc31985fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:41078,DS-a6126593-0ed3-4a9d-bf8f-afb95690186d,DISK], DatanodeInfoWithStorage[127.0.0.1:45228,DS-889ac8a5-ab48-4cee-87cb-be4edcef4b4f,DISK], DatanodeInfoWithStorage[127.0.0.1:44068,DS-7543ac81-62d9-454e-ad55-fbc0f5d24763,DISK], DatanodeInfoWithStorage[127.0.0.1:35654,DS-950c9644-aa6a-4fcb-81d9-f5e9ec5ce2df,DISK], DatanodeInfoWithStorage[127.0.0.1:45022,DS-6b1a67f9-de69-437b-b201-ab6c14bef1bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37497,DS-e146fe71-a615-42a5-9434-b92bc8281fa0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-382545470-172.17.0.7-1595421541456:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33103,DS-18209fac-fe2d-43d1-a223-757e08638918,DISK], DatanodeInfoWithStorage[127.0.0.1:39285,DS-973cb0f4-3834-49ae-ae8f-54cc31985fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:41078,DS-a6126593-0ed3-4a9d-bf8f-afb95690186d,DISK], DatanodeInfoWithStorage[127.0.0.1:45228,DS-889ac8a5-ab48-4cee-87cb-be4edcef4b4f,DISK], DatanodeInfoWithStorage[127.0.0.1:44068,DS-7543ac81-62d9-454e-ad55-fbc0f5d24763,DISK], DatanodeInfoWithStorage[127.0.0.1:35654,DS-950c9644-aa6a-4fcb-81d9-f5e9ec5ce2df,DISK], DatanodeInfoWithStorage[127.0.0.1:45022,DS-6b1a67f9-de69-437b-b201-ab6c14bef1bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37497,DS-e146fe71-a615-42a5-9434-b92bc8281fa0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-99002339-172.17.0.7-1595421589644:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34430,DS-4fe906bb-28fa-44db-be9e-51fe12a53627,DISK], DatanodeInfoWithStorage[127.0.0.1:43051,DS-101e1bc9-a8be-4a0b-bc0a-6a956aa87828,DISK], DatanodeInfoWithStorage[127.0.0.1:41688,DS-f2a27997-38c6-40f5-b081-e41fc3854ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:46493,DS-b9c47dd1-56a3-4feb-8a1c-725e36062bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:40732,DS-03862dc0-54b8-4846-ab68-592ff2a8881f,DISK], DatanodeInfoWithStorage[127.0.0.1:40220,DS-52c738d6-3709-4902-8cb8-5415bb3386df,DISK], DatanodeInfoWithStorage[127.0.0.1:42989,DS-c06fb6c4-dbb4-4573-b909-e73de7150fc8,DISK], DatanodeInfoWithStorage[127.0.0.1:36413,DS-aa9febdb-484a-453b-bbae-990ef8e9d033,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-99002339-172.17.0.7-1595421589644:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34430,DS-4fe906bb-28fa-44db-be9e-51fe12a53627,DISK], DatanodeInfoWithStorage[127.0.0.1:43051,DS-101e1bc9-a8be-4a0b-bc0a-6a956aa87828,DISK], DatanodeInfoWithStorage[127.0.0.1:41688,DS-f2a27997-38c6-40f5-b081-e41fc3854ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:46493,DS-b9c47dd1-56a3-4feb-8a1c-725e36062bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:40732,DS-03862dc0-54b8-4846-ab68-592ff2a8881f,DISK], DatanodeInfoWithStorage[127.0.0.1:40220,DS-52c738d6-3709-4902-8cb8-5415bb3386df,DISK], DatanodeInfoWithStorage[127.0.0.1:42989,DS-c06fb6c4-dbb4-4573-b909-e73de7150fc8,DISK], DatanodeInfoWithStorage[127.0.0.1:36413,DS-aa9febdb-484a-453b-bbae-990ef8e9d033,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-794641287-172.17.0.7-1595421684017:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35515,DS-ad1b4f3a-41f4-4586-aab7-64eed786303e,DISK], DatanodeInfoWithStorage[127.0.0.1:41611,DS-552ab8e4-4048-49d4-9b12-1e72b49db1f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45084,DS-d1a65474-fc46-4e82-8211-6deab3264ec6,DISK], DatanodeInfoWithStorage[127.0.0.1:34172,DS-ee9b8326-7b04-4e35-9450-0e8ed9a2d041,DISK], DatanodeInfoWithStorage[127.0.0.1:45269,DS-4bad2012-0792-45f6-a0a0-da583bd821bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36381,DS-23b5c01b-3be3-4e69-b98f-eb069533564c,DISK], DatanodeInfoWithStorage[127.0.0.1:40839,DS-9df712ee-ab3d-497f-96b8-44b407a2f72f,DISK], DatanodeInfoWithStorage[127.0.0.1:46426,DS-0c5380dd-1381-4f21-965e-2f985efc171d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-794641287-172.17.0.7-1595421684017:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35515,DS-ad1b4f3a-41f4-4586-aab7-64eed786303e,DISK], DatanodeInfoWithStorage[127.0.0.1:41611,DS-552ab8e4-4048-49d4-9b12-1e72b49db1f2,DISK], DatanodeInfoWithStorage[127.0.0.1:45084,DS-d1a65474-fc46-4e82-8211-6deab3264ec6,DISK], DatanodeInfoWithStorage[127.0.0.1:34172,DS-ee9b8326-7b04-4e35-9450-0e8ed9a2d041,DISK], DatanodeInfoWithStorage[127.0.0.1:45269,DS-4bad2012-0792-45f6-a0a0-da583bd821bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36381,DS-23b5c01b-3be3-4e69-b98f-eb069533564c,DISK], DatanodeInfoWithStorage[127.0.0.1:40839,DS-9df712ee-ab3d-497f-96b8-44b407a2f72f,DISK], DatanodeInfoWithStorage[127.0.0.1:46426,DS-0c5380dd-1381-4f21-965e-2f985efc171d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1868054706-172.17.0.7-1595421730932:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44514,DS-4a481852-31ae-4cd0-87b3-60750a18304b,DISK], DatanodeInfoWithStorage[127.0.0.1:37098,DS-15529019-5fd4-44fe-add8-514b517a8a1d,DISK], DatanodeInfoWithStorage[127.0.0.1:42757,DS-fec6bd5f-79ce-49b0-9d3e-3b1e88e71531,DISK], DatanodeInfoWithStorage[127.0.0.1:33710,DS-bbc6a538-1e29-4ba9-9744-512777f97511,DISK], DatanodeInfoWithStorage[127.0.0.1:43196,DS-0a846bea-131a-409f-99fd-6bdfa5a0c659,DISK], DatanodeInfoWithStorage[127.0.0.1:35066,DS-05c37f15-a261-405e-a717-f53dedd2b12e,DISK], DatanodeInfoWithStorage[127.0.0.1:36678,DS-c9d45deb-057a-4fd3-8049-ba46d3869e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:33636,DS-73ef9a1f-5f40-48a0-9c5d-9c345fdb7768,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1868054706-172.17.0.7-1595421730932:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44514,DS-4a481852-31ae-4cd0-87b3-60750a18304b,DISK], DatanodeInfoWithStorage[127.0.0.1:37098,DS-15529019-5fd4-44fe-add8-514b517a8a1d,DISK], DatanodeInfoWithStorage[127.0.0.1:42757,DS-fec6bd5f-79ce-49b0-9d3e-3b1e88e71531,DISK], DatanodeInfoWithStorage[127.0.0.1:33710,DS-bbc6a538-1e29-4ba9-9744-512777f97511,DISK], DatanodeInfoWithStorage[127.0.0.1:43196,DS-0a846bea-131a-409f-99fd-6bdfa5a0c659,DISK], DatanodeInfoWithStorage[127.0.0.1:35066,DS-05c37f15-a261-405e-a717-f53dedd2b12e,DISK], DatanodeInfoWithStorage[127.0.0.1:36678,DS-c9d45deb-057a-4fd3-8049-ba46d3869e1f,DISK], DatanodeInfoWithStorage[127.0.0.1:33636,DS-73ef9a1f-5f40-48a0-9c5d-9c345fdb7768,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1277746837-172.17.0.7-1595421826458:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41555,DS-e1fdcaac-c4f6-4b1f-91f4-fbd18272edf8,DISK], DatanodeInfoWithStorage[127.0.0.1:33393,DS-2b7d6ff3-5e77-481e-bad3-c9c1bf78c312,DISK], DatanodeInfoWithStorage[127.0.0.1:44307,DS-e1c37896-d770-4566-8fb4-63fbaf0db92e,DISK], DatanodeInfoWithStorage[127.0.0.1:38910,DS-c95c14e9-632c-45c2-b3fc-02a57396366a,DISK], DatanodeInfoWithStorage[127.0.0.1:38552,DS-25e8c545-52d6-4020-a33f-86cb415ebcff,DISK], DatanodeInfoWithStorage[127.0.0.1:44746,DS-9091a33b-e2d6-4853-b78f-ea32fa26f7ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36448,DS-b827e46c-4dfe-43f5-bdc5-82c7e382158d,DISK], DatanodeInfoWithStorage[127.0.0.1:44162,DS-3e9a3ce5-93ce-4755-bc62-a4a8ca5c0f67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1277746837-172.17.0.7-1595421826458:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41555,DS-e1fdcaac-c4f6-4b1f-91f4-fbd18272edf8,DISK], DatanodeInfoWithStorage[127.0.0.1:33393,DS-2b7d6ff3-5e77-481e-bad3-c9c1bf78c312,DISK], DatanodeInfoWithStorage[127.0.0.1:44307,DS-e1c37896-d770-4566-8fb4-63fbaf0db92e,DISK], DatanodeInfoWithStorage[127.0.0.1:38910,DS-c95c14e9-632c-45c2-b3fc-02a57396366a,DISK], DatanodeInfoWithStorage[127.0.0.1:38552,DS-25e8c545-52d6-4020-a33f-86cb415ebcff,DISK], DatanodeInfoWithStorage[127.0.0.1:44746,DS-9091a33b-e2d6-4853-b78f-ea32fa26f7ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36448,DS-b827e46c-4dfe-43f5-bdc5-82c7e382158d,DISK], DatanodeInfoWithStorage[127.0.0.1:44162,DS-3e9a3ce5-93ce-4755-bc62-a4a8ca5c0f67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1850568307-172.17.0.7-1595421969036:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38350,DS-3a43246c-5878-48e0-a51b-370d1a6a19c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40415,DS-530191fc-dbc8-4444-bb1f-08c6477d9493,DISK], DatanodeInfoWithStorage[127.0.0.1:46278,DS-7053cc6d-7196-4501-bd47-767db73b09ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34286,DS-cfb3ce92-4184-4966-8eed-87f7a352a4f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40087,DS-ab400fe3-b77a-4aa0-912a-b9f3a92dcac3,DISK], DatanodeInfoWithStorage[127.0.0.1:33444,DS-c1c70c4a-6e66-4aaf-8982-3a7a7b7e42ff,DISK], DatanodeInfoWithStorage[127.0.0.1:41853,DS-c5f13ecf-ca0c-428c-97ab-3981cab843ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42856,DS-63bf9d51-c31e-485a-a122-f1ffa56e04b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1850568307-172.17.0.7-1595421969036:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38350,DS-3a43246c-5878-48e0-a51b-370d1a6a19c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40415,DS-530191fc-dbc8-4444-bb1f-08c6477d9493,DISK], DatanodeInfoWithStorage[127.0.0.1:46278,DS-7053cc6d-7196-4501-bd47-767db73b09ac,DISK], DatanodeInfoWithStorage[127.0.0.1:34286,DS-cfb3ce92-4184-4966-8eed-87f7a352a4f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40087,DS-ab400fe3-b77a-4aa0-912a-b9f3a92dcac3,DISK], DatanodeInfoWithStorage[127.0.0.1:33444,DS-c1c70c4a-6e66-4aaf-8982-3a7a7b7e42ff,DISK], DatanodeInfoWithStorage[127.0.0.1:41853,DS-c5f13ecf-ca0c-428c-97ab-3981cab843ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42856,DS-63bf9d51-c31e-485a-a122-f1ffa56e04b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1917721630-172.17.0.7-1595422143429:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34357,DS-a751d0af-076e-407c-982d-87d8db9e1b3f,DISK], DatanodeInfoWithStorage[127.0.0.1:34546,DS-d5a6ca29-2333-46a8-9281-b27847928bfc,DISK], DatanodeInfoWithStorage[127.0.0.1:37285,DS-3ae7e721-c489-41bb-a9f0-962a72955596,DISK], DatanodeInfoWithStorage[127.0.0.1:41445,DS-b01820a2-948e-48c5-b801-99b7d4b41dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:33867,DS-0b6a593d-cb03-4697-b249-9d2da4d7a806,DISK], DatanodeInfoWithStorage[127.0.0.1:42198,DS-c63099cc-3714-475c-af5b-4e4cd0c39d89,DISK], DatanodeInfoWithStorage[127.0.0.1:34226,DS-8e44eb4c-e8ee-4948-ae6e-068656220699,DISK], DatanodeInfoWithStorage[127.0.0.1:41256,DS-df433763-c08e-44d2-994e-6063f876f948,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1917721630-172.17.0.7-1595422143429:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34357,DS-a751d0af-076e-407c-982d-87d8db9e1b3f,DISK], DatanodeInfoWithStorage[127.0.0.1:34546,DS-d5a6ca29-2333-46a8-9281-b27847928bfc,DISK], DatanodeInfoWithStorage[127.0.0.1:37285,DS-3ae7e721-c489-41bb-a9f0-962a72955596,DISK], DatanodeInfoWithStorage[127.0.0.1:41445,DS-b01820a2-948e-48c5-b801-99b7d4b41dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:33867,DS-0b6a593d-cb03-4697-b249-9d2da4d7a806,DISK], DatanodeInfoWithStorage[127.0.0.1:42198,DS-c63099cc-3714-475c-af5b-4e4cd0c39d89,DISK], DatanodeInfoWithStorage[127.0.0.1:34226,DS-8e44eb4c-e8ee-4948-ae6e-068656220699,DISK], DatanodeInfoWithStorage[127.0.0.1:41256,DS-df433763-c08e-44d2-994e-6063f876f948,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-249577576-172.17.0.7-1595422301266:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33999,DS-ef45484e-0fdb-4c7b-bfa4-c3b9f9ee545a,DISK], DatanodeInfoWithStorage[127.0.0.1:40611,DS-99f9792c-6b60-4765-83a6-7e6c817350d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34072,DS-2cbc9253-7d71-4381-a570-337ed00e4248,DISK], DatanodeInfoWithStorage[127.0.0.1:39708,DS-0be205fb-76be-40ba-9f39-46986d7224d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40762,DS-21bbf784-161b-4cb4-9c50-f8f6845878c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35438,DS-2ac2a934-7f00-4318-a9e8-09c8fa5c5270,DISK], DatanodeInfoWithStorage[127.0.0.1:46009,DS-e0c6b64c-855e-4f19-85bd-23ec91539b73,DISK], DatanodeInfoWithStorage[127.0.0.1:41602,DS-b772909c-c282-46fa-9962-b4fe96f6dc5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-249577576-172.17.0.7-1595422301266:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33999,DS-ef45484e-0fdb-4c7b-bfa4-c3b9f9ee545a,DISK], DatanodeInfoWithStorage[127.0.0.1:40611,DS-99f9792c-6b60-4765-83a6-7e6c817350d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34072,DS-2cbc9253-7d71-4381-a570-337ed00e4248,DISK], DatanodeInfoWithStorage[127.0.0.1:39708,DS-0be205fb-76be-40ba-9f39-46986d7224d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40762,DS-21bbf784-161b-4cb4-9c50-f8f6845878c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35438,DS-2ac2a934-7f00-4318-a9e8-09c8fa5c5270,DISK], DatanodeInfoWithStorage[127.0.0.1:46009,DS-e0c6b64c-855e-4f19-85bd-23ec91539b73,DISK], DatanodeInfoWithStorage[127.0.0.1:41602,DS-b772909c-c282-46fa-9962-b4fe96f6dc5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1372904961-172.17.0.7-1595422380552:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43391,DS-41bce110-bd98-4459-b393-9339e5556f48,DISK], DatanodeInfoWithStorage[127.0.0.1:45507,DS-42b133d7-e440-4765-bb1c-359daa461128,DISK], DatanodeInfoWithStorage[127.0.0.1:42064,DS-c5453360-0a43-498a-9fd6-c18e5e07f35b,DISK], DatanodeInfoWithStorage[127.0.0.1:40445,DS-6c7f82f9-3f0d-40dd-b264-058801208b11,DISK], DatanodeInfoWithStorage[127.0.0.1:42917,DS-0a40a102-73c1-482f-a0d8-2363dd968293,DISK], DatanodeInfoWithStorage[127.0.0.1:35407,DS-71837fda-2ec1-42d6-8714-a1a86dc61e20,DISK], DatanodeInfoWithStorage[127.0.0.1:40067,DS-b3efe801-f591-4a99-ab15-4b558fbe3a10,DISK], DatanodeInfoWithStorage[127.0.0.1:39093,DS-d1f6f821-f443-40c5-9bb7-f4f91303f5f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1372904961-172.17.0.7-1595422380552:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43391,DS-41bce110-bd98-4459-b393-9339e5556f48,DISK], DatanodeInfoWithStorage[127.0.0.1:45507,DS-42b133d7-e440-4765-bb1c-359daa461128,DISK], DatanodeInfoWithStorage[127.0.0.1:42064,DS-c5453360-0a43-498a-9fd6-c18e5e07f35b,DISK], DatanodeInfoWithStorage[127.0.0.1:40445,DS-6c7f82f9-3f0d-40dd-b264-058801208b11,DISK], DatanodeInfoWithStorage[127.0.0.1:42917,DS-0a40a102-73c1-482f-a0d8-2363dd968293,DISK], DatanodeInfoWithStorage[127.0.0.1:35407,DS-71837fda-2ec1-42d6-8714-a1a86dc61e20,DISK], DatanodeInfoWithStorage[127.0.0.1:40067,DS-b3efe801-f591-4a99-ab15-4b558fbe3a10,DISK], DatanodeInfoWithStorage[127.0.0.1:39093,DS-d1f6f821-f443-40c5-9bb7-f4f91303f5f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1690873695-172.17.0.7-1595422428118:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40304,DS-b3641c93-4432-4a6c-9d03-6fc4a3e8ff75,DISK], DatanodeInfoWithStorage[127.0.0.1:42963,DS-c873d374-4d61-42b7-b850-8d500747c4d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42772,DS-18ed38c5-e388-42f7-bd8a-c5d714466456,DISK], DatanodeInfoWithStorage[127.0.0.1:36271,DS-ef29e8d4-fe5a-4bc4-8aec-4992a190c7df,DISK], DatanodeInfoWithStorage[127.0.0.1:42834,DS-ae2e6d36-6ebc-473c-b09b-4e1425c5ef9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45601,DS-171cda1a-370d-493f-9b94-53e2059c5cc0,DISK], DatanodeInfoWithStorage[127.0.0.1:40728,DS-1f611657-22ae-45bb-87d8-4cc8ababe940,DISK], DatanodeInfoWithStorage[127.0.0.1:35593,DS-63ea5eb3-ec42-4d07-b8a4-d0637ad74fd2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1690873695-172.17.0.7-1595422428118:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40304,DS-b3641c93-4432-4a6c-9d03-6fc4a3e8ff75,DISK], DatanodeInfoWithStorage[127.0.0.1:42963,DS-c873d374-4d61-42b7-b850-8d500747c4d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42772,DS-18ed38c5-e388-42f7-bd8a-c5d714466456,DISK], DatanodeInfoWithStorage[127.0.0.1:36271,DS-ef29e8d4-fe5a-4bc4-8aec-4992a190c7df,DISK], DatanodeInfoWithStorage[127.0.0.1:42834,DS-ae2e6d36-6ebc-473c-b09b-4e1425c5ef9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45601,DS-171cda1a-370d-493f-9b94-53e2059c5cc0,DISK], DatanodeInfoWithStorage[127.0.0.1:40728,DS-1f611657-22ae-45bb-87d8-4cc8ababe940,DISK], DatanodeInfoWithStorage[127.0.0.1:35593,DS-63ea5eb3-ec42-4d07-b8a4-d0637ad74fd2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.use.dfs.network.topology
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1832018844-172.17.0.7-1595422570443:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34206,DS-16bfe512-16c5-4f40-bc6d-7fb4e9c2c6b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36043,DS-0211ae1e-faf2-426e-8a77-f577856c8280,DISK], DatanodeInfoWithStorage[127.0.0.1:37906,DS-365416ba-ba9d-4521-8a14-4674126f6d55,DISK], DatanodeInfoWithStorage[127.0.0.1:43365,DS-0abb2288-9da5-4516-bc70-7a1525e3e402,DISK], DatanodeInfoWithStorage[127.0.0.1:35410,DS-ba370359-5f06-45ee-b455-82ca9fff3f10,DISK], DatanodeInfoWithStorage[127.0.0.1:36358,DS-1984bfc2-ac13-42ef-9f32-57e46fb8b702,DISK], DatanodeInfoWithStorage[127.0.0.1:39509,DS-58c138c6-d8b2-4973-83d7-5186582542b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45780,DS-06d0d745-5971-4385-a263-46c4a5fa27e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1832018844-172.17.0.7-1595422570443:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34206,DS-16bfe512-16c5-4f40-bc6d-7fb4e9c2c6b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36043,DS-0211ae1e-faf2-426e-8a77-f577856c8280,DISK], DatanodeInfoWithStorage[127.0.0.1:37906,DS-365416ba-ba9d-4521-8a14-4674126f6d55,DISK], DatanodeInfoWithStorage[127.0.0.1:43365,DS-0abb2288-9da5-4516-bc70-7a1525e3e402,DISK], DatanodeInfoWithStorage[127.0.0.1:35410,DS-ba370359-5f06-45ee-b455-82ca9fff3f10,DISK], DatanodeInfoWithStorage[127.0.0.1:36358,DS-1984bfc2-ac13-42ef-9f32-57e46fb8b702,DISK], DatanodeInfoWithStorage[127.0.0.1:39509,DS-58c138c6-d8b2-4973-83d7-5186582542b0,DISK], DatanodeInfoWithStorage[127.0.0.1:45780,DS-06d0d745-5971-4385-a263-46c4a5fa27e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 3879
