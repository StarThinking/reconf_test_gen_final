reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-646822787-172.17.0.19-1596950158681:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33342,DS-d62281fc-a2d3-4653-a94c-6b2d1a25b88b,DISK], DatanodeInfoWithStorage[127.0.0.1:39028,DS-019ae931-4077-43a1-b09e-cdcc28604ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:41567,DS-9c24e42f-196f-4e62-b33f-911d56677917,DISK], DatanodeInfoWithStorage[127.0.0.1:35981,DS-b6a8da00-1cda-4729-a3cf-717cc24bc9ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45232,DS-bf3a7c06-73b2-455a-81b0-bee0fd66c17c,DISK], DatanodeInfoWithStorage[127.0.0.1:36218,DS-820f749c-e82c-43cb-936f-26256f067a13,DISK], DatanodeInfoWithStorage[127.0.0.1:39874,DS-3ed9f306-a5e6-4790-ac52-4ddbf2ba21d3,DISK], DatanodeInfoWithStorage[127.0.0.1:36018,DS-06210c81-01d6-40bd-a0bd-0151a3fbce99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-646822787-172.17.0.19-1596950158681:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33342,DS-d62281fc-a2d3-4653-a94c-6b2d1a25b88b,DISK], DatanodeInfoWithStorage[127.0.0.1:39028,DS-019ae931-4077-43a1-b09e-cdcc28604ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:41567,DS-9c24e42f-196f-4e62-b33f-911d56677917,DISK], DatanodeInfoWithStorage[127.0.0.1:35981,DS-b6a8da00-1cda-4729-a3cf-717cc24bc9ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45232,DS-bf3a7c06-73b2-455a-81b0-bee0fd66c17c,DISK], DatanodeInfoWithStorage[127.0.0.1:36218,DS-820f749c-e82c-43cb-936f-26256f067a13,DISK], DatanodeInfoWithStorage[127.0.0.1:39874,DS-3ed9f306-a5e6-4790-ac52-4ddbf2ba21d3,DISK], DatanodeInfoWithStorage[127.0.0.1:36018,DS-06210c81-01d6-40bd-a0bd-0151a3fbce99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2091879934-172.17.0.19-1596950295898:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34748,DS-7eb3565c-3c0f-4ae2-a421-54d96f459558,DISK], DatanodeInfoWithStorage[127.0.0.1:36944,DS-bf695d49-670a-42ac-ab79-baf511de0503,DISK], DatanodeInfoWithStorage[127.0.0.1:42778,DS-a0dad6a3-a0e1-46d9-add5-30a7f87117f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39917,DS-b38dad83-4a84-412f-bffa-aa6ef7ae6cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:33847,DS-68a3eb60-78a0-4e29-8c6f-15726af8e882,DISK], DatanodeInfoWithStorage[127.0.0.1:38171,DS-c6baf8b2-93e9-49fe-93b1-ddfb3aec8399,DISK], DatanodeInfoWithStorage[127.0.0.1:44130,DS-f68919eb-c2e9-46ea-b606-6a6be1815554,DISK], DatanodeInfoWithStorage[127.0.0.1:33818,DS-be134e6c-306a-4754-88d0-0c2466e780aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2091879934-172.17.0.19-1596950295898:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34748,DS-7eb3565c-3c0f-4ae2-a421-54d96f459558,DISK], DatanodeInfoWithStorage[127.0.0.1:36944,DS-bf695d49-670a-42ac-ab79-baf511de0503,DISK], DatanodeInfoWithStorage[127.0.0.1:42778,DS-a0dad6a3-a0e1-46d9-add5-30a7f87117f0,DISK], DatanodeInfoWithStorage[127.0.0.1:39917,DS-b38dad83-4a84-412f-bffa-aa6ef7ae6cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:33847,DS-68a3eb60-78a0-4e29-8c6f-15726af8e882,DISK], DatanodeInfoWithStorage[127.0.0.1:38171,DS-c6baf8b2-93e9-49fe-93b1-ddfb3aec8399,DISK], DatanodeInfoWithStorage[127.0.0.1:44130,DS-f68919eb-c2e9-46ea-b606-6a6be1815554,DISK], DatanodeInfoWithStorage[127.0.0.1:33818,DS-be134e6c-306a-4754-88d0-0c2466e780aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-870374053-172.17.0.19-1596950365637:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40951,DS-e4854e04-4aff-483a-91d8-1a82c778da80,DISK], DatanodeInfoWithStorage[127.0.0.1:43259,DS-b584db50-69c6-4eb8-9031-92fe3e5c69d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38587,DS-065f433a-88aa-4e26-a20b-7123851be9f4,DISK], DatanodeInfoWithStorage[127.0.0.1:35051,DS-7026fe13-8f6e-4544-ac63-6c59a6f079b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38738,DS-060f4569-0c90-496a-a4e0-62c16a8617dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38693,DS-a159ae0e-5046-462a-8aa6-a692968ea3b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38055,DS-986c64c8-aec4-448a-acdc-3ba1a5460b77,DISK], DatanodeInfoWithStorage[127.0.0.1:37847,DS-164e8ae9-06cb-47ea-8f68-ef3a9a784581,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-870374053-172.17.0.19-1596950365637:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40951,DS-e4854e04-4aff-483a-91d8-1a82c778da80,DISK], DatanodeInfoWithStorage[127.0.0.1:43259,DS-b584db50-69c6-4eb8-9031-92fe3e5c69d2,DISK], DatanodeInfoWithStorage[127.0.0.1:38587,DS-065f433a-88aa-4e26-a20b-7123851be9f4,DISK], DatanodeInfoWithStorage[127.0.0.1:35051,DS-7026fe13-8f6e-4544-ac63-6c59a6f079b6,DISK], DatanodeInfoWithStorage[127.0.0.1:38738,DS-060f4569-0c90-496a-a4e0-62c16a8617dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38693,DS-a159ae0e-5046-462a-8aa6-a692968ea3b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38055,DS-986c64c8-aec4-448a-acdc-3ba1a5460b77,DISK], DatanodeInfoWithStorage[127.0.0.1:37847,DS-164e8ae9-06cb-47ea-8f68-ef3a9a784581,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1659898465-172.17.0.19-1596950430951:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34492,DS-7c87d08c-211f-47eb-a893-ee8cf4031d5b,DISK], DatanodeInfoWithStorage[127.0.0.1:39819,DS-b3581ae7-c161-4763-a971-8ce6fd12c748,DISK], DatanodeInfoWithStorage[127.0.0.1:35950,DS-d455acdc-de9b-4d8b-be21-9d269450b633,DISK], DatanodeInfoWithStorage[127.0.0.1:42248,DS-81e42db7-720e-44c9-a8bb-2f56e5063ea8,DISK], DatanodeInfoWithStorage[127.0.0.1:44114,DS-921ff1ed-8eef-471c-a566-a1a5e61f6b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:46838,DS-49fc07c6-0f0e-42e3-85d3-d6317bf89897,DISK], DatanodeInfoWithStorage[127.0.0.1:44568,DS-57e33f37-d116-4675-8ef6-fc106399f921,DISK], DatanodeInfoWithStorage[127.0.0.1:43095,DS-8fdd5ce4-940e-4b10-a30d-04124678dce3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1659898465-172.17.0.19-1596950430951:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34492,DS-7c87d08c-211f-47eb-a893-ee8cf4031d5b,DISK], DatanodeInfoWithStorage[127.0.0.1:39819,DS-b3581ae7-c161-4763-a971-8ce6fd12c748,DISK], DatanodeInfoWithStorage[127.0.0.1:35950,DS-d455acdc-de9b-4d8b-be21-9d269450b633,DISK], DatanodeInfoWithStorage[127.0.0.1:42248,DS-81e42db7-720e-44c9-a8bb-2f56e5063ea8,DISK], DatanodeInfoWithStorage[127.0.0.1:44114,DS-921ff1ed-8eef-471c-a566-a1a5e61f6b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:46838,DS-49fc07c6-0f0e-42e3-85d3-d6317bf89897,DISK], DatanodeInfoWithStorage[127.0.0.1:44568,DS-57e33f37-d116-4675-8ef6-fc106399f921,DISK], DatanodeInfoWithStorage[127.0.0.1:43095,DS-8fdd5ce4-940e-4b10-a30d-04124678dce3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-781727072-172.17.0.19-1596950857339:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46352,DS-30f1afd0-5915-4bab-8f1f-e727941a0b77,DISK], DatanodeInfoWithStorage[127.0.0.1:40374,DS-ffd5a423-16fe-48fb-aaf2-db239a739bef,DISK], DatanodeInfoWithStorage[127.0.0.1:46136,DS-c5b1b4ab-f907-430e-ba06-00159c5deaaa,DISK], DatanodeInfoWithStorage[127.0.0.1:42403,DS-966ef740-bef0-4080-9b45-b06b186725e8,DISK], DatanodeInfoWithStorage[127.0.0.1:46574,DS-18c3be6d-bc18-40e3-80ca-ebd989c63dde,DISK], DatanodeInfoWithStorage[127.0.0.1:34132,DS-774608a1-995d-45bb-903b-bf38a62de7a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33247,DS-bbc5f686-5f9e-4f76-891a-2b5e08587675,DISK], DatanodeInfoWithStorage[127.0.0.1:45831,DS-b0576d43-d740-4748-984a-024be35b0888,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-781727072-172.17.0.19-1596950857339:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46352,DS-30f1afd0-5915-4bab-8f1f-e727941a0b77,DISK], DatanodeInfoWithStorage[127.0.0.1:40374,DS-ffd5a423-16fe-48fb-aaf2-db239a739bef,DISK], DatanodeInfoWithStorage[127.0.0.1:46136,DS-c5b1b4ab-f907-430e-ba06-00159c5deaaa,DISK], DatanodeInfoWithStorage[127.0.0.1:42403,DS-966ef740-bef0-4080-9b45-b06b186725e8,DISK], DatanodeInfoWithStorage[127.0.0.1:46574,DS-18c3be6d-bc18-40e3-80ca-ebd989c63dde,DISK], DatanodeInfoWithStorage[127.0.0.1:34132,DS-774608a1-995d-45bb-903b-bf38a62de7a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33247,DS-bbc5f686-5f9e-4f76-891a-2b5e08587675,DISK], DatanodeInfoWithStorage[127.0.0.1:45831,DS-b0576d43-d740-4748-984a-024be35b0888,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1207373406-172.17.0.19-1596950915023:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38603,DS-3ae2c701-d8d3-4df8-a915-cf6064bf5ef1,DISK], DatanodeInfoWithStorage[127.0.0.1:39732,DS-ad97dcdb-b0cb-4782-bf1b-91f9c59257d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46373,DS-74504a0f-9d50-4b45-a0a1-5d1ffd0139d7,DISK], DatanodeInfoWithStorage[127.0.0.1:35787,DS-ec037a2e-70a6-45df-8531-11e6b78f0e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:44449,DS-f44bb22e-87ce-4a2e-a509-d9e7359a4f74,DISK], DatanodeInfoWithStorage[127.0.0.1:39603,DS-6eade572-f9b8-40ed-8b39-84daccc3d8a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44403,DS-2410c383-dbfc-4e9f-8b9b-7f067bea8b78,DISK], DatanodeInfoWithStorage[127.0.0.1:39247,DS-01c8604f-54ac-414f-9072-d6a9d3fcfb95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1207373406-172.17.0.19-1596950915023:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38603,DS-3ae2c701-d8d3-4df8-a915-cf6064bf5ef1,DISK], DatanodeInfoWithStorage[127.0.0.1:39732,DS-ad97dcdb-b0cb-4782-bf1b-91f9c59257d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46373,DS-74504a0f-9d50-4b45-a0a1-5d1ffd0139d7,DISK], DatanodeInfoWithStorage[127.0.0.1:35787,DS-ec037a2e-70a6-45df-8531-11e6b78f0e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:44449,DS-f44bb22e-87ce-4a2e-a509-d9e7359a4f74,DISK], DatanodeInfoWithStorage[127.0.0.1:39603,DS-6eade572-f9b8-40ed-8b39-84daccc3d8a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44403,DS-2410c383-dbfc-4e9f-8b9b-7f067bea8b78,DISK], DatanodeInfoWithStorage[127.0.0.1:39247,DS-01c8604f-54ac-414f-9072-d6a9d3fcfb95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2114262544-172.17.0.19-1596950993104:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46528,DS-8fb9b08d-8790-4493-ae38-07b960dd590c,DISK], DatanodeInfoWithStorage[127.0.0.1:41582,DS-6e3d31a2-837d-4bfd-87aa-9cd1380d538f,DISK], DatanodeInfoWithStorage[127.0.0.1:46615,DS-9cffe86b-9d1a-43d1-8af1-ce7637aa68cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37226,DS-e6a8fc49-cba6-4b7f-878b-1655c0eb060e,DISK], DatanodeInfoWithStorage[127.0.0.1:46801,DS-a9e45c0c-0728-4d88-8fea-d916237882cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37966,DS-bffd6734-408d-4191-a5c4-bb41af0f2081,DISK], DatanodeInfoWithStorage[127.0.0.1:38238,DS-636be015-26e8-4d28-987c-e2f2bd9fb3ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44681,DS-7a5f759f-5123-471e-b756-eb8dc838964d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2114262544-172.17.0.19-1596950993104:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46528,DS-8fb9b08d-8790-4493-ae38-07b960dd590c,DISK], DatanodeInfoWithStorage[127.0.0.1:41582,DS-6e3d31a2-837d-4bfd-87aa-9cd1380d538f,DISK], DatanodeInfoWithStorage[127.0.0.1:46615,DS-9cffe86b-9d1a-43d1-8af1-ce7637aa68cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37226,DS-e6a8fc49-cba6-4b7f-878b-1655c0eb060e,DISK], DatanodeInfoWithStorage[127.0.0.1:46801,DS-a9e45c0c-0728-4d88-8fea-d916237882cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37966,DS-bffd6734-408d-4191-a5c4-bb41af0f2081,DISK], DatanodeInfoWithStorage[127.0.0.1:38238,DS-636be015-26e8-4d28-987c-e2f2bd9fb3ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44681,DS-7a5f759f-5123-471e-b756-eb8dc838964d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1900911347-172.17.0.19-1596951287284:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43037,DS-65c10126-acd9-427d-a55a-faff5d24df5f,DISK], DatanodeInfoWithStorage[127.0.0.1:41239,DS-afe7b51d-d284-4860-b57e-852450638e42,DISK], DatanodeInfoWithStorage[127.0.0.1:44973,DS-21730168-d5c6-4c38-85b7-6a66e6e88cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:46881,DS-4a27b24f-da99-4a56-a027-a371e52f486d,DISK], DatanodeInfoWithStorage[127.0.0.1:38352,DS-56bbe5a2-fd50-4e0b-a9cf-55a7d8fa3aae,DISK], DatanodeInfoWithStorage[127.0.0.1:37609,DS-17adc0a1-b066-4041-893e-571b4635f455,DISK], DatanodeInfoWithStorage[127.0.0.1:35002,DS-0c4637a7-0e57-4d80-af0c-92b9c9fecca4,DISK], DatanodeInfoWithStorage[127.0.0.1:42086,DS-7c77c930-cf8e-4183-9ee0-844b7448761d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1900911347-172.17.0.19-1596951287284:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43037,DS-65c10126-acd9-427d-a55a-faff5d24df5f,DISK], DatanodeInfoWithStorage[127.0.0.1:41239,DS-afe7b51d-d284-4860-b57e-852450638e42,DISK], DatanodeInfoWithStorage[127.0.0.1:44973,DS-21730168-d5c6-4c38-85b7-6a66e6e88cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:46881,DS-4a27b24f-da99-4a56-a027-a371e52f486d,DISK], DatanodeInfoWithStorage[127.0.0.1:38352,DS-56bbe5a2-fd50-4e0b-a9cf-55a7d8fa3aae,DISK], DatanodeInfoWithStorage[127.0.0.1:37609,DS-17adc0a1-b066-4041-893e-571b4635f455,DISK], DatanodeInfoWithStorage[127.0.0.1:35002,DS-0c4637a7-0e57-4d80-af0c-92b9c9fecca4,DISK], DatanodeInfoWithStorage[127.0.0.1:42086,DS-7c77c930-cf8e-4183-9ee0-844b7448761d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2142133052-172.17.0.19-1596951317496:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41885,DS-bf748868-d398-437e-a455-b2c66a0ff9e7,DISK], DatanodeInfoWithStorage[127.0.0.1:41323,DS-18bf700e-755c-42ca-a37a-cb5e061a442a,DISK], DatanodeInfoWithStorage[127.0.0.1:36808,DS-c4113adb-26c4-458a-812f-bdf1767df207,DISK], DatanodeInfoWithStorage[127.0.0.1:39760,DS-cb4c99d9-8f47-411d-81fe-43852742b6e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44567,DS-2e440892-46fc-4251-af2a-38c3914af772,DISK], DatanodeInfoWithStorage[127.0.0.1:38210,DS-ec5e0bce-f73b-4293-891c-ab38922b4b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:42180,DS-affe6ffd-0934-499a-acbf-b7f0f7b9cb48,DISK], DatanodeInfoWithStorage[127.0.0.1:33701,DS-a7e377c2-4585-4ae1-9f44-e7222b61326c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2142133052-172.17.0.19-1596951317496:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41885,DS-bf748868-d398-437e-a455-b2c66a0ff9e7,DISK], DatanodeInfoWithStorage[127.0.0.1:41323,DS-18bf700e-755c-42ca-a37a-cb5e061a442a,DISK], DatanodeInfoWithStorage[127.0.0.1:36808,DS-c4113adb-26c4-458a-812f-bdf1767df207,DISK], DatanodeInfoWithStorage[127.0.0.1:39760,DS-cb4c99d9-8f47-411d-81fe-43852742b6e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44567,DS-2e440892-46fc-4251-af2a-38c3914af772,DISK], DatanodeInfoWithStorage[127.0.0.1:38210,DS-ec5e0bce-f73b-4293-891c-ab38922b4b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:42180,DS-affe6ffd-0934-499a-acbf-b7f0f7b9cb48,DISK], DatanodeInfoWithStorage[127.0.0.1:33701,DS-a7e377c2-4585-4ae1-9f44-e7222b61326c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1246752687-172.17.0.19-1596951490360:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36411,DS-145a5f75-231b-4556-b033-046e34d26b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:43183,DS-4e816340-377a-4c9e-950d-eb110f5e7bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:33049,DS-c5f1a3ea-f2d6-43bc-9d02-be212c66d1a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38055,DS-a179a61f-9346-4f76-a46e-7d52d32e06f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33000,DS-db1c92e7-1602-4fdf-a2b1-d68e7d723d7e,DISK], DatanodeInfoWithStorage[127.0.0.1:40003,DS-f4124d21-b5dd-4901-9ff9-b91640b801e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45320,DS-6d0392db-9ae8-461e-9d3c-7123e7c02a00,DISK], DatanodeInfoWithStorage[127.0.0.1:45425,DS-6b49c822-e7db-4b7b-bb28-4c0a38057dd5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1246752687-172.17.0.19-1596951490360:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36411,DS-145a5f75-231b-4556-b033-046e34d26b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:43183,DS-4e816340-377a-4c9e-950d-eb110f5e7bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:33049,DS-c5f1a3ea-f2d6-43bc-9d02-be212c66d1a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38055,DS-a179a61f-9346-4f76-a46e-7d52d32e06f8,DISK], DatanodeInfoWithStorage[127.0.0.1:33000,DS-db1c92e7-1602-4fdf-a2b1-d68e7d723d7e,DISK], DatanodeInfoWithStorage[127.0.0.1:40003,DS-f4124d21-b5dd-4901-9ff9-b91640b801e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45320,DS-6d0392db-9ae8-461e-9d3c-7123e7c02a00,DISK], DatanodeInfoWithStorage[127.0.0.1:45425,DS-6b49c822-e7db-4b7b-bb28-4c0a38057dd5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-319568612-172.17.0.19-1596951555996:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43995,DS-9ef03e14-3169-467d-bc64-5961fcc278cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42982,DS-e4a518a0-1927-4192-b733-39869100cd5d,DISK], DatanodeInfoWithStorage[127.0.0.1:45013,DS-1d1ca869-df56-40f4-bfdb-4d9632b09cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:40556,DS-b4cbb712-7d23-4734-bdb1-512b11da5b77,DISK], DatanodeInfoWithStorage[127.0.0.1:32862,DS-86f19fd1-fb08-4c8d-a262-69127352b8bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41675,DS-46005d5f-bf9f-4d30-8978-bd9039801419,DISK], DatanodeInfoWithStorage[127.0.0.1:41974,DS-299b8b83-51bc-44e5-aa98-8311b55e3fe8,DISK], DatanodeInfoWithStorage[127.0.0.1:36704,DS-6fd67849-34a7-46b0-a9f9-17a69fe7d5ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-319568612-172.17.0.19-1596951555996:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43995,DS-9ef03e14-3169-467d-bc64-5961fcc278cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42982,DS-e4a518a0-1927-4192-b733-39869100cd5d,DISK], DatanodeInfoWithStorage[127.0.0.1:45013,DS-1d1ca869-df56-40f4-bfdb-4d9632b09cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:40556,DS-b4cbb712-7d23-4734-bdb1-512b11da5b77,DISK], DatanodeInfoWithStorage[127.0.0.1:32862,DS-86f19fd1-fb08-4c8d-a262-69127352b8bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41675,DS-46005d5f-bf9f-4d30-8978-bd9039801419,DISK], DatanodeInfoWithStorage[127.0.0.1:41974,DS-299b8b83-51bc-44e5-aa98-8311b55e3fe8,DISK], DatanodeInfoWithStorage[127.0.0.1:36704,DS-6fd67849-34a7-46b0-a9f9-17a69fe7d5ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1716522552-172.17.0.19-1596951831623:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40412,DS-af3659a6-d085-40eb-b4a6-e82a37f31ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:41296,DS-25c35f41-c96c-4d60-bbea-8d2fc647dbdb,DISK], DatanodeInfoWithStorage[127.0.0.1:44557,DS-37d94c52-b094-4134-be05-967a8be8402d,DISK], DatanodeInfoWithStorage[127.0.0.1:40575,DS-9293903c-b54c-4412-979b-c13efb42fc4e,DISK], DatanodeInfoWithStorage[127.0.0.1:46632,DS-e2696fdb-3870-429d-b737-b10cc6fa867e,DISK], DatanodeInfoWithStorage[127.0.0.1:43704,DS-ab1c3cf5-d002-4c63-abb5-d0b9eba33d9a,DISK], DatanodeInfoWithStorage[127.0.0.1:33583,DS-467821b3-aec1-4416-9ec0-523796b09584,DISK], DatanodeInfoWithStorage[127.0.0.1:38996,DS-f88a8fdd-6e0d-4454-937a-a2118df645dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1716522552-172.17.0.19-1596951831623:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40412,DS-af3659a6-d085-40eb-b4a6-e82a37f31ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:41296,DS-25c35f41-c96c-4d60-bbea-8d2fc647dbdb,DISK], DatanodeInfoWithStorage[127.0.0.1:44557,DS-37d94c52-b094-4134-be05-967a8be8402d,DISK], DatanodeInfoWithStorage[127.0.0.1:40575,DS-9293903c-b54c-4412-979b-c13efb42fc4e,DISK], DatanodeInfoWithStorage[127.0.0.1:46632,DS-e2696fdb-3870-429d-b737-b10cc6fa867e,DISK], DatanodeInfoWithStorage[127.0.0.1:43704,DS-ab1c3cf5-d002-4c63-abb5-d0b9eba33d9a,DISK], DatanodeInfoWithStorage[127.0.0.1:33583,DS-467821b3-aec1-4416-9ec0-523796b09584,DISK], DatanodeInfoWithStorage[127.0.0.1:38996,DS-f88a8fdd-6e0d-4454-937a-a2118df645dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-56032030-172.17.0.19-1596951933260:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39503,DS-d789e5fe-9dfc-46b7-98a7-c7c0a2172f6a,DISK], DatanodeInfoWithStorage[127.0.0.1:33419,DS-a342b16b-cf81-4d6c-bea9-702a0ef1fab3,DISK], DatanodeInfoWithStorage[127.0.0.1:38082,DS-0af8b0c6-fc2a-4f5d-8a6c-2bff14cd5c0c,DISK], DatanodeInfoWithStorage[127.0.0.1:33960,DS-7df5f51e-2850-4d8d-bf73-8280b67edcec,DISK], DatanodeInfoWithStorage[127.0.0.1:41636,DS-60741ebe-7ca4-426c-b344-1be2d9410afe,DISK], DatanodeInfoWithStorage[127.0.0.1:38160,DS-737e19fd-52a7-4fbd-bbfa-002022fe77da,DISK], DatanodeInfoWithStorage[127.0.0.1:34630,DS-795fd213-3a97-49f7-ac20-7b931e0ccd4a,DISK], DatanodeInfoWithStorage[127.0.0.1:33042,DS-a2789522-5492-45d5-b548-5380332e96b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-56032030-172.17.0.19-1596951933260:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39503,DS-d789e5fe-9dfc-46b7-98a7-c7c0a2172f6a,DISK], DatanodeInfoWithStorage[127.0.0.1:33419,DS-a342b16b-cf81-4d6c-bea9-702a0ef1fab3,DISK], DatanodeInfoWithStorage[127.0.0.1:38082,DS-0af8b0c6-fc2a-4f5d-8a6c-2bff14cd5c0c,DISK], DatanodeInfoWithStorage[127.0.0.1:33960,DS-7df5f51e-2850-4d8d-bf73-8280b67edcec,DISK], DatanodeInfoWithStorage[127.0.0.1:41636,DS-60741ebe-7ca4-426c-b344-1be2d9410afe,DISK], DatanodeInfoWithStorage[127.0.0.1:38160,DS-737e19fd-52a7-4fbd-bbfa-002022fe77da,DISK], DatanodeInfoWithStorage[127.0.0.1:34630,DS-795fd213-3a97-49f7-ac20-7b931e0ccd4a,DISK], DatanodeInfoWithStorage[127.0.0.1:33042,DS-a2789522-5492-45d5-b548-5380332e96b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1351741598-172.17.0.19-1596952181402:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37381,DS-6333f47d-ea40-447b-9b38-ec9a5c014318,DISK], DatanodeInfoWithStorage[127.0.0.1:36692,DS-da8d0acf-d4b8-494f-afab-0d58ff1460bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34864,DS-93d1ee96-d481-47af-a600-0a9d56e34fbd,DISK], DatanodeInfoWithStorage[127.0.0.1:33670,DS-37960b24-33e7-4a56-bea0-09f8d02dc29f,DISK], DatanodeInfoWithStorage[127.0.0.1:40049,DS-85787574-d232-4d2d-97d5-3ea5bc6589b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37579,DS-bff38e32-bb62-41a5-a628-ad1a9082471d,DISK], DatanodeInfoWithStorage[127.0.0.1:42371,DS-981ed987-21d9-415d-8e81-b1a10d7da1bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38312,DS-116cb346-adc0-4e15-a36f-486cdaab0694,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1351741598-172.17.0.19-1596952181402:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37381,DS-6333f47d-ea40-447b-9b38-ec9a5c014318,DISK], DatanodeInfoWithStorage[127.0.0.1:36692,DS-da8d0acf-d4b8-494f-afab-0d58ff1460bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34864,DS-93d1ee96-d481-47af-a600-0a9d56e34fbd,DISK], DatanodeInfoWithStorage[127.0.0.1:33670,DS-37960b24-33e7-4a56-bea0-09f8d02dc29f,DISK], DatanodeInfoWithStorage[127.0.0.1:40049,DS-85787574-d232-4d2d-97d5-3ea5bc6589b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37579,DS-bff38e32-bb62-41a5-a628-ad1a9082471d,DISK], DatanodeInfoWithStorage[127.0.0.1:42371,DS-981ed987-21d9-415d-8e81-b1a10d7da1bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38312,DS-116cb346-adc0-4e15-a36f-486cdaab0694,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-286657894-172.17.0.19-1596952503760:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43014,DS-a45f365f-8915-4a89-997b-4818e2c8f10c,DISK], DatanodeInfoWithStorage[127.0.0.1:37377,DS-a061a4b6-1881-4a7c-a4ca-26f6921764fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43304,DS-5ce5d577-e0b2-4b7a-b96b-2efe7c1e69ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33262,DS-7bea6554-5072-4aa4-8d98-82e6cb916247,DISK], DatanodeInfoWithStorage[127.0.0.1:43628,DS-789070e9-c367-4e2f-9e13-062aee3762ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44273,DS-6acd958f-f4d5-46cd-92a5-25d04a83148b,DISK], DatanodeInfoWithStorage[127.0.0.1:40390,DS-45074c66-5263-4296-bd9a-3c2eddbb3b19,DISK], DatanodeInfoWithStorage[127.0.0.1:37621,DS-ed8ef199-097b-47b6-b1fe-b350b2924ac9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-286657894-172.17.0.19-1596952503760:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43014,DS-a45f365f-8915-4a89-997b-4818e2c8f10c,DISK], DatanodeInfoWithStorage[127.0.0.1:37377,DS-a061a4b6-1881-4a7c-a4ca-26f6921764fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43304,DS-5ce5d577-e0b2-4b7a-b96b-2efe7c1e69ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33262,DS-7bea6554-5072-4aa4-8d98-82e6cb916247,DISK], DatanodeInfoWithStorage[127.0.0.1:43628,DS-789070e9-c367-4e2f-9e13-062aee3762ef,DISK], DatanodeInfoWithStorage[127.0.0.1:44273,DS-6acd958f-f4d5-46cd-92a5-25d04a83148b,DISK], DatanodeInfoWithStorage[127.0.0.1:40390,DS-45074c66-5263-4296-bd9a-3c2eddbb3b19,DISK], DatanodeInfoWithStorage[127.0.0.1:37621,DS-ed8ef199-097b-47b6-b1fe-b350b2924ac9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-389926765-172.17.0.19-1596953968215:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40840,DS-2d80994f-29b4-4694-ac6f-797a5bb2c102,DISK], DatanodeInfoWithStorage[127.0.0.1:33005,DS-6d218ec3-9dab-4be7-a4ee-0fc381895d26,DISK], DatanodeInfoWithStorage[127.0.0.1:33739,DS-43830596-03e4-4861-b928-1b50b76e2e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:35596,DS-63e5f271-7a16-41b9-81bb-5a1900cfe6c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42155,DS-21458f7f-6ff2-4571-a491-748e1ecea881,DISK], DatanodeInfoWithStorage[127.0.0.1:37934,DS-a4a0c624-6158-463a-93e2-82f4c33387f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40196,DS-8449c40f-ab35-4efb-8a66-94e5c8eb28ff,DISK], DatanodeInfoWithStorage[127.0.0.1:46645,DS-408bc9d2-cfab-431b-af86-2ad230118b8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-389926765-172.17.0.19-1596953968215:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40840,DS-2d80994f-29b4-4694-ac6f-797a5bb2c102,DISK], DatanodeInfoWithStorage[127.0.0.1:33005,DS-6d218ec3-9dab-4be7-a4ee-0fc381895d26,DISK], DatanodeInfoWithStorage[127.0.0.1:33739,DS-43830596-03e4-4861-b928-1b50b76e2e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:35596,DS-63e5f271-7a16-41b9-81bb-5a1900cfe6c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42155,DS-21458f7f-6ff2-4571-a491-748e1ecea881,DISK], DatanodeInfoWithStorage[127.0.0.1:37934,DS-a4a0c624-6158-463a-93e2-82f4c33387f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40196,DS-8449c40f-ab35-4efb-8a66-94e5c8eb28ff,DISK], DatanodeInfoWithStorage[127.0.0.1:46645,DS-408bc9d2-cfab-431b-af86-2ad230118b8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1675912361-172.17.0.19-1596954346936:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39053,DS-6801d48c-3bf2-465b-b3f2-98497c7f76b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39290,DS-5bc3cc61-82de-47fe-ab55-a0937f72fd97,DISK], DatanodeInfoWithStorage[127.0.0.1:33231,DS-c4680a7d-f88a-4f08-a5f5-d06ada44b396,DISK], DatanodeInfoWithStorage[127.0.0.1:35661,DS-f2f44967-bab7-45b1-95a4-7f99c815f1ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39475,DS-d96bea6f-2db9-43a7-802f-f45d702e1470,DISK], DatanodeInfoWithStorage[127.0.0.1:38961,DS-05f83f9c-8b59-4f35-b2f9-5255fe7ac7c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36844,DS-04d84ab4-24ef-4b1c-81d6-cb96398647ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44887,DS-5787df4c-fa34-46f6-a935-be024a60a30b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1675912361-172.17.0.19-1596954346936:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39053,DS-6801d48c-3bf2-465b-b3f2-98497c7f76b4,DISK], DatanodeInfoWithStorage[127.0.0.1:39290,DS-5bc3cc61-82de-47fe-ab55-a0937f72fd97,DISK], DatanodeInfoWithStorage[127.0.0.1:33231,DS-c4680a7d-f88a-4f08-a5f5-d06ada44b396,DISK], DatanodeInfoWithStorage[127.0.0.1:35661,DS-f2f44967-bab7-45b1-95a4-7f99c815f1ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39475,DS-d96bea6f-2db9-43a7-802f-f45d702e1470,DISK], DatanodeInfoWithStorage[127.0.0.1:38961,DS-05f83f9c-8b59-4f35-b2f9-5255fe7ac7c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36844,DS-04d84ab4-24ef-4b1c-81d6-cb96398647ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44887,DS-5787df4c-fa34-46f6-a935-be024a60a30b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1909874365-172.17.0.19-1596954570783:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32800,DS-5c5842a6-363c-4a15-a446-3059f59fe257,DISK], DatanodeInfoWithStorage[127.0.0.1:36492,DS-636f2c1e-5f58-448f-a389-cbd019b7fb65,DISK], DatanodeInfoWithStorage[127.0.0.1:41450,DS-03de6c7d-4dbd-48f2-8e26-1c822d922338,DISK], DatanodeInfoWithStorage[127.0.0.1:36040,DS-2320c209-1f4d-4228-a388-d05c754c0727,DISK], DatanodeInfoWithStorage[127.0.0.1:33581,DS-4a7cca8a-1b9a-449a-8aa6-80a13ba75895,DISK], DatanodeInfoWithStorage[127.0.0.1:35990,DS-6186d2ac-4c71-47a2-b7e6-53812fd0d0b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46756,DS-a91c9a15-49ea-4a75-b03d-c2a8e2219543,DISK], DatanodeInfoWithStorage[127.0.0.1:45133,DS-412bcc50-551a-4625-a9bc-d38a56ec5d18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1909874365-172.17.0.19-1596954570783:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32800,DS-5c5842a6-363c-4a15-a446-3059f59fe257,DISK], DatanodeInfoWithStorage[127.0.0.1:36492,DS-636f2c1e-5f58-448f-a389-cbd019b7fb65,DISK], DatanodeInfoWithStorage[127.0.0.1:41450,DS-03de6c7d-4dbd-48f2-8e26-1c822d922338,DISK], DatanodeInfoWithStorage[127.0.0.1:36040,DS-2320c209-1f4d-4228-a388-d05c754c0727,DISK], DatanodeInfoWithStorage[127.0.0.1:33581,DS-4a7cca8a-1b9a-449a-8aa6-80a13ba75895,DISK], DatanodeInfoWithStorage[127.0.0.1:35990,DS-6186d2ac-4c71-47a2-b7e6-53812fd0d0b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46756,DS-a91c9a15-49ea-4a75-b03d-c2a8e2219543,DISK], DatanodeInfoWithStorage[127.0.0.1:45133,DS-412bcc50-551a-4625-a9bc-d38a56ec5d18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1934664296-172.17.0.19-1596954691067:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35960,DS-73972772-cc42-4f28-b8da-12202801f101,DISK], DatanodeInfoWithStorage[127.0.0.1:43656,DS-b6071ee2-3cc5-4e94-8eb0-97ec7ea65b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:43484,DS-c343e9d1-5c1a-4fd0-af71-593e7592b82e,DISK], DatanodeInfoWithStorage[127.0.0.1:45836,DS-544d57ab-32e8-4f9f-bd1f-05d1eaaccd69,DISK], DatanodeInfoWithStorage[127.0.0.1:32988,DS-e25a6e0c-0f1a-4f94-96b9-5a31862f9baf,DISK], DatanodeInfoWithStorage[127.0.0.1:40137,DS-d3d85292-9198-4fdc-aa7d-bd39905f7c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:40046,DS-ee14263a-bf12-4f78-9773-95bc71d2129c,DISK], DatanodeInfoWithStorage[127.0.0.1:41617,DS-b080323b-0dfd-420f-900c-ee9ce6d03219,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1934664296-172.17.0.19-1596954691067:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35960,DS-73972772-cc42-4f28-b8da-12202801f101,DISK], DatanodeInfoWithStorage[127.0.0.1:43656,DS-b6071ee2-3cc5-4e94-8eb0-97ec7ea65b8f,DISK], DatanodeInfoWithStorage[127.0.0.1:43484,DS-c343e9d1-5c1a-4fd0-af71-593e7592b82e,DISK], DatanodeInfoWithStorage[127.0.0.1:45836,DS-544d57ab-32e8-4f9f-bd1f-05d1eaaccd69,DISK], DatanodeInfoWithStorage[127.0.0.1:32988,DS-e25a6e0c-0f1a-4f94-96b9-5a31862f9baf,DISK], DatanodeInfoWithStorage[127.0.0.1:40137,DS-d3d85292-9198-4fdc-aa7d-bd39905f7c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:40046,DS-ee14263a-bf12-4f78-9773-95bc71d2129c,DISK], DatanodeInfoWithStorage[127.0.0.1:41617,DS-b080323b-0dfd-420f-900c-ee9ce6d03219,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1358808834-172.17.0.19-1596954834602:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42032,DS-fdedf929-2822-4053-bb70-ead982ae9879,DISK], DatanodeInfoWithStorage[127.0.0.1:41488,DS-ca9fe0d2-66ed-42c0-957f-93745e79dd14,DISK], DatanodeInfoWithStorage[127.0.0.1:45169,DS-11b61549-46c4-42b6-801a-cdb981b863e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35159,DS-403c61b5-0bd4-4618-bffb-0e29841d2627,DISK], DatanodeInfoWithStorage[127.0.0.1:33277,DS-a93a2fb9-5210-4d54-a7d0-c83665309260,DISK], DatanodeInfoWithStorage[127.0.0.1:44569,DS-d0e140da-5b62-4fcc-bb00-e24078659dff,DISK], DatanodeInfoWithStorage[127.0.0.1:38903,DS-a13d7077-b71e-4b4a-b3ee-3b98437f0edd,DISK], DatanodeInfoWithStorage[127.0.0.1:41127,DS-e4763e8a-6069-41df-9427-68edfe3867f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1358808834-172.17.0.19-1596954834602:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42032,DS-fdedf929-2822-4053-bb70-ead982ae9879,DISK], DatanodeInfoWithStorage[127.0.0.1:41488,DS-ca9fe0d2-66ed-42c0-957f-93745e79dd14,DISK], DatanodeInfoWithStorage[127.0.0.1:45169,DS-11b61549-46c4-42b6-801a-cdb981b863e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35159,DS-403c61b5-0bd4-4618-bffb-0e29841d2627,DISK], DatanodeInfoWithStorage[127.0.0.1:33277,DS-a93a2fb9-5210-4d54-a7d0-c83665309260,DISK], DatanodeInfoWithStorage[127.0.0.1:44569,DS-d0e140da-5b62-4fcc-bb00-e24078659dff,DISK], DatanodeInfoWithStorage[127.0.0.1:38903,DS-a13d7077-b71e-4b4a-b3ee-3b98437f0edd,DISK], DatanodeInfoWithStorage[127.0.0.1:41127,DS-e4763e8a-6069-41df-9427-68edfe3867f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5315
