reconf_parameter: ipc.client.fallback-to-simple-auth-allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.fallback-to-simple-auth-allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-337179559-172.17.0.7-1595314515972:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43678,DS-6ecafbad-eb24-4715-9eab-18ed804aa587,DISK], DatanodeInfoWithStorage[127.0.0.1:41387,DS-3c7f5525-c07c-4442-bb72-29d8bccd6487,DISK], DatanodeInfoWithStorage[127.0.0.1:33921,DS-7e8132e5-b45c-4f22-869b-9704c12cac35,DISK], DatanodeInfoWithStorage[127.0.0.1:44728,DS-4e882151-2006-450a-8fae-6ddc9022560d,DISK], DatanodeInfoWithStorage[127.0.0.1:46372,DS-f9c5dab2-0c83-458d-90a3-fbc08d60f176,DISK], DatanodeInfoWithStorage[127.0.0.1:37833,DS-53450369-3dea-453d-8a63-b905b8700ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:46012,DS-dcb8e6fe-6c24-4fe5-a42d-436b86ad2666,DISK], DatanodeInfoWithStorage[127.0.0.1:46464,DS-f6b2e373-3536-43dc-9101-dbd93d9afc04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-337179559-172.17.0.7-1595314515972:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43678,DS-6ecafbad-eb24-4715-9eab-18ed804aa587,DISK], DatanodeInfoWithStorage[127.0.0.1:41387,DS-3c7f5525-c07c-4442-bb72-29d8bccd6487,DISK], DatanodeInfoWithStorage[127.0.0.1:33921,DS-7e8132e5-b45c-4f22-869b-9704c12cac35,DISK], DatanodeInfoWithStorage[127.0.0.1:44728,DS-4e882151-2006-450a-8fae-6ddc9022560d,DISK], DatanodeInfoWithStorage[127.0.0.1:46372,DS-f9c5dab2-0c83-458d-90a3-fbc08d60f176,DISK], DatanodeInfoWithStorage[127.0.0.1:37833,DS-53450369-3dea-453d-8a63-b905b8700ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:46012,DS-dcb8e6fe-6c24-4fe5-a42d-436b86ad2666,DISK], DatanodeInfoWithStorage[127.0.0.1:46464,DS-f6b2e373-3536-43dc-9101-dbd93d9afc04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.fallback-to-simple-auth-allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-432787171-172.17.0.7-1595315216354:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42103,DS-9e8a5090-d2ef-4445-9a4e-fbd3b36450f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34505,DS-d4da09e0-dd9f-4c18-a781-f2ef7ab3fd91,DISK], DatanodeInfoWithStorage[127.0.0.1:34964,DS-06835a3b-890c-4706-b147-990c5e92df37,DISK], DatanodeInfoWithStorage[127.0.0.1:35927,DS-19ab4e15-5491-4c3b-889e-b1007e7e34bb,DISK], DatanodeInfoWithStorage[127.0.0.1:46073,DS-0869b8c1-6e00-457a-9bda-7ac9ff6e5a77,DISK], DatanodeInfoWithStorage[127.0.0.1:44634,DS-95ec6be9-3062-4906-b660-9412662acea9,DISK], DatanodeInfoWithStorage[127.0.0.1:33851,DS-b0f4c4eb-9b1a-44d5-8c22-97b936ae8095,DISK], DatanodeInfoWithStorage[127.0.0.1:45777,DS-067f5dbc-a778-42ec-a0d2-f461a7412987,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-432787171-172.17.0.7-1595315216354:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42103,DS-9e8a5090-d2ef-4445-9a4e-fbd3b36450f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34505,DS-d4da09e0-dd9f-4c18-a781-f2ef7ab3fd91,DISK], DatanodeInfoWithStorage[127.0.0.1:34964,DS-06835a3b-890c-4706-b147-990c5e92df37,DISK], DatanodeInfoWithStorage[127.0.0.1:35927,DS-19ab4e15-5491-4c3b-889e-b1007e7e34bb,DISK], DatanodeInfoWithStorage[127.0.0.1:46073,DS-0869b8c1-6e00-457a-9bda-7ac9ff6e5a77,DISK], DatanodeInfoWithStorage[127.0.0.1:44634,DS-95ec6be9-3062-4906-b660-9412662acea9,DISK], DatanodeInfoWithStorage[127.0.0.1:33851,DS-b0f4c4eb-9b1a-44d5-8c22-97b936ae8095,DISK], DatanodeInfoWithStorage[127.0.0.1:45777,DS-067f5dbc-a778-42ec-a0d2-f461a7412987,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.fallback-to-simple-auth-allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1239455424-172.17.0.7-1595315598514:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46181,DS-9e1da915-942c-45e6-8929-698e8865d04e,DISK], DatanodeInfoWithStorage[127.0.0.1:34267,DS-51957317-929b-4f9c-b143-4f23bcd5c1c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45747,DS-901edc09-b030-44d4-86cc-fbbff71a0da7,DISK], DatanodeInfoWithStorage[127.0.0.1:42488,DS-68445d36-c9aa-4375-903d-1993dbda5043,DISK], DatanodeInfoWithStorage[127.0.0.1:44567,DS-0cac0ec5-2253-47b9-acef-f1d9414b2a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:42337,DS-a3e879c7-f0ff-43f7-affb-289d75af989b,DISK], DatanodeInfoWithStorage[127.0.0.1:36174,DS-9839aae8-aa93-4233-8f8c-54141ec79b4f,DISK], DatanodeInfoWithStorage[127.0.0.1:32888,DS-e4a54d3f-4927-4b11-8ab7-54aa9def2798,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1239455424-172.17.0.7-1595315598514:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46181,DS-9e1da915-942c-45e6-8929-698e8865d04e,DISK], DatanodeInfoWithStorage[127.0.0.1:34267,DS-51957317-929b-4f9c-b143-4f23bcd5c1c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45747,DS-901edc09-b030-44d4-86cc-fbbff71a0da7,DISK], DatanodeInfoWithStorage[127.0.0.1:42488,DS-68445d36-c9aa-4375-903d-1993dbda5043,DISK], DatanodeInfoWithStorage[127.0.0.1:44567,DS-0cac0ec5-2253-47b9-acef-f1d9414b2a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:42337,DS-a3e879c7-f0ff-43f7-affb-289d75af989b,DISK], DatanodeInfoWithStorage[127.0.0.1:36174,DS-9839aae8-aa93-4233-8f8c-54141ec79b4f,DISK], DatanodeInfoWithStorage[127.0.0.1:32888,DS-e4a54d3f-4927-4b11-8ab7-54aa9def2798,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.fallback-to-simple-auth-allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1534319671-172.17.0.7-1595315669236:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46368,DS-f1f64336-e2bb-479d-b25d-2a3c4358e605,DISK], DatanodeInfoWithStorage[127.0.0.1:41838,DS-a4df8b03-3d7f-4c7a-9787-f5e275d16da0,DISK], DatanodeInfoWithStorage[127.0.0.1:33981,DS-dad7c657-f718-4f46-8d93-b58e7d71f96f,DISK], DatanodeInfoWithStorage[127.0.0.1:37506,DS-81b0ff85-f051-4a9d-8de3-c1e68608ebfb,DISK], DatanodeInfoWithStorage[127.0.0.1:40174,DS-2590b441-0e45-4611-9030-81c0f318ea3f,DISK], DatanodeInfoWithStorage[127.0.0.1:41049,DS-8ebda475-ee1d-4f0b-8cfc-1b481130ecaa,DISK], DatanodeInfoWithStorage[127.0.0.1:39165,DS-98cd39fe-64e0-4c4b-9d87-67c68accdb86,DISK], DatanodeInfoWithStorage[127.0.0.1:45289,DS-892ec61f-885b-4e73-97f4-fb66a46849d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1534319671-172.17.0.7-1595315669236:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46368,DS-f1f64336-e2bb-479d-b25d-2a3c4358e605,DISK], DatanodeInfoWithStorage[127.0.0.1:41838,DS-a4df8b03-3d7f-4c7a-9787-f5e275d16da0,DISK], DatanodeInfoWithStorage[127.0.0.1:33981,DS-dad7c657-f718-4f46-8d93-b58e7d71f96f,DISK], DatanodeInfoWithStorage[127.0.0.1:37506,DS-81b0ff85-f051-4a9d-8de3-c1e68608ebfb,DISK], DatanodeInfoWithStorage[127.0.0.1:40174,DS-2590b441-0e45-4611-9030-81c0f318ea3f,DISK], DatanodeInfoWithStorage[127.0.0.1:41049,DS-8ebda475-ee1d-4f0b-8cfc-1b481130ecaa,DISK], DatanodeInfoWithStorage[127.0.0.1:39165,DS-98cd39fe-64e0-4c4b-9d87-67c68accdb86,DISK], DatanodeInfoWithStorage[127.0.0.1:45289,DS-892ec61f-885b-4e73-97f4-fb66a46849d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.fallback-to-simple-auth-allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-498010242-172.17.0.7-1595315828917:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40369,DS-ac423720-a6e5-43ad-9f15-3217f2f91e82,DISK], DatanodeInfoWithStorage[127.0.0.1:40825,DS-427ec43f-3c80-467d-bcd4-19be3b8efa22,DISK], DatanodeInfoWithStorage[127.0.0.1:41341,DS-33033b51-91d9-42c0-badc-0e18b2dfcf5a,DISK], DatanodeInfoWithStorage[127.0.0.1:32962,DS-2b2b3e28-0212-4bb2-afcb-5b1c99a6edd1,DISK], DatanodeInfoWithStorage[127.0.0.1:44990,DS-99739f29-9960-4c3d-bbca-51be35755000,DISK], DatanodeInfoWithStorage[127.0.0.1:46243,DS-fad598d8-0ae4-4456-929d-102c293a0661,DISK], DatanodeInfoWithStorage[127.0.0.1:38846,DS-b7bb6205-ef48-409d-a370-3396baf9fea8,DISK], DatanodeInfoWithStorage[127.0.0.1:43908,DS-200277c6-7b01-45fc-9374-d3030b1f6fdb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-498010242-172.17.0.7-1595315828917:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40369,DS-ac423720-a6e5-43ad-9f15-3217f2f91e82,DISK], DatanodeInfoWithStorage[127.0.0.1:40825,DS-427ec43f-3c80-467d-bcd4-19be3b8efa22,DISK], DatanodeInfoWithStorage[127.0.0.1:41341,DS-33033b51-91d9-42c0-badc-0e18b2dfcf5a,DISK], DatanodeInfoWithStorage[127.0.0.1:32962,DS-2b2b3e28-0212-4bb2-afcb-5b1c99a6edd1,DISK], DatanodeInfoWithStorage[127.0.0.1:44990,DS-99739f29-9960-4c3d-bbca-51be35755000,DISK], DatanodeInfoWithStorage[127.0.0.1:46243,DS-fad598d8-0ae4-4456-929d-102c293a0661,DISK], DatanodeInfoWithStorage[127.0.0.1:38846,DS-b7bb6205-ef48-409d-a370-3396baf9fea8,DISK], DatanodeInfoWithStorage[127.0.0.1:43908,DS-200277c6-7b01-45fc-9374-d3030b1f6fdb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.fallback-to-simple-auth-allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-399098504-172.17.0.7-1595318512782:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43252,DS-1ef8a4a1-87f8-495c-9b29-0d41b8f70063,DISK], DatanodeInfoWithStorage[127.0.0.1:40894,DS-cedcd21a-d93a-4a95-9cf3-42faa3dd651d,DISK], DatanodeInfoWithStorage[127.0.0.1:43164,DS-bbf9fa3c-f075-48fe-8878-b3748ecafc91,DISK], DatanodeInfoWithStorage[127.0.0.1:38985,DS-4886cc94-a64f-4a27-9e96-06d5de622816,DISK], DatanodeInfoWithStorage[127.0.0.1:33970,DS-f2db71cc-5072-4809-9f0b-7b96b7eb0322,DISK], DatanodeInfoWithStorage[127.0.0.1:42449,DS-56f3102f-36e4-459e-87b1-a875f6432a49,DISK], DatanodeInfoWithStorage[127.0.0.1:35730,DS-0a982e8d-a3d0-4e2b-a511-16762ea96ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:38236,DS-792ef313-21b8-46cf-84b6-ac6052b93e99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-399098504-172.17.0.7-1595318512782:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43252,DS-1ef8a4a1-87f8-495c-9b29-0d41b8f70063,DISK], DatanodeInfoWithStorage[127.0.0.1:40894,DS-cedcd21a-d93a-4a95-9cf3-42faa3dd651d,DISK], DatanodeInfoWithStorage[127.0.0.1:43164,DS-bbf9fa3c-f075-48fe-8878-b3748ecafc91,DISK], DatanodeInfoWithStorage[127.0.0.1:38985,DS-4886cc94-a64f-4a27-9e96-06d5de622816,DISK], DatanodeInfoWithStorage[127.0.0.1:33970,DS-f2db71cc-5072-4809-9f0b-7b96b7eb0322,DISK], DatanodeInfoWithStorage[127.0.0.1:42449,DS-56f3102f-36e4-459e-87b1-a875f6432a49,DISK], DatanodeInfoWithStorage[127.0.0.1:35730,DS-0a982e8d-a3d0-4e2b-a511-16762ea96ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:38236,DS-792ef313-21b8-46cf-84b6-ac6052b93e99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.fallback-to-simple-auth-allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1534435866-172.17.0.7-1595318669651:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42471,DS-10d90d8b-bf4a-434c-9f62-00a8f44ee470,DISK], DatanodeInfoWithStorage[127.0.0.1:40864,DS-96268e6c-ee19-4c08-af0e-6176a37d7abc,DISK], DatanodeInfoWithStorage[127.0.0.1:35502,DS-5538065c-77be-4296-ba6d-aa263649b4b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34033,DS-6a77ab31-df2d-487a-9349-2f399d095a12,DISK], DatanodeInfoWithStorage[127.0.0.1:41267,DS-a53fe39f-a6c5-4bff-81c3-62c57faccc49,DISK], DatanodeInfoWithStorage[127.0.0.1:35336,DS-d117caba-68fb-44cd-bcfc-8880f4ae808f,DISK], DatanodeInfoWithStorage[127.0.0.1:44825,DS-544707db-da35-4967-b6e4-99f7ca45bd4d,DISK], DatanodeInfoWithStorage[127.0.0.1:35973,DS-4f34c1f4-4656-469d-bbf5-d4a3edf3d4f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1534435866-172.17.0.7-1595318669651:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42471,DS-10d90d8b-bf4a-434c-9f62-00a8f44ee470,DISK], DatanodeInfoWithStorage[127.0.0.1:40864,DS-96268e6c-ee19-4c08-af0e-6176a37d7abc,DISK], DatanodeInfoWithStorage[127.0.0.1:35502,DS-5538065c-77be-4296-ba6d-aa263649b4b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34033,DS-6a77ab31-df2d-487a-9349-2f399d095a12,DISK], DatanodeInfoWithStorage[127.0.0.1:41267,DS-a53fe39f-a6c5-4bff-81c3-62c57faccc49,DISK], DatanodeInfoWithStorage[127.0.0.1:35336,DS-d117caba-68fb-44cd-bcfc-8880f4ae808f,DISK], DatanodeInfoWithStorage[127.0.0.1:44825,DS-544707db-da35-4967-b6e4-99f7ca45bd4d,DISK], DatanodeInfoWithStorage[127.0.0.1:35973,DS-4f34c1f4-4656-469d-bbf5-d4a3edf3d4f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.fallback-to-simple-auth-allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-287257312-172.17.0.7-1595319326392:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44201,DS-451fcdde-ea6a-4799-aa15-842fb526ff83,DISK], DatanodeInfoWithStorage[127.0.0.1:45870,DS-4f0d0d4d-f1ee-4ea3-b28d-cce75bbe5298,DISK], DatanodeInfoWithStorage[127.0.0.1:43132,DS-73d4be25-e2ec-4398-9258-b1ffa30a3106,DISK], DatanodeInfoWithStorage[127.0.0.1:44793,DS-740b35da-90ec-4d18-b767-255fc6754028,DISK], DatanodeInfoWithStorage[127.0.0.1:39167,DS-73b1faea-9381-40b9-a79d-0e9d1a3005f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45919,DS-f7da3bd4-f4ff-433a-ad5b-c2adc74841a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42291,DS-cc4bbadb-8a21-4918-8c58-e25f013862dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41886,DS-ae957d84-74f9-4cb2-a84e-425873c63cd6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-287257312-172.17.0.7-1595319326392:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44201,DS-451fcdde-ea6a-4799-aa15-842fb526ff83,DISK], DatanodeInfoWithStorage[127.0.0.1:45870,DS-4f0d0d4d-f1ee-4ea3-b28d-cce75bbe5298,DISK], DatanodeInfoWithStorage[127.0.0.1:43132,DS-73d4be25-e2ec-4398-9258-b1ffa30a3106,DISK], DatanodeInfoWithStorage[127.0.0.1:44793,DS-740b35da-90ec-4d18-b767-255fc6754028,DISK], DatanodeInfoWithStorage[127.0.0.1:39167,DS-73b1faea-9381-40b9-a79d-0e9d1a3005f5,DISK], DatanodeInfoWithStorage[127.0.0.1:45919,DS-f7da3bd4-f4ff-433a-ad5b-c2adc74841a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42291,DS-cc4bbadb-8a21-4918-8c58-e25f013862dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41886,DS-ae957d84-74f9-4cb2-a84e-425873c63cd6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.fallback-to-simple-auth-allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1973863198-172.17.0.7-1595319365534:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37675,DS-3ff88be3-aac1-494f-bc25-b0490b3cba3b,DISK], DatanodeInfoWithStorage[127.0.0.1:46660,DS-af8bf873-569b-4047-ab61-d8d173a68b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:41867,DS-9a9a9ce4-c90a-42f0-baec-571b98a29a93,DISK], DatanodeInfoWithStorage[127.0.0.1:36004,DS-4540ddf5-f766-4b81-a8da-b3879128e7dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38342,DS-2caf3b92-8e36-468b-a030-70747bcaba18,DISK], DatanodeInfoWithStorage[127.0.0.1:39855,DS-e8b7e824-5296-4927-8905-204e462ac41c,DISK], DatanodeInfoWithStorage[127.0.0.1:35019,DS-d7d47ec8-eecc-4d8e-a256-b71e183477a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41424,DS-55a12c36-7576-4884-9411-2717b8b77465,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1973863198-172.17.0.7-1595319365534:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37675,DS-3ff88be3-aac1-494f-bc25-b0490b3cba3b,DISK], DatanodeInfoWithStorage[127.0.0.1:46660,DS-af8bf873-569b-4047-ab61-d8d173a68b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:41867,DS-9a9a9ce4-c90a-42f0-baec-571b98a29a93,DISK], DatanodeInfoWithStorage[127.0.0.1:36004,DS-4540ddf5-f766-4b81-a8da-b3879128e7dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38342,DS-2caf3b92-8e36-468b-a030-70747bcaba18,DISK], DatanodeInfoWithStorage[127.0.0.1:39855,DS-e8b7e824-5296-4927-8905-204e462ac41c,DISK], DatanodeInfoWithStorage[127.0.0.1:35019,DS-d7d47ec8-eecc-4d8e-a256-b71e183477a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41424,DS-55a12c36-7576-4884-9411-2717b8b77465,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.fallback-to-simple-auth-allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1619990343-172.17.0.7-1595319829775:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36488,DS-57c41f7e-d90d-4c9b-9ff6-78139d641ed4,DISK], DatanodeInfoWithStorage[127.0.0.1:34068,DS-a39a7716-79ee-49b2-a29c-8369b3a50f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:46254,DS-f4cb5475-35d5-4649-8e2e-f4c639b5d298,DISK], DatanodeInfoWithStorage[127.0.0.1:34016,DS-959adb1b-2a06-409c-834b-c9475169461d,DISK], DatanodeInfoWithStorage[127.0.0.1:41746,DS-04ee9178-880f-4481-b121-0ffe31dd4b94,DISK], DatanodeInfoWithStorage[127.0.0.1:40154,DS-64c93c48-4d78-4e3d-bafa-afa84a939498,DISK], DatanodeInfoWithStorage[127.0.0.1:42018,DS-544b5dfb-fed2-4358-a0c2-f7a0f5c28b32,DISK], DatanodeInfoWithStorage[127.0.0.1:45696,DS-a703d721-c57b-4be7-9c6c-c92434395f93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1619990343-172.17.0.7-1595319829775:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36488,DS-57c41f7e-d90d-4c9b-9ff6-78139d641ed4,DISK], DatanodeInfoWithStorage[127.0.0.1:34068,DS-a39a7716-79ee-49b2-a29c-8369b3a50f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:46254,DS-f4cb5475-35d5-4649-8e2e-f4c639b5d298,DISK], DatanodeInfoWithStorage[127.0.0.1:34016,DS-959adb1b-2a06-409c-834b-c9475169461d,DISK], DatanodeInfoWithStorage[127.0.0.1:41746,DS-04ee9178-880f-4481-b121-0ffe31dd4b94,DISK], DatanodeInfoWithStorage[127.0.0.1:40154,DS-64c93c48-4d78-4e3d-bafa-afa84a939498,DISK], DatanodeInfoWithStorage[127.0.0.1:42018,DS-544b5dfb-fed2-4358-a0c2-f7a0f5c28b32,DISK], DatanodeInfoWithStorage[127.0.0.1:45696,DS-a703d721-c57b-4be7-9c6c-c92434395f93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.fallback-to-simple-auth-allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1988636194-172.17.0.7-1595319858573:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44357,DS-8ac60410-f41c-4439-98ce-a40ccf53cf7f,DISK], DatanodeInfoWithStorage[127.0.0.1:45791,DS-278e5cac-58c2-4fa4-bd08-7ff4dc61eca4,DISK], DatanodeInfoWithStorage[127.0.0.1:39238,DS-a6a21360-0ceb-4e4d-8f28-24bc0f2d2de3,DISK], DatanodeInfoWithStorage[127.0.0.1:42598,DS-5fb950b0-4d40-4341-8121-ddb101524460,DISK], DatanodeInfoWithStorage[127.0.0.1:38370,DS-482c35b8-8ebc-4d73-a018-3b63bcc58456,DISK], DatanodeInfoWithStorage[127.0.0.1:35450,DS-03f65498-e718-4fca-b4e7-c6637b633a08,DISK], DatanodeInfoWithStorage[127.0.0.1:39082,DS-e13f173f-0f42-4b34-9e23-2f83c0964ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:34926,DS-ddd50f08-2aa9-48f4-a27f-89df87f5d04a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1988636194-172.17.0.7-1595319858573:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44357,DS-8ac60410-f41c-4439-98ce-a40ccf53cf7f,DISK], DatanodeInfoWithStorage[127.0.0.1:45791,DS-278e5cac-58c2-4fa4-bd08-7ff4dc61eca4,DISK], DatanodeInfoWithStorage[127.0.0.1:39238,DS-a6a21360-0ceb-4e4d-8f28-24bc0f2d2de3,DISK], DatanodeInfoWithStorage[127.0.0.1:42598,DS-5fb950b0-4d40-4341-8121-ddb101524460,DISK], DatanodeInfoWithStorage[127.0.0.1:38370,DS-482c35b8-8ebc-4d73-a018-3b63bcc58456,DISK], DatanodeInfoWithStorage[127.0.0.1:35450,DS-03f65498-e718-4fca-b4e7-c6637b633a08,DISK], DatanodeInfoWithStorage[127.0.0.1:39082,DS-e13f173f-0f42-4b34-9e23-2f83c0964ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:34926,DS-ddd50f08-2aa9-48f4-a27f-89df87f5d04a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.fallback-to-simple-auth-allowed
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1300953667-172.17.0.7-1595320139077:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45680,DS-8019d5ae-07f3-423f-866f-024a5882c7de,DISK], DatanodeInfoWithStorage[127.0.0.1:45376,DS-8684e965-d2ff-4d3c-b02b-2462aa959b17,DISK], DatanodeInfoWithStorage[127.0.0.1:42475,DS-63777242-07b5-4886-9336-ffcbb789c186,DISK], DatanodeInfoWithStorage[127.0.0.1:36121,DS-559ef379-8bac-4c5b-8ce8-f25ceafe35b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44335,DS-11cb46f6-c466-41c5-8274-1d31bcaf1606,DISK], DatanodeInfoWithStorage[127.0.0.1:46674,DS-1398f6d0-de59-4291-8069-130cf5f201e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34534,DS-2ad86593-3591-4f11-8f01-0115d0aad037,DISK], DatanodeInfoWithStorage[127.0.0.1:38994,DS-0529ea5a-f855-4c72-b8a6-84731bbc501e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1300953667-172.17.0.7-1595320139077:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45680,DS-8019d5ae-07f3-423f-866f-024a5882c7de,DISK], DatanodeInfoWithStorage[127.0.0.1:45376,DS-8684e965-d2ff-4d3c-b02b-2462aa959b17,DISK], DatanodeInfoWithStorage[127.0.0.1:42475,DS-63777242-07b5-4886-9336-ffcbb789c186,DISK], DatanodeInfoWithStorage[127.0.0.1:36121,DS-559ef379-8bac-4c5b-8ce8-f25ceafe35b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44335,DS-11cb46f6-c466-41c5-8274-1d31bcaf1606,DISK], DatanodeInfoWithStorage[127.0.0.1:46674,DS-1398f6d0-de59-4291-8069-130cf5f201e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34534,DS-2ad86593-3591-4f11-8f01-0115d0aad037,DISK], DatanodeInfoWithStorage[127.0.0.1:38994,DS-0529ea5a-f855-4c72-b8a6-84731bbc501e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: false positive !!!
Total execution time in seconds : 5766
