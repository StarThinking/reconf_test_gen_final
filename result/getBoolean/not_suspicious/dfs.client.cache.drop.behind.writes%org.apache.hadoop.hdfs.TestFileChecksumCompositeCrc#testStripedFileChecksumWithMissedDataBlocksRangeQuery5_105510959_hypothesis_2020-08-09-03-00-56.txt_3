reconf_parameter: dfs.client.cache.drop.behind.writes
component: hdfs:NameNode
v1: false
v2: null
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.writes
component: hdfs:NameNode
v1: false
v2: null
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1267345498-172.17.0.20-1596942352045:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46825,DS-59936c10-da4d-4b64-83bb-f492eab95418,DISK], DatanodeInfoWithStorage[127.0.0.1:36194,DS-914ad41d-2a1f-4959-b177-924a076b18ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45596,DS-21f7dc24-e464-418e-a18a-5f4a2ed95005,DISK], DatanodeInfoWithStorage[127.0.0.1:38709,DS-8a7724a2-b7bc-48cb-9f26-b851f45cf60c,DISK], DatanodeInfoWithStorage[127.0.0.1:33631,DS-dbf5abab-819f-4a4b-9d45-dc7825356c9a,DISK], DatanodeInfoWithStorage[127.0.0.1:39234,DS-7d65ffa4-6de0-4f7f-a17f-7967614d746d,DISK], DatanodeInfoWithStorage[127.0.0.1:40819,DS-31cd3d06-b937-4417-a067-fdd438587b8c,DISK], DatanodeInfoWithStorage[127.0.0.1:35949,DS-136a7fed-351b-4f64-877a-f2eaeab5ef11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1267345498-172.17.0.20-1596942352045:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46825,DS-59936c10-da4d-4b64-83bb-f492eab95418,DISK], DatanodeInfoWithStorage[127.0.0.1:36194,DS-914ad41d-2a1f-4959-b177-924a076b18ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45596,DS-21f7dc24-e464-418e-a18a-5f4a2ed95005,DISK], DatanodeInfoWithStorage[127.0.0.1:38709,DS-8a7724a2-b7bc-48cb-9f26-b851f45cf60c,DISK], DatanodeInfoWithStorage[127.0.0.1:33631,DS-dbf5abab-819f-4a4b-9d45-dc7825356c9a,DISK], DatanodeInfoWithStorage[127.0.0.1:39234,DS-7d65ffa4-6de0-4f7f-a17f-7967614d746d,DISK], DatanodeInfoWithStorage[127.0.0.1:40819,DS-31cd3d06-b937-4417-a067-fdd438587b8c,DISK], DatanodeInfoWithStorage[127.0.0.1:35949,DS-136a7fed-351b-4f64-877a-f2eaeab5ef11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.writes
component: hdfs:NameNode
v1: false
v2: null
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1498068399-172.17.0.20-1596942694195:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38476,DS-da6506d1-5839-4f62-a6e1-e6060f363dea,DISK], DatanodeInfoWithStorage[127.0.0.1:44635,DS-de911b9b-ddaa-4900-8589-75d62f758068,DISK], DatanodeInfoWithStorage[127.0.0.1:37071,DS-159487db-1b6c-4c0b-a8c3-fb6bddcd6591,DISK], DatanodeInfoWithStorage[127.0.0.1:37436,DS-0b9ed0e7-b2a0-4418-bf8e-e0b667c32613,DISK], DatanodeInfoWithStorage[127.0.0.1:42404,DS-2402c86a-93ff-4246-9f74-6db3d0ada4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:42962,DS-dc981be4-91e8-4567-a973-c379eea82b47,DISK], DatanodeInfoWithStorage[127.0.0.1:37550,DS-fa944f59-4eb7-4a3d-b063-b4ece5f08d14,DISK], DatanodeInfoWithStorage[127.0.0.1:38672,DS-30c29552-8b6d-4906-aa58-a8d66367d879,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1498068399-172.17.0.20-1596942694195:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38476,DS-da6506d1-5839-4f62-a6e1-e6060f363dea,DISK], DatanodeInfoWithStorage[127.0.0.1:44635,DS-de911b9b-ddaa-4900-8589-75d62f758068,DISK], DatanodeInfoWithStorage[127.0.0.1:37071,DS-159487db-1b6c-4c0b-a8c3-fb6bddcd6591,DISK], DatanodeInfoWithStorage[127.0.0.1:37436,DS-0b9ed0e7-b2a0-4418-bf8e-e0b667c32613,DISK], DatanodeInfoWithStorage[127.0.0.1:42404,DS-2402c86a-93ff-4246-9f74-6db3d0ada4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:42962,DS-dc981be4-91e8-4567-a973-c379eea82b47,DISK], DatanodeInfoWithStorage[127.0.0.1:37550,DS-fa944f59-4eb7-4a3d-b063-b4ece5f08d14,DISK], DatanodeInfoWithStorage[127.0.0.1:38672,DS-30c29552-8b6d-4906-aa58-a8d66367d879,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.writes
component: hdfs:NameNode
v1: false
v2: null
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1149763711-172.17.0.20-1596943521632:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35291,DS-918e8632-43ff-4e86-a76b-77065da3853f,DISK], DatanodeInfoWithStorage[127.0.0.1:33159,DS-9d940007-130b-4364-be05-059c86c860af,DISK], DatanodeInfoWithStorage[127.0.0.1:46128,DS-284de6c0-c2c7-40d1-9620-cc98c5c48b4c,DISK], DatanodeInfoWithStorage[127.0.0.1:43548,DS-b8537eef-ea20-4609-a492-0aa26a82790e,DISK], DatanodeInfoWithStorage[127.0.0.1:36815,DS-7aa84d95-31e2-42ea-b50a-469cdc0bd932,DISK], DatanodeInfoWithStorage[127.0.0.1:33606,DS-4cdf4be8-ff9e-49c3-802a-9410bd5e27c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36685,DS-129d496d-98b5-4148-bc14-fb17f31e9253,DISK], DatanodeInfoWithStorage[127.0.0.1:35003,DS-570b4e96-c945-4b35-8807-de65f85517b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1149763711-172.17.0.20-1596943521632:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35291,DS-918e8632-43ff-4e86-a76b-77065da3853f,DISK], DatanodeInfoWithStorage[127.0.0.1:33159,DS-9d940007-130b-4364-be05-059c86c860af,DISK], DatanodeInfoWithStorage[127.0.0.1:46128,DS-284de6c0-c2c7-40d1-9620-cc98c5c48b4c,DISK], DatanodeInfoWithStorage[127.0.0.1:43548,DS-b8537eef-ea20-4609-a492-0aa26a82790e,DISK], DatanodeInfoWithStorage[127.0.0.1:36815,DS-7aa84d95-31e2-42ea-b50a-469cdc0bd932,DISK], DatanodeInfoWithStorage[127.0.0.1:33606,DS-4cdf4be8-ff9e-49c3-802a-9410bd5e27c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36685,DS-129d496d-98b5-4148-bc14-fb17f31e9253,DISK], DatanodeInfoWithStorage[127.0.0.1:35003,DS-570b4e96-c945-4b35-8807-de65f85517b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.writes
component: hdfs:NameNode
v1: false
v2: null
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1109417764-172.17.0.20-1596943620408:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37861,DS-f93316f9-e150-4af4-8424-ffd9c7a544b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34336,DS-0d0eea7c-a9e4-434a-adda-7a6236dd021f,DISK], DatanodeInfoWithStorage[127.0.0.1:44735,DS-532462d8-5332-48b2-a29c-cb89c19570bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39000,DS-cb44ac6e-54f4-4092-837b-39a23198be8c,DISK], DatanodeInfoWithStorage[127.0.0.1:41755,DS-d1e0e129-9c8a-4641-9228-d60ca5f294db,DISK], DatanodeInfoWithStorage[127.0.0.1:35427,DS-d07160a7-f5d2-49f9-826a-4e342ac33830,DISK], DatanodeInfoWithStorage[127.0.0.1:36564,DS-cd56f8e7-c74f-4c39-9a32-a4aa05d4aacc,DISK], DatanodeInfoWithStorage[127.0.0.1:38234,DS-9b47fe24-3333-4afb-8bcf-10c102924000,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1109417764-172.17.0.20-1596943620408:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37861,DS-f93316f9-e150-4af4-8424-ffd9c7a544b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34336,DS-0d0eea7c-a9e4-434a-adda-7a6236dd021f,DISK], DatanodeInfoWithStorage[127.0.0.1:44735,DS-532462d8-5332-48b2-a29c-cb89c19570bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39000,DS-cb44ac6e-54f4-4092-837b-39a23198be8c,DISK], DatanodeInfoWithStorage[127.0.0.1:41755,DS-d1e0e129-9c8a-4641-9228-d60ca5f294db,DISK], DatanodeInfoWithStorage[127.0.0.1:35427,DS-d07160a7-f5d2-49f9-826a-4e342ac33830,DISK], DatanodeInfoWithStorage[127.0.0.1:36564,DS-cd56f8e7-c74f-4c39-9a32-a4aa05d4aacc,DISK], DatanodeInfoWithStorage[127.0.0.1:38234,DS-9b47fe24-3333-4afb-8bcf-10c102924000,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.writes
component: hdfs:NameNode
v1: false
v2: null
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1052717621-172.17.0.20-1596944041239:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42661,DS-8ffda4f7-d71d-4724-b543-a79dfb315f56,DISK], DatanodeInfoWithStorage[127.0.0.1:35856,DS-27e44cd3-dbd3-48d2-b973-d7b39bfb006a,DISK], DatanodeInfoWithStorage[127.0.0.1:36725,DS-82e04dd5-7704-4503-8cc5-737428ecb2e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34889,DS-f68a86d9-facd-46e5-a7ca-95ed7f67e1b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45337,DS-a6a6a129-1989-41ed-9a63-dd729ebaa5aa,DISK], DatanodeInfoWithStorage[127.0.0.1:42381,DS-0e31c715-ee23-40b3-b38a-c2277888b951,DISK], DatanodeInfoWithStorage[127.0.0.1:40545,DS-afddf87f-3781-4ee2-9a76-d3eee57ac87a,DISK], DatanodeInfoWithStorage[127.0.0.1:35867,DS-2e70f6b1-2074-47d9-9cc2-ae02b1f6b48a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1052717621-172.17.0.20-1596944041239:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42661,DS-8ffda4f7-d71d-4724-b543-a79dfb315f56,DISK], DatanodeInfoWithStorage[127.0.0.1:35856,DS-27e44cd3-dbd3-48d2-b973-d7b39bfb006a,DISK], DatanodeInfoWithStorage[127.0.0.1:36725,DS-82e04dd5-7704-4503-8cc5-737428ecb2e9,DISK], DatanodeInfoWithStorage[127.0.0.1:34889,DS-f68a86d9-facd-46e5-a7ca-95ed7f67e1b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45337,DS-a6a6a129-1989-41ed-9a63-dd729ebaa5aa,DISK], DatanodeInfoWithStorage[127.0.0.1:42381,DS-0e31c715-ee23-40b3-b38a-c2277888b951,DISK], DatanodeInfoWithStorage[127.0.0.1:40545,DS-afddf87f-3781-4ee2-9a76-d3eee57ac87a,DISK], DatanodeInfoWithStorage[127.0.0.1:35867,DS-2e70f6b1-2074-47d9-9cc2-ae02b1f6b48a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.writes
component: hdfs:NameNode
v1: false
v2: null
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-910647546-172.17.0.20-1596944297967:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37712,DS-84e4eee0-2bd2-4333-aa87-9cf502ca943e,DISK], DatanodeInfoWithStorage[127.0.0.1:39275,DS-fe758e0f-f40b-4c4b-812b-63655465cc94,DISK], DatanodeInfoWithStorage[127.0.0.1:33212,DS-9cec6cb6-91eb-41e2-ac61-3e018843e025,DISK], DatanodeInfoWithStorage[127.0.0.1:41621,DS-552a1d0a-dbe3-4b1e-ae08-926d92e60052,DISK], DatanodeInfoWithStorage[127.0.0.1:44711,DS-4c2cb165-dd49-4645-8888-052280762f35,DISK], DatanodeInfoWithStorage[127.0.0.1:36668,DS-e6be504f-8a9d-4ec5-a5e1-aaa4d5827d6e,DISK], DatanodeInfoWithStorage[127.0.0.1:43333,DS-d94497e6-951c-45e1-82f1-c00f8eb7bfa3,DISK], DatanodeInfoWithStorage[127.0.0.1:40767,DS-93e9bee5-05df-47aa-a8fe-2e1301c02359,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-910647546-172.17.0.20-1596944297967:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37712,DS-84e4eee0-2bd2-4333-aa87-9cf502ca943e,DISK], DatanodeInfoWithStorage[127.0.0.1:39275,DS-fe758e0f-f40b-4c4b-812b-63655465cc94,DISK], DatanodeInfoWithStorage[127.0.0.1:33212,DS-9cec6cb6-91eb-41e2-ac61-3e018843e025,DISK], DatanodeInfoWithStorage[127.0.0.1:41621,DS-552a1d0a-dbe3-4b1e-ae08-926d92e60052,DISK], DatanodeInfoWithStorage[127.0.0.1:44711,DS-4c2cb165-dd49-4645-8888-052280762f35,DISK], DatanodeInfoWithStorage[127.0.0.1:36668,DS-e6be504f-8a9d-4ec5-a5e1-aaa4d5827d6e,DISK], DatanodeInfoWithStorage[127.0.0.1:43333,DS-d94497e6-951c-45e1-82f1-c00f8eb7bfa3,DISK], DatanodeInfoWithStorage[127.0.0.1:40767,DS-93e9bee5-05df-47aa-a8fe-2e1301c02359,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.writes
component: hdfs:NameNode
v1: false
v2: null
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1494224143-172.17.0.20-1596944406085:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46671,DS-713650be-f79f-47fd-aefd-d3c9d1a16cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:38521,DS-7288d1f7-bc69-4a7e-8164-95ba77aa6fda,DISK], DatanodeInfoWithStorage[127.0.0.1:39761,DS-63eec1eb-706c-4de2-aec4-2f248d3d49e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42004,DS-40e6a0f3-5688-448f-9042-273228353c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:39748,DS-89b7dc9c-d125-42a3-8a3b-1fafe3045612,DISK], DatanodeInfoWithStorage[127.0.0.1:42359,DS-1a493aee-8fec-4ed0-aa95-c72a2c681a86,DISK], DatanodeInfoWithStorage[127.0.0.1:38913,DS-029c35da-eb29-4f71-8eda-8dc07966826a,DISK], DatanodeInfoWithStorage[127.0.0.1:40727,DS-29ad8b95-949d-4b17-bec7-2c82c00bd2f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1494224143-172.17.0.20-1596944406085:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46671,DS-713650be-f79f-47fd-aefd-d3c9d1a16cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:38521,DS-7288d1f7-bc69-4a7e-8164-95ba77aa6fda,DISK], DatanodeInfoWithStorage[127.0.0.1:39761,DS-63eec1eb-706c-4de2-aec4-2f248d3d49e2,DISK], DatanodeInfoWithStorage[127.0.0.1:42004,DS-40e6a0f3-5688-448f-9042-273228353c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:39748,DS-89b7dc9c-d125-42a3-8a3b-1fafe3045612,DISK], DatanodeInfoWithStorage[127.0.0.1:42359,DS-1a493aee-8fec-4ed0-aa95-c72a2c681a86,DISK], DatanodeInfoWithStorage[127.0.0.1:38913,DS-029c35da-eb29-4f71-8eda-8dc07966826a,DISK], DatanodeInfoWithStorage[127.0.0.1:40727,DS-29ad8b95-949d-4b17-bec7-2c82c00bd2f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.writes
component: hdfs:NameNode
v1: false
v2: null
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-826347898-172.17.0.20-1596944595365:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33525,DS-2bde63b4-4848-4291-adfe-e566bd559d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:33239,DS-113943fb-041a-4edc-affe-f70124fd56f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40515,DS-813e161d-def0-4264-846d-09a4c1c8384a,DISK], DatanodeInfoWithStorage[127.0.0.1:46451,DS-54bdc0cd-89da-4f83-8cb2-39124eff2816,DISK], DatanodeInfoWithStorage[127.0.0.1:41343,DS-84fe97fb-7a63-424c-80cb-090495deba8d,DISK], DatanodeInfoWithStorage[127.0.0.1:41936,DS-03a05acc-6b14-462f-a78d-c80fe5cc51c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43749,DS-7f486ed8-c954-4ae6-8024-88248ef85aea,DISK], DatanodeInfoWithStorage[127.0.0.1:44871,DS-295c954e-09e5-4e86-821f-88b76dead022,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-826347898-172.17.0.20-1596944595365:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33525,DS-2bde63b4-4848-4291-adfe-e566bd559d9e,DISK], DatanodeInfoWithStorage[127.0.0.1:33239,DS-113943fb-041a-4edc-affe-f70124fd56f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40515,DS-813e161d-def0-4264-846d-09a4c1c8384a,DISK], DatanodeInfoWithStorage[127.0.0.1:46451,DS-54bdc0cd-89da-4f83-8cb2-39124eff2816,DISK], DatanodeInfoWithStorage[127.0.0.1:41343,DS-84fe97fb-7a63-424c-80cb-090495deba8d,DISK], DatanodeInfoWithStorage[127.0.0.1:41936,DS-03a05acc-6b14-462f-a78d-c80fe5cc51c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43749,DS-7f486ed8-c954-4ae6-8024-88248ef85aea,DISK], DatanodeInfoWithStorage[127.0.0.1:44871,DS-295c954e-09e5-4e86-821f-88b76dead022,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.writes
component: hdfs:NameNode
v1: false
v2: null
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-749544815-172.17.0.20-1596944892796:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40723,DS-1f631fc3-9a1d-433d-b9e4-7dd7e6ea1267,DISK], DatanodeInfoWithStorage[127.0.0.1:37033,DS-6834fbfc-5002-49fd-a1b3-903763670209,DISK], DatanodeInfoWithStorage[127.0.0.1:42189,DS-c94f6be1-4504-45e9-b387-3685caa0f715,DISK], DatanodeInfoWithStorage[127.0.0.1:40361,DS-6bceb3e7-12b0-467d-98da-2fea40f2784f,DISK], DatanodeInfoWithStorage[127.0.0.1:44948,DS-a4525d42-1993-47ff-830f-b28adfedf700,DISK], DatanodeInfoWithStorage[127.0.0.1:42971,DS-4d359629-d607-4e8b-a8af-bbc08c679816,DISK], DatanodeInfoWithStorage[127.0.0.1:33134,DS-5dea3eb5-37c5-456e-b3cf-a93ec92faa12,DISK], DatanodeInfoWithStorage[127.0.0.1:42218,DS-83b769e7-bcd0-440d-9688-3bd8fd36148e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-749544815-172.17.0.20-1596944892796:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40723,DS-1f631fc3-9a1d-433d-b9e4-7dd7e6ea1267,DISK], DatanodeInfoWithStorage[127.0.0.1:37033,DS-6834fbfc-5002-49fd-a1b3-903763670209,DISK], DatanodeInfoWithStorage[127.0.0.1:42189,DS-c94f6be1-4504-45e9-b387-3685caa0f715,DISK], DatanodeInfoWithStorage[127.0.0.1:40361,DS-6bceb3e7-12b0-467d-98da-2fea40f2784f,DISK], DatanodeInfoWithStorage[127.0.0.1:44948,DS-a4525d42-1993-47ff-830f-b28adfedf700,DISK], DatanodeInfoWithStorage[127.0.0.1:42971,DS-4d359629-d607-4e8b-a8af-bbc08c679816,DISK], DatanodeInfoWithStorage[127.0.0.1:33134,DS-5dea3eb5-37c5-456e-b3cf-a93ec92faa12,DISK], DatanodeInfoWithStorage[127.0.0.1:42218,DS-83b769e7-bcd0-440d-9688-3bd8fd36148e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.writes
component: hdfs:NameNode
v1: false
v2: null
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1051093988-172.17.0.20-1596944951534:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38918,DS-490217ba-e4a2-4a6b-b13f-961701d15763,DISK], DatanodeInfoWithStorage[127.0.0.1:32794,DS-60fbd270-f630-4e8e-a077-5decdae420dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39452,DS-cd308016-35a0-473d-9333-16e7590c6e3e,DISK], DatanodeInfoWithStorage[127.0.0.1:35404,DS-77718c13-e230-46db-a9b8-df1b376c7324,DISK], DatanodeInfoWithStorage[127.0.0.1:41890,DS-498c1b29-6546-4b0d-a655-ef3dcf1a43d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44900,DS-fd624a48-6c47-472f-ae9d-ace93f66858f,DISK], DatanodeInfoWithStorage[127.0.0.1:37468,DS-7dde33db-ffdb-4b50-983f-b6afd8496ddf,DISK], DatanodeInfoWithStorage[127.0.0.1:46814,DS-f8d28e98-8ecd-4d1b-ab96-3716cb819ffe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1051093988-172.17.0.20-1596944951534:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38918,DS-490217ba-e4a2-4a6b-b13f-961701d15763,DISK], DatanodeInfoWithStorage[127.0.0.1:32794,DS-60fbd270-f630-4e8e-a077-5decdae420dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39452,DS-cd308016-35a0-473d-9333-16e7590c6e3e,DISK], DatanodeInfoWithStorage[127.0.0.1:35404,DS-77718c13-e230-46db-a9b8-df1b376c7324,DISK], DatanodeInfoWithStorage[127.0.0.1:41890,DS-498c1b29-6546-4b0d-a655-ef3dcf1a43d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44900,DS-fd624a48-6c47-472f-ae9d-ace93f66858f,DISK], DatanodeInfoWithStorage[127.0.0.1:37468,DS-7dde33db-ffdb-4b50-983f-b6afd8496ddf,DISK], DatanodeInfoWithStorage[127.0.0.1:46814,DS-f8d28e98-8ecd-4d1b-ab96-3716cb819ffe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.writes
component: hdfs:NameNode
v1: false
v2: null
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1685251124-172.17.0.20-1596944991265:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40570,DS-5bfd12c6-74fa-4a51-a815-bd9a5a619cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:33933,DS-762ac365-9b24-46f0-a097-376c8fe588e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44780,DS-faf55dba-db0c-4f0a-92ab-4fa908250f80,DISK], DatanodeInfoWithStorage[127.0.0.1:46692,DS-48b0d807-a2ba-46e9-a612-3b46e398add1,DISK], DatanodeInfoWithStorage[127.0.0.1:37113,DS-53591fe3-6831-400f-b403-83e304366143,DISK], DatanodeInfoWithStorage[127.0.0.1:35360,DS-93d31cad-aa97-4b6b-89fe-bb0854bb2e55,DISK], DatanodeInfoWithStorage[127.0.0.1:38760,DS-e8cce0bf-2aec-4a12-bc90-7096a1304d93,DISK], DatanodeInfoWithStorage[127.0.0.1:42727,DS-155d498e-8cea-48c3-a448-c9b89e97af4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1685251124-172.17.0.20-1596944991265:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40570,DS-5bfd12c6-74fa-4a51-a815-bd9a5a619cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:33933,DS-762ac365-9b24-46f0-a097-376c8fe588e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44780,DS-faf55dba-db0c-4f0a-92ab-4fa908250f80,DISK], DatanodeInfoWithStorage[127.0.0.1:46692,DS-48b0d807-a2ba-46e9-a612-3b46e398add1,DISK], DatanodeInfoWithStorage[127.0.0.1:37113,DS-53591fe3-6831-400f-b403-83e304366143,DISK], DatanodeInfoWithStorage[127.0.0.1:35360,DS-93d31cad-aa97-4b6b-89fe-bb0854bb2e55,DISK], DatanodeInfoWithStorage[127.0.0.1:38760,DS-e8cce0bf-2aec-4a12-bc90-7096a1304d93,DISK], DatanodeInfoWithStorage[127.0.0.1:42727,DS-155d498e-8cea-48c3-a448-c9b89e97af4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.writes
component: hdfs:NameNode
v1: false
v2: null
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1937118445-172.17.0.20-1596945955830:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36803,DS-265e060c-a81d-4e88-91a1-98b60da8db6e,DISK], DatanodeInfoWithStorage[127.0.0.1:39068,DS-0aa8c2d2-c568-4c68-a4cf-bcfe7a11a2be,DISK], DatanodeInfoWithStorage[127.0.0.1:38111,DS-1be2e7d2-e116-480c-a28f-932568da6521,DISK], DatanodeInfoWithStorage[127.0.0.1:38945,DS-2a47c99b-2bb7-4da5-8f0b-ba28dccc23ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42714,DS-4954cc81-b8fa-4970-8213-7184271b3618,DISK], DatanodeInfoWithStorage[127.0.0.1:35794,DS-d6b274fb-2015-4d6a-a656-a06ee14903d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40237,DS-123154ba-c49d-40c5-8a32-38c861fe9a04,DISK], DatanodeInfoWithStorage[127.0.0.1:33757,DS-24da5e52-3a6b-45bc-a1c6-da90b663ac26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1937118445-172.17.0.20-1596945955830:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36803,DS-265e060c-a81d-4e88-91a1-98b60da8db6e,DISK], DatanodeInfoWithStorage[127.0.0.1:39068,DS-0aa8c2d2-c568-4c68-a4cf-bcfe7a11a2be,DISK], DatanodeInfoWithStorage[127.0.0.1:38111,DS-1be2e7d2-e116-480c-a28f-932568da6521,DISK], DatanodeInfoWithStorage[127.0.0.1:38945,DS-2a47c99b-2bb7-4da5-8f0b-ba28dccc23ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42714,DS-4954cc81-b8fa-4970-8213-7184271b3618,DISK], DatanodeInfoWithStorage[127.0.0.1:35794,DS-d6b274fb-2015-4d6a-a656-a06ee14903d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40237,DS-123154ba-c49d-40c5-8a32-38c861fe9a04,DISK], DatanodeInfoWithStorage[127.0.0.1:33757,DS-24da5e52-3a6b-45bc-a1c6-da90b663ac26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.writes
component: hdfs:NameNode
v1: false
v2: null
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-460433519-172.17.0.20-1596946092359:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39752,DS-8b0a20ee-fe32-4f9c-82ab-b899c15b58c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40613,DS-27aa08bf-e003-42d8-890e-10e80d70a489,DISK], DatanodeInfoWithStorage[127.0.0.1:41317,DS-fb9d42c2-1d71-40eb-a847-cebe001b7cf9,DISK], DatanodeInfoWithStorage[127.0.0.1:40338,DS-b7066a0c-6c24-4b68-967f-e56ce26c4823,DISK], DatanodeInfoWithStorage[127.0.0.1:41883,DS-fe21bb66-53f2-4be3-adbd-db231a69b02b,DISK], DatanodeInfoWithStorage[127.0.0.1:34192,DS-ed6a8018-1a25-49df-8d9e-e1e7b51bb969,DISK], DatanodeInfoWithStorage[127.0.0.1:36490,DS-1040ee1d-76f1-47f2-9280-9dbccc805b79,DISK], DatanodeInfoWithStorage[127.0.0.1:39864,DS-8c51e750-3a64-4a53-8b79-aecb7c8d0776,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-460433519-172.17.0.20-1596946092359:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39752,DS-8b0a20ee-fe32-4f9c-82ab-b899c15b58c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40613,DS-27aa08bf-e003-42d8-890e-10e80d70a489,DISK], DatanodeInfoWithStorage[127.0.0.1:41317,DS-fb9d42c2-1d71-40eb-a847-cebe001b7cf9,DISK], DatanodeInfoWithStorage[127.0.0.1:40338,DS-b7066a0c-6c24-4b68-967f-e56ce26c4823,DISK], DatanodeInfoWithStorage[127.0.0.1:41883,DS-fe21bb66-53f2-4be3-adbd-db231a69b02b,DISK], DatanodeInfoWithStorage[127.0.0.1:34192,DS-ed6a8018-1a25-49df-8d9e-e1e7b51bb969,DISK], DatanodeInfoWithStorage[127.0.0.1:36490,DS-1040ee1d-76f1-47f2-9280-9dbccc805b79,DISK], DatanodeInfoWithStorage[127.0.0.1:39864,DS-8c51e750-3a64-4a53-8b79-aecb7c8d0776,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.writes
component: hdfs:NameNode
v1: false
v2: null
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1830140207-172.17.0.20-1596946495972:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39991,DS-bc047b31-d00f-45c6-9801-27f0920e238f,DISK], DatanodeInfoWithStorage[127.0.0.1:38449,DS-35acefbb-9912-4e47-a3a3-be32c4e92210,DISK], DatanodeInfoWithStorage[127.0.0.1:44125,DS-5d50b43d-1568-44fe-aa1e-332a5211aaa5,DISK], DatanodeInfoWithStorage[127.0.0.1:43159,DS-4a8a18da-81f0-4be4-a752-ec8b7fd54243,DISK], DatanodeInfoWithStorage[127.0.0.1:45944,DS-eb79d193-a3e8-4c27-8fef-7e3803348eff,DISK], DatanodeInfoWithStorage[127.0.0.1:38882,DS-42e0b255-9b2e-4e08-adff-b2b39614fd0b,DISK], DatanodeInfoWithStorage[127.0.0.1:37491,DS-2ff216fc-980e-4d29-a7f2-6bde83eddf8e,DISK], DatanodeInfoWithStorage[127.0.0.1:35462,DS-a1b5ca2e-713c-47cb-aec8-dd5bbe50e48b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1830140207-172.17.0.20-1596946495972:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39991,DS-bc047b31-d00f-45c6-9801-27f0920e238f,DISK], DatanodeInfoWithStorage[127.0.0.1:38449,DS-35acefbb-9912-4e47-a3a3-be32c4e92210,DISK], DatanodeInfoWithStorage[127.0.0.1:44125,DS-5d50b43d-1568-44fe-aa1e-332a5211aaa5,DISK], DatanodeInfoWithStorage[127.0.0.1:43159,DS-4a8a18da-81f0-4be4-a752-ec8b7fd54243,DISK], DatanodeInfoWithStorage[127.0.0.1:45944,DS-eb79d193-a3e8-4c27-8fef-7e3803348eff,DISK], DatanodeInfoWithStorage[127.0.0.1:38882,DS-42e0b255-9b2e-4e08-adff-b2b39614fd0b,DISK], DatanodeInfoWithStorage[127.0.0.1:37491,DS-2ff216fc-980e-4d29-a7f2-6bde83eddf8e,DISK], DatanodeInfoWithStorage[127.0.0.1:35462,DS-a1b5ca2e-713c-47cb-aec8-dd5bbe50e48b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.writes
component: hdfs:NameNode
v1: false
v2: null
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1068819719-172.17.0.20-1596946629473:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33410,DS-35d0d2df-1270-475a-94c0-387957f17d6e,DISK], DatanodeInfoWithStorage[127.0.0.1:40008,DS-b3fd8ec1-9509-483f-aea0-018829c6ae28,DISK], DatanodeInfoWithStorage[127.0.0.1:38682,DS-6a3c5e40-298d-43f5-9799-3e076ef8b829,DISK], DatanodeInfoWithStorage[127.0.0.1:45208,DS-220ab0cb-7f6d-4f52-ac13-e7ef4889afff,DISK], DatanodeInfoWithStorage[127.0.0.1:39123,DS-5e77b458-e0ea-4dd3-a4c2-a34d6c4b5225,DISK], DatanodeInfoWithStorage[127.0.0.1:41664,DS-67584a57-b31a-442a-99d5-45ff81e735b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38357,DS-478cd47d-d811-4859-b74a-91571a90e233,DISK], DatanodeInfoWithStorage[127.0.0.1:43227,DS-6e078392-daa6-4f99-8758-f4eb456b389e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1068819719-172.17.0.20-1596946629473:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33410,DS-35d0d2df-1270-475a-94c0-387957f17d6e,DISK], DatanodeInfoWithStorage[127.0.0.1:40008,DS-b3fd8ec1-9509-483f-aea0-018829c6ae28,DISK], DatanodeInfoWithStorage[127.0.0.1:38682,DS-6a3c5e40-298d-43f5-9799-3e076ef8b829,DISK], DatanodeInfoWithStorage[127.0.0.1:45208,DS-220ab0cb-7f6d-4f52-ac13-e7ef4889afff,DISK], DatanodeInfoWithStorage[127.0.0.1:39123,DS-5e77b458-e0ea-4dd3-a4c2-a34d6c4b5225,DISK], DatanodeInfoWithStorage[127.0.0.1:41664,DS-67584a57-b31a-442a-99d5-45ff81e735b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38357,DS-478cd47d-d811-4859-b74a-91571a90e233,DISK], DatanodeInfoWithStorage[127.0.0.1:43227,DS-6e078392-daa6-4f99-8758-f4eb456b389e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.writes
component: hdfs:NameNode
v1: false
v2: null
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-205314890-172.17.0.20-1596946969422:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43641,DS-141b974e-9fd1-4a9a-a8f8-10dd4b225759,DISK], DatanodeInfoWithStorage[127.0.0.1:44305,DS-a032275a-b106-40cf-a26f-b803198ffe5b,DISK], DatanodeInfoWithStorage[127.0.0.1:46736,DS-cb414e17-6578-4708-beeb-7f5a0c7779ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40088,DS-20c29f27-3a17-4a1a-aed6-65ec13b5dfd7,DISK], DatanodeInfoWithStorage[127.0.0.1:33106,DS-60450871-1a40-4d7f-b279-b3555f68cf80,DISK], DatanodeInfoWithStorage[127.0.0.1:37908,DS-025e5f01-808e-498f-992b-6aff99730fdc,DISK], DatanodeInfoWithStorage[127.0.0.1:45834,DS-d20574af-3f82-48f0-9184-5997d42bb043,DISK], DatanodeInfoWithStorage[127.0.0.1:35205,DS-e33d285d-e410-45b2-a244-91297596a7b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-205314890-172.17.0.20-1596946969422:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43641,DS-141b974e-9fd1-4a9a-a8f8-10dd4b225759,DISK], DatanodeInfoWithStorage[127.0.0.1:44305,DS-a032275a-b106-40cf-a26f-b803198ffe5b,DISK], DatanodeInfoWithStorage[127.0.0.1:46736,DS-cb414e17-6578-4708-beeb-7f5a0c7779ae,DISK], DatanodeInfoWithStorage[127.0.0.1:40088,DS-20c29f27-3a17-4a1a-aed6-65ec13b5dfd7,DISK], DatanodeInfoWithStorage[127.0.0.1:33106,DS-60450871-1a40-4d7f-b279-b3555f68cf80,DISK], DatanodeInfoWithStorage[127.0.0.1:37908,DS-025e5f01-808e-498f-992b-6aff99730fdc,DISK], DatanodeInfoWithStorage[127.0.0.1:45834,DS-d20574af-3f82-48f0-9184-5997d42bb043,DISK], DatanodeInfoWithStorage[127.0.0.1:35205,DS-e33d285d-e410-45b2-a244-91297596a7b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.writes
component: hdfs:NameNode
v1: false
v2: null
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1559468043-172.17.0.20-1596947160132:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40445,DS-c1653f70-ab61-4ab4-b72e-10fb4aed29a1,DISK], DatanodeInfoWithStorage[127.0.0.1:46283,DS-9f8c5938-132f-48be-8a36-040383f781d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44837,DS-79a009e1-df53-4272-a167-33cd99d2879e,DISK], DatanodeInfoWithStorage[127.0.0.1:37372,DS-4f0fce3c-90c1-4cfb-9ac2-7f7058fadf90,DISK], DatanodeInfoWithStorage[127.0.0.1:36579,DS-5238e376-599b-42dc-a230-6c09f025dadb,DISK], DatanodeInfoWithStorage[127.0.0.1:41708,DS-9e4b6099-beb6-40b2-ba32-622c7ddadfb5,DISK], DatanodeInfoWithStorage[127.0.0.1:42705,DS-edf014ca-e28a-4142-868c-d606926c5478,DISK], DatanodeInfoWithStorage[127.0.0.1:34863,DS-48b0634b-4a12-4677-abe6-6488dae2e62e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1559468043-172.17.0.20-1596947160132:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40445,DS-c1653f70-ab61-4ab4-b72e-10fb4aed29a1,DISK], DatanodeInfoWithStorage[127.0.0.1:46283,DS-9f8c5938-132f-48be-8a36-040383f781d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44837,DS-79a009e1-df53-4272-a167-33cd99d2879e,DISK], DatanodeInfoWithStorage[127.0.0.1:37372,DS-4f0fce3c-90c1-4cfb-9ac2-7f7058fadf90,DISK], DatanodeInfoWithStorage[127.0.0.1:36579,DS-5238e376-599b-42dc-a230-6c09f025dadb,DISK], DatanodeInfoWithStorage[127.0.0.1:41708,DS-9e4b6099-beb6-40b2-ba32-622c7ddadfb5,DISK], DatanodeInfoWithStorage[127.0.0.1:42705,DS-edf014ca-e28a-4142-868c-d606926c5478,DISK], DatanodeInfoWithStorage[127.0.0.1:34863,DS-48b0634b-4a12-4677-abe6-6488dae2e62e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.cache.drop.behind.writes
component: hdfs:NameNode
v1: false
v2: null
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1234560578-172.17.0.20-1596947206619:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45543,DS-0d6cf455-246a-43c6-a15b-0946b5d83837,DISK], DatanodeInfoWithStorage[127.0.0.1:45358,DS-88149293-a363-4e16-96a4-10d464694365,DISK], DatanodeInfoWithStorage[127.0.0.1:44429,DS-36d55ca6-beea-4e5e-af19-2b200d426ad4,DISK], DatanodeInfoWithStorage[127.0.0.1:35472,DS-aab3902c-c10a-4ce8-bdf4-88502ff234d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39967,DS-117ab920-f60d-49fa-81f6-01cd148327bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33902,DS-d7cc1783-dfab-4e78-9e12-5844abfb5bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:36672,DS-000c02ff-eb6f-49b4-b675-75566ef939a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36412,DS-a03aa212-32b3-41e2-9bea-cea640e3d23c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1234560578-172.17.0.20-1596947206619:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45543,DS-0d6cf455-246a-43c6-a15b-0946b5d83837,DISK], DatanodeInfoWithStorage[127.0.0.1:45358,DS-88149293-a363-4e16-96a4-10d464694365,DISK], DatanodeInfoWithStorage[127.0.0.1:44429,DS-36d55ca6-beea-4e5e-af19-2b200d426ad4,DISK], DatanodeInfoWithStorage[127.0.0.1:35472,DS-aab3902c-c10a-4ce8-bdf4-88502ff234d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39967,DS-117ab920-f60d-49fa-81f6-01cd148327bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33902,DS-d7cc1783-dfab-4e78-9e12-5844abfb5bb9,DISK], DatanodeInfoWithStorage[127.0.0.1:36672,DS-000c02ff-eb6f-49b4-b675-75566ef939a2,DISK], DatanodeInfoWithStorage[127.0.0.1:36412,DS-a03aa212-32b3-41e2-9bea-cea640e3d23c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.writes
component: hdfs:NameNode
v1: false
v2: null
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2060619127-172.17.0.20-1596947611615:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40512,DS-d9349e2c-37b3-47c7-8af3-0bf1f167d1e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34384,DS-4775f9a6-d234-4c0f-815c-431275875e82,DISK], DatanodeInfoWithStorage[127.0.0.1:38592,DS-c6692872-5bea-4ebc-933d-08bef0bca38c,DISK], DatanodeInfoWithStorage[127.0.0.1:33824,DS-96bc83b1-eaaf-4839-8d09-ae7740dc6333,DISK], DatanodeInfoWithStorage[127.0.0.1:40821,DS-ba21775b-86ce-4151-979b-2baecc40d688,DISK], DatanodeInfoWithStorage[127.0.0.1:35477,DS-ba5b578d-32d3-4841-8d48-e7c589067304,DISK], DatanodeInfoWithStorage[127.0.0.1:40738,DS-6e816d26-f6e4-4c28-ba0e-3f2eb74f5629,DISK], DatanodeInfoWithStorage[127.0.0.1:36656,DS-ccefe4ba-3b5f-44c7-b1c9-54787c7311df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2060619127-172.17.0.20-1596947611615:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40512,DS-d9349e2c-37b3-47c7-8af3-0bf1f167d1e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34384,DS-4775f9a6-d234-4c0f-815c-431275875e82,DISK], DatanodeInfoWithStorage[127.0.0.1:38592,DS-c6692872-5bea-4ebc-933d-08bef0bca38c,DISK], DatanodeInfoWithStorage[127.0.0.1:33824,DS-96bc83b1-eaaf-4839-8d09-ae7740dc6333,DISK], DatanodeInfoWithStorage[127.0.0.1:40821,DS-ba21775b-86ce-4151-979b-2baecc40d688,DISK], DatanodeInfoWithStorage[127.0.0.1:35477,DS-ba5b578d-32d3-4841-8d48-e7c589067304,DISK], DatanodeInfoWithStorage[127.0.0.1:40738,DS-6e816d26-f6e4-4c28-ba0e-3f2eb74f5629,DISK], DatanodeInfoWithStorage[127.0.0.1:36656,DS-ccefe4ba-3b5f-44c7-b1c9-54787c7311df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.writes
component: hdfs:NameNode
v1: false
v2: null
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-213409189-172.17.0.20-1596947931130:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36884,DS-c52e6218-624a-49db-b518-e6c0c83d6f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:42514,DS-db6df43e-cd45-4f15-a22d-de2d0864e66d,DISK], DatanodeInfoWithStorage[127.0.0.1:46369,DS-943571e1-1622-48cb-a824-a3be2fd0059d,DISK], DatanodeInfoWithStorage[127.0.0.1:35945,DS-bb8b6590-262b-4b32-8930-ffd96cea73de,DISK], DatanodeInfoWithStorage[127.0.0.1:39252,DS-030520e9-d2fb-4a1f-ac66-c2c099cc52f7,DISK], DatanodeInfoWithStorage[127.0.0.1:32805,DS-edbb9d9d-7da8-4b4c-ab11-3a2db68863d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34317,DS-77e3b989-9c91-4472-b3eb-77a4dcccc8dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44689,DS-753d0615-25da-41bc-b308-fd0a0c25a8cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-213409189-172.17.0.20-1596947931130:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36884,DS-c52e6218-624a-49db-b518-e6c0c83d6f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:42514,DS-db6df43e-cd45-4f15-a22d-de2d0864e66d,DISK], DatanodeInfoWithStorage[127.0.0.1:46369,DS-943571e1-1622-48cb-a824-a3be2fd0059d,DISK], DatanodeInfoWithStorage[127.0.0.1:35945,DS-bb8b6590-262b-4b32-8930-ffd96cea73de,DISK], DatanodeInfoWithStorage[127.0.0.1:39252,DS-030520e9-d2fb-4a1f-ac66-c2c099cc52f7,DISK], DatanodeInfoWithStorage[127.0.0.1:32805,DS-edbb9d9d-7da8-4b4c-ab11-3a2db68863d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34317,DS-77e3b989-9c91-4472-b3eb-77a4dcccc8dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44689,DS-753d0615-25da-41bc-b308-fd0a0c25a8cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.writes
component: hdfs:NameNode
v1: false
v2: null
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1283704175-172.17.0.20-1596948199092:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44026,DS-e2560d03-5531-4486-a2bc-0f147f7f0341,DISK], DatanodeInfoWithStorage[127.0.0.1:35997,DS-7d032549-f45a-4fb1-88d4-2be8f0f34f5e,DISK], DatanodeInfoWithStorage[127.0.0.1:39550,DS-19b18f85-fdc8-4766-9e1c-3efce84f9da1,DISK], DatanodeInfoWithStorage[127.0.0.1:32946,DS-c4457067-a284-4bcc-baf8-893fc50cb8c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45001,DS-1569da2f-963f-4850-9bae-beed213845b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35094,DS-4fbfcdee-e0a0-413b-8376-b3df0c1b9036,DISK], DatanodeInfoWithStorage[127.0.0.1:44793,DS-95278fe3-0ad7-4324-9c08-aa6e00901491,DISK], DatanodeInfoWithStorage[127.0.0.1:36152,DS-b57dd0ce-9669-437e-ba0e-eea0e00552a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1283704175-172.17.0.20-1596948199092:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44026,DS-e2560d03-5531-4486-a2bc-0f147f7f0341,DISK], DatanodeInfoWithStorage[127.0.0.1:35997,DS-7d032549-f45a-4fb1-88d4-2be8f0f34f5e,DISK], DatanodeInfoWithStorage[127.0.0.1:39550,DS-19b18f85-fdc8-4766-9e1c-3efce84f9da1,DISK], DatanodeInfoWithStorage[127.0.0.1:32946,DS-c4457067-a284-4bcc-baf8-893fc50cb8c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45001,DS-1569da2f-963f-4850-9bae-beed213845b1,DISK], DatanodeInfoWithStorage[127.0.0.1:35094,DS-4fbfcdee-e0a0-413b-8376-b3df0c1b9036,DISK], DatanodeInfoWithStorage[127.0.0.1:44793,DS-95278fe3-0ad7-4324-9c08-aa6e00901491,DISK], DatanodeInfoWithStorage[127.0.0.1:36152,DS-b57dd0ce-9669-437e-ba0e-eea0e00552a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.writes
component: hdfs:NameNode
v1: false
v2: null
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-287251888-172.17.0.20-1596948303074:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42989,DS-40f5585b-599c-4f43-a224-5056e13a8161,DISK], DatanodeInfoWithStorage[127.0.0.1:43571,DS-315a8af7-aad7-432c-9dfe-ba5c9c40473b,DISK], DatanodeInfoWithStorage[127.0.0.1:40443,DS-91840ade-1d26-4caf-9713-1870fc591204,DISK], DatanodeInfoWithStorage[127.0.0.1:44075,DS-e7014fbc-f938-4f3d-9c13-71973b168edb,DISK], DatanodeInfoWithStorage[127.0.0.1:35421,DS-f2021780-04e0-47e0-bfc3-9f7a8adc5f1f,DISK], DatanodeInfoWithStorage[127.0.0.1:45051,DS-a2f3f274-09ca-46d1-beb7-0cb11f9c0442,DISK], DatanodeInfoWithStorage[127.0.0.1:43024,DS-2e6aaa26-c9c3-48ac-926a-b3a9dcaaa307,DISK], DatanodeInfoWithStorage[127.0.0.1:36342,DS-e889dc2c-b51d-4920-a050-d9801ec0c2d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-287251888-172.17.0.20-1596948303074:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42989,DS-40f5585b-599c-4f43-a224-5056e13a8161,DISK], DatanodeInfoWithStorage[127.0.0.1:43571,DS-315a8af7-aad7-432c-9dfe-ba5c9c40473b,DISK], DatanodeInfoWithStorage[127.0.0.1:40443,DS-91840ade-1d26-4caf-9713-1870fc591204,DISK], DatanodeInfoWithStorage[127.0.0.1:44075,DS-e7014fbc-f938-4f3d-9c13-71973b168edb,DISK], DatanodeInfoWithStorage[127.0.0.1:35421,DS-f2021780-04e0-47e0-bfc3-9f7a8adc5f1f,DISK], DatanodeInfoWithStorage[127.0.0.1:45051,DS-a2f3f274-09ca-46d1-beb7-0cb11f9c0442,DISK], DatanodeInfoWithStorage[127.0.0.1:43024,DS-2e6aaa26-c9c3-48ac-926a-b3a9dcaaa307,DISK], DatanodeInfoWithStorage[127.0.0.1:36342,DS-e889dc2c-b51d-4920-a050-d9801ec0c2d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 7210
