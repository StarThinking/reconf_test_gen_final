reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-360945300-172.17.0.4-1595306676488:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38598,DS-40787839-d79d-4d3a-875f-4e6817b89c1a,DISK], DatanodeInfoWithStorage[127.0.0.1:37694,DS-ffba3419-c967-4a84-ad84-090db48b66d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33301,DS-d44bd726-b610-43d5-9be2-f8896d319604,DISK], DatanodeInfoWithStorage[127.0.0.1:43731,DS-3fd8acf1-377c-4448-82b4-7a970c3affc7,DISK], DatanodeInfoWithStorage[127.0.0.1:35388,DS-fa2d093d-46f0-4737-8cd0-3ae7fe47c04d,DISK], DatanodeInfoWithStorage[127.0.0.1:33428,DS-50a03f5a-4529-4419-8339-181720de0f4a,DISK], DatanodeInfoWithStorage[127.0.0.1:43472,DS-c1711def-d712-48d9-b80f-cc1de6471986,DISK], DatanodeInfoWithStorage[127.0.0.1:40410,DS-0bb41834-c6cb-43fc-9851-fc6650972e5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-360945300-172.17.0.4-1595306676488:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38598,DS-40787839-d79d-4d3a-875f-4e6817b89c1a,DISK], DatanodeInfoWithStorage[127.0.0.1:37694,DS-ffba3419-c967-4a84-ad84-090db48b66d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33301,DS-d44bd726-b610-43d5-9be2-f8896d319604,DISK], DatanodeInfoWithStorage[127.0.0.1:43731,DS-3fd8acf1-377c-4448-82b4-7a970c3affc7,DISK], DatanodeInfoWithStorage[127.0.0.1:35388,DS-fa2d093d-46f0-4737-8cd0-3ae7fe47c04d,DISK], DatanodeInfoWithStorage[127.0.0.1:33428,DS-50a03f5a-4529-4419-8339-181720de0f4a,DISK], DatanodeInfoWithStorage[127.0.0.1:43472,DS-c1711def-d712-48d9-b80f-cc1de6471986,DISK], DatanodeInfoWithStorage[127.0.0.1:40410,DS-0bb41834-c6cb-43fc-9851-fc6650972e5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1277931948-172.17.0.4-1595306936397:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38837,DS-d34e42ea-c410-47e5-9027-50e2e0cb9cfb,DISK], DatanodeInfoWithStorage[127.0.0.1:38480,DS-2463c469-1658-47c6-a8f2-78a29399a00c,DISK], DatanodeInfoWithStorage[127.0.0.1:39479,DS-577c0514-dd83-4035-97a6-b058b98c1d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:37398,DS-39d26277-a303-44c1-9c4c-29ace8a6ab80,DISK], DatanodeInfoWithStorage[127.0.0.1:34292,DS-eadaa4fe-8c14-4dc4-b64c-86d9d51afd90,DISK], DatanodeInfoWithStorage[127.0.0.1:36352,DS-d8b12c19-3c1d-4140-8cc1-01d65024a6f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35327,DS-000964e9-8516-415f-9f3d-d6bbac6cbe4a,DISK], DatanodeInfoWithStorage[127.0.0.1:35254,DS-12aeb219-7d6c-4388-96ec-7b405b3e54e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1277931948-172.17.0.4-1595306936397:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38837,DS-d34e42ea-c410-47e5-9027-50e2e0cb9cfb,DISK], DatanodeInfoWithStorage[127.0.0.1:38480,DS-2463c469-1658-47c6-a8f2-78a29399a00c,DISK], DatanodeInfoWithStorage[127.0.0.1:39479,DS-577c0514-dd83-4035-97a6-b058b98c1d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:37398,DS-39d26277-a303-44c1-9c4c-29ace8a6ab80,DISK], DatanodeInfoWithStorage[127.0.0.1:34292,DS-eadaa4fe-8c14-4dc4-b64c-86d9d51afd90,DISK], DatanodeInfoWithStorage[127.0.0.1:36352,DS-d8b12c19-3c1d-4140-8cc1-01d65024a6f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35327,DS-000964e9-8516-415f-9f3d-d6bbac6cbe4a,DISK], DatanodeInfoWithStorage[127.0.0.1:35254,DS-12aeb219-7d6c-4388-96ec-7b405b3e54e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1973472441-172.17.0.4-1595307009395:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46758,DS-9bd8bdf9-5171-4a4d-85df-7e727f31ec97,DISK], DatanodeInfoWithStorage[127.0.0.1:32851,DS-7171cb1a-0668-44a7-8473-48e644cb1446,DISK], DatanodeInfoWithStorage[127.0.0.1:42046,DS-0b76aa57-503f-47c4-95f8-eb0b97460a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:41373,DS-91cc5d5c-b973-4f5d-8710-1ad8e4c9ccbe,DISK], DatanodeInfoWithStorage[127.0.0.1:34709,DS-4fed7e2b-733f-4193-897c-c24ddb1a8afb,DISK], DatanodeInfoWithStorage[127.0.0.1:34628,DS-4d933cab-0f95-4742-b309-a66f921d9576,DISK], DatanodeInfoWithStorage[127.0.0.1:46162,DS-0a4b788c-e9d5-446c-9a23-fce8534a6b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:46442,DS-7775bc96-c79f-4d74-bbdc-9f180dccc152,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1973472441-172.17.0.4-1595307009395:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46758,DS-9bd8bdf9-5171-4a4d-85df-7e727f31ec97,DISK], DatanodeInfoWithStorage[127.0.0.1:32851,DS-7171cb1a-0668-44a7-8473-48e644cb1446,DISK], DatanodeInfoWithStorage[127.0.0.1:42046,DS-0b76aa57-503f-47c4-95f8-eb0b97460a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:41373,DS-91cc5d5c-b973-4f5d-8710-1ad8e4c9ccbe,DISK], DatanodeInfoWithStorage[127.0.0.1:34709,DS-4fed7e2b-733f-4193-897c-c24ddb1a8afb,DISK], DatanodeInfoWithStorage[127.0.0.1:34628,DS-4d933cab-0f95-4742-b309-a66f921d9576,DISK], DatanodeInfoWithStorage[127.0.0.1:46162,DS-0a4b788c-e9d5-446c-9a23-fce8534a6b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:46442,DS-7775bc96-c79f-4d74-bbdc-9f180dccc152,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1461996817-172.17.0.4-1595307094857:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39988,DS-f9fd27db-ca19-4d40-8d89-9ebcc762c473,DISK], DatanodeInfoWithStorage[127.0.0.1:44022,DS-61b0f92b-3051-4e83-9910-775714fec1cd,DISK], DatanodeInfoWithStorage[127.0.0.1:35955,DS-7cbb9435-883c-4e9f-b271-830d06fd4776,DISK], DatanodeInfoWithStorage[127.0.0.1:33130,DS-8855b8f9-54ed-4acf-9a7f-73a5a606f954,DISK], DatanodeInfoWithStorage[127.0.0.1:43624,DS-9c40713c-9b35-48e3-931c-46c8767c4452,DISK], DatanodeInfoWithStorage[127.0.0.1:32849,DS-a0c818e2-7370-4344-bbee-0f7b5e1c7833,DISK], DatanodeInfoWithStorage[127.0.0.1:37279,DS-8b777e2c-a1a3-4010-bc65-516ff6e38833,DISK], DatanodeInfoWithStorage[127.0.0.1:43381,DS-1f7a6308-a316-449c-987a-5dcb54f23621,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1461996817-172.17.0.4-1595307094857:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39988,DS-f9fd27db-ca19-4d40-8d89-9ebcc762c473,DISK], DatanodeInfoWithStorage[127.0.0.1:44022,DS-61b0f92b-3051-4e83-9910-775714fec1cd,DISK], DatanodeInfoWithStorage[127.0.0.1:35955,DS-7cbb9435-883c-4e9f-b271-830d06fd4776,DISK], DatanodeInfoWithStorage[127.0.0.1:33130,DS-8855b8f9-54ed-4acf-9a7f-73a5a606f954,DISK], DatanodeInfoWithStorage[127.0.0.1:43624,DS-9c40713c-9b35-48e3-931c-46c8767c4452,DISK], DatanodeInfoWithStorage[127.0.0.1:32849,DS-a0c818e2-7370-4344-bbee-0f7b5e1c7833,DISK], DatanodeInfoWithStorage[127.0.0.1:37279,DS-8b777e2c-a1a3-4010-bc65-516ff6e38833,DISK], DatanodeInfoWithStorage[127.0.0.1:43381,DS-1f7a6308-a316-449c-987a-5dcb54f23621,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1820406226-172.17.0.4-1595308190563:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40411,DS-56041e1b-cd1b-4d7e-b13b-12dd47c93c67,DISK], DatanodeInfoWithStorage[127.0.0.1:33069,DS-b919413c-381a-45ff-a0d5-e2dc970b5b2d,DISK], DatanodeInfoWithStorage[127.0.0.1:45118,DS-46425dd0-6245-4e31-bee8-d277d833288e,DISK], DatanodeInfoWithStorage[127.0.0.1:38089,DS-38a0c8e7-7825-4f02-a422-f691278b17db,DISK], DatanodeInfoWithStorage[127.0.0.1:37851,DS-36d97bc9-e7de-429b-9290-547e6824d9e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33706,DS-250db2d0-2cf2-4286-885a-5a6a68e55a99,DISK], DatanodeInfoWithStorage[127.0.0.1:38208,DS-05c7994d-03cc-42dc-af38-675f72c1ecdc,DISK], DatanodeInfoWithStorage[127.0.0.1:42703,DS-d03f6366-401f-4e50-ab49-a2785e3f7514,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1820406226-172.17.0.4-1595308190563:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40411,DS-56041e1b-cd1b-4d7e-b13b-12dd47c93c67,DISK], DatanodeInfoWithStorage[127.0.0.1:33069,DS-b919413c-381a-45ff-a0d5-e2dc970b5b2d,DISK], DatanodeInfoWithStorage[127.0.0.1:45118,DS-46425dd0-6245-4e31-bee8-d277d833288e,DISK], DatanodeInfoWithStorage[127.0.0.1:38089,DS-38a0c8e7-7825-4f02-a422-f691278b17db,DISK], DatanodeInfoWithStorage[127.0.0.1:37851,DS-36d97bc9-e7de-429b-9290-547e6824d9e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33706,DS-250db2d0-2cf2-4286-885a-5a6a68e55a99,DISK], DatanodeInfoWithStorage[127.0.0.1:38208,DS-05c7994d-03cc-42dc-af38-675f72c1ecdc,DISK], DatanodeInfoWithStorage[127.0.0.1:42703,DS-d03f6366-401f-4e50-ab49-a2785e3f7514,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-734674871-172.17.0.4-1595308257798:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34767,DS-12921c06-b1a7-4379-9636-8b02741b8317,DISK], DatanodeInfoWithStorage[127.0.0.1:38022,DS-bfd75139-282e-4fab-a9c5-d054510d5ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:39931,DS-88fab361-9606-46ad-bd66-540a311bc075,DISK], DatanodeInfoWithStorage[127.0.0.1:39615,DS-6fa804be-5582-402e-8a2f-2ad7be222671,DISK], DatanodeInfoWithStorage[127.0.0.1:33184,DS-29f1a0b1-beb5-44f0-861c-0194d6882ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:37581,DS-312e1347-454a-46b2-aebb-d155235685da,DISK], DatanodeInfoWithStorage[127.0.0.1:43090,DS-81d50039-a71a-4043-a705-462d5e6d7c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:41523,DS-bc105d7c-6ca9-454a-bd3c-b72c3da8c268,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-734674871-172.17.0.4-1595308257798:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34767,DS-12921c06-b1a7-4379-9636-8b02741b8317,DISK], DatanodeInfoWithStorage[127.0.0.1:38022,DS-bfd75139-282e-4fab-a9c5-d054510d5ae0,DISK], DatanodeInfoWithStorage[127.0.0.1:39931,DS-88fab361-9606-46ad-bd66-540a311bc075,DISK], DatanodeInfoWithStorage[127.0.0.1:39615,DS-6fa804be-5582-402e-8a2f-2ad7be222671,DISK], DatanodeInfoWithStorage[127.0.0.1:33184,DS-29f1a0b1-beb5-44f0-861c-0194d6882ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:37581,DS-312e1347-454a-46b2-aebb-d155235685da,DISK], DatanodeInfoWithStorage[127.0.0.1:43090,DS-81d50039-a71a-4043-a705-462d5e6d7c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:41523,DS-bc105d7c-6ca9-454a-bd3c-b72c3da8c268,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1056744563-172.17.0.4-1595308473672:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40314,DS-ec2cf04f-409c-4ff3-8cdd-ef5a6b73b057,DISK], DatanodeInfoWithStorage[127.0.0.1:33556,DS-fd62972a-2015-4185-8fc4-170b4d42325b,DISK], DatanodeInfoWithStorage[127.0.0.1:39754,DS-68e6e22d-e4bc-4e5c-addc-63e35001e034,DISK], DatanodeInfoWithStorage[127.0.0.1:37124,DS-109a977f-44b6-4ab4-bebd-3ae00ee08778,DISK], DatanodeInfoWithStorage[127.0.0.1:42751,DS-f4143aef-c557-4835-957f-bd80fe14f887,DISK], DatanodeInfoWithStorage[127.0.0.1:38607,DS-767cc65e-732f-49da-a8b1-7bd496c525be,DISK], DatanodeInfoWithStorage[127.0.0.1:39245,DS-7538e18f-d038-4a29-b1f4-ff1155725bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:43150,DS-94936e31-487f-40ae-833c-946db4ac8622,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1056744563-172.17.0.4-1595308473672:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40314,DS-ec2cf04f-409c-4ff3-8cdd-ef5a6b73b057,DISK], DatanodeInfoWithStorage[127.0.0.1:33556,DS-fd62972a-2015-4185-8fc4-170b4d42325b,DISK], DatanodeInfoWithStorage[127.0.0.1:39754,DS-68e6e22d-e4bc-4e5c-addc-63e35001e034,DISK], DatanodeInfoWithStorage[127.0.0.1:37124,DS-109a977f-44b6-4ab4-bebd-3ae00ee08778,DISK], DatanodeInfoWithStorage[127.0.0.1:42751,DS-f4143aef-c557-4835-957f-bd80fe14f887,DISK], DatanodeInfoWithStorage[127.0.0.1:38607,DS-767cc65e-732f-49da-a8b1-7bd496c525be,DISK], DatanodeInfoWithStorage[127.0.0.1:39245,DS-7538e18f-d038-4a29-b1f4-ff1155725bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:43150,DS-94936e31-487f-40ae-833c-946db4ac8622,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1905154178-172.17.0.4-1595308964169:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39523,DS-edacf1d7-fd2b-4c03-bef2-48a298a5975d,DISK], DatanodeInfoWithStorage[127.0.0.1:42191,DS-b2e175bc-e0aa-4626-91cd-0f06f288eaa4,DISK], DatanodeInfoWithStorage[127.0.0.1:35886,DS-f57d669e-78e0-4229-bfdc-d652d8c64ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:39461,DS-256cb1ee-e106-49ba-995f-a22f9e0ea07d,DISK], DatanodeInfoWithStorage[127.0.0.1:33015,DS-b7814bcd-ac8b-48c9-b81a-4b035dc24e7a,DISK], DatanodeInfoWithStorage[127.0.0.1:38906,DS-76b1a024-25ac-4f8e-a2c8-e3ed53def975,DISK], DatanodeInfoWithStorage[127.0.0.1:45716,DS-3a94136f-78ef-4d0d-a829-3d1ed16fdce3,DISK], DatanodeInfoWithStorage[127.0.0.1:42930,DS-d2cc9754-49d3-4d7c-9d91-034ab32a08c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1905154178-172.17.0.4-1595308964169:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39523,DS-edacf1d7-fd2b-4c03-bef2-48a298a5975d,DISK], DatanodeInfoWithStorage[127.0.0.1:42191,DS-b2e175bc-e0aa-4626-91cd-0f06f288eaa4,DISK], DatanodeInfoWithStorage[127.0.0.1:35886,DS-f57d669e-78e0-4229-bfdc-d652d8c64ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:39461,DS-256cb1ee-e106-49ba-995f-a22f9e0ea07d,DISK], DatanodeInfoWithStorage[127.0.0.1:33015,DS-b7814bcd-ac8b-48c9-b81a-4b035dc24e7a,DISK], DatanodeInfoWithStorage[127.0.0.1:38906,DS-76b1a024-25ac-4f8e-a2c8-e3ed53def975,DISK], DatanodeInfoWithStorage[127.0.0.1:45716,DS-3a94136f-78ef-4d0d-a829-3d1ed16fdce3,DISK], DatanodeInfoWithStorage[127.0.0.1:42930,DS-d2cc9754-49d3-4d7c-9d91-034ab32a08c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1306896574-172.17.0.4-1595309087833:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35342,DS-f552ade9-c511-41d2-b650-86d965296c21,DISK], DatanodeInfoWithStorage[127.0.0.1:43203,DS-b312cc66-fceb-4526-8dae-be8221baacf4,DISK], DatanodeInfoWithStorage[127.0.0.1:38425,DS-8a7e5221-e129-4c1e-b4ea-b4d491b74091,DISK], DatanodeInfoWithStorage[127.0.0.1:43756,DS-a1af8b16-1aca-4379-b2e3-a02474c51397,DISK], DatanodeInfoWithStorage[127.0.0.1:41500,DS-dbafdee2-d5fb-43df-b83d-4ccefd5f5ddc,DISK], DatanodeInfoWithStorage[127.0.0.1:42170,DS-b27b65e8-974e-4451-9d83-f5e6be306650,DISK], DatanodeInfoWithStorage[127.0.0.1:34776,DS-17a3ec66-3b17-46af-a909-4809774c3c6a,DISK], DatanodeInfoWithStorage[127.0.0.1:34733,DS-f70d3b23-bf2c-42a4-bdad-9f561c986303,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1306896574-172.17.0.4-1595309087833:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35342,DS-f552ade9-c511-41d2-b650-86d965296c21,DISK], DatanodeInfoWithStorage[127.0.0.1:43203,DS-b312cc66-fceb-4526-8dae-be8221baacf4,DISK], DatanodeInfoWithStorage[127.0.0.1:38425,DS-8a7e5221-e129-4c1e-b4ea-b4d491b74091,DISK], DatanodeInfoWithStorage[127.0.0.1:43756,DS-a1af8b16-1aca-4379-b2e3-a02474c51397,DISK], DatanodeInfoWithStorage[127.0.0.1:41500,DS-dbafdee2-d5fb-43df-b83d-4ccefd5f5ddc,DISK], DatanodeInfoWithStorage[127.0.0.1:42170,DS-b27b65e8-974e-4451-9d83-f5e6be306650,DISK], DatanodeInfoWithStorage[127.0.0.1:34776,DS-17a3ec66-3b17-46af-a909-4809774c3c6a,DISK], DatanodeInfoWithStorage[127.0.0.1:34733,DS-f70d3b23-bf2c-42a4-bdad-9f561c986303,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-806299999-172.17.0.4-1595309231718:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46649,DS-8dc9efb4-f073-4b29-89e7-bc303570a9c8,DISK], DatanodeInfoWithStorage[127.0.0.1:33792,DS-5944489e-8db7-4c02-8e01-47116ba3ea9f,DISK], DatanodeInfoWithStorage[127.0.0.1:35405,DS-316a2e64-579f-4134-9ebb-96012bd42ce3,DISK], DatanodeInfoWithStorage[127.0.0.1:38229,DS-f364fca7-574e-4d0a-a3bb-1a111430e730,DISK], DatanodeInfoWithStorage[127.0.0.1:35437,DS-4b98f865-919c-4332-ae90-5ff59fa7e2b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44595,DS-914c31ed-d8b2-42c6-9497-e266043e95e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34606,DS-800af663-5e87-4a87-b236-7ee43ae4fa65,DISK], DatanodeInfoWithStorage[127.0.0.1:45213,DS-ee2e9892-fb4e-4110-8f2a-44eeeb773661,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-806299999-172.17.0.4-1595309231718:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46649,DS-8dc9efb4-f073-4b29-89e7-bc303570a9c8,DISK], DatanodeInfoWithStorage[127.0.0.1:33792,DS-5944489e-8db7-4c02-8e01-47116ba3ea9f,DISK], DatanodeInfoWithStorage[127.0.0.1:35405,DS-316a2e64-579f-4134-9ebb-96012bd42ce3,DISK], DatanodeInfoWithStorage[127.0.0.1:38229,DS-f364fca7-574e-4d0a-a3bb-1a111430e730,DISK], DatanodeInfoWithStorage[127.0.0.1:35437,DS-4b98f865-919c-4332-ae90-5ff59fa7e2b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44595,DS-914c31ed-d8b2-42c6-9497-e266043e95e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34606,DS-800af663-5e87-4a87-b236-7ee43ae4fa65,DISK], DatanodeInfoWithStorage[127.0.0.1:45213,DS-ee2e9892-fb4e-4110-8f2a-44eeeb773661,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-139789026-172.17.0.4-1595309820862:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46521,DS-069c5e22-5e77-4aa8-8c61-64ddf1d52699,DISK], DatanodeInfoWithStorage[127.0.0.1:38389,DS-1df20985-4407-4b6b-9e53-a5a3533f32f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39029,DS-88ce68a2-9513-49f3-bee9-ff8fb50e089c,DISK], DatanodeInfoWithStorage[127.0.0.1:33331,DS-9b5b16fe-ad03-43b7-96b7-4b81a0de1c30,DISK], DatanodeInfoWithStorage[127.0.0.1:38062,DS-922a72b6-fcb9-4c9c-a283-2953de1c6a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:46353,DS-22fe783c-f1e2-4491-b64e-82e895bba668,DISK], DatanodeInfoWithStorage[127.0.0.1:43375,DS-a2502799-e8a8-4427-9977-7d700271e9cd,DISK], DatanodeInfoWithStorage[127.0.0.1:39757,DS-fc075e62-6e16-4b8b-be79-3c690d662273,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-139789026-172.17.0.4-1595309820862:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46521,DS-069c5e22-5e77-4aa8-8c61-64ddf1d52699,DISK], DatanodeInfoWithStorage[127.0.0.1:38389,DS-1df20985-4407-4b6b-9e53-a5a3533f32f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39029,DS-88ce68a2-9513-49f3-bee9-ff8fb50e089c,DISK], DatanodeInfoWithStorage[127.0.0.1:33331,DS-9b5b16fe-ad03-43b7-96b7-4b81a0de1c30,DISK], DatanodeInfoWithStorage[127.0.0.1:38062,DS-922a72b6-fcb9-4c9c-a283-2953de1c6a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:46353,DS-22fe783c-f1e2-4491-b64e-82e895bba668,DISK], DatanodeInfoWithStorage[127.0.0.1:43375,DS-a2502799-e8a8-4427-9977-7d700271e9cd,DISK], DatanodeInfoWithStorage[127.0.0.1:39757,DS-fc075e62-6e16-4b8b-be79-3c690d662273,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1617530786-172.17.0.4-1595309932230:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42726,DS-97e275fc-7081-4095-8e33-adfa3874d812,DISK], DatanodeInfoWithStorage[127.0.0.1:45555,DS-2b6e08f1-b18c-4b4c-8d5b-62967954ab45,DISK], DatanodeInfoWithStorage[127.0.0.1:38474,DS-152e73fc-bc40-46b4-adbd-34bec3eeb42b,DISK], DatanodeInfoWithStorage[127.0.0.1:40134,DS-b9054b5e-c505-4812-90de-7ade56d9c7ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40603,DS-c86547a5-9e1f-4325-b0ac-a2a1b3c44366,DISK], DatanodeInfoWithStorage[127.0.0.1:44261,DS-1a3cb0fd-4504-4bf4-a38b-4c4b2439596e,DISK], DatanodeInfoWithStorage[127.0.0.1:43118,DS-f6e28a6e-937a-441d-b2ed-67aa4262033f,DISK], DatanodeInfoWithStorage[127.0.0.1:44756,DS-134760db-47d5-4f1c-a8f6-c25c0290ad69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1617530786-172.17.0.4-1595309932230:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42726,DS-97e275fc-7081-4095-8e33-adfa3874d812,DISK], DatanodeInfoWithStorage[127.0.0.1:45555,DS-2b6e08f1-b18c-4b4c-8d5b-62967954ab45,DISK], DatanodeInfoWithStorage[127.0.0.1:38474,DS-152e73fc-bc40-46b4-adbd-34bec3eeb42b,DISK], DatanodeInfoWithStorage[127.0.0.1:40134,DS-b9054b5e-c505-4812-90de-7ade56d9c7ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40603,DS-c86547a5-9e1f-4325-b0ac-a2a1b3c44366,DISK], DatanodeInfoWithStorage[127.0.0.1:44261,DS-1a3cb0fd-4504-4bf4-a38b-4c4b2439596e,DISK], DatanodeInfoWithStorage[127.0.0.1:43118,DS-f6e28a6e-937a-441d-b2ed-67aa4262033f,DISK], DatanodeInfoWithStorage[127.0.0.1:44756,DS-134760db-47d5-4f1c-a8f6-c25c0290ad69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1219917463-172.17.0.4-1595310184213:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36249,DS-77854e6b-b861-4a32-8f91-7584dee94a64,DISK], DatanodeInfoWithStorage[127.0.0.1:42392,DS-624a57ec-85e4-4317-8200-69177e59a1ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36679,DS-1d03d268-7f91-404c-bf7e-dd43d1066124,DISK], DatanodeInfoWithStorage[127.0.0.1:34479,DS-da4e79f7-800b-4059-96ce-a64afdbc400b,DISK], DatanodeInfoWithStorage[127.0.0.1:42850,DS-a06a8802-1066-40ad-baeb-b9acd3b843ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38752,DS-f1767496-b910-4244-a929-c0cd710d121a,DISK], DatanodeInfoWithStorage[127.0.0.1:38599,DS-1eeb3d3d-4cc9-4a57-a6ba-3e3d0e75885a,DISK], DatanodeInfoWithStorage[127.0.0.1:45713,DS-55f20e9d-4f0a-461e-95b6-caba7d19a590,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1219917463-172.17.0.4-1595310184213:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36249,DS-77854e6b-b861-4a32-8f91-7584dee94a64,DISK], DatanodeInfoWithStorage[127.0.0.1:42392,DS-624a57ec-85e4-4317-8200-69177e59a1ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36679,DS-1d03d268-7f91-404c-bf7e-dd43d1066124,DISK], DatanodeInfoWithStorage[127.0.0.1:34479,DS-da4e79f7-800b-4059-96ce-a64afdbc400b,DISK], DatanodeInfoWithStorage[127.0.0.1:42850,DS-a06a8802-1066-40ad-baeb-b9acd3b843ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38752,DS-f1767496-b910-4244-a929-c0cd710d121a,DISK], DatanodeInfoWithStorage[127.0.0.1:38599,DS-1eeb3d3d-4cc9-4a57-a6ba-3e3d0e75885a,DISK], DatanodeInfoWithStorage[127.0.0.1:45713,DS-55f20e9d-4f0a-461e-95b6-caba7d19a590,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1677160570-172.17.0.4-1595310357943:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38241,DS-9d618db3-be35-4af7-867d-ac0b6eb2969e,DISK], DatanodeInfoWithStorage[127.0.0.1:42219,DS-924a78ae-9de6-456c-8608-28b59b88c8e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34222,DS-34ab6672-285f-4975-9f3e-9ad2c6491f54,DISK], DatanodeInfoWithStorage[127.0.0.1:37876,DS-6b60f029-17b9-49c6-9f7e-1c3245374ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:44053,DS-7cda5840-84f3-4b35-876c-be95d73b9958,DISK], DatanodeInfoWithStorage[127.0.0.1:35431,DS-b249f225-9228-4d5b-b73a-13e5d3cb06a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40669,DS-66698635-8d4e-46ec-bc37-ff6b8d82455a,DISK], DatanodeInfoWithStorage[127.0.0.1:35183,DS-5f9df158-ee81-4cde-a422-81e8c7382269,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1677160570-172.17.0.4-1595310357943:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38241,DS-9d618db3-be35-4af7-867d-ac0b6eb2969e,DISK], DatanodeInfoWithStorage[127.0.0.1:42219,DS-924a78ae-9de6-456c-8608-28b59b88c8e8,DISK], DatanodeInfoWithStorage[127.0.0.1:34222,DS-34ab6672-285f-4975-9f3e-9ad2c6491f54,DISK], DatanodeInfoWithStorage[127.0.0.1:37876,DS-6b60f029-17b9-49c6-9f7e-1c3245374ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:44053,DS-7cda5840-84f3-4b35-876c-be95d73b9958,DISK], DatanodeInfoWithStorage[127.0.0.1:35431,DS-b249f225-9228-4d5b-b73a-13e5d3cb06a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40669,DS-66698635-8d4e-46ec-bc37-ff6b8d82455a,DISK], DatanodeInfoWithStorage[127.0.0.1:35183,DS-5f9df158-ee81-4cde-a422-81e8c7382269,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-567679696-172.17.0.4-1595310549110:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40026,DS-50207306-609d-4ca1-adcc-8d8811beba82,DISK], DatanodeInfoWithStorage[127.0.0.1:35887,DS-2dcc78f1-d55d-451c-93a0-db10da520e51,DISK], DatanodeInfoWithStorage[127.0.0.1:34904,DS-a46cf69a-98ad-429e-9a48-ef0e47f5875e,DISK], DatanodeInfoWithStorage[127.0.0.1:41640,DS-e2a265dd-2554-4511-b537-64e55dd2fd9b,DISK], DatanodeInfoWithStorage[127.0.0.1:44799,DS-69f7124c-5441-415a-bbf5-757bc92d768f,DISK], DatanodeInfoWithStorage[127.0.0.1:38624,DS-204a1c22-cebe-4779-b4d4-be8f308ca562,DISK], DatanodeInfoWithStorage[127.0.0.1:35003,DS-13bcd8c1-ef26-4217-8215-ca636f991094,DISK], DatanodeInfoWithStorage[127.0.0.1:36486,DS-a154fc4c-02bf-4145-82fb-608f4647f409,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-567679696-172.17.0.4-1595310549110:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40026,DS-50207306-609d-4ca1-adcc-8d8811beba82,DISK], DatanodeInfoWithStorage[127.0.0.1:35887,DS-2dcc78f1-d55d-451c-93a0-db10da520e51,DISK], DatanodeInfoWithStorage[127.0.0.1:34904,DS-a46cf69a-98ad-429e-9a48-ef0e47f5875e,DISK], DatanodeInfoWithStorage[127.0.0.1:41640,DS-e2a265dd-2554-4511-b537-64e55dd2fd9b,DISK], DatanodeInfoWithStorage[127.0.0.1:44799,DS-69f7124c-5441-415a-bbf5-757bc92d768f,DISK], DatanodeInfoWithStorage[127.0.0.1:38624,DS-204a1c22-cebe-4779-b4d4-be8f308ca562,DISK], DatanodeInfoWithStorage[127.0.0.1:35003,DS-13bcd8c1-ef26-4217-8215-ca636f991094,DISK], DatanodeInfoWithStorage[127.0.0.1:36486,DS-a154fc4c-02bf-4145-82fb-608f4647f409,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1955942076-172.17.0.4-1595310585554:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45381,DS-cb3ba5f3-a7b0-4ab6-872d-265f70645cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:45493,DS-863f1978-7694-4c91-9dbd-695dd64bf8fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36967,DS-ae0274da-73ca-4081-8933-e2ab91749739,DISK], DatanodeInfoWithStorage[127.0.0.1:38988,DS-10f625ac-686e-4c38-b117-f85bce09b436,DISK], DatanodeInfoWithStorage[127.0.0.1:33136,DS-dd826aad-3c2e-4079-ad12-b58d530c5ad3,DISK], DatanodeInfoWithStorage[127.0.0.1:40553,DS-2903e765-a2fb-4a01-be3a-43e5b580f1e5,DISK], DatanodeInfoWithStorage[127.0.0.1:39140,DS-246fc77b-bf32-4fba-b33e-c4bca0434c5b,DISK], DatanodeInfoWithStorage[127.0.0.1:34341,DS-1f66966f-147e-4f64-985b-5c993d5406bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1955942076-172.17.0.4-1595310585554:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45381,DS-cb3ba5f3-a7b0-4ab6-872d-265f70645cc4,DISK], DatanodeInfoWithStorage[127.0.0.1:45493,DS-863f1978-7694-4c91-9dbd-695dd64bf8fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36967,DS-ae0274da-73ca-4081-8933-e2ab91749739,DISK], DatanodeInfoWithStorage[127.0.0.1:38988,DS-10f625ac-686e-4c38-b117-f85bce09b436,DISK], DatanodeInfoWithStorage[127.0.0.1:33136,DS-dd826aad-3c2e-4079-ad12-b58d530c5ad3,DISK], DatanodeInfoWithStorage[127.0.0.1:40553,DS-2903e765-a2fb-4a01-be3a-43e5b580f1e5,DISK], DatanodeInfoWithStorage[127.0.0.1:39140,DS-246fc77b-bf32-4fba-b33e-c4bca0434c5b,DISK], DatanodeInfoWithStorage[127.0.0.1:34341,DS-1f66966f-147e-4f64-985b-5c993d5406bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1070932750-172.17.0.4-1595311233557:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33611,DS-27050cca-fcee-4337-b6a8-eed88a423a17,DISK], DatanodeInfoWithStorage[127.0.0.1:43344,DS-781a0c61-f097-46b3-b31d-f480d7b3dfda,DISK], DatanodeInfoWithStorage[127.0.0.1:35319,DS-03d28056-f173-4626-86ce-d17bdd700184,DISK], DatanodeInfoWithStorage[127.0.0.1:38151,DS-94e79b35-3c93-49e8-824a-88dc4ecd3f95,DISK], DatanodeInfoWithStorage[127.0.0.1:41851,DS-06951e48-4d55-4f3d-8164-3008fac00f60,DISK], DatanodeInfoWithStorage[127.0.0.1:46301,DS-1defac91-1a7c-4d74-a0e2-15289207f668,DISK], DatanodeInfoWithStorage[127.0.0.1:46370,DS-9227bc9b-63e5-4169-bfb1-f158671180e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38118,DS-c6e75938-6ca4-460d-9f55-878fa62e980f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1070932750-172.17.0.4-1595311233557:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33611,DS-27050cca-fcee-4337-b6a8-eed88a423a17,DISK], DatanodeInfoWithStorage[127.0.0.1:43344,DS-781a0c61-f097-46b3-b31d-f480d7b3dfda,DISK], DatanodeInfoWithStorage[127.0.0.1:35319,DS-03d28056-f173-4626-86ce-d17bdd700184,DISK], DatanodeInfoWithStorage[127.0.0.1:38151,DS-94e79b35-3c93-49e8-824a-88dc4ecd3f95,DISK], DatanodeInfoWithStorage[127.0.0.1:41851,DS-06951e48-4d55-4f3d-8164-3008fac00f60,DISK], DatanodeInfoWithStorage[127.0.0.1:46301,DS-1defac91-1a7c-4d74-a0e2-15289207f668,DISK], DatanodeInfoWithStorage[127.0.0.1:46370,DS-9227bc9b-63e5-4169-bfb1-f158671180e8,DISK], DatanodeInfoWithStorage[127.0.0.1:38118,DS-c6e75938-6ca4-460d-9f55-878fa62e980f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-848556426-172.17.0.4-1595311579246:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45362,DS-29c3c535-f166-40ed-a97d-b2070a8e755f,DISK], DatanodeInfoWithStorage[127.0.0.1:34457,DS-93e22126-b202-4ccf-9a69-efeca6f85fcf,DISK], DatanodeInfoWithStorage[127.0.0.1:36577,DS-ca84e8f0-cb83-4957-b72d-319c88e21ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:44351,DS-fa76009d-39e0-44ff-a914-e81d175918d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40928,DS-dc8819a7-ee44-40f0-a49a-800497a631cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36039,DS-78a6b747-b864-4dd3-88fa-1f051e9b6413,DISK], DatanodeInfoWithStorage[127.0.0.1:46113,DS-adeec635-e2e5-45fb-b16b-f27c60f292ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42887,DS-ff816419-488a-4229-8d9d-6f8a18634e8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-848556426-172.17.0.4-1595311579246:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45362,DS-29c3c535-f166-40ed-a97d-b2070a8e755f,DISK], DatanodeInfoWithStorage[127.0.0.1:34457,DS-93e22126-b202-4ccf-9a69-efeca6f85fcf,DISK], DatanodeInfoWithStorage[127.0.0.1:36577,DS-ca84e8f0-cb83-4957-b72d-319c88e21ad7,DISK], DatanodeInfoWithStorage[127.0.0.1:44351,DS-fa76009d-39e0-44ff-a914-e81d175918d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40928,DS-dc8819a7-ee44-40f0-a49a-800497a631cf,DISK], DatanodeInfoWithStorage[127.0.0.1:36039,DS-78a6b747-b864-4dd3-88fa-1f051e9b6413,DISK], DatanodeInfoWithStorage[127.0.0.1:46113,DS-adeec635-e2e5-45fb-b16b-f27c60f292ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42887,DS-ff816419-488a-4229-8d9d-6f8a18634e8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-106004575-172.17.0.4-1595311664209:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40562,DS-f138eb47-7d81-490c-a5a8-8732a903594f,DISK], DatanodeInfoWithStorage[127.0.0.1:39170,DS-06b8689c-66f9-4422-a4ac-ddc8ce190a28,DISK], DatanodeInfoWithStorage[127.0.0.1:46728,DS-c8ce7482-16a5-4d3e-b3eb-e70a6ca861ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36094,DS-9ef5399d-3269-4971-9722-34879e0b2ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:41985,DS-ec3562bc-4ba1-4980-b256-6a880880c014,DISK], DatanodeInfoWithStorage[127.0.0.1:46003,DS-8aa69095-c615-4f98-ba54-b689e7fe7746,DISK], DatanodeInfoWithStorage[127.0.0.1:41767,DS-3cc84873-c029-4aac-9a1b-b97888089dbe,DISK], DatanodeInfoWithStorage[127.0.0.1:33349,DS-2df53bdb-f325-4e38-89b9-d828c141da8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-106004575-172.17.0.4-1595311664209:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40562,DS-f138eb47-7d81-490c-a5a8-8732a903594f,DISK], DatanodeInfoWithStorage[127.0.0.1:39170,DS-06b8689c-66f9-4422-a4ac-ddc8ce190a28,DISK], DatanodeInfoWithStorage[127.0.0.1:46728,DS-c8ce7482-16a5-4d3e-b3eb-e70a6ca861ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36094,DS-9ef5399d-3269-4971-9722-34879e0b2ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:41985,DS-ec3562bc-4ba1-4980-b256-6a880880c014,DISK], DatanodeInfoWithStorage[127.0.0.1:46003,DS-8aa69095-c615-4f98-ba54-b689e7fe7746,DISK], DatanodeInfoWithStorage[127.0.0.1:41767,DS-3cc84873-c029-4aac-9a1b-b97888089dbe,DISK], DatanodeInfoWithStorage[127.0.0.1:33349,DS-2df53bdb-f325-4e38-89b9-d828c141da8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1606799128-172.17.0.4-1595311736255:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41451,DS-884bbcc2-8be5-4951-96ed-0290db73434d,DISK], DatanodeInfoWithStorage[127.0.0.1:45641,DS-4da229a4-2f4e-4c79-b1ec-5aa0fa804a14,DISK], DatanodeInfoWithStorage[127.0.0.1:38153,DS-094b849a-c862-4632-b797-cec0bd640ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:38310,DS-57c91446-1368-4dbc-a2e1-9d85244c9007,DISK], DatanodeInfoWithStorage[127.0.0.1:33277,DS-e292cd12-596d-47bd-89c2-1e5aa983c902,DISK], DatanodeInfoWithStorage[127.0.0.1:45148,DS-9ffc6a61-3210-423f-8dd7-0118b0cfe1ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45571,DS-8536964a-9a66-4406-a865-8be1afcf3203,DISK], DatanodeInfoWithStorage[127.0.0.1:39470,DS-8dd45df3-d6e7-425f-a3d5-d448c79f1a08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1606799128-172.17.0.4-1595311736255:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41451,DS-884bbcc2-8be5-4951-96ed-0290db73434d,DISK], DatanodeInfoWithStorage[127.0.0.1:45641,DS-4da229a4-2f4e-4c79-b1ec-5aa0fa804a14,DISK], DatanodeInfoWithStorage[127.0.0.1:38153,DS-094b849a-c862-4632-b797-cec0bd640ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:38310,DS-57c91446-1368-4dbc-a2e1-9d85244c9007,DISK], DatanodeInfoWithStorage[127.0.0.1:33277,DS-e292cd12-596d-47bd-89c2-1e5aa983c902,DISK], DatanodeInfoWithStorage[127.0.0.1:45148,DS-9ffc6a61-3210-423f-8dd7-0118b0cfe1ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45571,DS-8536964a-9a66-4406-a865-8be1afcf3203,DISK], DatanodeInfoWithStorage[127.0.0.1:39470,DS-8dd45df3-d6e7-425f-a3d5-d448c79f1a08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-148583101-172.17.0.4-1595311919391:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45968,DS-6cdefb3c-7bc0-457e-941e-82392cb1650e,DISK], DatanodeInfoWithStorage[127.0.0.1:35393,DS-dfca19e4-f239-4c30-9b82-b7714d26bdde,DISK], DatanodeInfoWithStorage[127.0.0.1:39521,DS-64d291e0-f9af-4b85-bee1-76c2bb8437ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40707,DS-dbd0d352-1c4a-4c8b-b62a-9a2b2a6f5511,DISK], DatanodeInfoWithStorage[127.0.0.1:33845,DS-acb2b659-732a-4411-9edc-22b7f92058d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44283,DS-6ce11372-e917-45f8-9124-f75a07f3e4bc,DISK], DatanodeInfoWithStorage[127.0.0.1:40473,DS-4677d452-468e-4e82-a5b2-e489659f103b,DISK], DatanodeInfoWithStorage[127.0.0.1:34718,DS-6c0a325d-9a3c-43d0-8262-f51a9d1c8271,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-148583101-172.17.0.4-1595311919391:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45968,DS-6cdefb3c-7bc0-457e-941e-82392cb1650e,DISK], DatanodeInfoWithStorage[127.0.0.1:35393,DS-dfca19e4-f239-4c30-9b82-b7714d26bdde,DISK], DatanodeInfoWithStorage[127.0.0.1:39521,DS-64d291e0-f9af-4b85-bee1-76c2bb8437ff,DISK], DatanodeInfoWithStorage[127.0.0.1:40707,DS-dbd0d352-1c4a-4c8b-b62a-9a2b2a6f5511,DISK], DatanodeInfoWithStorage[127.0.0.1:33845,DS-acb2b659-732a-4411-9edc-22b7f92058d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44283,DS-6ce11372-e917-45f8-9124-f75a07f3e4bc,DISK], DatanodeInfoWithStorage[127.0.0.1:40473,DS-4677d452-468e-4e82-a5b2-e489659f103b,DISK], DatanodeInfoWithStorage[127.0.0.1:34718,DS-6c0a325d-9a3c-43d0-8262-f51a9d1c8271,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5566
