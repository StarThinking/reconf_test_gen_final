reconf_parameter: fs.automatic.close
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.automatic.close
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1020014103-172.17.0.19-1596985047330:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41454,DS-0447018c-41fa-4220-b40d-7d6d13f1d311,DISK], DatanodeInfoWithStorage[127.0.0.1:43210,DS-7e2d30d3-397f-4b64-83b2-4559e57008ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34774,DS-054c62c3-74e6-4238-8e90-878e334c97e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42106,DS-380c4be0-2be9-459c-a48c-db68865eaab9,DISK], DatanodeInfoWithStorage[127.0.0.1:36328,DS-1c81018f-58ee-4639-9c14-35f199933e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:37494,DS-1444a4cf-94f5-4efe-aa98-b8013512b221,DISK], DatanodeInfoWithStorage[127.0.0.1:40223,DS-a8359438-de0b-4ca2-b433-5aa6dfebd500,DISK], DatanodeInfoWithStorage[127.0.0.1:36059,DS-e001e4cf-c5e9-4114-80a8-dcb14e87856a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1020014103-172.17.0.19-1596985047330:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41454,DS-0447018c-41fa-4220-b40d-7d6d13f1d311,DISK], DatanodeInfoWithStorage[127.0.0.1:43210,DS-7e2d30d3-397f-4b64-83b2-4559e57008ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34774,DS-054c62c3-74e6-4238-8e90-878e334c97e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42106,DS-380c4be0-2be9-459c-a48c-db68865eaab9,DISK], DatanodeInfoWithStorage[127.0.0.1:36328,DS-1c81018f-58ee-4639-9c14-35f199933e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:37494,DS-1444a4cf-94f5-4efe-aa98-b8013512b221,DISK], DatanodeInfoWithStorage[127.0.0.1:40223,DS-a8359438-de0b-4ca2-b433-5aa6dfebd500,DISK], DatanodeInfoWithStorage[127.0.0.1:36059,DS-e001e4cf-c5e9-4114-80a8-dcb14e87856a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.automatic.close
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1980540823-172.17.0.19-1596985149516:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44418,DS-00bd0c0c-e95e-4ea6-93b1-736d944622e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38792,DS-4eafe36e-9336-4673-97fc-6242b11fe20d,DISK], DatanodeInfoWithStorage[127.0.0.1:43530,DS-baf6497c-a228-4e1a-ad95-efe7c03dae00,DISK], DatanodeInfoWithStorage[127.0.0.1:40326,DS-7cdfd5f5-41f8-406f-a1d6-dc597ea4d475,DISK], DatanodeInfoWithStorage[127.0.0.1:43624,DS-51cf8324-05ba-4f84-85f8-0f3511296bfc,DISK], DatanodeInfoWithStorage[127.0.0.1:36774,DS-318e6567-b504-4adb-99b4-058d224e4406,DISK], DatanodeInfoWithStorage[127.0.0.1:44213,DS-dd932612-110c-4f20-93b7-9ca8d6cddd8f,DISK], DatanodeInfoWithStorage[127.0.0.1:43818,DS-8fd4af69-620a-4304-8b47-5a4d8ca178b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1980540823-172.17.0.19-1596985149516:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44418,DS-00bd0c0c-e95e-4ea6-93b1-736d944622e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38792,DS-4eafe36e-9336-4673-97fc-6242b11fe20d,DISK], DatanodeInfoWithStorage[127.0.0.1:43530,DS-baf6497c-a228-4e1a-ad95-efe7c03dae00,DISK], DatanodeInfoWithStorage[127.0.0.1:40326,DS-7cdfd5f5-41f8-406f-a1d6-dc597ea4d475,DISK], DatanodeInfoWithStorage[127.0.0.1:43624,DS-51cf8324-05ba-4f84-85f8-0f3511296bfc,DISK], DatanodeInfoWithStorage[127.0.0.1:36774,DS-318e6567-b504-4adb-99b4-058d224e4406,DISK], DatanodeInfoWithStorage[127.0.0.1:44213,DS-dd932612-110c-4f20-93b7-9ca8d6cddd8f,DISK], DatanodeInfoWithStorage[127.0.0.1:43818,DS-8fd4af69-620a-4304-8b47-5a4d8ca178b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.automatic.close
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-643600545-172.17.0.19-1596985422966:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38576,DS-26cfbc09-d84a-47fe-a802-cc968b1372ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37323,DS-a0017318-b420-40a8-90da-e5ca8176060f,DISK], DatanodeInfoWithStorage[127.0.0.1:45121,DS-2bff5c7b-9e48-44b4-92b5-8f31c4ddf849,DISK], DatanodeInfoWithStorage[127.0.0.1:40838,DS-6899e8f8-1d83-41a4-a45c-f5cf9139c9c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38252,DS-7981f963-a300-4955-8a4f-a4d0aea20bbb,DISK], DatanodeInfoWithStorage[127.0.0.1:38210,DS-d149c59c-8a0e-4939-96ae-5239ab6760eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34658,DS-883d54c2-7a89-4b05-bf90-35c55c1def41,DISK], DatanodeInfoWithStorage[127.0.0.1:34405,DS-7331bb96-4789-4bef-8ee0-24c59c0ddce3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-643600545-172.17.0.19-1596985422966:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38576,DS-26cfbc09-d84a-47fe-a802-cc968b1372ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37323,DS-a0017318-b420-40a8-90da-e5ca8176060f,DISK], DatanodeInfoWithStorage[127.0.0.1:45121,DS-2bff5c7b-9e48-44b4-92b5-8f31c4ddf849,DISK], DatanodeInfoWithStorage[127.0.0.1:40838,DS-6899e8f8-1d83-41a4-a45c-f5cf9139c9c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38252,DS-7981f963-a300-4955-8a4f-a4d0aea20bbb,DISK], DatanodeInfoWithStorage[127.0.0.1:38210,DS-d149c59c-8a0e-4939-96ae-5239ab6760eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34658,DS-883d54c2-7a89-4b05-bf90-35c55c1def41,DISK], DatanodeInfoWithStorage[127.0.0.1:34405,DS-7331bb96-4789-4bef-8ee0-24c59c0ddce3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.automatic.close
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1640338120-172.17.0.19-1596985497794:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40708,DS-c786571c-ea04-4e8d-97c0-03b32078a538,DISK], DatanodeInfoWithStorage[127.0.0.1:35730,DS-2b5637f2-d654-423e-b744-d94c24a3757a,DISK], DatanodeInfoWithStorage[127.0.0.1:44684,DS-2d654591-bf48-424b-8e31-a7028851a9d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33823,DS-d0152d6a-391f-4db3-ac09-eb02b8a47c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:39239,DS-8ce0203a-ceba-479c-a8a3-a3a89c1028e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35757,DS-1de2c2c7-79a3-48f8-9098-d8117e432191,DISK], DatanodeInfoWithStorage[127.0.0.1:45474,DS-f0ce0c6f-5d8c-4c9a-a0e8-f9e4d2574442,DISK], DatanodeInfoWithStorage[127.0.0.1:33588,DS-8ea30a6e-84e8-4524-a957-757735c23b2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1640338120-172.17.0.19-1596985497794:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40708,DS-c786571c-ea04-4e8d-97c0-03b32078a538,DISK], DatanodeInfoWithStorage[127.0.0.1:35730,DS-2b5637f2-d654-423e-b744-d94c24a3757a,DISK], DatanodeInfoWithStorage[127.0.0.1:44684,DS-2d654591-bf48-424b-8e31-a7028851a9d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33823,DS-d0152d6a-391f-4db3-ac09-eb02b8a47c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:39239,DS-8ce0203a-ceba-479c-a8a3-a3a89c1028e3,DISK], DatanodeInfoWithStorage[127.0.0.1:35757,DS-1de2c2c7-79a3-48f8-9098-d8117e432191,DISK], DatanodeInfoWithStorage[127.0.0.1:45474,DS-f0ce0c6f-5d8c-4c9a-a0e8-f9e4d2574442,DISK], DatanodeInfoWithStorage[127.0.0.1:33588,DS-8ea30a6e-84e8-4524-a957-757735c23b2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.automatic.close
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-456632634-172.17.0.19-1596985676427:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42210,DS-38358522-8f8b-4676-a112-7fd42813423d,DISK], DatanodeInfoWithStorage[127.0.0.1:33309,DS-4b99135a-aeac-425c-bef1-301ff03be195,DISK], DatanodeInfoWithStorage[127.0.0.1:45144,DS-c9672fdd-78c2-418b-8c80-6a16ab1aa9fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35750,DS-84c424a2-4a94-4da4-8cc8-df18c3543496,DISK], DatanodeInfoWithStorage[127.0.0.1:33741,DS-c8edd3fd-3ff2-4b9c-a550-5e0d6dc166fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42087,DS-9f5357b8-8493-47bc-ae1a-7d62c7000788,DISK], DatanodeInfoWithStorage[127.0.0.1:35944,DS-576a7509-4b8a-4564-ad34-f4196044b2f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41954,DS-46a51c04-e001-4dc6-8f73-d86bfe455fd2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-456632634-172.17.0.19-1596985676427:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42210,DS-38358522-8f8b-4676-a112-7fd42813423d,DISK], DatanodeInfoWithStorage[127.0.0.1:33309,DS-4b99135a-aeac-425c-bef1-301ff03be195,DISK], DatanodeInfoWithStorage[127.0.0.1:45144,DS-c9672fdd-78c2-418b-8c80-6a16ab1aa9fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35750,DS-84c424a2-4a94-4da4-8cc8-df18c3543496,DISK], DatanodeInfoWithStorage[127.0.0.1:33741,DS-c8edd3fd-3ff2-4b9c-a550-5e0d6dc166fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42087,DS-9f5357b8-8493-47bc-ae1a-7d62c7000788,DISK], DatanodeInfoWithStorage[127.0.0.1:35944,DS-576a7509-4b8a-4564-ad34-f4196044b2f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41954,DS-46a51c04-e001-4dc6-8f73-d86bfe455fd2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.automatic.close
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-33900487-172.17.0.19-1596985890248:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39189,DS-194e51fb-0fe0-42e4-b2ca-568867379810,DISK], DatanodeInfoWithStorage[127.0.0.1:40364,DS-ee432ea2-27ce-4d1d-b349-c4b67b6504e4,DISK], DatanodeInfoWithStorage[127.0.0.1:46816,DS-f01a94a9-aebe-4dfe-9e58-dd844d00c89d,DISK], DatanodeInfoWithStorage[127.0.0.1:40363,DS-384ea7c7-a3a8-4776-b0cd-76fef7ab836f,DISK], DatanodeInfoWithStorage[127.0.0.1:44924,DS-73745025-a175-455f-8c2f-4849420d8d06,DISK], DatanodeInfoWithStorage[127.0.0.1:41332,DS-5222e4bb-6572-4000-ae5f-59a4b143846a,DISK], DatanodeInfoWithStorage[127.0.0.1:36996,DS-ed7aebbd-a6a2-4352-a306-d11e3e0ffabe,DISK], DatanodeInfoWithStorage[127.0.0.1:33354,DS-179cd52e-63e1-4e02-8f1d-bf939686724a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-33900487-172.17.0.19-1596985890248:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39189,DS-194e51fb-0fe0-42e4-b2ca-568867379810,DISK], DatanodeInfoWithStorage[127.0.0.1:40364,DS-ee432ea2-27ce-4d1d-b349-c4b67b6504e4,DISK], DatanodeInfoWithStorage[127.0.0.1:46816,DS-f01a94a9-aebe-4dfe-9e58-dd844d00c89d,DISK], DatanodeInfoWithStorage[127.0.0.1:40363,DS-384ea7c7-a3a8-4776-b0cd-76fef7ab836f,DISK], DatanodeInfoWithStorage[127.0.0.1:44924,DS-73745025-a175-455f-8c2f-4849420d8d06,DISK], DatanodeInfoWithStorage[127.0.0.1:41332,DS-5222e4bb-6572-4000-ae5f-59a4b143846a,DISK], DatanodeInfoWithStorage[127.0.0.1:36996,DS-ed7aebbd-a6a2-4352-a306-d11e3e0ffabe,DISK], DatanodeInfoWithStorage[127.0.0.1:33354,DS-179cd52e-63e1-4e02-8f1d-bf939686724a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.automatic.close
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-118842124-172.17.0.19-1596986103071:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32991,DS-c04efb52-e725-408c-a72f-729b00c9e0d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44635,DS-ee1a0f58-7c89-4390-b605-ee40685a98a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34064,DS-7c1cd3ea-2133-431d-8cd4-091afb0c28e4,DISK], DatanodeInfoWithStorage[127.0.0.1:46591,DS-5d3a490d-2690-4093-b928-fac5085016a7,DISK], DatanodeInfoWithStorage[127.0.0.1:43133,DS-96caeb48-a363-4ee7-b447-9205cfbd63a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38305,DS-b2d02e21-1e1a-485a-bc94-b96c1ab7c0eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41644,DS-ecf2209a-3e32-42e1-969c-8c20d618d369,DISK], DatanodeInfoWithStorage[127.0.0.1:40905,DS-d855f45b-f814-4c91-9807-e5a38999c30e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-118842124-172.17.0.19-1596986103071:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32991,DS-c04efb52-e725-408c-a72f-729b00c9e0d9,DISK], DatanodeInfoWithStorage[127.0.0.1:44635,DS-ee1a0f58-7c89-4390-b605-ee40685a98a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34064,DS-7c1cd3ea-2133-431d-8cd4-091afb0c28e4,DISK], DatanodeInfoWithStorage[127.0.0.1:46591,DS-5d3a490d-2690-4093-b928-fac5085016a7,DISK], DatanodeInfoWithStorage[127.0.0.1:43133,DS-96caeb48-a363-4ee7-b447-9205cfbd63a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38305,DS-b2d02e21-1e1a-485a-bc94-b96c1ab7c0eb,DISK], DatanodeInfoWithStorage[127.0.0.1:41644,DS-ecf2209a-3e32-42e1-969c-8c20d618d369,DISK], DatanodeInfoWithStorage[127.0.0.1:40905,DS-d855f45b-f814-4c91-9807-e5a38999c30e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.automatic.close
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-658149272-172.17.0.19-1596986368128:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34121,DS-08487170-7cfa-470e-a097-b15db9c152a7,DISK], DatanodeInfoWithStorage[127.0.0.1:44171,DS-50f7a48c-88af-4604-8191-fa83a0aa503f,DISK], DatanodeInfoWithStorage[127.0.0.1:42512,DS-cafa5218-9c37-45ba-94dc-fc6d5df73de8,DISK], DatanodeInfoWithStorage[127.0.0.1:33034,DS-f814c4c5-453c-4eaa-9e55-57e6fb8999af,DISK], DatanodeInfoWithStorage[127.0.0.1:45732,DS-7fb3139e-47a3-4be2-b3c2-9ecd0ccd0d71,DISK], DatanodeInfoWithStorage[127.0.0.1:45824,DS-941fb1f4-8ec4-4802-bd52-8f523c74f2e7,DISK], DatanodeInfoWithStorage[127.0.0.1:35182,DS-ac0bd5d1-1ec2-4d45-ad75-fc12b0eef145,DISK], DatanodeInfoWithStorage[127.0.0.1:37216,DS-c4f413e3-9216-4d8c-b3a2-f8640dbf03b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-658149272-172.17.0.19-1596986368128:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34121,DS-08487170-7cfa-470e-a097-b15db9c152a7,DISK], DatanodeInfoWithStorage[127.0.0.1:44171,DS-50f7a48c-88af-4604-8191-fa83a0aa503f,DISK], DatanodeInfoWithStorage[127.0.0.1:42512,DS-cafa5218-9c37-45ba-94dc-fc6d5df73de8,DISK], DatanodeInfoWithStorage[127.0.0.1:33034,DS-f814c4c5-453c-4eaa-9e55-57e6fb8999af,DISK], DatanodeInfoWithStorage[127.0.0.1:45732,DS-7fb3139e-47a3-4be2-b3c2-9ecd0ccd0d71,DISK], DatanodeInfoWithStorage[127.0.0.1:45824,DS-941fb1f4-8ec4-4802-bd52-8f523c74f2e7,DISK], DatanodeInfoWithStorage[127.0.0.1:35182,DS-ac0bd5d1-1ec2-4d45-ad75-fc12b0eef145,DISK], DatanodeInfoWithStorage[127.0.0.1:37216,DS-c4f413e3-9216-4d8c-b3a2-f8640dbf03b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.automatic.close
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1937330312-172.17.0.19-1596986705426:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33564,DS-03520a1c-52d9-456a-9486-d9ae0974f2e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39086,DS-4ca95a9d-266f-45e5-b347-bef76c53e135,DISK], DatanodeInfoWithStorage[127.0.0.1:39360,DS-e647d22b-7f52-4132-8da6-3a3b8c13ffcd,DISK], DatanodeInfoWithStorage[127.0.0.1:44599,DS-4a29f5e1-4c98-4b0b-bc4e-9309f69c408d,DISK], DatanodeInfoWithStorage[127.0.0.1:43504,DS-e6f90059-a0a2-4aec-b57b-cdcbce272f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:42016,DS-b9475cd1-5ff5-4b11-bd7f-f8ba1c07d5ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45336,DS-622fd05f-4890-48f6-a8ad-e26f1cd9171e,DISK], DatanodeInfoWithStorage[127.0.0.1:33752,DS-ef45c8d3-1e22-4497-81dc-6956fcfb7b51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1937330312-172.17.0.19-1596986705426:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33564,DS-03520a1c-52d9-456a-9486-d9ae0974f2e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39086,DS-4ca95a9d-266f-45e5-b347-bef76c53e135,DISK], DatanodeInfoWithStorage[127.0.0.1:39360,DS-e647d22b-7f52-4132-8da6-3a3b8c13ffcd,DISK], DatanodeInfoWithStorage[127.0.0.1:44599,DS-4a29f5e1-4c98-4b0b-bc4e-9309f69c408d,DISK], DatanodeInfoWithStorage[127.0.0.1:43504,DS-e6f90059-a0a2-4aec-b57b-cdcbce272f8a,DISK], DatanodeInfoWithStorage[127.0.0.1:42016,DS-b9475cd1-5ff5-4b11-bd7f-f8ba1c07d5ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45336,DS-622fd05f-4890-48f6-a8ad-e26f1cd9171e,DISK], DatanodeInfoWithStorage[127.0.0.1:33752,DS-ef45c8d3-1e22-4497-81dc-6956fcfb7b51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.automatic.close
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1885072988-172.17.0.19-1596986744426:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33200,DS-cd705dc8-7795-4010-bd74-17e28e52227d,DISK], DatanodeInfoWithStorage[127.0.0.1:42524,DS-48e55a38-741e-4e3f-8d81-665aa1d60803,DISK], DatanodeInfoWithStorage[127.0.0.1:41051,DS-ac14779f-8cbe-4dc1-b6bc-a97dcc4391c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41309,DS-c8d73708-ca37-439d-81aa-637e85c5c320,DISK], DatanodeInfoWithStorage[127.0.0.1:37855,DS-5caa83eb-8ffd-46f3-ac28-fd248fbf4d03,DISK], DatanodeInfoWithStorage[127.0.0.1:33695,DS-73ad9964-7298-4ecd-97c1-de60eb3d47e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42305,DS-5351740c-d735-4864-8c72-188f066cf290,DISK], DatanodeInfoWithStorage[127.0.0.1:39077,DS-520ca48a-4c78-4a1f-96a2-4e25647c5d86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1885072988-172.17.0.19-1596986744426:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33200,DS-cd705dc8-7795-4010-bd74-17e28e52227d,DISK], DatanodeInfoWithStorage[127.0.0.1:42524,DS-48e55a38-741e-4e3f-8d81-665aa1d60803,DISK], DatanodeInfoWithStorage[127.0.0.1:41051,DS-ac14779f-8cbe-4dc1-b6bc-a97dcc4391c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41309,DS-c8d73708-ca37-439d-81aa-637e85c5c320,DISK], DatanodeInfoWithStorage[127.0.0.1:37855,DS-5caa83eb-8ffd-46f3-ac28-fd248fbf4d03,DISK], DatanodeInfoWithStorage[127.0.0.1:33695,DS-73ad9964-7298-4ecd-97c1-de60eb3d47e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42305,DS-5351740c-d735-4864-8c72-188f066cf290,DISK], DatanodeInfoWithStorage[127.0.0.1:39077,DS-520ca48a-4c78-4a1f-96a2-4e25647c5d86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.automatic.close
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1026834900-172.17.0.19-1596986814233:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45437,DS-4ed96ccd-4720-4019-9226-1435fd42ce39,DISK], DatanodeInfoWithStorage[127.0.0.1:34825,DS-31a4cd85-3850-4831-a2d3-cdf6cf8df399,DISK], DatanodeInfoWithStorage[127.0.0.1:38776,DS-ff37b13b-d88d-4448-a711-602e0f6f7fca,DISK], DatanodeInfoWithStorage[127.0.0.1:44812,DS-278383a2-6834-4796-bbca-b01e975bcfed,DISK], DatanodeInfoWithStorage[127.0.0.1:34806,DS-98295c38-c32d-4afc-a0ed-dbaa39c148ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42717,DS-3a8ed501-68ed-4a93-a2ef-466ab20feb0b,DISK], DatanodeInfoWithStorage[127.0.0.1:38041,DS-d83e8b05-51e6-45ca-b454-375f66a441f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42462,DS-e6afe13e-56e7-4c3d-b047-01c9c31baed8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1026834900-172.17.0.19-1596986814233:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45437,DS-4ed96ccd-4720-4019-9226-1435fd42ce39,DISK], DatanodeInfoWithStorage[127.0.0.1:34825,DS-31a4cd85-3850-4831-a2d3-cdf6cf8df399,DISK], DatanodeInfoWithStorage[127.0.0.1:38776,DS-ff37b13b-d88d-4448-a711-602e0f6f7fca,DISK], DatanodeInfoWithStorage[127.0.0.1:44812,DS-278383a2-6834-4796-bbca-b01e975bcfed,DISK], DatanodeInfoWithStorage[127.0.0.1:34806,DS-98295c38-c32d-4afc-a0ed-dbaa39c148ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42717,DS-3a8ed501-68ed-4a93-a2ef-466ab20feb0b,DISK], DatanodeInfoWithStorage[127.0.0.1:38041,DS-d83e8b05-51e6-45ca-b454-375f66a441f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42462,DS-e6afe13e-56e7-4c3d-b047-01c9c31baed8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.automatic.close
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1980416128-172.17.0.19-1596986947327:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42608,DS-a14477a9-6af0-4d18-9d01-3d1fa539df98,DISK], DatanodeInfoWithStorage[127.0.0.1:42092,DS-afe6b85d-a068-499f-8e58-da8891771296,DISK], DatanodeInfoWithStorage[127.0.0.1:33839,DS-2bd272e1-74f6-4edb-8f38-0e1363f0ee5c,DISK], DatanodeInfoWithStorage[127.0.0.1:35468,DS-32141c1d-43e7-4350-8fb4-20f504e2d5bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41056,DS-9dbfd601-61da-4eb8-a5a2-eddbc1562bb4,DISK], DatanodeInfoWithStorage[127.0.0.1:44786,DS-e5c8ebab-d452-4866-8981-2fe133335391,DISK], DatanodeInfoWithStorage[127.0.0.1:42883,DS-0541c78b-14c5-4a7b-b5fd-300f2e1b38dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39299,DS-7fca542f-fa35-41d0-abcb-ab2d6eb96a0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1980416128-172.17.0.19-1596986947327:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42608,DS-a14477a9-6af0-4d18-9d01-3d1fa539df98,DISK], DatanodeInfoWithStorage[127.0.0.1:42092,DS-afe6b85d-a068-499f-8e58-da8891771296,DISK], DatanodeInfoWithStorage[127.0.0.1:33839,DS-2bd272e1-74f6-4edb-8f38-0e1363f0ee5c,DISK], DatanodeInfoWithStorage[127.0.0.1:35468,DS-32141c1d-43e7-4350-8fb4-20f504e2d5bf,DISK], DatanodeInfoWithStorage[127.0.0.1:41056,DS-9dbfd601-61da-4eb8-a5a2-eddbc1562bb4,DISK], DatanodeInfoWithStorage[127.0.0.1:44786,DS-e5c8ebab-d452-4866-8981-2fe133335391,DISK], DatanodeInfoWithStorage[127.0.0.1:42883,DS-0541c78b-14c5-4a7b-b5fd-300f2e1b38dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39299,DS-7fca542f-fa35-41d0-abcb-ab2d6eb96a0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.automatic.close
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1808367843-172.17.0.19-1596987186624:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39160,DS-07cda1c5-2554-4d97-83c7-cf7d98f71066,DISK], DatanodeInfoWithStorage[127.0.0.1:46837,DS-9575ed08-efbe-4324-a890-445f1386d66b,DISK], DatanodeInfoWithStorage[127.0.0.1:40049,DS-ebb4972e-5844-448e-b010-32abea9eb79f,DISK], DatanodeInfoWithStorage[127.0.0.1:43987,DS-0d16308b-87bd-44d9-8ade-8b152f3a166b,DISK], DatanodeInfoWithStorage[127.0.0.1:46478,DS-6bb8de38-c696-4560-8f96-6f74258579cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40648,DS-f125cd8e-d107-41c8-b1df-030e35302513,DISK], DatanodeInfoWithStorage[127.0.0.1:34381,DS-6dfdf45b-2395-402f-b1ce-cf300b2bf056,DISK], DatanodeInfoWithStorage[127.0.0.1:43422,DS-43cdbdc6-31a4-4976-9a37-4a99eacdef01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1808367843-172.17.0.19-1596987186624:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39160,DS-07cda1c5-2554-4d97-83c7-cf7d98f71066,DISK], DatanodeInfoWithStorage[127.0.0.1:46837,DS-9575ed08-efbe-4324-a890-445f1386d66b,DISK], DatanodeInfoWithStorage[127.0.0.1:40049,DS-ebb4972e-5844-448e-b010-32abea9eb79f,DISK], DatanodeInfoWithStorage[127.0.0.1:43987,DS-0d16308b-87bd-44d9-8ade-8b152f3a166b,DISK], DatanodeInfoWithStorage[127.0.0.1:46478,DS-6bb8de38-c696-4560-8f96-6f74258579cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40648,DS-f125cd8e-d107-41c8-b1df-030e35302513,DISK], DatanodeInfoWithStorage[127.0.0.1:34381,DS-6dfdf45b-2395-402f-b1ce-cf300b2bf056,DISK], DatanodeInfoWithStorage[127.0.0.1:43422,DS-43cdbdc6-31a4-4976-9a37-4a99eacdef01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.automatic.close
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-728754173-172.17.0.19-1596987217611:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33814,DS-8ab982c6-9708-4e10-afb3-d4b9da7947fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37650,DS-d0490ae7-1f62-4189-aeaf-1ac594ffdb03,DISK], DatanodeInfoWithStorage[127.0.0.1:41945,DS-594c8456-e20c-46f1-bb4d-b2553e920b06,DISK], DatanodeInfoWithStorage[127.0.0.1:37699,DS-355faf22-a50f-48a2-af9d-67a7d14308f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42156,DS-6a0c476c-0552-4eb9-94ba-e8226dadb141,DISK], DatanodeInfoWithStorage[127.0.0.1:38378,DS-a436eec3-38a3-41cb-a0d0-c3ae74637695,DISK], DatanodeInfoWithStorage[127.0.0.1:35915,DS-05a271b2-a157-4b52-a53a-b355d57fe118,DISK], DatanodeInfoWithStorage[127.0.0.1:34054,DS-ad926600-5240-4400-ad6b-4c267c567ced,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-728754173-172.17.0.19-1596987217611:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33814,DS-8ab982c6-9708-4e10-afb3-d4b9da7947fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37650,DS-d0490ae7-1f62-4189-aeaf-1ac594ffdb03,DISK], DatanodeInfoWithStorage[127.0.0.1:41945,DS-594c8456-e20c-46f1-bb4d-b2553e920b06,DISK], DatanodeInfoWithStorage[127.0.0.1:37699,DS-355faf22-a50f-48a2-af9d-67a7d14308f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42156,DS-6a0c476c-0552-4eb9-94ba-e8226dadb141,DISK], DatanodeInfoWithStorage[127.0.0.1:38378,DS-a436eec3-38a3-41cb-a0d0-c3ae74637695,DISK], DatanodeInfoWithStorage[127.0.0.1:35915,DS-05a271b2-a157-4b52-a53a-b355d57fe118,DISK], DatanodeInfoWithStorage[127.0.0.1:34054,DS-ad926600-5240-4400-ad6b-4c267c567ced,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.automatic.close
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-290686689-172.17.0.19-1596987258427:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35030,DS-43d50c5e-37de-40d8-baea-664808144344,DISK], DatanodeInfoWithStorage[127.0.0.1:34140,DS-02bfa41a-8990-4ce8-a2aa-46790b1bc254,DISK], DatanodeInfoWithStorage[127.0.0.1:34587,DS-af709231-2988-4e2a-b491-76120d7e518f,DISK], DatanodeInfoWithStorage[127.0.0.1:34846,DS-b3dad308-47ca-4312-86c3-3eab910401a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45457,DS-58a8c674-56d1-4495-9417-0117088629e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36208,DS-e8a377a7-3506-4fe3-83ad-9eb12a9c4fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:33578,DS-61205f5a-b3e1-413d-992c-f187e21746be,DISK], DatanodeInfoWithStorage[127.0.0.1:43232,DS-2096d3d5-0cf9-433e-904b-f7d633da6466,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-290686689-172.17.0.19-1596987258427:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35030,DS-43d50c5e-37de-40d8-baea-664808144344,DISK], DatanodeInfoWithStorage[127.0.0.1:34140,DS-02bfa41a-8990-4ce8-a2aa-46790b1bc254,DISK], DatanodeInfoWithStorage[127.0.0.1:34587,DS-af709231-2988-4e2a-b491-76120d7e518f,DISK], DatanodeInfoWithStorage[127.0.0.1:34846,DS-b3dad308-47ca-4312-86c3-3eab910401a7,DISK], DatanodeInfoWithStorage[127.0.0.1:45457,DS-58a8c674-56d1-4495-9417-0117088629e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36208,DS-e8a377a7-3506-4fe3-83ad-9eb12a9c4fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:33578,DS-61205f5a-b3e1-413d-992c-f187e21746be,DISK], DatanodeInfoWithStorage[127.0.0.1:43232,DS-2096d3d5-0cf9-433e-904b-f7d633da6466,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.automatic.close
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2098708029-172.17.0.19-1596987427940:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37945,DS-ea682c87-f2b3-498b-ba7a-e334c357d9f7,DISK], DatanodeInfoWithStorage[127.0.0.1:43164,DS-3d2af445-ad64-4cf8-b990-4ed639e3ae75,DISK], DatanodeInfoWithStorage[127.0.0.1:43522,DS-682626df-875b-4fc3-841d-e628ce31ace3,DISK], DatanodeInfoWithStorage[127.0.0.1:37615,DS-af449ad6-5490-4878-ba9f-bc86c13621f9,DISK], DatanodeInfoWithStorage[127.0.0.1:46572,DS-9999d132-9b91-4f9e-b063-b4651fa10e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:42640,DS-4f40c305-f20a-42c0-b472-330136c4f5c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35097,DS-488f6467-5d6e-4a4e-898b-81e4f2af495c,DISK], DatanodeInfoWithStorage[127.0.0.1:33403,DS-0e4ee5ad-651f-4a4d-ab39-8927e4616b00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2098708029-172.17.0.19-1596987427940:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37945,DS-ea682c87-f2b3-498b-ba7a-e334c357d9f7,DISK], DatanodeInfoWithStorage[127.0.0.1:43164,DS-3d2af445-ad64-4cf8-b990-4ed639e3ae75,DISK], DatanodeInfoWithStorage[127.0.0.1:43522,DS-682626df-875b-4fc3-841d-e628ce31ace3,DISK], DatanodeInfoWithStorage[127.0.0.1:37615,DS-af449ad6-5490-4878-ba9f-bc86c13621f9,DISK], DatanodeInfoWithStorage[127.0.0.1:46572,DS-9999d132-9b91-4f9e-b063-b4651fa10e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:42640,DS-4f40c305-f20a-42c0-b472-330136c4f5c4,DISK], DatanodeInfoWithStorage[127.0.0.1:35097,DS-488f6467-5d6e-4a4e-898b-81e4f2af495c,DISK], DatanodeInfoWithStorage[127.0.0.1:33403,DS-0e4ee5ad-651f-4a4d-ab39-8927e4616b00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.automatic.close
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1559368504-172.17.0.19-1596987528197:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42950,DS-1f73bed6-7893-49a4-84a7-0935d48a9013,DISK], DatanodeInfoWithStorage[127.0.0.1:44196,DS-66334f7b-844f-4dc1-9d6f-85581590c993,DISK], DatanodeInfoWithStorage[127.0.0.1:45536,DS-6d4ca7d9-a46d-434f-b768-f809c33baeff,DISK], DatanodeInfoWithStorage[127.0.0.1:40569,DS-a7f24642-fdd6-4863-817e-d39e84c063f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41669,DS-8de8b097-047f-4142-946e-9aa9e985b1c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34446,DS-0f7a5953-3413-4a74-a878-ecae11eecbeb,DISK], DatanodeInfoWithStorage[127.0.0.1:37832,DS-f831ab83-b45a-4ef5-bd8c-3ee65a1f4a73,DISK], DatanodeInfoWithStorage[127.0.0.1:35393,DS-ebc7f5e1-251d-4390-a49d-2a3839f73820,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1559368504-172.17.0.19-1596987528197:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42950,DS-1f73bed6-7893-49a4-84a7-0935d48a9013,DISK], DatanodeInfoWithStorage[127.0.0.1:44196,DS-66334f7b-844f-4dc1-9d6f-85581590c993,DISK], DatanodeInfoWithStorage[127.0.0.1:45536,DS-6d4ca7d9-a46d-434f-b768-f809c33baeff,DISK], DatanodeInfoWithStorage[127.0.0.1:40569,DS-a7f24642-fdd6-4863-817e-d39e84c063f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41669,DS-8de8b097-047f-4142-946e-9aa9e985b1c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34446,DS-0f7a5953-3413-4a74-a878-ecae11eecbeb,DISK], DatanodeInfoWithStorage[127.0.0.1:37832,DS-f831ab83-b45a-4ef5-bd8c-3ee65a1f4a73,DISK], DatanodeInfoWithStorage[127.0.0.1:35393,DS-ebc7f5e1-251d-4390-a49d-2a3839f73820,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.automatic.close
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-459854616-172.17.0.19-1596987560521:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37391,DS-30e7717c-8bde-451c-8862-da2bda7024a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34952,DS-fe4da596-c880-419f-8565-53cb56413eae,DISK], DatanodeInfoWithStorage[127.0.0.1:43265,DS-a5c0dad5-8590-4a16-bdd0-69021e0cd137,DISK], DatanodeInfoWithStorage[127.0.0.1:36170,DS-2d3e3099-eb7d-4b64-84b1-fade5a910346,DISK], DatanodeInfoWithStorage[127.0.0.1:39355,DS-cfe9a470-0a8a-4d7c-9950-ed532f704201,DISK], DatanodeInfoWithStorage[127.0.0.1:37307,DS-23436515-ebc1-4a05-a053-25732efba596,DISK], DatanodeInfoWithStorage[127.0.0.1:38827,DS-83321bbd-28c0-4cb6-b37b-6fe4cc0e1732,DISK], DatanodeInfoWithStorage[127.0.0.1:34917,DS-c0fbf758-4188-4a28-a35f-8b0ca44a76b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-459854616-172.17.0.19-1596987560521:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37391,DS-30e7717c-8bde-451c-8862-da2bda7024a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34952,DS-fe4da596-c880-419f-8565-53cb56413eae,DISK], DatanodeInfoWithStorage[127.0.0.1:43265,DS-a5c0dad5-8590-4a16-bdd0-69021e0cd137,DISK], DatanodeInfoWithStorage[127.0.0.1:36170,DS-2d3e3099-eb7d-4b64-84b1-fade5a910346,DISK], DatanodeInfoWithStorage[127.0.0.1:39355,DS-cfe9a470-0a8a-4d7c-9950-ed532f704201,DISK], DatanodeInfoWithStorage[127.0.0.1:37307,DS-23436515-ebc1-4a05-a053-25732efba596,DISK], DatanodeInfoWithStorage[127.0.0.1:38827,DS-83321bbd-28c0-4cb6-b37b-6fe4cc0e1732,DISK], DatanodeInfoWithStorage[127.0.0.1:34917,DS-c0fbf758-4188-4a28-a35f-8b0ca44a76b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.automatic.close
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-366655118-172.17.0.19-1596987921765:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46003,DS-6fed8f8f-3791-40a7-98d1-aa8bbdbded31,DISK], DatanodeInfoWithStorage[127.0.0.1:37783,DS-8c9a5fbc-6fbd-445f-9de4-663979c321dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45724,DS-64478abd-4fc6-4633-9392-83523bd1eb86,DISK], DatanodeInfoWithStorage[127.0.0.1:34102,DS-1e050794-e716-4b52-b7f4-7894a8531e64,DISK], DatanodeInfoWithStorage[127.0.0.1:44341,DS-8f5ff2df-cd47-4ba7-8fde-92fa9ccccffe,DISK], DatanodeInfoWithStorage[127.0.0.1:43318,DS-fe57cd29-e945-4989-a918-e95821906036,DISK], DatanodeInfoWithStorage[127.0.0.1:38135,DS-563d2fc3-1cf1-4e72-a9c5-556ed39f4829,DISK], DatanodeInfoWithStorage[127.0.0.1:34641,DS-583adfb2-08d5-49e4-a200-6d5eebc4bcce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-366655118-172.17.0.19-1596987921765:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46003,DS-6fed8f8f-3791-40a7-98d1-aa8bbdbded31,DISK], DatanodeInfoWithStorage[127.0.0.1:37783,DS-8c9a5fbc-6fbd-445f-9de4-663979c321dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45724,DS-64478abd-4fc6-4633-9392-83523bd1eb86,DISK], DatanodeInfoWithStorage[127.0.0.1:34102,DS-1e050794-e716-4b52-b7f4-7894a8531e64,DISK], DatanodeInfoWithStorage[127.0.0.1:44341,DS-8f5ff2df-cd47-4ba7-8fde-92fa9ccccffe,DISK], DatanodeInfoWithStorage[127.0.0.1:43318,DS-fe57cd29-e945-4989-a918-e95821906036,DISK], DatanodeInfoWithStorage[127.0.0.1:38135,DS-563d2fc3-1cf1-4e72-a9c5-556ed39f4829,DISK], DatanodeInfoWithStorage[127.0.0.1:34641,DS-583adfb2-08d5-49e4-a200-6d5eebc4bcce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.automatic.close
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-371395693-172.17.0.19-1596988052974:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36131,DS-8b14e101-a11a-44f2-af9f-d98d91398f17,DISK], DatanodeInfoWithStorage[127.0.0.1:40628,DS-ceb5208d-18cf-474f-845e-530bdab5a36e,DISK], DatanodeInfoWithStorage[127.0.0.1:45650,DS-c4e983c6-519b-4ff6-9222-7e88f27d95dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37403,DS-4c2a2dc6-01f2-4785-8cb4-73e7dc8dc05d,DISK], DatanodeInfoWithStorage[127.0.0.1:34725,DS-0e0295f3-0466-455b-8a43-b2fa692b8d0d,DISK], DatanodeInfoWithStorage[127.0.0.1:36043,DS-05eeee48-6e7c-4069-ae44-da03132590a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36994,DS-95e6d15b-9f49-42de-996c-2eae7b17b41e,DISK], DatanodeInfoWithStorage[127.0.0.1:40680,DS-31df9120-cd53-49be-a7ee-2fc7d7b68401,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-371395693-172.17.0.19-1596988052974:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36131,DS-8b14e101-a11a-44f2-af9f-d98d91398f17,DISK], DatanodeInfoWithStorage[127.0.0.1:40628,DS-ceb5208d-18cf-474f-845e-530bdab5a36e,DISK], DatanodeInfoWithStorage[127.0.0.1:45650,DS-c4e983c6-519b-4ff6-9222-7e88f27d95dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37403,DS-4c2a2dc6-01f2-4785-8cb4-73e7dc8dc05d,DISK], DatanodeInfoWithStorage[127.0.0.1:34725,DS-0e0295f3-0466-455b-8a43-b2fa692b8d0d,DISK], DatanodeInfoWithStorage[127.0.0.1:36043,DS-05eeee48-6e7c-4069-ae44-da03132590a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36994,DS-95e6d15b-9f49-42de-996c-2eae7b17b41e,DISK], DatanodeInfoWithStorage[127.0.0.1:40680,DS-31df9120-cd53-49be-a7ee-2fc7d7b68401,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.automatic.close
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-190220082-172.17.0.19-1596988217047:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36002,DS-38e7a5ae-d272-4a18-81e4-d78ee31ef00e,DISK], DatanodeInfoWithStorage[127.0.0.1:36216,DS-ef132160-4767-4363-baee-264d5ad5b24f,DISK], DatanodeInfoWithStorage[127.0.0.1:35632,DS-f6871ce7-2bf0-4a9b-8d3d-67496de9a610,DISK], DatanodeInfoWithStorage[127.0.0.1:36433,DS-f1ce1a1d-47e9-4eba-92b0-09b880ba2436,DISK], DatanodeInfoWithStorage[127.0.0.1:42582,DS-50706a2a-83e2-4521-9843-8aeacf0ef8df,DISK], DatanodeInfoWithStorage[127.0.0.1:36795,DS-62d55df2-43a6-4843-92b6-bdab71858f64,DISK], DatanodeInfoWithStorage[127.0.0.1:46711,DS-691a95d7-03c7-4a1d-9764-97c1bd4f004b,DISK], DatanodeInfoWithStorage[127.0.0.1:37559,DS-5c5bd03d-54d3-405e-80e6-54cd040406c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-190220082-172.17.0.19-1596988217047:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36002,DS-38e7a5ae-d272-4a18-81e4-d78ee31ef00e,DISK], DatanodeInfoWithStorage[127.0.0.1:36216,DS-ef132160-4767-4363-baee-264d5ad5b24f,DISK], DatanodeInfoWithStorage[127.0.0.1:35632,DS-f6871ce7-2bf0-4a9b-8d3d-67496de9a610,DISK], DatanodeInfoWithStorage[127.0.0.1:36433,DS-f1ce1a1d-47e9-4eba-92b0-09b880ba2436,DISK], DatanodeInfoWithStorage[127.0.0.1:42582,DS-50706a2a-83e2-4521-9843-8aeacf0ef8df,DISK], DatanodeInfoWithStorage[127.0.0.1:36795,DS-62d55df2-43a6-4843-92b6-bdab71858f64,DISK], DatanodeInfoWithStorage[127.0.0.1:46711,DS-691a95d7-03c7-4a1d-9764-97c1bd4f004b,DISK], DatanodeInfoWithStorage[127.0.0.1:37559,DS-5c5bd03d-54d3-405e-80e6-54cd040406c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.automatic.close
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-113098327-172.17.0.19-1596988348793:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36741,DS-50b04d23-7956-4af4-b20c-50bf0e96eee5,DISK], DatanodeInfoWithStorage[127.0.0.1:44876,DS-aaa79e8c-a481-4469-bb2f-ed14c7b1454d,DISK], DatanodeInfoWithStorage[127.0.0.1:40354,DS-957257a3-2eb2-4a72-a04a-f4e44dfd9752,DISK], DatanodeInfoWithStorage[127.0.0.1:44762,DS-d8b6f054-3a5b-4414-b94a-be31dfd33415,DISK], DatanodeInfoWithStorage[127.0.0.1:39040,DS-3b6ec870-b060-4cf5-a743-4044e165d3bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36876,DS-6e01186b-dc79-4a7d-a4eb-ab786d574e63,DISK], DatanodeInfoWithStorage[127.0.0.1:43445,DS-f40d9d7b-3804-4268-8f44-1120ad1dab83,DISK], DatanodeInfoWithStorage[127.0.0.1:44535,DS-6d2ee006-452c-4887-bfd1-111c42380a43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-113098327-172.17.0.19-1596988348793:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36741,DS-50b04d23-7956-4af4-b20c-50bf0e96eee5,DISK], DatanodeInfoWithStorage[127.0.0.1:44876,DS-aaa79e8c-a481-4469-bb2f-ed14c7b1454d,DISK], DatanodeInfoWithStorage[127.0.0.1:40354,DS-957257a3-2eb2-4a72-a04a-f4e44dfd9752,DISK], DatanodeInfoWithStorage[127.0.0.1:44762,DS-d8b6f054-3a5b-4414-b94a-be31dfd33415,DISK], DatanodeInfoWithStorage[127.0.0.1:39040,DS-3b6ec870-b060-4cf5-a743-4044e165d3bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36876,DS-6e01186b-dc79-4a7d-a4eb-ab786d574e63,DISK], DatanodeInfoWithStorage[127.0.0.1:43445,DS-f40d9d7b-3804-4268-8f44-1120ad1dab83,DISK], DatanodeInfoWithStorage[127.0.0.1:44535,DS-6d2ee006-452c-4887-bfd1-111c42380a43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.automatic.close
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-446322282-172.17.0.19-1596988479118:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41959,DS-310c6b0e-26fb-4398-ab2b-468141d3fc29,DISK], DatanodeInfoWithStorage[127.0.0.1:46214,DS-ac480171-c73e-4201-a597-dd414cc6de54,DISK], DatanodeInfoWithStorage[127.0.0.1:37262,DS-5360c912-3b2e-4a07-a613-f7f696d6aafd,DISK], DatanodeInfoWithStorage[127.0.0.1:40227,DS-24dfd28d-a4ae-47df-a937-3a7d307cde28,DISK], DatanodeInfoWithStorage[127.0.0.1:43281,DS-fd81d528-faee-4cb3-b97f-f650e56cb3c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34109,DS-8286b1d7-4387-4877-9c34-7fed5b724f44,DISK], DatanodeInfoWithStorage[127.0.0.1:40212,DS-69d03683-ac9a-4538-8bcc-1540ad59d4db,DISK], DatanodeInfoWithStorage[127.0.0.1:37360,DS-c86eef89-40c5-4e9f-a28e-6b9c7736a498,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-446322282-172.17.0.19-1596988479118:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41959,DS-310c6b0e-26fb-4398-ab2b-468141d3fc29,DISK], DatanodeInfoWithStorage[127.0.0.1:46214,DS-ac480171-c73e-4201-a597-dd414cc6de54,DISK], DatanodeInfoWithStorage[127.0.0.1:37262,DS-5360c912-3b2e-4a07-a613-f7f696d6aafd,DISK], DatanodeInfoWithStorage[127.0.0.1:40227,DS-24dfd28d-a4ae-47df-a937-3a7d307cde28,DISK], DatanodeInfoWithStorage[127.0.0.1:43281,DS-fd81d528-faee-4cb3-b97f-f650e56cb3c9,DISK], DatanodeInfoWithStorage[127.0.0.1:34109,DS-8286b1d7-4387-4877-9c34-7fed5b724f44,DISK], DatanodeInfoWithStorage[127.0.0.1:40212,DS-69d03683-ac9a-4538-8bcc-1540ad59d4db,DISK], DatanodeInfoWithStorage[127.0.0.1:37360,DS-c86eef89-40c5-4e9f-a28e-6b9c7736a498,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.automatic.close
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-945482750-172.17.0.19-1596988627846:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38695,DS-2f62c3d7-8917-4b66-99dd-5e636098dc2c,DISK], DatanodeInfoWithStorage[127.0.0.1:46430,DS-3b17ccae-335e-4e75-a68b-0dfc3ea0a87f,DISK], DatanodeInfoWithStorage[127.0.0.1:43075,DS-8db65611-c873-47de-85a2-0eb67a62804f,DISK], DatanodeInfoWithStorage[127.0.0.1:36515,DS-06d267f2-43ab-4a83-ab37-e71563c92468,DISK], DatanodeInfoWithStorage[127.0.0.1:43699,DS-8fee9030-9a2b-4eb3-bd3b-b81d2ce71838,DISK], DatanodeInfoWithStorage[127.0.0.1:42335,DS-67001dc9-6e7f-4b1c-ab63-14a0e6729a68,DISK], DatanodeInfoWithStorage[127.0.0.1:44143,DS-5b091160-f2f5-4361-b898-c66de14d0214,DISK], DatanodeInfoWithStorage[127.0.0.1:42809,DS-b1248395-7d4a-44b2-a7a9-389ad84560cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-945482750-172.17.0.19-1596988627846:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38695,DS-2f62c3d7-8917-4b66-99dd-5e636098dc2c,DISK], DatanodeInfoWithStorage[127.0.0.1:46430,DS-3b17ccae-335e-4e75-a68b-0dfc3ea0a87f,DISK], DatanodeInfoWithStorage[127.0.0.1:43075,DS-8db65611-c873-47de-85a2-0eb67a62804f,DISK], DatanodeInfoWithStorage[127.0.0.1:36515,DS-06d267f2-43ab-4a83-ab37-e71563c92468,DISK], DatanodeInfoWithStorage[127.0.0.1:43699,DS-8fee9030-9a2b-4eb3-bd3b-b81d2ce71838,DISK], DatanodeInfoWithStorage[127.0.0.1:42335,DS-67001dc9-6e7f-4b1c-ab63-14a0e6729a68,DISK], DatanodeInfoWithStorage[127.0.0.1:44143,DS-5b091160-f2f5-4361-b898-c66de14d0214,DISK], DatanodeInfoWithStorage[127.0.0.1:42809,DS-b1248395-7d4a-44b2-a7a9-389ad84560cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.automatic.close
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1875747384-172.17.0.19-1596988709532:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36599,DS-d5779bba-7875-40ae-a69c-b6ef8fc14ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:41647,DS-55325b4f-7067-4a1a-922f-0cd518089b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:46519,DS-3d514aa1-5664-4df8-83c9-79a5635b9725,DISK], DatanodeInfoWithStorage[127.0.0.1:40190,DS-d251c37c-4f05-49b8-ab6e-8771dbe5daf8,DISK], DatanodeInfoWithStorage[127.0.0.1:46575,DS-5dc523ad-6cdc-4354-beea-d17cd25a3dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:37628,DS-a0d4862c-251e-48a4-a0b3-ba1062db3caa,DISK], DatanodeInfoWithStorage[127.0.0.1:43345,DS-244ad1f0-d85c-4c14-bef7-5ba97b5b0d90,DISK], DatanodeInfoWithStorage[127.0.0.1:44994,DS-7daac706-46f5-4eb8-8e4f-11f6a8fa8e46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1875747384-172.17.0.19-1596988709532:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36599,DS-d5779bba-7875-40ae-a69c-b6ef8fc14ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:41647,DS-55325b4f-7067-4a1a-922f-0cd518089b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:46519,DS-3d514aa1-5664-4df8-83c9-79a5635b9725,DISK], DatanodeInfoWithStorage[127.0.0.1:40190,DS-d251c37c-4f05-49b8-ab6e-8771dbe5daf8,DISK], DatanodeInfoWithStorage[127.0.0.1:46575,DS-5dc523ad-6cdc-4354-beea-d17cd25a3dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:37628,DS-a0d4862c-251e-48a4-a0b3-ba1062db3caa,DISK], DatanodeInfoWithStorage[127.0.0.1:43345,DS-244ad1f0-d85c-4c14-bef7-5ba97b5b0d90,DISK], DatanodeInfoWithStorage[127.0.0.1:44994,DS-7daac706-46f5-4eb8-8e4f-11f6a8fa8e46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.automatic.close
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1495146277-172.17.0.19-1596988742683:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40158,DS-b1f6f60e-518b-47a7-a121-4c549c50d1f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36834,DS-884950c1-ec49-4d56-a7d1-b0a99ddaa551,DISK], DatanodeInfoWithStorage[127.0.0.1:45998,DS-a2a7fdbc-c3c9-4564-8100-59e916b7eb2f,DISK], DatanodeInfoWithStorage[127.0.0.1:39192,DS-0ea13ec3-d043-4604-aa02-646107df9e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:42298,DS-5f260606-2ca8-4baf-9e7d-ba51da1a038a,DISK], DatanodeInfoWithStorage[127.0.0.1:44481,DS-45e61f36-06e8-4a67-bc69-c0c107674c72,DISK], DatanodeInfoWithStorage[127.0.0.1:33861,DS-8254ac12-b5ed-4844-b3f9-d96299437b91,DISK], DatanodeInfoWithStorage[127.0.0.1:38475,DS-ac6e750d-0503-456c-8f51-59d8fc001697,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1495146277-172.17.0.19-1596988742683:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40158,DS-b1f6f60e-518b-47a7-a121-4c549c50d1f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36834,DS-884950c1-ec49-4d56-a7d1-b0a99ddaa551,DISK], DatanodeInfoWithStorage[127.0.0.1:45998,DS-a2a7fdbc-c3c9-4564-8100-59e916b7eb2f,DISK], DatanodeInfoWithStorage[127.0.0.1:39192,DS-0ea13ec3-d043-4604-aa02-646107df9e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:42298,DS-5f260606-2ca8-4baf-9e7d-ba51da1a038a,DISK], DatanodeInfoWithStorage[127.0.0.1:44481,DS-45e61f36-06e8-4a67-bc69-c0c107674c72,DISK], DatanodeInfoWithStorage[127.0.0.1:33861,DS-8254ac12-b5ed-4844-b3f9-d96299437b91,DISK], DatanodeInfoWithStorage[127.0.0.1:38475,DS-ac6e750d-0503-456c-8f51-59d8fc001697,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 16 out of 50
result: false positive !!!
Total execution time in seconds : 3752
