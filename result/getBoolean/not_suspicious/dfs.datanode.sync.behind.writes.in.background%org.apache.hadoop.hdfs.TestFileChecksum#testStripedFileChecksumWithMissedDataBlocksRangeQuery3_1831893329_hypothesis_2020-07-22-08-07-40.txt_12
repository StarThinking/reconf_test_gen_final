reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1178414416-172.17.0.3-1595405275403:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35544,DS-c24beda7-02b0-4f02-a353-aeedfea4a51f,DISK], DatanodeInfoWithStorage[127.0.0.1:45223,DS-bf514496-1bca-494e-b76e-4ac588fd0b71,DISK], DatanodeInfoWithStorage[127.0.0.1:33841,DS-28583f27-3c6a-45d0-9b84-8176859b2930,DISK], DatanodeInfoWithStorage[127.0.0.1:39129,DS-82b33b31-e7e1-4d4e-9079-a27ebd3cb7f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35549,DS-e1ee18aa-003f-496a-b946-802982a31fb4,DISK], DatanodeInfoWithStorage[127.0.0.1:32901,DS-c04b9db6-1c6b-408d-b977-b5f895d37be2,DISK], DatanodeInfoWithStorage[127.0.0.1:44461,DS-42de8a4c-42e0-47b6-b940-3141eee8b333,DISK], DatanodeInfoWithStorage[127.0.0.1:44350,DS-a654d78b-e79b-467c-9cd9-1d32d9d0a7a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1178414416-172.17.0.3-1595405275403:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35544,DS-c24beda7-02b0-4f02-a353-aeedfea4a51f,DISK], DatanodeInfoWithStorage[127.0.0.1:45223,DS-bf514496-1bca-494e-b76e-4ac588fd0b71,DISK], DatanodeInfoWithStorage[127.0.0.1:33841,DS-28583f27-3c6a-45d0-9b84-8176859b2930,DISK], DatanodeInfoWithStorage[127.0.0.1:39129,DS-82b33b31-e7e1-4d4e-9079-a27ebd3cb7f3,DISK], DatanodeInfoWithStorage[127.0.0.1:35549,DS-e1ee18aa-003f-496a-b946-802982a31fb4,DISK], DatanodeInfoWithStorage[127.0.0.1:32901,DS-c04b9db6-1c6b-408d-b977-b5f895d37be2,DISK], DatanodeInfoWithStorage[127.0.0.1:44461,DS-42de8a4c-42e0-47b6-b940-3141eee8b333,DISK], DatanodeInfoWithStorage[127.0.0.1:44350,DS-a654d78b-e79b-467c-9cd9-1d32d9d0a7a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2031578498-172.17.0.3-1595405380265:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40193,DS-fefae1f7-d505-4c14-8aa2-2cfa18b1e957,DISK], DatanodeInfoWithStorage[127.0.0.1:39979,DS-d6649cd8-82e2-4e22-aedb-f58f25a0cd60,DISK], DatanodeInfoWithStorage[127.0.0.1:37116,DS-1ae427c6-4a85-49e4-aa29-bf9aadddaa5f,DISK], DatanodeInfoWithStorage[127.0.0.1:34825,DS-160509ae-f216-44d5-82cf-fe4178a8c7a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44907,DS-d7ce7a79-696d-4b37-8447-090196a6762b,DISK], DatanodeInfoWithStorage[127.0.0.1:33316,DS-069d786f-5445-4585-8b7c-1f1482a6ee24,DISK], DatanodeInfoWithStorage[127.0.0.1:36960,DS-a166a296-542f-4e77-b0de-9019871b4da9,DISK], DatanodeInfoWithStorage[127.0.0.1:44007,DS-5647289c-f11d-411f-a825-dd0a13f9a396,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2031578498-172.17.0.3-1595405380265:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40193,DS-fefae1f7-d505-4c14-8aa2-2cfa18b1e957,DISK], DatanodeInfoWithStorage[127.0.0.1:39979,DS-d6649cd8-82e2-4e22-aedb-f58f25a0cd60,DISK], DatanodeInfoWithStorage[127.0.0.1:37116,DS-1ae427c6-4a85-49e4-aa29-bf9aadddaa5f,DISK], DatanodeInfoWithStorage[127.0.0.1:34825,DS-160509ae-f216-44d5-82cf-fe4178a8c7a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44907,DS-d7ce7a79-696d-4b37-8447-090196a6762b,DISK], DatanodeInfoWithStorage[127.0.0.1:33316,DS-069d786f-5445-4585-8b7c-1f1482a6ee24,DISK], DatanodeInfoWithStorage[127.0.0.1:36960,DS-a166a296-542f-4e77-b0de-9019871b4da9,DISK], DatanodeInfoWithStorage[127.0.0.1:44007,DS-5647289c-f11d-411f-a825-dd0a13f9a396,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1548106552-172.17.0.3-1595405579287:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37095,DS-8b865031-44ce-49b7-a9bc-1c8b5c4553e8,DISK], DatanodeInfoWithStorage[127.0.0.1:33681,DS-2edb72b3-84a0-4b30-9293-e1e062038366,DISK], DatanodeInfoWithStorage[127.0.0.1:36079,DS-f379f160-1f40-45eb-bd72-7592a30fe12b,DISK], DatanodeInfoWithStorage[127.0.0.1:41258,DS-7a4edfb5-0fb7-412b-abfe-447e860801f8,DISK], DatanodeInfoWithStorage[127.0.0.1:42572,DS-6c75c444-db0b-492d-b0ef-2ff2e66412c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34850,DS-a252eb78-4bac-4234-8355-68225954ce7a,DISK], DatanodeInfoWithStorage[127.0.0.1:44728,DS-94710df2-3bd5-4593-918f-71d94e6f91d6,DISK], DatanodeInfoWithStorage[127.0.0.1:36830,DS-93c0cb61-f0db-4c6c-b3c9-a033567c8e9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1548106552-172.17.0.3-1595405579287:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37095,DS-8b865031-44ce-49b7-a9bc-1c8b5c4553e8,DISK], DatanodeInfoWithStorage[127.0.0.1:33681,DS-2edb72b3-84a0-4b30-9293-e1e062038366,DISK], DatanodeInfoWithStorage[127.0.0.1:36079,DS-f379f160-1f40-45eb-bd72-7592a30fe12b,DISK], DatanodeInfoWithStorage[127.0.0.1:41258,DS-7a4edfb5-0fb7-412b-abfe-447e860801f8,DISK], DatanodeInfoWithStorage[127.0.0.1:42572,DS-6c75c444-db0b-492d-b0ef-2ff2e66412c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34850,DS-a252eb78-4bac-4234-8355-68225954ce7a,DISK], DatanodeInfoWithStorage[127.0.0.1:44728,DS-94710df2-3bd5-4593-918f-71d94e6f91d6,DISK], DatanodeInfoWithStorage[127.0.0.1:36830,DS-93c0cb61-f0db-4c6c-b3c9-a033567c8e9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-395246-172.17.0.3-1595406170405:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46509,DS-270bbd24-c809-446e-be3d-7883f64ecf7d,DISK], DatanodeInfoWithStorage[127.0.0.1:44828,DS-9de36390-38e2-46c6-8031-f5777f5eed7e,DISK], DatanodeInfoWithStorage[127.0.0.1:43597,DS-f488f300-9177-4af4-85d1-80d750522ce5,DISK], DatanodeInfoWithStorage[127.0.0.1:45712,DS-92f03497-265f-4e01-a9ed-94bf015f79cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33169,DS-56db6ec7-8d2a-4f31-9abc-860ed5918f09,DISK], DatanodeInfoWithStorage[127.0.0.1:41647,DS-ec619241-2484-4ef7-b0a5-87f0fd3035c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45114,DS-faba460c-587d-468e-98c4-6cf803af248c,DISK], DatanodeInfoWithStorage[127.0.0.1:45795,DS-c7f715df-a354-44c3-b8d3-dba6dd8df839,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-395246-172.17.0.3-1595406170405:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46509,DS-270bbd24-c809-446e-be3d-7883f64ecf7d,DISK], DatanodeInfoWithStorage[127.0.0.1:44828,DS-9de36390-38e2-46c6-8031-f5777f5eed7e,DISK], DatanodeInfoWithStorage[127.0.0.1:43597,DS-f488f300-9177-4af4-85d1-80d750522ce5,DISK], DatanodeInfoWithStorage[127.0.0.1:45712,DS-92f03497-265f-4e01-a9ed-94bf015f79cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33169,DS-56db6ec7-8d2a-4f31-9abc-860ed5918f09,DISK], DatanodeInfoWithStorage[127.0.0.1:41647,DS-ec619241-2484-4ef7-b0a5-87f0fd3035c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45114,DS-faba460c-587d-468e-98c4-6cf803af248c,DISK], DatanodeInfoWithStorage[127.0.0.1:45795,DS-c7f715df-a354-44c3-b8d3-dba6dd8df839,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2017223242-172.17.0.3-1595406928127:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45157,DS-51cea57b-20a4-4e98-a3e4-c1ed800e9f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:45533,DS-87905928-ee8c-4792-b1ab-ce7d6a170b83,DISK], DatanodeInfoWithStorage[127.0.0.1:44282,DS-8fa1caa1-e20a-4dec-85dd-fa08da24f695,DISK], DatanodeInfoWithStorage[127.0.0.1:37351,DS-f07dc57a-cb3c-4b94-ad2a-ffb4d554bcbf,DISK], DatanodeInfoWithStorage[127.0.0.1:33118,DS-27cf5fb4-d5dd-453c-9cf0-893ea4b8391b,DISK], DatanodeInfoWithStorage[127.0.0.1:39150,DS-770c6709-4d58-4c10-9d17-66c592214995,DISK], DatanodeInfoWithStorage[127.0.0.1:34805,DS-5a6ae37e-c594-4e0c-95dd-33d07c518022,DISK], DatanodeInfoWithStorage[127.0.0.1:45379,DS-a559c10a-393f-42e3-8bf1-3283be35e672,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2017223242-172.17.0.3-1595406928127:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45157,DS-51cea57b-20a4-4e98-a3e4-c1ed800e9f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:45533,DS-87905928-ee8c-4792-b1ab-ce7d6a170b83,DISK], DatanodeInfoWithStorage[127.0.0.1:44282,DS-8fa1caa1-e20a-4dec-85dd-fa08da24f695,DISK], DatanodeInfoWithStorage[127.0.0.1:37351,DS-f07dc57a-cb3c-4b94-ad2a-ffb4d554bcbf,DISK], DatanodeInfoWithStorage[127.0.0.1:33118,DS-27cf5fb4-d5dd-453c-9cf0-893ea4b8391b,DISK], DatanodeInfoWithStorage[127.0.0.1:39150,DS-770c6709-4d58-4c10-9d17-66c592214995,DISK], DatanodeInfoWithStorage[127.0.0.1:34805,DS-5a6ae37e-c594-4e0c-95dd-33d07c518022,DISK], DatanodeInfoWithStorage[127.0.0.1:45379,DS-a559c10a-393f-42e3-8bf1-3283be35e672,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-727992429-172.17.0.3-1595407081205:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32841,DS-0f03dac6-b661-4aaf-a35b-7f1083c5631a,DISK], DatanodeInfoWithStorage[127.0.0.1:41989,DS-52441b41-f045-467b-9c27-dcf01f3f3233,DISK], DatanodeInfoWithStorage[127.0.0.1:36376,DS-8cd1bc00-7acd-441f-9f90-cbbc9fc93029,DISK], DatanodeInfoWithStorage[127.0.0.1:44362,DS-39e264de-ee47-41b0-80c8-2160f1889453,DISK], DatanodeInfoWithStorage[127.0.0.1:39341,DS-97b29b6c-94f1-4152-b760-9a19f2d94744,DISK], DatanodeInfoWithStorage[127.0.0.1:45992,DS-477322c7-c313-40ec-91a3-5652f27fcb25,DISK], DatanodeInfoWithStorage[127.0.0.1:44842,DS-eb023b0b-0512-463f-a221-331316e9286d,DISK], DatanodeInfoWithStorage[127.0.0.1:43659,DS-27b511c3-d151-45a9-9da8-89bc65f297f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-727992429-172.17.0.3-1595407081205:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32841,DS-0f03dac6-b661-4aaf-a35b-7f1083c5631a,DISK], DatanodeInfoWithStorage[127.0.0.1:41989,DS-52441b41-f045-467b-9c27-dcf01f3f3233,DISK], DatanodeInfoWithStorage[127.0.0.1:36376,DS-8cd1bc00-7acd-441f-9f90-cbbc9fc93029,DISK], DatanodeInfoWithStorage[127.0.0.1:44362,DS-39e264de-ee47-41b0-80c8-2160f1889453,DISK], DatanodeInfoWithStorage[127.0.0.1:39341,DS-97b29b6c-94f1-4152-b760-9a19f2d94744,DISK], DatanodeInfoWithStorage[127.0.0.1:45992,DS-477322c7-c313-40ec-91a3-5652f27fcb25,DISK], DatanodeInfoWithStorage[127.0.0.1:44842,DS-eb023b0b-0512-463f-a221-331316e9286d,DISK], DatanodeInfoWithStorage[127.0.0.1:43659,DS-27b511c3-d151-45a9-9da8-89bc65f297f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2027455045-172.17.0.3-1595407181576:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42992,DS-3103984d-252e-4744-bf7f-1fdeed51e535,DISK], DatanodeInfoWithStorage[127.0.0.1:37237,DS-31158263-9e15-4f5d-8cf3-e17dfdfd4d65,DISK], DatanodeInfoWithStorage[127.0.0.1:37568,DS-d8dd6f7c-77b5-49dc-a813-c8aca6ea6627,DISK], DatanodeInfoWithStorage[127.0.0.1:33574,DS-db71779c-d675-43be-acf3-36c98eea0662,DISK], DatanodeInfoWithStorage[127.0.0.1:39163,DS-fddc0eb5-5b7c-4c2f-a0f8-61222c2d4d5d,DISK], DatanodeInfoWithStorage[127.0.0.1:40073,DS-8ea4afaf-99d8-48e0-a314-1afa62bc1e30,DISK], DatanodeInfoWithStorage[127.0.0.1:44933,DS-a71dc627-bdf4-40f6-a3ec-49658e830d21,DISK], DatanodeInfoWithStorage[127.0.0.1:36212,DS-d9cb3451-33a2-485f-af23-15ecc23b69aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2027455045-172.17.0.3-1595407181576:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42992,DS-3103984d-252e-4744-bf7f-1fdeed51e535,DISK], DatanodeInfoWithStorage[127.0.0.1:37237,DS-31158263-9e15-4f5d-8cf3-e17dfdfd4d65,DISK], DatanodeInfoWithStorage[127.0.0.1:37568,DS-d8dd6f7c-77b5-49dc-a813-c8aca6ea6627,DISK], DatanodeInfoWithStorage[127.0.0.1:33574,DS-db71779c-d675-43be-acf3-36c98eea0662,DISK], DatanodeInfoWithStorage[127.0.0.1:39163,DS-fddc0eb5-5b7c-4c2f-a0f8-61222c2d4d5d,DISK], DatanodeInfoWithStorage[127.0.0.1:40073,DS-8ea4afaf-99d8-48e0-a314-1afa62bc1e30,DISK], DatanodeInfoWithStorage[127.0.0.1:44933,DS-a71dc627-bdf4-40f6-a3ec-49658e830d21,DISK], DatanodeInfoWithStorage[127.0.0.1:36212,DS-d9cb3451-33a2-485f-af23-15ecc23b69aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-477588077-172.17.0.3-1595407215015:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34530,DS-42cf1cd8-dbdc-4a48-b70c-9c45dc12472a,DISK], DatanodeInfoWithStorage[127.0.0.1:46418,DS-ee6da090-83a5-4192-bd87-ba884f3bd736,DISK], DatanodeInfoWithStorage[127.0.0.1:36468,DS-5ce2495c-b6b2-488b-a632-fd1222fd41ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34705,DS-caa41d4e-48dd-48f8-8615-98208e83fb06,DISK], DatanodeInfoWithStorage[127.0.0.1:34505,DS-60e40766-4662-47f8-8b27-5c20823b40e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40447,DS-2cbfbabb-f468-445a-ac93-5c5e4ce6177b,DISK], DatanodeInfoWithStorage[127.0.0.1:44176,DS-f25f7df4-f0b9-43b5-9178-4683fb31841f,DISK], DatanodeInfoWithStorage[127.0.0.1:34676,DS-28e74710-0462-41c5-9030-60510fb4ec18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-477588077-172.17.0.3-1595407215015:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34530,DS-42cf1cd8-dbdc-4a48-b70c-9c45dc12472a,DISK], DatanodeInfoWithStorage[127.0.0.1:46418,DS-ee6da090-83a5-4192-bd87-ba884f3bd736,DISK], DatanodeInfoWithStorage[127.0.0.1:36468,DS-5ce2495c-b6b2-488b-a632-fd1222fd41ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34705,DS-caa41d4e-48dd-48f8-8615-98208e83fb06,DISK], DatanodeInfoWithStorage[127.0.0.1:34505,DS-60e40766-4662-47f8-8b27-5c20823b40e4,DISK], DatanodeInfoWithStorage[127.0.0.1:40447,DS-2cbfbabb-f468-445a-ac93-5c5e4ce6177b,DISK], DatanodeInfoWithStorage[127.0.0.1:44176,DS-f25f7df4-f0b9-43b5-9178-4683fb31841f,DISK], DatanodeInfoWithStorage[127.0.0.1:34676,DS-28e74710-0462-41c5-9030-60510fb4ec18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1085976533-172.17.0.3-1595407263320:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35524,DS-d4fc78d1-ac5b-414c-bc40-0f4b4fc3899a,DISK], DatanodeInfoWithStorage[127.0.0.1:37035,DS-492e9a7f-abbd-4511-bf47-ac4f5b93ef24,DISK], DatanodeInfoWithStorage[127.0.0.1:33406,DS-3e5699a4-09ed-4bf1-ad45-3ab7932e9196,DISK], DatanodeInfoWithStorage[127.0.0.1:36033,DS-d928c5e9-ef03-460f-9c12-94271ab34876,DISK], DatanodeInfoWithStorage[127.0.0.1:39971,DS-3ac0506e-a9aa-404b-a675-4cb8f769b737,DISK], DatanodeInfoWithStorage[127.0.0.1:40169,DS-73fb2857-b1d7-4304-9ea7-949818785686,DISK], DatanodeInfoWithStorage[127.0.0.1:35978,DS-4b9f2977-e956-461b-8eb3-8c0c172f9625,DISK], DatanodeInfoWithStorage[127.0.0.1:41322,DS-12853812-a9d9-4d72-97ef-15aee73a986a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1085976533-172.17.0.3-1595407263320:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35524,DS-d4fc78d1-ac5b-414c-bc40-0f4b4fc3899a,DISK], DatanodeInfoWithStorage[127.0.0.1:37035,DS-492e9a7f-abbd-4511-bf47-ac4f5b93ef24,DISK], DatanodeInfoWithStorage[127.0.0.1:33406,DS-3e5699a4-09ed-4bf1-ad45-3ab7932e9196,DISK], DatanodeInfoWithStorage[127.0.0.1:36033,DS-d928c5e9-ef03-460f-9c12-94271ab34876,DISK], DatanodeInfoWithStorage[127.0.0.1:39971,DS-3ac0506e-a9aa-404b-a675-4cb8f769b737,DISK], DatanodeInfoWithStorage[127.0.0.1:40169,DS-73fb2857-b1d7-4304-9ea7-949818785686,DISK], DatanodeInfoWithStorage[127.0.0.1:35978,DS-4b9f2977-e956-461b-8eb3-8c0c172f9625,DISK], DatanodeInfoWithStorage[127.0.0.1:41322,DS-12853812-a9d9-4d72-97ef-15aee73a986a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-59133693-172.17.0.3-1595407373470:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46360,DS-fedc340d-1ff5-46cb-a3d4-67e8a3ae100d,DISK], DatanodeInfoWithStorage[127.0.0.1:44926,DS-f2382ec8-b3a0-47eb-86c2-fd7b96782526,DISK], DatanodeInfoWithStorage[127.0.0.1:38293,DS-49ca1c14-af0a-4e79-81f1-50fca5f64032,DISK], DatanodeInfoWithStorage[127.0.0.1:44580,DS-7cb2fa74-0256-4e59-b45f-6ec8aa0689e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37976,DS-e3b5578d-e4ca-4131-b263-d065aa0ced3b,DISK], DatanodeInfoWithStorage[127.0.0.1:38846,DS-dd311b13-4bc2-4122-9c7f-c5e6f7b30e21,DISK], DatanodeInfoWithStorage[127.0.0.1:43255,DS-efaf606e-7918-46fc-bd03-d78826dd0c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:42408,DS-3326072a-ac13-4432-8037-a5d9ed4a2da9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-59133693-172.17.0.3-1595407373470:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46360,DS-fedc340d-1ff5-46cb-a3d4-67e8a3ae100d,DISK], DatanodeInfoWithStorage[127.0.0.1:44926,DS-f2382ec8-b3a0-47eb-86c2-fd7b96782526,DISK], DatanodeInfoWithStorage[127.0.0.1:38293,DS-49ca1c14-af0a-4e79-81f1-50fca5f64032,DISK], DatanodeInfoWithStorage[127.0.0.1:44580,DS-7cb2fa74-0256-4e59-b45f-6ec8aa0689e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37976,DS-e3b5578d-e4ca-4131-b263-d065aa0ced3b,DISK], DatanodeInfoWithStorage[127.0.0.1:38846,DS-dd311b13-4bc2-4122-9c7f-c5e6f7b30e21,DISK], DatanodeInfoWithStorage[127.0.0.1:43255,DS-efaf606e-7918-46fc-bd03-d78826dd0c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:42408,DS-3326072a-ac13-4432-8037-a5d9ed4a2da9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-117869167-172.17.0.3-1595407877285:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38641,DS-97240a5a-f7fb-4a9d-bdd1-578a7fc89a20,DISK], DatanodeInfoWithStorage[127.0.0.1:36959,DS-cc746566-5069-46f3-a46f-2e8778833775,DISK], DatanodeInfoWithStorage[127.0.0.1:41394,DS-7dae5df1-1abb-4501-bac2-aa247c61980c,DISK], DatanodeInfoWithStorage[127.0.0.1:39970,DS-d5b0be23-9a66-43ae-b1ed-d9e84679a7a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33361,DS-d0259091-e446-437e-a76a-f873baf5cf81,DISK], DatanodeInfoWithStorage[127.0.0.1:36219,DS-8ae77b9b-810f-4be4-822e-a71afb591b02,DISK], DatanodeInfoWithStorage[127.0.0.1:36025,DS-390d2d23-68e3-4e82-8038-ead463b76e46,DISK], DatanodeInfoWithStorage[127.0.0.1:45600,DS-7d411c05-f94f-49f6-9a1f-8ec3462d2b5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-117869167-172.17.0.3-1595407877285:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38641,DS-97240a5a-f7fb-4a9d-bdd1-578a7fc89a20,DISK], DatanodeInfoWithStorage[127.0.0.1:36959,DS-cc746566-5069-46f3-a46f-2e8778833775,DISK], DatanodeInfoWithStorage[127.0.0.1:41394,DS-7dae5df1-1abb-4501-bac2-aa247c61980c,DISK], DatanodeInfoWithStorage[127.0.0.1:39970,DS-d5b0be23-9a66-43ae-b1ed-d9e84679a7a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33361,DS-d0259091-e446-437e-a76a-f873baf5cf81,DISK], DatanodeInfoWithStorage[127.0.0.1:36219,DS-8ae77b9b-810f-4be4-822e-a71afb591b02,DISK], DatanodeInfoWithStorage[127.0.0.1:36025,DS-390d2d23-68e3-4e82-8038-ead463b76e46,DISK], DatanodeInfoWithStorage[127.0.0.1:45600,DS-7d411c05-f94f-49f6-9a1f-8ec3462d2b5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1861488483-172.17.0.3-1595408719914:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38321,DS-79555b2d-0877-41ad-91a4-24fb34e2b152,DISK], DatanodeInfoWithStorage[127.0.0.1:46405,DS-158250f5-f14a-4d4b-8364-e3ac38f4f667,DISK], DatanodeInfoWithStorage[127.0.0.1:38936,DS-1a9702d5-c63e-4699-a084-cc0f6fe519c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44099,DS-55360973-3e76-440d-9acc-d5dd3eb7ad54,DISK], DatanodeInfoWithStorage[127.0.0.1:45982,DS-33d5e1fa-b216-496a-a1ba-59a6a996a8aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35934,DS-85ced18f-141e-4930-a4f1-116bb6e6fad7,DISK], DatanodeInfoWithStorage[127.0.0.1:40931,DS-c254c95a-d92d-4764-bee5-ea76a7988248,DISK], DatanodeInfoWithStorage[127.0.0.1:43319,DS-8d62c914-2fb0-429b-ab6c-722d09bf8d23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1861488483-172.17.0.3-1595408719914:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38321,DS-79555b2d-0877-41ad-91a4-24fb34e2b152,DISK], DatanodeInfoWithStorage[127.0.0.1:46405,DS-158250f5-f14a-4d4b-8364-e3ac38f4f667,DISK], DatanodeInfoWithStorage[127.0.0.1:38936,DS-1a9702d5-c63e-4699-a084-cc0f6fe519c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44099,DS-55360973-3e76-440d-9acc-d5dd3eb7ad54,DISK], DatanodeInfoWithStorage[127.0.0.1:45982,DS-33d5e1fa-b216-496a-a1ba-59a6a996a8aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35934,DS-85ced18f-141e-4930-a4f1-116bb6e6fad7,DISK], DatanodeInfoWithStorage[127.0.0.1:40931,DS-c254c95a-d92d-4764-bee5-ea76a7988248,DISK], DatanodeInfoWithStorage[127.0.0.1:43319,DS-8d62c914-2fb0-429b-ab6c-722d09bf8d23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-815716397-172.17.0.3-1595409106473:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34208,DS-bb029f4f-1b8d-45ef-ba42-aa48d5c1197e,DISK], DatanodeInfoWithStorage[127.0.0.1:43279,DS-5a9fbacd-8bb6-499d-86b7-204057d6a123,DISK], DatanodeInfoWithStorage[127.0.0.1:34313,DS-28b4486d-e601-42ee-bdac-c32d9f4cde12,DISK], DatanodeInfoWithStorage[127.0.0.1:45959,DS-f3605e5b-8436-4a65-9206-65e8c3845593,DISK], DatanodeInfoWithStorage[127.0.0.1:41275,DS-5938b803-ff45-4d82-a82c-eb919b335eb0,DISK], DatanodeInfoWithStorage[127.0.0.1:45697,DS-566dc31b-9d19-4d4a-a63c-e3e6e6bfe82f,DISK], DatanodeInfoWithStorage[127.0.0.1:35554,DS-31868ac4-1bab-4ef7-a14f-94954bbda251,DISK], DatanodeInfoWithStorage[127.0.0.1:40035,DS-7886a056-e5a1-49e1-b9a6-575b9f249f84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-815716397-172.17.0.3-1595409106473:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34208,DS-bb029f4f-1b8d-45ef-ba42-aa48d5c1197e,DISK], DatanodeInfoWithStorage[127.0.0.1:43279,DS-5a9fbacd-8bb6-499d-86b7-204057d6a123,DISK], DatanodeInfoWithStorage[127.0.0.1:34313,DS-28b4486d-e601-42ee-bdac-c32d9f4cde12,DISK], DatanodeInfoWithStorage[127.0.0.1:45959,DS-f3605e5b-8436-4a65-9206-65e8c3845593,DISK], DatanodeInfoWithStorage[127.0.0.1:41275,DS-5938b803-ff45-4d82-a82c-eb919b335eb0,DISK], DatanodeInfoWithStorage[127.0.0.1:45697,DS-566dc31b-9d19-4d4a-a63c-e3e6e6bfe82f,DISK], DatanodeInfoWithStorage[127.0.0.1:35554,DS-31868ac4-1bab-4ef7-a14f-94954bbda251,DISK], DatanodeInfoWithStorage[127.0.0.1:40035,DS-7886a056-e5a1-49e1-b9a6-575b9f249f84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1744910541-172.17.0.3-1595409314736:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39955,DS-4094b882-7b00-4214-ada3-071a4e709c16,DISK], DatanodeInfoWithStorage[127.0.0.1:34785,DS-ac60426e-e0eb-4c57-b49d-b5e7b10cee17,DISK], DatanodeInfoWithStorage[127.0.0.1:33614,DS-c8c71aa8-1bc3-4ec4-9fee-bf19b7d4f663,DISK], DatanodeInfoWithStorage[127.0.0.1:42355,DS-1d7e661d-a204-4c83-a22a-8123039a2cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:40428,DS-91e838f9-79ab-4220-9722-c1a55e38b6f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39471,DS-47e721a9-53e7-4edc-95d8-f0e7d83dea80,DISK], DatanodeInfoWithStorage[127.0.0.1:43175,DS-a8520844-cce3-482b-9c89-9d3681a65732,DISK], DatanodeInfoWithStorage[127.0.0.1:39724,DS-1815a0ab-6847-4993-986c-5ec833883b11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1744910541-172.17.0.3-1595409314736:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39955,DS-4094b882-7b00-4214-ada3-071a4e709c16,DISK], DatanodeInfoWithStorage[127.0.0.1:34785,DS-ac60426e-e0eb-4c57-b49d-b5e7b10cee17,DISK], DatanodeInfoWithStorage[127.0.0.1:33614,DS-c8c71aa8-1bc3-4ec4-9fee-bf19b7d4f663,DISK], DatanodeInfoWithStorage[127.0.0.1:42355,DS-1d7e661d-a204-4c83-a22a-8123039a2cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:40428,DS-91e838f9-79ab-4220-9722-c1a55e38b6f6,DISK], DatanodeInfoWithStorage[127.0.0.1:39471,DS-47e721a9-53e7-4edc-95d8-f0e7d83dea80,DISK], DatanodeInfoWithStorage[127.0.0.1:43175,DS-a8520844-cce3-482b-9c89-9d3681a65732,DISK], DatanodeInfoWithStorage[127.0.0.1:39724,DS-1815a0ab-6847-4993-986c-5ec833883b11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1123306249-172.17.0.3-1595409957418:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42484,DS-6f46a308-ad84-41ce-9072-d5065069649f,DISK], DatanodeInfoWithStorage[127.0.0.1:33735,DS-d7de0f6c-9d5b-4eaf-a32a-3958e006637c,DISK], DatanodeInfoWithStorage[127.0.0.1:44273,DS-96b966fb-134d-46d5-9c45-568f22dce7b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37278,DS-d8ee836c-9a5a-4daf-810f-274137da23c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38636,DS-29411751-7886-49d0-adad-13d1dff3da14,DISK], DatanodeInfoWithStorage[127.0.0.1:32768,DS-c2c64605-0ef7-44ee-9ac3-2c140db40d33,DISK], DatanodeInfoWithStorage[127.0.0.1:40494,DS-4bb8f32d-da4b-4208-95a1-0066cd8afadc,DISK], DatanodeInfoWithStorage[127.0.0.1:36397,DS-fa06fa05-7479-4a38-b88f-d94588ad3e2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1123306249-172.17.0.3-1595409957418:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42484,DS-6f46a308-ad84-41ce-9072-d5065069649f,DISK], DatanodeInfoWithStorage[127.0.0.1:33735,DS-d7de0f6c-9d5b-4eaf-a32a-3958e006637c,DISK], DatanodeInfoWithStorage[127.0.0.1:44273,DS-96b966fb-134d-46d5-9c45-568f22dce7b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37278,DS-d8ee836c-9a5a-4daf-810f-274137da23c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38636,DS-29411751-7886-49d0-adad-13d1dff3da14,DISK], DatanodeInfoWithStorage[127.0.0.1:32768,DS-c2c64605-0ef7-44ee-9ac3-2c140db40d33,DISK], DatanodeInfoWithStorage[127.0.0.1:40494,DS-4bb8f32d-da4b-4208-95a1-0066cd8afadc,DISK], DatanodeInfoWithStorage[127.0.0.1:36397,DS-fa06fa05-7479-4a38-b88f-d94588ad3e2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 5634
