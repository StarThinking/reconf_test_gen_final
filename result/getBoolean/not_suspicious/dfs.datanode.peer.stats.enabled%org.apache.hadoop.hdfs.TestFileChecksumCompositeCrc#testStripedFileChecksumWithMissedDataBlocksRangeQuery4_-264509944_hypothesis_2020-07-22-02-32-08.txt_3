reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-145051391-172.17.0.3-1595385142915:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36387,DS-fdffee00-efa7-4d49-9763-991d620f809c,DISK], DatanodeInfoWithStorage[127.0.0.1:34935,DS-9311a07c-3818-4777-9327-f626ddc0243b,DISK], DatanodeInfoWithStorage[127.0.0.1:43833,DS-b9013c97-115e-4dfe-a75b-82a46be725c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45202,DS-06873bb2-1d48-473a-b4e6-be2d00c23e83,DISK], DatanodeInfoWithStorage[127.0.0.1:42032,DS-3fec1a5a-b522-4d23-89c0-3738cafbca7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36541,DS-2d6e3bef-35d4-4530-b31a-91e3d387ebe2,DISK], DatanodeInfoWithStorage[127.0.0.1:46676,DS-6e62ebae-23ce-4b39-9704-157f116117be,DISK], DatanodeInfoWithStorage[127.0.0.1:38341,DS-2d678f1a-764f-47cc-9aa7-b353fff6b569,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-145051391-172.17.0.3-1595385142915:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36387,DS-fdffee00-efa7-4d49-9763-991d620f809c,DISK], DatanodeInfoWithStorage[127.0.0.1:34935,DS-9311a07c-3818-4777-9327-f626ddc0243b,DISK], DatanodeInfoWithStorage[127.0.0.1:43833,DS-b9013c97-115e-4dfe-a75b-82a46be725c2,DISK], DatanodeInfoWithStorage[127.0.0.1:45202,DS-06873bb2-1d48-473a-b4e6-be2d00c23e83,DISK], DatanodeInfoWithStorage[127.0.0.1:42032,DS-3fec1a5a-b522-4d23-89c0-3738cafbca7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36541,DS-2d6e3bef-35d4-4530-b31a-91e3d387ebe2,DISK], DatanodeInfoWithStorage[127.0.0.1:46676,DS-6e62ebae-23ce-4b39-9704-157f116117be,DISK], DatanodeInfoWithStorage[127.0.0.1:38341,DS-2d678f1a-764f-47cc-9aa7-b353fff6b569,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1141394730-172.17.0.3-1595385507056:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43940,DS-22d0ce94-bbcd-42f5-957c-c0b012bf2f87,DISK], DatanodeInfoWithStorage[127.0.0.1:41608,DS-596ffeae-eff1-4390-947d-3e5a17c2a7c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36339,DS-7ec7fdf0-0849-4396-8ded-8dc8ae97d42e,DISK], DatanodeInfoWithStorage[127.0.0.1:44443,DS-ad81b750-1acc-4ca0-8ce0-19b7fcbdf10e,DISK], DatanodeInfoWithStorage[127.0.0.1:34874,DS-e25248fa-344a-45c9-af06-55698ab5e8f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34686,DS-b0e55739-ca23-4a34-8184-377f2ed640cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40934,DS-bb91d859-a00d-4105-91ff-91c7b89de344,DISK], DatanodeInfoWithStorage[127.0.0.1:41246,DS-b12e423a-5f8d-4314-936d-6b49ce044404,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1141394730-172.17.0.3-1595385507056:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43940,DS-22d0ce94-bbcd-42f5-957c-c0b012bf2f87,DISK], DatanodeInfoWithStorage[127.0.0.1:41608,DS-596ffeae-eff1-4390-947d-3e5a17c2a7c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36339,DS-7ec7fdf0-0849-4396-8ded-8dc8ae97d42e,DISK], DatanodeInfoWithStorage[127.0.0.1:44443,DS-ad81b750-1acc-4ca0-8ce0-19b7fcbdf10e,DISK], DatanodeInfoWithStorage[127.0.0.1:34874,DS-e25248fa-344a-45c9-af06-55698ab5e8f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34686,DS-b0e55739-ca23-4a34-8184-377f2ed640cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40934,DS-bb91d859-a00d-4105-91ff-91c7b89de344,DISK], DatanodeInfoWithStorage[127.0.0.1:41246,DS-b12e423a-5f8d-4314-936d-6b49ce044404,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-645126901-172.17.0.3-1595385975100:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35990,DS-f5ab7b14-2139-4b4f-87b6-4ca0bfbe2d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:36465,DS-2a24ea10-be62-4ef1-abe4-61309a32fdf8,DISK], DatanodeInfoWithStorage[127.0.0.1:45800,DS-3dfb1173-5fb1-4ca4-93e4-62d687a1baad,DISK], DatanodeInfoWithStorage[127.0.0.1:34860,DS-c8fc0b47-a551-4707-873f-e007a745626d,DISK], DatanodeInfoWithStorage[127.0.0.1:40376,DS-5053762b-bcaf-46a6-8ead-1bea509d7f65,DISK], DatanodeInfoWithStorage[127.0.0.1:46456,DS-5ba1707d-d98a-4b28-8cb5-cca5f6b673c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40346,DS-dfc76bfc-21e0-4ea5-8c93-b61a81a370ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33673,DS-fba02973-6c29-43dd-bacb-f24520975b31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-645126901-172.17.0.3-1595385975100:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35990,DS-f5ab7b14-2139-4b4f-87b6-4ca0bfbe2d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:36465,DS-2a24ea10-be62-4ef1-abe4-61309a32fdf8,DISK], DatanodeInfoWithStorage[127.0.0.1:45800,DS-3dfb1173-5fb1-4ca4-93e4-62d687a1baad,DISK], DatanodeInfoWithStorage[127.0.0.1:34860,DS-c8fc0b47-a551-4707-873f-e007a745626d,DISK], DatanodeInfoWithStorage[127.0.0.1:40376,DS-5053762b-bcaf-46a6-8ead-1bea509d7f65,DISK], DatanodeInfoWithStorage[127.0.0.1:46456,DS-5ba1707d-d98a-4b28-8cb5-cca5f6b673c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40346,DS-dfc76bfc-21e0-4ea5-8c93-b61a81a370ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33673,DS-fba02973-6c29-43dd-bacb-f24520975b31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1405935941-172.17.0.3-1595386309806:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36566,DS-f7506d47-06ae-4df5-ad98-6b16013fad9f,DISK], DatanodeInfoWithStorage[127.0.0.1:40804,DS-628367cc-7ae2-4dec-a9d6-8dd936ad573f,DISK], DatanodeInfoWithStorage[127.0.0.1:39593,DS-5d372cff-f6c8-4eff-91a9-48d9de700886,DISK], DatanodeInfoWithStorage[127.0.0.1:41877,DS-73d406a0-1091-4b58-861b-406102b25e50,DISK], DatanodeInfoWithStorage[127.0.0.1:36441,DS-73554330-6a7d-46e4-9f85-172bff93e5b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41466,DS-a769443a-5b65-49cd-843c-0b03cba09ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:39572,DS-8beb38ad-30db-46fd-90a9-de3542e9e7f8,DISK], DatanodeInfoWithStorage[127.0.0.1:39981,DS-9b11facf-022f-4de1-b9f4-76314db5e1ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1405935941-172.17.0.3-1595386309806:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36566,DS-f7506d47-06ae-4df5-ad98-6b16013fad9f,DISK], DatanodeInfoWithStorage[127.0.0.1:40804,DS-628367cc-7ae2-4dec-a9d6-8dd936ad573f,DISK], DatanodeInfoWithStorage[127.0.0.1:39593,DS-5d372cff-f6c8-4eff-91a9-48d9de700886,DISK], DatanodeInfoWithStorage[127.0.0.1:41877,DS-73d406a0-1091-4b58-861b-406102b25e50,DISK], DatanodeInfoWithStorage[127.0.0.1:36441,DS-73554330-6a7d-46e4-9f85-172bff93e5b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41466,DS-a769443a-5b65-49cd-843c-0b03cba09ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:39572,DS-8beb38ad-30db-46fd-90a9-de3542e9e7f8,DISK], DatanodeInfoWithStorage[127.0.0.1:39981,DS-9b11facf-022f-4de1-b9f4-76314db5e1ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1909867312-172.17.0.3-1595386531541:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46182,DS-9ee39e93-edbf-412e-a20a-731f8a68b033,DISK], DatanodeInfoWithStorage[127.0.0.1:44476,DS-05e9e0ba-b706-4217-a80d-68735cce8c64,DISK], DatanodeInfoWithStorage[127.0.0.1:42560,DS-65e09b63-d737-42df-bb19-2c7592530d75,DISK], DatanodeInfoWithStorage[127.0.0.1:35864,DS-647fc377-f5b3-4e53-b1f1-4fcf7176aa63,DISK], DatanodeInfoWithStorage[127.0.0.1:44597,DS-1e7c745e-efc9-48d7-b05f-d6997033fa77,DISK], DatanodeInfoWithStorage[127.0.0.1:34240,DS-4ab2d7f7-8383-4a86-8895-e15b539bcce1,DISK], DatanodeInfoWithStorage[127.0.0.1:37828,DS-f0b2aadf-7601-4379-966e-164e84eac932,DISK], DatanodeInfoWithStorage[127.0.0.1:39534,DS-d4666f93-7f1e-421e-862e-e0ff6dc7da91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1909867312-172.17.0.3-1595386531541:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46182,DS-9ee39e93-edbf-412e-a20a-731f8a68b033,DISK], DatanodeInfoWithStorage[127.0.0.1:44476,DS-05e9e0ba-b706-4217-a80d-68735cce8c64,DISK], DatanodeInfoWithStorage[127.0.0.1:42560,DS-65e09b63-d737-42df-bb19-2c7592530d75,DISK], DatanodeInfoWithStorage[127.0.0.1:35864,DS-647fc377-f5b3-4e53-b1f1-4fcf7176aa63,DISK], DatanodeInfoWithStorage[127.0.0.1:44597,DS-1e7c745e-efc9-48d7-b05f-d6997033fa77,DISK], DatanodeInfoWithStorage[127.0.0.1:34240,DS-4ab2d7f7-8383-4a86-8895-e15b539bcce1,DISK], DatanodeInfoWithStorage[127.0.0.1:37828,DS-f0b2aadf-7601-4379-966e-164e84eac932,DISK], DatanodeInfoWithStorage[127.0.0.1:39534,DS-d4666f93-7f1e-421e-862e-e0ff6dc7da91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1723410415-172.17.0.3-1595387458316:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33297,DS-41bc4e28-43fa-477f-aafa-ba3756d10e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:41799,DS-046e1f29-b827-465c-964d-a0216268b054,DISK], DatanodeInfoWithStorage[127.0.0.1:42902,DS-12c7f5e8-d5d5-484a-a486-3862e8fc47c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43676,DS-d66cbbaf-9af4-409c-a27c-73a722a6f57d,DISK], DatanodeInfoWithStorage[127.0.0.1:44854,DS-59e2d332-77ff-4f3a-bd1e-75582cb89781,DISK], DatanodeInfoWithStorage[127.0.0.1:39205,DS-c23b8bd9-e8c8-46c5-9a82-016df78e1439,DISK], DatanodeInfoWithStorage[127.0.0.1:39101,DS-12fbe7ac-7011-4c9e-9aaf-c1c5530e5653,DISK], DatanodeInfoWithStorage[127.0.0.1:39298,DS-70014986-867e-4f7f-8bb7-f71d649c730c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1723410415-172.17.0.3-1595387458316:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33297,DS-41bc4e28-43fa-477f-aafa-ba3756d10e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:41799,DS-046e1f29-b827-465c-964d-a0216268b054,DISK], DatanodeInfoWithStorage[127.0.0.1:42902,DS-12c7f5e8-d5d5-484a-a486-3862e8fc47c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43676,DS-d66cbbaf-9af4-409c-a27c-73a722a6f57d,DISK], DatanodeInfoWithStorage[127.0.0.1:44854,DS-59e2d332-77ff-4f3a-bd1e-75582cb89781,DISK], DatanodeInfoWithStorage[127.0.0.1:39205,DS-c23b8bd9-e8c8-46c5-9a82-016df78e1439,DISK], DatanodeInfoWithStorage[127.0.0.1:39101,DS-12fbe7ac-7011-4c9e-9aaf-c1c5530e5653,DISK], DatanodeInfoWithStorage[127.0.0.1:39298,DS-70014986-867e-4f7f-8bb7-f71d649c730c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-475638362-172.17.0.3-1595387678975:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39981,DS-5cf486ae-c119-47e6-9cdb-e760c161763c,DISK], DatanodeInfoWithStorage[127.0.0.1:42893,DS-f2a24a1e-07b6-48d1-b433-6241b111c4b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45629,DS-7cebcebe-f3ab-4944-9fbb-65e0b3a020b0,DISK], DatanodeInfoWithStorage[127.0.0.1:46729,DS-a31aa236-80b2-499b-8e9e-62d84492d587,DISK], DatanodeInfoWithStorage[127.0.0.1:36662,DS-bba6c082-d6b4-4f04-aa16-1093df4f6eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:35452,DS-c3d3a38b-bde3-4154-ad37-b31f02c782c0,DISK], DatanodeInfoWithStorage[127.0.0.1:43129,DS-4eeff0bc-c11d-45e6-ac40-69b60d5e347c,DISK], DatanodeInfoWithStorage[127.0.0.1:37903,DS-641f1421-7c11-4204-92d3-d7392849f0f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-475638362-172.17.0.3-1595387678975:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39981,DS-5cf486ae-c119-47e6-9cdb-e760c161763c,DISK], DatanodeInfoWithStorage[127.0.0.1:42893,DS-f2a24a1e-07b6-48d1-b433-6241b111c4b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45629,DS-7cebcebe-f3ab-4944-9fbb-65e0b3a020b0,DISK], DatanodeInfoWithStorage[127.0.0.1:46729,DS-a31aa236-80b2-499b-8e9e-62d84492d587,DISK], DatanodeInfoWithStorage[127.0.0.1:36662,DS-bba6c082-d6b4-4f04-aa16-1093df4f6eb3,DISK], DatanodeInfoWithStorage[127.0.0.1:35452,DS-c3d3a38b-bde3-4154-ad37-b31f02c782c0,DISK], DatanodeInfoWithStorage[127.0.0.1:43129,DS-4eeff0bc-c11d-45e6-ac40-69b60d5e347c,DISK], DatanodeInfoWithStorage[127.0.0.1:37903,DS-641f1421-7c11-4204-92d3-d7392849f0f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1288063248-172.17.0.3-1595388172811:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45565,DS-32780c8f-399f-4080-96e1-95edc6723050,DISK], DatanodeInfoWithStorage[127.0.0.1:38869,DS-d496f158-393a-42fa-bd5e-a86071ea597b,DISK], DatanodeInfoWithStorage[127.0.0.1:36692,DS-1ace929e-9958-4152-9770-d2ee71b665c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33754,DS-d0a2b99d-0cc3-452b-9e77-b4ee5de167f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35000,DS-67a5bbdf-9579-4016-b5c5-de9e940efd56,DISK], DatanodeInfoWithStorage[127.0.0.1:38819,DS-539d055b-bfee-4355-b1cb-c76fa30d7d28,DISK], DatanodeInfoWithStorage[127.0.0.1:44923,DS-bb21a34c-bf84-49b3-bc3e-49a8538b75c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35384,DS-2a33f5b4-2b0b-4503-91b7-f3b4cb2d19b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1288063248-172.17.0.3-1595388172811:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45565,DS-32780c8f-399f-4080-96e1-95edc6723050,DISK], DatanodeInfoWithStorage[127.0.0.1:38869,DS-d496f158-393a-42fa-bd5e-a86071ea597b,DISK], DatanodeInfoWithStorage[127.0.0.1:36692,DS-1ace929e-9958-4152-9770-d2ee71b665c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33754,DS-d0a2b99d-0cc3-452b-9e77-b4ee5de167f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35000,DS-67a5bbdf-9579-4016-b5c5-de9e940efd56,DISK], DatanodeInfoWithStorage[127.0.0.1:38819,DS-539d055b-bfee-4355-b1cb-c76fa30d7d28,DISK], DatanodeInfoWithStorage[127.0.0.1:44923,DS-bb21a34c-bf84-49b3-bc3e-49a8538b75c6,DISK], DatanodeInfoWithStorage[127.0.0.1:35384,DS-2a33f5b4-2b0b-4503-91b7-f3b4cb2d19b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1748153326-172.17.0.3-1595388317380:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39542,DS-fe08b3b8-7f44-4122-a3ce-7ba6e044ad94,DISK], DatanodeInfoWithStorage[127.0.0.1:40209,DS-6dcf6f14-789b-4f55-a8a3-973811717b92,DISK], DatanodeInfoWithStorage[127.0.0.1:44462,DS-21849112-3e7f-438a-88da-27d67f6ca6ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37671,DS-19dc011c-420d-4142-b5e9-4a0eeba7dd11,DISK], DatanodeInfoWithStorage[127.0.0.1:33313,DS-f7cb9945-84fe-4a12-b076-5dc39c60db45,DISK], DatanodeInfoWithStorage[127.0.0.1:39203,DS-bac6ad3c-7c74-452c-8229-30d0a74ed8cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45371,DS-34771148-d9ce-4453-9dfe-351a8ddb7831,DISK], DatanodeInfoWithStorage[127.0.0.1:45729,DS-0af5d071-5783-41d8-b20c-9a79752f3eed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1748153326-172.17.0.3-1595388317380:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39542,DS-fe08b3b8-7f44-4122-a3ce-7ba6e044ad94,DISK], DatanodeInfoWithStorage[127.0.0.1:40209,DS-6dcf6f14-789b-4f55-a8a3-973811717b92,DISK], DatanodeInfoWithStorage[127.0.0.1:44462,DS-21849112-3e7f-438a-88da-27d67f6ca6ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37671,DS-19dc011c-420d-4142-b5e9-4a0eeba7dd11,DISK], DatanodeInfoWithStorage[127.0.0.1:33313,DS-f7cb9945-84fe-4a12-b076-5dc39c60db45,DISK], DatanodeInfoWithStorage[127.0.0.1:39203,DS-bac6ad3c-7c74-452c-8229-30d0a74ed8cd,DISK], DatanodeInfoWithStorage[127.0.0.1:45371,DS-34771148-d9ce-4453-9dfe-351a8ddb7831,DISK], DatanodeInfoWithStorage[127.0.0.1:45729,DS-0af5d071-5783-41d8-b20c-9a79752f3eed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-516061499-172.17.0.3-1595388535550:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43206,DS-03276636-94d2-4d17-bad6-fc39233ae4d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38576,DS-2fa14edd-a4df-4325-a0b9-8da0321b2f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:38773,DS-6820fc44-5e6a-4e73-a1db-fbf585566085,DISK], DatanodeInfoWithStorage[127.0.0.1:34542,DS-7df6283d-9a5f-45f6-9eea-71e6555e6749,DISK], DatanodeInfoWithStorage[127.0.0.1:40096,DS-291d8963-df87-4408-9351-86f94b1703f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34845,DS-15a62e4e-d6a0-465a-b47f-8d11a95ba506,DISK], DatanodeInfoWithStorage[127.0.0.1:38198,DS-0c2a088a-6101-4b9e-84d5-70e8ab445aa4,DISK], DatanodeInfoWithStorage[127.0.0.1:40379,DS-255ea844-3585-4492-9b4d-56e57c9b7b1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-516061499-172.17.0.3-1595388535550:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43206,DS-03276636-94d2-4d17-bad6-fc39233ae4d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38576,DS-2fa14edd-a4df-4325-a0b9-8da0321b2f1a,DISK], DatanodeInfoWithStorage[127.0.0.1:38773,DS-6820fc44-5e6a-4e73-a1db-fbf585566085,DISK], DatanodeInfoWithStorage[127.0.0.1:34542,DS-7df6283d-9a5f-45f6-9eea-71e6555e6749,DISK], DatanodeInfoWithStorage[127.0.0.1:40096,DS-291d8963-df87-4408-9351-86f94b1703f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34845,DS-15a62e4e-d6a0-465a-b47f-8d11a95ba506,DISK], DatanodeInfoWithStorage[127.0.0.1:38198,DS-0c2a088a-6101-4b9e-84d5-70e8ab445aa4,DISK], DatanodeInfoWithStorage[127.0.0.1:40379,DS-255ea844-3585-4492-9b4d-56e57c9b7b1b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-808230671-172.17.0.3-1595388744312:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43819,DS-53912258-d148-4383-a510-3d952841781f,DISK], DatanodeInfoWithStorage[127.0.0.1:41019,DS-da93e3f2-4aa1-49e2-9785-ec1a91caf65e,DISK], DatanodeInfoWithStorage[127.0.0.1:44510,DS-bcfa2186-42d2-42ab-a37a-417a9898cd15,DISK], DatanodeInfoWithStorage[127.0.0.1:37339,DS-ccf2920e-3dba-4c39-b3c5-1645e4b04273,DISK], DatanodeInfoWithStorage[127.0.0.1:43744,DS-2e5ffcdf-b931-46c3-b013-057d018262ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36706,DS-ffeeb380-d256-4051-a745-597483debeca,DISK], DatanodeInfoWithStorage[127.0.0.1:35041,DS-28f3f370-5b5b-4a49-a8d5-c1a434901588,DISK], DatanodeInfoWithStorage[127.0.0.1:44328,DS-0faeb6c6-2bb8-4cde-9d27-01525a7640fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-808230671-172.17.0.3-1595388744312:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43819,DS-53912258-d148-4383-a510-3d952841781f,DISK], DatanodeInfoWithStorage[127.0.0.1:41019,DS-da93e3f2-4aa1-49e2-9785-ec1a91caf65e,DISK], DatanodeInfoWithStorage[127.0.0.1:44510,DS-bcfa2186-42d2-42ab-a37a-417a9898cd15,DISK], DatanodeInfoWithStorage[127.0.0.1:37339,DS-ccf2920e-3dba-4c39-b3c5-1645e4b04273,DISK], DatanodeInfoWithStorage[127.0.0.1:43744,DS-2e5ffcdf-b931-46c3-b013-057d018262ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36706,DS-ffeeb380-d256-4051-a745-597483debeca,DISK], DatanodeInfoWithStorage[127.0.0.1:35041,DS-28f3f370-5b5b-4a49-a8d5-c1a434901588,DISK], DatanodeInfoWithStorage[127.0.0.1:44328,DS-0faeb6c6-2bb8-4cde-9d27-01525a7640fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1669905638-172.17.0.3-1595388982732:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36008,DS-ba4532de-c3f2-443a-892f-5415da8b47ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42913,DS-8896fe6b-c3f0-481d-8664-66a100df32f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33991,DS-8c373bc3-1614-4b2d-a742-d5c1fc3db240,DISK], DatanodeInfoWithStorage[127.0.0.1:34797,DS-f8aa8dfd-e431-426b-a75d-cf25d7a5078a,DISK], DatanodeInfoWithStorage[127.0.0.1:36224,DS-b3fbd867-1f10-436f-a7a2-b692b4e15ece,DISK], DatanodeInfoWithStorage[127.0.0.1:46770,DS-4cdf6a4d-56b1-434a-b546-00af084e4f64,DISK], DatanodeInfoWithStorage[127.0.0.1:34872,DS-1cd53ad4-0cb7-4377-94d1-973fef52e6f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40122,DS-fb35249b-65ce-441e-a4f7-602315281def,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1669905638-172.17.0.3-1595388982732:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36008,DS-ba4532de-c3f2-443a-892f-5415da8b47ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42913,DS-8896fe6b-c3f0-481d-8664-66a100df32f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33991,DS-8c373bc3-1614-4b2d-a742-d5c1fc3db240,DISK], DatanodeInfoWithStorage[127.0.0.1:34797,DS-f8aa8dfd-e431-426b-a75d-cf25d7a5078a,DISK], DatanodeInfoWithStorage[127.0.0.1:36224,DS-b3fbd867-1f10-436f-a7a2-b692b4e15ece,DISK], DatanodeInfoWithStorage[127.0.0.1:46770,DS-4cdf6a4d-56b1-434a-b546-00af084e4f64,DISK], DatanodeInfoWithStorage[127.0.0.1:34872,DS-1cd53ad4-0cb7-4377-94d1-973fef52e6f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40122,DS-fb35249b-65ce-441e-a4f7-602315281def,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-383340826-172.17.0.3-1595389660747:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45199,DS-5c7c3acf-3605-450d-b042-92808e27a9ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44088,DS-dc38d535-e978-474d-8f1c-196796a1cd9b,DISK], DatanodeInfoWithStorage[127.0.0.1:39043,DS-e2ab300b-3408-4878-b323-085c96271a28,DISK], DatanodeInfoWithStorage[127.0.0.1:43869,DS-2acf2f5c-98aa-4e34-beb4-5129b3bbdad3,DISK], DatanodeInfoWithStorage[127.0.0.1:36507,DS-a0de65f4-8600-48a0-b4e3-af02a658e24c,DISK], DatanodeInfoWithStorage[127.0.0.1:37312,DS-de5f1d7a-d6d3-4fb0-a045-3481535f3947,DISK], DatanodeInfoWithStorage[127.0.0.1:39497,DS-3145344b-c2d5-43ab-9288-df72f5002183,DISK], DatanodeInfoWithStorage[127.0.0.1:37754,DS-98b3205d-d266-44c2-88ce-bd4285a0433a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-383340826-172.17.0.3-1595389660747:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45199,DS-5c7c3acf-3605-450d-b042-92808e27a9ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44088,DS-dc38d535-e978-474d-8f1c-196796a1cd9b,DISK], DatanodeInfoWithStorage[127.0.0.1:39043,DS-e2ab300b-3408-4878-b323-085c96271a28,DISK], DatanodeInfoWithStorage[127.0.0.1:43869,DS-2acf2f5c-98aa-4e34-beb4-5129b3bbdad3,DISK], DatanodeInfoWithStorage[127.0.0.1:36507,DS-a0de65f4-8600-48a0-b4e3-af02a658e24c,DISK], DatanodeInfoWithStorage[127.0.0.1:37312,DS-de5f1d7a-d6d3-4fb0-a045-3481535f3947,DISK], DatanodeInfoWithStorage[127.0.0.1:39497,DS-3145344b-c2d5-43ab-9288-df72f5002183,DISK], DatanodeInfoWithStorage[127.0.0.1:37754,DS-98b3205d-d266-44c2-88ce-bd4285a0433a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1587376047-172.17.0.3-1595390066863:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33635,DS-98d7ee27-492b-438d-83a5-8fdc5d05a326,DISK], DatanodeInfoWithStorage[127.0.0.1:46457,DS-f88ff9d6-3b52-4369-b3fb-a5865f695d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:43199,DS-4a16e850-6219-4e51-84f3-6cbff2d7d3f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46367,DS-3c7129c1-ff1f-4707-8400-3abb2f7eab1f,DISK], DatanodeInfoWithStorage[127.0.0.1:38203,DS-50b248d5-2782-4377-9bc4-a03043cc47ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45789,DS-9bdd58d1-95a4-4214-844d-0efdbcecdee9,DISK], DatanodeInfoWithStorage[127.0.0.1:33403,DS-d0642ecc-b73d-425b-8fc6-b65fc9ee7512,DISK], DatanodeInfoWithStorage[127.0.0.1:45311,DS-b5d75d6b-4714-42f2-93f6-8403205a71ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1587376047-172.17.0.3-1595390066863:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33635,DS-98d7ee27-492b-438d-83a5-8fdc5d05a326,DISK], DatanodeInfoWithStorage[127.0.0.1:46457,DS-f88ff9d6-3b52-4369-b3fb-a5865f695d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:43199,DS-4a16e850-6219-4e51-84f3-6cbff2d7d3f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46367,DS-3c7129c1-ff1f-4707-8400-3abb2f7eab1f,DISK], DatanodeInfoWithStorage[127.0.0.1:38203,DS-50b248d5-2782-4377-9bc4-a03043cc47ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45789,DS-9bdd58d1-95a4-4214-844d-0efdbcecdee9,DISK], DatanodeInfoWithStorage[127.0.0.1:33403,DS-d0642ecc-b73d-425b-8fc6-b65fc9ee7512,DISK], DatanodeInfoWithStorage[127.0.0.1:45311,DS-b5d75d6b-4714-42f2-93f6-8403205a71ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5166
