reconf_parameter: dfs.client.mmap.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-605303731-172.17.0.12-1596955514946:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35795,DS-a6934c1f-0266-46d9-a3c5-22283e020e92,DISK], DatanodeInfoWithStorage[127.0.0.1:32929,DS-f7822c47-8891-4cd0-ae09-248369aeeab2,DISK], DatanodeInfoWithStorage[127.0.0.1:45971,DS-1c677650-29f1-4c0e-96c5-f39ae2a31437,DISK], DatanodeInfoWithStorage[127.0.0.1:36927,DS-2cf7b89c-254c-412b-bfa6-f34e57d98602,DISK], DatanodeInfoWithStorage[127.0.0.1:35807,DS-0696d5a0-1e65-4c39-b28d-b22101301817,DISK], DatanodeInfoWithStorage[127.0.0.1:44036,DS-1de4b2bd-f93d-4d5d-8023-78b3ec549fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:40507,DS-88714d90-4028-4ace-bb8e-1111998181fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37642,DS-a7e454c1-e69f-4f47-a6f1-bda061abe71d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-605303731-172.17.0.12-1596955514946:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35795,DS-a6934c1f-0266-46d9-a3c5-22283e020e92,DISK], DatanodeInfoWithStorage[127.0.0.1:32929,DS-f7822c47-8891-4cd0-ae09-248369aeeab2,DISK], DatanodeInfoWithStorage[127.0.0.1:45971,DS-1c677650-29f1-4c0e-96c5-f39ae2a31437,DISK], DatanodeInfoWithStorage[127.0.0.1:36927,DS-2cf7b89c-254c-412b-bfa6-f34e57d98602,DISK], DatanodeInfoWithStorage[127.0.0.1:35807,DS-0696d5a0-1e65-4c39-b28d-b22101301817,DISK], DatanodeInfoWithStorage[127.0.0.1:44036,DS-1de4b2bd-f93d-4d5d-8023-78b3ec549fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:40507,DS-88714d90-4028-4ace-bb8e-1111998181fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37642,DS-a7e454c1-e69f-4f47-a6f1-bda061abe71d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-673273249-172.17.0.12-1596955651333:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46471,DS-be2fa0f9-ef97-4424-a882-b18c57dec9ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44428,DS-45633eeb-e8a0-4cf3-a12c-4d3773c9e6c3,DISK], DatanodeInfoWithStorage[127.0.0.1:45674,DS-ee8cdba5-6b8f-41c7-9b62-05e8640d4ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:39234,DS-54908172-22e1-4222-b449-c7bb35cba67d,DISK], DatanodeInfoWithStorage[127.0.0.1:35477,DS-99a8465d-3729-463d-9b86-d1f8cf18f3a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38597,DS-5af29b51-d2d7-4078-a403-169e618ab005,DISK], DatanodeInfoWithStorage[127.0.0.1:45203,DS-420804d7-8fba-48e6-a898-96b6b1deec17,DISK], DatanodeInfoWithStorage[127.0.0.1:42303,DS-7c5c29c2-c83d-4034-8fbc-2191f3362c4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-673273249-172.17.0.12-1596955651333:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46471,DS-be2fa0f9-ef97-4424-a882-b18c57dec9ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44428,DS-45633eeb-e8a0-4cf3-a12c-4d3773c9e6c3,DISK], DatanodeInfoWithStorage[127.0.0.1:45674,DS-ee8cdba5-6b8f-41c7-9b62-05e8640d4ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:39234,DS-54908172-22e1-4222-b449-c7bb35cba67d,DISK], DatanodeInfoWithStorage[127.0.0.1:35477,DS-99a8465d-3729-463d-9b86-d1f8cf18f3a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38597,DS-5af29b51-d2d7-4078-a403-169e618ab005,DISK], DatanodeInfoWithStorage[127.0.0.1:45203,DS-420804d7-8fba-48e6-a898-96b6b1deec17,DISK], DatanodeInfoWithStorage[127.0.0.1:42303,DS-7c5c29c2-c83d-4034-8fbc-2191f3362c4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.mmap.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1492556384-172.17.0.12-1596955684288:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34398,DS-f75a3735-16db-4c49-80ab-1bf1f595b09f,DISK], DatanodeInfoWithStorage[127.0.0.1:33165,DS-bb214d55-ea79-4dc2-8867-bee093ae6927,DISK], DatanodeInfoWithStorage[127.0.0.1:42662,DS-d21fac60-df96-4ab5-bf92-00759da48d61,DISK], DatanodeInfoWithStorage[127.0.0.1:44846,DS-6ce47adc-ae1e-42c7-96e0-70210d03ac31,DISK], DatanodeInfoWithStorage[127.0.0.1:40097,DS-479c0158-8989-480d-b752-55b9ba62dc89,DISK], DatanodeInfoWithStorage[127.0.0.1:36383,DS-13a1fd6a-6bc9-447d-b4ea-3a107cf6885c,DISK], DatanodeInfoWithStorage[127.0.0.1:42046,DS-23ae51a9-4740-452b-aa93-23b55fefb361,DISK], DatanodeInfoWithStorage[127.0.0.1:42551,DS-25d441bf-f2a6-47a2-b182-41f09c276020,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1492556384-172.17.0.12-1596955684288:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34398,DS-f75a3735-16db-4c49-80ab-1bf1f595b09f,DISK], DatanodeInfoWithStorage[127.0.0.1:33165,DS-bb214d55-ea79-4dc2-8867-bee093ae6927,DISK], DatanodeInfoWithStorage[127.0.0.1:42662,DS-d21fac60-df96-4ab5-bf92-00759da48d61,DISK], DatanodeInfoWithStorage[127.0.0.1:44846,DS-6ce47adc-ae1e-42c7-96e0-70210d03ac31,DISK], DatanodeInfoWithStorage[127.0.0.1:40097,DS-479c0158-8989-480d-b752-55b9ba62dc89,DISK], DatanodeInfoWithStorage[127.0.0.1:36383,DS-13a1fd6a-6bc9-447d-b4ea-3a107cf6885c,DISK], DatanodeInfoWithStorage[127.0.0.1:42046,DS-23ae51a9-4740-452b-aa93-23b55fefb361,DISK], DatanodeInfoWithStorage[127.0.0.1:42551,DS-25d441bf-f2a6-47a2-b182-41f09c276020,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2081226466-172.17.0.12-1596955854111:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44815,DS-a5df9bc7-37f7-41d3-96cd-fde9474bb037,DISK], DatanodeInfoWithStorage[127.0.0.1:37215,DS-6812c494-7e60-4145-919b-a8009b3c6180,DISK], DatanodeInfoWithStorage[127.0.0.1:33717,DS-42dd154f-6a41-4917-92c5-e67d1112f03c,DISK], DatanodeInfoWithStorage[127.0.0.1:34700,DS-108e1bad-878e-41fd-9c4c-27c621fd7bfb,DISK], DatanodeInfoWithStorage[127.0.0.1:45199,DS-126c1867-5fcc-4c32-8a54-26615c20ab4d,DISK], DatanodeInfoWithStorage[127.0.0.1:34239,DS-88bcdfbf-c04b-4269-8bf4-980e6e03f80e,DISK], DatanodeInfoWithStorage[127.0.0.1:44543,DS-f30380a2-ed36-4ee6-9c54-3286b88aacf3,DISK], DatanodeInfoWithStorage[127.0.0.1:33886,DS-27199fe4-abf5-4607-af6f-1fd395bdc745,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2081226466-172.17.0.12-1596955854111:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44815,DS-a5df9bc7-37f7-41d3-96cd-fde9474bb037,DISK], DatanodeInfoWithStorage[127.0.0.1:37215,DS-6812c494-7e60-4145-919b-a8009b3c6180,DISK], DatanodeInfoWithStorage[127.0.0.1:33717,DS-42dd154f-6a41-4917-92c5-e67d1112f03c,DISK], DatanodeInfoWithStorage[127.0.0.1:34700,DS-108e1bad-878e-41fd-9c4c-27c621fd7bfb,DISK], DatanodeInfoWithStorage[127.0.0.1:45199,DS-126c1867-5fcc-4c32-8a54-26615c20ab4d,DISK], DatanodeInfoWithStorage[127.0.0.1:34239,DS-88bcdfbf-c04b-4269-8bf4-980e6e03f80e,DISK], DatanodeInfoWithStorage[127.0.0.1:44543,DS-f30380a2-ed36-4ee6-9c54-3286b88aacf3,DISK], DatanodeInfoWithStorage[127.0.0.1:33886,DS-27199fe4-abf5-4607-af6f-1fd395bdc745,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.mmap.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-200081983-172.17.0.12-1596955882565:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38269,DS-d76b5417-31cd-4223-ad90-43d8860b701d,DISK], DatanodeInfoWithStorage[127.0.0.1:35837,DS-f7e954d1-b815-4655-8011-b1d5b6b98019,DISK], DatanodeInfoWithStorage[127.0.0.1:36804,DS-957bb9f3-035b-48bc-b623-1f88822addb4,DISK], DatanodeInfoWithStorage[127.0.0.1:38184,DS-73a12f00-f030-4caf-9da3-88feeab97fca,DISK], DatanodeInfoWithStorage[127.0.0.1:38582,DS-ea5059cf-1e3c-486a-a199-0b915acb6b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:43826,DS-04c1011d-f911-464a-8481-da1673552b03,DISK], DatanodeInfoWithStorage[127.0.0.1:34223,DS-97170827-5777-4a72-bc93-93201351b356,DISK], DatanodeInfoWithStorage[127.0.0.1:38651,DS-5454585e-610e-4e29-9499-ecca30720403,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-200081983-172.17.0.12-1596955882565:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38269,DS-d76b5417-31cd-4223-ad90-43d8860b701d,DISK], DatanodeInfoWithStorage[127.0.0.1:35837,DS-f7e954d1-b815-4655-8011-b1d5b6b98019,DISK], DatanodeInfoWithStorage[127.0.0.1:36804,DS-957bb9f3-035b-48bc-b623-1f88822addb4,DISK], DatanodeInfoWithStorage[127.0.0.1:38184,DS-73a12f00-f030-4caf-9da3-88feeab97fca,DISK], DatanodeInfoWithStorage[127.0.0.1:38582,DS-ea5059cf-1e3c-486a-a199-0b915acb6b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:43826,DS-04c1011d-f911-464a-8481-da1673552b03,DISK], DatanodeInfoWithStorage[127.0.0.1:34223,DS-97170827-5777-4a72-bc93-93201351b356,DISK], DatanodeInfoWithStorage[127.0.0.1:38651,DS-5454585e-610e-4e29-9499-ecca30720403,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1346406453-172.17.0.12-1596956026190:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46205,DS-c8f1aa37-da26-44cd-a412-2dadd0f62381,DISK], DatanodeInfoWithStorage[127.0.0.1:42232,DS-c79bad03-b600-46c8-b2ee-61de57ac844b,DISK], DatanodeInfoWithStorage[127.0.0.1:38269,DS-e96fbdd5-4539-41fc-9768-25cf5b9c34de,DISK], DatanodeInfoWithStorage[127.0.0.1:39603,DS-4cde956a-a40c-4b25-bcf6-f86c4a0e0401,DISK], DatanodeInfoWithStorage[127.0.0.1:42131,DS-651e4213-bb81-49b6-81c5-d45f52d0ed76,DISK], DatanodeInfoWithStorage[127.0.0.1:42645,DS-1c24d501-e474-4341-82a4-04d1bc4868d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39984,DS-da787051-f99a-473d-ae2b-524a9f9520ca,DISK], DatanodeInfoWithStorage[127.0.0.1:46400,DS-cff1e3b9-0786-4b24-b623-6ba58e25b52c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1346406453-172.17.0.12-1596956026190:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46205,DS-c8f1aa37-da26-44cd-a412-2dadd0f62381,DISK], DatanodeInfoWithStorage[127.0.0.1:42232,DS-c79bad03-b600-46c8-b2ee-61de57ac844b,DISK], DatanodeInfoWithStorage[127.0.0.1:38269,DS-e96fbdd5-4539-41fc-9768-25cf5b9c34de,DISK], DatanodeInfoWithStorage[127.0.0.1:39603,DS-4cde956a-a40c-4b25-bcf6-f86c4a0e0401,DISK], DatanodeInfoWithStorage[127.0.0.1:42131,DS-651e4213-bb81-49b6-81c5-d45f52d0ed76,DISK], DatanodeInfoWithStorage[127.0.0.1:42645,DS-1c24d501-e474-4341-82a4-04d1bc4868d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39984,DS-da787051-f99a-473d-ae2b-524a9f9520ca,DISK], DatanodeInfoWithStorage[127.0.0.1:46400,DS-cff1e3b9-0786-4b24-b623-6ba58e25b52c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-222629346-172.17.0.12-1596956132126:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46773,DS-2f153263-4f82-4097-8fcb-d4950416ba69,DISK], DatanodeInfoWithStorage[127.0.0.1:32818,DS-925f8648-ed8b-418f-bc69-b9e9f1bd3992,DISK], DatanodeInfoWithStorage[127.0.0.1:35564,DS-93f9d080-0193-4834-8b30-0d06aec3473d,DISK], DatanodeInfoWithStorage[127.0.0.1:45656,DS-bec7884d-3686-4340-9dfd-9c1ee5bbd7f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44589,DS-f8deb440-f32c-4c1f-aa72-3fedcfc816b8,DISK], DatanodeInfoWithStorage[127.0.0.1:36825,DS-e0ea08b2-6338-4400-8cb7-25f2dd47d714,DISK], DatanodeInfoWithStorage[127.0.0.1:40600,DS-979969c8-f38f-4b2b-8c4c-0c1e77acfa88,DISK], DatanodeInfoWithStorage[127.0.0.1:34188,DS-1f41d3d0-11ec-4462-8c6f-08470382fd93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-222629346-172.17.0.12-1596956132126:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46773,DS-2f153263-4f82-4097-8fcb-d4950416ba69,DISK], DatanodeInfoWithStorage[127.0.0.1:32818,DS-925f8648-ed8b-418f-bc69-b9e9f1bd3992,DISK], DatanodeInfoWithStorage[127.0.0.1:35564,DS-93f9d080-0193-4834-8b30-0d06aec3473d,DISK], DatanodeInfoWithStorage[127.0.0.1:45656,DS-bec7884d-3686-4340-9dfd-9c1ee5bbd7f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44589,DS-f8deb440-f32c-4c1f-aa72-3fedcfc816b8,DISK], DatanodeInfoWithStorage[127.0.0.1:36825,DS-e0ea08b2-6338-4400-8cb7-25f2dd47d714,DISK], DatanodeInfoWithStorage[127.0.0.1:40600,DS-979969c8-f38f-4b2b-8c4c-0c1e77acfa88,DISK], DatanodeInfoWithStorage[127.0.0.1:34188,DS-1f41d3d0-11ec-4462-8c6f-08470382fd93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-369813316-172.17.0.12-1596956266859:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45465,DS-f38474b0-3fd6-4644-997e-4a37f070ab57,DISK], DatanodeInfoWithStorage[127.0.0.1:42013,DS-2dd3f045-3c3e-41fe-8db4-01484c3af727,DISK], DatanodeInfoWithStorage[127.0.0.1:41230,DS-812e787c-d677-4904-b713-a6b32094f12a,DISK], DatanodeInfoWithStorage[127.0.0.1:37140,DS-f0189399-1258-404e-bc8b-ade201a1e291,DISK], DatanodeInfoWithStorage[127.0.0.1:40240,DS-fa23d4ab-eb11-40e0-9a09-7c6afe5a67af,DISK], DatanodeInfoWithStorage[127.0.0.1:32840,DS-5f5d8cde-fd71-47e3-a37c-78d9dca7ddf9,DISK], DatanodeInfoWithStorage[127.0.0.1:37377,DS-e202e61b-1aeb-4ab7-a169-fe273628aa00,DISK], DatanodeInfoWithStorage[127.0.0.1:33789,DS-74791343-0511-431a-b8c5-71c816b1267f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-369813316-172.17.0.12-1596956266859:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45465,DS-f38474b0-3fd6-4644-997e-4a37f070ab57,DISK], DatanodeInfoWithStorage[127.0.0.1:42013,DS-2dd3f045-3c3e-41fe-8db4-01484c3af727,DISK], DatanodeInfoWithStorage[127.0.0.1:41230,DS-812e787c-d677-4904-b713-a6b32094f12a,DISK], DatanodeInfoWithStorage[127.0.0.1:37140,DS-f0189399-1258-404e-bc8b-ade201a1e291,DISK], DatanodeInfoWithStorage[127.0.0.1:40240,DS-fa23d4ab-eb11-40e0-9a09-7c6afe5a67af,DISK], DatanodeInfoWithStorage[127.0.0.1:32840,DS-5f5d8cde-fd71-47e3-a37c-78d9dca7ddf9,DISK], DatanodeInfoWithStorage[127.0.0.1:37377,DS-e202e61b-1aeb-4ab7-a169-fe273628aa00,DISK], DatanodeInfoWithStorage[127.0.0.1:33789,DS-74791343-0511-431a-b8c5-71c816b1267f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-800648214-172.17.0.12-1596956474714:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40918,DS-68190f34-bcb6-4337-a9dc-ec7f58f0652d,DISK], DatanodeInfoWithStorage[127.0.0.1:38466,DS-572d3643-96ed-4a45-9b11-4f96c672badc,DISK], DatanodeInfoWithStorage[127.0.0.1:42262,DS-050a664b-8587-42b4-8516-1ae244dd50e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43368,DS-4afe5509-e4b1-406f-8cb8-90e70ea76278,DISK], DatanodeInfoWithStorage[127.0.0.1:36227,DS-f6fdc90c-21c7-4136-873d-e52d5ab9567e,DISK], DatanodeInfoWithStorage[127.0.0.1:46429,DS-394d4b3a-007d-4845-9bf3-0ba2fbc4fbcf,DISK], DatanodeInfoWithStorage[127.0.0.1:46497,DS-9fce2176-04da-48a7-b72e-b6a17b3bdd3b,DISK], DatanodeInfoWithStorage[127.0.0.1:40271,DS-b0873375-6ccb-43aa-a94f-ae30f55f37f2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-800648214-172.17.0.12-1596956474714:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40918,DS-68190f34-bcb6-4337-a9dc-ec7f58f0652d,DISK], DatanodeInfoWithStorage[127.0.0.1:38466,DS-572d3643-96ed-4a45-9b11-4f96c672badc,DISK], DatanodeInfoWithStorage[127.0.0.1:42262,DS-050a664b-8587-42b4-8516-1ae244dd50e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43368,DS-4afe5509-e4b1-406f-8cb8-90e70ea76278,DISK], DatanodeInfoWithStorage[127.0.0.1:36227,DS-f6fdc90c-21c7-4136-873d-e52d5ab9567e,DISK], DatanodeInfoWithStorage[127.0.0.1:46429,DS-394d4b3a-007d-4845-9bf3-0ba2fbc4fbcf,DISK], DatanodeInfoWithStorage[127.0.0.1:46497,DS-9fce2176-04da-48a7-b72e-b6a17b3bdd3b,DISK], DatanodeInfoWithStorage[127.0.0.1:40271,DS-b0873375-6ccb-43aa-a94f-ae30f55f37f2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-481396394-172.17.0.12-1596956715161:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38343,DS-efa3f0ac-9c25-4046-b00e-781a8be2a297,DISK], DatanodeInfoWithStorage[127.0.0.1:46721,DS-107b3054-6301-4ffa-95c3-08ca4cc7f918,DISK], DatanodeInfoWithStorage[127.0.0.1:34953,DS-4bce7a68-4737-49a4-a653-a6a73a4fe3a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40326,DS-a646555d-2d50-4a81-afcf-14f2637bae8d,DISK], DatanodeInfoWithStorage[127.0.0.1:33707,DS-6ffc6c6c-00e0-4b07-a71d-4d5dcf7e1133,DISK], DatanodeInfoWithStorage[127.0.0.1:36147,DS-8f9a393d-36e3-4067-b45c-0519fe3748c0,DISK], DatanodeInfoWithStorage[127.0.0.1:44491,DS-45ea61b1-c15f-499f-afe0-ddea10ba8f09,DISK], DatanodeInfoWithStorage[127.0.0.1:42865,DS-75fd849d-6282-4157-a0f1-50573be81733,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-481396394-172.17.0.12-1596956715161:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38343,DS-efa3f0ac-9c25-4046-b00e-781a8be2a297,DISK], DatanodeInfoWithStorage[127.0.0.1:46721,DS-107b3054-6301-4ffa-95c3-08ca4cc7f918,DISK], DatanodeInfoWithStorage[127.0.0.1:34953,DS-4bce7a68-4737-49a4-a653-a6a73a4fe3a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40326,DS-a646555d-2d50-4a81-afcf-14f2637bae8d,DISK], DatanodeInfoWithStorage[127.0.0.1:33707,DS-6ffc6c6c-00e0-4b07-a71d-4d5dcf7e1133,DISK], DatanodeInfoWithStorage[127.0.0.1:36147,DS-8f9a393d-36e3-4067-b45c-0519fe3748c0,DISK], DatanodeInfoWithStorage[127.0.0.1:44491,DS-45ea61b1-c15f-499f-afe0-ddea10ba8f09,DISK], DatanodeInfoWithStorage[127.0.0.1:42865,DS-75fd849d-6282-4157-a0f1-50573be81733,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-270797692-172.17.0.12-1596956819157:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42435,DS-86614c77-d0cd-417d-864a-1af71f0bcf38,DISK], DatanodeInfoWithStorage[127.0.0.1:45645,DS-228f2e70-6e58-4e17-87e9-048bfc89161f,DISK], DatanodeInfoWithStorage[127.0.0.1:43158,DS-d37f32a2-35cf-4120-8ee7-76a51d591547,DISK], DatanodeInfoWithStorage[127.0.0.1:44022,DS-211373e9-3072-4256-b6dd-6344300fe663,DISK], DatanodeInfoWithStorage[127.0.0.1:38985,DS-54ba3f57-84a3-40df-9bf5-278f23c7a04d,DISK], DatanodeInfoWithStorage[127.0.0.1:41555,DS-4993a0f4-0945-4de9-947f-449868de3f87,DISK], DatanodeInfoWithStorage[127.0.0.1:45698,DS-e55865ed-8d35-4020-ba31-453dcf8eb8d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45388,DS-a4abad01-3aaa-490e-885d-55dbf2320b8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-270797692-172.17.0.12-1596956819157:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42435,DS-86614c77-d0cd-417d-864a-1af71f0bcf38,DISK], DatanodeInfoWithStorage[127.0.0.1:45645,DS-228f2e70-6e58-4e17-87e9-048bfc89161f,DISK], DatanodeInfoWithStorage[127.0.0.1:43158,DS-d37f32a2-35cf-4120-8ee7-76a51d591547,DISK], DatanodeInfoWithStorage[127.0.0.1:44022,DS-211373e9-3072-4256-b6dd-6344300fe663,DISK], DatanodeInfoWithStorage[127.0.0.1:38985,DS-54ba3f57-84a3-40df-9bf5-278f23c7a04d,DISK], DatanodeInfoWithStorage[127.0.0.1:41555,DS-4993a0f4-0945-4de9-947f-449868de3f87,DISK], DatanodeInfoWithStorage[127.0.0.1:45698,DS-e55865ed-8d35-4020-ba31-453dcf8eb8d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45388,DS-a4abad01-3aaa-490e-885d-55dbf2320b8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2018882060-172.17.0.12-1596956853074:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38274,DS-bf0dad2a-bfdc-4d95-8e0e-7e9a4f85fe64,DISK], DatanodeInfoWithStorage[127.0.0.1:33942,DS-6a4e1584-a311-403d-ab0c-f86b7ff2e550,DISK], DatanodeInfoWithStorage[127.0.0.1:37789,DS-f0ce77bd-e9d9-47a5-9d9d-cdb86efcf09a,DISK], DatanodeInfoWithStorage[127.0.0.1:42194,DS-78726455-47d8-4386-a7b0-b8c1fee12ec2,DISK], DatanodeInfoWithStorage[127.0.0.1:44237,DS-ef46ef66-8460-4628-9e5e-815bb34b2ee9,DISK], DatanodeInfoWithStorage[127.0.0.1:34485,DS-019ec624-449e-4955-b81b-ad4253c6a40d,DISK], DatanodeInfoWithStorage[127.0.0.1:33654,DS-84ac90ec-f9df-40fc-a298-5d7caabbc6d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36122,DS-a43a39a9-8297-4122-96cb-fc5cf9a9a0b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2018882060-172.17.0.12-1596956853074:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38274,DS-bf0dad2a-bfdc-4d95-8e0e-7e9a4f85fe64,DISK], DatanodeInfoWithStorage[127.0.0.1:33942,DS-6a4e1584-a311-403d-ab0c-f86b7ff2e550,DISK], DatanodeInfoWithStorage[127.0.0.1:37789,DS-f0ce77bd-e9d9-47a5-9d9d-cdb86efcf09a,DISK], DatanodeInfoWithStorage[127.0.0.1:42194,DS-78726455-47d8-4386-a7b0-b8c1fee12ec2,DISK], DatanodeInfoWithStorage[127.0.0.1:44237,DS-ef46ef66-8460-4628-9e5e-815bb34b2ee9,DISK], DatanodeInfoWithStorage[127.0.0.1:34485,DS-019ec624-449e-4955-b81b-ad4253c6a40d,DISK], DatanodeInfoWithStorage[127.0.0.1:33654,DS-84ac90ec-f9df-40fc-a298-5d7caabbc6d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36122,DS-a43a39a9-8297-4122-96cb-fc5cf9a9a0b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1770776624-172.17.0.12-1596957055494:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40059,DS-08d0eaed-fcb6-4aba-adf2-a81261e159ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39463,DS-e73b53cc-a3f8-4916-b692-175272ef4ade,DISK], DatanodeInfoWithStorage[127.0.0.1:36760,DS-ca552404-8a2f-4389-a229-6020e81e90cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39626,DS-80c64c1a-45c8-482f-95c2-b427e208b11e,DISK], DatanodeInfoWithStorage[127.0.0.1:42540,DS-011c0079-caeb-4422-a2c7-16baab2787d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42240,DS-dce7e360-e87c-4c9d-aa73-74e769873cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:43429,DS-5900b294-c313-4381-b054-3faa2d2030cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39596,DS-6abab18f-4f69-41ae-b1e2-3e8005243df5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1770776624-172.17.0.12-1596957055494:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40059,DS-08d0eaed-fcb6-4aba-adf2-a81261e159ea,DISK], DatanodeInfoWithStorage[127.0.0.1:39463,DS-e73b53cc-a3f8-4916-b692-175272ef4ade,DISK], DatanodeInfoWithStorage[127.0.0.1:36760,DS-ca552404-8a2f-4389-a229-6020e81e90cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39626,DS-80c64c1a-45c8-482f-95c2-b427e208b11e,DISK], DatanodeInfoWithStorage[127.0.0.1:42540,DS-011c0079-caeb-4422-a2c7-16baab2787d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42240,DS-dce7e360-e87c-4c9d-aa73-74e769873cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:43429,DS-5900b294-c313-4381-b054-3faa2d2030cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39596,DS-6abab18f-4f69-41ae-b1e2-3e8005243df5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1828943462-172.17.0.12-1596957122670:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42697,DS-4080e78f-b388-4c3d-9734-ac230197d3b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41978,DS-07d5fbcd-a63c-4ca7-a989-c500e22170a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35756,DS-5e62e788-428e-450c-a546-5481162ed496,DISK], DatanodeInfoWithStorage[127.0.0.1:33617,DS-e73806f2-78e3-4a06-9bd7-bb879ce03bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:46548,DS-efc233f2-3550-4e5c-8903-4e99d683bd70,DISK], DatanodeInfoWithStorage[127.0.0.1:40969,DS-6daab598-38ec-46c4-9b6d-504763fbcc72,DISK], DatanodeInfoWithStorage[127.0.0.1:37625,DS-e2b04baf-e2a9-4bdf-a47a-31ea97a03489,DISK], DatanodeInfoWithStorage[127.0.0.1:33441,DS-ae417016-e34f-48a3-bb5d-05104ba588b3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1828943462-172.17.0.12-1596957122670:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42697,DS-4080e78f-b388-4c3d-9734-ac230197d3b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41978,DS-07d5fbcd-a63c-4ca7-a989-c500e22170a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35756,DS-5e62e788-428e-450c-a546-5481162ed496,DISK], DatanodeInfoWithStorage[127.0.0.1:33617,DS-e73806f2-78e3-4a06-9bd7-bb879ce03bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:46548,DS-efc233f2-3550-4e5c-8903-4e99d683bd70,DISK], DatanodeInfoWithStorage[127.0.0.1:40969,DS-6daab598-38ec-46c4-9b6d-504763fbcc72,DISK], DatanodeInfoWithStorage[127.0.0.1:37625,DS-e2b04baf-e2a9-4bdf-a47a-31ea97a03489,DISK], DatanodeInfoWithStorage[127.0.0.1:33441,DS-ae417016-e34f-48a3-bb5d-05104ba588b3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-3956768-172.17.0.12-1596957187682:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42916,DS-7be796f9-f101-4b41-bd0e-5d8b06871ea5,DISK], DatanodeInfoWithStorage[127.0.0.1:46603,DS-158e5f70-03a0-4cd9-ae57-c0726ee6131f,DISK], DatanodeInfoWithStorage[127.0.0.1:46169,DS-4c9ddbf1-14bf-4efb-a800-81343e9f31d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35591,DS-9ecca887-8abc-4d1f-b263-816400194425,DISK], DatanodeInfoWithStorage[127.0.0.1:43646,DS-35515e6c-7093-4751-91ff-9776b2c72aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:44733,DS-37b46b1d-81ff-442d-8e9f-855153f3f149,DISK], DatanodeInfoWithStorage[127.0.0.1:36765,DS-2a59b92e-c52e-415b-8864-602c5abf70ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42077,DS-39291739-c814-4264-9e74-38136f940fed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-3956768-172.17.0.12-1596957187682:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42916,DS-7be796f9-f101-4b41-bd0e-5d8b06871ea5,DISK], DatanodeInfoWithStorage[127.0.0.1:46603,DS-158e5f70-03a0-4cd9-ae57-c0726ee6131f,DISK], DatanodeInfoWithStorage[127.0.0.1:46169,DS-4c9ddbf1-14bf-4efb-a800-81343e9f31d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35591,DS-9ecca887-8abc-4d1f-b263-816400194425,DISK], DatanodeInfoWithStorage[127.0.0.1:43646,DS-35515e6c-7093-4751-91ff-9776b2c72aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:44733,DS-37b46b1d-81ff-442d-8e9f-855153f3f149,DISK], DatanodeInfoWithStorage[127.0.0.1:36765,DS-2a59b92e-c52e-415b-8864-602c5abf70ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42077,DS-39291739-c814-4264-9e74-38136f940fed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2116833788-172.17.0.12-1596957244906:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40132,DS-cdb9bf9e-46a7-4153-8ec1-3f91874917e1,DISK], DatanodeInfoWithStorage[127.0.0.1:46115,DS-f995a816-1aba-465b-aaf3-1675bf6ef726,DISK], DatanodeInfoWithStorage[127.0.0.1:38366,DS-587cb88a-5984-4c49-baa9-cd768e06db8c,DISK], DatanodeInfoWithStorage[127.0.0.1:45485,DS-7f80edc4-2903-4ced-9ace-ee65c947ff6a,DISK], DatanodeInfoWithStorage[127.0.0.1:34314,DS-818e447e-015f-4207-9338-215da95df985,DISK], DatanodeInfoWithStorage[127.0.0.1:36941,DS-1f55d785-37dd-4e96-b0ec-2900c3b9d1b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44173,DS-0d058bd8-5d88-4bfd-afbc-f0b34c7f05ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37483,DS-4b65f117-2558-4987-acdf-2b04aeea445f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2116833788-172.17.0.12-1596957244906:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40132,DS-cdb9bf9e-46a7-4153-8ec1-3f91874917e1,DISK], DatanodeInfoWithStorage[127.0.0.1:46115,DS-f995a816-1aba-465b-aaf3-1675bf6ef726,DISK], DatanodeInfoWithStorage[127.0.0.1:38366,DS-587cb88a-5984-4c49-baa9-cd768e06db8c,DISK], DatanodeInfoWithStorage[127.0.0.1:45485,DS-7f80edc4-2903-4ced-9ace-ee65c947ff6a,DISK], DatanodeInfoWithStorage[127.0.0.1:34314,DS-818e447e-015f-4207-9338-215da95df985,DISK], DatanodeInfoWithStorage[127.0.0.1:36941,DS-1f55d785-37dd-4e96-b0ec-2900c3b9d1b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44173,DS-0d058bd8-5d88-4bfd-afbc-f0b34c7f05ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37483,DS-4b65f117-2558-4987-acdf-2b04aeea445f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1143999296-172.17.0.12-1596957344179:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39406,DS-a951d13a-4372-4f68-a312-712ccb193e3e,DISK], DatanodeInfoWithStorage[127.0.0.1:43935,DS-b623f459-7033-4164-b6c7-0f4c17de7a12,DISK], DatanodeInfoWithStorage[127.0.0.1:33077,DS-7306ed86-b5b0-4c80-a4b5-3431878538f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38983,DS-a4df6880-4a12-4b2c-91e0-22e90bec659f,DISK], DatanodeInfoWithStorage[127.0.0.1:34783,DS-2ff21cc5-5774-4bd9-a0a6-cc5f6a7d1d05,DISK], DatanodeInfoWithStorage[127.0.0.1:40183,DS-2e53b820-6b07-4f3b-9ba8-11f4e59fb4db,DISK], DatanodeInfoWithStorage[127.0.0.1:34444,DS-8eee8a1f-923e-4395-a108-2fc9a93d62e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42206,DS-f344980f-257d-45b1-97ca-5a56a80076fa,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1143999296-172.17.0.12-1596957344179:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39406,DS-a951d13a-4372-4f68-a312-712ccb193e3e,DISK], DatanodeInfoWithStorage[127.0.0.1:43935,DS-b623f459-7033-4164-b6c7-0f4c17de7a12,DISK], DatanodeInfoWithStorage[127.0.0.1:33077,DS-7306ed86-b5b0-4c80-a4b5-3431878538f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38983,DS-a4df6880-4a12-4b2c-91e0-22e90bec659f,DISK], DatanodeInfoWithStorage[127.0.0.1:34783,DS-2ff21cc5-5774-4bd9-a0a6-cc5f6a7d1d05,DISK], DatanodeInfoWithStorage[127.0.0.1:40183,DS-2e53b820-6b07-4f3b-9ba8-11f4e59fb4db,DISK], DatanodeInfoWithStorage[127.0.0.1:34444,DS-8eee8a1f-923e-4395-a108-2fc9a93d62e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42206,DS-f344980f-257d-45b1-97ca-5a56a80076fa,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1544921047-172.17.0.12-1596957534850:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46521,DS-290d17d4-96c1-4d72-a4c4-2449fef0a446,DISK], DatanodeInfoWithStorage[127.0.0.1:35455,DS-0b38f532-3f05-473d-8209-5f9dced00dcd,DISK], DatanodeInfoWithStorage[127.0.0.1:34911,DS-97bf7dc3-c9e1-41b6-bfae-059b69b2ebc7,DISK], DatanodeInfoWithStorage[127.0.0.1:37777,DS-3dd090e0-6cfc-4299-87dd-a3bb8a4936fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45645,DS-628bb1f9-31cd-4e76-8268-3ef365acb704,DISK], DatanodeInfoWithStorage[127.0.0.1:39300,DS-440f735d-83c6-4462-b2ba-68c3ba7ff628,DISK], DatanodeInfoWithStorage[127.0.0.1:44530,DS-3172db02-189e-4081-9de0-f7ae6f57f956,DISK], DatanodeInfoWithStorage[127.0.0.1:33116,DS-07a28557-8409-4bb6-a5cd-f3ce2c840824,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1544921047-172.17.0.12-1596957534850:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46521,DS-290d17d4-96c1-4d72-a4c4-2449fef0a446,DISK], DatanodeInfoWithStorage[127.0.0.1:35455,DS-0b38f532-3f05-473d-8209-5f9dced00dcd,DISK], DatanodeInfoWithStorage[127.0.0.1:34911,DS-97bf7dc3-c9e1-41b6-bfae-059b69b2ebc7,DISK], DatanodeInfoWithStorage[127.0.0.1:37777,DS-3dd090e0-6cfc-4299-87dd-a3bb8a4936fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45645,DS-628bb1f9-31cd-4e76-8268-3ef365acb704,DISK], DatanodeInfoWithStorage[127.0.0.1:39300,DS-440f735d-83c6-4462-b2ba-68c3ba7ff628,DISK], DatanodeInfoWithStorage[127.0.0.1:44530,DS-3172db02-189e-4081-9de0-f7ae6f57f956,DISK], DatanodeInfoWithStorage[127.0.0.1:33116,DS-07a28557-8409-4bb6-a5cd-f3ce2c840824,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-418132191-172.17.0.12-1596957794746:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34280,DS-8ed25bf2-f7a7-4447-9220-edff06ef3569,DISK], DatanodeInfoWithStorage[127.0.0.1:35043,DS-7135c35b-2ce9-458c-bcef-6635cb9f487b,DISK], DatanodeInfoWithStorage[127.0.0.1:34694,DS-b75b549c-63e2-4a55-8f06-02d7f95e68c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38272,DS-bbcec6e3-d326-4580-8f65-120cd4238d62,DISK], DatanodeInfoWithStorage[127.0.0.1:38489,DS-3b3c0093-b3ec-497f-be36-353da0c2a79f,DISK], DatanodeInfoWithStorage[127.0.0.1:35025,DS-9e0f7d44-a7be-419a-8251-5704e9f42e38,DISK], DatanodeInfoWithStorage[127.0.0.1:41034,DS-2068c8b0-73e6-499b-819c-faf57e0bb55e,DISK], DatanodeInfoWithStorage[127.0.0.1:33184,DS-b0abeca0-c6b3-47f7-8973-e7410628af35,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-418132191-172.17.0.12-1596957794746:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34280,DS-8ed25bf2-f7a7-4447-9220-edff06ef3569,DISK], DatanodeInfoWithStorage[127.0.0.1:35043,DS-7135c35b-2ce9-458c-bcef-6635cb9f487b,DISK], DatanodeInfoWithStorage[127.0.0.1:34694,DS-b75b549c-63e2-4a55-8f06-02d7f95e68c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38272,DS-bbcec6e3-d326-4580-8f65-120cd4238d62,DISK], DatanodeInfoWithStorage[127.0.0.1:38489,DS-3b3c0093-b3ec-497f-be36-353da0c2a79f,DISK], DatanodeInfoWithStorage[127.0.0.1:35025,DS-9e0f7d44-a7be-419a-8251-5704e9f42e38,DISK], DatanodeInfoWithStorage[127.0.0.1:41034,DS-2068c8b0-73e6-499b-819c-faf57e0bb55e,DISK], DatanodeInfoWithStorage[127.0.0.1:33184,DS-b0abeca0-c6b3-47f7-8973-e7410628af35,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1509115318-172.17.0.12-1596958113255:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44340,DS-ec7fb400-cf67-46e9-b0d6-7dae4f63b37c,DISK], DatanodeInfoWithStorage[127.0.0.1:43962,DS-fb6703b0-0ad4-4dee-917a-b40b28d79178,DISK], DatanodeInfoWithStorage[127.0.0.1:37448,DS-c0e58e8a-8436-4b73-b6b0-32cab5f13c94,DISK], DatanodeInfoWithStorage[127.0.0.1:43315,DS-dee05e42-2353-495b-935f-a3dbcadd303d,DISK], DatanodeInfoWithStorage[127.0.0.1:33297,DS-9073e617-4c66-44e9-9e8d-941e43572ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:33594,DS-90282c82-1f86-41d1-98f8-8e9e5f80bba3,DISK], DatanodeInfoWithStorage[127.0.0.1:42649,DS-a5d10e4f-5174-4f04-b9ed-e0781cb3eaec,DISK], DatanodeInfoWithStorage[127.0.0.1:45069,DS-5661ade1-eb46-46df-b3a8-35f226a4e963,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1509115318-172.17.0.12-1596958113255:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44340,DS-ec7fb400-cf67-46e9-b0d6-7dae4f63b37c,DISK], DatanodeInfoWithStorage[127.0.0.1:43962,DS-fb6703b0-0ad4-4dee-917a-b40b28d79178,DISK], DatanodeInfoWithStorage[127.0.0.1:37448,DS-c0e58e8a-8436-4b73-b6b0-32cab5f13c94,DISK], DatanodeInfoWithStorage[127.0.0.1:43315,DS-dee05e42-2353-495b-935f-a3dbcadd303d,DISK], DatanodeInfoWithStorage[127.0.0.1:33297,DS-9073e617-4c66-44e9-9e8d-941e43572ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:33594,DS-90282c82-1f86-41d1-98f8-8e9e5f80bba3,DISK], DatanodeInfoWithStorage[127.0.0.1:42649,DS-a5d10e4f-5174-4f04-b9ed-e0781cb3eaec,DISK], DatanodeInfoWithStorage[127.0.0.1:45069,DS-5661ade1-eb46-46df-b3a8-35f226a4e963,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1278011220-172.17.0.12-1596958348518:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33869,DS-3768f65a-8446-4d0c-be1a-7f1385c6ca0f,DISK], DatanodeInfoWithStorage[127.0.0.1:34915,DS-b697aac0-f2b5-49de-8494-a403f51e076e,DISK], DatanodeInfoWithStorage[127.0.0.1:34266,DS-2d9c9b89-3aa8-4839-8e9c-b8f2071e6075,DISK], DatanodeInfoWithStorage[127.0.0.1:35065,DS-f84079f2-3482-4bcf-bc5a-d0d9eabdf2be,DISK], DatanodeInfoWithStorage[127.0.0.1:44218,DS-1b810f0c-5efa-4e4c-a31d-4c1173c7bad2,DISK], DatanodeInfoWithStorage[127.0.0.1:41555,DS-ebe4e13d-c10f-478f-8e73-dc00fc81ee3e,DISK], DatanodeInfoWithStorage[127.0.0.1:37064,DS-a6f45d2a-5f08-403c-80d7-64b82af7c27f,DISK], DatanodeInfoWithStorage[127.0.0.1:36426,DS-00cae5fb-3b73-4683-ae16-7ebfef1e7407,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1278011220-172.17.0.12-1596958348518:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33869,DS-3768f65a-8446-4d0c-be1a-7f1385c6ca0f,DISK], DatanodeInfoWithStorage[127.0.0.1:34915,DS-b697aac0-f2b5-49de-8494-a403f51e076e,DISK], DatanodeInfoWithStorage[127.0.0.1:34266,DS-2d9c9b89-3aa8-4839-8e9c-b8f2071e6075,DISK], DatanodeInfoWithStorage[127.0.0.1:35065,DS-f84079f2-3482-4bcf-bc5a-d0d9eabdf2be,DISK], DatanodeInfoWithStorage[127.0.0.1:44218,DS-1b810f0c-5efa-4e4c-a31d-4c1173c7bad2,DISK], DatanodeInfoWithStorage[127.0.0.1:41555,DS-ebe4e13d-c10f-478f-8e73-dc00fc81ee3e,DISK], DatanodeInfoWithStorage[127.0.0.1:37064,DS-a6f45d2a-5f08-403c-80d7-64b82af7c27f,DISK], DatanodeInfoWithStorage[127.0.0.1:36426,DS-00cae5fb-3b73-4683-ae16-7ebfef1e7407,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1639858752-172.17.0.12-1596958437484:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38727,DS-dfd2c15a-22b1-48c1-8224-9fc27741b8ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44889,DS-2ba44fd3-ad41-41cc-96be-50edc3b02a48,DISK], DatanodeInfoWithStorage[127.0.0.1:39450,DS-da7314a3-4760-48ba-b332-320be7545aaa,DISK], DatanodeInfoWithStorage[127.0.0.1:38416,DS-ced7b5a8-56f4-45e2-a426-cf317944c395,DISK], DatanodeInfoWithStorage[127.0.0.1:40780,DS-973557af-ff79-4fc9-b6f8-0a91e1430cdf,DISK], DatanodeInfoWithStorage[127.0.0.1:40671,DS-db5b4fd3-505f-41f8-9386-29e1dafc3d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:35466,DS-0690c5c7-4541-45fe-9d80-8330b6fd6ec3,DISK], DatanodeInfoWithStorage[127.0.0.1:39205,DS-4abd7940-6478-48de-8436-5c2fdda356f6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1639858752-172.17.0.12-1596958437484:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38727,DS-dfd2c15a-22b1-48c1-8224-9fc27741b8ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44889,DS-2ba44fd3-ad41-41cc-96be-50edc3b02a48,DISK], DatanodeInfoWithStorage[127.0.0.1:39450,DS-da7314a3-4760-48ba-b332-320be7545aaa,DISK], DatanodeInfoWithStorage[127.0.0.1:38416,DS-ced7b5a8-56f4-45e2-a426-cf317944c395,DISK], DatanodeInfoWithStorage[127.0.0.1:40780,DS-973557af-ff79-4fc9-b6f8-0a91e1430cdf,DISK], DatanodeInfoWithStorage[127.0.0.1:40671,DS-db5b4fd3-505f-41f8-9386-29e1dafc3d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:35466,DS-0690c5c7-4541-45fe-9d80-8330b6fd6ec3,DISK], DatanodeInfoWithStorage[127.0.0.1:39205,DS-4abd7940-6478-48de-8436-5c2fdda356f6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-8570366-172.17.0.12-1596958704562:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33231,DS-439ab519-bc8e-40bc-a4b3-3bfd766b5483,DISK], DatanodeInfoWithStorage[127.0.0.1:40260,DS-db86df4d-6f94-4fbe-b6e8-6ac9d7bb1038,DISK], DatanodeInfoWithStorage[127.0.0.1:33434,DS-2db6366d-8520-41f6-81eb-932996daa688,DISK], DatanodeInfoWithStorage[127.0.0.1:35899,DS-df759a19-c8c9-4c13-9092-489854fc140c,DISK], DatanodeInfoWithStorage[127.0.0.1:43359,DS-85e1d574-0e31-4315-9b6b-64595ef40929,DISK], DatanodeInfoWithStorage[127.0.0.1:39555,DS-8d2197f2-66f9-4597-9927-837307facae2,DISK], DatanodeInfoWithStorage[127.0.0.1:46825,DS-5b22bb73-0bab-470a-98ec-ca1250f85185,DISK], DatanodeInfoWithStorage[127.0.0.1:33844,DS-38ca006b-b243-4c50-8896-8df37963c236,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-8570366-172.17.0.12-1596958704562:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33231,DS-439ab519-bc8e-40bc-a4b3-3bfd766b5483,DISK], DatanodeInfoWithStorage[127.0.0.1:40260,DS-db86df4d-6f94-4fbe-b6e8-6ac9d7bb1038,DISK], DatanodeInfoWithStorage[127.0.0.1:33434,DS-2db6366d-8520-41f6-81eb-932996daa688,DISK], DatanodeInfoWithStorage[127.0.0.1:35899,DS-df759a19-c8c9-4c13-9092-489854fc140c,DISK], DatanodeInfoWithStorage[127.0.0.1:43359,DS-85e1d574-0e31-4315-9b6b-64595ef40929,DISK], DatanodeInfoWithStorage[127.0.0.1:39555,DS-8d2197f2-66f9-4597-9927-837307facae2,DISK], DatanodeInfoWithStorage[127.0.0.1:46825,DS-5b22bb73-0bab-470a-98ec-ca1250f85185,DISK], DatanodeInfoWithStorage[127.0.0.1:33844,DS-38ca006b-b243-4c50-8896-8df37963c236,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.mmap.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1944016242-172.17.0.12-1596958738270:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42995,DS-f5b2851c-ae10-4ad1-a563-4b9022c349cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45618,DS-81d62a3b-8b98-458b-a0a9-32d651488ab1,DISK], DatanodeInfoWithStorage[127.0.0.1:35556,DS-4b206e27-f6f2-4735-bacf-04e284c9120a,DISK], DatanodeInfoWithStorage[127.0.0.1:36356,DS-b3408316-baa7-42f4-8b6d-9505735e22af,DISK], DatanodeInfoWithStorage[127.0.0.1:36190,DS-06321e09-1e09-4172-b658-17a5f05ab7d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35644,DS-9e6756a2-f83a-4706-89f0-98b71644a7df,DISK], DatanodeInfoWithStorage[127.0.0.1:40393,DS-0cbe207e-8ba3-4fe5-9f83-61ca4babb9a4,DISK], DatanodeInfoWithStorage[127.0.0.1:45510,DS-6fcc17ef-f826-418c-b44c-16f843febcf5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1944016242-172.17.0.12-1596958738270:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42995,DS-f5b2851c-ae10-4ad1-a563-4b9022c349cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45618,DS-81d62a3b-8b98-458b-a0a9-32d651488ab1,DISK], DatanodeInfoWithStorage[127.0.0.1:35556,DS-4b206e27-f6f2-4735-bacf-04e284c9120a,DISK], DatanodeInfoWithStorage[127.0.0.1:36356,DS-b3408316-baa7-42f4-8b6d-9505735e22af,DISK], DatanodeInfoWithStorage[127.0.0.1:36190,DS-06321e09-1e09-4172-b658-17a5f05ab7d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35644,DS-9e6756a2-f83a-4706-89f0-98b71644a7df,DISK], DatanodeInfoWithStorage[127.0.0.1:40393,DS-0cbe207e-8ba3-4fe5-9f83-61ca4babb9a4,DISK], DatanodeInfoWithStorage[127.0.0.1:45510,DS-6fcc17ef-f826-418c-b44c-16f843febcf5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1652950492-172.17.0.12-1596958902782:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35453,DS-1ea4238f-871e-4c83-84ff-72a755ff81ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38884,DS-27a5a7cd-7030-48a5-8422-d4016215bf9f,DISK], DatanodeInfoWithStorage[127.0.0.1:43746,DS-e9dbca81-c952-4279-952d-9f2dd966a43e,DISK], DatanodeInfoWithStorage[127.0.0.1:40602,DS-2b3a8219-2e45-46d4-be87-1b4dd202caf1,DISK], DatanodeInfoWithStorage[127.0.0.1:43913,DS-83a2c43c-0dfd-4298-81ad-dc45f005a116,DISK], DatanodeInfoWithStorage[127.0.0.1:35610,DS-675c7bff-2ab4-4d6a-9db2-98c43972aa26,DISK], DatanodeInfoWithStorage[127.0.0.1:41986,DS-02f5e91e-7a35-441d-a159-3b09b1279ab8,DISK], DatanodeInfoWithStorage[127.0.0.1:36886,DS-9ebd78b9-677a-4866-8bb8-c0f19388e1ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1652950492-172.17.0.12-1596958902782:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35453,DS-1ea4238f-871e-4c83-84ff-72a755ff81ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38884,DS-27a5a7cd-7030-48a5-8422-d4016215bf9f,DISK], DatanodeInfoWithStorage[127.0.0.1:43746,DS-e9dbca81-c952-4279-952d-9f2dd966a43e,DISK], DatanodeInfoWithStorage[127.0.0.1:40602,DS-2b3a8219-2e45-46d4-be87-1b4dd202caf1,DISK], DatanodeInfoWithStorage[127.0.0.1:43913,DS-83a2c43c-0dfd-4298-81ad-dc45f005a116,DISK], DatanodeInfoWithStorage[127.0.0.1:35610,DS-675c7bff-2ab4-4d6a-9db2-98c43972aa26,DISK], DatanodeInfoWithStorage[127.0.0.1:41986,DS-02f5e91e-7a35-441d-a159-3b09b1279ab8,DISK], DatanodeInfoWithStorage[127.0.0.1:36886,DS-9ebd78b9-677a-4866-8bb8-c0f19388e1ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.mmap.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-247671729-172.17.0.12-1596958935389:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46227,DS-c4a1e2c2-9186-446f-a879-40beb7752320,DISK], DatanodeInfoWithStorage[127.0.0.1:45616,DS-5fe70b48-9cc9-475d-8382-5454625297e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33480,DS-2b97c595-e6c6-44ec-82fe-df70fb6beaa2,DISK], DatanodeInfoWithStorage[127.0.0.1:46011,DS-f7c031f9-a7db-462a-a87e-58b0e97dc0ee,DISK], DatanodeInfoWithStorage[127.0.0.1:46057,DS-63eea351-b00e-4f0b-932d-f77ee320850f,DISK], DatanodeInfoWithStorage[127.0.0.1:38074,DS-27ba21fc-9ce9-493f-be41-1baa4dfb26a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41955,DS-714ba233-3ba5-4f38-ad24-4d380f881bb3,DISK], DatanodeInfoWithStorage[127.0.0.1:38945,DS-4ba3be13-fac5-4af0-ba94-02f14a6f97b9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-247671729-172.17.0.12-1596958935389:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46227,DS-c4a1e2c2-9186-446f-a879-40beb7752320,DISK], DatanodeInfoWithStorage[127.0.0.1:45616,DS-5fe70b48-9cc9-475d-8382-5454625297e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33480,DS-2b97c595-e6c6-44ec-82fe-df70fb6beaa2,DISK], DatanodeInfoWithStorage[127.0.0.1:46011,DS-f7c031f9-a7db-462a-a87e-58b0e97dc0ee,DISK], DatanodeInfoWithStorage[127.0.0.1:46057,DS-63eea351-b00e-4f0b-932d-f77ee320850f,DISK], DatanodeInfoWithStorage[127.0.0.1:38074,DS-27ba21fc-9ce9-493f-be41-1baa4dfb26a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41955,DS-714ba233-3ba5-4f38-ad24-4d380f881bb3,DISK], DatanodeInfoWithStorage[127.0.0.1:38945,DS-4ba3be13-fac5-4af0-ba94-02f14a6f97b9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2003125957-172.17.0.12-1596959046231:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41130,DS-e3258d88-14b3-4836-b346-9401e2f42793,DISK], DatanodeInfoWithStorage[127.0.0.1:36164,DS-64521473-7962-4c06-897e-3e61f21b6cea,DISK], DatanodeInfoWithStorage[127.0.0.1:40697,DS-d1a67f30-36f2-4959-bb7e-a4d64e748335,DISK], DatanodeInfoWithStorage[127.0.0.1:35808,DS-fcdc8439-59f6-4f21-a92a-707bd78eb804,DISK], DatanodeInfoWithStorage[127.0.0.1:34228,DS-80a28511-bafb-4fdc-9bbf-777a776d81bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45405,DS-aafeb3a8-7480-4e82-a95f-b474927f7d82,DISK], DatanodeInfoWithStorage[127.0.0.1:34239,DS-fb68ab93-2b85-470a-9bb0-81400f90bb05,DISK], DatanodeInfoWithStorage[127.0.0.1:33814,DS-7918324a-101a-412b-85cc-59462b73a521,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2003125957-172.17.0.12-1596959046231:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41130,DS-e3258d88-14b3-4836-b346-9401e2f42793,DISK], DatanodeInfoWithStorage[127.0.0.1:36164,DS-64521473-7962-4c06-897e-3e61f21b6cea,DISK], DatanodeInfoWithStorage[127.0.0.1:40697,DS-d1a67f30-36f2-4959-bb7e-a4d64e748335,DISK], DatanodeInfoWithStorage[127.0.0.1:35808,DS-fcdc8439-59f6-4f21-a92a-707bd78eb804,DISK], DatanodeInfoWithStorage[127.0.0.1:34228,DS-80a28511-bafb-4fdc-9bbf-777a776d81bb,DISK], DatanodeInfoWithStorage[127.0.0.1:45405,DS-aafeb3a8-7480-4e82-a95f-b474927f7d82,DISK], DatanodeInfoWithStorage[127.0.0.1:34239,DS-fb68ab93-2b85-470a-9bb0-81400f90bb05,DISK], DatanodeInfoWithStorage[127.0.0.1:33814,DS-7918324a-101a-412b-85cc-59462b73a521,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1862270955-172.17.0.12-1596959159156:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41303,DS-b474670f-de1b-4e60-a6e3-09aef264444d,DISK], DatanodeInfoWithStorage[127.0.0.1:35132,DS-414dd218-e238-4d00-aba0-1cfd383e0a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:45610,DS-622fdcc3-706b-4fb7-a1cc-e1613592dee8,DISK], DatanodeInfoWithStorage[127.0.0.1:43309,DS-1e3dafb6-cf9c-490f-ac25-a7b7a60a8fa9,DISK], DatanodeInfoWithStorage[127.0.0.1:36014,DS-cb893c74-9820-4b91-804c-625f8a8898b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33498,DS-a78854c3-33ea-47c7-ae6e-90aa0412595c,DISK], DatanodeInfoWithStorage[127.0.0.1:40679,DS-f7a4806f-6aba-4e18-a4f9-5bc715038d5d,DISK], DatanodeInfoWithStorage[127.0.0.1:36188,DS-92f77d7e-cab9-46f5-b84a-dae3a8692184,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1862270955-172.17.0.12-1596959159156:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41303,DS-b474670f-de1b-4e60-a6e3-09aef264444d,DISK], DatanodeInfoWithStorage[127.0.0.1:35132,DS-414dd218-e238-4d00-aba0-1cfd383e0a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:45610,DS-622fdcc3-706b-4fb7-a1cc-e1613592dee8,DISK], DatanodeInfoWithStorage[127.0.0.1:43309,DS-1e3dafb6-cf9c-490f-ac25-a7b7a60a8fa9,DISK], DatanodeInfoWithStorage[127.0.0.1:36014,DS-cb893c74-9820-4b91-804c-625f8a8898b2,DISK], DatanodeInfoWithStorage[127.0.0.1:33498,DS-a78854c3-33ea-47c7-ae6e-90aa0412595c,DISK], DatanodeInfoWithStorage[127.0.0.1:40679,DS-f7a4806f-6aba-4e18-a4f9-5bc715038d5d,DISK], DatanodeInfoWithStorage[127.0.0.1:36188,DS-92f77d7e-cab9-46f5-b84a-dae3a8692184,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1604731607-172.17.0.12-1596959552184:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42694,DS-e556a700-c367-40c2-9ccd-c6e3f99ff3ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39114,DS-aed04457-6675-4f49-80c4-4aac7ef933ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44181,DS-5ed8321a-a891-4a47-8a63-b01f85d689bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38679,DS-799eca4a-19aa-4d59-b44b-6fc8a94aa82f,DISK], DatanodeInfoWithStorage[127.0.0.1:44627,DS-bcef3000-147d-487e-b643-85d64899d0d5,DISK], DatanodeInfoWithStorage[127.0.0.1:39569,DS-e99e626b-0aa5-41fa-8502-10792ffbfe93,DISK], DatanodeInfoWithStorage[127.0.0.1:32788,DS-1251a931-8b73-4145-82e0-5a01b5ae9004,DISK], DatanodeInfoWithStorage[127.0.0.1:43226,DS-ac8bbe4e-9668-48e2-bea7-e5feb35ce7e7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1604731607-172.17.0.12-1596959552184:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42694,DS-e556a700-c367-40c2-9ccd-c6e3f99ff3ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39114,DS-aed04457-6675-4f49-80c4-4aac7ef933ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44181,DS-5ed8321a-a891-4a47-8a63-b01f85d689bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38679,DS-799eca4a-19aa-4d59-b44b-6fc8a94aa82f,DISK], DatanodeInfoWithStorage[127.0.0.1:44627,DS-bcef3000-147d-487e-b643-85d64899d0d5,DISK], DatanodeInfoWithStorage[127.0.0.1:39569,DS-e99e626b-0aa5-41fa-8502-10792ffbfe93,DISK], DatanodeInfoWithStorage[127.0.0.1:32788,DS-1251a931-8b73-4145-82e0-5a01b5ae9004,DISK], DatanodeInfoWithStorage[127.0.0.1:43226,DS-ac8bbe4e-9668-48e2-bea7-e5feb35ce7e7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-86782623-172.17.0.12-1596959705426:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38571,DS-a8b60f20-d606-4033-a61d-6c7602c21a40,DISK], DatanodeInfoWithStorage[127.0.0.1:38188,DS-eaf2a15e-f59c-4d85-a4de-5ffc4542ffd5,DISK], DatanodeInfoWithStorage[127.0.0.1:42954,DS-377d143c-4092-4ad0-9d2c-486029486e66,DISK], DatanodeInfoWithStorage[127.0.0.1:45465,DS-b4325b9f-3b42-424a-a242-3337a5e68eec,DISK], DatanodeInfoWithStorage[127.0.0.1:43734,DS-bcbb7da3-d6a5-41e5-99dd-6135ef93e5b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35154,DS-39b991bb-7418-4853-82ec-4becdd1558cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34662,DS-e3ef21f1-9c7e-49ef-8e92-2e22a949c0c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44453,DS-1883bb72-94b0-46a2-ad35-0796fc20d5a4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-86782623-172.17.0.12-1596959705426:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38571,DS-a8b60f20-d606-4033-a61d-6c7602c21a40,DISK], DatanodeInfoWithStorage[127.0.0.1:38188,DS-eaf2a15e-f59c-4d85-a4de-5ffc4542ffd5,DISK], DatanodeInfoWithStorage[127.0.0.1:42954,DS-377d143c-4092-4ad0-9d2c-486029486e66,DISK], DatanodeInfoWithStorage[127.0.0.1:45465,DS-b4325b9f-3b42-424a-a242-3337a5e68eec,DISK], DatanodeInfoWithStorage[127.0.0.1:43734,DS-bcbb7da3-d6a5-41e5-99dd-6135ef93e5b2,DISK], DatanodeInfoWithStorage[127.0.0.1:35154,DS-39b991bb-7418-4853-82ec-4becdd1558cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34662,DS-e3ef21f1-9c7e-49ef-8e92-2e22a949c0c8,DISK], DatanodeInfoWithStorage[127.0.0.1:44453,DS-1883bb72-94b0-46a2-ad35-0796fc20d5a4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1260673700-172.17.0.12-1596959774686:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43174,DS-b05a9fe3-201e-48c9-9116-307e53dc9121,DISK], DatanodeInfoWithStorage[127.0.0.1:44550,DS-6a4bddb3-2db5-4f1f-9bd7-d41e119d2c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:39792,DS-9112890e-4043-4cd2-9195-f6802d5f2c09,DISK], DatanodeInfoWithStorage[127.0.0.1:38029,DS-5f679e42-4f28-493d-b5ac-e0d76953a2be,DISK], DatanodeInfoWithStorage[127.0.0.1:44479,DS-dde70459-a425-460e-80c9-e2c27b22da0f,DISK], DatanodeInfoWithStorage[127.0.0.1:34530,DS-08058997-64db-48d8-a01f-889fea1ea549,DISK], DatanodeInfoWithStorage[127.0.0.1:43735,DS-e3c6c558-a4ea-40b9-a2e9-ac86a2b1ae9a,DISK], DatanodeInfoWithStorage[127.0.0.1:43848,DS-7230e495-543f-4d87-a9d1-119a69de7f34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1260673700-172.17.0.12-1596959774686:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43174,DS-b05a9fe3-201e-48c9-9116-307e53dc9121,DISK], DatanodeInfoWithStorage[127.0.0.1:44550,DS-6a4bddb3-2db5-4f1f-9bd7-d41e119d2c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:39792,DS-9112890e-4043-4cd2-9195-f6802d5f2c09,DISK], DatanodeInfoWithStorage[127.0.0.1:38029,DS-5f679e42-4f28-493d-b5ac-e0d76953a2be,DISK], DatanodeInfoWithStorage[127.0.0.1:44479,DS-dde70459-a425-460e-80c9-e2c27b22da0f,DISK], DatanodeInfoWithStorage[127.0.0.1:34530,DS-08058997-64db-48d8-a01f-889fea1ea549,DISK], DatanodeInfoWithStorage[127.0.0.1:43735,DS-e3c6c558-a4ea-40b9-a2e9-ac86a2b1ae9a,DISK], DatanodeInfoWithStorage[127.0.0.1:43848,DS-7230e495-543f-4d87-a9d1-119a69de7f34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.mmap.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1183099917-172.17.0.12-1596959810850:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35410,DS-b1d934dd-09f9-4755-a4c2-91faec95368a,DISK], DatanodeInfoWithStorage[127.0.0.1:46538,DS-dc81894b-1acd-470b-ad4a-cac7932acb14,DISK], DatanodeInfoWithStorage[127.0.0.1:35854,DS-4faa9ec2-59d5-4629-a6bc-2c6f2c53cbe4,DISK], DatanodeInfoWithStorage[127.0.0.1:46872,DS-11f8e9f5-20ad-4129-a087-c9eef06ec5a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33578,DS-3f657cb8-2e00-4991-8146-4b8de1af73e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38127,DS-9f27e35d-a1dd-4642-b329-0ecac7d104ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42786,DS-35bb31c2-6d15-49cc-9a57-ec26f5a57464,DISK], DatanodeInfoWithStorage[127.0.0.1:37789,DS-69e546f6-741d-489a-a0d1-dba19cd04dad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1183099917-172.17.0.12-1596959810850:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35410,DS-b1d934dd-09f9-4755-a4c2-91faec95368a,DISK], DatanodeInfoWithStorage[127.0.0.1:46538,DS-dc81894b-1acd-470b-ad4a-cac7932acb14,DISK], DatanodeInfoWithStorage[127.0.0.1:35854,DS-4faa9ec2-59d5-4629-a6bc-2c6f2c53cbe4,DISK], DatanodeInfoWithStorage[127.0.0.1:46872,DS-11f8e9f5-20ad-4129-a087-c9eef06ec5a0,DISK], DatanodeInfoWithStorage[127.0.0.1:33578,DS-3f657cb8-2e00-4991-8146-4b8de1af73e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38127,DS-9f27e35d-a1dd-4642-b329-0ecac7d104ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42786,DS-35bb31c2-6d15-49cc-9a57-ec26f5a57464,DISK], DatanodeInfoWithStorage[127.0.0.1:37789,DS-69e546f6-741d-489a-a0d1-dba19cd04dad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.mmap.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-387072254-172.17.0.12-1596959846782:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42704,DS-1af2ee2d-e2b0-4f50-8314-43ba76de39ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34132,DS-e2344a20-8c29-48c0-9bd1-889142a62bf6,DISK], DatanodeInfoWithStorage[127.0.0.1:32919,DS-1a0a5c18-f6a7-46a8-a71a-1b4b58d7a2fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41531,DS-afee2856-10f9-49ef-bebf-e8105c4be78f,DISK], DatanodeInfoWithStorage[127.0.0.1:39075,DS-98f16658-6800-4097-b240-0569ae63684d,DISK], DatanodeInfoWithStorage[127.0.0.1:44778,DS-4653849e-8973-4d34-b282-8e3971aec7de,DISK], DatanodeInfoWithStorage[127.0.0.1:37628,DS-55d16aa4-e080-42cb-899e-9baff2bec704,DISK], DatanodeInfoWithStorage[127.0.0.1:45613,DS-5ad73f81-dd23-4abb-b9e5-0f36fba7e9c7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-387072254-172.17.0.12-1596959846782:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42704,DS-1af2ee2d-e2b0-4f50-8314-43ba76de39ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34132,DS-e2344a20-8c29-48c0-9bd1-889142a62bf6,DISK], DatanodeInfoWithStorage[127.0.0.1:32919,DS-1a0a5c18-f6a7-46a8-a71a-1b4b58d7a2fb,DISK], DatanodeInfoWithStorage[127.0.0.1:41531,DS-afee2856-10f9-49ef-bebf-e8105c4be78f,DISK], DatanodeInfoWithStorage[127.0.0.1:39075,DS-98f16658-6800-4097-b240-0569ae63684d,DISK], DatanodeInfoWithStorage[127.0.0.1:44778,DS-4653849e-8973-4d34-b282-8e3971aec7de,DISK], DatanodeInfoWithStorage[127.0.0.1:37628,DS-55d16aa4-e080-42cb-899e-9baff2bec704,DISK], DatanodeInfoWithStorage[127.0.0.1:45613,DS-5ad73f81-dd23-4abb-b9e5-0f36fba7e9c7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2134370146-172.17.0.12-1596959923995:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38041,DS-5184983d-5de1-4471-918f-8723cf70cbc4,DISK], DatanodeInfoWithStorage[127.0.0.1:42146,DS-0c1d8700-c3e4-445d-9037-56ee085d9e30,DISK], DatanodeInfoWithStorage[127.0.0.1:33899,DS-cd3a3c99-54bd-4cfd-93fc-2fed1550aa0a,DISK], DatanodeInfoWithStorage[127.0.0.1:39226,DS-1041866a-c19a-494d-8367-608165d8429b,DISK], DatanodeInfoWithStorage[127.0.0.1:34123,DS-995fff9d-42ff-4c7b-af54-ae87139c545a,DISK], DatanodeInfoWithStorage[127.0.0.1:43509,DS-6db29142-15e2-4698-9bb9-34cc275f9f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:46436,DS-c80e0f09-c6b1-4a1e-9f25-09b49b9a276b,DISK], DatanodeInfoWithStorage[127.0.0.1:41874,DS-8add542a-e225-4846-b7db-bcd4594800d4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2134370146-172.17.0.12-1596959923995:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38041,DS-5184983d-5de1-4471-918f-8723cf70cbc4,DISK], DatanodeInfoWithStorage[127.0.0.1:42146,DS-0c1d8700-c3e4-445d-9037-56ee085d9e30,DISK], DatanodeInfoWithStorage[127.0.0.1:33899,DS-cd3a3c99-54bd-4cfd-93fc-2fed1550aa0a,DISK], DatanodeInfoWithStorage[127.0.0.1:39226,DS-1041866a-c19a-494d-8367-608165d8429b,DISK], DatanodeInfoWithStorage[127.0.0.1:34123,DS-995fff9d-42ff-4c7b-af54-ae87139c545a,DISK], DatanodeInfoWithStorage[127.0.0.1:43509,DS-6db29142-15e2-4698-9bb9-34cc275f9f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:46436,DS-c80e0f09-c6b1-4a1e-9f25-09b49b9a276b,DISK], DatanodeInfoWithStorage[127.0.0.1:41874,DS-8add542a-e225-4846-b7db-bcd4594800d4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-324986342-172.17.0.12-1596959997995:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43415,DS-0a6669eb-66d1-46b6-bd55-34f48f7bc902,DISK], DatanodeInfoWithStorage[127.0.0.1:43340,DS-31fffe39-9fe1-4bcc-b468-5fcbc9ac6c42,DISK], DatanodeInfoWithStorage[127.0.0.1:33535,DS-493b38d8-9e76-4959-b2e9-817cc41da7a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43914,DS-f95234fc-6912-429e-ae66-e72ac5e47647,DISK], DatanodeInfoWithStorage[127.0.0.1:44318,DS-09353e1c-1e38-4449-88a9-b7dcb5dd2064,DISK], DatanodeInfoWithStorage[127.0.0.1:39471,DS-c9926a4b-1c69-4d46-92a5-8306c6724e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:36890,DS-ac6f9b7a-63ec-42cf-bc16-003fc4f5705b,DISK], DatanodeInfoWithStorage[127.0.0.1:33822,DS-cb57f2e6-e5ce-42c1-9c89-06cb4d1b7929,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-324986342-172.17.0.12-1596959997995:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43415,DS-0a6669eb-66d1-46b6-bd55-34f48f7bc902,DISK], DatanodeInfoWithStorage[127.0.0.1:43340,DS-31fffe39-9fe1-4bcc-b468-5fcbc9ac6c42,DISK], DatanodeInfoWithStorage[127.0.0.1:33535,DS-493b38d8-9e76-4959-b2e9-817cc41da7a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43914,DS-f95234fc-6912-429e-ae66-e72ac5e47647,DISK], DatanodeInfoWithStorage[127.0.0.1:44318,DS-09353e1c-1e38-4449-88a9-b7dcb5dd2064,DISK], DatanodeInfoWithStorage[127.0.0.1:39471,DS-c9926a4b-1c69-4d46-92a5-8306c6724e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:36890,DS-ac6f9b7a-63ec-42cf-bc16-003fc4f5705b,DISK], DatanodeInfoWithStorage[127.0.0.1:33822,DS-cb57f2e6-e5ce-42c1-9c89-06cb4d1b7929,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.mmap.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-27058779-172.17.0.12-1596960446900:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38729,DS-2cc1222e-a9eb-4c70-b964-b935ddf479a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33240,DS-23e653da-d860-4563-a6a9-5a42a42d3a47,DISK], DatanodeInfoWithStorage[127.0.0.1:35002,DS-7f2c1e48-2af8-40fc-84e0-5e06ea51d680,DISK], DatanodeInfoWithStorage[127.0.0.1:43647,DS-4d245e0c-ca8a-4a36-9677-67e10ecf792c,DISK], DatanodeInfoWithStorage[127.0.0.1:42445,DS-dcbf29db-0e1d-4cff-8b65-41ce9f644f45,DISK], DatanodeInfoWithStorage[127.0.0.1:36806,DS-131becf8-ab0f-4504-83ea-9b61e83ce90a,DISK], DatanodeInfoWithStorage[127.0.0.1:34976,DS-7cf09561-6eba-4a83-b826-bdfc19c3bf4a,DISK], DatanodeInfoWithStorage[127.0.0.1:40066,DS-54db0aef-b965-41fd-8843-f1fa0f9f35a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-27058779-172.17.0.12-1596960446900:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38729,DS-2cc1222e-a9eb-4c70-b964-b935ddf479a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33240,DS-23e653da-d860-4563-a6a9-5a42a42d3a47,DISK], DatanodeInfoWithStorage[127.0.0.1:35002,DS-7f2c1e48-2af8-40fc-84e0-5e06ea51d680,DISK], DatanodeInfoWithStorage[127.0.0.1:43647,DS-4d245e0c-ca8a-4a36-9677-67e10ecf792c,DISK], DatanodeInfoWithStorage[127.0.0.1:42445,DS-dcbf29db-0e1d-4cff-8b65-41ce9f644f45,DISK], DatanodeInfoWithStorage[127.0.0.1:36806,DS-131becf8-ab0f-4504-83ea-9b61e83ce90a,DISK], DatanodeInfoWithStorage[127.0.0.1:34976,DS-7cf09561-6eba-4a83-b826-bdfc19c3bf4a,DISK], DatanodeInfoWithStorage[127.0.0.1:40066,DS-54db0aef-b965-41fd-8843-f1fa0f9f35a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 22 out of 50
result: false positive !!!
Total execution time in seconds : 5178
