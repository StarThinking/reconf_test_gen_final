reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-574706174-172.17.0.17-1595377171944:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46028,DS-6a01aa29-6f9e-473b-b9be-fa618a440de9,DISK], DatanodeInfoWithStorage[127.0.0.1:46204,DS-3db8ab99-8759-4d0f-8481-639cd3f934ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41395,DS-6c2bfac4-ec7d-4d67-97f2-3bb0ff8c129b,DISK], DatanodeInfoWithStorage[127.0.0.1:37534,DS-07211e03-e9cd-40fa-b9a3-0f9505e3e3cc,DISK], DatanodeInfoWithStorage[127.0.0.1:40747,DS-dc40c077-4c61-4f5a-9ee5-7f8ad09105aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35030,DS-f6cffbd8-2416-4f58-bfbf-f6bc0c2bcd1c,DISK], DatanodeInfoWithStorage[127.0.0.1:37278,DS-0a8306b1-1998-47ba-9fd7-350ec8b3dc8d,DISK], DatanodeInfoWithStorage[127.0.0.1:45661,DS-50defd0c-e7b0-4a48-8822-12e3c8e55aa5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-574706174-172.17.0.17-1595377171944:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46028,DS-6a01aa29-6f9e-473b-b9be-fa618a440de9,DISK], DatanodeInfoWithStorage[127.0.0.1:46204,DS-3db8ab99-8759-4d0f-8481-639cd3f934ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41395,DS-6c2bfac4-ec7d-4d67-97f2-3bb0ff8c129b,DISK], DatanodeInfoWithStorage[127.0.0.1:37534,DS-07211e03-e9cd-40fa-b9a3-0f9505e3e3cc,DISK], DatanodeInfoWithStorage[127.0.0.1:40747,DS-dc40c077-4c61-4f5a-9ee5-7f8ad09105aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35030,DS-f6cffbd8-2416-4f58-bfbf-f6bc0c2bcd1c,DISK], DatanodeInfoWithStorage[127.0.0.1:37278,DS-0a8306b1-1998-47ba-9fd7-350ec8b3dc8d,DISK], DatanodeInfoWithStorage[127.0.0.1:45661,DS-50defd0c-e7b0-4a48-8822-12e3c8e55aa5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-354228760-172.17.0.17-1595377638718:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33561,DS-bf011c66-5f92-48d8-8c0b-4b3cd421c2a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43384,DS-ceee1b1b-5a70-48cc-b16e-001e5fecf9e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41988,DS-5f2b0ea5-8a2a-4349-8250-cdc75ae882a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37885,DS-7f8a79da-32ff-4973-8dc7-84e009d34888,DISK], DatanodeInfoWithStorage[127.0.0.1:36302,DS-74170355-9d70-4085-a44d-c1cc18014444,DISK], DatanodeInfoWithStorage[127.0.0.1:34888,DS-ca60b98d-8259-48e5-91b9-d7a04dba6f07,DISK], DatanodeInfoWithStorage[127.0.0.1:40791,DS-e7135eb3-e43e-423f-8bdc-08d8f96d968f,DISK], DatanodeInfoWithStorage[127.0.0.1:33181,DS-e2623fe0-299a-487d-8fde-0fcd1f79c92e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-354228760-172.17.0.17-1595377638718:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33561,DS-bf011c66-5f92-48d8-8c0b-4b3cd421c2a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43384,DS-ceee1b1b-5a70-48cc-b16e-001e5fecf9e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41988,DS-5f2b0ea5-8a2a-4349-8250-cdc75ae882a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37885,DS-7f8a79da-32ff-4973-8dc7-84e009d34888,DISK], DatanodeInfoWithStorage[127.0.0.1:36302,DS-74170355-9d70-4085-a44d-c1cc18014444,DISK], DatanodeInfoWithStorage[127.0.0.1:34888,DS-ca60b98d-8259-48e5-91b9-d7a04dba6f07,DISK], DatanodeInfoWithStorage[127.0.0.1:40791,DS-e7135eb3-e43e-423f-8bdc-08d8f96d968f,DISK], DatanodeInfoWithStorage[127.0.0.1:33181,DS-e2623fe0-299a-487d-8fde-0fcd1f79c92e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1699065999-172.17.0.17-1595378857307:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41975,DS-f0374b2b-ec62-4654-9be2-440d9d8344f4,DISK], DatanodeInfoWithStorage[127.0.0.1:35377,DS-e5f9360f-0a8d-4309-8cc5-4395733a334a,DISK], DatanodeInfoWithStorage[127.0.0.1:42231,DS-2b76b3cf-f107-41ba-aac0-33a2037515b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34097,DS-88815a5b-e29c-4bd0-9ab5-ed3a7fbd1751,DISK], DatanodeInfoWithStorage[127.0.0.1:32995,DS-6cec0cd9-eb5e-4f80-be48-81f1901c2a4f,DISK], DatanodeInfoWithStorage[127.0.0.1:40715,DS-d56b21e9-3c45-4bec-9592-62ee8cf9b0c4,DISK], DatanodeInfoWithStorage[127.0.0.1:37069,DS-e08646d5-5975-42b0-aaed-bf80d180448b,DISK], DatanodeInfoWithStorage[127.0.0.1:35915,DS-03211882-4bbe-4bf1-b71b-5852ef07527a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1699065999-172.17.0.17-1595378857307:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41975,DS-f0374b2b-ec62-4654-9be2-440d9d8344f4,DISK], DatanodeInfoWithStorage[127.0.0.1:35377,DS-e5f9360f-0a8d-4309-8cc5-4395733a334a,DISK], DatanodeInfoWithStorage[127.0.0.1:42231,DS-2b76b3cf-f107-41ba-aac0-33a2037515b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34097,DS-88815a5b-e29c-4bd0-9ab5-ed3a7fbd1751,DISK], DatanodeInfoWithStorage[127.0.0.1:32995,DS-6cec0cd9-eb5e-4f80-be48-81f1901c2a4f,DISK], DatanodeInfoWithStorage[127.0.0.1:40715,DS-d56b21e9-3c45-4bec-9592-62ee8cf9b0c4,DISK], DatanodeInfoWithStorage[127.0.0.1:37069,DS-e08646d5-5975-42b0-aaed-bf80d180448b,DISK], DatanodeInfoWithStorage[127.0.0.1:35915,DS-03211882-4bbe-4bf1-b71b-5852ef07527a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-580868544-172.17.0.17-1595379410808:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41004,DS-80009956-e1ad-4da1-945e-ba5c0e721273,DISK], DatanodeInfoWithStorage[127.0.0.1:39287,DS-16466014-7fd3-4ae2-93c2-55b4cc51aa72,DISK], DatanodeInfoWithStorage[127.0.0.1:44850,DS-5e1543d2-6a28-47e7-b0a0-4a93dd45f009,DISK], DatanodeInfoWithStorage[127.0.0.1:43932,DS-07a479de-1964-40e4-b349-58e9cc0acac2,DISK], DatanodeInfoWithStorage[127.0.0.1:39804,DS-87282807-01a6-4129-989c-22d129adc497,DISK], DatanodeInfoWithStorage[127.0.0.1:40134,DS-bede2400-ee8b-470d-9a19-c5a4ece2c4a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40462,DS-6659737b-fae2-4d23-83e0-e6e36a283b37,DISK], DatanodeInfoWithStorage[127.0.0.1:37205,DS-b49e3c22-0bc3-41f7-b27d-e9057ef17d69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-580868544-172.17.0.17-1595379410808:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41004,DS-80009956-e1ad-4da1-945e-ba5c0e721273,DISK], DatanodeInfoWithStorage[127.0.0.1:39287,DS-16466014-7fd3-4ae2-93c2-55b4cc51aa72,DISK], DatanodeInfoWithStorage[127.0.0.1:44850,DS-5e1543d2-6a28-47e7-b0a0-4a93dd45f009,DISK], DatanodeInfoWithStorage[127.0.0.1:43932,DS-07a479de-1964-40e4-b349-58e9cc0acac2,DISK], DatanodeInfoWithStorage[127.0.0.1:39804,DS-87282807-01a6-4129-989c-22d129adc497,DISK], DatanodeInfoWithStorage[127.0.0.1:40134,DS-bede2400-ee8b-470d-9a19-c5a4ece2c4a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40462,DS-6659737b-fae2-4d23-83e0-e6e36a283b37,DISK], DatanodeInfoWithStorage[127.0.0.1:37205,DS-b49e3c22-0bc3-41f7-b27d-e9057ef17d69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-868885733-172.17.0.17-1595379577882:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40339,DS-4f468ca1-b8c9-4c21-9b56-d279d5a7999a,DISK], DatanodeInfoWithStorage[127.0.0.1:34545,DS-5a193ae8-784b-4c89-a5bb-414871756840,DISK], DatanodeInfoWithStorage[127.0.0.1:39797,DS-f361b5c0-751c-4b6f-ba4f-7f45cecd4e53,DISK], DatanodeInfoWithStorage[127.0.0.1:44588,DS-7df084e2-c378-4413-8aeb-289252baa8b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43452,DS-68a533d9-6b86-4650-b1b2-ba7809369bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:39706,DS-e250dedd-6ac5-4df1-872e-1ea5bcd5a434,DISK], DatanodeInfoWithStorage[127.0.0.1:38273,DS-dda65d9a-9844-46b8-8e32-651a387e5a35,DISK], DatanodeInfoWithStorage[127.0.0.1:34897,DS-be2e82e1-9280-435c-86ce-b25934b65f6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-868885733-172.17.0.17-1595379577882:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40339,DS-4f468ca1-b8c9-4c21-9b56-d279d5a7999a,DISK], DatanodeInfoWithStorage[127.0.0.1:34545,DS-5a193ae8-784b-4c89-a5bb-414871756840,DISK], DatanodeInfoWithStorage[127.0.0.1:39797,DS-f361b5c0-751c-4b6f-ba4f-7f45cecd4e53,DISK], DatanodeInfoWithStorage[127.0.0.1:44588,DS-7df084e2-c378-4413-8aeb-289252baa8b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43452,DS-68a533d9-6b86-4650-b1b2-ba7809369bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:39706,DS-e250dedd-6ac5-4df1-872e-1ea5bcd5a434,DISK], DatanodeInfoWithStorage[127.0.0.1:38273,DS-dda65d9a-9844-46b8-8e32-651a387e5a35,DISK], DatanodeInfoWithStorage[127.0.0.1:34897,DS-be2e82e1-9280-435c-86ce-b25934b65f6b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1540409535-172.17.0.17-1595379612117:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45301,DS-db6f6a8a-21d8-4eb8-b7f9-6ba8e829542e,DISK], DatanodeInfoWithStorage[127.0.0.1:46463,DS-7f336434-d0e3-49cb-843a-a0dd2ca8ab35,DISK], DatanodeInfoWithStorage[127.0.0.1:34134,DS-f772fb01-ead3-4ef8-9005-88d9304d5c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:44697,DS-682422a1-195a-46b5-b1e9-ec442710e465,DISK], DatanodeInfoWithStorage[127.0.0.1:42852,DS-133f7bbb-9c2c-427f-aaca-24a9813dd2d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43474,DS-e21bf4ff-c2c6-4280-9198-e510344e6c0c,DISK], DatanodeInfoWithStorage[127.0.0.1:44667,DS-d464a655-35dc-45bf-9fe5-be406ccb843b,DISK], DatanodeInfoWithStorage[127.0.0.1:40273,DS-c0970c35-2e76-4f10-9553-c99a4adef489,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1540409535-172.17.0.17-1595379612117:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45301,DS-db6f6a8a-21d8-4eb8-b7f9-6ba8e829542e,DISK], DatanodeInfoWithStorage[127.0.0.1:46463,DS-7f336434-d0e3-49cb-843a-a0dd2ca8ab35,DISK], DatanodeInfoWithStorage[127.0.0.1:34134,DS-f772fb01-ead3-4ef8-9005-88d9304d5c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:44697,DS-682422a1-195a-46b5-b1e9-ec442710e465,DISK], DatanodeInfoWithStorage[127.0.0.1:42852,DS-133f7bbb-9c2c-427f-aaca-24a9813dd2d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43474,DS-e21bf4ff-c2c6-4280-9198-e510344e6c0c,DISK], DatanodeInfoWithStorage[127.0.0.1:44667,DS-d464a655-35dc-45bf-9fe5-be406ccb843b,DISK], DatanodeInfoWithStorage[127.0.0.1:40273,DS-c0970c35-2e76-4f10-9553-c99a4adef489,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-155708485-172.17.0.17-1595379854853:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44505,DS-5e3bab5b-0595-404d-a10b-b1784d783fb6,DISK], DatanodeInfoWithStorage[127.0.0.1:42006,DS-fd01946f-2d58-46a3-a5f2-92ec9d4ee683,DISK], DatanodeInfoWithStorage[127.0.0.1:41163,DS-b6b00247-caa0-4138-9f08-f1b03ff86d03,DISK], DatanodeInfoWithStorage[127.0.0.1:42645,DS-cd4aead2-888d-4113-9946-b63d814cd318,DISK], DatanodeInfoWithStorage[127.0.0.1:36074,DS-e1dcf603-eba4-485f-8377-bda6367b313f,DISK], DatanodeInfoWithStorage[127.0.0.1:33190,DS-c9fc3b29-3955-408c-8ebc-0cb887f07310,DISK], DatanodeInfoWithStorage[127.0.0.1:36103,DS-849127aa-fa83-4177-9528-9fc778989a56,DISK], DatanodeInfoWithStorage[127.0.0.1:40875,DS-198a8993-1cf8-4cc1-840b-7a5fc5bb75c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-155708485-172.17.0.17-1595379854853:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44505,DS-5e3bab5b-0595-404d-a10b-b1784d783fb6,DISK], DatanodeInfoWithStorage[127.0.0.1:42006,DS-fd01946f-2d58-46a3-a5f2-92ec9d4ee683,DISK], DatanodeInfoWithStorage[127.0.0.1:41163,DS-b6b00247-caa0-4138-9f08-f1b03ff86d03,DISK], DatanodeInfoWithStorage[127.0.0.1:42645,DS-cd4aead2-888d-4113-9946-b63d814cd318,DISK], DatanodeInfoWithStorage[127.0.0.1:36074,DS-e1dcf603-eba4-485f-8377-bda6367b313f,DISK], DatanodeInfoWithStorage[127.0.0.1:33190,DS-c9fc3b29-3955-408c-8ebc-0cb887f07310,DISK], DatanodeInfoWithStorage[127.0.0.1:36103,DS-849127aa-fa83-4177-9528-9fc778989a56,DISK], DatanodeInfoWithStorage[127.0.0.1:40875,DS-198a8993-1cf8-4cc1-840b-7a5fc5bb75c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-83521208-172.17.0.17-1595379931545:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43789,DS-e8191c4f-8e70-4274-a524-3d675190b6fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45518,DS-c3c69aa6-9f74-4d5a-86e1-e563ac4441c3,DISK], DatanodeInfoWithStorage[127.0.0.1:39293,DS-088ca3b9-1974-4ed1-a1a3-0068028e1435,DISK], DatanodeInfoWithStorage[127.0.0.1:36755,DS-274cf661-5c8a-48d4-a1a7-430f3e67930f,DISK], DatanodeInfoWithStorage[127.0.0.1:39714,DS-50edac35-6c87-41d3-9a0d-f9d82d7aa4cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38012,DS-febbc45c-0576-4528-81a6-2b6bfcf4aafb,DISK], DatanodeInfoWithStorage[127.0.0.1:44307,DS-6b294473-b5f2-47d2-b8c0-add177ce2ee2,DISK], DatanodeInfoWithStorage[127.0.0.1:33807,DS-314a3428-dbe3-45e0-a3b0-2168705865d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-83521208-172.17.0.17-1595379931545:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43789,DS-e8191c4f-8e70-4274-a524-3d675190b6fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45518,DS-c3c69aa6-9f74-4d5a-86e1-e563ac4441c3,DISK], DatanodeInfoWithStorage[127.0.0.1:39293,DS-088ca3b9-1974-4ed1-a1a3-0068028e1435,DISK], DatanodeInfoWithStorage[127.0.0.1:36755,DS-274cf661-5c8a-48d4-a1a7-430f3e67930f,DISK], DatanodeInfoWithStorage[127.0.0.1:39714,DS-50edac35-6c87-41d3-9a0d-f9d82d7aa4cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38012,DS-febbc45c-0576-4528-81a6-2b6bfcf4aafb,DISK], DatanodeInfoWithStorage[127.0.0.1:44307,DS-6b294473-b5f2-47d2-b8c0-add177ce2ee2,DISK], DatanodeInfoWithStorage[127.0.0.1:33807,DS-314a3428-dbe3-45e0-a3b0-2168705865d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-664798145-172.17.0.17-1595380285787:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33213,DS-3c7dce10-41af-4469-9255-aaf2be2b5568,DISK], DatanodeInfoWithStorage[127.0.0.1:44292,DS-a268b3e4-b20c-4693-b4e6-5683354393ea,DISK], DatanodeInfoWithStorage[127.0.0.1:46095,DS-e9bf3fd2-942a-4ebb-9460-26e8c97eb9c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37432,DS-baec7768-5c4b-4e6f-af1f-0d6e49c94b0a,DISK], DatanodeInfoWithStorage[127.0.0.1:34654,DS-c82386f3-3502-4f43-bbba-5cffa0f79269,DISK], DatanodeInfoWithStorage[127.0.0.1:33849,DS-53c8910f-e266-4a0c-9ce6-dd69e97a26e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42967,DS-6a4bc7c1-dfb4-4bea-b0b0-b817c498d985,DISK], DatanodeInfoWithStorage[127.0.0.1:39313,DS-1aafe30e-fb1f-48f6-ad20-ce26a3c4320e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-664798145-172.17.0.17-1595380285787:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33213,DS-3c7dce10-41af-4469-9255-aaf2be2b5568,DISK], DatanodeInfoWithStorage[127.0.0.1:44292,DS-a268b3e4-b20c-4693-b4e6-5683354393ea,DISK], DatanodeInfoWithStorage[127.0.0.1:46095,DS-e9bf3fd2-942a-4ebb-9460-26e8c97eb9c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37432,DS-baec7768-5c4b-4e6f-af1f-0d6e49c94b0a,DISK], DatanodeInfoWithStorage[127.0.0.1:34654,DS-c82386f3-3502-4f43-bbba-5cffa0f79269,DISK], DatanodeInfoWithStorage[127.0.0.1:33849,DS-53c8910f-e266-4a0c-9ce6-dd69e97a26e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42967,DS-6a4bc7c1-dfb4-4bea-b0b0-b817c498d985,DISK], DatanodeInfoWithStorage[127.0.0.1:39313,DS-1aafe30e-fb1f-48f6-ad20-ce26a3c4320e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-578082857-172.17.0.17-1595381036588:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43161,DS-2720a7bf-d2ef-4e43-9588-aa80ddbf2149,DISK], DatanodeInfoWithStorage[127.0.0.1:45294,DS-144e2fda-fe46-41ac-aef2-ce0f0f40cc03,DISK], DatanodeInfoWithStorage[127.0.0.1:40080,DS-b76f0455-f700-4b33-a83b-c12268e6b24d,DISK], DatanodeInfoWithStorage[127.0.0.1:35732,DS-5214a013-fc39-4d83-94b0-c525a624e98d,DISK], DatanodeInfoWithStorage[127.0.0.1:33499,DS-8761fcec-6cf0-47f4-8869-4dcd2dbbf2e5,DISK], DatanodeInfoWithStorage[127.0.0.1:32907,DS-6d0f3bad-0bde-4d1a-bd35-c8df642bdc49,DISK], DatanodeInfoWithStorage[127.0.0.1:40009,DS-d1745b0a-745f-4fd7-a4f8-d2aead989020,DISK], DatanodeInfoWithStorage[127.0.0.1:42925,DS-8b715d80-4fee-45ab-8e59-61b7c78d5ba7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-578082857-172.17.0.17-1595381036588:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43161,DS-2720a7bf-d2ef-4e43-9588-aa80ddbf2149,DISK], DatanodeInfoWithStorage[127.0.0.1:45294,DS-144e2fda-fe46-41ac-aef2-ce0f0f40cc03,DISK], DatanodeInfoWithStorage[127.0.0.1:40080,DS-b76f0455-f700-4b33-a83b-c12268e6b24d,DISK], DatanodeInfoWithStorage[127.0.0.1:35732,DS-5214a013-fc39-4d83-94b0-c525a624e98d,DISK], DatanodeInfoWithStorage[127.0.0.1:33499,DS-8761fcec-6cf0-47f4-8869-4dcd2dbbf2e5,DISK], DatanodeInfoWithStorage[127.0.0.1:32907,DS-6d0f3bad-0bde-4d1a-bd35-c8df642bdc49,DISK], DatanodeInfoWithStorage[127.0.0.1:40009,DS-d1745b0a-745f-4fd7-a4f8-d2aead989020,DISK], DatanodeInfoWithStorage[127.0.0.1:42925,DS-8b715d80-4fee-45ab-8e59-61b7c78d5ba7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.edits.noeditlogchannelflush
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-809532801-172.17.0.17-1595381150831:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34990,DS-6c39ef0d-1c70-4ce8-ae0c-4e0bb9eccab8,DISK], DatanodeInfoWithStorage[127.0.0.1:35672,DS-240e9ebb-8c28-428d-8dc9-b5b9a3f7fb8b,DISK], DatanodeInfoWithStorage[127.0.0.1:41740,DS-ab3612e8-76d9-4c87-9138-d58c6f382e84,DISK], DatanodeInfoWithStorage[127.0.0.1:44866,DS-83e49dd6-b604-4f41-8ce5-810f7a1e3988,DISK], DatanodeInfoWithStorage[127.0.0.1:45242,DS-22b1422e-bbcf-4aae-9139-84b87f1b9a7a,DISK], DatanodeInfoWithStorage[127.0.0.1:32945,DS-a88ec8a6-4dc9-4e1c-97db-4ee8204dcd28,DISK], DatanodeInfoWithStorage[127.0.0.1:35573,DS-350461d1-e24e-489e-b4d4-d6f2a39e3be2,DISK], DatanodeInfoWithStorage[127.0.0.1:35199,DS-7497bd93-4c3d-448d-b9b5-cc9e9c6cd2db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-809532801-172.17.0.17-1595381150831:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34990,DS-6c39ef0d-1c70-4ce8-ae0c-4e0bb9eccab8,DISK], DatanodeInfoWithStorage[127.0.0.1:35672,DS-240e9ebb-8c28-428d-8dc9-b5b9a3f7fb8b,DISK], DatanodeInfoWithStorage[127.0.0.1:41740,DS-ab3612e8-76d9-4c87-9138-d58c6f382e84,DISK], DatanodeInfoWithStorage[127.0.0.1:44866,DS-83e49dd6-b604-4f41-8ce5-810f7a1e3988,DISK], DatanodeInfoWithStorage[127.0.0.1:45242,DS-22b1422e-bbcf-4aae-9139-84b87f1b9a7a,DISK], DatanodeInfoWithStorage[127.0.0.1:32945,DS-a88ec8a6-4dc9-4e1c-97db-4ee8204dcd28,DISK], DatanodeInfoWithStorage[127.0.0.1:35573,DS-350461d1-e24e-489e-b4d4-d6f2a39e3be2,DISK], DatanodeInfoWithStorage[127.0.0.1:35199,DS-7497bd93-4c3d-448d-b9b5-cc9e9c6cd2db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 5 out of 50
result: false positive !!!
Total execution time in seconds : 5210
