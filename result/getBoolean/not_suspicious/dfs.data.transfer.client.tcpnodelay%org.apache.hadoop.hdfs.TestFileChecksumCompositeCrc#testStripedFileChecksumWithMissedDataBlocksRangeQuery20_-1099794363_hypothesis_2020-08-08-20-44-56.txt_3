reconf_parameter: dfs.data.transfer.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.data.transfer.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1066470804-172.17.0.15-1596919807154:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43311,DS-92168543-9034-4162-86e2-f828db7e0bf1,DISK], DatanodeInfoWithStorage[127.0.0.1:33945,DS-e1b4628e-9882-4073-b499-3d0a8dbc6598,DISK], DatanodeInfoWithStorage[127.0.0.1:36739,DS-e1a5b943-044f-464c-ad6e-d0b779d10c82,DISK], DatanodeInfoWithStorage[127.0.0.1:46511,DS-a7d7a290-ce1b-4f3f-b4a2-67d45ce13df4,DISK], DatanodeInfoWithStorage[127.0.0.1:46479,DS-02e218de-427b-4c23-b1eb-05a895c3db71,DISK], DatanodeInfoWithStorage[127.0.0.1:42834,DS-f7e64ffb-aac3-42a5-af5b-616034467368,DISK], DatanodeInfoWithStorage[127.0.0.1:45612,DS-746a792c-7e0d-40b2-aad1-2560f3729c44,DISK], DatanodeInfoWithStorage[127.0.0.1:42845,DS-357160ef-0339-4545-b2c2-ae96771416fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1066470804-172.17.0.15-1596919807154:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43311,DS-92168543-9034-4162-86e2-f828db7e0bf1,DISK], DatanodeInfoWithStorage[127.0.0.1:33945,DS-e1b4628e-9882-4073-b499-3d0a8dbc6598,DISK], DatanodeInfoWithStorage[127.0.0.1:36739,DS-e1a5b943-044f-464c-ad6e-d0b779d10c82,DISK], DatanodeInfoWithStorage[127.0.0.1:46511,DS-a7d7a290-ce1b-4f3f-b4a2-67d45ce13df4,DISK], DatanodeInfoWithStorage[127.0.0.1:46479,DS-02e218de-427b-4c23-b1eb-05a895c3db71,DISK], DatanodeInfoWithStorage[127.0.0.1:42834,DS-f7e64ffb-aac3-42a5-af5b-616034467368,DISK], DatanodeInfoWithStorage[127.0.0.1:45612,DS-746a792c-7e0d-40b2-aad1-2560f3729c44,DISK], DatanodeInfoWithStorage[127.0.0.1:42845,DS-357160ef-0339-4545-b2c2-ae96771416fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1977989303-172.17.0.15-1596919871023:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36575,DS-8113925e-7a70-49d8-9ffe-97027306f73c,DISK], DatanodeInfoWithStorage[127.0.0.1:46566,DS-562d7735-0c18-465c-a0ef-6a6c8bacfb04,DISK], DatanodeInfoWithStorage[127.0.0.1:43793,DS-768837db-da47-4705-944e-2b1f78da1c00,DISK], DatanodeInfoWithStorage[127.0.0.1:44773,DS-f753039c-f6d8-4b14-9262-62c7939a75fc,DISK], DatanodeInfoWithStorage[127.0.0.1:41900,DS-47e310ff-1767-4f36-9dfc-261a3383969a,DISK], DatanodeInfoWithStorage[127.0.0.1:41639,DS-0a12832c-8a7e-4a71-98a8-80e85d392946,DISK], DatanodeInfoWithStorage[127.0.0.1:37729,DS-5c1a1868-38f0-49ab-8f45-ef063d685039,DISK], DatanodeInfoWithStorage[127.0.0.1:35079,DS-8bb0b91a-2f73-47c3-8d77-dafa8d9e7d4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1977989303-172.17.0.15-1596919871023:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36575,DS-8113925e-7a70-49d8-9ffe-97027306f73c,DISK], DatanodeInfoWithStorage[127.0.0.1:46566,DS-562d7735-0c18-465c-a0ef-6a6c8bacfb04,DISK], DatanodeInfoWithStorage[127.0.0.1:43793,DS-768837db-da47-4705-944e-2b1f78da1c00,DISK], DatanodeInfoWithStorage[127.0.0.1:44773,DS-f753039c-f6d8-4b14-9262-62c7939a75fc,DISK], DatanodeInfoWithStorage[127.0.0.1:41900,DS-47e310ff-1767-4f36-9dfc-261a3383969a,DISK], DatanodeInfoWithStorage[127.0.0.1:41639,DS-0a12832c-8a7e-4a71-98a8-80e85d392946,DISK], DatanodeInfoWithStorage[127.0.0.1:37729,DS-5c1a1868-38f0-49ab-8f45-ef063d685039,DISK], DatanodeInfoWithStorage[127.0.0.1:35079,DS-8bb0b91a-2f73-47c3-8d77-dafa8d9e7d4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1516492686-172.17.0.15-1596919972050:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34423,DS-8c74267f-6c57-4a89-b1e7-cfa6b4572c58,DISK], DatanodeInfoWithStorage[127.0.0.1:40590,DS-f8d64159-6518-4b31-8d5b-1a4a12e0f941,DISK], DatanodeInfoWithStorage[127.0.0.1:39831,DS-5618ac1d-926c-42e5-9220-8dd3250aad15,DISK], DatanodeInfoWithStorage[127.0.0.1:33967,DS-c1c9d8f0-025b-419d-9fd4-274f3f4e016b,DISK], DatanodeInfoWithStorage[127.0.0.1:36485,DS-84cb0f24-c4ab-49dc-895b-ea2d133665f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42252,DS-c3f9c1ff-b942-43d9-abb8-9dcba6a47cd6,DISK], DatanodeInfoWithStorage[127.0.0.1:35928,DS-b5e94c33-f455-4ba2-9868-c342e55c740a,DISK], DatanodeInfoWithStorage[127.0.0.1:40489,DS-1b5f7e1e-462e-4634-90a3-52e22efc7057,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1516492686-172.17.0.15-1596919972050:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34423,DS-8c74267f-6c57-4a89-b1e7-cfa6b4572c58,DISK], DatanodeInfoWithStorage[127.0.0.1:40590,DS-f8d64159-6518-4b31-8d5b-1a4a12e0f941,DISK], DatanodeInfoWithStorage[127.0.0.1:39831,DS-5618ac1d-926c-42e5-9220-8dd3250aad15,DISK], DatanodeInfoWithStorage[127.0.0.1:33967,DS-c1c9d8f0-025b-419d-9fd4-274f3f4e016b,DISK], DatanodeInfoWithStorage[127.0.0.1:36485,DS-84cb0f24-c4ab-49dc-895b-ea2d133665f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42252,DS-c3f9c1ff-b942-43d9-abb8-9dcba6a47cd6,DISK], DatanodeInfoWithStorage[127.0.0.1:35928,DS-b5e94c33-f455-4ba2-9868-c342e55c740a,DISK], DatanodeInfoWithStorage[127.0.0.1:40489,DS-1b5f7e1e-462e-4634-90a3-52e22efc7057,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-654001348-172.17.0.15-1596920253448:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45495,DS-6c5091de-d834-470f-b702-7380248a1567,DISK], DatanodeInfoWithStorage[127.0.0.1:45873,DS-c9516718-6794-4592-bd31-69d210a1251c,DISK], DatanodeInfoWithStorage[127.0.0.1:43658,DS-286be4eb-9c2e-43a4-9809-192075805186,DISK], DatanodeInfoWithStorage[127.0.0.1:46464,DS-517215cf-207f-42e2-835f-e6aeda698f63,DISK], DatanodeInfoWithStorage[127.0.0.1:37569,DS-09abcfa4-ffee-46bf-a566-b80431db9858,DISK], DatanodeInfoWithStorage[127.0.0.1:45951,DS-263127b5-bc18-4680-8908-4fcd8b6fe770,DISK], DatanodeInfoWithStorage[127.0.0.1:34076,DS-3b5cc34b-38e6-48b0-a516-519ab592c078,DISK], DatanodeInfoWithStorage[127.0.0.1:34103,DS-1d2656b1-7dd7-47c7-af73-59d93cd97fb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-654001348-172.17.0.15-1596920253448:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45495,DS-6c5091de-d834-470f-b702-7380248a1567,DISK], DatanodeInfoWithStorage[127.0.0.1:45873,DS-c9516718-6794-4592-bd31-69d210a1251c,DISK], DatanodeInfoWithStorage[127.0.0.1:43658,DS-286be4eb-9c2e-43a4-9809-192075805186,DISK], DatanodeInfoWithStorage[127.0.0.1:46464,DS-517215cf-207f-42e2-835f-e6aeda698f63,DISK], DatanodeInfoWithStorage[127.0.0.1:37569,DS-09abcfa4-ffee-46bf-a566-b80431db9858,DISK], DatanodeInfoWithStorage[127.0.0.1:45951,DS-263127b5-bc18-4680-8908-4fcd8b6fe770,DISK], DatanodeInfoWithStorage[127.0.0.1:34076,DS-3b5cc34b-38e6-48b0-a516-519ab592c078,DISK], DatanodeInfoWithStorage[127.0.0.1:34103,DS-1d2656b1-7dd7-47c7-af73-59d93cd97fb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1035225297-172.17.0.15-1596920546187:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33907,DS-c7542291-3216-4d76-aee5-f606c198460c,DISK], DatanodeInfoWithStorage[127.0.0.1:33961,DS-d54b3e5b-d76f-4b22-ac86-f80eafa053b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42720,DS-2d32de2c-5f64-42c0-a86e-5286568e5b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:43161,DS-9b0f94ff-c1ac-40b4-b5fc-8e11300446df,DISK], DatanodeInfoWithStorage[127.0.0.1:43953,DS-37bddd22-e45d-4d27-9496-2e1af1524305,DISK], DatanodeInfoWithStorage[127.0.0.1:46772,DS-2eb69301-fdba-4a41-9c01-b1e67829216d,DISK], DatanodeInfoWithStorage[127.0.0.1:44593,DS-0dfd92bc-e415-4b3f-bd57-bbacde4cce76,DISK], DatanodeInfoWithStorage[127.0.0.1:33376,DS-21094eca-5285-4ca1-b015-45a0e028a6c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1035225297-172.17.0.15-1596920546187:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33907,DS-c7542291-3216-4d76-aee5-f606c198460c,DISK], DatanodeInfoWithStorage[127.0.0.1:33961,DS-d54b3e5b-d76f-4b22-ac86-f80eafa053b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42720,DS-2d32de2c-5f64-42c0-a86e-5286568e5b6b,DISK], DatanodeInfoWithStorage[127.0.0.1:43161,DS-9b0f94ff-c1ac-40b4-b5fc-8e11300446df,DISK], DatanodeInfoWithStorage[127.0.0.1:43953,DS-37bddd22-e45d-4d27-9496-2e1af1524305,DISK], DatanodeInfoWithStorage[127.0.0.1:46772,DS-2eb69301-fdba-4a41-9c01-b1e67829216d,DISK], DatanodeInfoWithStorage[127.0.0.1:44593,DS-0dfd92bc-e415-4b3f-bd57-bbacde4cce76,DISK], DatanodeInfoWithStorage[127.0.0.1:33376,DS-21094eca-5285-4ca1-b015-45a0e028a6c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1786831022-172.17.0.15-1596920640624:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33481,DS-641844a4-fce9-4fb6-b481-cc3387d75735,DISK], DatanodeInfoWithStorage[127.0.0.1:35664,DS-901be874-4035-477b-8974-2348f5f3af36,DISK], DatanodeInfoWithStorage[127.0.0.1:45245,DS-c1032a0a-a11b-4ec4-80a9-d0a78277030b,DISK], DatanodeInfoWithStorage[127.0.0.1:46193,DS-a438e6b7-6990-4fb3-8383-aa51fbc06603,DISK], DatanodeInfoWithStorage[127.0.0.1:41299,DS-cc486f83-893f-4564-beba-9cf4783def50,DISK], DatanodeInfoWithStorage[127.0.0.1:37165,DS-997a8746-cca6-44d4-8e43-16c7c4689a19,DISK], DatanodeInfoWithStorage[127.0.0.1:42821,DS-7b91a015-fc2c-4973-b02a-a44f7af62807,DISK], DatanodeInfoWithStorage[127.0.0.1:33251,DS-80233f0d-8795-4814-8ff7-c7c72cb1a699,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1786831022-172.17.0.15-1596920640624:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33481,DS-641844a4-fce9-4fb6-b481-cc3387d75735,DISK], DatanodeInfoWithStorage[127.0.0.1:35664,DS-901be874-4035-477b-8974-2348f5f3af36,DISK], DatanodeInfoWithStorage[127.0.0.1:45245,DS-c1032a0a-a11b-4ec4-80a9-d0a78277030b,DISK], DatanodeInfoWithStorage[127.0.0.1:46193,DS-a438e6b7-6990-4fb3-8383-aa51fbc06603,DISK], DatanodeInfoWithStorage[127.0.0.1:41299,DS-cc486f83-893f-4564-beba-9cf4783def50,DISK], DatanodeInfoWithStorage[127.0.0.1:37165,DS-997a8746-cca6-44d4-8e43-16c7c4689a19,DISK], DatanodeInfoWithStorage[127.0.0.1:42821,DS-7b91a015-fc2c-4973-b02a-a44f7af62807,DISK], DatanodeInfoWithStorage[127.0.0.1:33251,DS-80233f0d-8795-4814-8ff7-c7c72cb1a699,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-885429595-172.17.0.15-1596920780296:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38995,DS-f4ab6d1f-d00d-461c-ba02-ff358fa8219a,DISK], DatanodeInfoWithStorage[127.0.0.1:35601,DS-04420a29-d0ec-4c2d-84d7-a95ba3d49822,DISK], DatanodeInfoWithStorage[127.0.0.1:40987,DS-ce21ca96-ef6f-43e2-8e3b-88c92f641356,DISK], DatanodeInfoWithStorage[127.0.0.1:42918,DS-0a98e510-7408-43d6-9a7c-e221b4e8e7f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34103,DS-7e92e19e-d63f-4442-92b4-1bf4eb0da6fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45770,DS-3d4c3184-6633-4dbd-9dc5-103ccd7a3a3e,DISK], DatanodeInfoWithStorage[127.0.0.1:33065,DS-96e8ea2f-5b59-4e9b-b159-6be988a9bc65,DISK], DatanodeInfoWithStorage[127.0.0.1:36730,DS-7670f8ef-3503-4748-8085-0a6ba831b02f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-885429595-172.17.0.15-1596920780296:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38995,DS-f4ab6d1f-d00d-461c-ba02-ff358fa8219a,DISK], DatanodeInfoWithStorage[127.0.0.1:35601,DS-04420a29-d0ec-4c2d-84d7-a95ba3d49822,DISK], DatanodeInfoWithStorage[127.0.0.1:40987,DS-ce21ca96-ef6f-43e2-8e3b-88c92f641356,DISK], DatanodeInfoWithStorage[127.0.0.1:42918,DS-0a98e510-7408-43d6-9a7c-e221b4e8e7f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34103,DS-7e92e19e-d63f-4442-92b4-1bf4eb0da6fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45770,DS-3d4c3184-6633-4dbd-9dc5-103ccd7a3a3e,DISK], DatanodeInfoWithStorage[127.0.0.1:33065,DS-96e8ea2f-5b59-4e9b-b159-6be988a9bc65,DISK], DatanodeInfoWithStorage[127.0.0.1:36730,DS-7670f8ef-3503-4748-8085-0a6ba831b02f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2088256174-172.17.0.15-1596920954964:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40976,DS-5b609543-c783-440f-abc2-3fc4c7effcc8,DISK], DatanodeInfoWithStorage[127.0.0.1:34070,DS-09dad29a-ea95-468e-b5a6-47853044d998,DISK], DatanodeInfoWithStorage[127.0.0.1:36569,DS-001f23d7-7c5f-4e3c-bc98-7870e9a47cf2,DISK], DatanodeInfoWithStorage[127.0.0.1:35917,DS-06954f2b-0283-491a-b2a3-e186800d09df,DISK], DatanodeInfoWithStorage[127.0.0.1:38760,DS-cc9c58f2-62d7-47e5-9c57-fdf9d7844b57,DISK], DatanodeInfoWithStorage[127.0.0.1:35235,DS-16a8a46d-7377-4674-93d9-ffa5dffce32c,DISK], DatanodeInfoWithStorage[127.0.0.1:45329,DS-aac2d7bf-a363-4a1b-9956-e39eaf1c49df,DISK], DatanodeInfoWithStorage[127.0.0.1:45492,DS-f4c5d2c9-0f0b-4353-94c7-49cba30b280e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2088256174-172.17.0.15-1596920954964:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40976,DS-5b609543-c783-440f-abc2-3fc4c7effcc8,DISK], DatanodeInfoWithStorage[127.0.0.1:34070,DS-09dad29a-ea95-468e-b5a6-47853044d998,DISK], DatanodeInfoWithStorage[127.0.0.1:36569,DS-001f23d7-7c5f-4e3c-bc98-7870e9a47cf2,DISK], DatanodeInfoWithStorage[127.0.0.1:35917,DS-06954f2b-0283-491a-b2a3-e186800d09df,DISK], DatanodeInfoWithStorage[127.0.0.1:38760,DS-cc9c58f2-62d7-47e5-9c57-fdf9d7844b57,DISK], DatanodeInfoWithStorage[127.0.0.1:35235,DS-16a8a46d-7377-4674-93d9-ffa5dffce32c,DISK], DatanodeInfoWithStorage[127.0.0.1:45329,DS-aac2d7bf-a363-4a1b-9956-e39eaf1c49df,DISK], DatanodeInfoWithStorage[127.0.0.1:45492,DS-f4c5d2c9-0f0b-4353-94c7-49cba30b280e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1046773823-172.17.0.15-1596921179289:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39668,DS-0c961256-4da8-4335-a66b-4da62b6edb0d,DISK], DatanodeInfoWithStorage[127.0.0.1:35761,DS-3a6bda7b-34c6-4a62-964c-953c1e3dfc63,DISK], DatanodeInfoWithStorage[127.0.0.1:37310,DS-4ccec9dc-d881-4f4e-b6ea-088011fae737,DISK], DatanodeInfoWithStorage[127.0.0.1:40089,DS-882b8900-17c0-4c8d-aa1d-7e1b564506db,DISK], DatanodeInfoWithStorage[127.0.0.1:36361,DS-453482dc-3706-47f7-85af-6e5621d02276,DISK], DatanodeInfoWithStorage[127.0.0.1:34611,DS-8e23b3ba-1f9f-4a31-b6e7-207fbd33699d,DISK], DatanodeInfoWithStorage[127.0.0.1:42228,DS-dca57b19-fd16-4795-9aa7-8641966f007d,DISK], DatanodeInfoWithStorage[127.0.0.1:37863,DS-3d9b62ec-e6c0-4e8a-842c-a477ddc3a40b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1046773823-172.17.0.15-1596921179289:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39668,DS-0c961256-4da8-4335-a66b-4da62b6edb0d,DISK], DatanodeInfoWithStorage[127.0.0.1:35761,DS-3a6bda7b-34c6-4a62-964c-953c1e3dfc63,DISK], DatanodeInfoWithStorage[127.0.0.1:37310,DS-4ccec9dc-d881-4f4e-b6ea-088011fae737,DISK], DatanodeInfoWithStorage[127.0.0.1:40089,DS-882b8900-17c0-4c8d-aa1d-7e1b564506db,DISK], DatanodeInfoWithStorage[127.0.0.1:36361,DS-453482dc-3706-47f7-85af-6e5621d02276,DISK], DatanodeInfoWithStorage[127.0.0.1:34611,DS-8e23b3ba-1f9f-4a31-b6e7-207fbd33699d,DISK], DatanodeInfoWithStorage[127.0.0.1:42228,DS-dca57b19-fd16-4795-9aa7-8641966f007d,DISK], DatanodeInfoWithStorage[127.0.0.1:37863,DS-3d9b62ec-e6c0-4e8a-842c-a477ddc3a40b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.data.transfer.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-406635980-172.17.0.15-1596921698388:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45022,DS-30784524-ffbf-4749-a0ac-669ece8ebcc8,DISK], DatanodeInfoWithStorage[127.0.0.1:46276,DS-e445aa29-4522-4ae6-b4ba-8b08231fadd2,DISK], DatanodeInfoWithStorage[127.0.0.1:44242,DS-affb1c48-cf20-4c8e-9d92-3e39536bb3ac,DISK], DatanodeInfoWithStorage[127.0.0.1:33146,DS-eeecfd5e-99dc-4a76-ad4a-9d217b5a2352,DISK], DatanodeInfoWithStorage[127.0.0.1:35534,DS-39c4b1c0-ffd1-4f2e-a08a-03fb9d9ea81d,DISK], DatanodeInfoWithStorage[127.0.0.1:42499,DS-1745bcde-9192-4e46-bfc6-4f20259260c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36755,DS-c7cb12c0-a585-49dd-bed0-36a1d23c521a,DISK], DatanodeInfoWithStorage[127.0.0.1:46073,DS-95eceae0-3af5-446b-8c36-19445b049bdc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-406635980-172.17.0.15-1596921698388:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45022,DS-30784524-ffbf-4749-a0ac-669ece8ebcc8,DISK], DatanodeInfoWithStorage[127.0.0.1:46276,DS-e445aa29-4522-4ae6-b4ba-8b08231fadd2,DISK], DatanodeInfoWithStorage[127.0.0.1:44242,DS-affb1c48-cf20-4c8e-9d92-3e39536bb3ac,DISK], DatanodeInfoWithStorage[127.0.0.1:33146,DS-eeecfd5e-99dc-4a76-ad4a-9d217b5a2352,DISK], DatanodeInfoWithStorage[127.0.0.1:35534,DS-39c4b1c0-ffd1-4f2e-a08a-03fb9d9ea81d,DISK], DatanodeInfoWithStorage[127.0.0.1:42499,DS-1745bcde-9192-4e46-bfc6-4f20259260c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36755,DS-c7cb12c0-a585-49dd-bed0-36a1d23c521a,DISK], DatanodeInfoWithStorage[127.0.0.1:46073,DS-95eceae0-3af5-446b-8c36-19445b049bdc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.data.transfer.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-915705705-172.17.0.15-1596922098485:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45241,DS-262fa665-d036-4cd5-b14f-002770fb3aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:37993,DS-ff76413d-44fd-4615-af08-1ddd933587fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41383,DS-46c5414e-be4b-426b-93dd-4a3809f58677,DISK], DatanodeInfoWithStorage[127.0.0.1:35666,DS-79d9f6c8-98e1-44db-a246-ccb482358fed,DISK], DatanodeInfoWithStorage[127.0.0.1:34480,DS-82fc8140-622e-49e7-93ac-26ffe2004ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:34364,DS-2ce37c1c-b3dd-4988-961d-b9a173488f2c,DISK], DatanodeInfoWithStorage[127.0.0.1:37344,DS-53056946-b163-4e59-afa7-997cba30aba6,DISK], DatanodeInfoWithStorage[127.0.0.1:36870,DS-d245b728-ed97-4a2d-8ade-e1e7a5fc1bcb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-915705705-172.17.0.15-1596922098485:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45241,DS-262fa665-d036-4cd5-b14f-002770fb3aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:37993,DS-ff76413d-44fd-4615-af08-1ddd933587fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41383,DS-46c5414e-be4b-426b-93dd-4a3809f58677,DISK], DatanodeInfoWithStorage[127.0.0.1:35666,DS-79d9f6c8-98e1-44db-a246-ccb482358fed,DISK], DatanodeInfoWithStorage[127.0.0.1:34480,DS-82fc8140-622e-49e7-93ac-26ffe2004ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:34364,DS-2ce37c1c-b3dd-4988-961d-b9a173488f2c,DISK], DatanodeInfoWithStorage[127.0.0.1:37344,DS-53056946-b163-4e59-afa7-997cba30aba6,DISK], DatanodeInfoWithStorage[127.0.0.1:36870,DS-d245b728-ed97-4a2d-8ade-e1e7a5fc1bcb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1178867244-172.17.0.15-1596922518838:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45059,DS-d091014e-93d8-49d4-bfb3-eebcc0d86e73,DISK], DatanodeInfoWithStorage[127.0.0.1:36282,DS-30754bc0-1f7c-4ca5-9349-920f176c9440,DISK], DatanodeInfoWithStorage[127.0.0.1:35686,DS-259a94b7-bf4c-464a-b030-f06c21060c81,DISK], DatanodeInfoWithStorage[127.0.0.1:37583,DS-e9b19156-3dd2-4e04-94cc-63bc627b096b,DISK], DatanodeInfoWithStorage[127.0.0.1:37863,DS-9a121a21-2e1a-475f-8a5b-e9ce6ae17fab,DISK], DatanodeInfoWithStorage[127.0.0.1:44435,DS-828e7724-76cb-457f-ad5a-7c91a04d60d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44184,DS-fcefaf21-689c-4da3-8877-d0d67f152933,DISK], DatanodeInfoWithStorage[127.0.0.1:38462,DS-fabe95f0-d684-424c-a0b2-90778a2f8181,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1178867244-172.17.0.15-1596922518838:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45059,DS-d091014e-93d8-49d4-bfb3-eebcc0d86e73,DISK], DatanodeInfoWithStorage[127.0.0.1:36282,DS-30754bc0-1f7c-4ca5-9349-920f176c9440,DISK], DatanodeInfoWithStorage[127.0.0.1:35686,DS-259a94b7-bf4c-464a-b030-f06c21060c81,DISK], DatanodeInfoWithStorage[127.0.0.1:37583,DS-e9b19156-3dd2-4e04-94cc-63bc627b096b,DISK], DatanodeInfoWithStorage[127.0.0.1:37863,DS-9a121a21-2e1a-475f-8a5b-e9ce6ae17fab,DISK], DatanodeInfoWithStorage[127.0.0.1:44435,DS-828e7724-76cb-457f-ad5a-7c91a04d60d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44184,DS-fcefaf21-689c-4da3-8877-d0d67f152933,DISK], DatanodeInfoWithStorage[127.0.0.1:38462,DS-fabe95f0-d684-424c-a0b2-90778a2f8181,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-703842492-172.17.0.15-1596922911704:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44297,DS-f4454e95-af4b-4c3f-91b6-9fd90694e9e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45892,DS-cc88346e-acfd-49e7-9efb-fc7dac8112bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36050,DS-787e13f9-c5b2-41ec-b8c3-30f50d2a3db6,DISK], DatanodeInfoWithStorage[127.0.0.1:36884,DS-775eabf3-966e-4f48-a816-b17fa6cdfd58,DISK], DatanodeInfoWithStorage[127.0.0.1:34434,DS-25c07a82-3666-4159-8aa3-54db7686f829,DISK], DatanodeInfoWithStorage[127.0.0.1:43263,DS-38111c12-c434-44a6-995d-405bf2384030,DISK], DatanodeInfoWithStorage[127.0.0.1:43259,DS-cd763b5f-7ee8-45fe-a4bd-70071ba2b508,DISK], DatanodeInfoWithStorage[127.0.0.1:33379,DS-136b3e62-efba-46c3-aacc-a6a316ec6935,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-703842492-172.17.0.15-1596922911704:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44297,DS-f4454e95-af4b-4c3f-91b6-9fd90694e9e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45892,DS-cc88346e-acfd-49e7-9efb-fc7dac8112bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36050,DS-787e13f9-c5b2-41ec-b8c3-30f50d2a3db6,DISK], DatanodeInfoWithStorage[127.0.0.1:36884,DS-775eabf3-966e-4f48-a816-b17fa6cdfd58,DISK], DatanodeInfoWithStorage[127.0.0.1:34434,DS-25c07a82-3666-4159-8aa3-54db7686f829,DISK], DatanodeInfoWithStorage[127.0.0.1:43263,DS-38111c12-c434-44a6-995d-405bf2384030,DISK], DatanodeInfoWithStorage[127.0.0.1:43259,DS-cd763b5f-7ee8-45fe-a4bd-70071ba2b508,DISK], DatanodeInfoWithStorage[127.0.0.1:33379,DS-136b3e62-efba-46c3-aacc-a6a316ec6935,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-467509655-172.17.0.15-1596923011293:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44121,DS-a58dac02-1298-477a-9fad-1b851e44892e,DISK], DatanodeInfoWithStorage[127.0.0.1:37290,DS-224aa52c-8d7f-4c49-ba3e-d977d7916ef9,DISK], DatanodeInfoWithStorage[127.0.0.1:37548,DS-13ca264e-339c-4b38-a583-68e97b1666f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45120,DS-b4c5ee26-fda5-4956-9f26-b0e1968949d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46053,DS-afc60c70-32cc-4e5d-b2fa-c1606add884f,DISK], DatanodeInfoWithStorage[127.0.0.1:39713,DS-2041ce23-1838-4dc7-b56a-3b45f80fba45,DISK], DatanodeInfoWithStorage[127.0.0.1:46842,DS-823cc76f-beb7-499d-9d41-21e952aac2e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38176,DS-18c89f66-9df2-42a3-8df6-bf22da7ac9d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-467509655-172.17.0.15-1596923011293:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44121,DS-a58dac02-1298-477a-9fad-1b851e44892e,DISK], DatanodeInfoWithStorage[127.0.0.1:37290,DS-224aa52c-8d7f-4c49-ba3e-d977d7916ef9,DISK], DatanodeInfoWithStorage[127.0.0.1:37548,DS-13ca264e-339c-4b38-a583-68e97b1666f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45120,DS-b4c5ee26-fda5-4956-9f26-b0e1968949d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46053,DS-afc60c70-32cc-4e5d-b2fa-c1606add884f,DISK], DatanodeInfoWithStorage[127.0.0.1:39713,DS-2041ce23-1838-4dc7-b56a-3b45f80fba45,DISK], DatanodeInfoWithStorage[127.0.0.1:46842,DS-823cc76f-beb7-499d-9d41-21e952aac2e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38176,DS-18c89f66-9df2-42a3-8df6-bf22da7ac9d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-951951112-172.17.0.15-1596923808773:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44063,DS-a75d3da5-826f-40c8-9ad4-44ef39cee533,DISK], DatanodeInfoWithStorage[127.0.0.1:35355,DS-3ce9544e-c56f-4a8f-8ef5-d6a9841f9f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:45766,DS-53fa96ea-0f46-47fa-be6e-5002bc38483c,DISK], DatanodeInfoWithStorage[127.0.0.1:42087,DS-50228e21-ae3b-465b-af7a-f5752d4b91dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43552,DS-d0412e0a-81e2-48d9-83b1-ba635eb6a2e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41690,DS-1f3d2a6b-5a5a-4e49-9471-fe8dc189806c,DISK], DatanodeInfoWithStorage[127.0.0.1:35745,DS-a8ab1de5-07ae-4044-b2a1-d81f18ba57af,DISK], DatanodeInfoWithStorage[127.0.0.1:35088,DS-0c60070e-6700-4826-b8ee-3765b2d17a48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-951951112-172.17.0.15-1596923808773:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44063,DS-a75d3da5-826f-40c8-9ad4-44ef39cee533,DISK], DatanodeInfoWithStorage[127.0.0.1:35355,DS-3ce9544e-c56f-4a8f-8ef5-d6a9841f9f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:45766,DS-53fa96ea-0f46-47fa-be6e-5002bc38483c,DISK], DatanodeInfoWithStorage[127.0.0.1:42087,DS-50228e21-ae3b-465b-af7a-f5752d4b91dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43552,DS-d0412e0a-81e2-48d9-83b1-ba635eb6a2e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41690,DS-1f3d2a6b-5a5a-4e49-9471-fe8dc189806c,DISK], DatanodeInfoWithStorage[127.0.0.1:35745,DS-a8ab1de5-07ae-4044-b2a1-d81f18ba57af,DISK], DatanodeInfoWithStorage[127.0.0.1:35088,DS-0c60070e-6700-4826-b8ee-3765b2d17a48,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.data.transfer.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-92856521-172.17.0.15-1596923835431:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36656,DS-2af2e8c6-e2b7-4928-b663-27bb73cd012a,DISK], DatanodeInfoWithStorage[127.0.0.1:37940,DS-c82a9b23-d436-49b6-a130-c539bff3d4d9,DISK], DatanodeInfoWithStorage[127.0.0.1:46263,DS-104e89da-c42d-4f35-8038-77e37983de17,DISK], DatanodeInfoWithStorage[127.0.0.1:34351,DS-be957f15-b8f9-425c-bc62-a0578433b7b1,DISK], DatanodeInfoWithStorage[127.0.0.1:38730,DS-ecc54c07-2976-4df5-aa5e-5bd438add098,DISK], DatanodeInfoWithStorage[127.0.0.1:45387,DS-4c3ca5cd-3941-4610-a396-9bf30b300881,DISK], DatanodeInfoWithStorage[127.0.0.1:42983,DS-9c9248f5-b18f-4f3a-bce7-9d2d0ce9aa1d,DISK], DatanodeInfoWithStorage[127.0.0.1:42204,DS-f6872453-88aa-4f9b-b3ea-b4c40060bb7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-92856521-172.17.0.15-1596923835431:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36656,DS-2af2e8c6-e2b7-4928-b663-27bb73cd012a,DISK], DatanodeInfoWithStorage[127.0.0.1:37940,DS-c82a9b23-d436-49b6-a130-c539bff3d4d9,DISK], DatanodeInfoWithStorage[127.0.0.1:46263,DS-104e89da-c42d-4f35-8038-77e37983de17,DISK], DatanodeInfoWithStorage[127.0.0.1:34351,DS-be957f15-b8f9-425c-bc62-a0578433b7b1,DISK], DatanodeInfoWithStorage[127.0.0.1:38730,DS-ecc54c07-2976-4df5-aa5e-5bd438add098,DISK], DatanodeInfoWithStorage[127.0.0.1:45387,DS-4c3ca5cd-3941-4610-a396-9bf30b300881,DISK], DatanodeInfoWithStorage[127.0.0.1:42983,DS-9c9248f5-b18f-4f3a-bce7-9d2d0ce9aa1d,DISK], DatanodeInfoWithStorage[127.0.0.1:42204,DS-f6872453-88aa-4f9b-b3ea-b4c40060bb7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.client.tcpnodelay
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1421534642-172.17.0.15-1596923906936:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40834,DS-3ec58555-bca3-4bae-bbed-0e832de8e610,DISK], DatanodeInfoWithStorage[127.0.0.1:41974,DS-8e6f1aa3-ae13-475b-bdf2-ba7a09a1b995,DISK], DatanodeInfoWithStorage[127.0.0.1:40274,DS-05fcfe6a-1c45-43d2-92f5-957e77c9c5fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35798,DS-92c9b7b0-a9e9-4b16-8433-219d91e3375a,DISK], DatanodeInfoWithStorage[127.0.0.1:36766,DS-7e2b844a-f91c-431d-9059-54a3f0ffe44b,DISK], DatanodeInfoWithStorage[127.0.0.1:35241,DS-0533fb47-c2ad-444e-8555-22aade747eab,DISK], DatanodeInfoWithStorage[127.0.0.1:41938,DS-24edb40f-0fc2-4462-974f-ff7c64286f0f,DISK], DatanodeInfoWithStorage[127.0.0.1:41612,DS-1132417a-2c7d-4e43-b43d-57d7475bc695,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1421534642-172.17.0.15-1596923906936:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40834,DS-3ec58555-bca3-4bae-bbed-0e832de8e610,DISK], DatanodeInfoWithStorage[127.0.0.1:41974,DS-8e6f1aa3-ae13-475b-bdf2-ba7a09a1b995,DISK], DatanodeInfoWithStorage[127.0.0.1:40274,DS-05fcfe6a-1c45-43d2-92f5-957e77c9c5fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35798,DS-92c9b7b0-a9e9-4b16-8433-219d91e3375a,DISK], DatanodeInfoWithStorage[127.0.0.1:36766,DS-7e2b844a-f91c-431d-9059-54a3f0ffe44b,DISK], DatanodeInfoWithStorage[127.0.0.1:35241,DS-0533fb47-c2ad-444e-8555-22aade747eab,DISK], DatanodeInfoWithStorage[127.0.0.1:41938,DS-24edb40f-0fc2-4462-974f-ff7c64286f0f,DISK], DatanodeInfoWithStorage[127.0.0.1:41612,DS-1132417a-2c7d-4e43-b43d-57d7475bc695,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 4910
