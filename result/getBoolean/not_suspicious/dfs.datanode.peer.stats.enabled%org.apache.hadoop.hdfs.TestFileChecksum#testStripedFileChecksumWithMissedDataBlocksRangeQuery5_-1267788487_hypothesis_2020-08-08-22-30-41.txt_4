reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-702783354-172.17.0.10-1596926170062:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45784,DS-9c96682c-4322-4420-abe6-a97578afd755,DISK], DatanodeInfoWithStorage[127.0.0.1:46454,DS-07ae2782-8ef4-42c1-bc31-639cf54d603b,DISK], DatanodeInfoWithStorage[127.0.0.1:45667,DS-6ce089af-fd01-4a89-af73-d26aec370d39,DISK], DatanodeInfoWithStorage[127.0.0.1:38599,DS-350b8bf9-069c-4f36-8814-ef611eaf3588,DISK], DatanodeInfoWithStorage[127.0.0.1:39193,DS-88bd3309-ad24-460f-9006-c3e9af5fe532,DISK], DatanodeInfoWithStorage[127.0.0.1:34722,DS-ec7e328a-97d1-4ae5-ab8f-b570e0f608be,DISK], DatanodeInfoWithStorage[127.0.0.1:40763,DS-fe6af92f-d2c6-4a38-bcac-8e346761c7b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35415,DS-f49769ad-8a59-4f65-bebe-d95ec6ba95e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-702783354-172.17.0.10-1596926170062:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45784,DS-9c96682c-4322-4420-abe6-a97578afd755,DISK], DatanodeInfoWithStorage[127.0.0.1:46454,DS-07ae2782-8ef4-42c1-bc31-639cf54d603b,DISK], DatanodeInfoWithStorage[127.0.0.1:45667,DS-6ce089af-fd01-4a89-af73-d26aec370d39,DISK], DatanodeInfoWithStorage[127.0.0.1:38599,DS-350b8bf9-069c-4f36-8814-ef611eaf3588,DISK], DatanodeInfoWithStorage[127.0.0.1:39193,DS-88bd3309-ad24-460f-9006-c3e9af5fe532,DISK], DatanodeInfoWithStorage[127.0.0.1:34722,DS-ec7e328a-97d1-4ae5-ab8f-b570e0f608be,DISK], DatanodeInfoWithStorage[127.0.0.1:40763,DS-fe6af92f-d2c6-4a38-bcac-8e346761c7b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35415,DS-f49769ad-8a59-4f65-bebe-d95ec6ba95e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-571798542-172.17.0.10-1596926238539:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32865,DS-e2dd2d16-c085-476b-aa13-a3f5a899fc37,DISK], DatanodeInfoWithStorage[127.0.0.1:41755,DS-f89af705-0399-45ee-b9bb-8348ed9e8d02,DISK], DatanodeInfoWithStorage[127.0.0.1:35204,DS-959253e2-2ad7-468d-b83c-7120ca3c7b17,DISK], DatanodeInfoWithStorage[127.0.0.1:39328,DS-3b35e226-2e29-4041-bda1-7758d8227b21,DISK], DatanodeInfoWithStorage[127.0.0.1:44057,DS-7c9b6d3a-89f5-499f-b941-1c40d2dcfff8,DISK], DatanodeInfoWithStorage[127.0.0.1:45736,DS-9b42be75-3d94-4d0d-9004-ea23e8d277f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44723,DS-734ce18e-800f-4075-a745-ec9d37f77b2b,DISK], DatanodeInfoWithStorage[127.0.0.1:39902,DS-33196558-6c40-4e65-a0d7-c3fe124d236b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-571798542-172.17.0.10-1596926238539:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32865,DS-e2dd2d16-c085-476b-aa13-a3f5a899fc37,DISK], DatanodeInfoWithStorage[127.0.0.1:41755,DS-f89af705-0399-45ee-b9bb-8348ed9e8d02,DISK], DatanodeInfoWithStorage[127.0.0.1:35204,DS-959253e2-2ad7-468d-b83c-7120ca3c7b17,DISK], DatanodeInfoWithStorage[127.0.0.1:39328,DS-3b35e226-2e29-4041-bda1-7758d8227b21,DISK], DatanodeInfoWithStorage[127.0.0.1:44057,DS-7c9b6d3a-89f5-499f-b941-1c40d2dcfff8,DISK], DatanodeInfoWithStorage[127.0.0.1:45736,DS-9b42be75-3d94-4d0d-9004-ea23e8d277f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44723,DS-734ce18e-800f-4075-a745-ec9d37f77b2b,DISK], DatanodeInfoWithStorage[127.0.0.1:39902,DS-33196558-6c40-4e65-a0d7-c3fe124d236b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1297738046-172.17.0.10-1596926341319:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33708,DS-8d120bd8-03b0-49ca-bed8-3d9dd936c42f,DISK], DatanodeInfoWithStorage[127.0.0.1:40745,DS-281aa100-3577-46b6-b6ef-5cb7a77af875,DISK], DatanodeInfoWithStorage[127.0.0.1:45300,DS-53c4a10d-797c-4fdd-96ea-1c4768fee634,DISK], DatanodeInfoWithStorage[127.0.0.1:42780,DS-e0dbdc50-ef20-43ea-bdd4-aedae3f31085,DISK], DatanodeInfoWithStorage[127.0.0.1:45210,DS-b3798c4a-95ba-4f05-b2b1-7be0cd434ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:42555,DS-74e6dd3d-0181-463d-97c1-80f4a49afa70,DISK], DatanodeInfoWithStorage[127.0.0.1:44974,DS-4e26eb41-79ae-474f-8772-1d3c2f50a235,DISK], DatanodeInfoWithStorage[127.0.0.1:44052,DS-ce840924-928a-4560-b105-9139095234c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1297738046-172.17.0.10-1596926341319:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33708,DS-8d120bd8-03b0-49ca-bed8-3d9dd936c42f,DISK], DatanodeInfoWithStorage[127.0.0.1:40745,DS-281aa100-3577-46b6-b6ef-5cb7a77af875,DISK], DatanodeInfoWithStorage[127.0.0.1:45300,DS-53c4a10d-797c-4fdd-96ea-1c4768fee634,DISK], DatanodeInfoWithStorage[127.0.0.1:42780,DS-e0dbdc50-ef20-43ea-bdd4-aedae3f31085,DISK], DatanodeInfoWithStorage[127.0.0.1:45210,DS-b3798c4a-95ba-4f05-b2b1-7be0cd434ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:42555,DS-74e6dd3d-0181-463d-97c1-80f4a49afa70,DISK], DatanodeInfoWithStorage[127.0.0.1:44974,DS-4e26eb41-79ae-474f-8772-1d3c2f50a235,DISK], DatanodeInfoWithStorage[127.0.0.1:44052,DS-ce840924-928a-4560-b105-9139095234c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1599803450-172.17.0.10-1596926664570:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46520,DS-7313fd15-a86f-4130-bd3a-231ef9cb6ff6,DISK], DatanodeInfoWithStorage[127.0.0.1:35496,DS-4318142a-5592-432c-a440-50c9d16c45cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40131,DS-e64df6f3-242f-4186-a5d4-908535e4020f,DISK], DatanodeInfoWithStorage[127.0.0.1:36518,DS-3c73448b-586f-44f8-9ecb-4bea43f35dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:40631,DS-e9c04658-d6e9-4563-956f-811300ca4493,DISK], DatanodeInfoWithStorage[127.0.0.1:36151,DS-e147d35c-11a7-43a5-8b91-dce7635c430f,DISK], DatanodeInfoWithStorage[127.0.0.1:38966,DS-5eda0fda-511f-4153-b6fd-6d2fb1fcbba7,DISK], DatanodeInfoWithStorage[127.0.0.1:38218,DS-0f3c3f6f-5d98-4467-ac9d-bf2c9cb2f85c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1599803450-172.17.0.10-1596926664570:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46520,DS-7313fd15-a86f-4130-bd3a-231ef9cb6ff6,DISK], DatanodeInfoWithStorage[127.0.0.1:35496,DS-4318142a-5592-432c-a440-50c9d16c45cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40131,DS-e64df6f3-242f-4186-a5d4-908535e4020f,DISK], DatanodeInfoWithStorage[127.0.0.1:36518,DS-3c73448b-586f-44f8-9ecb-4bea43f35dcf,DISK], DatanodeInfoWithStorage[127.0.0.1:40631,DS-e9c04658-d6e9-4563-956f-811300ca4493,DISK], DatanodeInfoWithStorage[127.0.0.1:36151,DS-e147d35c-11a7-43a5-8b91-dce7635c430f,DISK], DatanodeInfoWithStorage[127.0.0.1:38966,DS-5eda0fda-511f-4153-b6fd-6d2fb1fcbba7,DISK], DatanodeInfoWithStorage[127.0.0.1:38218,DS-0f3c3f6f-5d98-4467-ac9d-bf2c9cb2f85c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2134597101-172.17.0.10-1596926933730:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45001,DS-a2df47ba-881a-4115-9de4-8b023d29a95b,DISK], DatanodeInfoWithStorage[127.0.0.1:37393,DS-04516753-bfdc-441e-9bc5-27823224a127,DISK], DatanodeInfoWithStorage[127.0.0.1:37066,DS-e7742fce-d48b-47dc-ad12-07f74cb6ebae,DISK], DatanodeInfoWithStorage[127.0.0.1:36087,DS-b4b79c3d-dfc6-4930-b0ba-1dac70fcd7e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38125,DS-ceb7c2c3-530c-4e89-9bfb-5f22b98b1679,DISK], DatanodeInfoWithStorage[127.0.0.1:46775,DS-4e80628a-43c2-4846-95db-aa30fb71eb98,DISK], DatanodeInfoWithStorage[127.0.0.1:37402,DS-25b0c06e-3dcb-4bd2-be1f-a855b1ab0729,DISK], DatanodeInfoWithStorage[127.0.0.1:36694,DS-590fb1b2-d19d-430b-9ce2-fe26aee96606,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2134597101-172.17.0.10-1596926933730:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45001,DS-a2df47ba-881a-4115-9de4-8b023d29a95b,DISK], DatanodeInfoWithStorage[127.0.0.1:37393,DS-04516753-bfdc-441e-9bc5-27823224a127,DISK], DatanodeInfoWithStorage[127.0.0.1:37066,DS-e7742fce-d48b-47dc-ad12-07f74cb6ebae,DISK], DatanodeInfoWithStorage[127.0.0.1:36087,DS-b4b79c3d-dfc6-4930-b0ba-1dac70fcd7e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38125,DS-ceb7c2c3-530c-4e89-9bfb-5f22b98b1679,DISK], DatanodeInfoWithStorage[127.0.0.1:46775,DS-4e80628a-43c2-4846-95db-aa30fb71eb98,DISK], DatanodeInfoWithStorage[127.0.0.1:37402,DS-25b0c06e-3dcb-4bd2-be1f-a855b1ab0729,DISK], DatanodeInfoWithStorage[127.0.0.1:36694,DS-590fb1b2-d19d-430b-9ce2-fe26aee96606,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-11866172-172.17.0.10-1596927168539:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35956,DS-58794f66-2542-4ea2-bc6b-02460da0e13a,DISK], DatanodeInfoWithStorage[127.0.0.1:39206,DS-1befb4fa-4036-4cdb-91b9-8851945fb706,DISK], DatanodeInfoWithStorage[127.0.0.1:41776,DS-257ab0b7-69d3-4235-8030-4072108502fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39353,DS-f68acb86-2a35-4990-8ff2-0c9b3b8a78ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45551,DS-c69d0a4a-418f-4583-8c34-2c67373e2108,DISK], DatanodeInfoWithStorage[127.0.0.1:36630,DS-a16608d1-b5a1-4a9b-b4fb-66d33506cc42,DISK], DatanodeInfoWithStorage[127.0.0.1:38477,DS-7e2212a0-6cfd-426c-af5b-123623c99b7b,DISK], DatanodeInfoWithStorage[127.0.0.1:36306,DS-d3d34fa8-d269-4db2-b29e-54e576c4b21c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-11866172-172.17.0.10-1596927168539:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35956,DS-58794f66-2542-4ea2-bc6b-02460da0e13a,DISK], DatanodeInfoWithStorage[127.0.0.1:39206,DS-1befb4fa-4036-4cdb-91b9-8851945fb706,DISK], DatanodeInfoWithStorage[127.0.0.1:41776,DS-257ab0b7-69d3-4235-8030-4072108502fb,DISK], DatanodeInfoWithStorage[127.0.0.1:39353,DS-f68acb86-2a35-4990-8ff2-0c9b3b8a78ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45551,DS-c69d0a4a-418f-4583-8c34-2c67373e2108,DISK], DatanodeInfoWithStorage[127.0.0.1:36630,DS-a16608d1-b5a1-4a9b-b4fb-66d33506cc42,DISK], DatanodeInfoWithStorage[127.0.0.1:38477,DS-7e2212a0-6cfd-426c-af5b-123623c99b7b,DISK], DatanodeInfoWithStorage[127.0.0.1:36306,DS-d3d34fa8-d269-4db2-b29e-54e576c4b21c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1542951961-172.17.0.10-1596927251554:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37226,DS-71bf7495-c178-460b-9121-7c847f3a1da6,DISK], DatanodeInfoWithStorage[127.0.0.1:44644,DS-f13e8d69-6636-4347-8a78-3bad64b03684,DISK], DatanodeInfoWithStorage[127.0.0.1:32870,DS-e2a15732-d5be-4915-af3d-3f98c05ca809,DISK], DatanodeInfoWithStorage[127.0.0.1:33380,DS-bc679f1f-5f0f-4eb7-844c-3a4cd7012d7a,DISK], DatanodeInfoWithStorage[127.0.0.1:35236,DS-7cbf8f63-6199-4501-9304-e38d62e62797,DISK], DatanodeInfoWithStorage[127.0.0.1:35597,DS-64ac3463-9383-483b-a6e5-e753324962d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33641,DS-cf313376-7ba4-4213-989a-ef8f75167e52,DISK], DatanodeInfoWithStorage[127.0.0.1:35261,DS-c94884d5-05a9-49f7-91d1-af619a70e33f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1542951961-172.17.0.10-1596927251554:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37226,DS-71bf7495-c178-460b-9121-7c847f3a1da6,DISK], DatanodeInfoWithStorage[127.0.0.1:44644,DS-f13e8d69-6636-4347-8a78-3bad64b03684,DISK], DatanodeInfoWithStorage[127.0.0.1:32870,DS-e2a15732-d5be-4915-af3d-3f98c05ca809,DISK], DatanodeInfoWithStorage[127.0.0.1:33380,DS-bc679f1f-5f0f-4eb7-844c-3a4cd7012d7a,DISK], DatanodeInfoWithStorage[127.0.0.1:35236,DS-7cbf8f63-6199-4501-9304-e38d62e62797,DISK], DatanodeInfoWithStorage[127.0.0.1:35597,DS-64ac3463-9383-483b-a6e5-e753324962d9,DISK], DatanodeInfoWithStorage[127.0.0.1:33641,DS-cf313376-7ba4-4213-989a-ef8f75167e52,DISK], DatanodeInfoWithStorage[127.0.0.1:35261,DS-c94884d5-05a9-49f7-91d1-af619a70e33f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-478658561-172.17.0.10-1596927461027:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33818,DS-7328c9a7-003e-45ae-a9a4-13db862ad777,DISK], DatanodeInfoWithStorage[127.0.0.1:41682,DS-9cf10a74-0766-4edc-87a5-71c2c2b0cf54,DISK], DatanodeInfoWithStorage[127.0.0.1:33763,DS-aa092054-4b56-4ed1-8c79-3d9798cccf06,DISK], DatanodeInfoWithStorage[127.0.0.1:43838,DS-8e028e10-06cc-4f8d-b209-899df4a05db3,DISK], DatanodeInfoWithStorage[127.0.0.1:39561,DS-5ebdade2-d18d-41e7-a47d-6e7bfce965ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36021,DS-6991b947-0450-4b94-add7-5d96728809d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34277,DS-ffbd5135-8f8a-4408-acd2-8c81ddbaffca,DISK], DatanodeInfoWithStorage[127.0.0.1:41718,DS-d5286efa-8092-4833-8a1a-dc16eb513b36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-478658561-172.17.0.10-1596927461027:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33818,DS-7328c9a7-003e-45ae-a9a4-13db862ad777,DISK], DatanodeInfoWithStorage[127.0.0.1:41682,DS-9cf10a74-0766-4edc-87a5-71c2c2b0cf54,DISK], DatanodeInfoWithStorage[127.0.0.1:33763,DS-aa092054-4b56-4ed1-8c79-3d9798cccf06,DISK], DatanodeInfoWithStorage[127.0.0.1:43838,DS-8e028e10-06cc-4f8d-b209-899df4a05db3,DISK], DatanodeInfoWithStorage[127.0.0.1:39561,DS-5ebdade2-d18d-41e7-a47d-6e7bfce965ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36021,DS-6991b947-0450-4b94-add7-5d96728809d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34277,DS-ffbd5135-8f8a-4408-acd2-8c81ddbaffca,DISK], DatanodeInfoWithStorage[127.0.0.1:41718,DS-d5286efa-8092-4833-8a1a-dc16eb513b36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1350345858-172.17.0.10-1596927796966:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36843,DS-44d57bc0-7832-4e91-be35-3b0dea575b04,DISK], DatanodeInfoWithStorage[127.0.0.1:46048,DS-6a0cfc40-6ea1-4b06-8c54-f2cf1714cf67,DISK], DatanodeInfoWithStorage[127.0.0.1:44367,DS-b6599dd3-4122-48f3-b78c-70fdd7e8b8dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37137,DS-7372cbc8-cdbc-4c86-85ef-1b7fe673c7e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33846,DS-41bcb030-e0d5-4f5f-9ff5-b090c5c1e1c7,DISK], DatanodeInfoWithStorage[127.0.0.1:46587,DS-5eb2556d-2435-496a-956a-033effb4b38e,DISK], DatanodeInfoWithStorage[127.0.0.1:46781,DS-91f5c058-6d51-4395-8802-5d61a6fc7897,DISK], DatanodeInfoWithStorage[127.0.0.1:36622,DS-7cd78da3-2cc5-44da-9298-7fb162e9d801,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1350345858-172.17.0.10-1596927796966:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36843,DS-44d57bc0-7832-4e91-be35-3b0dea575b04,DISK], DatanodeInfoWithStorage[127.0.0.1:46048,DS-6a0cfc40-6ea1-4b06-8c54-f2cf1714cf67,DISK], DatanodeInfoWithStorage[127.0.0.1:44367,DS-b6599dd3-4122-48f3-b78c-70fdd7e8b8dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37137,DS-7372cbc8-cdbc-4c86-85ef-1b7fe673c7e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33846,DS-41bcb030-e0d5-4f5f-9ff5-b090c5c1e1c7,DISK], DatanodeInfoWithStorage[127.0.0.1:46587,DS-5eb2556d-2435-496a-956a-033effb4b38e,DISK], DatanodeInfoWithStorage[127.0.0.1:46781,DS-91f5c058-6d51-4395-8802-5d61a6fc7897,DISK], DatanodeInfoWithStorage[127.0.0.1:36622,DS-7cd78da3-2cc5-44da-9298-7fb162e9d801,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-455873287-172.17.0.10-1596928310552:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36430,DS-5a418fda-c12a-46e9-8af0-2e545c54548d,DISK], DatanodeInfoWithStorage[127.0.0.1:35255,DS-08374102-b246-4f39-a5a2-99366a574b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:32858,DS-9262a4d3-c222-4b17-a4af-75fcdf295b26,DISK], DatanodeInfoWithStorage[127.0.0.1:42375,DS-6d2bfecd-c36a-4a43-aefa-a038a9d52f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:36264,DS-411603aa-ec21-43ee-a4a1-4f40174955bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44742,DS-55669964-a28f-416a-93d2-f11d65fe1590,DISK], DatanodeInfoWithStorage[127.0.0.1:46323,DS-17b65009-79cc-4b23-b55f-4e07de9dab42,DISK], DatanodeInfoWithStorage[127.0.0.1:42317,DS-643db12f-c787-4389-b091-ebf782a9846b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-455873287-172.17.0.10-1596928310552:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36430,DS-5a418fda-c12a-46e9-8af0-2e545c54548d,DISK], DatanodeInfoWithStorage[127.0.0.1:35255,DS-08374102-b246-4f39-a5a2-99366a574b7a,DISK], DatanodeInfoWithStorage[127.0.0.1:32858,DS-9262a4d3-c222-4b17-a4af-75fcdf295b26,DISK], DatanodeInfoWithStorage[127.0.0.1:42375,DS-6d2bfecd-c36a-4a43-aefa-a038a9d52f7f,DISK], DatanodeInfoWithStorage[127.0.0.1:36264,DS-411603aa-ec21-43ee-a4a1-4f40174955bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44742,DS-55669964-a28f-416a-93d2-f11d65fe1590,DISK], DatanodeInfoWithStorage[127.0.0.1:46323,DS-17b65009-79cc-4b23-b55f-4e07de9dab42,DISK], DatanodeInfoWithStorage[127.0.0.1:42317,DS-643db12f-c787-4389-b091-ebf782a9846b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-992188885-172.17.0.10-1596928345532:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42071,DS-a6c2c70d-3186-40eb-be4b-719927a6e2f6,DISK], DatanodeInfoWithStorage[127.0.0.1:46393,DS-b1d4296e-cf20-4a4d-848a-57e65222b66e,DISK], DatanodeInfoWithStorage[127.0.0.1:33206,DS-909e56a7-323c-4acc-a2b6-a58fa2bd56c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45477,DS-cd7d1acd-8aae-47ae-b648-67579648e4d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45218,DS-eb4ce478-c4da-47f3-b5f7-e59e55f8a6d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41091,DS-7564a5a1-b00a-47c4-a907-2733eed55ece,DISK], DatanodeInfoWithStorage[127.0.0.1:33893,DS-97560eb2-03d3-422a-8463-b0acaffb2b57,DISK], DatanodeInfoWithStorage[127.0.0.1:41653,DS-74e5cc17-1e9e-4009-88f5-ea185f7f63a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-992188885-172.17.0.10-1596928345532:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42071,DS-a6c2c70d-3186-40eb-be4b-719927a6e2f6,DISK], DatanodeInfoWithStorage[127.0.0.1:46393,DS-b1d4296e-cf20-4a4d-848a-57e65222b66e,DISK], DatanodeInfoWithStorage[127.0.0.1:33206,DS-909e56a7-323c-4acc-a2b6-a58fa2bd56c7,DISK], DatanodeInfoWithStorage[127.0.0.1:45477,DS-cd7d1acd-8aae-47ae-b648-67579648e4d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45218,DS-eb4ce478-c4da-47f3-b5f7-e59e55f8a6d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41091,DS-7564a5a1-b00a-47c4-a907-2733eed55ece,DISK], DatanodeInfoWithStorage[127.0.0.1:33893,DS-97560eb2-03d3-422a-8463-b0acaffb2b57,DISK], DatanodeInfoWithStorage[127.0.0.1:41653,DS-74e5cc17-1e9e-4009-88f5-ea185f7f63a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2130605435-172.17.0.10-1596929170887:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37017,DS-40be12ea-1565-4ef1-b440-cc6664f3b4d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45722,DS-9d091e5a-2326-4bb9-80a5-a124139ac85a,DISK], DatanodeInfoWithStorage[127.0.0.1:43389,DS-99d6cb34-68bc-4f25-b090-630231a309b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39486,DS-4d78928f-fa0c-4586-9381-294542e9c107,DISK], DatanodeInfoWithStorage[127.0.0.1:34191,DS-4a7a67fc-0de2-4b24-a90b-84c1906ae19a,DISK], DatanodeInfoWithStorage[127.0.0.1:41302,DS-03bc6179-a387-4fdd-97df-2d13dd5d9235,DISK], DatanodeInfoWithStorage[127.0.0.1:44287,DS-7d26a846-d36f-4d02-bf47-30a9b77a0786,DISK], DatanodeInfoWithStorage[127.0.0.1:38405,DS-87a2785e-d70d-4595-a5b2-cac31b858de4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2130605435-172.17.0.10-1596929170887:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37017,DS-40be12ea-1565-4ef1-b440-cc6664f3b4d0,DISK], DatanodeInfoWithStorage[127.0.0.1:45722,DS-9d091e5a-2326-4bb9-80a5-a124139ac85a,DISK], DatanodeInfoWithStorage[127.0.0.1:43389,DS-99d6cb34-68bc-4f25-b090-630231a309b5,DISK], DatanodeInfoWithStorage[127.0.0.1:39486,DS-4d78928f-fa0c-4586-9381-294542e9c107,DISK], DatanodeInfoWithStorage[127.0.0.1:34191,DS-4a7a67fc-0de2-4b24-a90b-84c1906ae19a,DISK], DatanodeInfoWithStorage[127.0.0.1:41302,DS-03bc6179-a387-4fdd-97df-2d13dd5d9235,DISK], DatanodeInfoWithStorage[127.0.0.1:44287,DS-7d26a846-d36f-4d02-bf47-30a9b77a0786,DISK], DatanodeInfoWithStorage[127.0.0.1:38405,DS-87a2785e-d70d-4595-a5b2-cac31b858de4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1476053243-172.17.0.10-1596929203163:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38235,DS-6176c1c7-033c-4d06-81fc-b2eef6568346,DISK], DatanodeInfoWithStorage[127.0.0.1:33149,DS-008f2d06-1a27-4c8b-9596-ddf6cb90f23e,DISK], DatanodeInfoWithStorage[127.0.0.1:41072,DS-81d55f2e-6f09-4f15-a805-7900480651b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43175,DS-bf35cf57-0949-4023-b538-c6c9b742d920,DISK], DatanodeInfoWithStorage[127.0.0.1:33225,DS-1f6603c9-4b77-4f83-91cc-73f807829bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:38847,DS-b98a079a-8ac2-4ae6-8845-43b8f70dd4fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40839,DS-018cd270-82db-465d-b903-d5ef7f7154ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40227,DS-e43683c4-ed0a-4fae-894b-ddf34ef1f4f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1476053243-172.17.0.10-1596929203163:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38235,DS-6176c1c7-033c-4d06-81fc-b2eef6568346,DISK], DatanodeInfoWithStorage[127.0.0.1:33149,DS-008f2d06-1a27-4c8b-9596-ddf6cb90f23e,DISK], DatanodeInfoWithStorage[127.0.0.1:41072,DS-81d55f2e-6f09-4f15-a805-7900480651b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43175,DS-bf35cf57-0949-4023-b538-c6c9b742d920,DISK], DatanodeInfoWithStorage[127.0.0.1:33225,DS-1f6603c9-4b77-4f83-91cc-73f807829bbd,DISK], DatanodeInfoWithStorage[127.0.0.1:38847,DS-b98a079a-8ac2-4ae6-8845-43b8f70dd4fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40839,DS-018cd270-82db-465d-b903-d5ef7f7154ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40227,DS-e43683c4-ed0a-4fae-894b-ddf34ef1f4f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-667774296-172.17.0.10-1596929444082:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42431,DS-3cc40a3c-8ce0-4e8b-ac50-e09f1123caa2,DISK], DatanodeInfoWithStorage[127.0.0.1:46658,DS-f25f418b-b99d-4b5e-ae30-463f281fe352,DISK], DatanodeInfoWithStorage[127.0.0.1:39589,DS-1e13ac9c-af45-42ad-9329-8a8dae07577b,DISK], DatanodeInfoWithStorage[127.0.0.1:35836,DS-777766fa-7285-4e79-acf6-1dd2c6007f83,DISK], DatanodeInfoWithStorage[127.0.0.1:36481,DS-4c5b38f9-55c2-4bb1-9788-985b69803aa6,DISK], DatanodeInfoWithStorage[127.0.0.1:39868,DS-93ca9989-b573-4194-b1f4-2ee1ae5fbb76,DISK], DatanodeInfoWithStorage[127.0.0.1:41640,DS-f0363779-f3bc-4224-bf54-bc1c4e120e92,DISK], DatanodeInfoWithStorage[127.0.0.1:40395,DS-37035dba-4e06-43ee-95e6-d6f577b21987,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-667774296-172.17.0.10-1596929444082:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42431,DS-3cc40a3c-8ce0-4e8b-ac50-e09f1123caa2,DISK], DatanodeInfoWithStorage[127.0.0.1:46658,DS-f25f418b-b99d-4b5e-ae30-463f281fe352,DISK], DatanodeInfoWithStorage[127.0.0.1:39589,DS-1e13ac9c-af45-42ad-9329-8a8dae07577b,DISK], DatanodeInfoWithStorage[127.0.0.1:35836,DS-777766fa-7285-4e79-acf6-1dd2c6007f83,DISK], DatanodeInfoWithStorage[127.0.0.1:36481,DS-4c5b38f9-55c2-4bb1-9788-985b69803aa6,DISK], DatanodeInfoWithStorage[127.0.0.1:39868,DS-93ca9989-b573-4194-b1f4-2ee1ae5fbb76,DISK], DatanodeInfoWithStorage[127.0.0.1:41640,DS-f0363779-f3bc-4224-bf54-bc1c4e120e92,DISK], DatanodeInfoWithStorage[127.0.0.1:40395,DS-37035dba-4e06-43ee-95e6-d6f577b21987,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-776652427-172.17.0.10-1596930324365:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37994,DS-1d7ccc7c-4db1-47cd-8da0-8ded675d1af5,DISK], DatanodeInfoWithStorage[127.0.0.1:37998,DS-517d4174-fae5-4dd3-a3d2-1de712aa18b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41694,DS-9c8e58eb-cf9a-4d36-9a1c-7ed666ed4ddc,DISK], DatanodeInfoWithStorage[127.0.0.1:43747,DS-18829710-4d77-4e63-a3a8-06c6acedf881,DISK], DatanodeInfoWithStorage[127.0.0.1:37308,DS-f8e9313b-6c1b-4b81-8d0c-5521eb4a706b,DISK], DatanodeInfoWithStorage[127.0.0.1:39480,DS-80ba5ef3-65d1-4340-a4c4-09f6c18fb5a1,DISK], DatanodeInfoWithStorage[127.0.0.1:40529,DS-98870af9-97fa-48a3-a956-750f833dd778,DISK], DatanodeInfoWithStorage[127.0.0.1:42780,DS-883847c3-a9c4-4b41-8e28-b52c1450c85b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-776652427-172.17.0.10-1596930324365:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37994,DS-1d7ccc7c-4db1-47cd-8da0-8ded675d1af5,DISK], DatanodeInfoWithStorage[127.0.0.1:37998,DS-517d4174-fae5-4dd3-a3d2-1de712aa18b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41694,DS-9c8e58eb-cf9a-4d36-9a1c-7ed666ed4ddc,DISK], DatanodeInfoWithStorage[127.0.0.1:43747,DS-18829710-4d77-4e63-a3a8-06c6acedf881,DISK], DatanodeInfoWithStorage[127.0.0.1:37308,DS-f8e9313b-6c1b-4b81-8d0c-5521eb4a706b,DISK], DatanodeInfoWithStorage[127.0.0.1:39480,DS-80ba5ef3-65d1-4340-a4c4-09f6c18fb5a1,DISK], DatanodeInfoWithStorage[127.0.0.1:40529,DS-98870af9-97fa-48a3-a956-750f833dd778,DISK], DatanodeInfoWithStorage[127.0.0.1:42780,DS-883847c3-a9c4-4b41-8e28-b52c1450c85b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1115794632-172.17.0.10-1596930724804:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42134,DS-9f1d96b1-155e-4e16-bc1d-c76fee9b8b12,DISK], DatanodeInfoWithStorage[127.0.0.1:46128,DS-5f0ca7c4-2bdc-4d20-95a4-0e25a763856c,DISK], DatanodeInfoWithStorage[127.0.0.1:39647,DS-2db22ef9-8ea4-4ef1-9513-07cc31d15024,DISK], DatanodeInfoWithStorage[127.0.0.1:36125,DS-e96d40f9-224c-47df-8b2d-c9f7e53a9528,DISK], DatanodeInfoWithStorage[127.0.0.1:43634,DS-ca9fe223-739d-4a8f-a713-3688e5b43133,DISK], DatanodeInfoWithStorage[127.0.0.1:43052,DS-7ad25943-2a2f-4ff0-889c-47e34783b735,DISK], DatanodeInfoWithStorage[127.0.0.1:38730,DS-58b5a612-b73f-4095-8dc9-30609a7bc184,DISK], DatanodeInfoWithStorage[127.0.0.1:42675,DS-09791616-227e-418d-987e-b335013fe0bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1115794632-172.17.0.10-1596930724804:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42134,DS-9f1d96b1-155e-4e16-bc1d-c76fee9b8b12,DISK], DatanodeInfoWithStorage[127.0.0.1:46128,DS-5f0ca7c4-2bdc-4d20-95a4-0e25a763856c,DISK], DatanodeInfoWithStorage[127.0.0.1:39647,DS-2db22ef9-8ea4-4ef1-9513-07cc31d15024,DISK], DatanodeInfoWithStorage[127.0.0.1:36125,DS-e96d40f9-224c-47df-8b2d-c9f7e53a9528,DISK], DatanodeInfoWithStorage[127.0.0.1:43634,DS-ca9fe223-739d-4a8f-a713-3688e5b43133,DISK], DatanodeInfoWithStorage[127.0.0.1:43052,DS-7ad25943-2a2f-4ff0-889c-47e34783b735,DISK], DatanodeInfoWithStorage[127.0.0.1:38730,DS-58b5a612-b73f-4095-8dc9-30609a7bc184,DISK], DatanodeInfoWithStorage[127.0.0.1:42675,DS-09791616-227e-418d-987e-b335013fe0bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1756699348-172.17.0.10-1596930971923:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33242,DS-ac89b808-df52-4015-8ea5-c4b730fe0676,DISK], DatanodeInfoWithStorage[127.0.0.1:43740,DS-f4fe1c94-3d5d-4c08-9ee7-8919a97eeed7,DISK], DatanodeInfoWithStorage[127.0.0.1:41487,DS-ba9aecc3-a749-48dd-9b73-491bbc87ad36,DISK], DatanodeInfoWithStorage[127.0.0.1:44451,DS-7f6672c0-b13b-4370-a96d-e371d7cc8f45,DISK], DatanodeInfoWithStorage[127.0.0.1:37758,DS-ea90c7bc-b26d-44fa-a728-da0703778c40,DISK], DatanodeInfoWithStorage[127.0.0.1:40700,DS-a1389382-36f1-43e4-ad4b-28569832ecaa,DISK], DatanodeInfoWithStorage[127.0.0.1:38256,DS-b5989c97-313d-4262-ade4-9402a96840cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39291,DS-cf53d781-fb77-4222-a99f-0f0592923e2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1756699348-172.17.0.10-1596930971923:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33242,DS-ac89b808-df52-4015-8ea5-c4b730fe0676,DISK], DatanodeInfoWithStorage[127.0.0.1:43740,DS-f4fe1c94-3d5d-4c08-9ee7-8919a97eeed7,DISK], DatanodeInfoWithStorage[127.0.0.1:41487,DS-ba9aecc3-a749-48dd-9b73-491bbc87ad36,DISK], DatanodeInfoWithStorage[127.0.0.1:44451,DS-7f6672c0-b13b-4370-a96d-e371d7cc8f45,DISK], DatanodeInfoWithStorage[127.0.0.1:37758,DS-ea90c7bc-b26d-44fa-a728-da0703778c40,DISK], DatanodeInfoWithStorage[127.0.0.1:40700,DS-a1389382-36f1-43e4-ad4b-28569832ecaa,DISK], DatanodeInfoWithStorage[127.0.0.1:38256,DS-b5989c97-313d-4262-ade4-9402a96840cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39291,DS-cf53d781-fb77-4222-a99f-0f0592923e2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-635328066-172.17.0.10-1596931043131:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45024,DS-6b47e815-9bab-4269-bd2e-6559281d8c8d,DISK], DatanodeInfoWithStorage[127.0.0.1:34736,DS-106be5fd-9d99-463d-8492-f6d1cc3f9e81,DISK], DatanodeInfoWithStorage[127.0.0.1:43089,DS-66b010ad-9921-482a-b182-a71a735fef24,DISK], DatanodeInfoWithStorage[127.0.0.1:37765,DS-4540b093-ca8e-4e91-90af-4a1a4ce29a7b,DISK], DatanodeInfoWithStorage[127.0.0.1:39954,DS-be5ba09e-e75b-4dd2-8f16-41937d0facee,DISK], DatanodeInfoWithStorage[127.0.0.1:41581,DS-8a6f2f44-07df-49ca-b4f3-52f8f2d09762,DISK], DatanodeInfoWithStorage[127.0.0.1:34306,DS-343a8752-2db6-469c-ba37-a7eda2229af2,DISK], DatanodeInfoWithStorage[127.0.0.1:42243,DS-ebb67b00-3120-4389-8517-0c8e86b7089b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-635328066-172.17.0.10-1596931043131:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45024,DS-6b47e815-9bab-4269-bd2e-6559281d8c8d,DISK], DatanodeInfoWithStorage[127.0.0.1:34736,DS-106be5fd-9d99-463d-8492-f6d1cc3f9e81,DISK], DatanodeInfoWithStorage[127.0.0.1:43089,DS-66b010ad-9921-482a-b182-a71a735fef24,DISK], DatanodeInfoWithStorage[127.0.0.1:37765,DS-4540b093-ca8e-4e91-90af-4a1a4ce29a7b,DISK], DatanodeInfoWithStorage[127.0.0.1:39954,DS-be5ba09e-e75b-4dd2-8f16-41937d0facee,DISK], DatanodeInfoWithStorage[127.0.0.1:41581,DS-8a6f2f44-07df-49ca-b4f3-52f8f2d09762,DISK], DatanodeInfoWithStorage[127.0.0.1:34306,DS-343a8752-2db6-469c-ba37-a7eda2229af2,DISK], DatanodeInfoWithStorage[127.0.0.1:42243,DS-ebb67b00-3120-4389-8517-0c8e86b7089b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-503511892-172.17.0.10-1596931231532:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36144,DS-9663521c-9dad-4733-98f6-5149a9de89f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34895,DS-85149fea-810e-4252-8ed5-17f1edc5d917,DISK], DatanodeInfoWithStorage[127.0.0.1:35682,DS-42afe3fc-5586-4e1e-8d20-6ef6fb8a0a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:46805,DS-e99122aa-1b60-465e-acf0-2aba1de0a8a6,DISK], DatanodeInfoWithStorage[127.0.0.1:46708,DS-0ff1248e-0a34-46c5-8744-12728f5c73dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38662,DS-fddc4696-4642-480f-9f65-92093168f2b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33915,DS-56f26797-9f21-4f6e-9619-500c4e01ffcb,DISK], DatanodeInfoWithStorage[127.0.0.1:38424,DS-9582acbc-f4c2-45a5-ad6c-119752f59419,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-503511892-172.17.0.10-1596931231532:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36144,DS-9663521c-9dad-4733-98f6-5149a9de89f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34895,DS-85149fea-810e-4252-8ed5-17f1edc5d917,DISK], DatanodeInfoWithStorage[127.0.0.1:35682,DS-42afe3fc-5586-4e1e-8d20-6ef6fb8a0a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:46805,DS-e99122aa-1b60-465e-acf0-2aba1de0a8a6,DISK], DatanodeInfoWithStorage[127.0.0.1:46708,DS-0ff1248e-0a34-46c5-8744-12728f5c73dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38662,DS-fddc4696-4642-480f-9f65-92093168f2b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33915,DS-56f26797-9f21-4f6e-9619-500c4e01ffcb,DISK], DatanodeInfoWithStorage[127.0.0.1:38424,DS-9582acbc-f4c2-45a5-ad6c-119752f59419,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5442
