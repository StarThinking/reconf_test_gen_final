reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1086191878-172.17.0.10-1596980900626:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37122,DS-0f3e356a-7c52-4574-83e2-c94cdc4aa6a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37992,DS-5c195913-6e1b-4c23-bdc0-3b648e694066,DISK], DatanodeInfoWithStorage[127.0.0.1:32849,DS-7ab7a5c5-169e-4870-bce5-0ddb867cf3d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39703,DS-2aba8d1c-ee9d-46c3-a400-e50c7f4e9c0f,DISK], DatanodeInfoWithStorage[127.0.0.1:39832,DS-ee1de2d8-ca84-4717-926c-a0989c3891b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38021,DS-b62542e3-4f3a-4505-b6f7-82f8e6f21ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:40866,DS-569162cc-f9e4-48ae-a9f9-8f35bf357f97,DISK], DatanodeInfoWithStorage[127.0.0.1:44826,DS-60aae9f3-8545-433e-9d2f-69c04ead6036,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1086191878-172.17.0.10-1596980900626:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37122,DS-0f3e356a-7c52-4574-83e2-c94cdc4aa6a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37992,DS-5c195913-6e1b-4c23-bdc0-3b648e694066,DISK], DatanodeInfoWithStorage[127.0.0.1:32849,DS-7ab7a5c5-169e-4870-bce5-0ddb867cf3d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39703,DS-2aba8d1c-ee9d-46c3-a400-e50c7f4e9c0f,DISK], DatanodeInfoWithStorage[127.0.0.1:39832,DS-ee1de2d8-ca84-4717-926c-a0989c3891b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38021,DS-b62542e3-4f3a-4505-b6f7-82f8e6f21ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:40866,DS-569162cc-f9e4-48ae-a9f9-8f35bf357f97,DISK], DatanodeInfoWithStorage[127.0.0.1:44826,DS-60aae9f3-8545-433e-9d2f-69c04ead6036,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2118889390-172.17.0.10-1596981033637:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33016,DS-3781ab26-6977-4831-b879-57d56d4a3f07,DISK], DatanodeInfoWithStorage[127.0.0.1:44003,DS-0945de4e-55a6-49f7-aa91-4d0e32cab868,DISK], DatanodeInfoWithStorage[127.0.0.1:42636,DS-81382fc5-a857-4110-b59c-2bddf514ad5c,DISK], DatanodeInfoWithStorage[127.0.0.1:37006,DS-a0891f45-9e8a-4875-96c2-92edb7f52014,DISK], DatanodeInfoWithStorage[127.0.0.1:44254,DS-3826256d-ce64-4289-a788-b9306f34ca40,DISK], DatanodeInfoWithStorage[127.0.0.1:40304,DS-da94ad18-eb0a-4b37-9b0c-e723123e3454,DISK], DatanodeInfoWithStorage[127.0.0.1:44767,DS-93698c33-1bab-496f-8152-1fe098803b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:41084,DS-85cf6715-b192-4b39-92e3-b1dd4cf4682b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2118889390-172.17.0.10-1596981033637:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33016,DS-3781ab26-6977-4831-b879-57d56d4a3f07,DISK], DatanodeInfoWithStorage[127.0.0.1:44003,DS-0945de4e-55a6-49f7-aa91-4d0e32cab868,DISK], DatanodeInfoWithStorage[127.0.0.1:42636,DS-81382fc5-a857-4110-b59c-2bddf514ad5c,DISK], DatanodeInfoWithStorage[127.0.0.1:37006,DS-a0891f45-9e8a-4875-96c2-92edb7f52014,DISK], DatanodeInfoWithStorage[127.0.0.1:44254,DS-3826256d-ce64-4289-a788-b9306f34ca40,DISK], DatanodeInfoWithStorage[127.0.0.1:40304,DS-da94ad18-eb0a-4b37-9b0c-e723123e3454,DISK], DatanodeInfoWithStorage[127.0.0.1:44767,DS-93698c33-1bab-496f-8152-1fe098803b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:41084,DS-85cf6715-b192-4b39-92e3-b1dd4cf4682b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-980777736-172.17.0.10-1596981165942:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41777,DS-ec4fb480-0971-4022-9cb5-c2a0a3bccd0e,DISK], DatanodeInfoWithStorage[127.0.0.1:46072,DS-3af63f24-fa9d-4e6b-bdb5-0c565608cfe6,DISK], DatanodeInfoWithStorage[127.0.0.1:40463,DS-b7107577-e2e6-4a0e-8d52-89f83a1f8d10,DISK], DatanodeInfoWithStorage[127.0.0.1:35750,DS-bf69b3e8-f40d-4c07-ab04-49f505bd6978,DISK], DatanodeInfoWithStorage[127.0.0.1:42956,DS-71a14f86-10f8-4a93-91b5-f6ae08d51960,DISK], DatanodeInfoWithStorage[127.0.0.1:42404,DS-4f417981-1091-471a-bac0-fe58d19fafe9,DISK], DatanodeInfoWithStorage[127.0.0.1:41772,DS-ec7bbd6e-dda5-4b40-a06c-59d04d1f4e71,DISK], DatanodeInfoWithStorage[127.0.0.1:43668,DS-d8fe92c9-2aa4-4f04-99c6-8aa8f34e0a23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-980777736-172.17.0.10-1596981165942:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41777,DS-ec4fb480-0971-4022-9cb5-c2a0a3bccd0e,DISK], DatanodeInfoWithStorage[127.0.0.1:46072,DS-3af63f24-fa9d-4e6b-bdb5-0c565608cfe6,DISK], DatanodeInfoWithStorage[127.0.0.1:40463,DS-b7107577-e2e6-4a0e-8d52-89f83a1f8d10,DISK], DatanodeInfoWithStorage[127.0.0.1:35750,DS-bf69b3e8-f40d-4c07-ab04-49f505bd6978,DISK], DatanodeInfoWithStorage[127.0.0.1:42956,DS-71a14f86-10f8-4a93-91b5-f6ae08d51960,DISK], DatanodeInfoWithStorage[127.0.0.1:42404,DS-4f417981-1091-471a-bac0-fe58d19fafe9,DISK], DatanodeInfoWithStorage[127.0.0.1:41772,DS-ec7bbd6e-dda5-4b40-a06c-59d04d1f4e71,DISK], DatanodeInfoWithStorage[127.0.0.1:43668,DS-d8fe92c9-2aa4-4f04-99c6-8aa8f34e0a23,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-102393747-172.17.0.10-1596981198199:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37309,DS-40489060-6197-4a95-8bf8-b642eba2e354,DISK], DatanodeInfoWithStorage[127.0.0.1:32920,DS-ef627fce-2616-4b30-b30d-c7bb5ad8f348,DISK], DatanodeInfoWithStorage[127.0.0.1:37094,DS-bf15e579-74c7-4094-a026-72b859ed8b63,DISK], DatanodeInfoWithStorage[127.0.0.1:44870,DS-0c0d7dd9-3337-43aa-95c4-ebdb19c6d49a,DISK], DatanodeInfoWithStorage[127.0.0.1:42694,DS-03104ebd-debd-476f-bbc3-1cd252cfe8fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36824,DS-68124ab8-496e-49a7-a65b-015bce33ff0f,DISK], DatanodeInfoWithStorage[127.0.0.1:33546,DS-c90a82e0-357b-44d7-acda-2c9c00acbaf4,DISK], DatanodeInfoWithStorage[127.0.0.1:43235,DS-2eb41338-a671-4732-af5e-4fa058bc4e97,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-102393747-172.17.0.10-1596981198199:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37309,DS-40489060-6197-4a95-8bf8-b642eba2e354,DISK], DatanodeInfoWithStorage[127.0.0.1:32920,DS-ef627fce-2616-4b30-b30d-c7bb5ad8f348,DISK], DatanodeInfoWithStorage[127.0.0.1:37094,DS-bf15e579-74c7-4094-a026-72b859ed8b63,DISK], DatanodeInfoWithStorage[127.0.0.1:44870,DS-0c0d7dd9-3337-43aa-95c4-ebdb19c6d49a,DISK], DatanodeInfoWithStorage[127.0.0.1:42694,DS-03104ebd-debd-476f-bbc3-1cd252cfe8fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36824,DS-68124ab8-496e-49a7-a65b-015bce33ff0f,DISK], DatanodeInfoWithStorage[127.0.0.1:33546,DS-c90a82e0-357b-44d7-acda-2c9c00acbaf4,DISK], DatanodeInfoWithStorage[127.0.0.1:43235,DS-2eb41338-a671-4732-af5e-4fa058bc4e97,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1978805125-172.17.0.10-1596981234166:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40623,DS-529fd570-8cc3-4a75-857e-1946ed159f29,DISK], DatanodeInfoWithStorage[127.0.0.1:41680,DS-6eb9fb47-92a7-423f-8c45-f64fa2219d50,DISK], DatanodeInfoWithStorage[127.0.0.1:41917,DS-11b93449-baf5-42d4-849a-71a7cc8d4f7a,DISK], DatanodeInfoWithStorage[127.0.0.1:37402,DS-ba72318f-ac4d-48b3-b306-9238ee4149b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36604,DS-4a5a2078-5aa4-4be2-ba49-e4343113a743,DISK], DatanodeInfoWithStorage[127.0.0.1:35907,DS-71c24b36-1b41-4e7b-a32c-057d2e8b549d,DISK], DatanodeInfoWithStorage[127.0.0.1:38562,DS-bad5a98e-089c-438c-b312-fad4df62550d,DISK], DatanodeInfoWithStorage[127.0.0.1:36508,DS-2d2b1198-6d89-4e98-a0d9-feddc0e5131a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1978805125-172.17.0.10-1596981234166:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40623,DS-529fd570-8cc3-4a75-857e-1946ed159f29,DISK], DatanodeInfoWithStorage[127.0.0.1:41680,DS-6eb9fb47-92a7-423f-8c45-f64fa2219d50,DISK], DatanodeInfoWithStorage[127.0.0.1:41917,DS-11b93449-baf5-42d4-849a-71a7cc8d4f7a,DISK], DatanodeInfoWithStorage[127.0.0.1:37402,DS-ba72318f-ac4d-48b3-b306-9238ee4149b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36604,DS-4a5a2078-5aa4-4be2-ba49-e4343113a743,DISK], DatanodeInfoWithStorage[127.0.0.1:35907,DS-71c24b36-1b41-4e7b-a32c-057d2e8b549d,DISK], DatanodeInfoWithStorage[127.0.0.1:38562,DS-bad5a98e-089c-438c-b312-fad4df62550d,DISK], DatanodeInfoWithStorage[127.0.0.1:36508,DS-2d2b1198-6d89-4e98-a0d9-feddc0e5131a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-629539031-172.17.0.10-1596981321456:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34283,DS-d741c420-c327-4b88-8b62-a3cc16109b30,DISK], DatanodeInfoWithStorage[127.0.0.1:40789,DS-8fa69e1b-2046-4d9d-8e55-440a758201bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44151,DS-5deb2d16-a38c-4311-ab45-da5b367549ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38379,DS-251ba857-c0fa-4d01-911f-29d1c512d8a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46506,DS-d7f195f8-826b-4215-947b-9d1c3a6a73fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42159,DS-9f9af3f0-d59f-464b-82fa-0f841007bc6f,DISK], DatanodeInfoWithStorage[127.0.0.1:33823,DS-2bd8d82f-4b8c-4290-b3d5-903fe31d6b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:36900,DS-7e8095eb-3cca-464e-a6b9-0eaa914e5e21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-629539031-172.17.0.10-1596981321456:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34283,DS-d741c420-c327-4b88-8b62-a3cc16109b30,DISK], DatanodeInfoWithStorage[127.0.0.1:40789,DS-8fa69e1b-2046-4d9d-8e55-440a758201bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44151,DS-5deb2d16-a38c-4311-ab45-da5b367549ac,DISK], DatanodeInfoWithStorage[127.0.0.1:38379,DS-251ba857-c0fa-4d01-911f-29d1c512d8a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46506,DS-d7f195f8-826b-4215-947b-9d1c3a6a73fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42159,DS-9f9af3f0-d59f-464b-82fa-0f841007bc6f,DISK], DatanodeInfoWithStorage[127.0.0.1:33823,DS-2bd8d82f-4b8c-4290-b3d5-903fe31d6b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:36900,DS-7e8095eb-3cca-464e-a6b9-0eaa914e5e21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1080049506-172.17.0.10-1596981895917:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42980,DS-06504b08-585b-4be9-b957-8e87e87a7acc,DISK], DatanodeInfoWithStorage[127.0.0.1:39195,DS-7a61bd0f-9c48-4d4f-8b9f-0d7e859d0f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:33720,DS-7fd8d7c3-a2df-4609-a6be-9fe138435467,DISK], DatanodeInfoWithStorage[127.0.0.1:43739,DS-cb40e8f3-3e41-4766-9ae8-cc1fac01759b,DISK], DatanodeInfoWithStorage[127.0.0.1:44121,DS-5bc2d69c-0d17-4bf9-b6bc-bc087e09e8f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33004,DS-148dc5c9-2deb-4fb5-8869-f8aea1338409,DISK], DatanodeInfoWithStorage[127.0.0.1:44782,DS-16110113-234c-4458-b49b-4d951107ff49,DISK], DatanodeInfoWithStorage[127.0.0.1:33803,DS-966932a7-1aa6-4237-9d5e-c0fce0dc0ff4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1080049506-172.17.0.10-1596981895917:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42980,DS-06504b08-585b-4be9-b957-8e87e87a7acc,DISK], DatanodeInfoWithStorage[127.0.0.1:39195,DS-7a61bd0f-9c48-4d4f-8b9f-0d7e859d0f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:33720,DS-7fd8d7c3-a2df-4609-a6be-9fe138435467,DISK], DatanodeInfoWithStorage[127.0.0.1:43739,DS-cb40e8f3-3e41-4766-9ae8-cc1fac01759b,DISK], DatanodeInfoWithStorage[127.0.0.1:44121,DS-5bc2d69c-0d17-4bf9-b6bc-bc087e09e8f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33004,DS-148dc5c9-2deb-4fb5-8869-f8aea1338409,DISK], DatanodeInfoWithStorage[127.0.0.1:44782,DS-16110113-234c-4458-b49b-4d951107ff49,DISK], DatanodeInfoWithStorage[127.0.0.1:33803,DS-966932a7-1aa6-4237-9d5e-c0fce0dc0ff4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-359541685-172.17.0.10-1596982236345:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45820,DS-369ab8a8-66be-4528-b3a1-f9165a5ec5df,DISK], DatanodeInfoWithStorage[127.0.0.1:35515,DS-2605cd89-46a8-407f-96ee-d9c7f73b0755,DISK], DatanodeInfoWithStorage[127.0.0.1:44732,DS-b61b89d9-8b5b-47af-8bf3-48a1850191bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37467,DS-907836f3-5a61-43ff-9474-973a406644f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35330,DS-2081a170-f8c1-4198-ac5f-12ba37ebffa3,DISK], DatanodeInfoWithStorage[127.0.0.1:35497,DS-c88c421f-ebc2-459c-a0ac-57cee887237e,DISK], DatanodeInfoWithStorage[127.0.0.1:35825,DS-6cac3596-a3de-4480-b7e2-ad78065124a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33056,DS-0057faa9-3ee1-49ab-9d4f-59054724ca8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-359541685-172.17.0.10-1596982236345:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45820,DS-369ab8a8-66be-4528-b3a1-f9165a5ec5df,DISK], DatanodeInfoWithStorage[127.0.0.1:35515,DS-2605cd89-46a8-407f-96ee-d9c7f73b0755,DISK], DatanodeInfoWithStorage[127.0.0.1:44732,DS-b61b89d9-8b5b-47af-8bf3-48a1850191bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37467,DS-907836f3-5a61-43ff-9474-973a406644f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35330,DS-2081a170-f8c1-4198-ac5f-12ba37ebffa3,DISK], DatanodeInfoWithStorage[127.0.0.1:35497,DS-c88c421f-ebc2-459c-a0ac-57cee887237e,DISK], DatanodeInfoWithStorage[127.0.0.1:35825,DS-6cac3596-a3de-4480-b7e2-ad78065124a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33056,DS-0057faa9-3ee1-49ab-9d4f-59054724ca8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2008331800-172.17.0.10-1596982794122:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37843,DS-4c96e5a7-3b08-47ac-9058-0e5af0621165,DISK], DatanodeInfoWithStorage[127.0.0.1:38149,DS-19b950f0-176a-4208-a9ec-14162fc8f56b,DISK], DatanodeInfoWithStorage[127.0.0.1:39473,DS-c2cc4cca-7fbe-40f8-b2d1-6efb0ec2e139,DISK], DatanodeInfoWithStorage[127.0.0.1:41112,DS-326457b7-db30-4a1f-aa18-c3eb57ac29a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38871,DS-2ebafffb-ad2a-4c9a-b5ff-7c4f9fb6324a,DISK], DatanodeInfoWithStorage[127.0.0.1:45805,DS-a5421858-c7a9-4cb0-90b2-3c174a371e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:35489,DS-38739e7c-0f16-4922-a2f6-7fef4aad79e8,DISK], DatanodeInfoWithStorage[127.0.0.1:44003,DS-2a7628d3-43d0-485b-b68c-2591302fb8c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2008331800-172.17.0.10-1596982794122:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37843,DS-4c96e5a7-3b08-47ac-9058-0e5af0621165,DISK], DatanodeInfoWithStorage[127.0.0.1:38149,DS-19b950f0-176a-4208-a9ec-14162fc8f56b,DISK], DatanodeInfoWithStorage[127.0.0.1:39473,DS-c2cc4cca-7fbe-40f8-b2d1-6efb0ec2e139,DISK], DatanodeInfoWithStorage[127.0.0.1:41112,DS-326457b7-db30-4a1f-aa18-c3eb57ac29a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38871,DS-2ebafffb-ad2a-4c9a-b5ff-7c4f9fb6324a,DISK], DatanodeInfoWithStorage[127.0.0.1:45805,DS-a5421858-c7a9-4cb0-90b2-3c174a371e6f,DISK], DatanodeInfoWithStorage[127.0.0.1:35489,DS-38739e7c-0f16-4922-a2f6-7fef4aad79e8,DISK], DatanodeInfoWithStorage[127.0.0.1:44003,DS-2a7628d3-43d0-485b-b68c-2591302fb8c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-315420430-172.17.0.10-1596983027696:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45712,DS-1eef179b-2c0e-4280-875e-95f27d6c623f,DISK], DatanodeInfoWithStorage[127.0.0.1:39746,DS-bd225380-334b-4dbd-8e5b-94d75bc33eee,DISK], DatanodeInfoWithStorage[127.0.0.1:42552,DS-349fb171-b710-4632-a6a0-5ca1e251abf5,DISK], DatanodeInfoWithStorage[127.0.0.1:34054,DS-37f223aa-9a4b-4804-a61f-daf9d4bf69ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41591,DS-8df4dbea-9e7b-4de7-8fdc-2964b644bf94,DISK], DatanodeInfoWithStorage[127.0.0.1:37175,DS-a06ef081-6117-47b1-ab84-1cb8a7e8c007,DISK], DatanodeInfoWithStorage[127.0.0.1:37779,DS-17429c70-8212-471d-bfec-45c0bbb11149,DISK], DatanodeInfoWithStorage[127.0.0.1:42431,DS-87e4bf1f-a7b6-44cf-9cfb-a9247927e6c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-315420430-172.17.0.10-1596983027696:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45712,DS-1eef179b-2c0e-4280-875e-95f27d6c623f,DISK], DatanodeInfoWithStorage[127.0.0.1:39746,DS-bd225380-334b-4dbd-8e5b-94d75bc33eee,DISK], DatanodeInfoWithStorage[127.0.0.1:42552,DS-349fb171-b710-4632-a6a0-5ca1e251abf5,DISK], DatanodeInfoWithStorage[127.0.0.1:34054,DS-37f223aa-9a4b-4804-a61f-daf9d4bf69ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41591,DS-8df4dbea-9e7b-4de7-8fdc-2964b644bf94,DISK], DatanodeInfoWithStorage[127.0.0.1:37175,DS-a06ef081-6117-47b1-ab84-1cb8a7e8c007,DISK], DatanodeInfoWithStorage[127.0.0.1:37779,DS-17429c70-8212-471d-bfec-45c0bbb11149,DISK], DatanodeInfoWithStorage[127.0.0.1:42431,DS-87e4bf1f-a7b6-44cf-9cfb-a9247927e6c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-524156554-172.17.0.10-1596983094106:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42562,DS-c788c690-17e3-445f-bffe-c240a391aed9,DISK], DatanodeInfoWithStorage[127.0.0.1:46772,DS-c75b3a4a-11bb-4c98-938c-83376c9f4d85,DISK], DatanodeInfoWithStorage[127.0.0.1:36751,DS-ec9115a6-b0e2-49fd-89f4-bc665228746f,DISK], DatanodeInfoWithStorage[127.0.0.1:37729,DS-e84a0870-fc79-4adf-9275-e2d808701090,DISK], DatanodeInfoWithStorage[127.0.0.1:32860,DS-f1de7be9-0f3e-493d-b439-77fe27a357f7,DISK], DatanodeInfoWithStorage[127.0.0.1:43475,DS-0fb5aef7-7924-42f4-9760-e6fcd9ee8537,DISK], DatanodeInfoWithStorage[127.0.0.1:46222,DS-a001dd34-2264-4a1c-a02d-aca815d8a7ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46039,DS-289d461c-b88c-4f16-bbf2-5f2a1c7f425b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-524156554-172.17.0.10-1596983094106:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42562,DS-c788c690-17e3-445f-bffe-c240a391aed9,DISK], DatanodeInfoWithStorage[127.0.0.1:46772,DS-c75b3a4a-11bb-4c98-938c-83376c9f4d85,DISK], DatanodeInfoWithStorage[127.0.0.1:36751,DS-ec9115a6-b0e2-49fd-89f4-bc665228746f,DISK], DatanodeInfoWithStorage[127.0.0.1:37729,DS-e84a0870-fc79-4adf-9275-e2d808701090,DISK], DatanodeInfoWithStorage[127.0.0.1:32860,DS-f1de7be9-0f3e-493d-b439-77fe27a357f7,DISK], DatanodeInfoWithStorage[127.0.0.1:43475,DS-0fb5aef7-7924-42f4-9760-e6fcd9ee8537,DISK], DatanodeInfoWithStorage[127.0.0.1:46222,DS-a001dd34-2264-4a1c-a02d-aca815d8a7ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46039,DS-289d461c-b88c-4f16-bbf2-5f2a1c7f425b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1394292596-172.17.0.10-1596983377105:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41940,DS-54754df8-a816-4ff4-9a74-e9c87ed5137b,DISK], DatanodeInfoWithStorage[127.0.0.1:38040,DS-110e0cba-f862-4a2e-80a7-a2689945982f,DISK], DatanodeInfoWithStorage[127.0.0.1:43081,DS-4547e0b7-b67b-4457-a276-18cb964eb6b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36216,DS-93f27cf7-9632-40cc-b17b-5de3dad0170a,DISK], DatanodeInfoWithStorage[127.0.0.1:41421,DS-7221c684-aaf4-4177-9c9a-8cdf79fa2618,DISK], DatanodeInfoWithStorage[127.0.0.1:46044,DS-fd59061e-3162-4fa2-b551-23998253cced,DISK], DatanodeInfoWithStorage[127.0.0.1:45627,DS-9fac4c15-856f-4cd2-8bce-e7b8634973bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33065,DS-bf894669-69f0-4d4c-9e20-8f31c06065f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1394292596-172.17.0.10-1596983377105:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41940,DS-54754df8-a816-4ff4-9a74-e9c87ed5137b,DISK], DatanodeInfoWithStorage[127.0.0.1:38040,DS-110e0cba-f862-4a2e-80a7-a2689945982f,DISK], DatanodeInfoWithStorage[127.0.0.1:43081,DS-4547e0b7-b67b-4457-a276-18cb964eb6b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36216,DS-93f27cf7-9632-40cc-b17b-5de3dad0170a,DISK], DatanodeInfoWithStorage[127.0.0.1:41421,DS-7221c684-aaf4-4177-9c9a-8cdf79fa2618,DISK], DatanodeInfoWithStorage[127.0.0.1:46044,DS-fd59061e-3162-4fa2-b551-23998253cced,DISK], DatanodeInfoWithStorage[127.0.0.1:45627,DS-9fac4c15-856f-4cd2-8bce-e7b8634973bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33065,DS-bf894669-69f0-4d4c-9e20-8f31c06065f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1557491778-172.17.0.10-1596983412129:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34632,DS-5c9b01ce-d77e-4f62-a97a-354401985c06,DISK], DatanodeInfoWithStorage[127.0.0.1:45903,DS-947d0ecd-6e34-4dbc-b82b-54c195cf9863,DISK], DatanodeInfoWithStorage[127.0.0.1:41653,DS-709b4acf-6baa-44b5-858f-8e644b859e4b,DISK], DatanodeInfoWithStorage[127.0.0.1:43583,DS-ab83d35e-2cdc-4591-ab20-e063a134a3b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41054,DS-75d9164f-e769-4f37-bb70-946a5a19aa29,DISK], DatanodeInfoWithStorage[127.0.0.1:41325,DS-82a17235-e4e8-4c98-94bb-6a0f2270a7fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37280,DS-e9ccb814-2515-4b32-897b-f01bd8569798,DISK], DatanodeInfoWithStorage[127.0.0.1:38708,DS-20c1439f-6186-48c2-a24b-9058afccf965,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1557491778-172.17.0.10-1596983412129:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34632,DS-5c9b01ce-d77e-4f62-a97a-354401985c06,DISK], DatanodeInfoWithStorage[127.0.0.1:45903,DS-947d0ecd-6e34-4dbc-b82b-54c195cf9863,DISK], DatanodeInfoWithStorage[127.0.0.1:41653,DS-709b4acf-6baa-44b5-858f-8e644b859e4b,DISK], DatanodeInfoWithStorage[127.0.0.1:43583,DS-ab83d35e-2cdc-4591-ab20-e063a134a3b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41054,DS-75d9164f-e769-4f37-bb70-946a5a19aa29,DISK], DatanodeInfoWithStorage[127.0.0.1:41325,DS-82a17235-e4e8-4c98-94bb-6a0f2270a7fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37280,DS-e9ccb814-2515-4b32-897b-f01bd8569798,DISK], DatanodeInfoWithStorage[127.0.0.1:38708,DS-20c1439f-6186-48c2-a24b-9058afccf965,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1839597141-172.17.0.10-1596983581371:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40920,DS-dc0df1d0-8e7c-4c3f-8b56-73b812457d8c,DISK], DatanodeInfoWithStorage[127.0.0.1:38979,DS-595b293f-d5f8-4a06-8b4f-a96f669fd4e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39032,DS-2643d163-2c1c-43b9-9e5e-81d875a1c24a,DISK], DatanodeInfoWithStorage[127.0.0.1:35457,DS-8af99373-69c9-4a29-b77f-e08d51a05ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:45672,DS-d1387907-921a-47e1-b208-ae62d7283105,DISK], DatanodeInfoWithStorage[127.0.0.1:35762,DS-ba7edefa-7729-4f83-9339-a17ff7c7a03c,DISK], DatanodeInfoWithStorage[127.0.0.1:33018,DS-8b6076ca-3b0e-4107-ada9-08c0d588024d,DISK], DatanodeInfoWithStorage[127.0.0.1:43191,DS-a3000414-403f-4af7-8013-ec7191a9b12b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1839597141-172.17.0.10-1596983581371:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40920,DS-dc0df1d0-8e7c-4c3f-8b56-73b812457d8c,DISK], DatanodeInfoWithStorage[127.0.0.1:38979,DS-595b293f-d5f8-4a06-8b4f-a96f669fd4e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39032,DS-2643d163-2c1c-43b9-9e5e-81d875a1c24a,DISK], DatanodeInfoWithStorage[127.0.0.1:35457,DS-8af99373-69c9-4a29-b77f-e08d51a05ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:45672,DS-d1387907-921a-47e1-b208-ae62d7283105,DISK], DatanodeInfoWithStorage[127.0.0.1:35762,DS-ba7edefa-7729-4f83-9339-a17ff7c7a03c,DISK], DatanodeInfoWithStorage[127.0.0.1:33018,DS-8b6076ca-3b0e-4107-ada9-08c0d588024d,DISK], DatanodeInfoWithStorage[127.0.0.1:43191,DS-a3000414-403f-4af7-8013-ec7191a9b12b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-803512924-172.17.0.10-1596983960380:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39171,DS-a63d5278-eccb-47da-a89b-f5f96b02fdaa,DISK], DatanodeInfoWithStorage[127.0.0.1:36299,DS-3e5482a3-41ad-4d20-8d92-8e32b2262bf7,DISK], DatanodeInfoWithStorage[127.0.0.1:36107,DS-09c26931-496e-4b66-ab66-1fcbedd293a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39481,DS-a7cce116-183c-42eb-b960-bf14474fb90d,DISK], DatanodeInfoWithStorage[127.0.0.1:46572,DS-7207c31b-d647-4c20-8954-7cb87f513908,DISK], DatanodeInfoWithStorage[127.0.0.1:43596,DS-13166993-9c48-4747-a5a3-dedf781e8dba,DISK], DatanodeInfoWithStorage[127.0.0.1:39093,DS-b0a95b34-fdcc-4981-a21e-4e5b21a29dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:36730,DS-01b0cdb9-51bc-4ce7-b8bb-83177eb67dbf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-803512924-172.17.0.10-1596983960380:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39171,DS-a63d5278-eccb-47da-a89b-f5f96b02fdaa,DISK], DatanodeInfoWithStorage[127.0.0.1:36299,DS-3e5482a3-41ad-4d20-8d92-8e32b2262bf7,DISK], DatanodeInfoWithStorage[127.0.0.1:36107,DS-09c26931-496e-4b66-ab66-1fcbedd293a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39481,DS-a7cce116-183c-42eb-b960-bf14474fb90d,DISK], DatanodeInfoWithStorage[127.0.0.1:46572,DS-7207c31b-d647-4c20-8954-7cb87f513908,DISK], DatanodeInfoWithStorage[127.0.0.1:43596,DS-13166993-9c48-4747-a5a3-dedf781e8dba,DISK], DatanodeInfoWithStorage[127.0.0.1:39093,DS-b0a95b34-fdcc-4981-a21e-4e5b21a29dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:36730,DS-01b0cdb9-51bc-4ce7-b8bb-83177eb67dbf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-20584999-172.17.0.10-1596984319364:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44511,DS-fa589b24-c0c6-4c90-82b1-2d1bf1cc9dce,DISK], DatanodeInfoWithStorage[127.0.0.1:45142,DS-49a17952-c64a-434d-b820-82d1eae6bf9c,DISK], DatanodeInfoWithStorage[127.0.0.1:36119,DS-e9f5a1ff-621f-466a-9f2c-4e87357de3a6,DISK], DatanodeInfoWithStorage[127.0.0.1:43852,DS-aee9bc47-dae3-488a-b9e4-67792a17be73,DISK], DatanodeInfoWithStorage[127.0.0.1:33628,DS-755e7fba-e960-4978-b1c9-c75151b4c488,DISK], DatanodeInfoWithStorage[127.0.0.1:41866,DS-5cfeb3dd-850b-4098-8631-7785e5fa3508,DISK], DatanodeInfoWithStorage[127.0.0.1:43055,DS-e7d4b658-9de1-4339-a87f-953f020b62f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35765,DS-506cbd70-731f-4696-9fc0-2cd9ad25da3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-20584999-172.17.0.10-1596984319364:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44511,DS-fa589b24-c0c6-4c90-82b1-2d1bf1cc9dce,DISK], DatanodeInfoWithStorage[127.0.0.1:45142,DS-49a17952-c64a-434d-b820-82d1eae6bf9c,DISK], DatanodeInfoWithStorage[127.0.0.1:36119,DS-e9f5a1ff-621f-466a-9f2c-4e87357de3a6,DISK], DatanodeInfoWithStorage[127.0.0.1:43852,DS-aee9bc47-dae3-488a-b9e4-67792a17be73,DISK], DatanodeInfoWithStorage[127.0.0.1:33628,DS-755e7fba-e960-4978-b1c9-c75151b4c488,DISK], DatanodeInfoWithStorage[127.0.0.1:41866,DS-5cfeb3dd-850b-4098-8631-7785e5fa3508,DISK], DatanodeInfoWithStorage[127.0.0.1:43055,DS-e7d4b658-9de1-4339-a87f-953f020b62f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35765,DS-506cbd70-731f-4696-9fc0-2cd9ad25da3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-973538739-172.17.0.10-1596984444830:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35471,DS-412483b4-1c72-4b40-81c2-07a63285cdaf,DISK], DatanodeInfoWithStorage[127.0.0.1:44522,DS-5b18c014-6089-4690-9573-07bbcb6b6c71,DISK], DatanodeInfoWithStorage[127.0.0.1:35097,DS-27a83cad-1955-4cc5-8d46-fe707e3e94b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34039,DS-596d0b7a-d2db-481b-84c7-257edf949f12,DISK], DatanodeInfoWithStorage[127.0.0.1:33429,DS-ad624f3d-fd21-4de0-b1ae-b790166c961d,DISK], DatanodeInfoWithStorage[127.0.0.1:35888,DS-d22937bf-563d-4a14-97b8-3c51061f5c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:43939,DS-c914aa20-1be5-4bb8-8e34-c8da57b1e07f,DISK], DatanodeInfoWithStorage[127.0.0.1:35707,DS-7f7b5f49-d2c4-4ed4-bf79-f4f3095452e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-973538739-172.17.0.10-1596984444830:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35471,DS-412483b4-1c72-4b40-81c2-07a63285cdaf,DISK], DatanodeInfoWithStorage[127.0.0.1:44522,DS-5b18c014-6089-4690-9573-07bbcb6b6c71,DISK], DatanodeInfoWithStorage[127.0.0.1:35097,DS-27a83cad-1955-4cc5-8d46-fe707e3e94b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34039,DS-596d0b7a-d2db-481b-84c7-257edf949f12,DISK], DatanodeInfoWithStorage[127.0.0.1:33429,DS-ad624f3d-fd21-4de0-b1ae-b790166c961d,DISK], DatanodeInfoWithStorage[127.0.0.1:35888,DS-d22937bf-563d-4a14-97b8-3c51061f5c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:43939,DS-c914aa20-1be5-4bb8-8e34-c8da57b1e07f,DISK], DatanodeInfoWithStorage[127.0.0.1:35707,DS-7f7b5f49-d2c4-4ed4-bf79-f4f3095452e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1326012439-172.17.0.10-1596984728367:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40381,DS-6fc8b36a-b939-4d47-9a21-fb5462e53db4,DISK], DatanodeInfoWithStorage[127.0.0.1:36648,DS-31774098-ac34-4f0b-bb5d-eeb5c01d3ac8,DISK], DatanodeInfoWithStorage[127.0.0.1:40417,DS-8f7587e3-8920-4f7d-ba86-8cc88ea0c91c,DISK], DatanodeInfoWithStorage[127.0.0.1:39589,DS-3224350d-9fb3-47e5-a0c2-ccdee6021d0f,DISK], DatanodeInfoWithStorage[127.0.0.1:34918,DS-b579e8bf-9635-4dda-ac20-ba239a743929,DISK], DatanodeInfoWithStorage[127.0.0.1:40433,DS-6fe67d98-8bae-4570-9e6f-e8828f8b35fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36937,DS-aa75e5ea-cc80-4b1c-a495-428da6a5f398,DISK], DatanodeInfoWithStorage[127.0.0.1:36300,DS-444e51fb-b12b-47cc-a4ab-8eb2ac6512f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1326012439-172.17.0.10-1596984728367:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40381,DS-6fc8b36a-b939-4d47-9a21-fb5462e53db4,DISK], DatanodeInfoWithStorage[127.0.0.1:36648,DS-31774098-ac34-4f0b-bb5d-eeb5c01d3ac8,DISK], DatanodeInfoWithStorage[127.0.0.1:40417,DS-8f7587e3-8920-4f7d-ba86-8cc88ea0c91c,DISK], DatanodeInfoWithStorage[127.0.0.1:39589,DS-3224350d-9fb3-47e5-a0c2-ccdee6021d0f,DISK], DatanodeInfoWithStorage[127.0.0.1:34918,DS-b579e8bf-9635-4dda-ac20-ba239a743929,DISK], DatanodeInfoWithStorage[127.0.0.1:40433,DS-6fe67d98-8bae-4570-9e6f-e8828f8b35fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36937,DS-aa75e5ea-cc80-4b1c-a495-428da6a5f398,DISK], DatanodeInfoWithStorage[127.0.0.1:36300,DS-444e51fb-b12b-47cc-a4ab-8eb2ac6512f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2026247636-172.17.0.10-1596985509117:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43810,DS-068ccfde-98c2-4d72-bad8-b7572a5a6c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:38942,DS-6837f534-2539-454c-9810-6548dbe822ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37196,DS-d9c8f6e3-8bde-4d3a-b365-e93c5afe6e3b,DISK], DatanodeInfoWithStorage[127.0.0.1:34223,DS-340e6911-eb6b-47dd-bce1-f7ba1a327b57,DISK], DatanodeInfoWithStorage[127.0.0.1:34066,DS-20332ee8-e331-4d19-bcb2-83119d6fea08,DISK], DatanodeInfoWithStorage[127.0.0.1:32800,DS-65f8e597-6fee-4a4e-a014-07e66667434d,DISK], DatanodeInfoWithStorage[127.0.0.1:35303,DS-13fccb38-544c-45cb-a92d-114613a341ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43857,DS-21694c2c-a112-4a6e-858b-cc10ad4ec627,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2026247636-172.17.0.10-1596985509117:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43810,DS-068ccfde-98c2-4d72-bad8-b7572a5a6c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:38942,DS-6837f534-2539-454c-9810-6548dbe822ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37196,DS-d9c8f6e3-8bde-4d3a-b365-e93c5afe6e3b,DISK], DatanodeInfoWithStorage[127.0.0.1:34223,DS-340e6911-eb6b-47dd-bce1-f7ba1a327b57,DISK], DatanodeInfoWithStorage[127.0.0.1:34066,DS-20332ee8-e331-4d19-bcb2-83119d6fea08,DISK], DatanodeInfoWithStorage[127.0.0.1:32800,DS-65f8e597-6fee-4a4e-a014-07e66667434d,DISK], DatanodeInfoWithStorage[127.0.0.1:35303,DS-13fccb38-544c-45cb-a92d-114613a341ab,DISK], DatanodeInfoWithStorage[127.0.0.1:43857,DS-21694c2c-a112-4a6e-858b-cc10ad4ec627,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 4852
