reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1330318548-172.17.0.13-1596917136433:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34788,DS-744b96e3-690e-4e61-b73c-aa24d0a3fd38,DISK], DatanodeInfoWithStorage[127.0.0.1:40852,DS-0a6a7ad5-6618-4544-9349-d1aa27641054,DISK], DatanodeInfoWithStorage[127.0.0.1:35945,DS-ff38aa48-64be-4cbc-a777-245b3ad58289,DISK], DatanodeInfoWithStorage[127.0.0.1:33993,DS-985d35b4-e548-49c9-8a11-eebcf016b0ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36723,DS-d9fb5a8e-ee04-4fd7-9482-bb6cbca0e8c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43568,DS-b257e421-a1d9-473c-b67a-29d6904a1ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:41241,DS-4a9c7153-65cf-4651-8ab7-0914b6930547,DISK], DatanodeInfoWithStorage[127.0.0.1:45980,DS-76d1f5a4-bf27-4af0-8bff-1acca6e86912,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1330318548-172.17.0.13-1596917136433:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34788,DS-744b96e3-690e-4e61-b73c-aa24d0a3fd38,DISK], DatanodeInfoWithStorage[127.0.0.1:40852,DS-0a6a7ad5-6618-4544-9349-d1aa27641054,DISK], DatanodeInfoWithStorage[127.0.0.1:35945,DS-ff38aa48-64be-4cbc-a777-245b3ad58289,DISK], DatanodeInfoWithStorage[127.0.0.1:33993,DS-985d35b4-e548-49c9-8a11-eebcf016b0ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36723,DS-d9fb5a8e-ee04-4fd7-9482-bb6cbca0e8c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43568,DS-b257e421-a1d9-473c-b67a-29d6904a1ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:41241,DS-4a9c7153-65cf-4651-8ab7-0914b6930547,DISK], DatanodeInfoWithStorage[127.0.0.1:45980,DS-76d1f5a4-bf27-4af0-8bff-1acca6e86912,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1213204363-172.17.0.13-1596917243233:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39444,DS-c487ba95-6579-4583-9f4e-55e3aa83d48e,DISK], DatanodeInfoWithStorage[127.0.0.1:36236,DS-bca0b5a6-7ad2-44cf-9622-787321525f75,DISK], DatanodeInfoWithStorage[127.0.0.1:33692,DS-36493807-48c8-4cb8-a651-2af69b617ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:42660,DS-ee4f2016-a0b3-4631-b640-ad21720f0de2,DISK], DatanodeInfoWithStorage[127.0.0.1:34969,DS-bc3fea39-6c4c-4291-8f0e-3882ffbacd23,DISK], DatanodeInfoWithStorage[127.0.0.1:42198,DS-c4ca25a5-3c58-4733-a93d-60e31ce6dd80,DISK], DatanodeInfoWithStorage[127.0.0.1:46176,DS-77beacca-3990-49bf-8244-c38898480dd9,DISK], DatanodeInfoWithStorage[127.0.0.1:41437,DS-d66d3769-cb67-4248-bb18-8ca4169fad0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1213204363-172.17.0.13-1596917243233:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39444,DS-c487ba95-6579-4583-9f4e-55e3aa83d48e,DISK], DatanodeInfoWithStorage[127.0.0.1:36236,DS-bca0b5a6-7ad2-44cf-9622-787321525f75,DISK], DatanodeInfoWithStorage[127.0.0.1:33692,DS-36493807-48c8-4cb8-a651-2af69b617ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:42660,DS-ee4f2016-a0b3-4631-b640-ad21720f0de2,DISK], DatanodeInfoWithStorage[127.0.0.1:34969,DS-bc3fea39-6c4c-4291-8f0e-3882ffbacd23,DISK], DatanodeInfoWithStorage[127.0.0.1:42198,DS-c4ca25a5-3c58-4733-a93d-60e31ce6dd80,DISK], DatanodeInfoWithStorage[127.0.0.1:46176,DS-77beacca-3990-49bf-8244-c38898480dd9,DISK], DatanodeInfoWithStorage[127.0.0.1:41437,DS-d66d3769-cb67-4248-bb18-8ca4169fad0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-562101972-172.17.0.13-1596917323349:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40688,DS-31f76049-18bf-4031-a770-182b3742f15e,DISK], DatanodeInfoWithStorage[127.0.0.1:42721,DS-2b287d38-d380-43e2-97bb-9dd83274faa5,DISK], DatanodeInfoWithStorage[127.0.0.1:43314,DS-5c066107-b373-43ee-ba3d-a2229c348e45,DISK], DatanodeInfoWithStorage[127.0.0.1:43259,DS-c6018d29-f175-4379-9508-9ded6c9fc5a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33996,DS-b6d48d87-92e4-4a2a-ad88-0650233f629e,DISK], DatanodeInfoWithStorage[127.0.0.1:35592,DS-27c3aba7-bbb7-462b-995c-b0e1e1312e23,DISK], DatanodeInfoWithStorage[127.0.0.1:40752,DS-2a230126-df12-48c1-aa7a-2f428ace3dc0,DISK], DatanodeInfoWithStorage[127.0.0.1:43249,DS-728718dc-6435-4038-b005-3e3120ff9e78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-562101972-172.17.0.13-1596917323349:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40688,DS-31f76049-18bf-4031-a770-182b3742f15e,DISK], DatanodeInfoWithStorage[127.0.0.1:42721,DS-2b287d38-d380-43e2-97bb-9dd83274faa5,DISK], DatanodeInfoWithStorage[127.0.0.1:43314,DS-5c066107-b373-43ee-ba3d-a2229c348e45,DISK], DatanodeInfoWithStorage[127.0.0.1:43259,DS-c6018d29-f175-4379-9508-9ded6c9fc5a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33996,DS-b6d48d87-92e4-4a2a-ad88-0650233f629e,DISK], DatanodeInfoWithStorage[127.0.0.1:35592,DS-27c3aba7-bbb7-462b-995c-b0e1e1312e23,DISK], DatanodeInfoWithStorage[127.0.0.1:40752,DS-2a230126-df12-48c1-aa7a-2f428ace3dc0,DISK], DatanodeInfoWithStorage[127.0.0.1:43249,DS-728718dc-6435-4038-b005-3e3120ff9e78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-817459551-172.17.0.13-1596917836069:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44311,DS-8a91a72c-0dec-4945-a5c6-09c16fb5a6be,DISK], DatanodeInfoWithStorage[127.0.0.1:35153,DS-74d0c5d8-f102-4542-a604-f04cc62ddaf4,DISK], DatanodeInfoWithStorage[127.0.0.1:36723,DS-145e8bf8-ea6c-48d6-9610-ea5b9f53f4b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40185,DS-4b693605-5c66-40c9-963e-e36c2118f45a,DISK], DatanodeInfoWithStorage[127.0.0.1:38087,DS-1c611a43-f0c2-4e8e-b6f2-e6b25205834a,DISK], DatanodeInfoWithStorage[127.0.0.1:42575,DS-24280507-2065-4b86-af22-4547ba4557f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46522,DS-158e728f-3134-4889-be2a-c79770cf6074,DISK], DatanodeInfoWithStorage[127.0.0.1:44940,DS-cc9efaaa-545d-4bb1-a1be-0b182e99df90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-817459551-172.17.0.13-1596917836069:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44311,DS-8a91a72c-0dec-4945-a5c6-09c16fb5a6be,DISK], DatanodeInfoWithStorage[127.0.0.1:35153,DS-74d0c5d8-f102-4542-a604-f04cc62ddaf4,DISK], DatanodeInfoWithStorage[127.0.0.1:36723,DS-145e8bf8-ea6c-48d6-9610-ea5b9f53f4b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40185,DS-4b693605-5c66-40c9-963e-e36c2118f45a,DISK], DatanodeInfoWithStorage[127.0.0.1:38087,DS-1c611a43-f0c2-4e8e-b6f2-e6b25205834a,DISK], DatanodeInfoWithStorage[127.0.0.1:42575,DS-24280507-2065-4b86-af22-4547ba4557f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46522,DS-158e728f-3134-4889-be2a-c79770cf6074,DISK], DatanodeInfoWithStorage[127.0.0.1:44940,DS-cc9efaaa-545d-4bb1-a1be-0b182e99df90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-105671707-172.17.0.13-1596918119305:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42538,DS-a2d1ae3b-4b60-4576-bc94-67f7ec1ea1bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44082,DS-98811b22-2343-421e-9585-cf56850ef3c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46529,DS-fb396827-4edd-40ea-829a-bdb987344958,DISK], DatanodeInfoWithStorage[127.0.0.1:42569,DS-9c95b2af-eb8b-46b1-b097-883942b1729b,DISK], DatanodeInfoWithStorage[127.0.0.1:46730,DS-a1e49083-f0a0-4d4e-acbd-42ccf34e6fab,DISK], DatanodeInfoWithStorage[127.0.0.1:42308,DS-3f5999ba-0355-4eca-829c-43a43bba6c31,DISK], DatanodeInfoWithStorage[127.0.0.1:39091,DS-efdc643e-5e3c-4ba6-b0b0-99c649f638c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43111,DS-95981177-3594-4e5e-9a09-5cad96aa25f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-105671707-172.17.0.13-1596918119305:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42538,DS-a2d1ae3b-4b60-4576-bc94-67f7ec1ea1bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44082,DS-98811b22-2343-421e-9585-cf56850ef3c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46529,DS-fb396827-4edd-40ea-829a-bdb987344958,DISK], DatanodeInfoWithStorage[127.0.0.1:42569,DS-9c95b2af-eb8b-46b1-b097-883942b1729b,DISK], DatanodeInfoWithStorage[127.0.0.1:46730,DS-a1e49083-f0a0-4d4e-acbd-42ccf34e6fab,DISK], DatanodeInfoWithStorage[127.0.0.1:42308,DS-3f5999ba-0355-4eca-829c-43a43bba6c31,DISK], DatanodeInfoWithStorage[127.0.0.1:39091,DS-efdc643e-5e3c-4ba6-b0b0-99c649f638c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43111,DS-95981177-3594-4e5e-9a09-5cad96aa25f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1214282283-172.17.0.13-1596918323931:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40833,DS-25ab8c32-64c4-4c5d-a093-5deb3f914a50,DISK], DatanodeInfoWithStorage[127.0.0.1:40842,DS-ca2e968a-c08d-40ff-bcd2-207bdcacf50c,DISK], DatanodeInfoWithStorage[127.0.0.1:46240,DS-8c4e2c1d-5af6-4256-bef2-e8dd3aedf9f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34748,DS-b897524b-93e2-4bc2-9a89-53cd22f32980,DISK], DatanodeInfoWithStorage[127.0.0.1:35145,DS-9441635e-57c9-45cd-bdee-3ac1ca9ff862,DISK], DatanodeInfoWithStorage[127.0.0.1:44891,DS-78266cde-da16-4581-a7e4-fed87be6f608,DISK], DatanodeInfoWithStorage[127.0.0.1:33365,DS-423a9a39-059a-4ef7-80e3-69b9ed3c44fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45700,DS-1277481b-6c0c-4779-a531-4f1aa8aae515,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1214282283-172.17.0.13-1596918323931:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40833,DS-25ab8c32-64c4-4c5d-a093-5deb3f914a50,DISK], DatanodeInfoWithStorage[127.0.0.1:40842,DS-ca2e968a-c08d-40ff-bcd2-207bdcacf50c,DISK], DatanodeInfoWithStorage[127.0.0.1:46240,DS-8c4e2c1d-5af6-4256-bef2-e8dd3aedf9f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34748,DS-b897524b-93e2-4bc2-9a89-53cd22f32980,DISK], DatanodeInfoWithStorage[127.0.0.1:35145,DS-9441635e-57c9-45cd-bdee-3ac1ca9ff862,DISK], DatanodeInfoWithStorage[127.0.0.1:44891,DS-78266cde-da16-4581-a7e4-fed87be6f608,DISK], DatanodeInfoWithStorage[127.0.0.1:33365,DS-423a9a39-059a-4ef7-80e3-69b9ed3c44fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45700,DS-1277481b-6c0c-4779-a531-4f1aa8aae515,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1118877205-172.17.0.13-1596918773479:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42507,DS-f2109cdf-ae3e-4a0e-adc7-7cc744bff9d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41745,DS-69fd231c-7a54-4a71-9c1f-9ef57d42acfb,DISK], DatanodeInfoWithStorage[127.0.0.1:37771,DS-5b748ae2-d6d2-4722-b2ac-11ec4734855b,DISK], DatanodeInfoWithStorage[127.0.0.1:36010,DS-bcea014a-3ebb-4eee-833b-96b6f6727126,DISK], DatanodeInfoWithStorage[127.0.0.1:45099,DS-085ff552-cd6d-436a-a88a-46f713f03d2a,DISK], DatanodeInfoWithStorage[127.0.0.1:39342,DS-b17bcae9-2651-44eb-8474-767b07f996aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38695,DS-8423f673-8efc-4297-99aa-0e71e905f417,DISK], DatanodeInfoWithStorage[127.0.0.1:34139,DS-5edcf548-3b8a-4fd7-860f-888e40a3d385,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1118877205-172.17.0.13-1596918773479:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42507,DS-f2109cdf-ae3e-4a0e-adc7-7cc744bff9d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41745,DS-69fd231c-7a54-4a71-9c1f-9ef57d42acfb,DISK], DatanodeInfoWithStorage[127.0.0.1:37771,DS-5b748ae2-d6d2-4722-b2ac-11ec4734855b,DISK], DatanodeInfoWithStorage[127.0.0.1:36010,DS-bcea014a-3ebb-4eee-833b-96b6f6727126,DISK], DatanodeInfoWithStorage[127.0.0.1:45099,DS-085ff552-cd6d-436a-a88a-46f713f03d2a,DISK], DatanodeInfoWithStorage[127.0.0.1:39342,DS-b17bcae9-2651-44eb-8474-767b07f996aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38695,DS-8423f673-8efc-4297-99aa-0e71e905f417,DISK], DatanodeInfoWithStorage[127.0.0.1:34139,DS-5edcf548-3b8a-4fd7-860f-888e40a3d385,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1269137938-172.17.0.13-1596918845915:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40369,DS-ee0f2b25-a815-4ed0-8706-e6d36767bd4f,DISK], DatanodeInfoWithStorage[127.0.0.1:37768,DS-27e02a9d-0bb0-4ae4-8be1-a272439d9a60,DISK], DatanodeInfoWithStorage[127.0.0.1:36597,DS-bab501b6-e9fb-4ea4-979e-0b6d59882ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:38031,DS-4ff471f3-a50f-4560-a8d2-2246f93da243,DISK], DatanodeInfoWithStorage[127.0.0.1:39475,DS-549e7448-2407-4ba4-a002-cc2f3ec50ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:41776,DS-97a63ce5-35ad-4065-97cf-97861be09023,DISK], DatanodeInfoWithStorage[127.0.0.1:34713,DS-7b2e7148-b2f4-46e0-bdf4-9e802f963a10,DISK], DatanodeInfoWithStorage[127.0.0.1:36070,DS-db37f0c9-29cb-4dc6-bfd9-05b68a7fc291,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1269137938-172.17.0.13-1596918845915:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40369,DS-ee0f2b25-a815-4ed0-8706-e6d36767bd4f,DISK], DatanodeInfoWithStorage[127.0.0.1:37768,DS-27e02a9d-0bb0-4ae4-8be1-a272439d9a60,DISK], DatanodeInfoWithStorage[127.0.0.1:36597,DS-bab501b6-e9fb-4ea4-979e-0b6d59882ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:38031,DS-4ff471f3-a50f-4560-a8d2-2246f93da243,DISK], DatanodeInfoWithStorage[127.0.0.1:39475,DS-549e7448-2407-4ba4-a002-cc2f3ec50ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:41776,DS-97a63ce5-35ad-4065-97cf-97861be09023,DISK], DatanodeInfoWithStorage[127.0.0.1:34713,DS-7b2e7148-b2f4-46e0-bdf4-9e802f963a10,DISK], DatanodeInfoWithStorage[127.0.0.1:36070,DS-db37f0c9-29cb-4dc6-bfd9-05b68a7fc291,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1274627485-172.17.0.13-1596919200460:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44040,DS-9f466470-1f44-47ef-9f9f-98a3c67e8f79,DISK], DatanodeInfoWithStorage[127.0.0.1:35751,DS-a71d813b-e92a-4291-a4a3-21a0dc501fae,DISK], DatanodeInfoWithStorage[127.0.0.1:42474,DS-8da3fc65-7d8a-49b0-af77-d6e096444054,DISK], DatanodeInfoWithStorage[127.0.0.1:45235,DS-9d9e6ea3-2a02-44d1-a4c4-5816ee5c7088,DISK], DatanodeInfoWithStorage[127.0.0.1:33083,DS-e08af721-39f2-47a9-858f-97c5dd5d1841,DISK], DatanodeInfoWithStorage[127.0.0.1:45449,DS-2bac055e-ff51-402b-8f2b-1863f1de9089,DISK], DatanodeInfoWithStorage[127.0.0.1:36986,DS-68312232-5ffe-43f0-98f7-c7f299fcfaa2,DISK], DatanodeInfoWithStorage[127.0.0.1:33046,DS-21ce35ff-0238-4f1b-8fbf-73198ab56025,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1274627485-172.17.0.13-1596919200460:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44040,DS-9f466470-1f44-47ef-9f9f-98a3c67e8f79,DISK], DatanodeInfoWithStorage[127.0.0.1:35751,DS-a71d813b-e92a-4291-a4a3-21a0dc501fae,DISK], DatanodeInfoWithStorage[127.0.0.1:42474,DS-8da3fc65-7d8a-49b0-af77-d6e096444054,DISK], DatanodeInfoWithStorage[127.0.0.1:45235,DS-9d9e6ea3-2a02-44d1-a4c4-5816ee5c7088,DISK], DatanodeInfoWithStorage[127.0.0.1:33083,DS-e08af721-39f2-47a9-858f-97c5dd5d1841,DISK], DatanodeInfoWithStorage[127.0.0.1:45449,DS-2bac055e-ff51-402b-8f2b-1863f1de9089,DISK], DatanodeInfoWithStorage[127.0.0.1:36986,DS-68312232-5ffe-43f0-98f7-c7f299fcfaa2,DISK], DatanodeInfoWithStorage[127.0.0.1:33046,DS-21ce35ff-0238-4f1b-8fbf-73198ab56025,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1080067702-172.17.0.13-1596919325848:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37076,DS-94f8973b-4222-4e32-a49f-d86e6bf73851,DISK], DatanodeInfoWithStorage[127.0.0.1:34707,DS-d9929ede-a3fd-4df2-8516-8453be24437c,DISK], DatanodeInfoWithStorage[127.0.0.1:45405,DS-455758cd-048d-4c39-a588-51eb11a66f12,DISK], DatanodeInfoWithStorage[127.0.0.1:38582,DS-d74ffc4e-4486-4a06-9bfd-f944bb6a3a89,DISK], DatanodeInfoWithStorage[127.0.0.1:44802,DS-309f81df-301d-4732-b76d-a30a8fa4b95a,DISK], DatanodeInfoWithStorage[127.0.0.1:35623,DS-4a5fde42-8989-46b5-b675-8121cbf9a18b,DISK], DatanodeInfoWithStorage[127.0.0.1:46511,DS-2d1fee03-58f2-4211-8a85-40785d39f5da,DISK], DatanodeInfoWithStorage[127.0.0.1:40748,DS-1f906794-e990-4200-bcaa-d28a904a94c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1080067702-172.17.0.13-1596919325848:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37076,DS-94f8973b-4222-4e32-a49f-d86e6bf73851,DISK], DatanodeInfoWithStorage[127.0.0.1:34707,DS-d9929ede-a3fd-4df2-8516-8453be24437c,DISK], DatanodeInfoWithStorage[127.0.0.1:45405,DS-455758cd-048d-4c39-a588-51eb11a66f12,DISK], DatanodeInfoWithStorage[127.0.0.1:38582,DS-d74ffc4e-4486-4a06-9bfd-f944bb6a3a89,DISK], DatanodeInfoWithStorage[127.0.0.1:44802,DS-309f81df-301d-4732-b76d-a30a8fa4b95a,DISK], DatanodeInfoWithStorage[127.0.0.1:35623,DS-4a5fde42-8989-46b5-b675-8121cbf9a18b,DISK], DatanodeInfoWithStorage[127.0.0.1:46511,DS-2d1fee03-58f2-4211-8a85-40785d39f5da,DISK], DatanodeInfoWithStorage[127.0.0.1:40748,DS-1f906794-e990-4200-bcaa-d28a904a94c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-111392161-172.17.0.13-1596919691888:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41182,DS-6740c5ac-1850-47a0-b3f1-b939f82aa180,DISK], DatanodeInfoWithStorage[127.0.0.1:37786,DS-de0bc662-e655-44c3-bcca-4f540ac9cb65,DISK], DatanodeInfoWithStorage[127.0.0.1:43998,DS-1a685d5f-3d96-48e6-859c-966b99eb1041,DISK], DatanodeInfoWithStorage[127.0.0.1:43473,DS-fd64fcaf-3271-4d90-8d68-b984e076ef5d,DISK], DatanodeInfoWithStorage[127.0.0.1:45679,DS-04399fb7-8b20-43cb-b087-25c00c4f4dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:44476,DS-3043d161-9074-4bd2-a796-7b1f5ce0a9fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43306,DS-6afb25e4-807d-4a17-a7da-d1245f62d436,DISK], DatanodeInfoWithStorage[127.0.0.1:40339,DS-5fac69f2-a8c0-4649-8a8b-a0efb8ef0a65,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-111392161-172.17.0.13-1596919691888:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41182,DS-6740c5ac-1850-47a0-b3f1-b939f82aa180,DISK], DatanodeInfoWithStorage[127.0.0.1:37786,DS-de0bc662-e655-44c3-bcca-4f540ac9cb65,DISK], DatanodeInfoWithStorage[127.0.0.1:43998,DS-1a685d5f-3d96-48e6-859c-966b99eb1041,DISK], DatanodeInfoWithStorage[127.0.0.1:43473,DS-fd64fcaf-3271-4d90-8d68-b984e076ef5d,DISK], DatanodeInfoWithStorage[127.0.0.1:45679,DS-04399fb7-8b20-43cb-b087-25c00c4f4dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:44476,DS-3043d161-9074-4bd2-a796-7b1f5ce0a9fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43306,DS-6afb25e4-807d-4a17-a7da-d1245f62d436,DISK], DatanodeInfoWithStorage[127.0.0.1:40339,DS-5fac69f2-a8c0-4649-8a8b-a0efb8ef0a65,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-272737252-172.17.0.13-1596919800504:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40619,DS-559bf334-0da1-4a9e-a9e0-c7762acf8a50,DISK], DatanodeInfoWithStorage[127.0.0.1:41296,DS-d76b6d9d-bf57-4a2f-9f07-58df5ee7d84a,DISK], DatanodeInfoWithStorage[127.0.0.1:35472,DS-a427ca3e-9213-40e1-a605-620691ac76c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41602,DS-372fa8fb-613e-4886-88f6-97009ce118aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41023,DS-532c8770-9c4f-4ab4-ab59-b9c5985db854,DISK], DatanodeInfoWithStorage[127.0.0.1:46683,DS-afa09e57-f0b8-4939-ac43-e474b4326c09,DISK], DatanodeInfoWithStorage[127.0.0.1:39737,DS-efc53947-a644-4103-a913-94b1d8a89b37,DISK], DatanodeInfoWithStorage[127.0.0.1:40419,DS-dd2fc33b-c6e7-46ee-b12c-cee749f0314b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-272737252-172.17.0.13-1596919800504:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40619,DS-559bf334-0da1-4a9e-a9e0-c7762acf8a50,DISK], DatanodeInfoWithStorage[127.0.0.1:41296,DS-d76b6d9d-bf57-4a2f-9f07-58df5ee7d84a,DISK], DatanodeInfoWithStorage[127.0.0.1:35472,DS-a427ca3e-9213-40e1-a605-620691ac76c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41602,DS-372fa8fb-613e-4886-88f6-97009ce118aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41023,DS-532c8770-9c4f-4ab4-ab59-b9c5985db854,DISK], DatanodeInfoWithStorage[127.0.0.1:46683,DS-afa09e57-f0b8-4939-ac43-e474b4326c09,DISK], DatanodeInfoWithStorage[127.0.0.1:39737,DS-efc53947-a644-4103-a913-94b1d8a89b37,DISK], DatanodeInfoWithStorage[127.0.0.1:40419,DS-dd2fc33b-c6e7-46ee-b12c-cee749f0314b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1380550409-172.17.0.13-1596920168012:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41535,DS-e5ba33d2-0370-4115-b468-cef657a8b76b,DISK], DatanodeInfoWithStorage[127.0.0.1:45069,DS-fa0cab02-d0c5-4178-a5fa-e133eb97bc44,DISK], DatanodeInfoWithStorage[127.0.0.1:41899,DS-52c29717-4f7d-47fd-a923-9e6d6aa43499,DISK], DatanodeInfoWithStorage[127.0.0.1:44546,DS-b833a568-47cc-4156-8266-b87c4f00d2f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33399,DS-54bd29e1-da17-4aa2-817f-826b2aecfc7e,DISK], DatanodeInfoWithStorage[127.0.0.1:41660,DS-9ac87d0d-ff59-4055-991a-7a79b8c34a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:40135,DS-93dac534-4cf0-4523-84a8-65b4ffbc8ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:35890,DS-7568552c-4c41-4d58-ac22-540fe811893d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1380550409-172.17.0.13-1596920168012:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41535,DS-e5ba33d2-0370-4115-b468-cef657a8b76b,DISK], DatanodeInfoWithStorage[127.0.0.1:45069,DS-fa0cab02-d0c5-4178-a5fa-e133eb97bc44,DISK], DatanodeInfoWithStorage[127.0.0.1:41899,DS-52c29717-4f7d-47fd-a923-9e6d6aa43499,DISK], DatanodeInfoWithStorage[127.0.0.1:44546,DS-b833a568-47cc-4156-8266-b87c4f00d2f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33399,DS-54bd29e1-da17-4aa2-817f-826b2aecfc7e,DISK], DatanodeInfoWithStorage[127.0.0.1:41660,DS-9ac87d0d-ff59-4055-991a-7a79b8c34a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:40135,DS-93dac534-4cf0-4523-84a8-65b4ffbc8ec8,DISK], DatanodeInfoWithStorage[127.0.0.1:35890,DS-7568552c-4c41-4d58-ac22-540fe811893d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1162682170-172.17.0.13-1596920659318:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33779,DS-36bf44d1-92fb-48f6-a516-965489139cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:37399,DS-fa4ca818-1bd5-430b-ac25-8b114342dfb5,DISK], DatanodeInfoWithStorage[127.0.0.1:44769,DS-1ede6394-6188-45aa-a7a3-0eb61d3f5fc7,DISK], DatanodeInfoWithStorage[127.0.0.1:41751,DS-d647577e-8949-479c-825c-445b5c1c3288,DISK], DatanodeInfoWithStorage[127.0.0.1:37621,DS-73c1a02f-dc9a-4935-8f50-f3f5f827b3c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43542,DS-31b660b0-26c0-411b-a53f-f6a6a7dfab84,DISK], DatanodeInfoWithStorage[127.0.0.1:38309,DS-bb9cf219-bb8b-4b5f-94a1-e37c1b5b4bfc,DISK], DatanodeInfoWithStorage[127.0.0.1:40141,DS-e603bda5-b66b-4a2e-86c6-9437cdda103a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1162682170-172.17.0.13-1596920659318:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33779,DS-36bf44d1-92fb-48f6-a516-965489139cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:37399,DS-fa4ca818-1bd5-430b-ac25-8b114342dfb5,DISK], DatanodeInfoWithStorage[127.0.0.1:44769,DS-1ede6394-6188-45aa-a7a3-0eb61d3f5fc7,DISK], DatanodeInfoWithStorage[127.0.0.1:41751,DS-d647577e-8949-479c-825c-445b5c1c3288,DISK], DatanodeInfoWithStorage[127.0.0.1:37621,DS-73c1a02f-dc9a-4935-8f50-f3f5f827b3c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43542,DS-31b660b0-26c0-411b-a53f-f6a6a7dfab84,DISK], DatanodeInfoWithStorage[127.0.0.1:38309,DS-bb9cf219-bb8b-4b5f-94a1-e37c1b5b4bfc,DISK], DatanodeInfoWithStorage[127.0.0.1:40141,DS-e603bda5-b66b-4a2e-86c6-9437cdda103a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1613538266-172.17.0.13-1596921275344:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36705,DS-1aa8f6e2-dd90-4cb8-aa26-0b804ceb0544,DISK], DatanodeInfoWithStorage[127.0.0.1:43214,DS-03542077-15c0-4cc0-8862-cee5453471b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45983,DS-f07be2ab-ad72-4d85-bc87-9f5f76ecaea7,DISK], DatanodeInfoWithStorage[127.0.0.1:37920,DS-18fde65b-3595-4a4d-b003-ccf979b5214e,DISK], DatanodeInfoWithStorage[127.0.0.1:43792,DS-0161cdee-8e63-45b4-92a4-ec405b5f5c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:37753,DS-161adcca-c998-49c7-9448-4fa8767b920d,DISK], DatanodeInfoWithStorage[127.0.0.1:34249,DS-b741b877-a35c-48a2-bb95-4f985a0cfc02,DISK], DatanodeInfoWithStorage[127.0.0.1:34631,DS-bcc06ed4-0192-49ce-aa36-30d7d7ace5dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1613538266-172.17.0.13-1596921275344:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36705,DS-1aa8f6e2-dd90-4cb8-aa26-0b804ceb0544,DISK], DatanodeInfoWithStorage[127.0.0.1:43214,DS-03542077-15c0-4cc0-8862-cee5453471b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45983,DS-f07be2ab-ad72-4d85-bc87-9f5f76ecaea7,DISK], DatanodeInfoWithStorage[127.0.0.1:37920,DS-18fde65b-3595-4a4d-b003-ccf979b5214e,DISK], DatanodeInfoWithStorage[127.0.0.1:43792,DS-0161cdee-8e63-45b4-92a4-ec405b5f5c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:37753,DS-161adcca-c998-49c7-9448-4fa8767b920d,DISK], DatanodeInfoWithStorage[127.0.0.1:34249,DS-b741b877-a35c-48a2-bb95-4f985a0cfc02,DISK], DatanodeInfoWithStorage[127.0.0.1:34631,DS-bcc06ed4-0192-49ce-aa36-30d7d7ace5dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-236874559-172.17.0.13-1596921593729:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34778,DS-532846e2-e68e-4a74-85f5-389c8b3b48ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38648,DS-1b8bfada-7659-41d9-a761-1148ab1e48c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34168,DS-a7267972-71dd-4faf-b5dd-9b6f209e5b20,DISK], DatanodeInfoWithStorage[127.0.0.1:39705,DS-1dd691fd-666c-4c39-b544-123f577e75e7,DISK], DatanodeInfoWithStorage[127.0.0.1:39193,DS-68fbde49-5b36-4433-8a28-155c39962ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:35721,DS-757f9f76-b471-4401-8c8f-415ede549089,DISK], DatanodeInfoWithStorage[127.0.0.1:41352,DS-ecdb7f5e-51f9-4fef-a6d6-45a496d10f05,DISK], DatanodeInfoWithStorage[127.0.0.1:39644,DS-33b8975e-be30-4855-8a93-33d23ec4716a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-236874559-172.17.0.13-1596921593729:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34778,DS-532846e2-e68e-4a74-85f5-389c8b3b48ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38648,DS-1b8bfada-7659-41d9-a761-1148ab1e48c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34168,DS-a7267972-71dd-4faf-b5dd-9b6f209e5b20,DISK], DatanodeInfoWithStorage[127.0.0.1:39705,DS-1dd691fd-666c-4c39-b544-123f577e75e7,DISK], DatanodeInfoWithStorage[127.0.0.1:39193,DS-68fbde49-5b36-4433-8a28-155c39962ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:35721,DS-757f9f76-b471-4401-8c8f-415ede549089,DISK], DatanodeInfoWithStorage[127.0.0.1:41352,DS-ecdb7f5e-51f9-4fef-a6d6-45a496d10f05,DISK], DatanodeInfoWithStorage[127.0.0.1:39644,DS-33b8975e-be30-4855-8a93-33d23ec4716a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5323
