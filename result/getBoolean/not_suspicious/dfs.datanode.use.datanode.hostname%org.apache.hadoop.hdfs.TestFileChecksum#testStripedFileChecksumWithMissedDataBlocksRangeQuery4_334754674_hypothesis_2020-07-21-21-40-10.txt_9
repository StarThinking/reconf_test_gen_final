reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-941009420-172.17.0.14-1595368168592:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41986,DS-3489ccd0-311f-466a-8b50-ff44fa098f35,DISK], DatanodeInfoWithStorage[127.0.0.1:39582,DS-a4150b8b-be98-4899-af71-efce7636d498,DISK], DatanodeInfoWithStorage[127.0.0.1:36902,DS-d39c0123-593f-4d7b-9938-8b3bf7388891,DISK], DatanodeInfoWithStorage[127.0.0.1:42100,DS-0ffe4fe0-f226-49fa-b474-c778f193796e,DISK], DatanodeInfoWithStorage[127.0.0.1:46094,DS-f8d96e94-ca06-4ecc-9e37-006f96565d30,DISK], DatanodeInfoWithStorage[127.0.0.1:45547,DS-e9d17174-6fb2-40f8-b143-7dd693aeb0a0,DISK], DatanodeInfoWithStorage[127.0.0.1:42768,DS-370a634c-166b-4251-9fe6-9b79fa002629,DISK], DatanodeInfoWithStorage[127.0.0.1:35692,DS-39408674-6fd5-4527-b987-368fce042d18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-941009420-172.17.0.14-1595368168592:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41986,DS-3489ccd0-311f-466a-8b50-ff44fa098f35,DISK], DatanodeInfoWithStorage[127.0.0.1:39582,DS-a4150b8b-be98-4899-af71-efce7636d498,DISK], DatanodeInfoWithStorage[127.0.0.1:36902,DS-d39c0123-593f-4d7b-9938-8b3bf7388891,DISK], DatanodeInfoWithStorage[127.0.0.1:42100,DS-0ffe4fe0-f226-49fa-b474-c778f193796e,DISK], DatanodeInfoWithStorage[127.0.0.1:46094,DS-f8d96e94-ca06-4ecc-9e37-006f96565d30,DISK], DatanodeInfoWithStorage[127.0.0.1:45547,DS-e9d17174-6fb2-40f8-b143-7dd693aeb0a0,DISK], DatanodeInfoWithStorage[127.0.0.1:42768,DS-370a634c-166b-4251-9fe6-9b79fa002629,DISK], DatanodeInfoWithStorage[127.0.0.1:35692,DS-39408674-6fd5-4527-b987-368fce042d18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1337917817-172.17.0.14-1595368242104:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35198,DS-75efc4c5-f8c4-4c7b-9f05-d037055232b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39591,DS-189c69dc-d093-4fd5-8435-080aa6a37971,DISK], DatanodeInfoWithStorage[127.0.0.1:40782,DS-f0c5a28e-2be4-4177-ba6d-38c53c5fa6c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35943,DS-6f4bf68c-52ab-4582-b2ab-d6c5dbca8984,DISK], DatanodeInfoWithStorage[127.0.0.1:39733,DS-52cf9cb4-d42d-4ce0-b370-3ae925e115cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38419,DS-08d14b59-e5ae-49f4-9cce-21daa7a2c01c,DISK], DatanodeInfoWithStorage[127.0.0.1:35402,DS-73d195fe-1569-44c0-8f1f-902a4b8ebdc6,DISK], DatanodeInfoWithStorage[127.0.0.1:36665,DS-72a6a596-b6fb-4916-9f57-640a6b5cc20e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1337917817-172.17.0.14-1595368242104:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35198,DS-75efc4c5-f8c4-4c7b-9f05-d037055232b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39591,DS-189c69dc-d093-4fd5-8435-080aa6a37971,DISK], DatanodeInfoWithStorage[127.0.0.1:40782,DS-f0c5a28e-2be4-4177-ba6d-38c53c5fa6c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35943,DS-6f4bf68c-52ab-4582-b2ab-d6c5dbca8984,DISK], DatanodeInfoWithStorage[127.0.0.1:39733,DS-52cf9cb4-d42d-4ce0-b370-3ae925e115cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38419,DS-08d14b59-e5ae-49f4-9cce-21daa7a2c01c,DISK], DatanodeInfoWithStorage[127.0.0.1:35402,DS-73d195fe-1569-44c0-8f1f-902a4b8ebdc6,DISK], DatanodeInfoWithStorage[127.0.0.1:36665,DS-72a6a596-b6fb-4916-9f57-640a6b5cc20e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-910313911-172.17.0.14-1595368863492:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34724,DS-990b6056-9659-4937-a3bf-1d3b3ed01a36,DISK], DatanodeInfoWithStorage[127.0.0.1:36426,DS-08587d4d-21a3-40b5-bc75-e218e8ffa24c,DISK], DatanodeInfoWithStorage[127.0.0.1:39739,DS-48f000f9-7777-48d0-9faa-151244626aa4,DISK], DatanodeInfoWithStorage[127.0.0.1:44291,DS-d7d9bd44-4dce-40c7-aafc-5c4f84461609,DISK], DatanodeInfoWithStorage[127.0.0.1:45064,DS-284e7445-e45b-4d63-95c3-05fdf71153eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40682,DS-a171b8fe-28ed-4e47-9fb9-01cdf6ce0151,DISK], DatanodeInfoWithStorage[127.0.0.1:44704,DS-8ea64c40-5061-4cf2-b5b4-767c432d8457,DISK], DatanodeInfoWithStorage[127.0.0.1:46036,DS-19558ca8-e6c5-448f-ae80-64a1255f642c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-910313911-172.17.0.14-1595368863492:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34724,DS-990b6056-9659-4937-a3bf-1d3b3ed01a36,DISK], DatanodeInfoWithStorage[127.0.0.1:36426,DS-08587d4d-21a3-40b5-bc75-e218e8ffa24c,DISK], DatanodeInfoWithStorage[127.0.0.1:39739,DS-48f000f9-7777-48d0-9faa-151244626aa4,DISK], DatanodeInfoWithStorage[127.0.0.1:44291,DS-d7d9bd44-4dce-40c7-aafc-5c4f84461609,DISK], DatanodeInfoWithStorage[127.0.0.1:45064,DS-284e7445-e45b-4d63-95c3-05fdf71153eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40682,DS-a171b8fe-28ed-4e47-9fb9-01cdf6ce0151,DISK], DatanodeInfoWithStorage[127.0.0.1:44704,DS-8ea64c40-5061-4cf2-b5b4-767c432d8457,DISK], DatanodeInfoWithStorage[127.0.0.1:46036,DS-19558ca8-e6c5-448f-ae80-64a1255f642c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1690766649-172.17.0.14-1595369359166:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33989,DS-bf8eb388-deb4-45c1-afb9-2b6664f8199d,DISK], DatanodeInfoWithStorage[127.0.0.1:33265,DS-cd5b0ded-4f54-4f93-9c75-f3999f4b6587,DISK], DatanodeInfoWithStorage[127.0.0.1:40799,DS-90f170db-002f-4a80-876b-31ab82945028,DISK], DatanodeInfoWithStorage[127.0.0.1:37384,DS-a21e99c1-f89f-480c-bf17-2bef6f3b1526,DISK], DatanodeInfoWithStorage[127.0.0.1:42440,DS-3e3dd6f3-cc20-41b7-b6df-6492db6589ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41216,DS-5444c873-976f-405a-8e40-866934daaa7f,DISK], DatanodeInfoWithStorage[127.0.0.1:43384,DS-fc261e2b-57c5-4e3f-82cd-e97010f22a4c,DISK], DatanodeInfoWithStorage[127.0.0.1:36933,DS-283cefcc-cb9e-47ec-97d7-af56800c48d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1690766649-172.17.0.14-1595369359166:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33989,DS-bf8eb388-deb4-45c1-afb9-2b6664f8199d,DISK], DatanodeInfoWithStorage[127.0.0.1:33265,DS-cd5b0ded-4f54-4f93-9c75-f3999f4b6587,DISK], DatanodeInfoWithStorage[127.0.0.1:40799,DS-90f170db-002f-4a80-876b-31ab82945028,DISK], DatanodeInfoWithStorage[127.0.0.1:37384,DS-a21e99c1-f89f-480c-bf17-2bef6f3b1526,DISK], DatanodeInfoWithStorage[127.0.0.1:42440,DS-3e3dd6f3-cc20-41b7-b6df-6492db6589ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41216,DS-5444c873-976f-405a-8e40-866934daaa7f,DISK], DatanodeInfoWithStorage[127.0.0.1:43384,DS-fc261e2b-57c5-4e3f-82cd-e97010f22a4c,DISK], DatanodeInfoWithStorage[127.0.0.1:36933,DS-283cefcc-cb9e-47ec-97d7-af56800c48d4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-255473096-172.17.0.14-1595369467827:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35620,DS-e01596ee-c0af-4698-97bf-251984ea4717,DISK], DatanodeInfoWithStorage[127.0.0.1:36016,DS-6e352c55-53ed-48b7-99b3-0c6c9bba8baf,DISK], DatanodeInfoWithStorage[127.0.0.1:46824,DS-3ca118f8-9a07-4ce8-9465-1aafe87faa3a,DISK], DatanodeInfoWithStorage[127.0.0.1:42675,DS-e2dbbd74-50ee-46a1-8312-aa0fc044a764,DISK], DatanodeInfoWithStorage[127.0.0.1:43390,DS-4a296a2e-a5e7-45f5-a508-7dbb0f735684,DISK], DatanodeInfoWithStorage[127.0.0.1:38613,DS-2fea3a49-4820-4606-b8d0-a6386d9656ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33132,DS-55d607e6-6e03-41b7-b5e0-dc08e97733b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41981,DS-890a6a18-6af9-4fcd-b190-c8273ac78ed4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-255473096-172.17.0.14-1595369467827:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35620,DS-e01596ee-c0af-4698-97bf-251984ea4717,DISK], DatanodeInfoWithStorage[127.0.0.1:36016,DS-6e352c55-53ed-48b7-99b3-0c6c9bba8baf,DISK], DatanodeInfoWithStorage[127.0.0.1:46824,DS-3ca118f8-9a07-4ce8-9465-1aafe87faa3a,DISK], DatanodeInfoWithStorage[127.0.0.1:42675,DS-e2dbbd74-50ee-46a1-8312-aa0fc044a764,DISK], DatanodeInfoWithStorage[127.0.0.1:43390,DS-4a296a2e-a5e7-45f5-a508-7dbb0f735684,DISK], DatanodeInfoWithStorage[127.0.0.1:38613,DS-2fea3a49-4820-4606-b8d0-a6386d9656ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33132,DS-55d607e6-6e03-41b7-b5e0-dc08e97733b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41981,DS-890a6a18-6af9-4fcd-b190-c8273ac78ed4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2022641883-172.17.0.14-1595369544429:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46082,DS-4f2d8459-9ff0-4e7c-baec-850fed6635a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38935,DS-d4f7f032-e605-4443-bfe0-cdab2219ce09,DISK], DatanodeInfoWithStorage[127.0.0.1:39115,DS-13707821-b2ab-4656-879f-f9724a11b155,DISK], DatanodeInfoWithStorage[127.0.0.1:34282,DS-265b7f4f-4788-4b76-86da-e4af042545a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34473,DS-e1fd5f17-6d1d-4f18-8522-26cdd05d91a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33047,DS-683c3cb9-e081-40b0-b2d4-84259611e7d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33332,DS-48d4a2d4-dd55-4418-bf79-9991d25efc4d,DISK], DatanodeInfoWithStorage[127.0.0.1:35322,DS-026de949-ccaf-49cb-99bb-58f39b2684a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2022641883-172.17.0.14-1595369544429:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46082,DS-4f2d8459-9ff0-4e7c-baec-850fed6635a0,DISK], DatanodeInfoWithStorage[127.0.0.1:38935,DS-d4f7f032-e605-4443-bfe0-cdab2219ce09,DISK], DatanodeInfoWithStorage[127.0.0.1:39115,DS-13707821-b2ab-4656-879f-f9724a11b155,DISK], DatanodeInfoWithStorage[127.0.0.1:34282,DS-265b7f4f-4788-4b76-86da-e4af042545a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34473,DS-e1fd5f17-6d1d-4f18-8522-26cdd05d91a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33047,DS-683c3cb9-e081-40b0-b2d4-84259611e7d8,DISK], DatanodeInfoWithStorage[127.0.0.1:33332,DS-48d4a2d4-dd55-4418-bf79-9991d25efc4d,DISK], DatanodeInfoWithStorage[127.0.0.1:35322,DS-026de949-ccaf-49cb-99bb-58f39b2684a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-490628620-172.17.0.14-1595369821975:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34402,DS-183ce522-33b2-4a35-b4c4-648fc6de8e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:38622,DS-b09cf003-2482-41b6-ab7d-dad601ab0903,DISK], DatanodeInfoWithStorage[127.0.0.1:37228,DS-974aff2d-39d3-4ab0-90e4-c217b3ee093e,DISK], DatanodeInfoWithStorage[127.0.0.1:41724,DS-0445eb11-949f-4580-b2e6-18a232641841,DISK], DatanodeInfoWithStorage[127.0.0.1:43383,DS-7ef75e03-b495-4887-bc84-6c381a0a34c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44029,DS-12f6f820-e958-4075-91c9-7c92d7e90e14,DISK], DatanodeInfoWithStorage[127.0.0.1:40694,DS-b7b11230-5dfe-4b38-a704-759d6dd4ca29,DISK], DatanodeInfoWithStorage[127.0.0.1:46603,DS-af6c3743-c6ad-445a-a471-b21b543924fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-490628620-172.17.0.14-1595369821975:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34402,DS-183ce522-33b2-4a35-b4c4-648fc6de8e2d,DISK], DatanodeInfoWithStorage[127.0.0.1:38622,DS-b09cf003-2482-41b6-ab7d-dad601ab0903,DISK], DatanodeInfoWithStorage[127.0.0.1:37228,DS-974aff2d-39d3-4ab0-90e4-c217b3ee093e,DISK], DatanodeInfoWithStorage[127.0.0.1:41724,DS-0445eb11-949f-4580-b2e6-18a232641841,DISK], DatanodeInfoWithStorage[127.0.0.1:43383,DS-7ef75e03-b495-4887-bc84-6c381a0a34c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44029,DS-12f6f820-e958-4075-91c9-7c92d7e90e14,DISK], DatanodeInfoWithStorage[127.0.0.1:40694,DS-b7b11230-5dfe-4b38-a704-759d6dd4ca29,DISK], DatanodeInfoWithStorage[127.0.0.1:46603,DS-af6c3743-c6ad-445a-a471-b21b543924fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-836130831-172.17.0.14-1595370492819:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35266,DS-ec042211-64cb-4c98-9f4c-71c6d57b893d,DISK], DatanodeInfoWithStorage[127.0.0.1:40581,DS-2c103030-d09b-45c1-a38f-3f0dffa13144,DISK], DatanodeInfoWithStorage[127.0.0.1:36307,DS-41597f34-0cb0-493c-9c66-63b10ffcc049,DISK], DatanodeInfoWithStorage[127.0.0.1:37578,DS-fe784467-666b-4a90-9f03-b1bb2d141245,DISK], DatanodeInfoWithStorage[127.0.0.1:34109,DS-b71e8fc3-aa93-4667-b0a2-db621a6e5580,DISK], DatanodeInfoWithStorage[127.0.0.1:41942,DS-278d073e-5906-414f-9eb3-9f6f8c8334d2,DISK], DatanodeInfoWithStorage[127.0.0.1:33764,DS-0383d2a2-0cf2-4c43-8e7f-c7ddeda3e66f,DISK], DatanodeInfoWithStorage[127.0.0.1:33741,DS-064b9a72-4c9e-4048-83a5-e9a58b1548ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-836130831-172.17.0.14-1595370492819:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35266,DS-ec042211-64cb-4c98-9f4c-71c6d57b893d,DISK], DatanodeInfoWithStorage[127.0.0.1:40581,DS-2c103030-d09b-45c1-a38f-3f0dffa13144,DISK], DatanodeInfoWithStorage[127.0.0.1:36307,DS-41597f34-0cb0-493c-9c66-63b10ffcc049,DISK], DatanodeInfoWithStorage[127.0.0.1:37578,DS-fe784467-666b-4a90-9f03-b1bb2d141245,DISK], DatanodeInfoWithStorage[127.0.0.1:34109,DS-b71e8fc3-aa93-4667-b0a2-db621a6e5580,DISK], DatanodeInfoWithStorage[127.0.0.1:41942,DS-278d073e-5906-414f-9eb3-9f6f8c8334d2,DISK], DatanodeInfoWithStorage[127.0.0.1:33764,DS-0383d2a2-0cf2-4c43-8e7f-c7ddeda3e66f,DISK], DatanodeInfoWithStorage[127.0.0.1:33741,DS-064b9a72-4c9e-4048-83a5-e9a58b1548ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-869308664-172.17.0.14-1595370528267:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44046,DS-d7ee65ab-bf70-45c8-9fd3-8185decec8e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34257,DS-ba2b4799-cf97-42c9-91ae-2ca849ca0e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:36203,DS-ac4e5fe5-0f70-4c8e-9a9f-78262fa128c0,DISK], DatanodeInfoWithStorage[127.0.0.1:44872,DS-b482d433-526b-42a4-8072-08d1e9609eef,DISK], DatanodeInfoWithStorage[127.0.0.1:46648,DS-6f1f15b7-0ead-496e-952c-206bc4511cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:41881,DS-81d6b13a-280a-4b5b-8def-f7f0f8f47e29,DISK], DatanodeInfoWithStorage[127.0.0.1:35383,DS-e6397fc6-a658-4b8f-8112-576272063545,DISK], DatanodeInfoWithStorage[127.0.0.1:35236,DS-8a604b4e-f7bd-41fc-96fc-42c6b7dc64d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-869308664-172.17.0.14-1595370528267:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44046,DS-d7ee65ab-bf70-45c8-9fd3-8185decec8e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34257,DS-ba2b4799-cf97-42c9-91ae-2ca849ca0e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:36203,DS-ac4e5fe5-0f70-4c8e-9a9f-78262fa128c0,DISK], DatanodeInfoWithStorage[127.0.0.1:44872,DS-b482d433-526b-42a4-8072-08d1e9609eef,DISK], DatanodeInfoWithStorage[127.0.0.1:46648,DS-6f1f15b7-0ead-496e-952c-206bc4511cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:41881,DS-81d6b13a-280a-4b5b-8def-f7f0f8f47e29,DISK], DatanodeInfoWithStorage[127.0.0.1:35383,DS-e6397fc6-a658-4b8f-8112-576272063545,DISK], DatanodeInfoWithStorage[127.0.0.1:35236,DS-8a604b4e-f7bd-41fc-96fc-42c6b7dc64d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-470863842-172.17.0.14-1595370564251:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46551,DS-9675ae56-e67e-49e9-90b9-993bad0d5928,DISK], DatanodeInfoWithStorage[127.0.0.1:33293,DS-34e84507-6c9a-4b73-8b94-cc589baa41ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37273,DS-5e262443-3380-4ae2-82ae-bb5390506160,DISK], DatanodeInfoWithStorage[127.0.0.1:34262,DS-30028b1c-9fa7-4fff-8e82-0acdad495852,DISK], DatanodeInfoWithStorage[127.0.0.1:33408,DS-e18bf735-0c58-4322-a519-0cd0bd0495ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37691,DS-5232ae7a-ce4b-4abb-82a5-6c7e92ee2b82,DISK], DatanodeInfoWithStorage[127.0.0.1:44800,DS-ee7c357b-25a3-4e97-90fb-97a41c346bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:35564,DS-3afaaea6-562d-4cde-85c0-07bfb02c56db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-470863842-172.17.0.14-1595370564251:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46551,DS-9675ae56-e67e-49e9-90b9-993bad0d5928,DISK], DatanodeInfoWithStorage[127.0.0.1:33293,DS-34e84507-6c9a-4b73-8b94-cc589baa41ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37273,DS-5e262443-3380-4ae2-82ae-bb5390506160,DISK], DatanodeInfoWithStorage[127.0.0.1:34262,DS-30028b1c-9fa7-4fff-8e82-0acdad495852,DISK], DatanodeInfoWithStorage[127.0.0.1:33408,DS-e18bf735-0c58-4322-a519-0cd0bd0495ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37691,DS-5232ae7a-ce4b-4abb-82a5-6c7e92ee2b82,DISK], DatanodeInfoWithStorage[127.0.0.1:44800,DS-ee7c357b-25a3-4e97-90fb-97a41c346bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:35564,DS-3afaaea6-562d-4cde-85c0-07bfb02c56db,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-712983228-172.17.0.14-1595370592755:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34757,DS-c268dfa9-a78f-4add-b20d-15d102bfc679,DISK], DatanodeInfoWithStorage[127.0.0.1:40180,DS-de88c4c2-18c1-4787-a8fa-977e12d86c25,DISK], DatanodeInfoWithStorage[127.0.0.1:32811,DS-2a5ff47b-06c7-419b-ad0c-b892136b0e82,DISK], DatanodeInfoWithStorage[127.0.0.1:35825,DS-43c151ec-fd2a-4db6-85fb-c70d78bd893e,DISK], DatanodeInfoWithStorage[127.0.0.1:40023,DS-7adf1d6f-7c01-4f16-a702-d45229b79b3a,DISK], DatanodeInfoWithStorage[127.0.0.1:45797,DS-ddf2e5ca-1a5d-4b38-b3db-fa603a0ea344,DISK], DatanodeInfoWithStorage[127.0.0.1:45222,DS-e1b8ab59-fb15-4b55-80e3-b7f42a2d121f,DISK], DatanodeInfoWithStorage[127.0.0.1:45150,DS-60ef5fb9-3b1d-43df-8fde-1b9c053f493e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-712983228-172.17.0.14-1595370592755:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34757,DS-c268dfa9-a78f-4add-b20d-15d102bfc679,DISK], DatanodeInfoWithStorage[127.0.0.1:40180,DS-de88c4c2-18c1-4787-a8fa-977e12d86c25,DISK], DatanodeInfoWithStorage[127.0.0.1:32811,DS-2a5ff47b-06c7-419b-ad0c-b892136b0e82,DISK], DatanodeInfoWithStorage[127.0.0.1:35825,DS-43c151ec-fd2a-4db6-85fb-c70d78bd893e,DISK], DatanodeInfoWithStorage[127.0.0.1:40023,DS-7adf1d6f-7c01-4f16-a702-d45229b79b3a,DISK], DatanodeInfoWithStorage[127.0.0.1:45797,DS-ddf2e5ca-1a5d-4b38-b3db-fa603a0ea344,DISK], DatanodeInfoWithStorage[127.0.0.1:45222,DS-e1b8ab59-fb15-4b55-80e3-b7f42a2d121f,DISK], DatanodeInfoWithStorage[127.0.0.1:45150,DS-60ef5fb9-3b1d-43df-8fde-1b9c053f493e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-339555557-172.17.0.14-1595370900038:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39338,DS-ff849b33-5974-42a9-b7e7-32f59c35dfaa,DISK], DatanodeInfoWithStorage[127.0.0.1:41770,DS-ded7eaff-21dd-4eae-8013-77e3e1a6d1ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33483,DS-ab4c977b-6cbc-4f44-8586-660bd551e9a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36562,DS-fcf83674-d2e9-4550-b741-26bb15b9633e,DISK], DatanodeInfoWithStorage[127.0.0.1:36806,DS-d5b94057-2dd2-401d-b4fb-c24c8da77990,DISK], DatanodeInfoWithStorage[127.0.0.1:33024,DS-580998d1-5ad4-4620-861e-ec36f5c76aae,DISK], DatanodeInfoWithStorage[127.0.0.1:39411,DS-df56c124-cce7-4734-81ad-d476cb76a772,DISK], DatanodeInfoWithStorage[127.0.0.1:36118,DS-30500707-4a66-40c8-bbde-b99f20d8a9f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-339555557-172.17.0.14-1595370900038:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39338,DS-ff849b33-5974-42a9-b7e7-32f59c35dfaa,DISK], DatanodeInfoWithStorage[127.0.0.1:41770,DS-ded7eaff-21dd-4eae-8013-77e3e1a6d1ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33483,DS-ab4c977b-6cbc-4f44-8586-660bd551e9a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36562,DS-fcf83674-d2e9-4550-b741-26bb15b9633e,DISK], DatanodeInfoWithStorage[127.0.0.1:36806,DS-d5b94057-2dd2-401d-b4fb-c24c8da77990,DISK], DatanodeInfoWithStorage[127.0.0.1:33024,DS-580998d1-5ad4-4620-861e-ec36f5c76aae,DISK], DatanodeInfoWithStorage[127.0.0.1:39411,DS-df56c124-cce7-4734-81ad-d476cb76a772,DISK], DatanodeInfoWithStorage[127.0.0.1:36118,DS-30500707-4a66-40c8-bbde-b99f20d8a9f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2140931044-172.17.0.14-1595370999646:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39205,DS-eb59023a-64b5-40f0-b147-715c717ca152,DISK], DatanodeInfoWithStorage[127.0.0.1:37383,DS-aadd01ed-9d12-42b4-a07a-27c09eb7c92e,DISK], DatanodeInfoWithStorage[127.0.0.1:44264,DS-c8f38c16-d188-4c7f-9b0a-4919d71959bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43943,DS-6711ebe0-61ca-4167-a8ad-51c4052fd4a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37965,DS-b1e3a91f-7fb9-4c9a-9bca-b77927bc9d70,DISK], DatanodeInfoWithStorage[127.0.0.1:36176,DS-32017400-0ddc-4dde-a52c-bcbc81770392,DISK], DatanodeInfoWithStorage[127.0.0.1:44157,DS-17098904-5bb0-4a26-a3d1-ab78eb34d55a,DISK], DatanodeInfoWithStorage[127.0.0.1:35246,DS-0e49ec79-4bdb-41a4-9854-9d433e112d85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2140931044-172.17.0.14-1595370999646:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39205,DS-eb59023a-64b5-40f0-b147-715c717ca152,DISK], DatanodeInfoWithStorage[127.0.0.1:37383,DS-aadd01ed-9d12-42b4-a07a-27c09eb7c92e,DISK], DatanodeInfoWithStorage[127.0.0.1:44264,DS-c8f38c16-d188-4c7f-9b0a-4919d71959bd,DISK], DatanodeInfoWithStorage[127.0.0.1:43943,DS-6711ebe0-61ca-4167-a8ad-51c4052fd4a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37965,DS-b1e3a91f-7fb9-4c9a-9bca-b77927bc9d70,DISK], DatanodeInfoWithStorage[127.0.0.1:36176,DS-32017400-0ddc-4dde-a52c-bcbc81770392,DISK], DatanodeInfoWithStorage[127.0.0.1:44157,DS-17098904-5bb0-4a26-a3d1-ab78eb34d55a,DISK], DatanodeInfoWithStorage[127.0.0.1:35246,DS-0e49ec79-4bdb-41a4-9854-9d433e112d85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-831051345-172.17.0.14-1595371203488:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36204,DS-51c5e1ad-200f-49bd-934f-dfce0fc9b611,DISK], DatanodeInfoWithStorage[127.0.0.1:40257,DS-6136a4bb-1f64-4b4e-8b0f-aad20fa870f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39203,DS-710d5285-7596-4b9a-af44-bfca2846e30b,DISK], DatanodeInfoWithStorage[127.0.0.1:42981,DS-8b7c4eeb-327b-4dbb-968f-4c929b8c5604,DISK], DatanodeInfoWithStorage[127.0.0.1:34281,DS-7ca405bd-f1aa-45ca-b5d3-247bc6f6908e,DISK], DatanodeInfoWithStorage[127.0.0.1:33909,DS-2c70bd31-f54a-448f-8e6e-5b01b8feadbc,DISK], DatanodeInfoWithStorage[127.0.0.1:36910,DS-39ae4451-24d7-444c-976b-d0d43c3d4660,DISK], DatanodeInfoWithStorage[127.0.0.1:43994,DS-05ef3c7b-2580-4b1b-9fc7-02b80fdfc713,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-831051345-172.17.0.14-1595371203488:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36204,DS-51c5e1ad-200f-49bd-934f-dfce0fc9b611,DISK], DatanodeInfoWithStorage[127.0.0.1:40257,DS-6136a4bb-1f64-4b4e-8b0f-aad20fa870f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39203,DS-710d5285-7596-4b9a-af44-bfca2846e30b,DISK], DatanodeInfoWithStorage[127.0.0.1:42981,DS-8b7c4eeb-327b-4dbb-968f-4c929b8c5604,DISK], DatanodeInfoWithStorage[127.0.0.1:34281,DS-7ca405bd-f1aa-45ca-b5d3-247bc6f6908e,DISK], DatanodeInfoWithStorage[127.0.0.1:33909,DS-2c70bd31-f54a-448f-8e6e-5b01b8feadbc,DISK], DatanodeInfoWithStorage[127.0.0.1:36910,DS-39ae4451-24d7-444c-976b-d0d43c3d4660,DISK], DatanodeInfoWithStorage[127.0.0.1:43994,DS-05ef3c7b-2580-4b1b-9fc7-02b80fdfc713,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1403304527-172.17.0.14-1595371278471:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39144,DS-055abf00-d5df-494d-8b5e-d54222a7c701,DISK], DatanodeInfoWithStorage[127.0.0.1:46092,DS-3d8a774e-ad6a-4a65-89c0-3d55ba9091de,DISK], DatanodeInfoWithStorage[127.0.0.1:36741,DS-697a3dfb-6e19-4695-b3b7-2dbf21e986bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43790,DS-11e5f253-89ca-43bd-9c52-4852a89e4152,DISK], DatanodeInfoWithStorage[127.0.0.1:45861,DS-eb74b452-7c9a-4333-a562-4beddd02991f,DISK], DatanodeInfoWithStorage[127.0.0.1:41714,DS-b70c4269-9c19-4d13-905a-166093598b68,DISK], DatanodeInfoWithStorage[127.0.0.1:46145,DS-2cac00d4-74b0-4b8c-9701-15b77de5dfc0,DISK], DatanodeInfoWithStorage[127.0.0.1:41372,DS-6dc4fd17-9f00-41c8-a46e-c18215a3e301,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1403304527-172.17.0.14-1595371278471:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39144,DS-055abf00-d5df-494d-8b5e-d54222a7c701,DISK], DatanodeInfoWithStorage[127.0.0.1:46092,DS-3d8a774e-ad6a-4a65-89c0-3d55ba9091de,DISK], DatanodeInfoWithStorage[127.0.0.1:36741,DS-697a3dfb-6e19-4695-b3b7-2dbf21e986bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43790,DS-11e5f253-89ca-43bd-9c52-4852a89e4152,DISK], DatanodeInfoWithStorage[127.0.0.1:45861,DS-eb74b452-7c9a-4333-a562-4beddd02991f,DISK], DatanodeInfoWithStorage[127.0.0.1:41714,DS-b70c4269-9c19-4d13-905a-166093598b68,DISK], DatanodeInfoWithStorage[127.0.0.1:46145,DS-2cac00d4-74b0-4b8c-9701-15b77de5dfc0,DISK], DatanodeInfoWithStorage[127.0.0.1:41372,DS-6dc4fd17-9f00-41c8-a46e-c18215a3e301,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1465837604-172.17.0.14-1595371383176:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37044,DS-bd40885a-4731-42f0-9026-37225387353e,DISK], DatanodeInfoWithStorage[127.0.0.1:45539,DS-7969a5b5-dd5c-4988-bdb3-705100f2f32a,DISK], DatanodeInfoWithStorage[127.0.0.1:43796,DS-f2ee54e0-ae9b-4504-a9b3-26b82f1a958e,DISK], DatanodeInfoWithStorage[127.0.0.1:44911,DS-f25f09b9-4e67-4ec3-bdfc-4e8e0e62735b,DISK], DatanodeInfoWithStorage[127.0.0.1:34812,DS-ebde9b44-c21d-47e4-a35a-49a9355af342,DISK], DatanodeInfoWithStorage[127.0.0.1:39688,DS-2b64f7b5-5d42-4f92-8850-fcd89ae136d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41928,DS-5f935798-d7db-4743-89d3-436c47d6bef1,DISK], DatanodeInfoWithStorage[127.0.0.1:43847,DS-cc43b943-ca49-43c5-91d5-e255ab257121,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1465837604-172.17.0.14-1595371383176:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37044,DS-bd40885a-4731-42f0-9026-37225387353e,DISK], DatanodeInfoWithStorage[127.0.0.1:45539,DS-7969a5b5-dd5c-4988-bdb3-705100f2f32a,DISK], DatanodeInfoWithStorage[127.0.0.1:43796,DS-f2ee54e0-ae9b-4504-a9b3-26b82f1a958e,DISK], DatanodeInfoWithStorage[127.0.0.1:44911,DS-f25f09b9-4e67-4ec3-bdfc-4e8e0e62735b,DISK], DatanodeInfoWithStorage[127.0.0.1:34812,DS-ebde9b44-c21d-47e4-a35a-49a9355af342,DISK], DatanodeInfoWithStorage[127.0.0.1:39688,DS-2b64f7b5-5d42-4f92-8850-fcd89ae136d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41928,DS-5f935798-d7db-4743-89d3-436c47d6bef1,DISK], DatanodeInfoWithStorage[127.0.0.1:43847,DS-cc43b943-ca49-43c5-91d5-e255ab257121,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-303763765-172.17.0.14-1595371416385:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35274,DS-81bdd7fd-3b83-4739-835f-5a2f57f010fe,DISK], DatanodeInfoWithStorage[127.0.0.1:40774,DS-9d8cd936-c2e3-455f-ae05-52f6e34d043c,DISK], DatanodeInfoWithStorage[127.0.0.1:44994,DS-48b4195d-11b4-421b-9bc6-6b4360e9070a,DISK], DatanodeInfoWithStorage[127.0.0.1:37509,DS-e8ef08fe-ba3d-40f5-bb89-6d5dcc1975b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44329,DS-7a43fbc4-d881-4031-ad70-529ec54c3ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:36042,DS-33f0769a-b0fa-44b0-82ac-6d613729bc4a,DISK], DatanodeInfoWithStorage[127.0.0.1:41510,DS-fef1dde1-e751-4ba3-975b-bc7516f79539,DISK], DatanodeInfoWithStorage[127.0.0.1:33786,DS-6a0bfe88-ff67-48f0-94c9-606ec74f9633,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-303763765-172.17.0.14-1595371416385:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35274,DS-81bdd7fd-3b83-4739-835f-5a2f57f010fe,DISK], DatanodeInfoWithStorage[127.0.0.1:40774,DS-9d8cd936-c2e3-455f-ae05-52f6e34d043c,DISK], DatanodeInfoWithStorage[127.0.0.1:44994,DS-48b4195d-11b4-421b-9bc6-6b4360e9070a,DISK], DatanodeInfoWithStorage[127.0.0.1:37509,DS-e8ef08fe-ba3d-40f5-bb89-6d5dcc1975b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44329,DS-7a43fbc4-d881-4031-ad70-529ec54c3ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:36042,DS-33f0769a-b0fa-44b0-82ac-6d613729bc4a,DISK], DatanodeInfoWithStorage[127.0.0.1:41510,DS-fef1dde1-e751-4ba3-975b-bc7516f79539,DISK], DatanodeInfoWithStorage[127.0.0.1:33786,DS-6a0bfe88-ff67-48f0-94c9-606ec74f9633,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-108806331-172.17.0.14-1595371450685:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32868,DS-7d007eb6-ebb2-4e78-9836-9698ce9204b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37138,DS-514b1d35-1874-4818-a7fb-f0ddf4b3bef0,DISK], DatanodeInfoWithStorage[127.0.0.1:39741,DS-09bec44f-d2bb-469e-a5a6-f3b8bfe8ca5f,DISK], DatanodeInfoWithStorage[127.0.0.1:33630,DS-ff01e99f-db42-46d0-ba0d-b2ba91779f61,DISK], DatanodeInfoWithStorage[127.0.0.1:42869,DS-7bb7437e-7452-46f8-979e-1c9c55a0e0b7,DISK], DatanodeInfoWithStorage[127.0.0.1:42319,DS-c911ec04-7678-4c4b-b71d-5b4e23705178,DISK], DatanodeInfoWithStorage[127.0.0.1:41149,DS-a0890a68-4130-4f62-aa63-946c792cdd64,DISK], DatanodeInfoWithStorage[127.0.0.1:33789,DS-5ab1d789-0624-49ec-8dbb-2be4c16b98ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-108806331-172.17.0.14-1595371450685:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32868,DS-7d007eb6-ebb2-4e78-9836-9698ce9204b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37138,DS-514b1d35-1874-4818-a7fb-f0ddf4b3bef0,DISK], DatanodeInfoWithStorage[127.0.0.1:39741,DS-09bec44f-d2bb-469e-a5a6-f3b8bfe8ca5f,DISK], DatanodeInfoWithStorage[127.0.0.1:33630,DS-ff01e99f-db42-46d0-ba0d-b2ba91779f61,DISK], DatanodeInfoWithStorage[127.0.0.1:42869,DS-7bb7437e-7452-46f8-979e-1c9c55a0e0b7,DISK], DatanodeInfoWithStorage[127.0.0.1:42319,DS-c911ec04-7678-4c4b-b71d-5b4e23705178,DISK], DatanodeInfoWithStorage[127.0.0.1:41149,DS-a0890a68-4130-4f62-aa63-946c792cdd64,DISK], DatanodeInfoWithStorage[127.0.0.1:33789,DS-5ab1d789-0624-49ec-8dbb-2be4c16b98ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1008807614-172.17.0.14-1595371532320:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38615,DS-12c5f419-78e9-40b5-be54-019cc85d8ea9,DISK], DatanodeInfoWithStorage[127.0.0.1:35479,DS-5b8a1bf5-886f-422f-a175-cfed8579b13a,DISK], DatanodeInfoWithStorage[127.0.0.1:43976,DS-efbb80af-0541-4ddd-873c-33d2d5a771a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34482,DS-44b1ec33-24bb-41b9-8eb4-a6514863c08b,DISK], DatanodeInfoWithStorage[127.0.0.1:37971,DS-4564bd83-a276-485c-a826-b79e1b3baee1,DISK], DatanodeInfoWithStorage[127.0.0.1:36170,DS-a1789323-2e42-4074-a678-92ffd8a7d370,DISK], DatanodeInfoWithStorage[127.0.0.1:43838,DS-ca10cd7c-ef45-42ae-90fe-26c81e5af8a5,DISK], DatanodeInfoWithStorage[127.0.0.1:37434,DS-5715acfa-ccbc-4b6e-8480-eab99ad4ffa6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1008807614-172.17.0.14-1595371532320:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38615,DS-12c5f419-78e9-40b5-be54-019cc85d8ea9,DISK], DatanodeInfoWithStorage[127.0.0.1:35479,DS-5b8a1bf5-886f-422f-a175-cfed8579b13a,DISK], DatanodeInfoWithStorage[127.0.0.1:43976,DS-efbb80af-0541-4ddd-873c-33d2d5a771a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34482,DS-44b1ec33-24bb-41b9-8eb4-a6514863c08b,DISK], DatanodeInfoWithStorage[127.0.0.1:37971,DS-4564bd83-a276-485c-a826-b79e1b3baee1,DISK], DatanodeInfoWithStorage[127.0.0.1:36170,DS-a1789323-2e42-4074-a678-92ffd8a7d370,DISK], DatanodeInfoWithStorage[127.0.0.1:43838,DS-ca10cd7c-ef45-42ae-90fe-26c81e5af8a5,DISK], DatanodeInfoWithStorage[127.0.0.1:37434,DS-5715acfa-ccbc-4b6e-8480-eab99ad4ffa6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2143272730-172.17.0.14-1595372095522:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45623,DS-f2d66b31-3f83-4f54-b439-0fb1cb1efa70,DISK], DatanodeInfoWithStorage[127.0.0.1:33153,DS-e3f1a4d1-4e4e-4940-bde1-bbfaed875b32,DISK], DatanodeInfoWithStorage[127.0.0.1:33200,DS-98f37e95-7de5-4b43-a158-f7204b83a0b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42940,DS-caa60551-b765-4963-ab54-d408e3fb556d,DISK], DatanodeInfoWithStorage[127.0.0.1:36045,DS-bf917d42-9d9a-4496-8408-53e933a06d78,DISK], DatanodeInfoWithStorage[127.0.0.1:44841,DS-1f2a9e51-8426-492b-b92b-a3797c37fc6b,DISK], DatanodeInfoWithStorage[127.0.0.1:34656,DS-e322797f-5539-4b1d-8af5-386bb9a6b76d,DISK], DatanodeInfoWithStorage[127.0.0.1:46714,DS-df0b4150-0297-4369-b959-4dbfed606bad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2143272730-172.17.0.14-1595372095522:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45623,DS-f2d66b31-3f83-4f54-b439-0fb1cb1efa70,DISK], DatanodeInfoWithStorage[127.0.0.1:33153,DS-e3f1a4d1-4e4e-4940-bde1-bbfaed875b32,DISK], DatanodeInfoWithStorage[127.0.0.1:33200,DS-98f37e95-7de5-4b43-a158-f7204b83a0b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42940,DS-caa60551-b765-4963-ab54-d408e3fb556d,DISK], DatanodeInfoWithStorage[127.0.0.1:36045,DS-bf917d42-9d9a-4496-8408-53e933a06d78,DISK], DatanodeInfoWithStorage[127.0.0.1:44841,DS-1f2a9e51-8426-492b-b92b-a3797c37fc6b,DISK], DatanodeInfoWithStorage[127.0.0.1:34656,DS-e322797f-5539-4b1d-8af5-386bb9a6b76d,DISK], DatanodeInfoWithStorage[127.0.0.1:46714,DS-df0b4150-0297-4369-b959-4dbfed606bad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-800520805-172.17.0.14-1595372199009:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41746,DS-89742367-d98c-4060-ab42-ace7003f243c,DISK], DatanodeInfoWithStorage[127.0.0.1:34169,DS-e8174267-8c4c-4257-a72b-09ef2703b27d,DISK], DatanodeInfoWithStorage[127.0.0.1:38119,DS-249dea27-0ab8-40d1-b467-e39e9bf3fe3d,DISK], DatanodeInfoWithStorage[127.0.0.1:41230,DS-d2d9cead-7bd4-46a4-82f6-dd30072b44a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35718,DS-db6320ca-0dc3-40a1-b417-dbb6ddbe1af4,DISK], DatanodeInfoWithStorage[127.0.0.1:45747,DS-b480db8c-9556-47d6-bc05-780ff055596f,DISK], DatanodeInfoWithStorage[127.0.0.1:35214,DS-cd0cc839-cf44-4332-b1f0-03e561d24f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:36412,DS-761eaa5a-da35-47d9-8a74-1fff8b1bd886,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-800520805-172.17.0.14-1595372199009:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41746,DS-89742367-d98c-4060-ab42-ace7003f243c,DISK], DatanodeInfoWithStorage[127.0.0.1:34169,DS-e8174267-8c4c-4257-a72b-09ef2703b27d,DISK], DatanodeInfoWithStorage[127.0.0.1:38119,DS-249dea27-0ab8-40d1-b467-e39e9bf3fe3d,DISK], DatanodeInfoWithStorage[127.0.0.1:41230,DS-d2d9cead-7bd4-46a4-82f6-dd30072b44a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35718,DS-db6320ca-0dc3-40a1-b417-dbb6ddbe1af4,DISK], DatanodeInfoWithStorage[127.0.0.1:45747,DS-b480db8c-9556-47d6-bc05-780ff055596f,DISK], DatanodeInfoWithStorage[127.0.0.1:35214,DS-cd0cc839-cf44-4332-b1f0-03e561d24f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:36412,DS-761eaa5a-da35-47d9-8a74-1fff8b1bd886,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-574712359-172.17.0.14-1595372296762:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42139,DS-319234ed-a6fc-4787-b1d7-9c62e681af30,DISK], DatanodeInfoWithStorage[127.0.0.1:40983,DS-fc8d6a12-f8d3-445b-b14b-158c278790c4,DISK], DatanodeInfoWithStorage[127.0.0.1:37950,DS-27ff5e66-5407-4b34-8ecf-9470e1611a86,DISK], DatanodeInfoWithStorage[127.0.0.1:46364,DS-f5900c7e-ef60-41ba-ae6c-2ddf01082bda,DISK], DatanodeInfoWithStorage[127.0.0.1:33357,DS-5db39dd6-77fe-406a-ac89-0a774ed638d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40547,DS-ae40fef5-00db-4c5b-a6e6-f2beed0796b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43517,DS-840590f2-e34d-4fdf-95f3-ce7de581abeb,DISK], DatanodeInfoWithStorage[127.0.0.1:44197,DS-c934cded-1e11-47dd-92a3-72e4bb85e905,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-574712359-172.17.0.14-1595372296762:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42139,DS-319234ed-a6fc-4787-b1d7-9c62e681af30,DISK], DatanodeInfoWithStorage[127.0.0.1:40983,DS-fc8d6a12-f8d3-445b-b14b-158c278790c4,DISK], DatanodeInfoWithStorage[127.0.0.1:37950,DS-27ff5e66-5407-4b34-8ecf-9470e1611a86,DISK], DatanodeInfoWithStorage[127.0.0.1:46364,DS-f5900c7e-ef60-41ba-ae6c-2ddf01082bda,DISK], DatanodeInfoWithStorage[127.0.0.1:33357,DS-5db39dd6-77fe-406a-ac89-0a774ed638d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40547,DS-ae40fef5-00db-4c5b-a6e6-f2beed0796b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43517,DS-840590f2-e34d-4fdf-95f3-ce7de581abeb,DISK], DatanodeInfoWithStorage[127.0.0.1:44197,DS-c934cded-1e11-47dd-92a3-72e4bb85e905,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1051681572-172.17.0.14-1595372639270:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35750,DS-c5401240-29e9-4d45-82a5-25b18abd7079,DISK], DatanodeInfoWithStorage[127.0.0.1:44764,DS-7663cb55-f297-4d8e-918e-e79a11e59cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:42016,DS-d6cddbbf-82f3-436c-ae66-e3f2d420a2e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40758,DS-932c4a05-2455-4f91-a4de-0f941547751c,DISK], DatanodeInfoWithStorage[127.0.0.1:33499,DS-95983c71-d088-43b8-bba4-652c36fb9358,DISK], DatanodeInfoWithStorage[127.0.0.1:37081,DS-06ae88f6-f5a4-464e-aaf8-ef66c34fd61f,DISK], DatanodeInfoWithStorage[127.0.0.1:42546,DS-4d28f604-be5d-48a3-8b38-d2335e45563d,DISK], DatanodeInfoWithStorage[127.0.0.1:41652,DS-55623ffc-463a-467d-b20f-056b3921b2ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1051681572-172.17.0.14-1595372639270:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35750,DS-c5401240-29e9-4d45-82a5-25b18abd7079,DISK], DatanodeInfoWithStorage[127.0.0.1:44764,DS-7663cb55-f297-4d8e-918e-e79a11e59cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:42016,DS-d6cddbbf-82f3-436c-ae66-e3f2d420a2e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40758,DS-932c4a05-2455-4f91-a4de-0f941547751c,DISK], DatanodeInfoWithStorage[127.0.0.1:33499,DS-95983c71-d088-43b8-bba4-652c36fb9358,DISK], DatanodeInfoWithStorage[127.0.0.1:37081,DS-06ae88f6-f5a4-464e-aaf8-ef66c34fd61f,DISK], DatanodeInfoWithStorage[127.0.0.1:42546,DS-4d28f604-be5d-48a3-8b38-d2335e45563d,DISK], DatanodeInfoWithStorage[127.0.0.1:41652,DS-55623ffc-463a-467d-b20f-056b3921b2ab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 5223
