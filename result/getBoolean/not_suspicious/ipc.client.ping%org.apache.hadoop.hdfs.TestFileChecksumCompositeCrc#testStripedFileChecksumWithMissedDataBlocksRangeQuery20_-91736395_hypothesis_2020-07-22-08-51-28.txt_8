reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-910135120-172.17.0.5-1595408133797:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38718,DS-7f66ca52-bb5c-4236-b96f-805c98a09683,DISK], DatanodeInfoWithStorage[127.0.0.1:38314,DS-ace4d06d-0ade-4686-ac4c-365048ae7d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:45427,DS-b28f1e18-aae6-4646-a95a-acbeb9603ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:46446,DS-b15f5667-0401-4e57-ad09-3bcae98d5d8e,DISK], DatanodeInfoWithStorage[127.0.0.1:37840,DS-dc3e8b79-bdb7-47b5-9cfe-7242095ce6f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36587,DS-982db4a6-44ce-4a39-8f33-99d62c415c50,DISK], DatanodeInfoWithStorage[127.0.0.1:44584,DS-a9b8292f-707a-4788-8f41-513535037035,DISK], DatanodeInfoWithStorage[127.0.0.1:35647,DS-d163c5dd-997b-47f2-b214-c7a96fc18d2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-910135120-172.17.0.5-1595408133797:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38718,DS-7f66ca52-bb5c-4236-b96f-805c98a09683,DISK], DatanodeInfoWithStorage[127.0.0.1:38314,DS-ace4d06d-0ade-4686-ac4c-365048ae7d0b,DISK], DatanodeInfoWithStorage[127.0.0.1:45427,DS-b28f1e18-aae6-4646-a95a-acbeb9603ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:46446,DS-b15f5667-0401-4e57-ad09-3bcae98d5d8e,DISK], DatanodeInfoWithStorage[127.0.0.1:37840,DS-dc3e8b79-bdb7-47b5-9cfe-7242095ce6f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36587,DS-982db4a6-44ce-4a39-8f33-99d62c415c50,DISK], DatanodeInfoWithStorage[127.0.0.1:44584,DS-a9b8292f-707a-4788-8f41-513535037035,DISK], DatanodeInfoWithStorage[127.0.0.1:35647,DS-d163c5dd-997b-47f2-b214-c7a96fc18d2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-970002190-172.17.0.5-1595408266552:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38873,DS-d021f844-e95e-4dbd-a378-42a327c8fa02,DISK], DatanodeInfoWithStorage[127.0.0.1:37051,DS-8575e115-288b-4179-8885-91df905bae4b,DISK], DatanodeInfoWithStorage[127.0.0.1:43932,DS-37638f0e-a43d-4d92-b680-837911703829,DISK], DatanodeInfoWithStorage[127.0.0.1:32814,DS-734cc559-83dd-45bb-bcd8-42d383e078f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46331,DS-7023079e-c121-429f-a0e9-a0be80c37f40,DISK], DatanodeInfoWithStorage[127.0.0.1:38153,DS-2f803167-675c-4a66-a3ff-ede097a30235,DISK], DatanodeInfoWithStorage[127.0.0.1:45801,DS-560fcd17-56fb-4300-87be-69c46f91c85c,DISK], DatanodeInfoWithStorage[127.0.0.1:43863,DS-50231160-bff0-449c-8487-07557c82e726,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-970002190-172.17.0.5-1595408266552:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38873,DS-d021f844-e95e-4dbd-a378-42a327c8fa02,DISK], DatanodeInfoWithStorage[127.0.0.1:37051,DS-8575e115-288b-4179-8885-91df905bae4b,DISK], DatanodeInfoWithStorage[127.0.0.1:43932,DS-37638f0e-a43d-4d92-b680-837911703829,DISK], DatanodeInfoWithStorage[127.0.0.1:32814,DS-734cc559-83dd-45bb-bcd8-42d383e078f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46331,DS-7023079e-c121-429f-a0e9-a0be80c37f40,DISK], DatanodeInfoWithStorage[127.0.0.1:38153,DS-2f803167-675c-4a66-a3ff-ede097a30235,DISK], DatanodeInfoWithStorage[127.0.0.1:45801,DS-560fcd17-56fb-4300-87be-69c46f91c85c,DISK], DatanodeInfoWithStorage[127.0.0.1:43863,DS-50231160-bff0-449c-8487-07557c82e726,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-566227050-172.17.0.5-1595408475643:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37828,DS-03c61093-06bd-4896-9714-f85d20959d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:34105,DS-45a47bfc-01aa-4807-8fda-ccfad5aaffee,DISK], DatanodeInfoWithStorage[127.0.0.1:32981,DS-3d8a6e89-a9a8-41b9-a425-66139b7583a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40812,DS-9e070262-540d-4af2-a107-974504140467,DISK], DatanodeInfoWithStorage[127.0.0.1:38857,DS-55cd9a81-e5a6-48a9-a410-d5c679b5e7c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43859,DS-e3d17034-d30e-4538-b1c0-f67618f012af,DISK], DatanodeInfoWithStorage[127.0.0.1:43982,DS-9c4d3116-9567-4f55-b747-8b58d29a0dda,DISK], DatanodeInfoWithStorage[127.0.0.1:34862,DS-1a8bc5b6-9715-4ee7-bd44-9376f06fc6ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-566227050-172.17.0.5-1595408475643:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37828,DS-03c61093-06bd-4896-9714-f85d20959d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:34105,DS-45a47bfc-01aa-4807-8fda-ccfad5aaffee,DISK], DatanodeInfoWithStorage[127.0.0.1:32981,DS-3d8a6e89-a9a8-41b9-a425-66139b7583a3,DISK], DatanodeInfoWithStorage[127.0.0.1:40812,DS-9e070262-540d-4af2-a107-974504140467,DISK], DatanodeInfoWithStorage[127.0.0.1:38857,DS-55cd9a81-e5a6-48a9-a410-d5c679b5e7c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43859,DS-e3d17034-d30e-4538-b1c0-f67618f012af,DISK], DatanodeInfoWithStorage[127.0.0.1:43982,DS-9c4d3116-9567-4f55-b747-8b58d29a0dda,DISK], DatanodeInfoWithStorage[127.0.0.1:34862,DS-1a8bc5b6-9715-4ee7-bd44-9376f06fc6ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1449777733-172.17.0.5-1595408878573:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43625,DS-6e2cc93d-c907-46a8-bb0c-aa251e4afaa7,DISK], DatanodeInfoWithStorage[127.0.0.1:33568,DS-f7d3bda1-178f-4ab0-9f37-6e4dce2ea991,DISK], DatanodeInfoWithStorage[127.0.0.1:42532,DS-0f5ed12c-78f8-4c2c-ba60-36cf21374a2a,DISK], DatanodeInfoWithStorage[127.0.0.1:38414,DS-ee0827bf-55ff-449d-ae11-78b070178b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:38492,DS-7b37a68f-5ae4-4974-a4a9-489faf009619,DISK], DatanodeInfoWithStorage[127.0.0.1:40656,DS-512cd6cd-8f21-47f6-854e-1eaad7219dba,DISK], DatanodeInfoWithStorage[127.0.0.1:39269,DS-3f268ce0-9a2b-425d-ab2b-848a24505cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:34162,DS-ddca1862-7628-4d5e-8fb0-b2225060a582,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1449777733-172.17.0.5-1595408878573:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43625,DS-6e2cc93d-c907-46a8-bb0c-aa251e4afaa7,DISK], DatanodeInfoWithStorage[127.0.0.1:33568,DS-f7d3bda1-178f-4ab0-9f37-6e4dce2ea991,DISK], DatanodeInfoWithStorage[127.0.0.1:42532,DS-0f5ed12c-78f8-4c2c-ba60-36cf21374a2a,DISK], DatanodeInfoWithStorage[127.0.0.1:38414,DS-ee0827bf-55ff-449d-ae11-78b070178b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:38492,DS-7b37a68f-5ae4-4974-a4a9-489faf009619,DISK], DatanodeInfoWithStorage[127.0.0.1:40656,DS-512cd6cd-8f21-47f6-854e-1eaad7219dba,DISK], DatanodeInfoWithStorage[127.0.0.1:39269,DS-3f268ce0-9a2b-425d-ab2b-848a24505cc5,DISK], DatanodeInfoWithStorage[127.0.0.1:34162,DS-ddca1862-7628-4d5e-8fb0-b2225060a582,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1105313532-172.17.0.5-1595409242656:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33036,DS-65e88ad5-4ea4-4889-b4dd-1576616480f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37115,DS-092d97a7-2af2-4f9e-89f1-e5bfb01e228f,DISK], DatanodeInfoWithStorage[127.0.0.1:37212,DS-bb46e954-90a2-4d1d-8c66-834663562049,DISK], DatanodeInfoWithStorage[127.0.0.1:38588,DS-eb37a845-86f3-4892-af4d-d8bb8cb8302f,DISK], DatanodeInfoWithStorage[127.0.0.1:45312,DS-24aa9cdc-d904-40e8-8c50-763b8a1cb39a,DISK], DatanodeInfoWithStorage[127.0.0.1:33829,DS-e77fbdff-45d6-4244-81bc-fd2c504cf1ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34181,DS-23e41785-8cd7-4770-8ad9-4ae3a8b62860,DISK], DatanodeInfoWithStorage[127.0.0.1:34424,DS-5830063d-e2ac-488f-b0c7-2194a359704c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1105313532-172.17.0.5-1595409242656:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33036,DS-65e88ad5-4ea4-4889-b4dd-1576616480f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37115,DS-092d97a7-2af2-4f9e-89f1-e5bfb01e228f,DISK], DatanodeInfoWithStorage[127.0.0.1:37212,DS-bb46e954-90a2-4d1d-8c66-834663562049,DISK], DatanodeInfoWithStorage[127.0.0.1:38588,DS-eb37a845-86f3-4892-af4d-d8bb8cb8302f,DISK], DatanodeInfoWithStorage[127.0.0.1:45312,DS-24aa9cdc-d904-40e8-8c50-763b8a1cb39a,DISK], DatanodeInfoWithStorage[127.0.0.1:33829,DS-e77fbdff-45d6-4244-81bc-fd2c504cf1ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34181,DS-23e41785-8cd7-4770-8ad9-4ae3a8b62860,DISK], DatanodeInfoWithStorage[127.0.0.1:34424,DS-5830063d-e2ac-488f-b0c7-2194a359704c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2030089554-172.17.0.5-1595409339705:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40628,DS-1dd05335-d89c-41df-92ca-5a4f8760835f,DISK], DatanodeInfoWithStorage[127.0.0.1:40828,DS-2c93b144-b9fd-4488-a14d-7a756921286d,DISK], DatanodeInfoWithStorage[127.0.0.1:36620,DS-7551efa5-e7c6-4691-b3e9-143e35e543c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38867,DS-22371566-a0c8-450c-9e34-52cc4a977463,DISK], DatanodeInfoWithStorage[127.0.0.1:42979,DS-631a1e95-6a41-441e-ad07-89da714e08dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43172,DS-aa9af610-20c9-443b-bc3b-1ec1c19d0496,DISK], DatanodeInfoWithStorage[127.0.0.1:40382,DS-36df7ac3-1877-4571-b397-748229c807d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40788,DS-374ac173-7e86-4be2-b643-369ba46acce3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2030089554-172.17.0.5-1595409339705:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40628,DS-1dd05335-d89c-41df-92ca-5a4f8760835f,DISK], DatanodeInfoWithStorage[127.0.0.1:40828,DS-2c93b144-b9fd-4488-a14d-7a756921286d,DISK], DatanodeInfoWithStorage[127.0.0.1:36620,DS-7551efa5-e7c6-4691-b3e9-143e35e543c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38867,DS-22371566-a0c8-450c-9e34-52cc4a977463,DISK], DatanodeInfoWithStorage[127.0.0.1:42979,DS-631a1e95-6a41-441e-ad07-89da714e08dd,DISK], DatanodeInfoWithStorage[127.0.0.1:43172,DS-aa9af610-20c9-443b-bc3b-1ec1c19d0496,DISK], DatanodeInfoWithStorage[127.0.0.1:40382,DS-36df7ac3-1877-4571-b397-748229c807d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40788,DS-374ac173-7e86-4be2-b643-369ba46acce3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1660584153-172.17.0.5-1595409576890:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43931,DS-9abe1c6c-b554-4208-a42d-e749e392810e,DISK], DatanodeInfoWithStorage[127.0.0.1:33454,DS-be19f953-1aaa-4d65-8bff-1e4cc58f1c88,DISK], DatanodeInfoWithStorage[127.0.0.1:33701,DS-48004aab-9fe8-454d-8d10-20dd71b6826c,DISK], DatanodeInfoWithStorage[127.0.0.1:44459,DS-14230bf1-51bd-40a2-b8c0-5d79f0908768,DISK], DatanodeInfoWithStorage[127.0.0.1:40555,DS-b8de7685-2e7d-4d3e-b3f3-155e66ea55ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42203,DS-d79f8450-1f89-4179-b733-96d0b99e8025,DISK], DatanodeInfoWithStorage[127.0.0.1:42344,DS-5fbf1608-8cd4-4ab1-9754-e8c989654efb,DISK], DatanodeInfoWithStorage[127.0.0.1:39579,DS-0fc2c4b4-db0b-4193-b143-8c98b238602f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1660584153-172.17.0.5-1595409576890:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43931,DS-9abe1c6c-b554-4208-a42d-e749e392810e,DISK], DatanodeInfoWithStorage[127.0.0.1:33454,DS-be19f953-1aaa-4d65-8bff-1e4cc58f1c88,DISK], DatanodeInfoWithStorage[127.0.0.1:33701,DS-48004aab-9fe8-454d-8d10-20dd71b6826c,DISK], DatanodeInfoWithStorage[127.0.0.1:44459,DS-14230bf1-51bd-40a2-b8c0-5d79f0908768,DISK], DatanodeInfoWithStorage[127.0.0.1:40555,DS-b8de7685-2e7d-4d3e-b3f3-155e66ea55ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42203,DS-d79f8450-1f89-4179-b733-96d0b99e8025,DISK], DatanodeInfoWithStorage[127.0.0.1:42344,DS-5fbf1608-8cd4-4ab1-9754-e8c989654efb,DISK], DatanodeInfoWithStorage[127.0.0.1:39579,DS-0fc2c4b4-db0b-4193-b143-8c98b238602f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1914501305-172.17.0.5-1595409616077:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42374,DS-0e08d1e1-225e-45f2-9341-8a8583c82e76,DISK], DatanodeInfoWithStorage[127.0.0.1:44386,DS-bad664cc-f4c3-47ab-842a-9a3b997b70a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36669,DS-3db056ea-8991-48fe-8bb2-e88db24e7afe,DISK], DatanodeInfoWithStorage[127.0.0.1:33014,DS-cf8e27b7-a73c-448b-b2c1-801c7a8008d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40595,DS-f972ac90-6864-408d-a6ee-aceb3a50a68f,DISK], DatanodeInfoWithStorage[127.0.0.1:34519,DS-abd5169e-4633-415e-abe5-f82ff18fef32,DISK], DatanodeInfoWithStorage[127.0.0.1:41993,DS-5efa2260-4c22-4586-af62-ddbf1b828f65,DISK], DatanodeInfoWithStorage[127.0.0.1:35816,DS-df8f7ca6-599e-4705-91cb-2ab6cfa16513,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1914501305-172.17.0.5-1595409616077:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42374,DS-0e08d1e1-225e-45f2-9341-8a8583c82e76,DISK], DatanodeInfoWithStorage[127.0.0.1:44386,DS-bad664cc-f4c3-47ab-842a-9a3b997b70a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36669,DS-3db056ea-8991-48fe-8bb2-e88db24e7afe,DISK], DatanodeInfoWithStorage[127.0.0.1:33014,DS-cf8e27b7-a73c-448b-b2c1-801c7a8008d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40595,DS-f972ac90-6864-408d-a6ee-aceb3a50a68f,DISK], DatanodeInfoWithStorage[127.0.0.1:34519,DS-abd5169e-4633-415e-abe5-f82ff18fef32,DISK], DatanodeInfoWithStorage[127.0.0.1:41993,DS-5efa2260-4c22-4586-af62-ddbf1b828f65,DISK], DatanodeInfoWithStorage[127.0.0.1:35816,DS-df8f7ca6-599e-4705-91cb-2ab6cfa16513,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1135879053-172.17.0.5-1595409955897:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35493,DS-f23e1bba-130e-4847-8079-6b3980eb08bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38681,DS-db47c42b-2bb2-4e11-b896-9adbe3859720,DISK], DatanodeInfoWithStorage[127.0.0.1:45453,DS-263c6c3b-92c2-4c9c-93b9-f915c076f28e,DISK], DatanodeInfoWithStorage[127.0.0.1:33456,DS-41d236d3-be82-4f19-a33c-4772d421e853,DISK], DatanodeInfoWithStorage[127.0.0.1:46095,DS-34831913-1c17-40ab-b65c-3fd4984ca1a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43418,DS-be1c6a2b-beae-4f9a-8d10-c63dca2b9f31,DISK], DatanodeInfoWithStorage[127.0.0.1:42965,DS-9333cb7e-5d72-4cd2-8d07-9375c67d8a87,DISK], DatanodeInfoWithStorage[127.0.0.1:34030,DS-6d0a4dcc-3334-4745-9212-b9abf8846c2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1135879053-172.17.0.5-1595409955897:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35493,DS-f23e1bba-130e-4847-8079-6b3980eb08bc,DISK], DatanodeInfoWithStorage[127.0.0.1:38681,DS-db47c42b-2bb2-4e11-b896-9adbe3859720,DISK], DatanodeInfoWithStorage[127.0.0.1:45453,DS-263c6c3b-92c2-4c9c-93b9-f915c076f28e,DISK], DatanodeInfoWithStorage[127.0.0.1:33456,DS-41d236d3-be82-4f19-a33c-4772d421e853,DISK], DatanodeInfoWithStorage[127.0.0.1:46095,DS-34831913-1c17-40ab-b65c-3fd4984ca1a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43418,DS-be1c6a2b-beae-4f9a-8d10-c63dca2b9f31,DISK], DatanodeInfoWithStorage[127.0.0.1:42965,DS-9333cb7e-5d72-4cd2-8d07-9375c67d8a87,DISK], DatanodeInfoWithStorage[127.0.0.1:34030,DS-6d0a4dcc-3334-4745-9212-b9abf8846c2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1668146899-172.17.0.5-1595410098909:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35037,DS-939bba2e-63e4-4e4e-a227-818040583ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:36458,DS-4e508929-0f89-4bd4-98fa-a375955c567a,DISK], DatanodeInfoWithStorage[127.0.0.1:35853,DS-bceca42d-3361-4649-9bb9-91c746b1550d,DISK], DatanodeInfoWithStorage[127.0.0.1:36929,DS-4a967e0f-5681-4ebe-953b-63a08d1e1628,DISK], DatanodeInfoWithStorage[127.0.0.1:37888,DS-bf644539-3442-4c1c-9a11-dfa5d709f2c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34107,DS-f6bd87c3-a66b-4363-a287-3901ea2142ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38655,DS-b4596f3c-0fcd-444b-9310-fbc1fc57062e,DISK], DatanodeInfoWithStorage[127.0.0.1:40988,DS-6ae8e915-9c84-4fdd-9b02-156c1c82e058,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1668146899-172.17.0.5-1595410098909:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35037,DS-939bba2e-63e4-4e4e-a227-818040583ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:36458,DS-4e508929-0f89-4bd4-98fa-a375955c567a,DISK], DatanodeInfoWithStorage[127.0.0.1:35853,DS-bceca42d-3361-4649-9bb9-91c746b1550d,DISK], DatanodeInfoWithStorage[127.0.0.1:36929,DS-4a967e0f-5681-4ebe-953b-63a08d1e1628,DISK], DatanodeInfoWithStorage[127.0.0.1:37888,DS-bf644539-3442-4c1c-9a11-dfa5d709f2c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34107,DS-f6bd87c3-a66b-4363-a287-3901ea2142ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38655,DS-b4596f3c-0fcd-444b-9310-fbc1fc57062e,DISK], DatanodeInfoWithStorage[127.0.0.1:40988,DS-6ae8e915-9c84-4fdd-9b02-156c1c82e058,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-968414371-172.17.0.5-1595410981566:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42506,DS-924899e0-2478-4866-87ae-a2b9a462ea06,DISK], DatanodeInfoWithStorage[127.0.0.1:34914,DS-4dac4771-2da7-45dd-ba23-904feea13466,DISK], DatanodeInfoWithStorage[127.0.0.1:41050,DS-226487cd-38c6-46b6-a1a7-c930025d75c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39002,DS-04cdb5cd-81f6-4bf0-a215-f076cda62509,DISK], DatanodeInfoWithStorage[127.0.0.1:35955,DS-5c8edaee-4103-4a7a-ba81-f85ec17d9834,DISK], DatanodeInfoWithStorage[127.0.0.1:41634,DS-32ffbf6e-bcca-43c1-b43f-e33098ce8075,DISK], DatanodeInfoWithStorage[127.0.0.1:45991,DS-75994b82-b948-4121-abf2-85b948823a95,DISK], DatanodeInfoWithStorage[127.0.0.1:33224,DS-14ee0b26-7527-4280-acab-b4dd590b88d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-968414371-172.17.0.5-1595410981566:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42506,DS-924899e0-2478-4866-87ae-a2b9a462ea06,DISK], DatanodeInfoWithStorage[127.0.0.1:34914,DS-4dac4771-2da7-45dd-ba23-904feea13466,DISK], DatanodeInfoWithStorage[127.0.0.1:41050,DS-226487cd-38c6-46b6-a1a7-c930025d75c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39002,DS-04cdb5cd-81f6-4bf0-a215-f076cda62509,DISK], DatanodeInfoWithStorage[127.0.0.1:35955,DS-5c8edaee-4103-4a7a-ba81-f85ec17d9834,DISK], DatanodeInfoWithStorage[127.0.0.1:41634,DS-32ffbf6e-bcca-43c1-b43f-e33098ce8075,DISK], DatanodeInfoWithStorage[127.0.0.1:45991,DS-75994b82-b948-4121-abf2-85b948823a95,DISK], DatanodeInfoWithStorage[127.0.0.1:33224,DS-14ee0b26-7527-4280-acab-b4dd590b88d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1383195414-172.17.0.5-1595411020492:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35290,DS-a21efd09-c039-42ed-8e8b-d3c7e22b483a,DISK], DatanodeInfoWithStorage[127.0.0.1:44489,DS-f0c75531-7ad8-4a29-aa56-b3a54af56f7a,DISK], DatanodeInfoWithStorage[127.0.0.1:38261,DS-915618e4-6423-479c-99d8-61bb2e5c6985,DISK], DatanodeInfoWithStorage[127.0.0.1:40774,DS-ed78dc8c-05dc-47c3-bc0e-e08153bdf015,DISK], DatanodeInfoWithStorage[127.0.0.1:36468,DS-d44fa82d-5490-4f82-bad6-483b524a437b,DISK], DatanodeInfoWithStorage[127.0.0.1:41078,DS-b5037eb6-815c-4967-a726-97ba720e4ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:45608,DS-6065975d-22a8-448c-b50b-a9c30d8843d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40617,DS-5b018628-65ef-434b-80b9-9d106fbec678,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1383195414-172.17.0.5-1595411020492:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35290,DS-a21efd09-c039-42ed-8e8b-d3c7e22b483a,DISK], DatanodeInfoWithStorage[127.0.0.1:44489,DS-f0c75531-7ad8-4a29-aa56-b3a54af56f7a,DISK], DatanodeInfoWithStorage[127.0.0.1:38261,DS-915618e4-6423-479c-99d8-61bb2e5c6985,DISK], DatanodeInfoWithStorage[127.0.0.1:40774,DS-ed78dc8c-05dc-47c3-bc0e-e08153bdf015,DISK], DatanodeInfoWithStorage[127.0.0.1:36468,DS-d44fa82d-5490-4f82-bad6-483b524a437b,DISK], DatanodeInfoWithStorage[127.0.0.1:41078,DS-b5037eb6-815c-4967-a726-97ba720e4ab5,DISK], DatanodeInfoWithStorage[127.0.0.1:45608,DS-6065975d-22a8-448c-b50b-a9c30d8843d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40617,DS-5b018628-65ef-434b-80b9-9d106fbec678,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1903852570-172.17.0.5-1595411173331:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41063,DS-e9988dde-14cd-4905-929b-ba5a8122ba77,DISK], DatanodeInfoWithStorage[127.0.0.1:37657,DS-6b2aa46e-24e5-4ca9-9cdb-90fd24648a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:38035,DS-a65d494a-8860-4f24-a688-5fc27d6c4bb3,DISK], DatanodeInfoWithStorage[127.0.0.1:37955,DS-a8099fe6-3051-4fdc-a32e-f04a0b6f84d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46404,DS-697bda57-e7ae-4f80-9daa-8d1ea2c6d17e,DISK], DatanodeInfoWithStorage[127.0.0.1:35098,DS-d28bb717-e5a2-4c1e-80ef-12b386027509,DISK], DatanodeInfoWithStorage[127.0.0.1:34381,DS-450fa782-b88f-4f30-8ec6-87940707df38,DISK], DatanodeInfoWithStorage[127.0.0.1:33732,DS-26df4b02-68f9-426d-be8b-84d1faa6b767,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1903852570-172.17.0.5-1595411173331:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41063,DS-e9988dde-14cd-4905-929b-ba5a8122ba77,DISK], DatanodeInfoWithStorage[127.0.0.1:37657,DS-6b2aa46e-24e5-4ca9-9cdb-90fd24648a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:38035,DS-a65d494a-8860-4f24-a688-5fc27d6c4bb3,DISK], DatanodeInfoWithStorage[127.0.0.1:37955,DS-a8099fe6-3051-4fdc-a32e-f04a0b6f84d1,DISK], DatanodeInfoWithStorage[127.0.0.1:46404,DS-697bda57-e7ae-4f80-9daa-8d1ea2c6d17e,DISK], DatanodeInfoWithStorage[127.0.0.1:35098,DS-d28bb717-e5a2-4c1e-80ef-12b386027509,DISK], DatanodeInfoWithStorage[127.0.0.1:34381,DS-450fa782-b88f-4f30-8ec6-87940707df38,DISK], DatanodeInfoWithStorage[127.0.0.1:33732,DS-26df4b02-68f9-426d-be8b-84d1faa6b767,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-486311344-172.17.0.5-1595411904543:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33025,DS-4d4dbabb-c813-43f7-8ade-40dd03c35190,DISK], DatanodeInfoWithStorage[127.0.0.1:42619,DS-af7c630b-3986-4499-9ccf-6c6487efa889,DISK], DatanodeInfoWithStorage[127.0.0.1:37848,DS-98ff86f9-04ff-4121-ae04-8b535d1c6e48,DISK], DatanodeInfoWithStorage[127.0.0.1:45652,DS-4f87a710-3a87-432d-9719-377c1633ff4f,DISK], DatanodeInfoWithStorage[127.0.0.1:44805,DS-96d713dc-245a-4c56-8f24-57bc00482dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:36681,DS-78634b29-74d9-4191-a76a-ccbb0a35b742,DISK], DatanodeInfoWithStorage[127.0.0.1:42778,DS-e35f0ab1-8c8c-4de3-b386-9ee2960edf88,DISK], DatanodeInfoWithStorage[127.0.0.1:35246,DS-3e6abc37-74ff-4646-84a2-84f9a5be235d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-486311344-172.17.0.5-1595411904543:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33025,DS-4d4dbabb-c813-43f7-8ade-40dd03c35190,DISK], DatanodeInfoWithStorage[127.0.0.1:42619,DS-af7c630b-3986-4499-9ccf-6c6487efa889,DISK], DatanodeInfoWithStorage[127.0.0.1:37848,DS-98ff86f9-04ff-4121-ae04-8b535d1c6e48,DISK], DatanodeInfoWithStorage[127.0.0.1:45652,DS-4f87a710-3a87-432d-9719-377c1633ff4f,DISK], DatanodeInfoWithStorage[127.0.0.1:44805,DS-96d713dc-245a-4c56-8f24-57bc00482dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:36681,DS-78634b29-74d9-4191-a76a-ccbb0a35b742,DISK], DatanodeInfoWithStorage[127.0.0.1:42778,DS-e35f0ab1-8c8c-4de3-b386-9ee2960edf88,DISK], DatanodeInfoWithStorage[127.0.0.1:35246,DS-3e6abc37-74ff-4646-84a2-84f9a5be235d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-578678465-172.17.0.5-1595412163358:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41333,DS-f7f9a0f6-74f1-4259-8456-184669718d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:37417,DS-d472448f-08fb-4eb5-bfdb-1807a624d72f,DISK], DatanodeInfoWithStorage[127.0.0.1:39469,DS-6c264082-545b-454a-a0f5-cba6db74b506,DISK], DatanodeInfoWithStorage[127.0.0.1:43610,DS-af826b53-51ee-4a0f-9739-cf1d6ec8efd2,DISK], DatanodeInfoWithStorage[127.0.0.1:46420,DS-732a317c-e007-460b-9177-50653c6397c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45360,DS-e78392d2-ee2c-4dcb-a3a7-50650a05989d,DISK], DatanodeInfoWithStorage[127.0.0.1:32933,DS-98f77bfb-099b-4cb2-a8f7-f25d928d54af,DISK], DatanodeInfoWithStorage[127.0.0.1:42614,DS-d57d02d2-4a35-49ef-8a42-c243792f9b99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-578678465-172.17.0.5-1595412163358:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41333,DS-f7f9a0f6-74f1-4259-8456-184669718d9f,DISK], DatanodeInfoWithStorage[127.0.0.1:37417,DS-d472448f-08fb-4eb5-bfdb-1807a624d72f,DISK], DatanodeInfoWithStorage[127.0.0.1:39469,DS-6c264082-545b-454a-a0f5-cba6db74b506,DISK], DatanodeInfoWithStorage[127.0.0.1:43610,DS-af826b53-51ee-4a0f-9739-cf1d6ec8efd2,DISK], DatanodeInfoWithStorage[127.0.0.1:46420,DS-732a317c-e007-460b-9177-50653c6397c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45360,DS-e78392d2-ee2c-4dcb-a3a7-50650a05989d,DISK], DatanodeInfoWithStorage[127.0.0.1:32933,DS-98f77bfb-099b-4cb2-a8f7-f25d928d54af,DISK], DatanodeInfoWithStorage[127.0.0.1:42614,DS-d57d02d2-4a35-49ef-8a42-c243792f9b99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-244645001-172.17.0.5-1595412436108:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34640,DS-3af059d2-2590-43b2-b71b-b5017a9537f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36388,DS-c983cc70-9dda-47cf-81c7-d95a390a2079,DISK], DatanodeInfoWithStorage[127.0.0.1:34041,DS-4b0b65de-a5e6-4650-a8e3-c14732568d5b,DISK], DatanodeInfoWithStorage[127.0.0.1:46510,DS-a02fb41f-5a07-4083-bd8e-d87ed2232e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:42855,DS-70822c84-ba31-445b-9ba0-165c6ffc17e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46593,DS-a80812cd-e9b0-4a0d-b1a8-108757c222a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36884,DS-03598d48-2c2f-4efd-aae7-2daa46158a82,DISK], DatanodeInfoWithStorage[127.0.0.1:35858,DS-30ece57f-c0b3-4e9c-9077-0f9aa8da6152,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-244645001-172.17.0.5-1595412436108:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34640,DS-3af059d2-2590-43b2-b71b-b5017a9537f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36388,DS-c983cc70-9dda-47cf-81c7-d95a390a2079,DISK], DatanodeInfoWithStorage[127.0.0.1:34041,DS-4b0b65de-a5e6-4650-a8e3-c14732568d5b,DISK], DatanodeInfoWithStorage[127.0.0.1:46510,DS-a02fb41f-5a07-4083-bd8e-d87ed2232e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:42855,DS-70822c84-ba31-445b-9ba0-165c6ffc17e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46593,DS-a80812cd-e9b0-4a0d-b1a8-108757c222a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36884,DS-03598d48-2c2f-4efd-aae7-2daa46158a82,DISK], DatanodeInfoWithStorage[127.0.0.1:35858,DS-30ece57f-c0b3-4e9c-9077-0f9aa8da6152,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1651255530-172.17.0.5-1595412746346:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42711,DS-98432b6d-40fc-42cd-a5a7-de513bbd7517,DISK], DatanodeInfoWithStorage[127.0.0.1:34916,DS-05b6abd5-3701-4fb3-9050-199ccf24b462,DISK], DatanodeInfoWithStorage[127.0.0.1:36985,DS-2a3c12e9-0efe-43cc-ad5f-ce89cc85bd93,DISK], DatanodeInfoWithStorage[127.0.0.1:40491,DS-c9ee6c95-3a7f-4a1f-a518-dd96c6b3ecb2,DISK], DatanodeInfoWithStorage[127.0.0.1:39582,DS-412d7e60-95d0-4bfa-ae62-2c9e7b73c71f,DISK], DatanodeInfoWithStorage[127.0.0.1:35183,DS-1f0e3429-b503-4a09-8058-5b577dbe28b7,DISK], DatanodeInfoWithStorage[127.0.0.1:32828,DS-adc8521f-5e4f-454f-beb9-9c0715e97798,DISK], DatanodeInfoWithStorage[127.0.0.1:44445,DS-555d83f4-0972-4976-a464-a4e53fc8a879,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1651255530-172.17.0.5-1595412746346:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42711,DS-98432b6d-40fc-42cd-a5a7-de513bbd7517,DISK], DatanodeInfoWithStorage[127.0.0.1:34916,DS-05b6abd5-3701-4fb3-9050-199ccf24b462,DISK], DatanodeInfoWithStorage[127.0.0.1:36985,DS-2a3c12e9-0efe-43cc-ad5f-ce89cc85bd93,DISK], DatanodeInfoWithStorage[127.0.0.1:40491,DS-c9ee6c95-3a7f-4a1f-a518-dd96c6b3ecb2,DISK], DatanodeInfoWithStorage[127.0.0.1:39582,DS-412d7e60-95d0-4bfa-ae62-2c9e7b73c71f,DISK], DatanodeInfoWithStorage[127.0.0.1:35183,DS-1f0e3429-b503-4a09-8058-5b577dbe28b7,DISK], DatanodeInfoWithStorage[127.0.0.1:32828,DS-adc8521f-5e4f-454f-beb9-9c0715e97798,DISK], DatanodeInfoWithStorage[127.0.0.1:44445,DS-555d83f4-0972-4976-a464-a4e53fc8a879,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1649923545-172.17.0.5-1595412872067:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42814,DS-752dc815-6517-433a-898b-3c25dc4425f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46832,DS-a153393b-9bca-4c32-858e-e9f05b896643,DISK], DatanodeInfoWithStorage[127.0.0.1:38792,DS-6855efc0-803d-4c5a-946f-57cd748d4638,DISK], DatanodeInfoWithStorage[127.0.0.1:44499,DS-a74f9ecf-2233-4281-9b2c-760ab52c5f67,DISK], DatanodeInfoWithStorage[127.0.0.1:34133,DS-7bb77429-cb84-4f0e-ab46-838e652cc9fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46861,DS-3d6ceb83-cb07-4d7c-a9d6-2cb888282b21,DISK], DatanodeInfoWithStorage[127.0.0.1:37756,DS-0fb923e3-c492-43db-9348-497c1461d05c,DISK], DatanodeInfoWithStorage[127.0.0.1:38863,DS-bba759bb-7da4-4717-81ce-02367fffb2c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1649923545-172.17.0.5-1595412872067:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42814,DS-752dc815-6517-433a-898b-3c25dc4425f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46832,DS-a153393b-9bca-4c32-858e-e9f05b896643,DISK], DatanodeInfoWithStorage[127.0.0.1:38792,DS-6855efc0-803d-4c5a-946f-57cd748d4638,DISK], DatanodeInfoWithStorage[127.0.0.1:44499,DS-a74f9ecf-2233-4281-9b2c-760ab52c5f67,DISK], DatanodeInfoWithStorage[127.0.0.1:34133,DS-7bb77429-cb84-4f0e-ab46-838e652cc9fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46861,DS-3d6ceb83-cb07-4d7c-a9d6-2cb888282b21,DISK], DatanodeInfoWithStorage[127.0.0.1:37756,DS-0fb923e3-c492-43db-9348-497c1461d05c,DISK], DatanodeInfoWithStorage[127.0.0.1:38863,DS-bba759bb-7da4-4717-81ce-02367fffb2c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-900065633-172.17.0.5-1595412971533:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41354,DS-1bb92a7e-1903-4351-86ad-bd601be51cd1,DISK], DatanodeInfoWithStorage[127.0.0.1:45838,DS-6aadd8d7-8041-4776-a8df-a77512d8b81b,DISK], DatanodeInfoWithStorage[127.0.0.1:46243,DS-dfc6910d-c3e7-46e1-a398-48405817ed0f,DISK], DatanodeInfoWithStorage[127.0.0.1:42211,DS-4e60ef14-d768-414b-b784-7184295a14ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40937,DS-50d5b415-59a9-4216-987a-2f92b88f8723,DISK], DatanodeInfoWithStorage[127.0.0.1:39718,DS-91f618d1-30e7-49df-bc8c-82973b4a3998,DISK], DatanodeInfoWithStorage[127.0.0.1:40308,DS-5d3afa44-583c-4602-950d-dcff46b091ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44314,DS-a660612e-ca0d-48fd-9ea0-6f70156390fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-900065633-172.17.0.5-1595412971533:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41354,DS-1bb92a7e-1903-4351-86ad-bd601be51cd1,DISK], DatanodeInfoWithStorage[127.0.0.1:45838,DS-6aadd8d7-8041-4776-a8df-a77512d8b81b,DISK], DatanodeInfoWithStorage[127.0.0.1:46243,DS-dfc6910d-c3e7-46e1-a398-48405817ed0f,DISK], DatanodeInfoWithStorage[127.0.0.1:42211,DS-4e60ef14-d768-414b-b784-7184295a14ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40937,DS-50d5b415-59a9-4216-987a-2f92b88f8723,DISK], DatanodeInfoWithStorage[127.0.0.1:39718,DS-91f618d1-30e7-49df-bc8c-82973b4a3998,DISK], DatanodeInfoWithStorage[127.0.0.1:40308,DS-5d3afa44-583c-4602-950d-dcff46b091ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44314,DS-a660612e-ca0d-48fd-9ea0-6f70156390fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1606051154-172.17.0.5-1595414193833:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45332,DS-f681c67c-74ed-4ad6-8fb9-10ab0f950629,DISK], DatanodeInfoWithStorage[127.0.0.1:38313,DS-8d3837ab-1470-4201-9bed-b5f0ed6c29c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33131,DS-936bf79b-369b-4077-bd62-9280b3a9d1e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37967,DS-9c425956-c211-46a1-8cb4-cfd848eced3c,DISK], DatanodeInfoWithStorage[127.0.0.1:34023,DS-6a878d4f-a491-4a64-b429-4cb053671a53,DISK], DatanodeInfoWithStorage[127.0.0.1:38917,DS-4542fe1f-9c8a-4c0d-9a42-bd472c7a18fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44881,DS-ecc7da7a-1fda-4735-8be8-908ca478a92a,DISK], DatanodeInfoWithStorage[127.0.0.1:43064,DS-5e5be42b-dca1-4f56-a78d-7e02f477a745,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1606051154-172.17.0.5-1595414193833:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45332,DS-f681c67c-74ed-4ad6-8fb9-10ab0f950629,DISK], DatanodeInfoWithStorage[127.0.0.1:38313,DS-8d3837ab-1470-4201-9bed-b5f0ed6c29c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33131,DS-936bf79b-369b-4077-bd62-9280b3a9d1e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37967,DS-9c425956-c211-46a1-8cb4-cfd848eced3c,DISK], DatanodeInfoWithStorage[127.0.0.1:34023,DS-6a878d4f-a491-4a64-b429-4cb053671a53,DISK], DatanodeInfoWithStorage[127.0.0.1:38917,DS-4542fe1f-9c8a-4c0d-9a42-bd472c7a18fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44881,DS-ecc7da7a-1fda-4735-8be8-908ca478a92a,DISK], DatanodeInfoWithStorage[127.0.0.1:43064,DS-5e5be42b-dca1-4f56-a78d-7e02f477a745,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1593120327-172.17.0.5-1595414438223:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41219,DS-9364e672-8b92-41ec-b886-07f5d28a069d,DISK], DatanodeInfoWithStorage[127.0.0.1:33776,DS-a5bbe42c-5af6-4f6c-874e-5c8ab3c91743,DISK], DatanodeInfoWithStorage[127.0.0.1:45606,DS-c4dc4b3d-4670-4662-afba-67bd88c0c36c,DISK], DatanodeInfoWithStorage[127.0.0.1:37848,DS-f8b27c60-1e60-4162-a40a-f1d4bffa8046,DISK], DatanodeInfoWithStorage[127.0.0.1:46600,DS-d8272056-7fea-45bf-aec3-a149ce79d84c,DISK], DatanodeInfoWithStorage[127.0.0.1:35588,DS-0199444f-7187-49a1-a022-2e11d4c526ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45465,DS-9e5e091a-d337-4874-a364-cdcd983820af,DISK], DatanodeInfoWithStorage[127.0.0.1:40795,DS-140b8102-f640-479b-b6c5-9e2e973b0e39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1593120327-172.17.0.5-1595414438223:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41219,DS-9364e672-8b92-41ec-b886-07f5d28a069d,DISK], DatanodeInfoWithStorage[127.0.0.1:33776,DS-a5bbe42c-5af6-4f6c-874e-5c8ab3c91743,DISK], DatanodeInfoWithStorage[127.0.0.1:45606,DS-c4dc4b3d-4670-4662-afba-67bd88c0c36c,DISK], DatanodeInfoWithStorage[127.0.0.1:37848,DS-f8b27c60-1e60-4162-a40a-f1d4bffa8046,DISK], DatanodeInfoWithStorage[127.0.0.1:46600,DS-d8272056-7fea-45bf-aec3-a149ce79d84c,DISK], DatanodeInfoWithStorage[127.0.0.1:35588,DS-0199444f-7187-49a1-a022-2e11d4c526ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45465,DS-9e5e091a-d337-4874-a364-cdcd983820af,DISK], DatanodeInfoWithStorage[127.0.0.1:40795,DS-140b8102-f640-479b-b6c5-9e2e973b0e39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.ping
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-703143730-172.17.0.5-1595414635841:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43880,DS-cde11156-0156-47a0-94bb-e89ef4512c85,DISK], DatanodeInfoWithStorage[127.0.0.1:35180,DS-d5400a89-0b76-460a-bc4f-34150c3fdde4,DISK], DatanodeInfoWithStorage[127.0.0.1:44171,DS-b39d129f-6f9c-43f4-892d-5c2eafdba953,DISK], DatanodeInfoWithStorage[127.0.0.1:33840,DS-5381e448-5105-4906-a0e9-b85a9a3e3529,DISK], DatanodeInfoWithStorage[127.0.0.1:44538,DS-366ca877-5c77-4efa-8b8c-5eccb10d329a,DISK], DatanodeInfoWithStorage[127.0.0.1:46347,DS-c34d5f76-1ed8-46cb-8c81-26720795db75,DISK], DatanodeInfoWithStorage[127.0.0.1:34857,DS-a2383611-2983-4677-b87f-240ed4142be1,DISK], DatanodeInfoWithStorage[127.0.0.1:38980,DS-84df44c1-dedb-4c57-88d9-fbd28ef318ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-703143730-172.17.0.5-1595414635841:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43880,DS-cde11156-0156-47a0-94bb-e89ef4512c85,DISK], DatanodeInfoWithStorage[127.0.0.1:35180,DS-d5400a89-0b76-460a-bc4f-34150c3fdde4,DISK], DatanodeInfoWithStorage[127.0.0.1:44171,DS-b39d129f-6f9c-43f4-892d-5c2eafdba953,DISK], DatanodeInfoWithStorage[127.0.0.1:33840,DS-5381e448-5105-4906-a0e9-b85a9a3e3529,DISK], DatanodeInfoWithStorage[127.0.0.1:44538,DS-366ca877-5c77-4efa-8b8c-5eccb10d329a,DISK], DatanodeInfoWithStorage[127.0.0.1:46347,DS-c34d5f76-1ed8-46cb-8c81-26720795db75,DISK], DatanodeInfoWithStorage[127.0.0.1:34857,DS-a2383611-2983-4677-b87f-240ed4142be1,DISK], DatanodeInfoWithStorage[127.0.0.1:38980,DS-84df44c1-dedb-4c57-88d9-fbd28ef318ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 6859
