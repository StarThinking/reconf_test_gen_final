reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-273772757-172.17.0.14-1595318067396:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34897,DS-db7202e1-b030-4af2-8f2c-b55cb2258748,DISK], DatanodeInfoWithStorage[127.0.0.1:44738,DS-3c3ddd98-4f01-4948-991d-2950348d6582,DISK], DatanodeInfoWithStorage[127.0.0.1:33891,DS-e310ba39-bed1-4c8e-a831-6c55fd49c79e,DISK], DatanodeInfoWithStorage[127.0.0.1:38833,DS-f62420f2-5ca4-4f1f-9a31-c06ecd465e96,DISK], DatanodeInfoWithStorage[127.0.0.1:38778,DS-8889e572-424f-4940-8fcd-002b1042e5e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45132,DS-5efad4d0-50ae-49e8-9e12-372a3387cb26,DISK], DatanodeInfoWithStorage[127.0.0.1:41422,DS-3d4e0527-a076-48f9-8175-facfd7bd8b3b,DISK], DatanodeInfoWithStorage[127.0.0.1:33954,DS-4b2110c5-a429-4df8-bcb9-6f64240051f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-273772757-172.17.0.14-1595318067396:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34897,DS-db7202e1-b030-4af2-8f2c-b55cb2258748,DISK], DatanodeInfoWithStorage[127.0.0.1:44738,DS-3c3ddd98-4f01-4948-991d-2950348d6582,DISK], DatanodeInfoWithStorage[127.0.0.1:33891,DS-e310ba39-bed1-4c8e-a831-6c55fd49c79e,DISK], DatanodeInfoWithStorage[127.0.0.1:38833,DS-f62420f2-5ca4-4f1f-9a31-c06ecd465e96,DISK], DatanodeInfoWithStorage[127.0.0.1:38778,DS-8889e572-424f-4940-8fcd-002b1042e5e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45132,DS-5efad4d0-50ae-49e8-9e12-372a3387cb26,DISK], DatanodeInfoWithStorage[127.0.0.1:41422,DS-3d4e0527-a076-48f9-8175-facfd7bd8b3b,DISK], DatanodeInfoWithStorage[127.0.0.1:33954,DS-4b2110c5-a429-4df8-bcb9-6f64240051f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1697112135-172.17.0.14-1595318100750:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44704,DS-a9f5929c-41cd-4339-ba0e-b5bf285a5837,DISK], DatanodeInfoWithStorage[127.0.0.1:43086,DS-9e16e111-90fb-480b-9347-5ae21e670777,DISK], DatanodeInfoWithStorage[127.0.0.1:37696,DS-0d361a8e-4e39-4207-98a8-8134bc19fcf4,DISK], DatanodeInfoWithStorage[127.0.0.1:42885,DS-19d9a533-ed25-42d9-8cfe-2009b3971df5,DISK], DatanodeInfoWithStorage[127.0.0.1:35028,DS-f1e71fd5-5ea4-42e0-9e9b-755dc0f3c72e,DISK], DatanodeInfoWithStorage[127.0.0.1:42905,DS-6c9b30b7-614f-499b-950a-71678ab86be9,DISK], DatanodeInfoWithStorage[127.0.0.1:42312,DS-05aa9372-477f-4eca-a7db-a82cedb2d807,DISK], DatanodeInfoWithStorage[127.0.0.1:43185,DS-2155adcb-6994-4c92-94dd-1f4b4906b115,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1697112135-172.17.0.14-1595318100750:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44704,DS-a9f5929c-41cd-4339-ba0e-b5bf285a5837,DISK], DatanodeInfoWithStorage[127.0.0.1:43086,DS-9e16e111-90fb-480b-9347-5ae21e670777,DISK], DatanodeInfoWithStorage[127.0.0.1:37696,DS-0d361a8e-4e39-4207-98a8-8134bc19fcf4,DISK], DatanodeInfoWithStorage[127.0.0.1:42885,DS-19d9a533-ed25-42d9-8cfe-2009b3971df5,DISK], DatanodeInfoWithStorage[127.0.0.1:35028,DS-f1e71fd5-5ea4-42e0-9e9b-755dc0f3c72e,DISK], DatanodeInfoWithStorage[127.0.0.1:42905,DS-6c9b30b7-614f-499b-950a-71678ab86be9,DISK], DatanodeInfoWithStorage[127.0.0.1:42312,DS-05aa9372-477f-4eca-a7db-a82cedb2d807,DISK], DatanodeInfoWithStorage[127.0.0.1:43185,DS-2155adcb-6994-4c92-94dd-1f4b4906b115,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1572629194-172.17.0.14-1595318459267:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35334,DS-1d554767-ca2b-4ffd-9321-7a4c0a0ef69f,DISK], DatanodeInfoWithStorage[127.0.0.1:43850,DS-ba9cfaf3-a1bf-4b4c-acb3-fa50321d9968,DISK], DatanodeInfoWithStorage[127.0.0.1:43150,DS-b31e9562-b74a-4b16-b97f-5199add6ece0,DISK], DatanodeInfoWithStorage[127.0.0.1:43895,DS-e79363fb-400f-456e-8140-0a2e87b894fc,DISK], DatanodeInfoWithStorage[127.0.0.1:46832,DS-599bd1f8-3223-4664-9243-35a9e59ddcc9,DISK], DatanodeInfoWithStorage[127.0.0.1:37593,DS-df2b1a53-dca5-4979-8d66-386467f31771,DISK], DatanodeInfoWithStorage[127.0.0.1:42461,DS-beb34889-9751-4691-8f64-13e0ceaa8af0,DISK], DatanodeInfoWithStorage[127.0.0.1:36414,DS-13e7ea54-dbe6-49fb-beb5-aba1038e2a94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1572629194-172.17.0.14-1595318459267:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35334,DS-1d554767-ca2b-4ffd-9321-7a4c0a0ef69f,DISK], DatanodeInfoWithStorage[127.0.0.1:43850,DS-ba9cfaf3-a1bf-4b4c-acb3-fa50321d9968,DISK], DatanodeInfoWithStorage[127.0.0.1:43150,DS-b31e9562-b74a-4b16-b97f-5199add6ece0,DISK], DatanodeInfoWithStorage[127.0.0.1:43895,DS-e79363fb-400f-456e-8140-0a2e87b894fc,DISK], DatanodeInfoWithStorage[127.0.0.1:46832,DS-599bd1f8-3223-4664-9243-35a9e59ddcc9,DISK], DatanodeInfoWithStorage[127.0.0.1:37593,DS-df2b1a53-dca5-4979-8d66-386467f31771,DISK], DatanodeInfoWithStorage[127.0.0.1:42461,DS-beb34889-9751-4691-8f64-13e0ceaa8af0,DISK], DatanodeInfoWithStorage[127.0.0.1:36414,DS-13e7ea54-dbe6-49fb-beb5-aba1038e2a94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-94479654-172.17.0.14-1595318599927:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42271,DS-cb7f63ac-73de-458a-8097-df73cd8685ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38049,DS-b71d71fa-f6ce-471f-ba02-1a852ccc0818,DISK], DatanodeInfoWithStorage[127.0.0.1:42152,DS-6eda14a0-273d-4b2d-969b-73fd481c836c,DISK], DatanodeInfoWithStorage[127.0.0.1:43645,DS-c94eee65-f2b9-43c0-b91d-069cd127ba51,DISK], DatanodeInfoWithStorage[127.0.0.1:43021,DS-7810bf78-b0d0-47f0-983b-8b4d3510f08b,DISK], DatanodeInfoWithStorage[127.0.0.1:37360,DS-62615c97-7c3c-484c-b62a-101a5b429dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:42399,DS-c44b8a1e-7abb-466a-a66c-faa77f6e2ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:41993,DS-bf937f1c-6d9d-4741-81b6-c2ee8ffe2ec7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-94479654-172.17.0.14-1595318599927:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42271,DS-cb7f63ac-73de-458a-8097-df73cd8685ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38049,DS-b71d71fa-f6ce-471f-ba02-1a852ccc0818,DISK], DatanodeInfoWithStorage[127.0.0.1:42152,DS-6eda14a0-273d-4b2d-969b-73fd481c836c,DISK], DatanodeInfoWithStorage[127.0.0.1:43645,DS-c94eee65-f2b9-43c0-b91d-069cd127ba51,DISK], DatanodeInfoWithStorage[127.0.0.1:43021,DS-7810bf78-b0d0-47f0-983b-8b4d3510f08b,DISK], DatanodeInfoWithStorage[127.0.0.1:37360,DS-62615c97-7c3c-484c-b62a-101a5b429dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:42399,DS-c44b8a1e-7abb-466a-a66c-faa77f6e2ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:41993,DS-bf937f1c-6d9d-4741-81b6-c2ee8ffe2ec7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-707019610-172.17.0.14-1595319801495:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45107,DS-52f24678-7962-4c4d-9c8e-795bb9f3174f,DISK], DatanodeInfoWithStorage[127.0.0.1:36574,DS-fd7a3a07-552a-4671-a0a3-2092ecccd388,DISK], DatanodeInfoWithStorage[127.0.0.1:33516,DS-f321adb0-c90d-4255-86ec-c22065733afd,DISK], DatanodeInfoWithStorage[127.0.0.1:46643,DS-7f1efa60-4394-4857-8209-aac5d9333405,DISK], DatanodeInfoWithStorage[127.0.0.1:40109,DS-3010735f-f51e-41cc-bcfe-5b5e35a16a71,DISK], DatanodeInfoWithStorage[127.0.0.1:39812,DS-e72ca5ae-97fe-4a07-8bc8-3b403b530915,DISK], DatanodeInfoWithStorage[127.0.0.1:33127,DS-77a58817-bbd8-4e45-bc11-7f26c9ab7136,DISK], DatanodeInfoWithStorage[127.0.0.1:36213,DS-7c93b392-49f4-4542-8c3b-96bdbacb31cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-707019610-172.17.0.14-1595319801495:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45107,DS-52f24678-7962-4c4d-9c8e-795bb9f3174f,DISK], DatanodeInfoWithStorage[127.0.0.1:36574,DS-fd7a3a07-552a-4671-a0a3-2092ecccd388,DISK], DatanodeInfoWithStorage[127.0.0.1:33516,DS-f321adb0-c90d-4255-86ec-c22065733afd,DISK], DatanodeInfoWithStorage[127.0.0.1:46643,DS-7f1efa60-4394-4857-8209-aac5d9333405,DISK], DatanodeInfoWithStorage[127.0.0.1:40109,DS-3010735f-f51e-41cc-bcfe-5b5e35a16a71,DISK], DatanodeInfoWithStorage[127.0.0.1:39812,DS-e72ca5ae-97fe-4a07-8bc8-3b403b530915,DISK], DatanodeInfoWithStorage[127.0.0.1:33127,DS-77a58817-bbd8-4e45-bc11-7f26c9ab7136,DISK], DatanodeInfoWithStorage[127.0.0.1:36213,DS-7c93b392-49f4-4542-8c3b-96bdbacb31cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-268302561-172.17.0.14-1595320139051:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40739,DS-9fd43dc4-069f-40e5-b2b8-8ebd7166e8da,DISK], DatanodeInfoWithStorage[127.0.0.1:33149,DS-cca1e797-ddb9-4803-a0c8-acc4ad3d82bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43574,DS-7f9c0929-989d-47ca-8868-befe5a49f8c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35234,DS-ccc0b5f0-3cb5-40eb-a6c9-083419de5d83,DISK], DatanodeInfoWithStorage[127.0.0.1:46673,DS-96c9c011-b33c-4a21-8515-50d7d2f69d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:37938,DS-29fdfc6e-d960-4184-b9a6-aa6e4f6bd826,DISK], DatanodeInfoWithStorage[127.0.0.1:35426,DS-9ed39bf3-9a1b-44da-bc8e-698c7fa08393,DISK], DatanodeInfoWithStorage[127.0.0.1:44930,DS-bb1c535e-b938-4f62-bba7-b97ee6294092,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-268302561-172.17.0.14-1595320139051:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40739,DS-9fd43dc4-069f-40e5-b2b8-8ebd7166e8da,DISK], DatanodeInfoWithStorage[127.0.0.1:33149,DS-cca1e797-ddb9-4803-a0c8-acc4ad3d82bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43574,DS-7f9c0929-989d-47ca-8868-befe5a49f8c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35234,DS-ccc0b5f0-3cb5-40eb-a6c9-083419de5d83,DISK], DatanodeInfoWithStorage[127.0.0.1:46673,DS-96c9c011-b33c-4a21-8515-50d7d2f69d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:37938,DS-29fdfc6e-d960-4184-b9a6-aa6e4f6bd826,DISK], DatanodeInfoWithStorage[127.0.0.1:35426,DS-9ed39bf3-9a1b-44da-bc8e-698c7fa08393,DISK], DatanodeInfoWithStorage[127.0.0.1:44930,DS-bb1c535e-b938-4f62-bba7-b97ee6294092,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1610673724-172.17.0.14-1595321039089:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45984,DS-1986b91f-23d0-43fd-8422-75911fc40bff,DISK], DatanodeInfoWithStorage[127.0.0.1:44610,DS-b6b782f7-5840-4f0d-a48f-60b228d1c3c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34731,DS-119e091c-1d18-4ed2-94d2-a90b5cb5a498,DISK], DatanodeInfoWithStorage[127.0.0.1:37570,DS-8e519075-5dfe-465a-bcc6-861f3d0d3810,DISK], DatanodeInfoWithStorage[127.0.0.1:45962,DS-feaf4fef-c36a-4dbb-b623-a107c230e0f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41224,DS-1e7f259b-680e-4af6-a79b-75b3d9dee120,DISK], DatanodeInfoWithStorage[127.0.0.1:43190,DS-f5e7f86d-9eaf-4a9d-930a-c647c2f2025c,DISK], DatanodeInfoWithStorage[127.0.0.1:36548,DS-7e907b0c-5fe7-461e-84e4-f9a1ab5a3705,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1610673724-172.17.0.14-1595321039089:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45984,DS-1986b91f-23d0-43fd-8422-75911fc40bff,DISK], DatanodeInfoWithStorage[127.0.0.1:44610,DS-b6b782f7-5840-4f0d-a48f-60b228d1c3c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34731,DS-119e091c-1d18-4ed2-94d2-a90b5cb5a498,DISK], DatanodeInfoWithStorage[127.0.0.1:37570,DS-8e519075-5dfe-465a-bcc6-861f3d0d3810,DISK], DatanodeInfoWithStorage[127.0.0.1:45962,DS-feaf4fef-c36a-4dbb-b623-a107c230e0f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41224,DS-1e7f259b-680e-4af6-a79b-75b3d9dee120,DISK], DatanodeInfoWithStorage[127.0.0.1:43190,DS-f5e7f86d-9eaf-4a9d-930a-c647c2f2025c,DISK], DatanodeInfoWithStorage[127.0.0.1:36548,DS-7e907b0c-5fe7-461e-84e4-f9a1ab5a3705,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-671976264-172.17.0.14-1595321504847:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39175,DS-79a16486-9aa0-4b81-9317-705437216649,DISK], DatanodeInfoWithStorage[127.0.0.1:37581,DS-8da9aa2a-f945-495d-9cd9-05f7a8494fbb,DISK], DatanodeInfoWithStorage[127.0.0.1:42661,DS-6d9d0034-ef0a-46e6-928d-516e5e0458dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35126,DS-25d2b68e-8db8-42d3-80cb-44152d15604a,DISK], DatanodeInfoWithStorage[127.0.0.1:46663,DS-49598385-2023-4b1c-9289-b239fb84af7d,DISK], DatanodeInfoWithStorage[127.0.0.1:38810,DS-173fc2b0-9cce-441e-aee1-fcf513b48a46,DISK], DatanodeInfoWithStorage[127.0.0.1:37223,DS-95b1016a-c436-4738-99e9-b4ef96787ded,DISK], DatanodeInfoWithStorage[127.0.0.1:34255,DS-2da47944-6b2f-483c-a703-0b31a4964ba0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-671976264-172.17.0.14-1595321504847:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39175,DS-79a16486-9aa0-4b81-9317-705437216649,DISK], DatanodeInfoWithStorage[127.0.0.1:37581,DS-8da9aa2a-f945-495d-9cd9-05f7a8494fbb,DISK], DatanodeInfoWithStorage[127.0.0.1:42661,DS-6d9d0034-ef0a-46e6-928d-516e5e0458dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35126,DS-25d2b68e-8db8-42d3-80cb-44152d15604a,DISK], DatanodeInfoWithStorage[127.0.0.1:46663,DS-49598385-2023-4b1c-9289-b239fb84af7d,DISK], DatanodeInfoWithStorage[127.0.0.1:38810,DS-173fc2b0-9cce-441e-aee1-fcf513b48a46,DISK], DatanodeInfoWithStorage[127.0.0.1:37223,DS-95b1016a-c436-4738-99e9-b4ef96787ded,DISK], DatanodeInfoWithStorage[127.0.0.1:34255,DS-2da47944-6b2f-483c-a703-0b31a4964ba0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1383876345-172.17.0.14-1595321539048:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45930,DS-1b81a025-eafc-45c2-8c0d-cb576d428287,DISK], DatanodeInfoWithStorage[127.0.0.1:40326,DS-0745c1f5-b499-4e65-b54a-a68101cb4597,DISK], DatanodeInfoWithStorage[127.0.0.1:35244,DS-90e92056-bfbe-49b7-b251-1d1b6822418e,DISK], DatanodeInfoWithStorage[127.0.0.1:33501,DS-977d9faf-688f-4d5d-8b88-93caae766f38,DISK], DatanodeInfoWithStorage[127.0.0.1:45998,DS-f7085751-2882-4623-9ed3-b777c6af255d,DISK], DatanodeInfoWithStorage[127.0.0.1:41298,DS-4794beff-f3e9-45f1-a64a-5b529bc5da49,DISK], DatanodeInfoWithStorage[127.0.0.1:40798,DS-2e91f218-4747-486e-a2b4-7327ec02ecc7,DISK], DatanodeInfoWithStorage[127.0.0.1:33747,DS-843815ff-04d0-4e5a-afb0-3a7a1bca04d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1383876345-172.17.0.14-1595321539048:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45930,DS-1b81a025-eafc-45c2-8c0d-cb576d428287,DISK], DatanodeInfoWithStorage[127.0.0.1:40326,DS-0745c1f5-b499-4e65-b54a-a68101cb4597,DISK], DatanodeInfoWithStorage[127.0.0.1:35244,DS-90e92056-bfbe-49b7-b251-1d1b6822418e,DISK], DatanodeInfoWithStorage[127.0.0.1:33501,DS-977d9faf-688f-4d5d-8b88-93caae766f38,DISK], DatanodeInfoWithStorage[127.0.0.1:45998,DS-f7085751-2882-4623-9ed3-b777c6af255d,DISK], DatanodeInfoWithStorage[127.0.0.1:41298,DS-4794beff-f3e9-45f1-a64a-5b529bc5da49,DISK], DatanodeInfoWithStorage[127.0.0.1:40798,DS-2e91f218-4747-486e-a2b4-7327ec02ecc7,DISK], DatanodeInfoWithStorage[127.0.0.1:33747,DS-843815ff-04d0-4e5a-afb0-3a7a1bca04d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-214898637-172.17.0.14-1595321801651:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40376,DS-40eab95b-c78a-4c67-b952-3edf0cdf0c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:38021,DS-86a44cb9-313b-4b12-8ee5-62e65ca7aaf2,DISK], DatanodeInfoWithStorage[127.0.0.1:34932,DS-fc966c73-7ab3-44c6-829d-f56ee955c4b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36329,DS-1db699aa-4c12-4ca8-9b7c-d8c64b210018,DISK], DatanodeInfoWithStorage[127.0.0.1:36706,DS-6ea8aae8-8b90-4e98-baed-d69d3c96b6eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38333,DS-3bfe1cd3-5a35-4dad-8a0e-1198a6fbddb9,DISK], DatanodeInfoWithStorage[127.0.0.1:45130,DS-8e89c354-537d-4b43-9975-bef947eb07bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43382,DS-e46412bd-9ff0-44a0-9571-8dd1e36a3ab0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-214898637-172.17.0.14-1595321801651:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40376,DS-40eab95b-c78a-4c67-b952-3edf0cdf0c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:38021,DS-86a44cb9-313b-4b12-8ee5-62e65ca7aaf2,DISK], DatanodeInfoWithStorage[127.0.0.1:34932,DS-fc966c73-7ab3-44c6-829d-f56ee955c4b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36329,DS-1db699aa-4c12-4ca8-9b7c-d8c64b210018,DISK], DatanodeInfoWithStorage[127.0.0.1:36706,DS-6ea8aae8-8b90-4e98-baed-d69d3c96b6eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38333,DS-3bfe1cd3-5a35-4dad-8a0e-1198a6fbddb9,DISK], DatanodeInfoWithStorage[127.0.0.1:45130,DS-8e89c354-537d-4b43-9975-bef947eb07bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43382,DS-e46412bd-9ff0-44a0-9571-8dd1e36a3ab0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-557757040-172.17.0.14-1595322028984:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43435,DS-4c3a8388-e058-47af-acae-bb01d06ea069,DISK], DatanodeInfoWithStorage[127.0.0.1:39269,DS-1aae4aa9-3ba4-4811-aea9-1204085aa3ce,DISK], DatanodeInfoWithStorage[127.0.0.1:43843,DS-99088ab3-ce66-4b92-aa9d-d930168972ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45304,DS-f2037357-9fa1-40a9-bbd7-aa6acdf95c1a,DISK], DatanodeInfoWithStorage[127.0.0.1:41744,DS-8fb0a050-7618-4683-87e2-0b45f53fcaa8,DISK], DatanodeInfoWithStorage[127.0.0.1:45547,DS-b142c71e-d9d1-4cc1-9763-ca98edb2c39a,DISK], DatanodeInfoWithStorage[127.0.0.1:42141,DS-c0c7dfd2-d8a5-462e-ae64-12e23ba880a3,DISK], DatanodeInfoWithStorage[127.0.0.1:37125,DS-01d740a1-a064-4bfd-ac2d-91cc053108f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-557757040-172.17.0.14-1595322028984:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43435,DS-4c3a8388-e058-47af-acae-bb01d06ea069,DISK], DatanodeInfoWithStorage[127.0.0.1:39269,DS-1aae4aa9-3ba4-4811-aea9-1204085aa3ce,DISK], DatanodeInfoWithStorage[127.0.0.1:43843,DS-99088ab3-ce66-4b92-aa9d-d930168972ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45304,DS-f2037357-9fa1-40a9-bbd7-aa6acdf95c1a,DISK], DatanodeInfoWithStorage[127.0.0.1:41744,DS-8fb0a050-7618-4683-87e2-0b45f53fcaa8,DISK], DatanodeInfoWithStorage[127.0.0.1:45547,DS-b142c71e-d9d1-4cc1-9763-ca98edb2c39a,DISK], DatanodeInfoWithStorage[127.0.0.1:42141,DS-c0c7dfd2-d8a5-462e-ae64-12e23ba880a3,DISK], DatanodeInfoWithStorage[127.0.0.1:37125,DS-01d740a1-a064-4bfd-ac2d-91cc053108f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2047405934-172.17.0.14-1595322199150:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46180,DS-b181fee7-5ccc-4b41-98f6-a45f1380d421,DISK], DatanodeInfoWithStorage[127.0.0.1:39958,DS-76035e0c-d87e-4843-9d81-105de0050e94,DISK], DatanodeInfoWithStorage[127.0.0.1:33746,DS-b7dc5da1-b063-49ee-ac03-82c36018d6d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46268,DS-859e9f61-7818-45cd-b7a6-521c29b1e24b,DISK], DatanodeInfoWithStorage[127.0.0.1:36920,DS-dea2ab32-f078-406d-9274-a54bd23ca845,DISK], DatanodeInfoWithStorage[127.0.0.1:33661,DS-64592857-9fb3-483c-a037-a8d87f71fae6,DISK], DatanodeInfoWithStorage[127.0.0.1:46597,DS-f8b46eee-1f35-4997-90a4-7a6fc8a81d8c,DISK], DatanodeInfoWithStorage[127.0.0.1:42904,DS-0813f98c-b7bd-49c5-86ed-8e4c0928c8fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2047405934-172.17.0.14-1595322199150:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46180,DS-b181fee7-5ccc-4b41-98f6-a45f1380d421,DISK], DatanodeInfoWithStorage[127.0.0.1:39958,DS-76035e0c-d87e-4843-9d81-105de0050e94,DISK], DatanodeInfoWithStorage[127.0.0.1:33746,DS-b7dc5da1-b063-49ee-ac03-82c36018d6d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46268,DS-859e9f61-7818-45cd-b7a6-521c29b1e24b,DISK], DatanodeInfoWithStorage[127.0.0.1:36920,DS-dea2ab32-f078-406d-9274-a54bd23ca845,DISK], DatanodeInfoWithStorage[127.0.0.1:33661,DS-64592857-9fb3-483c-a037-a8d87f71fae6,DISK], DatanodeInfoWithStorage[127.0.0.1:46597,DS-f8b46eee-1f35-4997-90a4-7a6fc8a81d8c,DISK], DatanodeInfoWithStorage[127.0.0.1:42904,DS-0813f98c-b7bd-49c5-86ed-8e4c0928c8fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2031302192-172.17.0.14-1595322565307:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40136,DS-5eae2fe1-eb97-44c6-92ea-edb41f17790c,DISK], DatanodeInfoWithStorage[127.0.0.1:40696,DS-63cf874a-b744-4486-8330-81fcdb853497,DISK], DatanodeInfoWithStorage[127.0.0.1:40211,DS-7c0f632d-7575-4023-9513-eb68e70a1768,DISK], DatanodeInfoWithStorage[127.0.0.1:32962,DS-5d8b6e34-3494-4870-affe-5e6750d1eadb,DISK], DatanodeInfoWithStorage[127.0.0.1:33808,DS-7da90f5c-9ead-4634-8ebd-7de9a631b1c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34829,DS-35fae2fc-68da-4077-bbde-8a339e5df9b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45712,DS-4d059982-5b61-4e47-917c-1f4488afb81f,DISK], DatanodeInfoWithStorage[127.0.0.1:44583,DS-9b23e9b1-32d6-4629-80d9-2e711a5f5a4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2031302192-172.17.0.14-1595322565307:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40136,DS-5eae2fe1-eb97-44c6-92ea-edb41f17790c,DISK], DatanodeInfoWithStorage[127.0.0.1:40696,DS-63cf874a-b744-4486-8330-81fcdb853497,DISK], DatanodeInfoWithStorage[127.0.0.1:40211,DS-7c0f632d-7575-4023-9513-eb68e70a1768,DISK], DatanodeInfoWithStorage[127.0.0.1:32962,DS-5d8b6e34-3494-4870-affe-5e6750d1eadb,DISK], DatanodeInfoWithStorage[127.0.0.1:33808,DS-7da90f5c-9ead-4634-8ebd-7de9a631b1c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34829,DS-35fae2fc-68da-4077-bbde-8a339e5df9b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45712,DS-4d059982-5b61-4e47-917c-1f4488afb81f,DISK], DatanodeInfoWithStorage[127.0.0.1:44583,DS-9b23e9b1-32d6-4629-80d9-2e711a5f5a4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 5340
