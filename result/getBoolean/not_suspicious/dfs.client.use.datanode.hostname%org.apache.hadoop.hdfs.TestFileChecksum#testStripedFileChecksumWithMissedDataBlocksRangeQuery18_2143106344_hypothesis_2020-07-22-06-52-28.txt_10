reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1209869032-172.17.0.7-1595400836794:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39404,DS-4861e892-9d56-4780-8c85-bffb921afe4d,DISK], DatanodeInfoWithStorage[127.0.0.1:37286,DS-3658fdf2-358e-4776-9b4b-3a84bfd9f287,DISK], DatanodeInfoWithStorage[127.0.0.1:33227,DS-21b09684-93d7-49f2-b339-e68b19183f2c,DISK], DatanodeInfoWithStorage[127.0.0.1:41839,DS-cdb64917-51fb-4389-a8ed-11f3cbabf0b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36713,DS-8ed0bf7b-0062-4697-b4d3-146cc82460f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43208,DS-51e4ecd4-af9b-4eb8-9975-4e89df673b26,DISK], DatanodeInfoWithStorage[127.0.0.1:45386,DS-cd506c8c-253b-4f3c-99d2-0ca00a957819,DISK], DatanodeInfoWithStorage[127.0.0.1:36445,DS-2073a0bc-c5aa-4648-8949-ab321483df74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1209869032-172.17.0.7-1595400836794:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39404,DS-4861e892-9d56-4780-8c85-bffb921afe4d,DISK], DatanodeInfoWithStorage[127.0.0.1:37286,DS-3658fdf2-358e-4776-9b4b-3a84bfd9f287,DISK], DatanodeInfoWithStorage[127.0.0.1:33227,DS-21b09684-93d7-49f2-b339-e68b19183f2c,DISK], DatanodeInfoWithStorage[127.0.0.1:41839,DS-cdb64917-51fb-4389-a8ed-11f3cbabf0b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36713,DS-8ed0bf7b-0062-4697-b4d3-146cc82460f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43208,DS-51e4ecd4-af9b-4eb8-9975-4e89df673b26,DISK], DatanodeInfoWithStorage[127.0.0.1:45386,DS-cd506c8c-253b-4f3c-99d2-0ca00a957819,DISK], DatanodeInfoWithStorage[127.0.0.1:36445,DS-2073a0bc-c5aa-4648-8949-ab321483df74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-271897248-172.17.0.7-1595401178158:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35519,DS-524672d7-4f69-4cac-bce2-5d2abf98111f,DISK], DatanodeInfoWithStorage[127.0.0.1:37869,DS-c71942e7-391a-43d7-b8ab-148ce3703d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:37509,DS-e10235d0-3063-4e83-b427-2f2e18a0b8b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40100,DS-11457d3b-db63-4620-9830-843bf1047f25,DISK], DatanodeInfoWithStorage[127.0.0.1:44630,DS-e9d091f6-11d6-48f3-aa73-54d50b873a0a,DISK], DatanodeInfoWithStorage[127.0.0.1:45967,DS-64c7e6f3-2898-4730-822b-a08506c02d00,DISK], DatanodeInfoWithStorage[127.0.0.1:38038,DS-f8cce0d5-f6c2-449f-8c9e-fc8452fc74cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34327,DS-afc22807-47e8-47a7-8e4f-5b111adf10c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-271897248-172.17.0.7-1595401178158:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35519,DS-524672d7-4f69-4cac-bce2-5d2abf98111f,DISK], DatanodeInfoWithStorage[127.0.0.1:37869,DS-c71942e7-391a-43d7-b8ab-148ce3703d7b,DISK], DatanodeInfoWithStorage[127.0.0.1:37509,DS-e10235d0-3063-4e83-b427-2f2e18a0b8b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40100,DS-11457d3b-db63-4620-9830-843bf1047f25,DISK], DatanodeInfoWithStorage[127.0.0.1:44630,DS-e9d091f6-11d6-48f3-aa73-54d50b873a0a,DISK], DatanodeInfoWithStorage[127.0.0.1:45967,DS-64c7e6f3-2898-4730-822b-a08506c02d00,DISK], DatanodeInfoWithStorage[127.0.0.1:38038,DS-f8cce0d5-f6c2-449f-8c9e-fc8452fc74cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34327,DS-afc22807-47e8-47a7-8e4f-5b111adf10c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-896512184-172.17.0.7-1595401674807:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35433,DS-dd7c236c-6bf5-4d9b-af4c-2e384b56828d,DISK], DatanodeInfoWithStorage[127.0.0.1:35697,DS-3888e852-ff5a-419f-9251-8cb451db28ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41514,DS-258e6f5b-be3f-4532-afc9-ea9c5b18c630,DISK], DatanodeInfoWithStorage[127.0.0.1:34101,DS-08eb91e4-535f-41e9-af82-53147010675f,DISK], DatanodeInfoWithStorage[127.0.0.1:42061,DS-168b052b-7fa4-4961-bba6-86be81186d7f,DISK], DatanodeInfoWithStorage[127.0.0.1:37661,DS-5985c619-00fd-442d-ae4e-824da9dc7b96,DISK], DatanodeInfoWithStorage[127.0.0.1:42703,DS-563fe1cc-a624-430f-b682-430c61b9ec57,DISK], DatanodeInfoWithStorage[127.0.0.1:44684,DS-9c80420a-5d9c-48a0-971e-94f839a5d540,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-896512184-172.17.0.7-1595401674807:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35433,DS-dd7c236c-6bf5-4d9b-af4c-2e384b56828d,DISK], DatanodeInfoWithStorage[127.0.0.1:35697,DS-3888e852-ff5a-419f-9251-8cb451db28ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41514,DS-258e6f5b-be3f-4532-afc9-ea9c5b18c630,DISK], DatanodeInfoWithStorage[127.0.0.1:34101,DS-08eb91e4-535f-41e9-af82-53147010675f,DISK], DatanodeInfoWithStorage[127.0.0.1:42061,DS-168b052b-7fa4-4961-bba6-86be81186d7f,DISK], DatanodeInfoWithStorage[127.0.0.1:37661,DS-5985c619-00fd-442d-ae4e-824da9dc7b96,DISK], DatanodeInfoWithStorage[127.0.0.1:42703,DS-563fe1cc-a624-430f-b682-430c61b9ec57,DISK], DatanodeInfoWithStorage[127.0.0.1:44684,DS-9c80420a-5d9c-48a0-971e-94f839a5d540,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-638574106-172.17.0.7-1595401790280:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41679,DS-83dccc08-633f-48c3-8126-d89f84cdbb98,DISK], DatanodeInfoWithStorage[127.0.0.1:36950,DS-d9852a57-415e-4a5a-a4d8-918d525a8ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:39865,DS-05032161-2a05-4dc0-a315-f9e3147d4a8c,DISK], DatanodeInfoWithStorage[127.0.0.1:37430,DS-08a55bbd-9cc7-48e9-8994-845338e61535,DISK], DatanodeInfoWithStorage[127.0.0.1:40412,DS-edc5c7b8-8115-445e-b061-64e8cdee0a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:40569,DS-1020cb46-27c9-40e1-8c32-b991c917a9d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40767,DS-9e5fb9a1-9ce5-4cb8-9ef2-2b9d432e7eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:42273,DS-ed6af1f3-d40d-4ee2-b4e4-f46600a69fd4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-638574106-172.17.0.7-1595401790280:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41679,DS-83dccc08-633f-48c3-8126-d89f84cdbb98,DISK], DatanodeInfoWithStorage[127.0.0.1:36950,DS-d9852a57-415e-4a5a-a4d8-918d525a8ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:39865,DS-05032161-2a05-4dc0-a315-f9e3147d4a8c,DISK], DatanodeInfoWithStorage[127.0.0.1:37430,DS-08a55bbd-9cc7-48e9-8994-845338e61535,DISK], DatanodeInfoWithStorage[127.0.0.1:40412,DS-edc5c7b8-8115-445e-b061-64e8cdee0a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:40569,DS-1020cb46-27c9-40e1-8c32-b991c917a9d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40767,DS-9e5fb9a1-9ce5-4cb8-9ef2-2b9d432e7eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:42273,DS-ed6af1f3-d40d-4ee2-b4e4-f46600a69fd4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1033803311-172.17.0.7-1595401857128:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38425,DS-4a3eb012-00b2-441a-b8cf-0f5e32384ac5,DISK], DatanodeInfoWithStorage[127.0.0.1:35687,DS-59041b44-289d-44b8-a19f-f18225edd622,DISK], DatanodeInfoWithStorage[127.0.0.1:34290,DS-6575c9d5-9c6e-4a05-8fc0-c1f18f124386,DISK], DatanodeInfoWithStorage[127.0.0.1:43225,DS-a49dd99f-fdb0-496b-8a8b-59c5cc479ad0,DISK], DatanodeInfoWithStorage[127.0.0.1:35462,DS-13bcefd8-ee0b-45af-960c-06920c3f92af,DISK], DatanodeInfoWithStorage[127.0.0.1:46568,DS-82bfdfa4-eec2-4541-a760-d09f250d1363,DISK], DatanodeInfoWithStorage[127.0.0.1:33240,DS-77064aea-88a9-4e3a-beb1-dc9b652abf08,DISK], DatanodeInfoWithStorage[127.0.0.1:42706,DS-fb83b4a2-bf40-4bde-be77-c6b80881be0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1033803311-172.17.0.7-1595401857128:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38425,DS-4a3eb012-00b2-441a-b8cf-0f5e32384ac5,DISK], DatanodeInfoWithStorage[127.0.0.1:35687,DS-59041b44-289d-44b8-a19f-f18225edd622,DISK], DatanodeInfoWithStorage[127.0.0.1:34290,DS-6575c9d5-9c6e-4a05-8fc0-c1f18f124386,DISK], DatanodeInfoWithStorage[127.0.0.1:43225,DS-a49dd99f-fdb0-496b-8a8b-59c5cc479ad0,DISK], DatanodeInfoWithStorage[127.0.0.1:35462,DS-13bcefd8-ee0b-45af-960c-06920c3f92af,DISK], DatanodeInfoWithStorage[127.0.0.1:46568,DS-82bfdfa4-eec2-4541-a760-d09f250d1363,DISK], DatanodeInfoWithStorage[127.0.0.1:33240,DS-77064aea-88a9-4e3a-beb1-dc9b652abf08,DISK], DatanodeInfoWithStorage[127.0.0.1:42706,DS-fb83b4a2-bf40-4bde-be77-c6b80881be0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-832707083-172.17.0.7-1595402039197:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34083,DS-4189b3d4-8663-4591-b4ea-4df8e061954a,DISK], DatanodeInfoWithStorage[127.0.0.1:44723,DS-77697c2d-b353-4dfd-ac4e-ba7982730e55,DISK], DatanodeInfoWithStorage[127.0.0.1:42747,DS-eb58bb70-38de-419d-b1ae-a7eaf0bfba79,DISK], DatanodeInfoWithStorage[127.0.0.1:44443,DS-c9f24c01-328c-4ce5-9e2d-f46d12044fb7,DISK], DatanodeInfoWithStorage[127.0.0.1:35037,DS-f8d42cdb-ed6d-4ee5-a56c-13085d5a347a,DISK], DatanodeInfoWithStorage[127.0.0.1:38940,DS-5c9d1ed0-1e54-47e5-8507-d961dc5b4b52,DISK], DatanodeInfoWithStorage[127.0.0.1:37450,DS-a4db0065-3352-4852-ae58-fb60806e9b53,DISK], DatanodeInfoWithStorage[127.0.0.1:43253,DS-00754d93-7e4d-487c-ac40-12dabfe0a18a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-832707083-172.17.0.7-1595402039197:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34083,DS-4189b3d4-8663-4591-b4ea-4df8e061954a,DISK], DatanodeInfoWithStorage[127.0.0.1:44723,DS-77697c2d-b353-4dfd-ac4e-ba7982730e55,DISK], DatanodeInfoWithStorage[127.0.0.1:42747,DS-eb58bb70-38de-419d-b1ae-a7eaf0bfba79,DISK], DatanodeInfoWithStorage[127.0.0.1:44443,DS-c9f24c01-328c-4ce5-9e2d-f46d12044fb7,DISK], DatanodeInfoWithStorage[127.0.0.1:35037,DS-f8d42cdb-ed6d-4ee5-a56c-13085d5a347a,DISK], DatanodeInfoWithStorage[127.0.0.1:38940,DS-5c9d1ed0-1e54-47e5-8507-d961dc5b4b52,DISK], DatanodeInfoWithStorage[127.0.0.1:37450,DS-a4db0065-3352-4852-ae58-fb60806e9b53,DISK], DatanodeInfoWithStorage[127.0.0.1:43253,DS-00754d93-7e4d-487c-ac40-12dabfe0a18a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1079438276-172.17.0.7-1595402262893:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39007,DS-50440993-bbe2-430d-b137-c4524dad98eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40981,DS-737f8fe7-26e8-4244-a4de-eb87082e1008,DISK], DatanodeInfoWithStorage[127.0.0.1:33133,DS-f6857b70-0583-4af1-ad0e-b59267ed05a3,DISK], DatanodeInfoWithStorage[127.0.0.1:39620,DS-7da1dd9c-e8ad-46ba-a2c7-7aecd98b8114,DISK], DatanodeInfoWithStorage[127.0.0.1:35440,DS-8b4a63ca-6653-4fa1-84f0-185cc681c4b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41795,DS-cc860589-b6ff-4431-8cbf-979adb278be4,DISK], DatanodeInfoWithStorage[127.0.0.1:46425,DS-4c89218f-30fd-4291-ae89-5ccb8ef53962,DISK], DatanodeInfoWithStorage[127.0.0.1:37270,DS-665b8cc4-4b06-4095-a09b-ef8886657826,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1079438276-172.17.0.7-1595402262893:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39007,DS-50440993-bbe2-430d-b137-c4524dad98eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40981,DS-737f8fe7-26e8-4244-a4de-eb87082e1008,DISK], DatanodeInfoWithStorage[127.0.0.1:33133,DS-f6857b70-0583-4af1-ad0e-b59267ed05a3,DISK], DatanodeInfoWithStorage[127.0.0.1:39620,DS-7da1dd9c-e8ad-46ba-a2c7-7aecd98b8114,DISK], DatanodeInfoWithStorage[127.0.0.1:35440,DS-8b4a63ca-6653-4fa1-84f0-185cc681c4b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41795,DS-cc860589-b6ff-4431-8cbf-979adb278be4,DISK], DatanodeInfoWithStorage[127.0.0.1:46425,DS-4c89218f-30fd-4291-ae89-5ccb8ef53962,DISK], DatanodeInfoWithStorage[127.0.0.1:37270,DS-665b8cc4-4b06-4095-a09b-ef8886657826,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-721485781-172.17.0.7-1595402301135:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33474,DS-15596df9-13e1-4297-bb73-c079b4a13404,DISK], DatanodeInfoWithStorage[127.0.0.1:44687,DS-6350bc2e-0549-4d87-9cf0-b093ad14ea04,DISK], DatanodeInfoWithStorage[127.0.0.1:36403,DS-44820cb6-6386-4eaf-a105-be772efc8968,DISK], DatanodeInfoWithStorage[127.0.0.1:41741,DS-dca13b88-44eb-4beb-94cf-02bd0f734655,DISK], DatanodeInfoWithStorage[127.0.0.1:43531,DS-6fc52d43-3e4b-4e99-91ee-ebccdc50e22e,DISK], DatanodeInfoWithStorage[127.0.0.1:36195,DS-2e18f0c7-28ff-4bd9-a229-2cc8afa16e26,DISK], DatanodeInfoWithStorage[127.0.0.1:40790,DS-2596e974-77cc-4330-8f36-e6ac771a0bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:45198,DS-291745e7-7e27-4e8e-88e7-57e9ad3ba2cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-721485781-172.17.0.7-1595402301135:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33474,DS-15596df9-13e1-4297-bb73-c079b4a13404,DISK], DatanodeInfoWithStorage[127.0.0.1:44687,DS-6350bc2e-0549-4d87-9cf0-b093ad14ea04,DISK], DatanodeInfoWithStorage[127.0.0.1:36403,DS-44820cb6-6386-4eaf-a105-be772efc8968,DISK], DatanodeInfoWithStorage[127.0.0.1:41741,DS-dca13b88-44eb-4beb-94cf-02bd0f734655,DISK], DatanodeInfoWithStorage[127.0.0.1:43531,DS-6fc52d43-3e4b-4e99-91ee-ebccdc50e22e,DISK], DatanodeInfoWithStorage[127.0.0.1:36195,DS-2e18f0c7-28ff-4bd9-a229-2cc8afa16e26,DISK], DatanodeInfoWithStorage[127.0.0.1:40790,DS-2596e974-77cc-4330-8f36-e6ac771a0bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:45198,DS-291745e7-7e27-4e8e-88e7-57e9ad3ba2cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-849816641-172.17.0.7-1595402486656:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34209,DS-52357ff3-b203-4f2b-aaa3-a56f48b688ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42033,DS-aa0b43b5-4e7d-4503-bcd6-00197b0544f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37391,DS-e8be6988-f793-4e42-a805-a8c9e893c243,DISK], DatanodeInfoWithStorage[127.0.0.1:35735,DS-9e86b3ae-c59a-4629-99c5-a8d50a4bd4ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46657,DS-f198ac84-d8d4-4063-a07a-69fb8b2eacae,DISK], DatanodeInfoWithStorage[127.0.0.1:36001,DS-a90edc1f-ee42-42a7-a689-72477f518c74,DISK], DatanodeInfoWithStorage[127.0.0.1:38829,DS-f11fe520-13fc-4500-a2fe-507ab4d66af1,DISK], DatanodeInfoWithStorage[127.0.0.1:36283,DS-28cfe834-caf9-4b2a-bfd5-b2903ab6f7af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-849816641-172.17.0.7-1595402486656:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34209,DS-52357ff3-b203-4f2b-aaa3-a56f48b688ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42033,DS-aa0b43b5-4e7d-4503-bcd6-00197b0544f0,DISK], DatanodeInfoWithStorage[127.0.0.1:37391,DS-e8be6988-f793-4e42-a805-a8c9e893c243,DISK], DatanodeInfoWithStorage[127.0.0.1:35735,DS-9e86b3ae-c59a-4629-99c5-a8d50a4bd4ef,DISK], DatanodeInfoWithStorage[127.0.0.1:46657,DS-f198ac84-d8d4-4063-a07a-69fb8b2eacae,DISK], DatanodeInfoWithStorage[127.0.0.1:36001,DS-a90edc1f-ee42-42a7-a689-72477f518c74,DISK], DatanodeInfoWithStorage[127.0.0.1:38829,DS-f11fe520-13fc-4500-a2fe-507ab4d66af1,DISK], DatanodeInfoWithStorage[127.0.0.1:36283,DS-28cfe834-caf9-4b2a-bfd5-b2903ab6f7af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1328427793-172.17.0.7-1595402929862:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45536,DS-807b6dce-ff3c-4acf-8dc9-82fa86d38452,DISK], DatanodeInfoWithStorage[127.0.0.1:44818,DS-3fb642f1-062a-4229-9155-4327bb2b83f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44634,DS-155c859e-bea5-4b3d-9127-d72f8afb8b46,DISK], DatanodeInfoWithStorage[127.0.0.1:40228,DS-d6b342a5-e9ba-408f-97c2-5853ffd04799,DISK], DatanodeInfoWithStorage[127.0.0.1:40615,DS-bb6dd291-dd90-4da5-ac1e-590a56c7e5d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36750,DS-ce96c916-cbef-4a8d-a56c-b905533f5649,DISK], DatanodeInfoWithStorage[127.0.0.1:44067,DS-f7169808-21b8-465b-ad60-6c5cfc56493a,DISK], DatanodeInfoWithStorage[127.0.0.1:37889,DS-c0bdccb3-654b-42e7-a7cb-e57820a5ef00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1328427793-172.17.0.7-1595402929862:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45536,DS-807b6dce-ff3c-4acf-8dc9-82fa86d38452,DISK], DatanodeInfoWithStorage[127.0.0.1:44818,DS-3fb642f1-062a-4229-9155-4327bb2b83f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44634,DS-155c859e-bea5-4b3d-9127-d72f8afb8b46,DISK], DatanodeInfoWithStorage[127.0.0.1:40228,DS-d6b342a5-e9ba-408f-97c2-5853ffd04799,DISK], DatanodeInfoWithStorage[127.0.0.1:40615,DS-bb6dd291-dd90-4da5-ac1e-590a56c7e5d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36750,DS-ce96c916-cbef-4a8d-a56c-b905533f5649,DISK], DatanodeInfoWithStorage[127.0.0.1:44067,DS-f7169808-21b8-465b-ad60-6c5cfc56493a,DISK], DatanodeInfoWithStorage[127.0.0.1:37889,DS-c0bdccb3-654b-42e7-a7cb-e57820a5ef00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-67525404-172.17.0.7-1595403929274:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35579,DS-e98a5e35-77d6-4c7e-9175-a485c063eabb,DISK], DatanodeInfoWithStorage[127.0.0.1:42804,DS-66c8d05f-0030-45af-9414-ac705375adc8,DISK], DatanodeInfoWithStorage[127.0.0.1:39561,DS-e57ac632-8f01-46c3-81f3-f3fa5ef77005,DISK], DatanodeInfoWithStorage[127.0.0.1:38502,DS-67167d91-5dc2-4df6-b700-d4e269c073c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42088,DS-743fd707-7029-4d11-93b1-ff757699a519,DISK], DatanodeInfoWithStorage[127.0.0.1:46124,DS-0b1daa06-a2aa-46b3-970f-f0905700b08a,DISK], DatanodeInfoWithStorage[127.0.0.1:40780,DS-8a3fa52a-de9b-4dc7-9256-a46638349e7b,DISK], DatanodeInfoWithStorage[127.0.0.1:33534,DS-4e035b2a-518f-4565-82c3-d483dbea7a39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-67525404-172.17.0.7-1595403929274:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35579,DS-e98a5e35-77d6-4c7e-9175-a485c063eabb,DISK], DatanodeInfoWithStorage[127.0.0.1:42804,DS-66c8d05f-0030-45af-9414-ac705375adc8,DISK], DatanodeInfoWithStorage[127.0.0.1:39561,DS-e57ac632-8f01-46c3-81f3-f3fa5ef77005,DISK], DatanodeInfoWithStorage[127.0.0.1:38502,DS-67167d91-5dc2-4df6-b700-d4e269c073c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42088,DS-743fd707-7029-4d11-93b1-ff757699a519,DISK], DatanodeInfoWithStorage[127.0.0.1:46124,DS-0b1daa06-a2aa-46b3-970f-f0905700b08a,DISK], DatanodeInfoWithStorage[127.0.0.1:40780,DS-8a3fa52a-de9b-4dc7-9256-a46638349e7b,DISK], DatanodeInfoWithStorage[127.0.0.1:33534,DS-4e035b2a-518f-4565-82c3-d483dbea7a39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1057336085-172.17.0.7-1595403999696:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42989,DS-7b785753-9887-42ef-85e7-c3fb19f7da75,DISK], DatanodeInfoWithStorage[127.0.0.1:39251,DS-a618566e-21b2-499e-b21d-91b67a6e7f58,DISK], DatanodeInfoWithStorage[127.0.0.1:42359,DS-b86334ff-5813-4c71-b4f3-b2bbe7a5e88c,DISK], DatanodeInfoWithStorage[127.0.0.1:43356,DS-443deb81-0f50-473c-86bb-28d90ed2acc2,DISK], DatanodeInfoWithStorage[127.0.0.1:36411,DS-5c51b808-55cd-4ec6-8631-484f1b390043,DISK], DatanodeInfoWithStorage[127.0.0.1:43891,DS-5b73934a-6d1c-4d79-9248-a543d15aae89,DISK], DatanodeInfoWithStorage[127.0.0.1:37917,DS-2516ee04-6121-43c4-860b-73fe309f661d,DISK], DatanodeInfoWithStorage[127.0.0.1:41048,DS-ed6c914e-7e96-45dc-9c51-ed347bbdb3c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1057336085-172.17.0.7-1595403999696:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42989,DS-7b785753-9887-42ef-85e7-c3fb19f7da75,DISK], DatanodeInfoWithStorage[127.0.0.1:39251,DS-a618566e-21b2-499e-b21d-91b67a6e7f58,DISK], DatanodeInfoWithStorage[127.0.0.1:42359,DS-b86334ff-5813-4c71-b4f3-b2bbe7a5e88c,DISK], DatanodeInfoWithStorage[127.0.0.1:43356,DS-443deb81-0f50-473c-86bb-28d90ed2acc2,DISK], DatanodeInfoWithStorage[127.0.0.1:36411,DS-5c51b808-55cd-4ec6-8631-484f1b390043,DISK], DatanodeInfoWithStorage[127.0.0.1:43891,DS-5b73934a-6d1c-4d79-9248-a543d15aae89,DISK], DatanodeInfoWithStorage[127.0.0.1:37917,DS-2516ee04-6121-43c4-860b-73fe309f661d,DISK], DatanodeInfoWithStorage[127.0.0.1:41048,DS-ed6c914e-7e96-45dc-9c51-ed347bbdb3c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1522285906-172.17.0.7-1595404134517:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44333,DS-0943a3db-d18b-42aa-aa6d-8beddeb06ee9,DISK], DatanodeInfoWithStorage[127.0.0.1:41663,DS-15901f9d-7119-42c1-8af2-edb617d5c834,DISK], DatanodeInfoWithStorage[127.0.0.1:43159,DS-37783cc3-0776-437b-ba51-a4df18329c87,DISK], DatanodeInfoWithStorage[127.0.0.1:43314,DS-2067675a-dc41-4690-a06a-8886a3cfee70,DISK], DatanodeInfoWithStorage[127.0.0.1:35065,DS-ac1617f9-9820-4341-924f-5f2ef10e655c,DISK], DatanodeInfoWithStorage[127.0.0.1:35480,DS-2fb06cf3-4d3b-4155-95b7-ec78afcf4087,DISK], DatanodeInfoWithStorage[127.0.0.1:39173,DS-5cdcb747-2b6a-4df0-afc1-5bf1bb3e1469,DISK], DatanodeInfoWithStorage[127.0.0.1:44567,DS-41b02f9c-b678-4678-8607-c1d6026c0f40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1522285906-172.17.0.7-1595404134517:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44333,DS-0943a3db-d18b-42aa-aa6d-8beddeb06ee9,DISK], DatanodeInfoWithStorage[127.0.0.1:41663,DS-15901f9d-7119-42c1-8af2-edb617d5c834,DISK], DatanodeInfoWithStorage[127.0.0.1:43159,DS-37783cc3-0776-437b-ba51-a4df18329c87,DISK], DatanodeInfoWithStorage[127.0.0.1:43314,DS-2067675a-dc41-4690-a06a-8886a3cfee70,DISK], DatanodeInfoWithStorage[127.0.0.1:35065,DS-ac1617f9-9820-4341-924f-5f2ef10e655c,DISK], DatanodeInfoWithStorage[127.0.0.1:35480,DS-2fb06cf3-4d3b-4155-95b7-ec78afcf4087,DISK], DatanodeInfoWithStorage[127.0.0.1:39173,DS-5cdcb747-2b6a-4df0-afc1-5bf1bb3e1469,DISK], DatanodeInfoWithStorage[127.0.0.1:44567,DS-41b02f9c-b678-4678-8607-c1d6026c0f40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-593064963-172.17.0.7-1595404492238:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43255,DS-10969b12-23f0-49af-8aea-4c59a43f3e04,DISK], DatanodeInfoWithStorage[127.0.0.1:44289,DS-239c0d45-e06d-445a-97df-fe0ab039c04b,DISK], DatanodeInfoWithStorage[127.0.0.1:32958,DS-bf8030b2-637d-4315-9f4c-359e843156f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33488,DS-af714562-fb6c-4910-88cf-88fcca3109a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34840,DS-059b9441-5718-4a31-b129-7f41a7f05604,DISK], DatanodeInfoWithStorage[127.0.0.1:43993,DS-79b9663d-600a-4bf3-8a01-0537cef11626,DISK], DatanodeInfoWithStorage[127.0.0.1:40978,DS-4323885e-6a28-488c-bc05-084aa0119548,DISK], DatanodeInfoWithStorage[127.0.0.1:45373,DS-5d89cfc6-4994-4584-a80a-dbc8a6443e82,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-593064963-172.17.0.7-1595404492238:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43255,DS-10969b12-23f0-49af-8aea-4c59a43f3e04,DISK], DatanodeInfoWithStorage[127.0.0.1:44289,DS-239c0d45-e06d-445a-97df-fe0ab039c04b,DISK], DatanodeInfoWithStorage[127.0.0.1:32958,DS-bf8030b2-637d-4315-9f4c-359e843156f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33488,DS-af714562-fb6c-4910-88cf-88fcca3109a3,DISK], DatanodeInfoWithStorage[127.0.0.1:34840,DS-059b9441-5718-4a31-b129-7f41a7f05604,DISK], DatanodeInfoWithStorage[127.0.0.1:43993,DS-79b9663d-600a-4bf3-8a01-0537cef11626,DISK], DatanodeInfoWithStorage[127.0.0.1:40978,DS-4323885e-6a28-488c-bc05-084aa0119548,DISK], DatanodeInfoWithStorage[127.0.0.1:45373,DS-5d89cfc6-4994-4584-a80a-dbc8a6443e82,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1307117763-172.17.0.7-1595404667686:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46626,DS-f9cdf4d3-a281-447a-9ce7-d98578e187de,DISK], DatanodeInfoWithStorage[127.0.0.1:41349,DS-60bf384a-306b-46ca-a55d-fb30c9a98643,DISK], DatanodeInfoWithStorage[127.0.0.1:42668,DS-8930c961-6a34-42a0-a565-6eed6c0efa48,DISK], DatanodeInfoWithStorage[127.0.0.1:36492,DS-2ebb6b78-6520-4fa7-a406-a765a02f9a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:44857,DS-5ad45b21-0583-4f42-9cbc-07c508ec8ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:35998,DS-07a1d59c-3bcf-40c4-9e17-249ece9617a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36379,DS-980a2132-350f-4630-8b89-c77950b0ee9d,DISK], DatanodeInfoWithStorage[127.0.0.1:45044,DS-a3d1ef78-66d7-4d19-b280-63e615a615ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1307117763-172.17.0.7-1595404667686:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46626,DS-f9cdf4d3-a281-447a-9ce7-d98578e187de,DISK], DatanodeInfoWithStorage[127.0.0.1:41349,DS-60bf384a-306b-46ca-a55d-fb30c9a98643,DISK], DatanodeInfoWithStorage[127.0.0.1:42668,DS-8930c961-6a34-42a0-a565-6eed6c0efa48,DISK], DatanodeInfoWithStorage[127.0.0.1:36492,DS-2ebb6b78-6520-4fa7-a406-a765a02f9a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:44857,DS-5ad45b21-0583-4f42-9cbc-07c508ec8ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:35998,DS-07a1d59c-3bcf-40c4-9e17-249ece9617a8,DISK], DatanodeInfoWithStorage[127.0.0.1:36379,DS-980a2132-350f-4630-8b89-c77950b0ee9d,DISK], DatanodeInfoWithStorage[127.0.0.1:45044,DS-a3d1ef78-66d7-4d19-b280-63e615a615ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1254958332-172.17.0.7-1595404874542:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43879,DS-5cde2369-87cb-4396-be28-949dc844e8f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37153,DS-622e578b-bb06-49dd-9922-d29146750755,DISK], DatanodeInfoWithStorage[127.0.0.1:39995,DS-5ec4246e-eb8a-44ee-b7cb-4e75f816dee4,DISK], DatanodeInfoWithStorage[127.0.0.1:42249,DS-6c9de517-7968-4e66-bd36-275e51af6b27,DISK], DatanodeInfoWithStorage[127.0.0.1:39596,DS-8f7085b3-f161-49fe-930f-1579d51f3c9a,DISK], DatanodeInfoWithStorage[127.0.0.1:43233,DS-20b7680f-c627-4f76-be08-3858d408fc1a,DISK], DatanodeInfoWithStorage[127.0.0.1:41999,DS-83e4dd42-f396-4890-b597-a14e1d478ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:40840,DS-938b961a-0451-4a15-957c-9f1feaf17b4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1254958332-172.17.0.7-1595404874542:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43879,DS-5cde2369-87cb-4396-be28-949dc844e8f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37153,DS-622e578b-bb06-49dd-9922-d29146750755,DISK], DatanodeInfoWithStorage[127.0.0.1:39995,DS-5ec4246e-eb8a-44ee-b7cb-4e75f816dee4,DISK], DatanodeInfoWithStorage[127.0.0.1:42249,DS-6c9de517-7968-4e66-bd36-275e51af6b27,DISK], DatanodeInfoWithStorage[127.0.0.1:39596,DS-8f7085b3-f161-49fe-930f-1579d51f3c9a,DISK], DatanodeInfoWithStorage[127.0.0.1:43233,DS-20b7680f-c627-4f76-be08-3858d408fc1a,DISK], DatanodeInfoWithStorage[127.0.0.1:41999,DS-83e4dd42-f396-4890-b597-a14e1d478ab6,DISK], DatanodeInfoWithStorage[127.0.0.1:40840,DS-938b961a-0451-4a15-957c-9f1feaf17b4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-919484889-172.17.0.7-1595405008946:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40960,DS-b85e0080-ad20-49ec-8d29-982d375021da,DISK], DatanodeInfoWithStorage[127.0.0.1:40176,DS-85cf7ef9-4da2-4d38-bc31-11e843d90007,DISK], DatanodeInfoWithStorage[127.0.0.1:35589,DS-b049171e-1ec9-40d1-960f-349926a83eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:44941,DS-11b9c24c-0d25-40e7-bdb6-ae7bb091750e,DISK], DatanodeInfoWithStorage[127.0.0.1:46258,DS-097c579e-b704-4cf4-a364-0fe433c52c27,DISK], DatanodeInfoWithStorage[127.0.0.1:44649,DS-f0d07f78-2b15-4565-8dcb-a2514798ebc1,DISK], DatanodeInfoWithStorage[127.0.0.1:41836,DS-c344ab41-b75b-4ed6-8005-cc6b49bb865f,DISK], DatanodeInfoWithStorage[127.0.0.1:39147,DS-b130b57c-6d2e-4760-b23f-278e90d3fd03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-919484889-172.17.0.7-1595405008946:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40960,DS-b85e0080-ad20-49ec-8d29-982d375021da,DISK], DatanodeInfoWithStorage[127.0.0.1:40176,DS-85cf7ef9-4da2-4d38-bc31-11e843d90007,DISK], DatanodeInfoWithStorage[127.0.0.1:35589,DS-b049171e-1ec9-40d1-960f-349926a83eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:44941,DS-11b9c24c-0d25-40e7-bdb6-ae7bb091750e,DISK], DatanodeInfoWithStorage[127.0.0.1:46258,DS-097c579e-b704-4cf4-a364-0fe433c52c27,DISK], DatanodeInfoWithStorage[127.0.0.1:44649,DS-f0d07f78-2b15-4565-8dcb-a2514798ebc1,DISK], DatanodeInfoWithStorage[127.0.0.1:41836,DS-c344ab41-b75b-4ed6-8005-cc6b49bb865f,DISK], DatanodeInfoWithStorage[127.0.0.1:39147,DS-b130b57c-6d2e-4760-b23f-278e90d3fd03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.datanode.hostname
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-221241200-172.17.0.7-1595405586716:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39973,DS-52a7b923-2a4c-45fc-9680-205efe9f3e06,DISK], DatanodeInfoWithStorage[127.0.0.1:41764,DS-1d178b33-550f-49fe-b3c5-9a222b47cb08,DISK], DatanodeInfoWithStorage[127.0.0.1:34507,DS-b8c42b97-0114-4d7e-a844-a61ab36fb99c,DISK], DatanodeInfoWithStorage[127.0.0.1:43469,DS-e49d3b18-2c9e-447b-a4ee-c1b213768c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:41727,DS-0412d9c2-d41e-4d59-8033-5f25e3412976,DISK], DatanodeInfoWithStorage[127.0.0.1:44412,DS-1e3d4063-62a1-4805-8d29-02b6ca66e302,DISK], DatanodeInfoWithStorage[127.0.0.1:42225,DS-617eb2b7-6fab-422f-997a-59053b65c074,DISK], DatanodeInfoWithStorage[127.0.0.1:38564,DS-d89a82ad-805b-4f67-b8e3-b61eb9f80621,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-221241200-172.17.0.7-1595405586716:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39973,DS-52a7b923-2a4c-45fc-9680-205efe9f3e06,DISK], DatanodeInfoWithStorage[127.0.0.1:41764,DS-1d178b33-550f-49fe-b3c5-9a222b47cb08,DISK], DatanodeInfoWithStorage[127.0.0.1:34507,DS-b8c42b97-0114-4d7e-a844-a61ab36fb99c,DISK], DatanodeInfoWithStorage[127.0.0.1:43469,DS-e49d3b18-2c9e-447b-a4ee-c1b213768c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:41727,DS-0412d9c2-d41e-4d59-8033-5f25e3412976,DISK], DatanodeInfoWithStorage[127.0.0.1:44412,DS-1e3d4063-62a1-4805-8d29-02b6ca66e302,DISK], DatanodeInfoWithStorage[127.0.0.1:42225,DS-617eb2b7-6fab-422f-997a-59053b65c074,DISK], DatanodeInfoWithStorage[127.0.0.1:38564,DS-d89a82ad-805b-4f67-b8e3-b61eb9f80621,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5470
