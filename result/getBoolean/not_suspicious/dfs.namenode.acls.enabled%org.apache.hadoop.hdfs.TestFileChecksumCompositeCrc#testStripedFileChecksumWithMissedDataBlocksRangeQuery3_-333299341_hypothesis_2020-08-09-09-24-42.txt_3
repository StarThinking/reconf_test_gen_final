reconf_parameter: dfs.namenode.acls.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.acls.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1253243602-172.17.0.21-1596965096447:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42776,DS-7c9a4e6d-9e42-4d35-9169-deb62522e494,DISK], DatanodeInfoWithStorage[127.0.0.1:43411,DS-af47f905-2875-4a57-9f9e-9605a412ca64,DISK], DatanodeInfoWithStorage[127.0.0.1:44471,DS-602fd88d-52b3-414b-a1be-ee9adaa9a763,DISK], DatanodeInfoWithStorage[127.0.0.1:37618,DS-2f79e6e1-131b-4b38-a424-9c31e408ebfa,DISK], DatanodeInfoWithStorage[127.0.0.1:42628,DS-1646e710-b428-47ff-8da6-68f859b2d8a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41002,DS-98621a52-13a8-4975-a609-17c262b52f39,DISK], DatanodeInfoWithStorage[127.0.0.1:40595,DS-eb010df9-e182-43ae-894e-1b574969ee2e,DISK], DatanodeInfoWithStorage[127.0.0.1:40343,DS-be10e693-c3ed-410f-bfb6-9cc22ccf388c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1253243602-172.17.0.21-1596965096447:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42776,DS-7c9a4e6d-9e42-4d35-9169-deb62522e494,DISK], DatanodeInfoWithStorage[127.0.0.1:43411,DS-af47f905-2875-4a57-9f9e-9605a412ca64,DISK], DatanodeInfoWithStorage[127.0.0.1:44471,DS-602fd88d-52b3-414b-a1be-ee9adaa9a763,DISK], DatanodeInfoWithStorage[127.0.0.1:37618,DS-2f79e6e1-131b-4b38-a424-9c31e408ebfa,DISK], DatanodeInfoWithStorage[127.0.0.1:42628,DS-1646e710-b428-47ff-8da6-68f859b2d8a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41002,DS-98621a52-13a8-4975-a609-17c262b52f39,DISK], DatanodeInfoWithStorage[127.0.0.1:40595,DS-eb010df9-e182-43ae-894e-1b574969ee2e,DISK], DatanodeInfoWithStorage[127.0.0.1:40343,DS-be10e693-c3ed-410f-bfb6-9cc22ccf388c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.acls.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-489652131-172.17.0.21-1596965174498:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33240,DS-cd715dab-2fde-4cab-9ed1-53e8ebc6c77e,DISK], DatanodeInfoWithStorage[127.0.0.1:40918,DS-2937a996-e4e0-4c07-8daa-9521218030a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42795,DS-33939b2c-9f7a-4a34-bbb4-d6f61c7182ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33419,DS-2a5cea6f-72ca-4cf0-bf3d-62442c7be7b0,DISK], DatanodeInfoWithStorage[127.0.0.1:32930,DS-c1b9f576-3477-4753-865c-fa39cc18ed0b,DISK], DatanodeInfoWithStorage[127.0.0.1:36943,DS-d458817a-a5c9-4ef0-a73e-761fd2a81f57,DISK], DatanodeInfoWithStorage[127.0.0.1:38782,DS-467d08a6-74ac-4f99-9cad-6b16a2a4d42d,DISK], DatanodeInfoWithStorage[127.0.0.1:33903,DS-75eb975c-cc8e-4a22-8ddd-6fdfc61d00eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-489652131-172.17.0.21-1596965174498:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33240,DS-cd715dab-2fde-4cab-9ed1-53e8ebc6c77e,DISK], DatanodeInfoWithStorage[127.0.0.1:40918,DS-2937a996-e4e0-4c07-8daa-9521218030a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42795,DS-33939b2c-9f7a-4a34-bbb4-d6f61c7182ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33419,DS-2a5cea6f-72ca-4cf0-bf3d-62442c7be7b0,DISK], DatanodeInfoWithStorage[127.0.0.1:32930,DS-c1b9f576-3477-4753-865c-fa39cc18ed0b,DISK], DatanodeInfoWithStorage[127.0.0.1:36943,DS-d458817a-a5c9-4ef0-a73e-761fd2a81f57,DISK], DatanodeInfoWithStorage[127.0.0.1:38782,DS-467d08a6-74ac-4f99-9cad-6b16a2a4d42d,DISK], DatanodeInfoWithStorage[127.0.0.1:33903,DS-75eb975c-cc8e-4a22-8ddd-6fdfc61d00eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.acls.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-88986672-172.17.0.21-1596965620435:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36110,DS-3cd1d0f1-908e-47f4-b7c4-9fdb1c591ec4,DISK], DatanodeInfoWithStorage[127.0.0.1:36706,DS-68c5daad-e163-4590-9e22-234029413edd,DISK], DatanodeInfoWithStorage[127.0.0.1:43636,DS-3bb98b9f-fe18-4e83-b614-be3d866a560d,DISK], DatanodeInfoWithStorage[127.0.0.1:36918,DS-d5c3375e-134c-4026-9cf5-fdc062aa9f81,DISK], DatanodeInfoWithStorage[127.0.0.1:42163,DS-bf5084f6-0447-4c88-b7e3-0b35b0ecac63,DISK], DatanodeInfoWithStorage[127.0.0.1:35011,DS-f818dba0-eb7f-48b4-96e2-e86018056e7e,DISK], DatanodeInfoWithStorage[127.0.0.1:36352,DS-2e3807a9-7f72-4a8c-8c48-f720d85c181a,DISK], DatanodeInfoWithStorage[127.0.0.1:34851,DS-b3c398db-1851-49be-9a67-f44e7af8707a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-88986672-172.17.0.21-1596965620435:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36110,DS-3cd1d0f1-908e-47f4-b7c4-9fdb1c591ec4,DISK], DatanodeInfoWithStorage[127.0.0.1:36706,DS-68c5daad-e163-4590-9e22-234029413edd,DISK], DatanodeInfoWithStorage[127.0.0.1:43636,DS-3bb98b9f-fe18-4e83-b614-be3d866a560d,DISK], DatanodeInfoWithStorage[127.0.0.1:36918,DS-d5c3375e-134c-4026-9cf5-fdc062aa9f81,DISK], DatanodeInfoWithStorage[127.0.0.1:42163,DS-bf5084f6-0447-4c88-b7e3-0b35b0ecac63,DISK], DatanodeInfoWithStorage[127.0.0.1:35011,DS-f818dba0-eb7f-48b4-96e2-e86018056e7e,DISK], DatanodeInfoWithStorage[127.0.0.1:36352,DS-2e3807a9-7f72-4a8c-8c48-f720d85c181a,DISK], DatanodeInfoWithStorage[127.0.0.1:34851,DS-b3c398db-1851-49be-9a67-f44e7af8707a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.acls.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2145801531-172.17.0.21-1596965693876:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40892,DS-ea638b84-e1ca-46d8-b7cb-259e3b992136,DISK], DatanodeInfoWithStorage[127.0.0.1:34342,DS-ae6f1857-8008-4494-a3de-9035b7b90e61,DISK], DatanodeInfoWithStorage[127.0.0.1:43978,DS-37e49aa7-6668-41d7-b58f-fbb4c30b7894,DISK], DatanodeInfoWithStorage[127.0.0.1:46304,DS-7ee69e6b-3e15-4932-8a03-8d6fda0889d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36964,DS-6f92cd32-a450-41fa-8eb9-9b5d0317caf1,DISK], DatanodeInfoWithStorage[127.0.0.1:33125,DS-8947f74c-0e2e-46e9-9099-9f411b722f51,DISK], DatanodeInfoWithStorage[127.0.0.1:40133,DS-413d184a-ff37-4557-bc17-cde0fbb47a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:35719,DS-6bd85513-2aac-46e5-aad6-38bb9ecd74ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2145801531-172.17.0.21-1596965693876:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40892,DS-ea638b84-e1ca-46d8-b7cb-259e3b992136,DISK], DatanodeInfoWithStorage[127.0.0.1:34342,DS-ae6f1857-8008-4494-a3de-9035b7b90e61,DISK], DatanodeInfoWithStorage[127.0.0.1:43978,DS-37e49aa7-6668-41d7-b58f-fbb4c30b7894,DISK], DatanodeInfoWithStorage[127.0.0.1:46304,DS-7ee69e6b-3e15-4932-8a03-8d6fda0889d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36964,DS-6f92cd32-a450-41fa-8eb9-9b5d0317caf1,DISK], DatanodeInfoWithStorage[127.0.0.1:33125,DS-8947f74c-0e2e-46e9-9099-9f411b722f51,DISK], DatanodeInfoWithStorage[127.0.0.1:40133,DS-413d184a-ff37-4557-bc17-cde0fbb47a0d,DISK], DatanodeInfoWithStorage[127.0.0.1:35719,DS-6bd85513-2aac-46e5-aad6-38bb9ecd74ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.acls.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1846560199-172.17.0.21-1596965826886:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40205,DS-a54c8593-3135-4a0c-80bc-afa3037d09ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40877,DS-887a0914-f227-4375-b625-243b3c98b1d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35804,DS-1e607774-0daf-482a-b109-980a92ffef05,DISK], DatanodeInfoWithStorage[127.0.0.1:35337,DS-ca8fa559-ac0b-4828-ab4c-587aac37ba01,DISK], DatanodeInfoWithStorage[127.0.0.1:33418,DS-fac8b678-7e61-4aca-a45d-ad392d2f6a02,DISK], DatanodeInfoWithStorage[127.0.0.1:34809,DS-964ce74c-3a02-4ea1-a6e4-e935de8cb17f,DISK], DatanodeInfoWithStorage[127.0.0.1:44424,DS-7a076744-6825-44e3-b52d-bc9670eca3ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35655,DS-93c732ba-abb6-498d-8815-3d6cdaab4fc6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1846560199-172.17.0.21-1596965826886:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40205,DS-a54c8593-3135-4a0c-80bc-afa3037d09ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40877,DS-887a0914-f227-4375-b625-243b3c98b1d2,DISK], DatanodeInfoWithStorage[127.0.0.1:35804,DS-1e607774-0daf-482a-b109-980a92ffef05,DISK], DatanodeInfoWithStorage[127.0.0.1:35337,DS-ca8fa559-ac0b-4828-ab4c-587aac37ba01,DISK], DatanodeInfoWithStorage[127.0.0.1:33418,DS-fac8b678-7e61-4aca-a45d-ad392d2f6a02,DISK], DatanodeInfoWithStorage[127.0.0.1:34809,DS-964ce74c-3a02-4ea1-a6e4-e935de8cb17f,DISK], DatanodeInfoWithStorage[127.0.0.1:44424,DS-7a076744-6825-44e3-b52d-bc9670eca3ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35655,DS-93c732ba-abb6-498d-8815-3d6cdaab4fc6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.acls.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1621191199-172.17.0.21-1596965861020:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38360,DS-5d77d71e-4322-4bdf-b660-c9c38bf40014,DISK], DatanodeInfoWithStorage[127.0.0.1:34975,DS-752688ef-2008-4b8a-8f10-57a29b87e52c,DISK], DatanodeInfoWithStorage[127.0.0.1:40605,DS-c4b4226f-f243-4376-b191-eb7fefb7a51a,DISK], DatanodeInfoWithStorage[127.0.0.1:42064,DS-b8499bd0-9e28-4cc1-a0ff-fc89ccbee95c,DISK], DatanodeInfoWithStorage[127.0.0.1:44439,DS-5c60a353-1b26-4f10-a57b-8e54ae10e70e,DISK], DatanodeInfoWithStorage[127.0.0.1:40218,DS-75047527-3552-4141-8774-3732316dd4f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46234,DS-db120c95-b000-4de3-9ea0-e7b1fe38194a,DISK], DatanodeInfoWithStorage[127.0.0.1:45538,DS-074ccb80-9f74-4247-b05a-847323569606,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1621191199-172.17.0.21-1596965861020:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38360,DS-5d77d71e-4322-4bdf-b660-c9c38bf40014,DISK], DatanodeInfoWithStorage[127.0.0.1:34975,DS-752688ef-2008-4b8a-8f10-57a29b87e52c,DISK], DatanodeInfoWithStorage[127.0.0.1:40605,DS-c4b4226f-f243-4376-b191-eb7fefb7a51a,DISK], DatanodeInfoWithStorage[127.0.0.1:42064,DS-b8499bd0-9e28-4cc1-a0ff-fc89ccbee95c,DISK], DatanodeInfoWithStorage[127.0.0.1:44439,DS-5c60a353-1b26-4f10-a57b-8e54ae10e70e,DISK], DatanodeInfoWithStorage[127.0.0.1:40218,DS-75047527-3552-4141-8774-3732316dd4f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46234,DS-db120c95-b000-4de3-9ea0-e7b1fe38194a,DISK], DatanodeInfoWithStorage[127.0.0.1:45538,DS-074ccb80-9f74-4247-b05a-847323569606,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.acls.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-945098739-172.17.0.21-1596966216507:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33424,DS-6fc01881-8ec7-494b-a0b1-be3bfff4a156,DISK], DatanodeInfoWithStorage[127.0.0.1:46224,DS-eb03be48-2d50-49f4-b40a-82b8b96c6283,DISK], DatanodeInfoWithStorage[127.0.0.1:37213,DS-706bca72-c380-4fdf-8c47-3faf6713e90e,DISK], DatanodeInfoWithStorage[127.0.0.1:35314,DS-cc2a1e78-e853-46c0-b908-72eb8f333362,DISK], DatanodeInfoWithStorage[127.0.0.1:35906,DS-66283890-dd75-4ae2-9e92-aacca24251ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37068,DS-33adb7ba-69bd-43d3-b38d-f3e997faf77d,DISK], DatanodeInfoWithStorage[127.0.0.1:35917,DS-dc649801-4b46-4ea3-a791-c1a20f72b6d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38229,DS-35a79e86-2ebc-402d-80e3-b89cb8c65897,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-945098739-172.17.0.21-1596966216507:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33424,DS-6fc01881-8ec7-494b-a0b1-be3bfff4a156,DISK], DatanodeInfoWithStorage[127.0.0.1:46224,DS-eb03be48-2d50-49f4-b40a-82b8b96c6283,DISK], DatanodeInfoWithStorage[127.0.0.1:37213,DS-706bca72-c380-4fdf-8c47-3faf6713e90e,DISK], DatanodeInfoWithStorage[127.0.0.1:35314,DS-cc2a1e78-e853-46c0-b908-72eb8f333362,DISK], DatanodeInfoWithStorage[127.0.0.1:35906,DS-66283890-dd75-4ae2-9e92-aacca24251ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37068,DS-33adb7ba-69bd-43d3-b38d-f3e997faf77d,DISK], DatanodeInfoWithStorage[127.0.0.1:35917,DS-dc649801-4b46-4ea3-a791-c1a20f72b6d7,DISK], DatanodeInfoWithStorage[127.0.0.1:38229,DS-35a79e86-2ebc-402d-80e3-b89cb8c65897,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.acls.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1381859203-172.17.0.21-1596966284909:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36635,DS-45b76c9c-4c64-4a24-975f-68a77831e888,DISK], DatanodeInfoWithStorage[127.0.0.1:33991,DS-97709d8c-aa4b-413e-8e94-a3f5794b01bb,DISK], DatanodeInfoWithStorage[127.0.0.1:46078,DS-4e8f2fce-f45e-43c3-ad91-38ac779ed284,DISK], DatanodeInfoWithStorage[127.0.0.1:46150,DS-44546696-d9e6-42e0-b843-fd96e492ec61,DISK], DatanodeInfoWithStorage[127.0.0.1:37240,DS-781622b3-825f-4b68-ade7-c1e0bce45941,DISK], DatanodeInfoWithStorage[127.0.0.1:45872,DS-a907f46e-54e4-4360-aae8-736df116c371,DISK], DatanodeInfoWithStorage[127.0.0.1:35413,DS-fcaf253a-642c-4a94-99ba-707709f27ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:46559,DS-6647972c-758e-427b-94f9-616f284210d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1381859203-172.17.0.21-1596966284909:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36635,DS-45b76c9c-4c64-4a24-975f-68a77831e888,DISK], DatanodeInfoWithStorage[127.0.0.1:33991,DS-97709d8c-aa4b-413e-8e94-a3f5794b01bb,DISK], DatanodeInfoWithStorage[127.0.0.1:46078,DS-4e8f2fce-f45e-43c3-ad91-38ac779ed284,DISK], DatanodeInfoWithStorage[127.0.0.1:46150,DS-44546696-d9e6-42e0-b843-fd96e492ec61,DISK], DatanodeInfoWithStorage[127.0.0.1:37240,DS-781622b3-825f-4b68-ade7-c1e0bce45941,DISK], DatanodeInfoWithStorage[127.0.0.1:45872,DS-a907f46e-54e4-4360-aae8-736df116c371,DISK], DatanodeInfoWithStorage[127.0.0.1:35413,DS-fcaf253a-642c-4a94-99ba-707709f27ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:46559,DS-6647972c-758e-427b-94f9-616f284210d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.acls.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-393536351-172.17.0.21-1596966437402:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44613,DS-50275cf7-a7fb-45e8-a75e-15f1f1122a61,DISK], DatanodeInfoWithStorage[127.0.0.1:39968,DS-a44726d5-57c7-4266-bedd-e8e62199c465,DISK], DatanodeInfoWithStorage[127.0.0.1:39061,DS-dbb9c9e0-ebd8-408d-80a9-d643ea81c8e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45942,DS-fd62bbce-be7e-4d01-9823-5c13c677f63a,DISK], DatanodeInfoWithStorage[127.0.0.1:42156,DS-1339ffd7-2b56-4239-9b53-42feaaba060c,DISK], DatanodeInfoWithStorage[127.0.0.1:33914,DS-15df955f-5a05-4474-97b1-f3730489ba63,DISK], DatanodeInfoWithStorage[127.0.0.1:35359,DS-6274e9b6-55b1-4811-ad42-7936e220bcc5,DISK], DatanodeInfoWithStorage[127.0.0.1:44154,DS-63eeb619-b892-4ef4-b3bf-58219d492f79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-393536351-172.17.0.21-1596966437402:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44613,DS-50275cf7-a7fb-45e8-a75e-15f1f1122a61,DISK], DatanodeInfoWithStorage[127.0.0.1:39968,DS-a44726d5-57c7-4266-bedd-e8e62199c465,DISK], DatanodeInfoWithStorage[127.0.0.1:39061,DS-dbb9c9e0-ebd8-408d-80a9-d643ea81c8e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45942,DS-fd62bbce-be7e-4d01-9823-5c13c677f63a,DISK], DatanodeInfoWithStorage[127.0.0.1:42156,DS-1339ffd7-2b56-4239-9b53-42feaaba060c,DISK], DatanodeInfoWithStorage[127.0.0.1:33914,DS-15df955f-5a05-4474-97b1-f3730489ba63,DISK], DatanodeInfoWithStorage[127.0.0.1:35359,DS-6274e9b6-55b1-4811-ad42-7936e220bcc5,DISK], DatanodeInfoWithStorage[127.0.0.1:44154,DS-63eeb619-b892-4ef4-b3bf-58219d492f79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.acls.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2109639911-172.17.0.21-1596966889522:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45624,DS-0ce3d9b3-f8b7-4a01-948b-2e28c515dc9b,DISK], DatanodeInfoWithStorage[127.0.0.1:46630,DS-04acb6ce-2a0f-4c07-8063-4170b2de9b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:43082,DS-2f68fdb5-6ebd-4a84-8d01-a944d72b64fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42765,DS-d726299f-34bc-42ff-87da-20a612c5a777,DISK], DatanodeInfoWithStorage[127.0.0.1:34881,DS-334bc25d-7e99-4d09-a63e-6c70da0cf0cf,DISK], DatanodeInfoWithStorage[127.0.0.1:44130,DS-1193232a-e4de-4b14-a00b-3ce2e4f8b321,DISK], DatanodeInfoWithStorage[127.0.0.1:34541,DS-564e0b4d-cb38-44c2-80e3-64a0ace18d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:43646,DS-51f9bb9c-cd3d-4c20-a21e-f74ec2f739a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2109639911-172.17.0.21-1596966889522:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45624,DS-0ce3d9b3-f8b7-4a01-948b-2e28c515dc9b,DISK], DatanodeInfoWithStorage[127.0.0.1:46630,DS-04acb6ce-2a0f-4c07-8063-4170b2de9b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:43082,DS-2f68fdb5-6ebd-4a84-8d01-a944d72b64fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42765,DS-d726299f-34bc-42ff-87da-20a612c5a777,DISK], DatanodeInfoWithStorage[127.0.0.1:34881,DS-334bc25d-7e99-4d09-a63e-6c70da0cf0cf,DISK], DatanodeInfoWithStorage[127.0.0.1:44130,DS-1193232a-e4de-4b14-a00b-3ce2e4f8b321,DISK], DatanodeInfoWithStorage[127.0.0.1:34541,DS-564e0b4d-cb38-44c2-80e3-64a0ace18d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:43646,DS-51f9bb9c-cd3d-4c20-a21e-f74ec2f739a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.acls.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-201169512-172.17.0.21-1596967198758:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34872,DS-12c9b18b-5a50-48de-b78c-1283e1d038e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36086,DS-c3010937-46ac-43fc-8ee3-5d70c1e7e28e,DISK], DatanodeInfoWithStorage[127.0.0.1:41548,DS-f6c01b65-0028-4472-8754-1c5a1b84f9f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46276,DS-38e2c594-e94d-4689-92b2-b74a0ad1f52b,DISK], DatanodeInfoWithStorage[127.0.0.1:34831,DS-6d5986cf-9128-44c4-b75d-b9d4cb9ffd7f,DISK], DatanodeInfoWithStorage[127.0.0.1:46718,DS-b650f82e-1927-4ee2-9e49-15cf1dbabfa6,DISK], DatanodeInfoWithStorage[127.0.0.1:38335,DS-ec5eb2a3-7af2-4896-9848-383137ad4cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:35214,DS-0ff745cc-6bf0-4ec4-a552-2a249382ca27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-201169512-172.17.0.21-1596967198758:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34872,DS-12c9b18b-5a50-48de-b78c-1283e1d038e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36086,DS-c3010937-46ac-43fc-8ee3-5d70c1e7e28e,DISK], DatanodeInfoWithStorage[127.0.0.1:41548,DS-f6c01b65-0028-4472-8754-1c5a1b84f9f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46276,DS-38e2c594-e94d-4689-92b2-b74a0ad1f52b,DISK], DatanodeInfoWithStorage[127.0.0.1:34831,DS-6d5986cf-9128-44c4-b75d-b9d4cb9ffd7f,DISK], DatanodeInfoWithStorage[127.0.0.1:46718,DS-b650f82e-1927-4ee2-9e49-15cf1dbabfa6,DISK], DatanodeInfoWithStorage[127.0.0.1:38335,DS-ec5eb2a3-7af2-4896-9848-383137ad4cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:35214,DS-0ff745cc-6bf0-4ec4-a552-2a249382ca27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.acls.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1301445852-172.17.0.21-1596967235213:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38812,DS-5b07b0ba-464e-477a-97e5-1787956993af,DISK], DatanodeInfoWithStorage[127.0.0.1:36089,DS-99613f41-cb43-4026-affc-799510566334,DISK], DatanodeInfoWithStorage[127.0.0.1:37553,DS-490ca715-dbc9-40ed-960c-61d0cfa02fc2,DISK], DatanodeInfoWithStorage[127.0.0.1:41714,DS-4a7709b2-5023-433b-aabd-424682dd4bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:33511,DS-1d381d59-3503-4d4c-b406-99de487ee203,DISK], DatanodeInfoWithStorage[127.0.0.1:46027,DS-168e0124-dd4a-41b3-860a-754fbc80023b,DISK], DatanodeInfoWithStorage[127.0.0.1:39522,DS-4b3b0c57-aede-4a71-93aa-92f66633e9d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35150,DS-871b8ef7-fab6-4818-80da-731b683be975,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1301445852-172.17.0.21-1596967235213:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38812,DS-5b07b0ba-464e-477a-97e5-1787956993af,DISK], DatanodeInfoWithStorage[127.0.0.1:36089,DS-99613f41-cb43-4026-affc-799510566334,DISK], DatanodeInfoWithStorage[127.0.0.1:37553,DS-490ca715-dbc9-40ed-960c-61d0cfa02fc2,DISK], DatanodeInfoWithStorage[127.0.0.1:41714,DS-4a7709b2-5023-433b-aabd-424682dd4bdd,DISK], DatanodeInfoWithStorage[127.0.0.1:33511,DS-1d381d59-3503-4d4c-b406-99de487ee203,DISK], DatanodeInfoWithStorage[127.0.0.1:46027,DS-168e0124-dd4a-41b3-860a-754fbc80023b,DISK], DatanodeInfoWithStorage[127.0.0.1:39522,DS-4b3b0c57-aede-4a71-93aa-92f66633e9d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35150,DS-871b8ef7-fab6-4818-80da-731b683be975,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.acls.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-686912348-172.17.0.21-1596967301943:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43302,DS-7c2d661d-434c-404d-b630-3d1c91187c7a,DISK], DatanodeInfoWithStorage[127.0.0.1:42471,DS-6fdb63ad-b9c7-4417-a9af-05f7edf71390,DISK], DatanodeInfoWithStorage[127.0.0.1:39091,DS-b798c76a-ba40-4ce3-b2ab-44a8641b7260,DISK], DatanodeInfoWithStorage[127.0.0.1:46139,DS-e2cc3743-9bae-43fa-afbe-59347d41804e,DISK], DatanodeInfoWithStorage[127.0.0.1:46487,DS-1ecdd4b2-a559-4506-8ea2-1b20159fa42c,DISK], DatanodeInfoWithStorage[127.0.0.1:40438,DS-a1ec0c4b-9143-46c2-83ad-8e61fea43de8,DISK], DatanodeInfoWithStorage[127.0.0.1:39786,DS-6681e381-f8b0-4caa-903c-ac17d519dfc1,DISK], DatanodeInfoWithStorage[127.0.0.1:42144,DS-c08afc54-7771-4050-9375-3e606b4f16e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-686912348-172.17.0.21-1596967301943:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43302,DS-7c2d661d-434c-404d-b630-3d1c91187c7a,DISK], DatanodeInfoWithStorage[127.0.0.1:42471,DS-6fdb63ad-b9c7-4417-a9af-05f7edf71390,DISK], DatanodeInfoWithStorage[127.0.0.1:39091,DS-b798c76a-ba40-4ce3-b2ab-44a8641b7260,DISK], DatanodeInfoWithStorage[127.0.0.1:46139,DS-e2cc3743-9bae-43fa-afbe-59347d41804e,DISK], DatanodeInfoWithStorage[127.0.0.1:46487,DS-1ecdd4b2-a559-4506-8ea2-1b20159fa42c,DISK], DatanodeInfoWithStorage[127.0.0.1:40438,DS-a1ec0c4b-9143-46c2-83ad-8e61fea43de8,DISK], DatanodeInfoWithStorage[127.0.0.1:39786,DS-6681e381-f8b0-4caa-903c-ac17d519dfc1,DISK], DatanodeInfoWithStorage[127.0.0.1:42144,DS-c08afc54-7771-4050-9375-3e606b4f16e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.acls.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1532861956-172.17.0.21-1596967410856:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44757,DS-5b0d23d8-59ec-46b4-b3c5-cfcc9e6efd84,DISK], DatanodeInfoWithStorage[127.0.0.1:42798,DS-1bb53060-f6d6-49df-8400-30b85141cdf1,DISK], DatanodeInfoWithStorage[127.0.0.1:46366,DS-aad46b30-4e9f-461f-8852-c083dbef1a42,DISK], DatanodeInfoWithStorage[127.0.0.1:42716,DS-d32014e0-08e6-4042-b447-e709104d6b71,DISK], DatanodeInfoWithStorage[127.0.0.1:36308,DS-12935f77-a5c0-4fbe-8ffb-959a8a4bd4a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43962,DS-9fe5f14a-edac-4d17-b515-e449a06ffc83,DISK], DatanodeInfoWithStorage[127.0.0.1:33158,DS-91cab4df-d6c9-4b9d-93b0-20a464004b61,DISK], DatanodeInfoWithStorage[127.0.0.1:46810,DS-70fe9141-0d80-4c36-bf3e-9784a30a2eba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1532861956-172.17.0.21-1596967410856:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44757,DS-5b0d23d8-59ec-46b4-b3c5-cfcc9e6efd84,DISK], DatanodeInfoWithStorage[127.0.0.1:42798,DS-1bb53060-f6d6-49df-8400-30b85141cdf1,DISK], DatanodeInfoWithStorage[127.0.0.1:46366,DS-aad46b30-4e9f-461f-8852-c083dbef1a42,DISK], DatanodeInfoWithStorage[127.0.0.1:42716,DS-d32014e0-08e6-4042-b447-e709104d6b71,DISK], DatanodeInfoWithStorage[127.0.0.1:36308,DS-12935f77-a5c0-4fbe-8ffb-959a8a4bd4a4,DISK], DatanodeInfoWithStorage[127.0.0.1:43962,DS-9fe5f14a-edac-4d17-b515-e449a06ffc83,DISK], DatanodeInfoWithStorage[127.0.0.1:33158,DS-91cab4df-d6c9-4b9d-93b0-20a464004b61,DISK], DatanodeInfoWithStorage[127.0.0.1:46810,DS-70fe9141-0d80-4c36-bf3e-9784a30a2eba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.acls.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-757522790-172.17.0.21-1596967545757:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46863,DS-7a0e379f-14d6-4afa-9fa9-18203eabfe0b,DISK], DatanodeInfoWithStorage[127.0.0.1:40829,DS-2000714a-0ab2-47b7-80f0-75e36ec99a50,DISK], DatanodeInfoWithStorage[127.0.0.1:37031,DS-d7c3041b-98c8-4361-af60-3fd65cdc8d28,DISK], DatanodeInfoWithStorage[127.0.0.1:42279,DS-33a06762-d7c9-4251-9381-951f92758b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:33609,DS-dbc01d17-3f30-4672-bbe5-df537bb84c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:44269,DS-2fbb9772-1b11-4529-8134-733fcbdffefa,DISK], DatanodeInfoWithStorage[127.0.0.1:44257,DS-161c5af9-bf00-4ee8-a5ff-5f80bc37db6e,DISK], DatanodeInfoWithStorage[127.0.0.1:41389,DS-43c38667-8d14-41bd-a931-5c76ace4ae75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-757522790-172.17.0.21-1596967545757:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46863,DS-7a0e379f-14d6-4afa-9fa9-18203eabfe0b,DISK], DatanodeInfoWithStorage[127.0.0.1:40829,DS-2000714a-0ab2-47b7-80f0-75e36ec99a50,DISK], DatanodeInfoWithStorage[127.0.0.1:37031,DS-d7c3041b-98c8-4361-af60-3fd65cdc8d28,DISK], DatanodeInfoWithStorage[127.0.0.1:42279,DS-33a06762-d7c9-4251-9381-951f92758b6a,DISK], DatanodeInfoWithStorage[127.0.0.1:33609,DS-dbc01d17-3f30-4672-bbe5-df537bb84c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:44269,DS-2fbb9772-1b11-4529-8134-733fcbdffefa,DISK], DatanodeInfoWithStorage[127.0.0.1:44257,DS-161c5af9-bf00-4ee8-a5ff-5f80bc37db6e,DISK], DatanodeInfoWithStorage[127.0.0.1:41389,DS-43c38667-8d14-41bd-a931-5c76ace4ae75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.acls.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1285695779-172.17.0.21-1596967791709:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44333,DS-6ec00422-ef6f-483f-9a2a-9df30e9efcfb,DISK], DatanodeInfoWithStorage[127.0.0.1:41331,DS-01623d1a-1939-422c-8b14-b6f166c0b318,DISK], DatanodeInfoWithStorage[127.0.0.1:43584,DS-ee3f3286-d266-42b0-8038-5e29315526f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39742,DS-c956d8a9-946f-47f9-8b4f-c9ec27fcd4cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33531,DS-77e258ab-b1e2-4e24-874f-c6b465fcd815,DISK], DatanodeInfoWithStorage[127.0.0.1:35458,DS-53c6e391-a179-4499-aeae-46f5c4e0c1a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44544,DS-648aae0a-78c3-4eec-a31d-c4f971595bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:44940,DS-1a665b8c-8bc9-4b20-92af-c25dd1df283c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1285695779-172.17.0.21-1596967791709:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44333,DS-6ec00422-ef6f-483f-9a2a-9df30e9efcfb,DISK], DatanodeInfoWithStorage[127.0.0.1:41331,DS-01623d1a-1939-422c-8b14-b6f166c0b318,DISK], DatanodeInfoWithStorage[127.0.0.1:43584,DS-ee3f3286-d266-42b0-8038-5e29315526f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39742,DS-c956d8a9-946f-47f9-8b4f-c9ec27fcd4cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33531,DS-77e258ab-b1e2-4e24-874f-c6b465fcd815,DISK], DatanodeInfoWithStorage[127.0.0.1:35458,DS-53c6e391-a179-4499-aeae-46f5c4e0c1a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44544,DS-648aae0a-78c3-4eec-a31d-c4f971595bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:44940,DS-1a665b8c-8bc9-4b20-92af-c25dd1df283c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.acls.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-313795788-172.17.0.21-1596968092227:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33045,DS-443f9362-adbb-47c5-b833-fdfba7b3cebf,DISK], DatanodeInfoWithStorage[127.0.0.1:33015,DS-8e29e48c-a2d6-40ad-8c0d-decc56f3b5fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42228,DS-8b1b68e3-4fa1-4eea-b615-62f46521edae,DISK], DatanodeInfoWithStorage[127.0.0.1:46352,DS-5f95a14e-6b88-422e-8ec0-9aaecdd1e938,DISK], DatanodeInfoWithStorage[127.0.0.1:34735,DS-6b8f7639-66fc-4a3c-9388-768cdfd5a631,DISK], DatanodeInfoWithStorage[127.0.0.1:34968,DS-c99ad62d-5607-4fb7-9582-acf56559dc41,DISK], DatanodeInfoWithStorage[127.0.0.1:37836,DS-c30f870b-c328-41cb-b422-fc5979a6f51d,DISK], DatanodeInfoWithStorage[127.0.0.1:34877,DS-36856d43-4007-4eeb-9427-816042624d4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-313795788-172.17.0.21-1596968092227:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33045,DS-443f9362-adbb-47c5-b833-fdfba7b3cebf,DISK], DatanodeInfoWithStorage[127.0.0.1:33015,DS-8e29e48c-a2d6-40ad-8c0d-decc56f3b5fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42228,DS-8b1b68e3-4fa1-4eea-b615-62f46521edae,DISK], DatanodeInfoWithStorage[127.0.0.1:46352,DS-5f95a14e-6b88-422e-8ec0-9aaecdd1e938,DISK], DatanodeInfoWithStorage[127.0.0.1:34735,DS-6b8f7639-66fc-4a3c-9388-768cdfd5a631,DISK], DatanodeInfoWithStorage[127.0.0.1:34968,DS-c99ad62d-5607-4fb7-9582-acf56559dc41,DISK], DatanodeInfoWithStorage[127.0.0.1:37836,DS-c30f870b-c328-41cb-b422-fc5979a6f51d,DISK], DatanodeInfoWithStorage[127.0.0.1:34877,DS-36856d43-4007-4eeb-9427-816042624d4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.acls.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-784308809-172.17.0.21-1596968277588:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43584,DS-7079228a-3bb3-45c0-a3ef-cc122bd8a44d,DISK], DatanodeInfoWithStorage[127.0.0.1:41498,DS-6d4f06a8-c789-4aca-96c1-691be0d86ab0,DISK], DatanodeInfoWithStorage[127.0.0.1:45817,DS-5f69f845-6d8e-4bba-b110-313526606970,DISK], DatanodeInfoWithStorage[127.0.0.1:36688,DS-97841e3f-c268-45f6-9874-8f5800c70b1a,DISK], DatanodeInfoWithStorage[127.0.0.1:36039,DS-dcea1e96-49bb-4611-bf6a-db924cc247d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41313,DS-451e5109-4ac5-420e-9da1-28700a778ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:45078,DS-cc7d7bf8-a3fd-4e0b-aabd-a1efccb8606c,DISK], DatanodeInfoWithStorage[127.0.0.1:43529,DS-83ef4206-8223-490c-a87f-be917a47a3a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-784308809-172.17.0.21-1596968277588:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43584,DS-7079228a-3bb3-45c0-a3ef-cc122bd8a44d,DISK], DatanodeInfoWithStorage[127.0.0.1:41498,DS-6d4f06a8-c789-4aca-96c1-691be0d86ab0,DISK], DatanodeInfoWithStorage[127.0.0.1:45817,DS-5f69f845-6d8e-4bba-b110-313526606970,DISK], DatanodeInfoWithStorage[127.0.0.1:36688,DS-97841e3f-c268-45f6-9874-8f5800c70b1a,DISK], DatanodeInfoWithStorage[127.0.0.1:36039,DS-dcea1e96-49bb-4611-bf6a-db924cc247d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41313,DS-451e5109-4ac5-420e-9da1-28700a778ca1,DISK], DatanodeInfoWithStorage[127.0.0.1:45078,DS-cc7d7bf8-a3fd-4e0b-aabd-a1efccb8606c,DISK], DatanodeInfoWithStorage[127.0.0.1:43529,DS-83ef4206-8223-490c-a87f-be917a47a3a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.acls.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1273854954-172.17.0.21-1596969266261:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36801,DS-58ff60f5-3804-41b2-9568-6608fa97d25d,DISK], DatanodeInfoWithStorage[127.0.0.1:46688,DS-c304417c-7295-448f-8b95-a257ac015c0f,DISK], DatanodeInfoWithStorage[127.0.0.1:43921,DS-c068a871-eaf7-4016-8d05-ce12049d1272,DISK], DatanodeInfoWithStorage[127.0.0.1:38562,DS-2ff64354-90e6-4476-92b4-f4a0942441d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34456,DS-872194dc-c3cf-4be8-b889-97c9a0d47944,DISK], DatanodeInfoWithStorage[127.0.0.1:46493,DS-692d3e01-5e15-4439-abb0-d67f3ec2c048,DISK], DatanodeInfoWithStorage[127.0.0.1:36592,DS-47353dc6-048c-47bf-a06a-b93e06bcefb7,DISK], DatanodeInfoWithStorage[127.0.0.1:39425,DS-a23c5c99-1618-45ba-8a2e-680f416de632,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1273854954-172.17.0.21-1596969266261:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36801,DS-58ff60f5-3804-41b2-9568-6608fa97d25d,DISK], DatanodeInfoWithStorage[127.0.0.1:46688,DS-c304417c-7295-448f-8b95-a257ac015c0f,DISK], DatanodeInfoWithStorage[127.0.0.1:43921,DS-c068a871-eaf7-4016-8d05-ce12049d1272,DISK], DatanodeInfoWithStorage[127.0.0.1:38562,DS-2ff64354-90e6-4476-92b4-f4a0942441d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34456,DS-872194dc-c3cf-4be8-b889-97c9a0d47944,DISK], DatanodeInfoWithStorage[127.0.0.1:46493,DS-692d3e01-5e15-4439-abb0-d67f3ec2c048,DISK], DatanodeInfoWithStorage[127.0.0.1:36592,DS-47353dc6-048c-47bf-a06a-b93e06bcefb7,DISK], DatanodeInfoWithStorage[127.0.0.1:39425,DS-a23c5c99-1618-45ba-8a2e-680f416de632,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.acls.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-213484137-172.17.0.21-1596969413946:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46755,DS-f81a80b0-6321-4932-8369-69703947222a,DISK], DatanodeInfoWithStorage[127.0.0.1:39265,DS-f467178c-261a-4517-85ee-8b469b246a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:33302,DS-227a27b9-2bb2-4a90-8656-42cb790bdcb0,DISK], DatanodeInfoWithStorage[127.0.0.1:43896,DS-d8cdd765-1cbb-40f6-a7ce-0e8febe51d24,DISK], DatanodeInfoWithStorage[127.0.0.1:33308,DS-f83b4879-7126-44d6-b023-1a90e75c7dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:36154,DS-d6bea735-0b9a-4551-ae1d-8a6dacd99e7b,DISK], DatanodeInfoWithStorage[127.0.0.1:37341,DS-f1b9f397-defd-4dbb-8a31-ce8e8af61392,DISK], DatanodeInfoWithStorage[127.0.0.1:35027,DS-67ebcdb9-f570-444e-9af1-a0f6148d629e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-213484137-172.17.0.21-1596969413946:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46755,DS-f81a80b0-6321-4932-8369-69703947222a,DISK], DatanodeInfoWithStorage[127.0.0.1:39265,DS-f467178c-261a-4517-85ee-8b469b246a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:33302,DS-227a27b9-2bb2-4a90-8656-42cb790bdcb0,DISK], DatanodeInfoWithStorage[127.0.0.1:43896,DS-d8cdd765-1cbb-40f6-a7ce-0e8febe51d24,DISK], DatanodeInfoWithStorage[127.0.0.1:33308,DS-f83b4879-7126-44d6-b023-1a90e75c7dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:36154,DS-d6bea735-0b9a-4551-ae1d-8a6dacd99e7b,DISK], DatanodeInfoWithStorage[127.0.0.1:37341,DS-f1b9f397-defd-4dbb-8a31-ce8e8af61392,DISK], DatanodeInfoWithStorage[127.0.0.1:35027,DS-67ebcdb9-f570-444e-9af1-a0f6148d629e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.acls.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-331233580-172.17.0.21-1596970026217:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41599,DS-d4bee2c6-d9f7-4785-ad60-3afcef72f910,DISK], DatanodeInfoWithStorage[127.0.0.1:36434,DS-a5a75ce0-7763-463b-b87b-60a25616cbc7,DISK], DatanodeInfoWithStorage[127.0.0.1:45550,DS-cea29a39-20b8-474c-9352-ad0a5e7cc4d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40301,DS-542f79cd-3143-495c-8db6-ef2ab36eef8f,DISK], DatanodeInfoWithStorage[127.0.0.1:44233,DS-97bad5f4-e790-4a52-a0a8-326d354509dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36473,DS-6f0bb99d-154b-4446-a0c0-40bdd8a04826,DISK], DatanodeInfoWithStorage[127.0.0.1:35164,DS-2f11cae4-3094-44a4-a63a-6bd4826c5c62,DISK], DatanodeInfoWithStorage[127.0.0.1:41257,DS-348315b9-d46e-4c06-82a5-a0f22fdf263a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-331233580-172.17.0.21-1596970026217:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41599,DS-d4bee2c6-d9f7-4785-ad60-3afcef72f910,DISK], DatanodeInfoWithStorage[127.0.0.1:36434,DS-a5a75ce0-7763-463b-b87b-60a25616cbc7,DISK], DatanodeInfoWithStorage[127.0.0.1:45550,DS-cea29a39-20b8-474c-9352-ad0a5e7cc4d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40301,DS-542f79cd-3143-495c-8db6-ef2ab36eef8f,DISK], DatanodeInfoWithStorage[127.0.0.1:44233,DS-97bad5f4-e790-4a52-a0a8-326d354509dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36473,DS-6f0bb99d-154b-4446-a0c0-40bdd8a04826,DISK], DatanodeInfoWithStorage[127.0.0.1:35164,DS-2f11cae4-3094-44a4-a63a-6bd4826c5c62,DISK], DatanodeInfoWithStorage[127.0.0.1:41257,DS-348315b9-d46e-4c06-82a5-a0f22fdf263a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.acls.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1261699825-172.17.0.21-1596970328412:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43124,DS-1c3863e4-47db-4824-979a-f462e10d3e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:46855,DS-10460927-dbfa-41f6-bec7-80e0152de31b,DISK], DatanodeInfoWithStorage[127.0.0.1:43667,DS-53a4166e-25c3-49ad-8e43-a6cd1ba6a09d,DISK], DatanodeInfoWithStorage[127.0.0.1:40758,DS-f75de83e-e824-4cd4-9c34-76f0afea386e,DISK], DatanodeInfoWithStorage[127.0.0.1:42098,DS-d9b12f98-c34f-4312-bcff-df553c65926e,DISK], DatanodeInfoWithStorage[127.0.0.1:37188,DS-3bbb21a8-45a4-4118-977b-949444cfe7e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37447,DS-946805de-f890-4171-b807-3403c2a3d376,DISK], DatanodeInfoWithStorage[127.0.0.1:39526,DS-b54c792b-e29d-4655-8d23-67523c212e53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1261699825-172.17.0.21-1596970328412:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43124,DS-1c3863e4-47db-4824-979a-f462e10d3e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:46855,DS-10460927-dbfa-41f6-bec7-80e0152de31b,DISK], DatanodeInfoWithStorage[127.0.0.1:43667,DS-53a4166e-25c3-49ad-8e43-a6cd1ba6a09d,DISK], DatanodeInfoWithStorage[127.0.0.1:40758,DS-f75de83e-e824-4cd4-9c34-76f0afea386e,DISK], DatanodeInfoWithStorage[127.0.0.1:42098,DS-d9b12f98-c34f-4312-bcff-df553c65926e,DISK], DatanodeInfoWithStorage[127.0.0.1:37188,DS-3bbb21a8-45a4-4118-977b-949444cfe7e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37447,DS-946805de-f890-4171-b807-3403c2a3d376,DISK], DatanodeInfoWithStorage[127.0.0.1:39526,DS-b54c792b-e29d-4655-8d23-67523c212e53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 5399
