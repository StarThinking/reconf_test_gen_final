reconf_parameter: dfs.client.use.legacy.blockreader.local
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.legacy.blockreader.local
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1876875440-172.17.0.16-1596962248985:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33690,DS-f3bd252d-f275-4106-ba4f-ee6f1921aea5,DISK], DatanodeInfoWithStorage[127.0.0.1:44248,DS-b99d1c54-362a-4a2e-a9e6-d1de74ea80f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38717,DS-608028cf-6843-4555-aa5b-01b74f04322a,DISK], DatanodeInfoWithStorage[127.0.0.1:33748,DS-31ad07bd-0047-4ac2-8ec8-16540edd3190,DISK], DatanodeInfoWithStorage[127.0.0.1:35444,DS-36157fa0-b0ec-48cd-8049-bd807e5e3535,DISK], DatanodeInfoWithStorage[127.0.0.1:42694,DS-1290dd01-4048-4ebb-b8b2-e3dca4880cff,DISK], DatanodeInfoWithStorage[127.0.0.1:40665,DS-1584ec5d-992f-4431-ad75-c4c3ac34a511,DISK], DatanodeInfoWithStorage[127.0.0.1:46395,DS-ab902826-16f8-4b42-9815-a10c8ac18a75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1876875440-172.17.0.16-1596962248985:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33690,DS-f3bd252d-f275-4106-ba4f-ee6f1921aea5,DISK], DatanodeInfoWithStorage[127.0.0.1:44248,DS-b99d1c54-362a-4a2e-a9e6-d1de74ea80f4,DISK], DatanodeInfoWithStorage[127.0.0.1:38717,DS-608028cf-6843-4555-aa5b-01b74f04322a,DISK], DatanodeInfoWithStorage[127.0.0.1:33748,DS-31ad07bd-0047-4ac2-8ec8-16540edd3190,DISK], DatanodeInfoWithStorage[127.0.0.1:35444,DS-36157fa0-b0ec-48cd-8049-bd807e5e3535,DISK], DatanodeInfoWithStorage[127.0.0.1:42694,DS-1290dd01-4048-4ebb-b8b2-e3dca4880cff,DISK], DatanodeInfoWithStorage[127.0.0.1:40665,DS-1584ec5d-992f-4431-ad75-c4c3ac34a511,DISK], DatanodeInfoWithStorage[127.0.0.1:46395,DS-ab902826-16f8-4b42-9815-a10c8ac18a75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.legacy.blockreader.local
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-726898614-172.17.0.16-1596962454931:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33339,DS-ec7b28e9-eb9a-4345-a9a8-4cdc49ffece7,DISK], DatanodeInfoWithStorage[127.0.0.1:46278,DS-c4df6a6c-dc2b-425f-9309-9e0d34a4bcbc,DISK], DatanodeInfoWithStorage[127.0.0.1:38023,DS-797cebae-72c4-448a-9f44-d2b4170d7c8b,DISK], DatanodeInfoWithStorage[127.0.0.1:33204,DS-90e531e3-bd84-4d8e-be09-d87867f16649,DISK], DatanodeInfoWithStorage[127.0.0.1:38188,DS-d880a34b-9b95-4c89-951a-76eb2d209921,DISK], DatanodeInfoWithStorage[127.0.0.1:43083,DS-dadc52ca-a11a-49e5-bd88-5b7772ba4c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:36328,DS-1b27a369-7c1b-40e2-b00f-21fb75209dfb,DISK], DatanodeInfoWithStorage[127.0.0.1:34274,DS-7aece22e-ad38-4b8e-a88a-a2c8ddddc9f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-726898614-172.17.0.16-1596962454931:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33339,DS-ec7b28e9-eb9a-4345-a9a8-4cdc49ffece7,DISK], DatanodeInfoWithStorage[127.0.0.1:46278,DS-c4df6a6c-dc2b-425f-9309-9e0d34a4bcbc,DISK], DatanodeInfoWithStorage[127.0.0.1:38023,DS-797cebae-72c4-448a-9f44-d2b4170d7c8b,DISK], DatanodeInfoWithStorage[127.0.0.1:33204,DS-90e531e3-bd84-4d8e-be09-d87867f16649,DISK], DatanodeInfoWithStorage[127.0.0.1:38188,DS-d880a34b-9b95-4c89-951a-76eb2d209921,DISK], DatanodeInfoWithStorage[127.0.0.1:43083,DS-dadc52ca-a11a-49e5-bd88-5b7772ba4c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:36328,DS-1b27a369-7c1b-40e2-b00f-21fb75209dfb,DISK], DatanodeInfoWithStorage[127.0.0.1:34274,DS-7aece22e-ad38-4b8e-a88a-a2c8ddddc9f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.legacy.blockreader.local
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-839854300-172.17.0.16-1596962678716:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36393,DS-4b37ed31-dd69-412a-ac6a-1db91a5a7ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:38262,DS-bb80b900-eddd-4767-8c42-478f8804db38,DISK], DatanodeInfoWithStorage[127.0.0.1:39145,DS-a5f859a5-0627-41dd-bc63-8b02a48c63f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33287,DS-281e9df8-3df2-4217-9b54-9ff400fdd23f,DISK], DatanodeInfoWithStorage[127.0.0.1:46789,DS-14432c3d-2870-49a5-9acd-3d41e947a630,DISK], DatanodeInfoWithStorage[127.0.0.1:37024,DS-1ce2c964-3486-4c69-bc8c-5eadee4e9ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:46385,DS-e3cc63f7-cb93-4494-bf28-27b46f890d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:41718,DS-86fe2959-fcd2-4ea5-a236-a57a3a8c0489,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-839854300-172.17.0.16-1596962678716:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36393,DS-4b37ed31-dd69-412a-ac6a-1db91a5a7ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:38262,DS-bb80b900-eddd-4767-8c42-478f8804db38,DISK], DatanodeInfoWithStorage[127.0.0.1:39145,DS-a5f859a5-0627-41dd-bc63-8b02a48c63f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33287,DS-281e9df8-3df2-4217-9b54-9ff400fdd23f,DISK], DatanodeInfoWithStorage[127.0.0.1:46789,DS-14432c3d-2870-49a5-9acd-3d41e947a630,DISK], DatanodeInfoWithStorage[127.0.0.1:37024,DS-1ce2c964-3486-4c69-bc8c-5eadee4e9ffe,DISK], DatanodeInfoWithStorage[127.0.0.1:46385,DS-e3cc63f7-cb93-4494-bf28-27b46f890d3c,DISK], DatanodeInfoWithStorage[127.0.0.1:41718,DS-86fe2959-fcd2-4ea5-a236-a57a3a8c0489,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.legacy.blockreader.local
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-14942715-172.17.0.16-1596962957493:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39469,DS-8d6991d3-bcad-492e-bdbd-af263f8d8e04,DISK], DatanodeInfoWithStorage[127.0.0.1:43503,DS-8bdb66e4-2bdb-4388-8812-2eaefa837b05,DISK], DatanodeInfoWithStorage[127.0.0.1:33730,DS-d2d930ae-39e6-49b1-800f-5d30c489e179,DISK], DatanodeInfoWithStorage[127.0.0.1:39087,DS-8b1d7a59-a1da-4cde-954e-467b4671b06a,DISK], DatanodeInfoWithStorage[127.0.0.1:41787,DS-76339a18-76bb-48d9-b40a-95d75439073d,DISK], DatanodeInfoWithStorage[127.0.0.1:44313,DS-c535bf70-ddbb-4345-a43a-40c201f6b684,DISK], DatanodeInfoWithStorage[127.0.0.1:46810,DS-384083a7-0da3-471b-b6e5-4d776f9903f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38347,DS-fdd98a60-1b15-4d29-aee8-c2b0a155e16d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-14942715-172.17.0.16-1596962957493:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39469,DS-8d6991d3-bcad-492e-bdbd-af263f8d8e04,DISK], DatanodeInfoWithStorage[127.0.0.1:43503,DS-8bdb66e4-2bdb-4388-8812-2eaefa837b05,DISK], DatanodeInfoWithStorage[127.0.0.1:33730,DS-d2d930ae-39e6-49b1-800f-5d30c489e179,DISK], DatanodeInfoWithStorage[127.0.0.1:39087,DS-8b1d7a59-a1da-4cde-954e-467b4671b06a,DISK], DatanodeInfoWithStorage[127.0.0.1:41787,DS-76339a18-76bb-48d9-b40a-95d75439073d,DISK], DatanodeInfoWithStorage[127.0.0.1:44313,DS-c535bf70-ddbb-4345-a43a-40c201f6b684,DISK], DatanodeInfoWithStorage[127.0.0.1:46810,DS-384083a7-0da3-471b-b6e5-4d776f9903f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38347,DS-fdd98a60-1b15-4d29-aee8-c2b0a155e16d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.legacy.blockreader.local
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-516541943-172.17.0.16-1596963170726:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38024,DS-7a29f2a7-46b4-4174-885c-d9748af5f706,DISK], DatanodeInfoWithStorage[127.0.0.1:37907,DS-cae75247-9b99-47e0-9356-33937997dc40,DISK], DatanodeInfoWithStorage[127.0.0.1:39721,DS-d670afc7-cff1-42f8-8f02-68973648b9e2,DISK], DatanodeInfoWithStorage[127.0.0.1:43368,DS-49e7ea00-d0f0-491b-b850-d0f8ca4f5166,DISK], DatanodeInfoWithStorage[127.0.0.1:39824,DS-8e15c11a-76d6-4783-b278-7d8e405d6cab,DISK], DatanodeInfoWithStorage[127.0.0.1:33786,DS-125b2aa8-73bb-4640-b658-908c62c9078e,DISK], DatanodeInfoWithStorage[127.0.0.1:45738,DS-d8b255a4-3264-47f1-8343-c2319183d845,DISK], DatanodeInfoWithStorage[127.0.0.1:34120,DS-3d6300f7-5903-411e-8722-985074fcafeb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-516541943-172.17.0.16-1596963170726:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38024,DS-7a29f2a7-46b4-4174-885c-d9748af5f706,DISK], DatanodeInfoWithStorage[127.0.0.1:37907,DS-cae75247-9b99-47e0-9356-33937997dc40,DISK], DatanodeInfoWithStorage[127.0.0.1:39721,DS-d670afc7-cff1-42f8-8f02-68973648b9e2,DISK], DatanodeInfoWithStorage[127.0.0.1:43368,DS-49e7ea00-d0f0-491b-b850-d0f8ca4f5166,DISK], DatanodeInfoWithStorage[127.0.0.1:39824,DS-8e15c11a-76d6-4783-b278-7d8e405d6cab,DISK], DatanodeInfoWithStorage[127.0.0.1:33786,DS-125b2aa8-73bb-4640-b658-908c62c9078e,DISK], DatanodeInfoWithStorage[127.0.0.1:45738,DS-d8b255a4-3264-47f1-8343-c2319183d845,DISK], DatanodeInfoWithStorage[127.0.0.1:34120,DS-3d6300f7-5903-411e-8722-985074fcafeb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.use.legacy.blockreader.local
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1504586538-172.17.0.16-1596963210764:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44628,DS-93e50c0d-73d8-4e67-a446-ff6ee4ae5bff,DISK], DatanodeInfoWithStorage[127.0.0.1:39188,DS-dd422b07-b5f5-4c60-9c1d-93a2b6c7ce84,DISK], DatanodeInfoWithStorage[127.0.0.1:46736,DS-e09af356-fad1-43ef-bc3d-32acd7cb5224,DISK], DatanodeInfoWithStorage[127.0.0.1:33125,DS-e79a60d4-cb2f-4480-ae0b-bf7708156304,DISK], DatanodeInfoWithStorage[127.0.0.1:38343,DS-aa9f0600-9417-40d0-a4a7-2b5f8981b22b,DISK], DatanodeInfoWithStorage[127.0.0.1:44645,DS-0d333696-7d57-4667-8009-2a86146d6a98,DISK], DatanodeInfoWithStorage[127.0.0.1:34204,DS-bcda62c5-2b18-4210-8e70-ec5f9d85db46,DISK], DatanodeInfoWithStorage[127.0.0.1:33622,DS-f8c7c081-ed06-4d93-b92e-c2210be08260,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1504586538-172.17.0.16-1596963210764:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44628,DS-93e50c0d-73d8-4e67-a446-ff6ee4ae5bff,DISK], DatanodeInfoWithStorage[127.0.0.1:39188,DS-dd422b07-b5f5-4c60-9c1d-93a2b6c7ce84,DISK], DatanodeInfoWithStorage[127.0.0.1:46736,DS-e09af356-fad1-43ef-bc3d-32acd7cb5224,DISK], DatanodeInfoWithStorage[127.0.0.1:33125,DS-e79a60d4-cb2f-4480-ae0b-bf7708156304,DISK], DatanodeInfoWithStorage[127.0.0.1:38343,DS-aa9f0600-9417-40d0-a4a7-2b5f8981b22b,DISK], DatanodeInfoWithStorage[127.0.0.1:44645,DS-0d333696-7d57-4667-8009-2a86146d6a98,DISK], DatanodeInfoWithStorage[127.0.0.1:34204,DS-bcda62c5-2b18-4210-8e70-ec5f9d85db46,DISK], DatanodeInfoWithStorage[127.0.0.1:33622,DS-f8c7c081-ed06-4d93-b92e-c2210be08260,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.legacy.blockreader.local
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1612242893-172.17.0.16-1596963277215:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40885,DS-4ea14252-6add-419a-ad27-db6352f4e75d,DISK], DatanodeInfoWithStorage[127.0.0.1:33184,DS-9422ed88-86fc-471e-a8d0-e0dede9c5954,DISK], DatanodeInfoWithStorage[127.0.0.1:43593,DS-bc7ccf53-3eff-459f-95cc-f947b5b86d42,DISK], DatanodeInfoWithStorage[127.0.0.1:45075,DS-07508679-7fbf-4641-9ac6-ae9a463fad9b,DISK], DatanodeInfoWithStorage[127.0.0.1:38596,DS-348e732a-11c1-454c-ac95-68a1e56c1195,DISK], DatanodeInfoWithStorage[127.0.0.1:45772,DS-22f59e8d-4338-4f09-8426-c8f2156128e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35921,DS-68313a52-ba55-483a-a5c2-22a34b382700,DISK], DatanodeInfoWithStorage[127.0.0.1:44639,DS-54cda60a-f54b-4f92-ad70-361f988c1e5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1612242893-172.17.0.16-1596963277215:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40885,DS-4ea14252-6add-419a-ad27-db6352f4e75d,DISK], DatanodeInfoWithStorage[127.0.0.1:33184,DS-9422ed88-86fc-471e-a8d0-e0dede9c5954,DISK], DatanodeInfoWithStorage[127.0.0.1:43593,DS-bc7ccf53-3eff-459f-95cc-f947b5b86d42,DISK], DatanodeInfoWithStorage[127.0.0.1:45075,DS-07508679-7fbf-4641-9ac6-ae9a463fad9b,DISK], DatanodeInfoWithStorage[127.0.0.1:38596,DS-348e732a-11c1-454c-ac95-68a1e56c1195,DISK], DatanodeInfoWithStorage[127.0.0.1:45772,DS-22f59e8d-4338-4f09-8426-c8f2156128e0,DISK], DatanodeInfoWithStorage[127.0.0.1:35921,DS-68313a52-ba55-483a-a5c2-22a34b382700,DISK], DatanodeInfoWithStorage[127.0.0.1:44639,DS-54cda60a-f54b-4f92-ad70-361f988c1e5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.legacy.blockreader.local
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2102814320-172.17.0.16-1596963499344:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40637,DS-53ea1007-1fde-4bf9-a400-bfc360826029,DISK], DatanodeInfoWithStorage[127.0.0.1:34693,DS-35136e12-af0a-4884-9eac-1eef7d711d0a,DISK], DatanodeInfoWithStorage[127.0.0.1:44584,DS-73dc2863-83f0-46eb-9f26-06a6d1248cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:37442,DS-5d6a052d-d110-4c34-a505-5cd7af88d3a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33861,DS-a57850a5-802b-4ad1-b378-9706def37eda,DISK], DatanodeInfoWithStorage[127.0.0.1:45226,DS-fbe936c4-b536-40d7-8d52-d25b8fbc019d,DISK], DatanodeInfoWithStorage[127.0.0.1:42758,DS-f524e71c-9e6c-45f6-bb60-18556f751c24,DISK], DatanodeInfoWithStorage[127.0.0.1:46851,DS-33644ded-39b3-46bf-b4f2-53d00fe9b151,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2102814320-172.17.0.16-1596963499344:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40637,DS-53ea1007-1fde-4bf9-a400-bfc360826029,DISK], DatanodeInfoWithStorage[127.0.0.1:34693,DS-35136e12-af0a-4884-9eac-1eef7d711d0a,DISK], DatanodeInfoWithStorage[127.0.0.1:44584,DS-73dc2863-83f0-46eb-9f26-06a6d1248cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:37442,DS-5d6a052d-d110-4c34-a505-5cd7af88d3a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33861,DS-a57850a5-802b-4ad1-b378-9706def37eda,DISK], DatanodeInfoWithStorage[127.0.0.1:45226,DS-fbe936c4-b536-40d7-8d52-d25b8fbc019d,DISK], DatanodeInfoWithStorage[127.0.0.1:42758,DS-f524e71c-9e6c-45f6-bb60-18556f751c24,DISK], DatanodeInfoWithStorage[127.0.0.1:46851,DS-33644ded-39b3-46bf-b4f2-53d00fe9b151,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.use.legacy.blockreader.local
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-336388843-172.17.0.16-1596963808561:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46203,DS-ceb0dc4a-2017-4201-8e2e-ef138d35a133,DISK], DatanodeInfoWithStorage[127.0.0.1:38123,DS-0d61be9c-616e-49fb-ac3d-387dc3f62dba,DISK], DatanodeInfoWithStorage[127.0.0.1:44731,DS-c5e8d161-c8ae-4ab4-bcf4-a31445ca0048,DISK], DatanodeInfoWithStorage[127.0.0.1:44917,DS-6170a2e9-65d7-4047-805d-aa8a216e1d01,DISK], DatanodeInfoWithStorage[127.0.0.1:33672,DS-e0fd9fdf-fdf2-4aaa-860d-442910b4c6f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37306,DS-01c01dca-a65e-4f7b-88fa-2f0154767bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:38564,DS-5b99c7ed-e57e-41da-969f-d237792a970c,DISK], DatanodeInfoWithStorage[127.0.0.1:43951,DS-9c2791b4-44ea-4201-b1c8-5a9d98a0b0c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-336388843-172.17.0.16-1596963808561:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46203,DS-ceb0dc4a-2017-4201-8e2e-ef138d35a133,DISK], DatanodeInfoWithStorage[127.0.0.1:38123,DS-0d61be9c-616e-49fb-ac3d-387dc3f62dba,DISK], DatanodeInfoWithStorage[127.0.0.1:44731,DS-c5e8d161-c8ae-4ab4-bcf4-a31445ca0048,DISK], DatanodeInfoWithStorage[127.0.0.1:44917,DS-6170a2e9-65d7-4047-805d-aa8a216e1d01,DISK], DatanodeInfoWithStorage[127.0.0.1:33672,DS-e0fd9fdf-fdf2-4aaa-860d-442910b4c6f5,DISK], DatanodeInfoWithStorage[127.0.0.1:37306,DS-01c01dca-a65e-4f7b-88fa-2f0154767bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:38564,DS-5b99c7ed-e57e-41da-969f-d237792a970c,DISK], DatanodeInfoWithStorage[127.0.0.1:43951,DS-9c2791b4-44ea-4201-b1c8-5a9d98a0b0c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.legacy.blockreader.local
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-28663695-172.17.0.16-1596963953095:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38839,DS-10d2d4bb-2717-42a6-b88a-ff7cd835bb42,DISK], DatanodeInfoWithStorage[127.0.0.1:39887,DS-d43507a2-15fc-4e3d-9ede-31dd9b136efc,DISK], DatanodeInfoWithStorage[127.0.0.1:37419,DS-81843b41-750c-4897-933b-56c76a0c4a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:46328,DS-aa3fa812-de32-47ca-a2d4-6ba456c4b559,DISK], DatanodeInfoWithStorage[127.0.0.1:38210,DS-17e83005-ff40-419c-996d-bfc4e30a248d,DISK], DatanodeInfoWithStorage[127.0.0.1:40719,DS-54ea71af-1aa0-4df8-953a-42c844308c65,DISK], DatanodeInfoWithStorage[127.0.0.1:34126,DS-86bb47ea-4891-424a-be85-67cb83272c71,DISK], DatanodeInfoWithStorage[127.0.0.1:39368,DS-4c148396-eb9f-4267-86f2-d60f9165a9ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-28663695-172.17.0.16-1596963953095:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38839,DS-10d2d4bb-2717-42a6-b88a-ff7cd835bb42,DISK], DatanodeInfoWithStorage[127.0.0.1:39887,DS-d43507a2-15fc-4e3d-9ede-31dd9b136efc,DISK], DatanodeInfoWithStorage[127.0.0.1:37419,DS-81843b41-750c-4897-933b-56c76a0c4a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:46328,DS-aa3fa812-de32-47ca-a2d4-6ba456c4b559,DISK], DatanodeInfoWithStorage[127.0.0.1:38210,DS-17e83005-ff40-419c-996d-bfc4e30a248d,DISK], DatanodeInfoWithStorage[127.0.0.1:40719,DS-54ea71af-1aa0-4df8-953a-42c844308c65,DISK], DatanodeInfoWithStorage[127.0.0.1:34126,DS-86bb47ea-4891-424a-be85-67cb83272c71,DISK], DatanodeInfoWithStorage[127.0.0.1:39368,DS-4c148396-eb9f-4267-86f2-d60f9165a9ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.legacy.blockreader.local
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2104278313-172.17.0.16-1596964101674:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46149,DS-46d3c2c7-0f18-4634-bbdb-6fedbc6a7f55,DISK], DatanodeInfoWithStorage[127.0.0.1:37995,DS-a05ab4b4-f837-415b-8929-810f0c27fce7,DISK], DatanodeInfoWithStorage[127.0.0.1:35095,DS-52928f64-58d2-4706-aebc-26930050a30f,DISK], DatanodeInfoWithStorage[127.0.0.1:45063,DS-2f7f7ecb-0c4c-4a91-8619-f3ae2d42e308,DISK], DatanodeInfoWithStorage[127.0.0.1:34902,DS-ab880b59-5314-45db-abfe-c4d86fbd4214,DISK], DatanodeInfoWithStorage[127.0.0.1:38701,DS-c34d0a6e-cefb-4c51-81cb-94ba1971303d,DISK], DatanodeInfoWithStorage[127.0.0.1:34783,DS-be4bbbda-e56c-4555-aafe-91f4c2cb8f50,DISK], DatanodeInfoWithStorage[127.0.0.1:46619,DS-e7ea3343-c8bb-406a-ad80-8661b1e0d2c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2104278313-172.17.0.16-1596964101674:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46149,DS-46d3c2c7-0f18-4634-bbdb-6fedbc6a7f55,DISK], DatanodeInfoWithStorage[127.0.0.1:37995,DS-a05ab4b4-f837-415b-8929-810f0c27fce7,DISK], DatanodeInfoWithStorage[127.0.0.1:35095,DS-52928f64-58d2-4706-aebc-26930050a30f,DISK], DatanodeInfoWithStorage[127.0.0.1:45063,DS-2f7f7ecb-0c4c-4a91-8619-f3ae2d42e308,DISK], DatanodeInfoWithStorage[127.0.0.1:34902,DS-ab880b59-5314-45db-abfe-c4d86fbd4214,DISK], DatanodeInfoWithStorage[127.0.0.1:38701,DS-c34d0a6e-cefb-4c51-81cb-94ba1971303d,DISK], DatanodeInfoWithStorage[127.0.0.1:34783,DS-be4bbbda-e56c-4555-aafe-91f4c2cb8f50,DISK], DatanodeInfoWithStorage[127.0.0.1:46619,DS-e7ea3343-c8bb-406a-ad80-8661b1e0d2c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.legacy.blockreader.local
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1092570167-172.17.0.16-1596964383606:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33525,DS-4c34d805-c69b-4212-95cf-760fc492becf,DISK], DatanodeInfoWithStorage[127.0.0.1:39705,DS-1e08e456-ecec-49ea-83e8-f4ebd7ddb2fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33046,DS-f04aa6a4-f3a8-45ca-8840-13eec6da0b61,DISK], DatanodeInfoWithStorage[127.0.0.1:37495,DS-57c4c8d9-0984-4d0a-87b3-aef9c0e541ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46416,DS-349a5737-d030-40b0-86a6-eb199096e88e,DISK], DatanodeInfoWithStorage[127.0.0.1:39488,DS-ff92696c-e685-49cb-b87c-9678c3a7eda5,DISK], DatanodeInfoWithStorage[127.0.0.1:38371,DS-9c7168e9-bcc9-41fd-b335-3882979ecc08,DISK], DatanodeInfoWithStorage[127.0.0.1:38981,DS-7c0e3fde-bf4b-4431-b356-e34b8e363165,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1092570167-172.17.0.16-1596964383606:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33525,DS-4c34d805-c69b-4212-95cf-760fc492becf,DISK], DatanodeInfoWithStorage[127.0.0.1:39705,DS-1e08e456-ecec-49ea-83e8-f4ebd7ddb2fd,DISK], DatanodeInfoWithStorage[127.0.0.1:33046,DS-f04aa6a4-f3a8-45ca-8840-13eec6da0b61,DISK], DatanodeInfoWithStorage[127.0.0.1:37495,DS-57c4c8d9-0984-4d0a-87b3-aef9c0e541ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46416,DS-349a5737-d030-40b0-86a6-eb199096e88e,DISK], DatanodeInfoWithStorage[127.0.0.1:39488,DS-ff92696c-e685-49cb-b87c-9678c3a7eda5,DISK], DatanodeInfoWithStorage[127.0.0.1:38371,DS-9c7168e9-bcc9-41fd-b335-3882979ecc08,DISK], DatanodeInfoWithStorage[127.0.0.1:38981,DS-7c0e3fde-bf4b-4431-b356-e34b8e363165,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.legacy.blockreader.local
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1709392393-172.17.0.16-1596964648688:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42787,DS-ebdded2b-903b-4cee-8f3c-44fc9bfa0105,DISK], DatanodeInfoWithStorage[127.0.0.1:35844,DS-4dd41b59-b4f7-486d-bb00-94f3ca90ac38,DISK], DatanodeInfoWithStorage[127.0.0.1:41596,DS-9435619e-bca3-4557-a8a8-844657fe7c20,DISK], DatanodeInfoWithStorage[127.0.0.1:34605,DS-9dcad0cf-c486-4739-af36-0c25cd4815d1,DISK], DatanodeInfoWithStorage[127.0.0.1:33902,DS-92a27eff-32eb-4624-85f9-7a245faecdd4,DISK], DatanodeInfoWithStorage[127.0.0.1:33737,DS-ada62999-60b7-4627-83b6-5ade59db3d8e,DISK], DatanodeInfoWithStorage[127.0.0.1:35937,DS-895b8a36-78f4-4e94-a212-7c93484fe564,DISK], DatanodeInfoWithStorage[127.0.0.1:33036,DS-ba0ce277-5703-465c-9228-543eb3a7ce00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1709392393-172.17.0.16-1596964648688:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42787,DS-ebdded2b-903b-4cee-8f3c-44fc9bfa0105,DISK], DatanodeInfoWithStorage[127.0.0.1:35844,DS-4dd41b59-b4f7-486d-bb00-94f3ca90ac38,DISK], DatanodeInfoWithStorage[127.0.0.1:41596,DS-9435619e-bca3-4557-a8a8-844657fe7c20,DISK], DatanodeInfoWithStorage[127.0.0.1:34605,DS-9dcad0cf-c486-4739-af36-0c25cd4815d1,DISK], DatanodeInfoWithStorage[127.0.0.1:33902,DS-92a27eff-32eb-4624-85f9-7a245faecdd4,DISK], DatanodeInfoWithStorage[127.0.0.1:33737,DS-ada62999-60b7-4627-83b6-5ade59db3d8e,DISK], DatanodeInfoWithStorage[127.0.0.1:35937,DS-895b8a36-78f4-4e94-a212-7c93484fe564,DISK], DatanodeInfoWithStorage[127.0.0.1:33036,DS-ba0ce277-5703-465c-9228-543eb3a7ce00,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.legacy.blockreader.local
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-702041562-172.17.0.16-1596965037887:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37380,DS-b6dc587e-5824-4fd0-a938-88b155467aaa,DISK], DatanodeInfoWithStorage[127.0.0.1:45057,DS-6c123bd6-a2d5-4173-8668-0afeea27378a,DISK], DatanodeInfoWithStorage[127.0.0.1:34393,DS-8746afa6-b19a-4d91-a108-8b1a2883ba7d,DISK], DatanodeInfoWithStorage[127.0.0.1:45595,DS-7fd1ac23-7324-4d4c-9791-1d032ff0a15f,DISK], DatanodeInfoWithStorage[127.0.0.1:42951,DS-7060a5d1-e041-4a06-b973-0b4ad3205ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:42175,DS-939476e7-8ff0-4d85-a478-b921444919e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41897,DS-3aaf35a2-1fc8-4c67-8f41-39aff7c5a83a,DISK], DatanodeInfoWithStorage[127.0.0.1:39000,DS-c8f0b191-1ee4-4df2-b046-6148ef9594f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-702041562-172.17.0.16-1596965037887:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37380,DS-b6dc587e-5824-4fd0-a938-88b155467aaa,DISK], DatanodeInfoWithStorage[127.0.0.1:45057,DS-6c123bd6-a2d5-4173-8668-0afeea27378a,DISK], DatanodeInfoWithStorage[127.0.0.1:34393,DS-8746afa6-b19a-4d91-a108-8b1a2883ba7d,DISK], DatanodeInfoWithStorage[127.0.0.1:45595,DS-7fd1ac23-7324-4d4c-9791-1d032ff0a15f,DISK], DatanodeInfoWithStorage[127.0.0.1:42951,DS-7060a5d1-e041-4a06-b973-0b4ad3205ca5,DISK], DatanodeInfoWithStorage[127.0.0.1:42175,DS-939476e7-8ff0-4d85-a478-b921444919e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41897,DS-3aaf35a2-1fc8-4c67-8f41-39aff7c5a83a,DISK], DatanodeInfoWithStorage[127.0.0.1:39000,DS-c8f0b191-1ee4-4df2-b046-6148ef9594f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.use.legacy.blockreader.local
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-460173047-172.17.0.16-1596965710794:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35307,DS-6b8ad650-254e-45a3-b055-211f5d1c9c32,DISK], DatanodeInfoWithStorage[127.0.0.1:37228,DS-25c51c90-099f-408c-94f6-723d92f5fffb,DISK], DatanodeInfoWithStorage[127.0.0.1:46867,DS-1f795365-f06e-4d43-9058-ec56435a998f,DISK], DatanodeInfoWithStorage[127.0.0.1:37283,DS-bf10e111-b4ce-47af-9187-8f39a3c541b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40372,DS-68e34e04-68d5-40ff-a100-8729d5eae9ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37798,DS-ecf201e8-7b1d-4c15-9df7-9cddc99199c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43627,DS-6fc8afee-9ed9-4c66-a1e9-c49843a04cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:40115,DS-c4b3c042-7b8d-4a4d-916b-e388b87902ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-460173047-172.17.0.16-1596965710794:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35307,DS-6b8ad650-254e-45a3-b055-211f5d1c9c32,DISK], DatanodeInfoWithStorage[127.0.0.1:37228,DS-25c51c90-099f-408c-94f6-723d92f5fffb,DISK], DatanodeInfoWithStorage[127.0.0.1:46867,DS-1f795365-f06e-4d43-9058-ec56435a998f,DISK], DatanodeInfoWithStorage[127.0.0.1:37283,DS-bf10e111-b4ce-47af-9187-8f39a3c541b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40372,DS-68e34e04-68d5-40ff-a100-8729d5eae9ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37798,DS-ecf201e8-7b1d-4c15-9df7-9cddc99199c2,DISK], DatanodeInfoWithStorage[127.0.0.1:43627,DS-6fc8afee-9ed9-4c66-a1e9-c49843a04cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:40115,DS-c4b3c042-7b8d-4a4d-916b-e388b87902ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.legacy.blockreader.local
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1584240837-172.17.0.16-1596965885155:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33672,DS-97b2ba40-ef17-4f70-b937-4c42c68e44c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45693,DS-4e086e8b-d2bb-4a30-a0d3-3d5b405ca265,DISK], DatanodeInfoWithStorage[127.0.0.1:43891,DS-b164b266-7262-490d-91e9-8dacdacc46d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38515,DS-993aff01-2a61-4977-9cb1-66ac3c6350b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33511,DS-349404e4-a4c4-468a-8951-cf8355338536,DISK], DatanodeInfoWithStorage[127.0.0.1:35397,DS-7d18365a-5c02-4a9c-9d4a-ba5712b040bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37335,DS-0a7a9c31-1b0c-4a57-8b0e-5e2276301792,DISK], DatanodeInfoWithStorage[127.0.0.1:43055,DS-4df8c935-43d1-4386-a79d-3535f8a51f77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1584240837-172.17.0.16-1596965885155:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33672,DS-97b2ba40-ef17-4f70-b937-4c42c68e44c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45693,DS-4e086e8b-d2bb-4a30-a0d3-3d5b405ca265,DISK], DatanodeInfoWithStorage[127.0.0.1:43891,DS-b164b266-7262-490d-91e9-8dacdacc46d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38515,DS-993aff01-2a61-4977-9cb1-66ac3c6350b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33511,DS-349404e4-a4c4-468a-8951-cf8355338536,DISK], DatanodeInfoWithStorage[127.0.0.1:35397,DS-7d18365a-5c02-4a9c-9d4a-ba5712b040bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37335,DS-0a7a9c31-1b0c-4a57-8b0e-5e2276301792,DISK], DatanodeInfoWithStorage[127.0.0.1:43055,DS-4df8c935-43d1-4386-a79d-3535f8a51f77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.legacy.blockreader.local
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1908628661-172.17.0.16-1596966050615:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43485,DS-4cea74ee-1bf2-4367-9320-d7a1977b33af,DISK], DatanodeInfoWithStorage[127.0.0.1:46790,DS-170bea98-dd69-4590-adcc-5fab86b110f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37718,DS-5560a7d3-5bb1-4058-9ba4-f96dfac7f4a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39967,DS-e426663d-8a19-4b1d-923b-4e6543e5d152,DISK], DatanodeInfoWithStorage[127.0.0.1:39764,DS-8b4df5d0-6aba-4472-8b11-27975e12a882,DISK], DatanodeInfoWithStorage[127.0.0.1:43133,DS-8d9b9e8c-b712-4f7b-a373-6be6abeeef30,DISK], DatanodeInfoWithStorage[127.0.0.1:36498,DS-330b4d8b-523f-4168-94a0-85976a08290c,DISK], DatanodeInfoWithStorage[127.0.0.1:37736,DS-289f11b3-8812-42d5-952b-f9480487be44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1908628661-172.17.0.16-1596966050615:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43485,DS-4cea74ee-1bf2-4367-9320-d7a1977b33af,DISK], DatanodeInfoWithStorage[127.0.0.1:46790,DS-170bea98-dd69-4590-adcc-5fab86b110f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37718,DS-5560a7d3-5bb1-4058-9ba4-f96dfac7f4a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39967,DS-e426663d-8a19-4b1d-923b-4e6543e5d152,DISK], DatanodeInfoWithStorage[127.0.0.1:39764,DS-8b4df5d0-6aba-4472-8b11-27975e12a882,DISK], DatanodeInfoWithStorage[127.0.0.1:43133,DS-8d9b9e8c-b712-4f7b-a373-6be6abeeef30,DISK], DatanodeInfoWithStorage[127.0.0.1:36498,DS-330b4d8b-523f-4168-94a0-85976a08290c,DISK], DatanodeInfoWithStorage[127.0.0.1:37736,DS-289f11b3-8812-42d5-952b-f9480487be44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.use.legacy.blockreader.local
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1517976155-172.17.0.16-1596966084728:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45571,DS-ab37df4d-d803-4265-8ea2-61dfcfffd589,DISK], DatanodeInfoWithStorage[127.0.0.1:44018,DS-cf4f4469-d134-405e-9e20-65b3bef0eddb,DISK], DatanodeInfoWithStorage[127.0.0.1:36122,DS-1af83b2f-93ed-48b8-b94c-0f925d0fe609,DISK], DatanodeInfoWithStorage[127.0.0.1:34972,DS-a13018b5-2672-4743-bf3e-59e8fb2f5b49,DISK], DatanodeInfoWithStorage[127.0.0.1:42429,DS-02245927-02c7-491a-99ba-a9b75de6b300,DISK], DatanodeInfoWithStorage[127.0.0.1:46492,DS-4bcc1614-e592-4ac2-aefc-d64b50d19716,DISK], DatanodeInfoWithStorage[127.0.0.1:40686,DS-2142eab2-5713-4170-b3ac-f3e164074c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:41743,DS-e5176181-86c9-462d-84b6-46e7a3478c76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1517976155-172.17.0.16-1596966084728:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45571,DS-ab37df4d-d803-4265-8ea2-61dfcfffd589,DISK], DatanodeInfoWithStorage[127.0.0.1:44018,DS-cf4f4469-d134-405e-9e20-65b3bef0eddb,DISK], DatanodeInfoWithStorage[127.0.0.1:36122,DS-1af83b2f-93ed-48b8-b94c-0f925d0fe609,DISK], DatanodeInfoWithStorage[127.0.0.1:34972,DS-a13018b5-2672-4743-bf3e-59e8fb2f5b49,DISK], DatanodeInfoWithStorage[127.0.0.1:42429,DS-02245927-02c7-491a-99ba-a9b75de6b300,DISK], DatanodeInfoWithStorage[127.0.0.1:46492,DS-4bcc1614-e592-4ac2-aefc-d64b50d19716,DISK], DatanodeInfoWithStorage[127.0.0.1:40686,DS-2142eab2-5713-4170-b3ac-f3e164074c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:41743,DS-e5176181-86c9-462d-84b6-46e7a3478c76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.legacy.blockreader.local
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-969898787-172.17.0.16-1596966249942:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34291,DS-e982c4a3-6b18-4a85-9145-63d8ee11989f,DISK], DatanodeInfoWithStorage[127.0.0.1:40132,DS-dc11b135-f225-4fd5-b84c-6abadcb77bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:44236,DS-849ed820-b671-4392-a3ab-071ca9c3f3d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34942,DS-bf44e089-ae5f-4a6f-895f-f952705be630,DISK], DatanodeInfoWithStorage[127.0.0.1:39075,DS-b0116537-c779-447c-8af5-a1af704320d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35025,DS-83c6a734-5284-4d8f-827f-5cf3102d2403,DISK], DatanodeInfoWithStorage[127.0.0.1:34973,DS-6815950a-197f-4e6a-b95d-997e89fd9c7e,DISK], DatanodeInfoWithStorage[127.0.0.1:38177,DS-eab257bf-88bc-455b-9739-92467070f702,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-969898787-172.17.0.16-1596966249942:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34291,DS-e982c4a3-6b18-4a85-9145-63d8ee11989f,DISK], DatanodeInfoWithStorage[127.0.0.1:40132,DS-dc11b135-f225-4fd5-b84c-6abadcb77bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:44236,DS-849ed820-b671-4392-a3ab-071ca9c3f3d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34942,DS-bf44e089-ae5f-4a6f-895f-f952705be630,DISK], DatanodeInfoWithStorage[127.0.0.1:39075,DS-b0116537-c779-447c-8af5-a1af704320d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35025,DS-83c6a734-5284-4d8f-827f-5cf3102d2403,DISK], DatanodeInfoWithStorage[127.0.0.1:34973,DS-6815950a-197f-4e6a-b95d-997e89fd9c7e,DISK], DatanodeInfoWithStorage[127.0.0.1:38177,DS-eab257bf-88bc-455b-9739-92467070f702,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.legacy.blockreader.local
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-768460857-172.17.0.16-1596966458425:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36433,DS-60806581-6919-4be4-a6df-d63d4f213f9f,DISK], DatanodeInfoWithStorage[127.0.0.1:33532,DS-5ec5609a-3cc7-47b0-a6e7-874ea7ba3b74,DISK], DatanodeInfoWithStorage[127.0.0.1:44050,DS-b203142b-fb5b-480e-8be0-8702f39b41b8,DISK], DatanodeInfoWithStorage[127.0.0.1:36466,DS-5869f954-8441-4bc2-80e8-19ebf1a68314,DISK], DatanodeInfoWithStorage[127.0.0.1:33637,DS-d1747395-9b7c-4feb-9b8c-723b035e8b1d,DISK], DatanodeInfoWithStorage[127.0.0.1:45142,DS-a0184215-27e0-439e-8eff-b496e522237c,DISK], DatanodeInfoWithStorage[127.0.0.1:42874,DS-74066f2f-8fe9-43dc-8426-1b85a721e5d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37240,DS-93403113-f832-4e4b-bc16-051054461b85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-768460857-172.17.0.16-1596966458425:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36433,DS-60806581-6919-4be4-a6df-d63d4f213f9f,DISK], DatanodeInfoWithStorage[127.0.0.1:33532,DS-5ec5609a-3cc7-47b0-a6e7-874ea7ba3b74,DISK], DatanodeInfoWithStorage[127.0.0.1:44050,DS-b203142b-fb5b-480e-8be0-8702f39b41b8,DISK], DatanodeInfoWithStorage[127.0.0.1:36466,DS-5869f954-8441-4bc2-80e8-19ebf1a68314,DISK], DatanodeInfoWithStorage[127.0.0.1:33637,DS-d1747395-9b7c-4feb-9b8c-723b035e8b1d,DISK], DatanodeInfoWithStorage[127.0.0.1:45142,DS-a0184215-27e0-439e-8eff-b496e522237c,DISK], DatanodeInfoWithStorage[127.0.0.1:42874,DS-74066f2f-8fe9-43dc-8426-1b85a721e5d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37240,DS-93403113-f832-4e4b-bc16-051054461b85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.legacy.blockreader.local
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1464532937-172.17.0.16-1596966651715:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37309,DS-bb526481-81c0-4006-b95f-b425ed2fd290,DISK], DatanodeInfoWithStorage[127.0.0.1:46457,DS-4d48e0ea-a7f1-4464-ae07-2d9b3398614f,DISK], DatanodeInfoWithStorage[127.0.0.1:44222,DS-fcca8fcf-8573-427b-84b8-0cdbaacecc4d,DISK], DatanodeInfoWithStorage[127.0.0.1:43784,DS-97b2d767-fc97-48e5-a04c-d32964da67af,DISK], DatanodeInfoWithStorage[127.0.0.1:46544,DS-bd6b57bb-3b22-4dc9-bf0b-4d72d9ab6c7e,DISK], DatanodeInfoWithStorage[127.0.0.1:45409,DS-a4f211a9-7b29-44bd-8da2-69ed913eeec0,DISK], DatanodeInfoWithStorage[127.0.0.1:38091,DS-37d7866f-9305-41f8-8692-1394f7619c20,DISK], DatanodeInfoWithStorage[127.0.0.1:41986,DS-2abb26eb-0d52-47da-b8cd-5b9fed4743e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1464532937-172.17.0.16-1596966651715:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37309,DS-bb526481-81c0-4006-b95f-b425ed2fd290,DISK], DatanodeInfoWithStorage[127.0.0.1:46457,DS-4d48e0ea-a7f1-4464-ae07-2d9b3398614f,DISK], DatanodeInfoWithStorage[127.0.0.1:44222,DS-fcca8fcf-8573-427b-84b8-0cdbaacecc4d,DISK], DatanodeInfoWithStorage[127.0.0.1:43784,DS-97b2d767-fc97-48e5-a04c-d32964da67af,DISK], DatanodeInfoWithStorage[127.0.0.1:46544,DS-bd6b57bb-3b22-4dc9-bf0b-4d72d9ab6c7e,DISK], DatanodeInfoWithStorage[127.0.0.1:45409,DS-a4f211a9-7b29-44bd-8da2-69ed913eeec0,DISK], DatanodeInfoWithStorage[127.0.0.1:38091,DS-37d7866f-9305-41f8-8692-1394f7619c20,DISK], DatanodeInfoWithStorage[127.0.0.1:41986,DS-2abb26eb-0d52-47da-b8cd-5b9fed4743e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.legacy.blockreader.local
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-93987831-172.17.0.16-1596966996646:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46124,DS-edd1d093-fbbb-4fec-9ada-04496c66a7b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33077,DS-c31a1b50-643c-467c-8184-adf8ce66f888,DISK], DatanodeInfoWithStorage[127.0.0.1:34970,DS-0edf0784-dccf-4ae6-a565-a51a8cbc4104,DISK], DatanodeInfoWithStorage[127.0.0.1:33884,DS-a2e52418-7fd4-47b8-8017-f44dc9cd5f97,DISK], DatanodeInfoWithStorage[127.0.0.1:46451,DS-693f1294-d0d9-4ceb-af37-025c57b87836,DISK], DatanodeInfoWithStorage[127.0.0.1:37202,DS-c10554c3-558d-478d-970e-e38063924dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:45540,DS-fff7c561-c5e3-4174-96c9-5a4c9e97803a,DISK], DatanodeInfoWithStorage[127.0.0.1:43441,DS-7b9c7785-e87e-4a9b-a7c4-b2cc1cbde6c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-93987831-172.17.0.16-1596966996646:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46124,DS-edd1d093-fbbb-4fec-9ada-04496c66a7b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33077,DS-c31a1b50-643c-467c-8184-adf8ce66f888,DISK], DatanodeInfoWithStorage[127.0.0.1:34970,DS-0edf0784-dccf-4ae6-a565-a51a8cbc4104,DISK], DatanodeInfoWithStorage[127.0.0.1:33884,DS-a2e52418-7fd4-47b8-8017-f44dc9cd5f97,DISK], DatanodeInfoWithStorage[127.0.0.1:46451,DS-693f1294-d0d9-4ceb-af37-025c57b87836,DISK], DatanodeInfoWithStorage[127.0.0.1:37202,DS-c10554c3-558d-478d-970e-e38063924dd3,DISK], DatanodeInfoWithStorage[127.0.0.1:45540,DS-fff7c561-c5e3-4174-96c9-5a4c9e97803a,DISK], DatanodeInfoWithStorage[127.0.0.1:43441,DS-7b9c7785-e87e-4a9b-a7c4-b2cc1cbde6c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.legacy.blockreader.local
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1729414939-172.17.0.16-1596967086746:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39311,DS-b9d7d9d9-5390-4fac-ba0d-1d9b29854349,DISK], DatanodeInfoWithStorage[127.0.0.1:38009,DS-776c8c7e-f5ef-41a4-a260-c504e5670749,DISK], DatanodeInfoWithStorage[127.0.0.1:34574,DS-8fb32757-b1d7-43a5-922e-78af1dae4a71,DISK], DatanodeInfoWithStorage[127.0.0.1:34766,DS-5c7bbde4-2120-42da-89a8-89db1f151928,DISK], DatanodeInfoWithStorage[127.0.0.1:37773,DS-0a71be36-910c-41ba-b484-ba39ac649c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:40330,DS-acecddf9-daf2-47e9-83c9-b4c90391df14,DISK], DatanodeInfoWithStorage[127.0.0.1:45119,DS-7045f7e8-5326-487d-8718-817dcba430d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45647,DS-6ce1c9f9-2224-49a5-b97f-e281c6517858,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1729414939-172.17.0.16-1596967086746:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39311,DS-b9d7d9d9-5390-4fac-ba0d-1d9b29854349,DISK], DatanodeInfoWithStorage[127.0.0.1:38009,DS-776c8c7e-f5ef-41a4-a260-c504e5670749,DISK], DatanodeInfoWithStorage[127.0.0.1:34574,DS-8fb32757-b1d7-43a5-922e-78af1dae4a71,DISK], DatanodeInfoWithStorage[127.0.0.1:34766,DS-5c7bbde4-2120-42da-89a8-89db1f151928,DISK], DatanodeInfoWithStorage[127.0.0.1:37773,DS-0a71be36-910c-41ba-b484-ba39ac649c9d,DISK], DatanodeInfoWithStorage[127.0.0.1:40330,DS-acecddf9-daf2-47e9-83c9-b4c90391df14,DISK], DatanodeInfoWithStorage[127.0.0.1:45119,DS-7045f7e8-5326-487d-8718-817dcba430d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45647,DS-6ce1c9f9-2224-49a5-b97f-e281c6517858,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 19 out of 50
result: false positive !!!
Total execution time in seconds : 5236
