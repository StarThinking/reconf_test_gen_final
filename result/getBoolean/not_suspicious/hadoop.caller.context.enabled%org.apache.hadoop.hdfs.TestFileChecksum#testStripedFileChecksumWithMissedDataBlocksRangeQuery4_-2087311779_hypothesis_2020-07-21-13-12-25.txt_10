reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1162242402-172.17.0.8-1595337701528:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46220,DS-79524410-855d-4cf3-a937-a02e9d1168ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36608,DS-3a6986fc-207a-4bb1-abe1-c82221d29717,DISK], DatanodeInfoWithStorage[127.0.0.1:43122,DS-3edaa599-3396-470e-9540-c16d142466a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34961,DS-000e3460-1f91-461c-8991-453570f0e62e,DISK], DatanodeInfoWithStorage[127.0.0.1:46384,DS-984224bb-4166-4234-bb9d-5bc3c69d4141,DISK], DatanodeInfoWithStorage[127.0.0.1:39825,DS-5e81302b-7772-493c-bc79-59be52e848c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34547,DS-ed586815-cbed-43ce-a834-2db14f94b94f,DISK], DatanodeInfoWithStorage[127.0.0.1:35551,DS-b3390c91-f1ce-4d0b-8466-6699d0925ca9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1162242402-172.17.0.8-1595337701528:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46220,DS-79524410-855d-4cf3-a937-a02e9d1168ff,DISK], DatanodeInfoWithStorage[127.0.0.1:36608,DS-3a6986fc-207a-4bb1-abe1-c82221d29717,DISK], DatanodeInfoWithStorage[127.0.0.1:43122,DS-3edaa599-3396-470e-9540-c16d142466a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34961,DS-000e3460-1f91-461c-8991-453570f0e62e,DISK], DatanodeInfoWithStorage[127.0.0.1:46384,DS-984224bb-4166-4234-bb9d-5bc3c69d4141,DISK], DatanodeInfoWithStorage[127.0.0.1:39825,DS-5e81302b-7772-493c-bc79-59be52e848c8,DISK], DatanodeInfoWithStorage[127.0.0.1:34547,DS-ed586815-cbed-43ce-a834-2db14f94b94f,DISK], DatanodeInfoWithStorage[127.0.0.1:35551,DS-b3390c91-f1ce-4d0b-8466-6699d0925ca9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-58529719-172.17.0.8-1595338768353:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36672,DS-7f205a06-507f-48a4-8c63-f4bc0c6639e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37236,DS-54d45251-e61c-405a-ad9c-9d9e9e46055d,DISK], DatanodeInfoWithStorage[127.0.0.1:43845,DS-4646799b-30e7-442f-bd65-c4b47805287d,DISK], DatanodeInfoWithStorage[127.0.0.1:46230,DS-f1050001-9f96-478f-857d-5b732567baf4,DISK], DatanodeInfoWithStorage[127.0.0.1:36946,DS-5a6047be-113e-42f1-af3c-34a7e7b103cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37106,DS-00150b82-e069-4b84-b761-991f9147e393,DISK], DatanodeInfoWithStorage[127.0.0.1:45428,DS-29b93b5b-25b3-4b3d-8cfc-7b38c9d2850e,DISK], DatanodeInfoWithStorage[127.0.0.1:40238,DS-57999b97-4047-4748-9fd4-d19d3af7c7c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-58529719-172.17.0.8-1595338768353:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36672,DS-7f205a06-507f-48a4-8c63-f4bc0c6639e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37236,DS-54d45251-e61c-405a-ad9c-9d9e9e46055d,DISK], DatanodeInfoWithStorage[127.0.0.1:43845,DS-4646799b-30e7-442f-bd65-c4b47805287d,DISK], DatanodeInfoWithStorage[127.0.0.1:46230,DS-f1050001-9f96-478f-857d-5b732567baf4,DISK], DatanodeInfoWithStorage[127.0.0.1:36946,DS-5a6047be-113e-42f1-af3c-34a7e7b103cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37106,DS-00150b82-e069-4b84-b761-991f9147e393,DISK], DatanodeInfoWithStorage[127.0.0.1:45428,DS-29b93b5b-25b3-4b3d-8cfc-7b38c9d2850e,DISK], DatanodeInfoWithStorage[127.0.0.1:40238,DS-57999b97-4047-4748-9fd4-d19d3af7c7c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1557506040-172.17.0.8-1595338803610:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44200,DS-61dcbb73-dedf-48e3-a112-4effcd62c661,DISK], DatanodeInfoWithStorage[127.0.0.1:39853,DS-3ccef7ef-92a4-4558-b972-31e08c21013d,DISK], DatanodeInfoWithStorage[127.0.0.1:37554,DS-0f249eba-3193-453a-9476-1a1fd42f2265,DISK], DatanodeInfoWithStorage[127.0.0.1:43916,DS-223a37be-3b0e-4eb9-9c14-c8c17dd30493,DISK], DatanodeInfoWithStorage[127.0.0.1:36592,DS-2f2d8f84-a1cb-4300-adb6-7d12c0530e98,DISK], DatanodeInfoWithStorage[127.0.0.1:38717,DS-bc142ce1-17b0-4f75-9895-a6e34c5a4c35,DISK], DatanodeInfoWithStorage[127.0.0.1:33458,DS-4a7abb8f-5da5-49cf-a16e-e6cd34e8d943,DISK], DatanodeInfoWithStorage[127.0.0.1:43376,DS-b2720015-a284-4db8-9cfd-7ede2b2e5004,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1557506040-172.17.0.8-1595338803610:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44200,DS-61dcbb73-dedf-48e3-a112-4effcd62c661,DISK], DatanodeInfoWithStorage[127.0.0.1:39853,DS-3ccef7ef-92a4-4558-b972-31e08c21013d,DISK], DatanodeInfoWithStorage[127.0.0.1:37554,DS-0f249eba-3193-453a-9476-1a1fd42f2265,DISK], DatanodeInfoWithStorage[127.0.0.1:43916,DS-223a37be-3b0e-4eb9-9c14-c8c17dd30493,DISK], DatanodeInfoWithStorage[127.0.0.1:36592,DS-2f2d8f84-a1cb-4300-adb6-7d12c0530e98,DISK], DatanodeInfoWithStorage[127.0.0.1:38717,DS-bc142ce1-17b0-4f75-9895-a6e34c5a4c35,DISK], DatanodeInfoWithStorage[127.0.0.1:33458,DS-4a7abb8f-5da5-49cf-a16e-e6cd34e8d943,DISK], DatanodeInfoWithStorage[127.0.0.1:43376,DS-b2720015-a284-4db8-9cfd-7ede2b2e5004,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2045720240-172.17.0.8-1595339408813:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38752,DS-76a110c5-fa03-4a55-a594-62d53589cd2c,DISK], DatanodeInfoWithStorage[127.0.0.1:42560,DS-2a83d094-008e-4ece-b603-eaaa9bd4a4d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43586,DS-b204b237-88b5-4b09-8dfc-a6d359f1f5fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43699,DS-dec0cf6a-9152-453d-a31f-658ac37c674b,DISK], DatanodeInfoWithStorage[127.0.0.1:36285,DS-88813348-568d-4c61-b423-940c2b250adb,DISK], DatanodeInfoWithStorage[127.0.0.1:41150,DS-75fe8ecd-c28c-4a4a-9c48-6318a8414bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:38392,DS-ad09ae45-0674-4cc0-923f-bcaf10c07bac,DISK], DatanodeInfoWithStorage[127.0.0.1:36800,DS-91b4d7b8-b9c5-4298-aa2c-cde922b5588d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2045720240-172.17.0.8-1595339408813:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38752,DS-76a110c5-fa03-4a55-a594-62d53589cd2c,DISK], DatanodeInfoWithStorage[127.0.0.1:42560,DS-2a83d094-008e-4ece-b603-eaaa9bd4a4d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43586,DS-b204b237-88b5-4b09-8dfc-a6d359f1f5fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43699,DS-dec0cf6a-9152-453d-a31f-658ac37c674b,DISK], DatanodeInfoWithStorage[127.0.0.1:36285,DS-88813348-568d-4c61-b423-940c2b250adb,DISK], DatanodeInfoWithStorage[127.0.0.1:41150,DS-75fe8ecd-c28c-4a4a-9c48-6318a8414bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:38392,DS-ad09ae45-0674-4cc0-923f-bcaf10c07bac,DISK], DatanodeInfoWithStorage[127.0.0.1:36800,DS-91b4d7b8-b9c5-4298-aa2c-cde922b5588d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-384135345-172.17.0.8-1595339483751:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45041,DS-7c94fb60-3cc4-4826-ad1a-526bd14b6a48,DISK], DatanodeInfoWithStorage[127.0.0.1:33567,DS-4cc47076-1111-4b2f-90c7-da97e1ce555d,DISK], DatanodeInfoWithStorage[127.0.0.1:36911,DS-d0f9a303-c194-489a-80a5-675c226d9a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:41388,DS-0195f7f2-d0d0-40c8-8513-6b54df441b29,DISK], DatanodeInfoWithStorage[127.0.0.1:41464,DS-4cf0701c-15ae-4bf2-93b5-fd8ada96e233,DISK], DatanodeInfoWithStorage[127.0.0.1:33599,DS-a0f6f966-82ee-4c22-a131-16d01fe3992f,DISK], DatanodeInfoWithStorage[127.0.0.1:38940,DS-bde2fada-3d64-4259-a342-7f9bba643dd9,DISK], DatanodeInfoWithStorage[127.0.0.1:46642,DS-d490a97f-950f-4c5c-9627-ef42481b2c4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-384135345-172.17.0.8-1595339483751:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45041,DS-7c94fb60-3cc4-4826-ad1a-526bd14b6a48,DISK], DatanodeInfoWithStorage[127.0.0.1:33567,DS-4cc47076-1111-4b2f-90c7-da97e1ce555d,DISK], DatanodeInfoWithStorage[127.0.0.1:36911,DS-d0f9a303-c194-489a-80a5-675c226d9a2e,DISK], DatanodeInfoWithStorage[127.0.0.1:41388,DS-0195f7f2-d0d0-40c8-8513-6b54df441b29,DISK], DatanodeInfoWithStorage[127.0.0.1:41464,DS-4cf0701c-15ae-4bf2-93b5-fd8ada96e233,DISK], DatanodeInfoWithStorage[127.0.0.1:33599,DS-a0f6f966-82ee-4c22-a131-16d01fe3992f,DISK], DatanodeInfoWithStorage[127.0.0.1:38940,DS-bde2fada-3d64-4259-a342-7f9bba643dd9,DISK], DatanodeInfoWithStorage[127.0.0.1:46642,DS-d490a97f-950f-4c5c-9627-ef42481b2c4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1448354479-172.17.0.8-1595339620572:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46612,DS-2d0334a1-3323-4d7a-935a-82f8a3ef8fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:36722,DS-b78b61de-e7e2-4a19-9bbd-457f0486ef2f,DISK], DatanodeInfoWithStorage[127.0.0.1:34376,DS-97126ea9-59f1-47cf-bb85-eaa0861b403e,DISK], DatanodeInfoWithStorage[127.0.0.1:37289,DS-3cc10d14-b174-462d-b47f-52bf262e64db,DISK], DatanodeInfoWithStorage[127.0.0.1:34466,DS-b7b43ad5-401b-4353-a535-cd1436b1b2a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45451,DS-714a72c9-6060-47a4-a821-461ab978b46a,DISK], DatanodeInfoWithStorage[127.0.0.1:34573,DS-b257800b-f70b-4310-a1dc-bcaf1bb8701e,DISK], DatanodeInfoWithStorage[127.0.0.1:45083,DS-b37d12e8-2ba1-4c86-975c-ae1336b01fc8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1448354479-172.17.0.8-1595339620572:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46612,DS-2d0334a1-3323-4d7a-935a-82f8a3ef8fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:36722,DS-b78b61de-e7e2-4a19-9bbd-457f0486ef2f,DISK], DatanodeInfoWithStorage[127.0.0.1:34376,DS-97126ea9-59f1-47cf-bb85-eaa0861b403e,DISK], DatanodeInfoWithStorage[127.0.0.1:37289,DS-3cc10d14-b174-462d-b47f-52bf262e64db,DISK], DatanodeInfoWithStorage[127.0.0.1:34466,DS-b7b43ad5-401b-4353-a535-cd1436b1b2a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45451,DS-714a72c9-6060-47a4-a821-461ab978b46a,DISK], DatanodeInfoWithStorage[127.0.0.1:34573,DS-b257800b-f70b-4310-a1dc-bcaf1bb8701e,DISK], DatanodeInfoWithStorage[127.0.0.1:45083,DS-b37d12e8-2ba1-4c86-975c-ae1336b01fc8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1184513396-172.17.0.8-1595339913623:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43326,DS-e1affa86-ebe3-44ba-b915-80f6085c4b0e,DISK], DatanodeInfoWithStorage[127.0.0.1:44384,DS-5474ffff-e868-43a5-93a9-40b132536453,DISK], DatanodeInfoWithStorage[127.0.0.1:44974,DS-c284e385-4b61-4e5b-8398-0af26a68819a,DISK], DatanodeInfoWithStorage[127.0.0.1:42295,DS-659ce3c9-5631-4f1f-aa14-537564bc3e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:32965,DS-c1b4b6fe-4488-44a0-aa24-c7c273c48d42,DISK], DatanodeInfoWithStorage[127.0.0.1:35681,DS-ca79be9d-2834-420c-ba41-237b1ed43548,DISK], DatanodeInfoWithStorage[127.0.0.1:42176,DS-649c64b2-a693-47f6-8784-0dcc22e53744,DISK], DatanodeInfoWithStorage[127.0.0.1:37364,DS-80e4db4b-b751-4a5e-a8c6-ac4d446624d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1184513396-172.17.0.8-1595339913623:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43326,DS-e1affa86-ebe3-44ba-b915-80f6085c4b0e,DISK], DatanodeInfoWithStorage[127.0.0.1:44384,DS-5474ffff-e868-43a5-93a9-40b132536453,DISK], DatanodeInfoWithStorage[127.0.0.1:44974,DS-c284e385-4b61-4e5b-8398-0af26a68819a,DISK], DatanodeInfoWithStorage[127.0.0.1:42295,DS-659ce3c9-5631-4f1f-aa14-537564bc3e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:32965,DS-c1b4b6fe-4488-44a0-aa24-c7c273c48d42,DISK], DatanodeInfoWithStorage[127.0.0.1:35681,DS-ca79be9d-2834-420c-ba41-237b1ed43548,DISK], DatanodeInfoWithStorage[127.0.0.1:42176,DS-649c64b2-a693-47f6-8784-0dcc22e53744,DISK], DatanodeInfoWithStorage[127.0.0.1:37364,DS-80e4db4b-b751-4a5e-a8c6-ac4d446624d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-484099741-172.17.0.8-1595340224665:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46508,DS-dae1f7f9-4813-48b0-8c48-8124cac190cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33275,DS-e1b2dc89-d3e5-45e5-abd5-0af2647a1520,DISK], DatanodeInfoWithStorage[127.0.0.1:41140,DS-540af6ae-31c4-4761-9970-5a969c70d6b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43874,DS-75b8cacd-f764-4586-8ed1-75f7870f8f41,DISK], DatanodeInfoWithStorage[127.0.0.1:38449,DS-4e7ed17b-f8a2-46af-a404-8981cb35b74d,DISK], DatanodeInfoWithStorage[127.0.0.1:33704,DS-6c14de7d-1433-4a17-ab33-54f7e87cea62,DISK], DatanodeInfoWithStorage[127.0.0.1:40723,DS-5ba0c36a-709e-412f-80bf-4cb8060cfbb3,DISK], DatanodeInfoWithStorage[127.0.0.1:42483,DS-8f186f7c-6800-47c8-a921-7c142e45ca56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-484099741-172.17.0.8-1595340224665:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46508,DS-dae1f7f9-4813-48b0-8c48-8124cac190cf,DISK], DatanodeInfoWithStorage[127.0.0.1:33275,DS-e1b2dc89-d3e5-45e5-abd5-0af2647a1520,DISK], DatanodeInfoWithStorage[127.0.0.1:41140,DS-540af6ae-31c4-4761-9970-5a969c70d6b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43874,DS-75b8cacd-f764-4586-8ed1-75f7870f8f41,DISK], DatanodeInfoWithStorage[127.0.0.1:38449,DS-4e7ed17b-f8a2-46af-a404-8981cb35b74d,DISK], DatanodeInfoWithStorage[127.0.0.1:33704,DS-6c14de7d-1433-4a17-ab33-54f7e87cea62,DISK], DatanodeInfoWithStorage[127.0.0.1:40723,DS-5ba0c36a-709e-412f-80bf-4cb8060cfbb3,DISK], DatanodeInfoWithStorage[127.0.0.1:42483,DS-8f186f7c-6800-47c8-a921-7c142e45ca56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2137078898-172.17.0.8-1595340480623:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45332,DS-f9abd36c-0db1-4d5a-b40f-060ff0eb3264,DISK], DatanodeInfoWithStorage[127.0.0.1:35774,DS-b7f4e47a-50ba-4993-a30c-7ae6fce4c9a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45773,DS-55c87e66-8359-4b0a-b63f-e7c0539d9f55,DISK], DatanodeInfoWithStorage[127.0.0.1:46178,DS-b153361e-67bb-41c1-ad04-8038d9f9b598,DISK], DatanodeInfoWithStorage[127.0.0.1:34377,DS-22cf1dff-d881-4251-ad4c-06c746af0c5a,DISK], DatanodeInfoWithStorage[127.0.0.1:36853,DS-5ad82ef2-5c47-4b3f-b387-79ca07b6e3ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34063,DS-130771d3-f0e0-48c1-a5fc-da90977a720b,DISK], DatanodeInfoWithStorage[127.0.0.1:41910,DS-5aec7722-0ddf-4660-99a9-9f34f7a61efa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2137078898-172.17.0.8-1595340480623:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45332,DS-f9abd36c-0db1-4d5a-b40f-060ff0eb3264,DISK], DatanodeInfoWithStorage[127.0.0.1:35774,DS-b7f4e47a-50ba-4993-a30c-7ae6fce4c9a8,DISK], DatanodeInfoWithStorage[127.0.0.1:45773,DS-55c87e66-8359-4b0a-b63f-e7c0539d9f55,DISK], DatanodeInfoWithStorage[127.0.0.1:46178,DS-b153361e-67bb-41c1-ad04-8038d9f9b598,DISK], DatanodeInfoWithStorage[127.0.0.1:34377,DS-22cf1dff-d881-4251-ad4c-06c746af0c5a,DISK], DatanodeInfoWithStorage[127.0.0.1:36853,DS-5ad82ef2-5c47-4b3f-b387-79ca07b6e3ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34063,DS-130771d3-f0e0-48c1-a5fc-da90977a720b,DISK], DatanodeInfoWithStorage[127.0.0.1:41910,DS-5aec7722-0ddf-4660-99a9-9f34f7a61efa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1167150940-172.17.0.8-1595340635299:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39402,DS-370d29a6-e3d6-45bb-b1fd-18fc7c55b866,DISK], DatanodeInfoWithStorage[127.0.0.1:44361,DS-1b62c328-f0b0-4098-bc72-aef3c56a0a13,DISK], DatanodeInfoWithStorage[127.0.0.1:41319,DS-9427f4a0-c39c-4e9c-af29-16c31fa01302,DISK], DatanodeInfoWithStorage[127.0.0.1:43921,DS-75061fbe-a8d9-4ec7-bda3-d0aeec29b3a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34354,DS-acbbae52-d67b-420b-b1b2-dbbe5cfcdf37,DISK], DatanodeInfoWithStorage[127.0.0.1:37118,DS-c7643409-66f6-4368-8be2-8bbe8494d652,DISK], DatanodeInfoWithStorage[127.0.0.1:36074,DS-dad341a8-6592-4e7c-99e9-1c2341b013c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38516,DS-86bdd491-006c-4996-8a42-93b8721fcf4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1167150940-172.17.0.8-1595340635299:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39402,DS-370d29a6-e3d6-45bb-b1fd-18fc7c55b866,DISK], DatanodeInfoWithStorage[127.0.0.1:44361,DS-1b62c328-f0b0-4098-bc72-aef3c56a0a13,DISK], DatanodeInfoWithStorage[127.0.0.1:41319,DS-9427f4a0-c39c-4e9c-af29-16c31fa01302,DISK], DatanodeInfoWithStorage[127.0.0.1:43921,DS-75061fbe-a8d9-4ec7-bda3-d0aeec29b3a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34354,DS-acbbae52-d67b-420b-b1b2-dbbe5cfcdf37,DISK], DatanodeInfoWithStorage[127.0.0.1:37118,DS-c7643409-66f6-4368-8be2-8bbe8494d652,DISK], DatanodeInfoWithStorage[127.0.0.1:36074,DS-dad341a8-6592-4e7c-99e9-1c2341b013c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38516,DS-86bdd491-006c-4996-8a42-93b8721fcf4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-204189976-172.17.0.8-1595340840153:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42668,DS-c5442b16-23a1-450b-ba7b-dc6e127509ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44129,DS-534e646c-f591-483e-b3d5-35dc125c04bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42203,DS-f6e8d037-452d-42c7-8818-44de52ef6005,DISK], DatanodeInfoWithStorage[127.0.0.1:41213,DS-335c0d0a-4f54-4345-bb27-9249837247be,DISK], DatanodeInfoWithStorage[127.0.0.1:34720,DS-f252aab8-d6e1-4790-8d7a-319afb63c7ff,DISK], DatanodeInfoWithStorage[127.0.0.1:41231,DS-90b6b504-5c42-4330-b0e0-6b62d417ae8b,DISK], DatanodeInfoWithStorage[127.0.0.1:43633,DS-cbe4c46c-eb2b-46e4-b531-e2f6d43af44b,DISK], DatanodeInfoWithStorage[127.0.0.1:34181,DS-e8c241a8-2977-43b0-ae46-349a5638b23a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-204189976-172.17.0.8-1595340840153:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42668,DS-c5442b16-23a1-450b-ba7b-dc6e127509ad,DISK], DatanodeInfoWithStorage[127.0.0.1:44129,DS-534e646c-f591-483e-b3d5-35dc125c04bc,DISK], DatanodeInfoWithStorage[127.0.0.1:42203,DS-f6e8d037-452d-42c7-8818-44de52ef6005,DISK], DatanodeInfoWithStorage[127.0.0.1:41213,DS-335c0d0a-4f54-4345-bb27-9249837247be,DISK], DatanodeInfoWithStorage[127.0.0.1:34720,DS-f252aab8-d6e1-4790-8d7a-319afb63c7ff,DISK], DatanodeInfoWithStorage[127.0.0.1:41231,DS-90b6b504-5c42-4330-b0e0-6b62d417ae8b,DISK], DatanodeInfoWithStorage[127.0.0.1:43633,DS-cbe4c46c-eb2b-46e4-b531-e2f6d43af44b,DISK], DatanodeInfoWithStorage[127.0.0.1:34181,DS-e8c241a8-2977-43b0-ae46-349a5638b23a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1119323046-172.17.0.8-1595341644343:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41308,DS-d620ad4f-7a86-407b-b148-bbc2b5a40eb6,DISK], DatanodeInfoWithStorage[127.0.0.1:36779,DS-ba4e78db-45ff-4001-8d7a-804b7fef278f,DISK], DatanodeInfoWithStorage[127.0.0.1:44059,DS-7e4461e9-d816-49a4-9160-7171a785347a,DISK], DatanodeInfoWithStorage[127.0.0.1:45164,DS-3289a11f-c179-4088-8cff-a79527596cc0,DISK], DatanodeInfoWithStorage[127.0.0.1:45380,DS-a606ab62-8617-44ef-8988-5ca306ed3dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:34995,DS-cb9c7f80-50ea-4cb4-b017-ac0414d29ee4,DISK], DatanodeInfoWithStorage[127.0.0.1:42456,DS-ca41c85e-6f26-4e53-9e72-7686f8b82553,DISK], DatanodeInfoWithStorage[127.0.0.1:39719,DS-4364b1ff-b232-427d-ac37-1dff1735c782,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1119323046-172.17.0.8-1595341644343:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41308,DS-d620ad4f-7a86-407b-b148-bbc2b5a40eb6,DISK], DatanodeInfoWithStorage[127.0.0.1:36779,DS-ba4e78db-45ff-4001-8d7a-804b7fef278f,DISK], DatanodeInfoWithStorage[127.0.0.1:44059,DS-7e4461e9-d816-49a4-9160-7171a785347a,DISK], DatanodeInfoWithStorage[127.0.0.1:45164,DS-3289a11f-c179-4088-8cff-a79527596cc0,DISK], DatanodeInfoWithStorage[127.0.0.1:45380,DS-a606ab62-8617-44ef-8988-5ca306ed3dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:34995,DS-cb9c7f80-50ea-4cb4-b017-ac0414d29ee4,DISK], DatanodeInfoWithStorage[127.0.0.1:42456,DS-ca41c85e-6f26-4e53-9e72-7686f8b82553,DISK], DatanodeInfoWithStorage[127.0.0.1:39719,DS-4364b1ff-b232-427d-ac37-1dff1735c782,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-502280657-172.17.0.8-1595342255428:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43320,DS-6e4bd55b-b8ad-4948-8e81-8af896ade425,DISK], DatanodeInfoWithStorage[127.0.0.1:46508,DS-6d980043-ee75-4c2e-9d68-300122bfaddf,DISK], DatanodeInfoWithStorage[127.0.0.1:41982,DS-8963e60e-84ac-422f-ab19-eb784d632791,DISK], DatanodeInfoWithStorage[127.0.0.1:43062,DS-a596704a-b48e-4b09-995b-021abaeb3e21,DISK], DatanodeInfoWithStorage[127.0.0.1:36814,DS-95219457-be84-4f57-8b29-ed5db78083ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40487,DS-b33281b1-bbe2-40d4-bee9-83d06780fbfd,DISK], DatanodeInfoWithStorage[127.0.0.1:43090,DS-9de323b0-7238-421e-8e3c-172616e478ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39099,DS-2b70481b-5e55-4a9f-b2d6-64048c2953b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-502280657-172.17.0.8-1595342255428:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43320,DS-6e4bd55b-b8ad-4948-8e81-8af896ade425,DISK], DatanodeInfoWithStorage[127.0.0.1:46508,DS-6d980043-ee75-4c2e-9d68-300122bfaddf,DISK], DatanodeInfoWithStorage[127.0.0.1:41982,DS-8963e60e-84ac-422f-ab19-eb784d632791,DISK], DatanodeInfoWithStorage[127.0.0.1:43062,DS-a596704a-b48e-4b09-995b-021abaeb3e21,DISK], DatanodeInfoWithStorage[127.0.0.1:36814,DS-95219457-be84-4f57-8b29-ed5db78083ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40487,DS-b33281b1-bbe2-40d4-bee9-83d06780fbfd,DISK], DatanodeInfoWithStorage[127.0.0.1:43090,DS-9de323b0-7238-421e-8e3c-172616e478ac,DISK], DatanodeInfoWithStorage[127.0.0.1:39099,DS-2b70481b-5e55-4a9f-b2d6-64048c2953b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: false positive !!!
Total execution time in seconds : 5135
