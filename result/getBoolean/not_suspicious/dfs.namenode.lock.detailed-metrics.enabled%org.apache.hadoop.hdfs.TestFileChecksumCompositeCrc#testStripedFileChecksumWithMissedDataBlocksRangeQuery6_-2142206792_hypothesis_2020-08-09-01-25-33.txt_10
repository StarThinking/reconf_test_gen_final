reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-174764505-172.17.0.15-1596936348979:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44403,DS-151bfa3a-2469-4561-bbcd-aa3723848825,DISK], DatanodeInfoWithStorage[127.0.0.1:41099,DS-9b50cc1b-3538-4056-83ab-0855c44c6fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:46740,DS-92516895-5dac-4105-885f-2a9f802c31a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46124,DS-2669d441-680c-4a3a-889e-575fb260300f,DISK], DatanodeInfoWithStorage[127.0.0.1:36645,DS-e69a1eb7-c20c-479d-9a27-df18330ac160,DISK], DatanodeInfoWithStorage[127.0.0.1:37077,DS-9d3ff375-406a-4b93-b522-ae42ea8054d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39479,DS-572e511b-1012-4ae7-8fa4-12436b659cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:45461,DS-a5255249-14e9-4ec3-ad1b-1db483e1948e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-174764505-172.17.0.15-1596936348979:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44403,DS-151bfa3a-2469-4561-bbcd-aa3723848825,DISK], DatanodeInfoWithStorage[127.0.0.1:41099,DS-9b50cc1b-3538-4056-83ab-0855c44c6fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:46740,DS-92516895-5dac-4105-885f-2a9f802c31a7,DISK], DatanodeInfoWithStorage[127.0.0.1:46124,DS-2669d441-680c-4a3a-889e-575fb260300f,DISK], DatanodeInfoWithStorage[127.0.0.1:36645,DS-e69a1eb7-c20c-479d-9a27-df18330ac160,DISK], DatanodeInfoWithStorage[127.0.0.1:37077,DS-9d3ff375-406a-4b93-b522-ae42ea8054d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39479,DS-572e511b-1012-4ae7-8fa4-12436b659cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:45461,DS-a5255249-14e9-4ec3-ad1b-1db483e1948e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1765672219-172.17.0.15-1596936791737:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43548,DS-00718431-43e8-4baa-895c-6e0afe43fb8a,DISK], DatanodeInfoWithStorage[127.0.0.1:38507,DS-6ce8d331-6525-4f39-a1b5-81320c9331ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45486,DS-2566ffc1-cb15-4664-935e-7e2d45af92f1,DISK], DatanodeInfoWithStorage[127.0.0.1:45204,DS-cc5e0b47-051e-4afe-8981-4c255cba80f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43180,DS-34be8cb1-92bb-4ea0-8745-207d9096f6b3,DISK], DatanodeInfoWithStorage[127.0.0.1:32948,DS-66f8f1c6-ddba-41af-a449-db9bc5c0e1ff,DISK], DatanodeInfoWithStorage[127.0.0.1:46818,DS-d9952c01-a9d7-45da-ae5f-53ac6d308e19,DISK], DatanodeInfoWithStorage[127.0.0.1:46205,DS-03353300-1d7e-4f2d-a0e7-aef3f61fc74a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1765672219-172.17.0.15-1596936791737:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43548,DS-00718431-43e8-4baa-895c-6e0afe43fb8a,DISK], DatanodeInfoWithStorage[127.0.0.1:38507,DS-6ce8d331-6525-4f39-a1b5-81320c9331ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45486,DS-2566ffc1-cb15-4664-935e-7e2d45af92f1,DISK], DatanodeInfoWithStorage[127.0.0.1:45204,DS-cc5e0b47-051e-4afe-8981-4c255cba80f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43180,DS-34be8cb1-92bb-4ea0-8745-207d9096f6b3,DISK], DatanodeInfoWithStorage[127.0.0.1:32948,DS-66f8f1c6-ddba-41af-a449-db9bc5c0e1ff,DISK], DatanodeInfoWithStorage[127.0.0.1:46818,DS-d9952c01-a9d7-45da-ae5f-53ac6d308e19,DISK], DatanodeInfoWithStorage[127.0.0.1:46205,DS-03353300-1d7e-4f2d-a0e7-aef3f61fc74a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2015960347-172.17.0.15-1596936864559:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45462,DS-6291d954-e778-4b29-a0f9-ce73215ab8c8,DISK], DatanodeInfoWithStorage[127.0.0.1:41737,DS-8fbb3bcf-e99f-4437-a116-97057ad4a083,DISK], DatanodeInfoWithStorage[127.0.0.1:33180,DS-a7c479d0-1db0-4fcc-8742-c2c0b79a187b,DISK], DatanodeInfoWithStorage[127.0.0.1:35063,DS-93c2fa35-9e9d-4973-85fe-b89222623791,DISK], DatanodeInfoWithStorage[127.0.0.1:46506,DS-44caab14-f2c7-4afe-a4c9-9fe9d1fdeac0,DISK], DatanodeInfoWithStorage[127.0.0.1:44633,DS-1cb65181-d6a8-4204-8593-f7476aff7b1c,DISK], DatanodeInfoWithStorage[127.0.0.1:44947,DS-1de008a8-e10d-404e-bbdb-bb215933a0ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44532,DS-a0fcd139-3e27-4081-8576-73b8ffba5421,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2015960347-172.17.0.15-1596936864559:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45462,DS-6291d954-e778-4b29-a0f9-ce73215ab8c8,DISK], DatanodeInfoWithStorage[127.0.0.1:41737,DS-8fbb3bcf-e99f-4437-a116-97057ad4a083,DISK], DatanodeInfoWithStorage[127.0.0.1:33180,DS-a7c479d0-1db0-4fcc-8742-c2c0b79a187b,DISK], DatanodeInfoWithStorage[127.0.0.1:35063,DS-93c2fa35-9e9d-4973-85fe-b89222623791,DISK], DatanodeInfoWithStorage[127.0.0.1:46506,DS-44caab14-f2c7-4afe-a4c9-9fe9d1fdeac0,DISK], DatanodeInfoWithStorage[127.0.0.1:44633,DS-1cb65181-d6a8-4204-8593-f7476aff7b1c,DISK], DatanodeInfoWithStorage[127.0.0.1:44947,DS-1de008a8-e10d-404e-bbdb-bb215933a0ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44532,DS-a0fcd139-3e27-4081-8576-73b8ffba5421,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-234685470-172.17.0.15-1596937198207:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33543,DS-5592bd9f-528b-44b1-9ee5-2fe6e02ddd86,DISK], DatanodeInfoWithStorage[127.0.0.1:46412,DS-eb1dbc14-0b23-42f0-ac42-52f219bf9a45,DISK], DatanodeInfoWithStorage[127.0.0.1:36592,DS-f0193f9d-0592-4329-a302-708933c2db3e,DISK], DatanodeInfoWithStorage[127.0.0.1:46299,DS-2ad58242-c4ae-4792-9a76-f410926333eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33195,DS-06661b0e-8d83-4c41-b527-ef2377dec457,DISK], DatanodeInfoWithStorage[127.0.0.1:38620,DS-4cee4033-d321-447c-960a-3b5d03b0bbd0,DISK], DatanodeInfoWithStorage[127.0.0.1:44569,DS-296aff10-bcac-43f3-a1c8-989b041902f4,DISK], DatanodeInfoWithStorage[127.0.0.1:42009,DS-a66fac61-cdae-4ebd-8611-3a188d911cca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-234685470-172.17.0.15-1596937198207:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33543,DS-5592bd9f-528b-44b1-9ee5-2fe6e02ddd86,DISK], DatanodeInfoWithStorage[127.0.0.1:46412,DS-eb1dbc14-0b23-42f0-ac42-52f219bf9a45,DISK], DatanodeInfoWithStorage[127.0.0.1:36592,DS-f0193f9d-0592-4329-a302-708933c2db3e,DISK], DatanodeInfoWithStorage[127.0.0.1:46299,DS-2ad58242-c4ae-4792-9a76-f410926333eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33195,DS-06661b0e-8d83-4c41-b527-ef2377dec457,DISK], DatanodeInfoWithStorage[127.0.0.1:38620,DS-4cee4033-d321-447c-960a-3b5d03b0bbd0,DISK], DatanodeInfoWithStorage[127.0.0.1:44569,DS-296aff10-bcac-43f3-a1c8-989b041902f4,DISK], DatanodeInfoWithStorage[127.0.0.1:42009,DS-a66fac61-cdae-4ebd-8611-3a188d911cca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-876775063-172.17.0.15-1596937584411:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39784,DS-a12ca2f5-01b0-4c4f-8201-270e9d38ec78,DISK], DatanodeInfoWithStorage[127.0.0.1:45544,DS-fd50bef8-27d6-48a1-afdc-657750228b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:45219,DS-bdadb174-8208-4f3f-bb79-0af875595ac3,DISK], DatanodeInfoWithStorage[127.0.0.1:36790,DS-0335ac51-3f29-4c2c-8851-2bfb2dacf44b,DISK], DatanodeInfoWithStorage[127.0.0.1:45891,DS-83ee03fb-46db-4b39-8832-444bdd45baa0,DISK], DatanodeInfoWithStorage[127.0.0.1:36424,DS-6d70a354-aa16-4549-baed-449cf4ffd900,DISK], DatanodeInfoWithStorage[127.0.0.1:35199,DS-98a1b0af-6ce8-4493-8dbe-cc498c3da4b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43974,DS-bed58409-0c74-4212-8a23-a126f6446f6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-876775063-172.17.0.15-1596937584411:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39784,DS-a12ca2f5-01b0-4c4f-8201-270e9d38ec78,DISK], DatanodeInfoWithStorage[127.0.0.1:45544,DS-fd50bef8-27d6-48a1-afdc-657750228b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:45219,DS-bdadb174-8208-4f3f-bb79-0af875595ac3,DISK], DatanodeInfoWithStorage[127.0.0.1:36790,DS-0335ac51-3f29-4c2c-8851-2bfb2dacf44b,DISK], DatanodeInfoWithStorage[127.0.0.1:45891,DS-83ee03fb-46db-4b39-8832-444bdd45baa0,DISK], DatanodeInfoWithStorage[127.0.0.1:36424,DS-6d70a354-aa16-4549-baed-449cf4ffd900,DISK], DatanodeInfoWithStorage[127.0.0.1:35199,DS-98a1b0af-6ce8-4493-8dbe-cc498c3da4b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43974,DS-bed58409-0c74-4212-8a23-a126f6446f6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-635180239-172.17.0.15-1596937651760:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43062,DS-c5cde936-d7b7-4c9f-9100-b94cefcdc393,DISK], DatanodeInfoWithStorage[127.0.0.1:43106,DS-4b167356-d9ef-4a40-aedc-23feb3921a60,DISK], DatanodeInfoWithStorage[127.0.0.1:43477,DS-3bccb2ff-845a-4b5e-a060-e90f514fe91e,DISK], DatanodeInfoWithStorage[127.0.0.1:41772,DS-3469d119-d4d3-4cfe-94b1-82d5ee14276e,DISK], DatanodeInfoWithStorage[127.0.0.1:33524,DS-7a6ff635-b0d3-470c-a903-6a518a0a2eb0,DISK], DatanodeInfoWithStorage[127.0.0.1:36760,DS-987ce7cc-68e5-4e2d-9229-71e785537b26,DISK], DatanodeInfoWithStorage[127.0.0.1:37035,DS-c5c0e876-2692-473f-848a-0e818daa9ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:45271,DS-22a70287-8d2d-44ea-9e75-8a6e18e78ad4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-635180239-172.17.0.15-1596937651760:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43062,DS-c5cde936-d7b7-4c9f-9100-b94cefcdc393,DISK], DatanodeInfoWithStorage[127.0.0.1:43106,DS-4b167356-d9ef-4a40-aedc-23feb3921a60,DISK], DatanodeInfoWithStorage[127.0.0.1:43477,DS-3bccb2ff-845a-4b5e-a060-e90f514fe91e,DISK], DatanodeInfoWithStorage[127.0.0.1:41772,DS-3469d119-d4d3-4cfe-94b1-82d5ee14276e,DISK], DatanodeInfoWithStorage[127.0.0.1:33524,DS-7a6ff635-b0d3-470c-a903-6a518a0a2eb0,DISK], DatanodeInfoWithStorage[127.0.0.1:36760,DS-987ce7cc-68e5-4e2d-9229-71e785537b26,DISK], DatanodeInfoWithStorage[127.0.0.1:37035,DS-c5c0e876-2692-473f-848a-0e818daa9ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:45271,DS-22a70287-8d2d-44ea-9e75-8a6e18e78ad4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-564205192-172.17.0.15-1596937812100:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33708,DS-f5d1dad6-e87c-4433-b478-a1eddbdbd052,DISK], DatanodeInfoWithStorage[127.0.0.1:36848,DS-30b9830a-838b-4062-ba17-db7603085f15,DISK], DatanodeInfoWithStorage[127.0.0.1:41621,DS-0adefb9a-f819-4462-be87-8e79a9f7be68,DISK], DatanodeInfoWithStorage[127.0.0.1:37501,DS-28267177-2ba8-43d3-b3af-4a1fc44fc169,DISK], DatanodeInfoWithStorage[127.0.0.1:44198,DS-a42fceac-46d2-4c6a-bb37-ea53e006d12c,DISK], DatanodeInfoWithStorage[127.0.0.1:45221,DS-2dd1d597-09c2-48e6-9ba4-e12a3a5a8cde,DISK], DatanodeInfoWithStorage[127.0.0.1:37244,DS-884a8f93-5450-41d9-acc6-507ba9c4c17b,DISK], DatanodeInfoWithStorage[127.0.0.1:45113,DS-42654aa1-f424-4d87-abb6-f9552837c1bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-564205192-172.17.0.15-1596937812100:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33708,DS-f5d1dad6-e87c-4433-b478-a1eddbdbd052,DISK], DatanodeInfoWithStorage[127.0.0.1:36848,DS-30b9830a-838b-4062-ba17-db7603085f15,DISK], DatanodeInfoWithStorage[127.0.0.1:41621,DS-0adefb9a-f819-4462-be87-8e79a9f7be68,DISK], DatanodeInfoWithStorage[127.0.0.1:37501,DS-28267177-2ba8-43d3-b3af-4a1fc44fc169,DISK], DatanodeInfoWithStorage[127.0.0.1:44198,DS-a42fceac-46d2-4c6a-bb37-ea53e006d12c,DISK], DatanodeInfoWithStorage[127.0.0.1:45221,DS-2dd1d597-09c2-48e6-9ba4-e12a3a5a8cde,DISK], DatanodeInfoWithStorage[127.0.0.1:37244,DS-884a8f93-5450-41d9-acc6-507ba9c4c17b,DISK], DatanodeInfoWithStorage[127.0.0.1:45113,DS-42654aa1-f424-4d87-abb6-f9552837c1bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-516740829-172.17.0.15-1596937908235:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39569,DS-aea4ce07-4c78-417a-b2f2-6db0da63712f,DISK], DatanodeInfoWithStorage[127.0.0.1:43673,DS-51a393a7-1060-40dc-9461-251ab6172bc4,DISK], DatanodeInfoWithStorage[127.0.0.1:41456,DS-f183b3c7-52f6-4a81-97c3-e7ccf1e8d1e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43292,DS-b7297bf8-e7ab-4022-876e-6845aaf5aa85,DISK], DatanodeInfoWithStorage[127.0.0.1:38524,DS-9935eec4-2752-4ca0-8b03-a37b94fd1b98,DISK], DatanodeInfoWithStorage[127.0.0.1:46438,DS-771d93bb-2927-46ac-9c8c-c9b6049c6dc5,DISK], DatanodeInfoWithStorage[127.0.0.1:44067,DS-e8b84233-f3f3-4cc7-bf22-c5319c4b8cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:36958,DS-6bb50d70-b9c9-45d0-b3ab-c33afe1d4bc0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-516740829-172.17.0.15-1596937908235:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39569,DS-aea4ce07-4c78-417a-b2f2-6db0da63712f,DISK], DatanodeInfoWithStorage[127.0.0.1:43673,DS-51a393a7-1060-40dc-9461-251ab6172bc4,DISK], DatanodeInfoWithStorage[127.0.0.1:41456,DS-f183b3c7-52f6-4a81-97c3-e7ccf1e8d1e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43292,DS-b7297bf8-e7ab-4022-876e-6845aaf5aa85,DISK], DatanodeInfoWithStorage[127.0.0.1:38524,DS-9935eec4-2752-4ca0-8b03-a37b94fd1b98,DISK], DatanodeInfoWithStorage[127.0.0.1:46438,DS-771d93bb-2927-46ac-9c8c-c9b6049c6dc5,DISK], DatanodeInfoWithStorage[127.0.0.1:44067,DS-e8b84233-f3f3-4cc7-bf22-c5319c4b8cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:36958,DS-6bb50d70-b9c9-45d0-b3ab-c33afe1d4bc0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-111549050-172.17.0.15-1596938045318:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34938,DS-820129f1-d772-4877-b6e6-75fee09e52da,DISK], DatanodeInfoWithStorage[127.0.0.1:40017,DS-2f71cb2f-7aaf-4839-975f-597450a7fc3a,DISK], DatanodeInfoWithStorage[127.0.0.1:45227,DS-5c8db6ec-6e4c-4331-b524-01e57b887759,DISK], DatanodeInfoWithStorage[127.0.0.1:33264,DS-ae5adb4c-8c60-4e16-afb4-db085cb1cf4c,DISK], DatanodeInfoWithStorage[127.0.0.1:41717,DS-051a8587-d269-4420-9573-3da2ade519cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43530,DS-708c52e7-d94b-47a1-96f8-f03ab1e66a07,DISK], DatanodeInfoWithStorage[127.0.0.1:44977,DS-b9bbaddf-5bff-4062-b08f-f8704c599516,DISK], DatanodeInfoWithStorage[127.0.0.1:39286,DS-1b6c2012-cfc6-4ad1-ab8e-2d9dfcada614,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-111549050-172.17.0.15-1596938045318:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34938,DS-820129f1-d772-4877-b6e6-75fee09e52da,DISK], DatanodeInfoWithStorage[127.0.0.1:40017,DS-2f71cb2f-7aaf-4839-975f-597450a7fc3a,DISK], DatanodeInfoWithStorage[127.0.0.1:45227,DS-5c8db6ec-6e4c-4331-b524-01e57b887759,DISK], DatanodeInfoWithStorage[127.0.0.1:33264,DS-ae5adb4c-8c60-4e16-afb4-db085cb1cf4c,DISK], DatanodeInfoWithStorage[127.0.0.1:41717,DS-051a8587-d269-4420-9573-3da2ade519cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43530,DS-708c52e7-d94b-47a1-96f8-f03ab1e66a07,DISK], DatanodeInfoWithStorage[127.0.0.1:44977,DS-b9bbaddf-5bff-4062-b08f-f8704c599516,DISK], DatanodeInfoWithStorage[127.0.0.1:39286,DS-1b6c2012-cfc6-4ad1-ab8e-2d9dfcada614,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1315325602-172.17.0.15-1596938360265:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46459,DS-2e8ead12-928a-4c3a-86e3-7c722815d94c,DISK], DatanodeInfoWithStorage[127.0.0.1:36494,DS-6b387a25-1dde-43e3-a2a4-e340cf14fc39,DISK], DatanodeInfoWithStorage[127.0.0.1:37849,DS-d371afc7-a6ba-4819-84aa-0c6ee886a2de,DISK], DatanodeInfoWithStorage[127.0.0.1:46595,DS-14e71b6a-bb91-490f-88e5-7bd90b490fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:38229,DS-2a6971b8-6adb-4f4d-8ff3-888dbddd3826,DISK], DatanodeInfoWithStorage[127.0.0.1:41725,DS-f74f27dc-fc81-45e9-b159-d204f9b174f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41203,DS-f445d960-e3f4-4329-bb5d-cdf5a2221cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:41432,DS-67bc9990-403c-4809-b973-340e7078cb3c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1315325602-172.17.0.15-1596938360265:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46459,DS-2e8ead12-928a-4c3a-86e3-7c722815d94c,DISK], DatanodeInfoWithStorage[127.0.0.1:36494,DS-6b387a25-1dde-43e3-a2a4-e340cf14fc39,DISK], DatanodeInfoWithStorage[127.0.0.1:37849,DS-d371afc7-a6ba-4819-84aa-0c6ee886a2de,DISK], DatanodeInfoWithStorage[127.0.0.1:46595,DS-14e71b6a-bb91-490f-88e5-7bd90b490fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:38229,DS-2a6971b8-6adb-4f4d-8ff3-888dbddd3826,DISK], DatanodeInfoWithStorage[127.0.0.1:41725,DS-f74f27dc-fc81-45e9-b159-d204f9b174f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41203,DS-f445d960-e3f4-4329-bb5d-cdf5a2221cf1,DISK], DatanodeInfoWithStorage[127.0.0.1:41432,DS-67bc9990-403c-4809-b973-340e7078cb3c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-173142489-172.17.0.15-1596938518097:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37827,DS-847a066b-be69-488f-a900-200ade3cea02,DISK], DatanodeInfoWithStorage[127.0.0.1:40983,DS-bda3b10d-ac98-4c1f-b16d-cc9a2590ed45,DISK], DatanodeInfoWithStorage[127.0.0.1:36084,DS-2c4aa722-06a0-4a8d-9da3-d4c1d2005e95,DISK], DatanodeInfoWithStorage[127.0.0.1:36882,DS-496eb63b-9d32-48d5-8556-c4ea550766c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37167,DS-9bd2a2aa-92a8-49d7-838c-34724d41e68b,DISK], DatanodeInfoWithStorage[127.0.0.1:36405,DS-95c1b5a2-5609-4850-bef3-d4a22ea6be40,DISK], DatanodeInfoWithStorage[127.0.0.1:38183,DS-2d6896eb-0076-43ab-afc9-f056b0f9266e,DISK], DatanodeInfoWithStorage[127.0.0.1:33178,DS-de8a3c33-26b8-4cf7-ae6f-ce0fc55a7031,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-173142489-172.17.0.15-1596938518097:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37827,DS-847a066b-be69-488f-a900-200ade3cea02,DISK], DatanodeInfoWithStorage[127.0.0.1:40983,DS-bda3b10d-ac98-4c1f-b16d-cc9a2590ed45,DISK], DatanodeInfoWithStorage[127.0.0.1:36084,DS-2c4aa722-06a0-4a8d-9da3-d4c1d2005e95,DISK], DatanodeInfoWithStorage[127.0.0.1:36882,DS-496eb63b-9d32-48d5-8556-c4ea550766c6,DISK], DatanodeInfoWithStorage[127.0.0.1:37167,DS-9bd2a2aa-92a8-49d7-838c-34724d41e68b,DISK], DatanodeInfoWithStorage[127.0.0.1:36405,DS-95c1b5a2-5609-4850-bef3-d4a22ea6be40,DISK], DatanodeInfoWithStorage[127.0.0.1:38183,DS-2d6896eb-0076-43ab-afc9-f056b0f9266e,DISK], DatanodeInfoWithStorage[127.0.0.1:33178,DS-de8a3c33-26b8-4cf7-ae6f-ce0fc55a7031,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1395389300-172.17.0.15-1596938583576:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45547,DS-61af7b1c-01f1-441f-9a56-04cfc0cafa81,DISK], DatanodeInfoWithStorage[127.0.0.1:41747,DS-865d4edc-c0a0-4041-87be-fadac2715aca,DISK], DatanodeInfoWithStorage[127.0.0.1:34428,DS-3ff67cab-5313-4449-8067-87cc04d7ad76,DISK], DatanodeInfoWithStorage[127.0.0.1:36254,DS-896dc324-f734-490f-8b3b-d74b9ec01e41,DISK], DatanodeInfoWithStorage[127.0.0.1:41613,DS-45e4066a-2111-4e33-b222-4c061cea0d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:37982,DS-0b9111b1-3665-4f7d-a332-e66d06948eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:42822,DS-c580232a-fb1f-429f-89c6-527d1ab21430,DISK], DatanodeInfoWithStorage[127.0.0.1:34150,DS-b0ea7328-8e27-4e60-b9be-cbd1b133e876,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1395389300-172.17.0.15-1596938583576:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45547,DS-61af7b1c-01f1-441f-9a56-04cfc0cafa81,DISK], DatanodeInfoWithStorage[127.0.0.1:41747,DS-865d4edc-c0a0-4041-87be-fadac2715aca,DISK], DatanodeInfoWithStorage[127.0.0.1:34428,DS-3ff67cab-5313-4449-8067-87cc04d7ad76,DISK], DatanodeInfoWithStorage[127.0.0.1:36254,DS-896dc324-f734-490f-8b3b-d74b9ec01e41,DISK], DatanodeInfoWithStorage[127.0.0.1:41613,DS-45e4066a-2111-4e33-b222-4c061cea0d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:37982,DS-0b9111b1-3665-4f7d-a332-e66d06948eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:42822,DS-c580232a-fb1f-429f-89c6-527d1ab21430,DISK], DatanodeInfoWithStorage[127.0.0.1:34150,DS-b0ea7328-8e27-4e60-b9be-cbd1b133e876,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1061802839-172.17.0.15-1596938688934:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35125,DS-1a6c3e47-2bb3-4faf-8639-f3d64bee0159,DISK], DatanodeInfoWithStorage[127.0.0.1:37109,DS-bb231249-80ae-4dad-9b6e-bf541ff1d8b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37550,DS-3a8ada24-8ace-49c2-9d5f-08c85f962c57,DISK], DatanodeInfoWithStorage[127.0.0.1:37672,DS-b0909207-b18a-4a7c-a92e-c872000659b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45620,DS-04c3610c-e802-403a-8044-50abe408f285,DISK], DatanodeInfoWithStorage[127.0.0.1:43029,DS-2e938ad9-a8d5-494b-bb84-d36ddbb081c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41406,DS-c9b8c5c0-3c8f-43a9-8e7d-b3b3d96a2af4,DISK], DatanodeInfoWithStorage[127.0.0.1:33636,DS-f467d7bd-ceea-4754-b916-3cb3e507b230,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1061802839-172.17.0.15-1596938688934:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35125,DS-1a6c3e47-2bb3-4faf-8639-f3d64bee0159,DISK], DatanodeInfoWithStorage[127.0.0.1:37109,DS-bb231249-80ae-4dad-9b6e-bf541ff1d8b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37550,DS-3a8ada24-8ace-49c2-9d5f-08c85f962c57,DISK], DatanodeInfoWithStorage[127.0.0.1:37672,DS-b0909207-b18a-4a7c-a92e-c872000659b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45620,DS-04c3610c-e802-403a-8044-50abe408f285,DISK], DatanodeInfoWithStorage[127.0.0.1:43029,DS-2e938ad9-a8d5-494b-bb84-d36ddbb081c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41406,DS-c9b8c5c0-3c8f-43a9-8e7d-b3b3d96a2af4,DISK], DatanodeInfoWithStorage[127.0.0.1:33636,DS-f467d7bd-ceea-4754-b916-3cb3e507b230,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1316363871-172.17.0.15-1596938911612:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33019,DS-fb9f9ac0-2113-4085-a3ad-7803bef8b199,DISK], DatanodeInfoWithStorage[127.0.0.1:37328,DS-f6a0ed8a-6366-4cce-b3b1-756208749185,DISK], DatanodeInfoWithStorage[127.0.0.1:41453,DS-547f7a7b-f9cf-4ee4-8d74-55feebce3f10,DISK], DatanodeInfoWithStorage[127.0.0.1:38038,DS-45dfc578-a58d-4915-beb4-8fd039426d00,DISK], DatanodeInfoWithStorage[127.0.0.1:40494,DS-28d5388c-2c4a-4279-ae02-03e2277891a6,DISK], DatanodeInfoWithStorage[127.0.0.1:43882,DS-acb9499e-467b-4df3-9521-f49464db86e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37492,DS-e64043bc-3d1f-419e-9b11-7fef17a7e46b,DISK], DatanodeInfoWithStorage[127.0.0.1:39314,DS-23371528-4669-4235-b923-aa96e5ab6a03,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1316363871-172.17.0.15-1596938911612:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33019,DS-fb9f9ac0-2113-4085-a3ad-7803bef8b199,DISK], DatanodeInfoWithStorage[127.0.0.1:37328,DS-f6a0ed8a-6366-4cce-b3b1-756208749185,DISK], DatanodeInfoWithStorage[127.0.0.1:41453,DS-547f7a7b-f9cf-4ee4-8d74-55feebce3f10,DISK], DatanodeInfoWithStorage[127.0.0.1:38038,DS-45dfc578-a58d-4915-beb4-8fd039426d00,DISK], DatanodeInfoWithStorage[127.0.0.1:40494,DS-28d5388c-2c4a-4279-ae02-03e2277891a6,DISK], DatanodeInfoWithStorage[127.0.0.1:43882,DS-acb9499e-467b-4df3-9521-f49464db86e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37492,DS-e64043bc-3d1f-419e-9b11-7fef17a7e46b,DISK], DatanodeInfoWithStorage[127.0.0.1:39314,DS-23371528-4669-4235-b923-aa96e5ab6a03,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1778059500-172.17.0.15-1596939045251:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38757,DS-28d767e9-1918-493b-9f93-1f3e6c84f52d,DISK], DatanodeInfoWithStorage[127.0.0.1:42894,DS-8fbba5c2-c086-4485-af14-53fcfefba0a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38654,DS-0685bf31-cdf4-4acd-8f68-2e8b273975b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33502,DS-e667f017-1035-400e-a7b6-e31205a0f0e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42160,DS-669f5687-4677-40d1-b115-1c6b6b71d0e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41686,DS-1bb72fc0-de73-4854-a6a3-abc410719bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:41460,DS-5d8b0078-17fa-4f15-bd24-8203a7cae005,DISK], DatanodeInfoWithStorage[127.0.0.1:37474,DS-7a805cc6-035f-4368-b422-5fa68fe51a51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1778059500-172.17.0.15-1596939045251:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38757,DS-28d767e9-1918-493b-9f93-1f3e6c84f52d,DISK], DatanodeInfoWithStorage[127.0.0.1:42894,DS-8fbba5c2-c086-4485-af14-53fcfefba0a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38654,DS-0685bf31-cdf4-4acd-8f68-2e8b273975b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33502,DS-e667f017-1035-400e-a7b6-e31205a0f0e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42160,DS-669f5687-4677-40d1-b115-1c6b6b71d0e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41686,DS-1bb72fc0-de73-4854-a6a3-abc410719bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:41460,DS-5d8b0078-17fa-4f15-bd24-8203a7cae005,DISK], DatanodeInfoWithStorage[127.0.0.1:37474,DS-7a805cc6-035f-4368-b422-5fa68fe51a51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-960524252-172.17.0.15-1596939073536:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45402,DS-d52555a2-6797-4dc0-a3de-c7c0a2792448,DISK], DatanodeInfoWithStorage[127.0.0.1:45743,DS-3027fcb9-caff-4194-a087-80c8d32d2026,DISK], DatanodeInfoWithStorage[127.0.0.1:35454,DS-2026b33f-ce14-4cef-87c9-cb4376ef7374,DISK], DatanodeInfoWithStorage[127.0.0.1:41612,DS-b26e2b0d-cedc-4a15-80c9-0265c79a5ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:36397,DS-a783be0c-87e7-4a36-a06a-6fe6e0019fa7,DISK], DatanodeInfoWithStorage[127.0.0.1:41118,DS-43d66db1-ece7-490f-b9d0-e1d974a24681,DISK], DatanodeInfoWithStorage[127.0.0.1:46213,DS-ebb493eb-264b-437c-a451-e2b5ae2f23b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41588,DS-3db77227-c6e7-4dd3-8827-cbc197870cd5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-960524252-172.17.0.15-1596939073536:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45402,DS-d52555a2-6797-4dc0-a3de-c7c0a2792448,DISK], DatanodeInfoWithStorage[127.0.0.1:45743,DS-3027fcb9-caff-4194-a087-80c8d32d2026,DISK], DatanodeInfoWithStorage[127.0.0.1:35454,DS-2026b33f-ce14-4cef-87c9-cb4376ef7374,DISK], DatanodeInfoWithStorage[127.0.0.1:41612,DS-b26e2b0d-cedc-4a15-80c9-0265c79a5ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:36397,DS-a783be0c-87e7-4a36-a06a-6fe6e0019fa7,DISK], DatanodeInfoWithStorage[127.0.0.1:41118,DS-43d66db1-ece7-490f-b9d0-e1d974a24681,DISK], DatanodeInfoWithStorage[127.0.0.1:46213,DS-ebb493eb-264b-437c-a451-e2b5ae2f23b9,DISK], DatanodeInfoWithStorage[127.0.0.1:41588,DS-3db77227-c6e7-4dd3-8827-cbc197870cd5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-622667526-172.17.0.15-1596939104776:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41862,DS-6e59d18b-4d39-4d41-82e4-c48b64c48740,DISK], DatanodeInfoWithStorage[127.0.0.1:34041,DS-997d296e-6983-4878-9c3c-38da1b348ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:43247,DS-0dfe59aa-30c1-4018-bdbc-32b31f2dc571,DISK], DatanodeInfoWithStorage[127.0.0.1:43278,DS-09d42935-886a-484f-8b42-c2d25e1730dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33724,DS-71250298-d65e-46a9-a1e4-1baca89d01fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34778,DS-464bea84-7759-4fdb-9c2a-b4f6edc3f464,DISK], DatanodeInfoWithStorage[127.0.0.1:38758,DS-b2d647db-63dc-4fe3-a4e7-eb111d3eea4d,DISK], DatanodeInfoWithStorage[127.0.0.1:39968,DS-59c8ff25-aadb-428b-82df-e09fb18c09e7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-622667526-172.17.0.15-1596939104776:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41862,DS-6e59d18b-4d39-4d41-82e4-c48b64c48740,DISK], DatanodeInfoWithStorage[127.0.0.1:34041,DS-997d296e-6983-4878-9c3c-38da1b348ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:43247,DS-0dfe59aa-30c1-4018-bdbc-32b31f2dc571,DISK], DatanodeInfoWithStorage[127.0.0.1:43278,DS-09d42935-886a-484f-8b42-c2d25e1730dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33724,DS-71250298-d65e-46a9-a1e4-1baca89d01fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34778,DS-464bea84-7759-4fdb-9c2a-b4f6edc3f464,DISK], DatanodeInfoWithStorage[127.0.0.1:38758,DS-b2d647db-63dc-4fe3-a4e7-eb111d3eea4d,DISK], DatanodeInfoWithStorage[127.0.0.1:39968,DS-59c8ff25-aadb-428b-82df-e09fb18c09e7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-576955364-172.17.0.15-1596939212750:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37386,DS-464ecab5-3bc5-41df-909e-c8c6e38b97b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33234,DS-41e6d895-3b4f-4fca-adfe-d942c56ca6a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34754,DS-254c1a9d-bbc3-49e5-9b0e-f959c158d044,DISK], DatanodeInfoWithStorage[127.0.0.1:41164,DS-1839f071-e407-470b-8c99-aa2fbc2bd728,DISK], DatanodeInfoWithStorage[127.0.0.1:45077,DS-7775ecc5-0a3e-4bbb-95f5-8ae216cae8cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35701,DS-ad89d0fb-428e-4ded-8a69-f656e5f268b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44672,DS-70c245d0-2d01-4408-88e6-7533fb0500fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45920,DS-3fbe74c7-a953-4f82-aaea-35e540b57021,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-576955364-172.17.0.15-1596939212750:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37386,DS-464ecab5-3bc5-41df-909e-c8c6e38b97b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33234,DS-41e6d895-3b4f-4fca-adfe-d942c56ca6a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34754,DS-254c1a9d-bbc3-49e5-9b0e-f959c158d044,DISK], DatanodeInfoWithStorage[127.0.0.1:41164,DS-1839f071-e407-470b-8c99-aa2fbc2bd728,DISK], DatanodeInfoWithStorage[127.0.0.1:45077,DS-7775ecc5-0a3e-4bbb-95f5-8ae216cae8cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35701,DS-ad89d0fb-428e-4ded-8a69-f656e5f268b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44672,DS-70c245d0-2d01-4408-88e6-7533fb0500fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45920,DS-3fbe74c7-a953-4f82-aaea-35e540b57021,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1537693840-172.17.0.15-1596939271248:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40984,DS-95070f5b-3d2c-41fd-8009-0b34e6229128,DISK], DatanodeInfoWithStorage[127.0.0.1:34577,DS-48f032af-6671-487f-b3df-e6d88222d765,DISK], DatanodeInfoWithStorage[127.0.0.1:37378,DS-75501fca-7002-4589-a4ea-914ea0ba4b65,DISK], DatanodeInfoWithStorage[127.0.0.1:36295,DS-98cf65bf-76d6-4dff-8b75-34ec5c7a2057,DISK], DatanodeInfoWithStorage[127.0.0.1:36592,DS-80714aef-b4be-4706-8582-fb7cf3939625,DISK], DatanodeInfoWithStorage[127.0.0.1:46620,DS-85d6076b-998a-4b45-8e6a-76b4a977813c,DISK], DatanodeInfoWithStorage[127.0.0.1:37964,DS-8a7270c3-6b30-4a03-beb6-1aeefccad915,DISK], DatanodeInfoWithStorage[127.0.0.1:41387,DS-7f383ff6-9230-45ed-8e45-50a647d45365,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1537693840-172.17.0.15-1596939271248:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40984,DS-95070f5b-3d2c-41fd-8009-0b34e6229128,DISK], DatanodeInfoWithStorage[127.0.0.1:34577,DS-48f032af-6671-487f-b3df-e6d88222d765,DISK], DatanodeInfoWithStorage[127.0.0.1:37378,DS-75501fca-7002-4589-a4ea-914ea0ba4b65,DISK], DatanodeInfoWithStorage[127.0.0.1:36295,DS-98cf65bf-76d6-4dff-8b75-34ec5c7a2057,DISK], DatanodeInfoWithStorage[127.0.0.1:36592,DS-80714aef-b4be-4706-8582-fb7cf3939625,DISK], DatanodeInfoWithStorage[127.0.0.1:46620,DS-85d6076b-998a-4b45-8e6a-76b4a977813c,DISK], DatanodeInfoWithStorage[127.0.0.1:37964,DS-8a7270c3-6b30-4a03-beb6-1aeefccad915,DISK], DatanodeInfoWithStorage[127.0.0.1:41387,DS-7f383ff6-9230-45ed-8e45-50a647d45365,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-556180224-172.17.0.15-1596940027126:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39722,DS-02ef5826-a2b6-45d7-a200-91b84029a90b,DISK], DatanodeInfoWithStorage[127.0.0.1:40728,DS-1341bc7d-0634-4249-ab70-e974eb10b76c,DISK], DatanodeInfoWithStorage[127.0.0.1:40549,DS-4541671a-18cd-4e9c-a5c0-c24b157eefd5,DISK], DatanodeInfoWithStorage[127.0.0.1:44094,DS-8c1b1b3f-e233-4a55-85ee-beaac3ef41e8,DISK], DatanodeInfoWithStorage[127.0.0.1:46769,DS-25304b98-a8e7-4388-abfb-653d28f5a89f,DISK], DatanodeInfoWithStorage[127.0.0.1:37980,DS-e625ba8a-5359-4ee5-a8c6-ae93fa444c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:43335,DS-93f49a68-e71a-4d6e-b9f8-07721628603b,DISK], DatanodeInfoWithStorage[127.0.0.1:38048,DS-a5812e47-4fc2-4df9-ab62-5ea6db5ad699,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-556180224-172.17.0.15-1596940027126:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39722,DS-02ef5826-a2b6-45d7-a200-91b84029a90b,DISK], DatanodeInfoWithStorage[127.0.0.1:40728,DS-1341bc7d-0634-4249-ab70-e974eb10b76c,DISK], DatanodeInfoWithStorage[127.0.0.1:40549,DS-4541671a-18cd-4e9c-a5c0-c24b157eefd5,DISK], DatanodeInfoWithStorage[127.0.0.1:44094,DS-8c1b1b3f-e233-4a55-85ee-beaac3ef41e8,DISK], DatanodeInfoWithStorage[127.0.0.1:46769,DS-25304b98-a8e7-4388-abfb-653d28f5a89f,DISK], DatanodeInfoWithStorage[127.0.0.1:37980,DS-e625ba8a-5359-4ee5-a8c6-ae93fa444c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:43335,DS-93f49a68-e71a-4d6e-b9f8-07721628603b,DISK], DatanodeInfoWithStorage[127.0.0.1:38048,DS-a5812e47-4fc2-4df9-ab62-5ea6db5ad699,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-145773734-172.17.0.15-1596940246003:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36841,DS-9aa761f2-389a-4224-83b6-b16bc89ace1a,DISK], DatanodeInfoWithStorage[127.0.0.1:38748,DS-7d4dd2f0-c3e7-40b6-8749-89e6bb9bd78c,DISK], DatanodeInfoWithStorage[127.0.0.1:45515,DS-efd57a8e-2651-4bfd-8f3d-cba60f0bf517,DISK], DatanodeInfoWithStorage[127.0.0.1:40943,DS-cb21a722-5948-431b-9ee2-d887137b3b61,DISK], DatanodeInfoWithStorage[127.0.0.1:44110,DS-4b271749-d7ea-4be5-b811-dbb81ca514e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46807,DS-d6dae195-fd16-4843-b2de-f335f8916f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:44378,DS-b9384d5a-f874-41d1-b2d3-127d9b3b7aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:41563,DS-62930806-5b75-4656-bf6b-7447057fc6a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-145773734-172.17.0.15-1596940246003:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36841,DS-9aa761f2-389a-4224-83b6-b16bc89ace1a,DISK], DatanodeInfoWithStorage[127.0.0.1:38748,DS-7d4dd2f0-c3e7-40b6-8749-89e6bb9bd78c,DISK], DatanodeInfoWithStorage[127.0.0.1:45515,DS-efd57a8e-2651-4bfd-8f3d-cba60f0bf517,DISK], DatanodeInfoWithStorage[127.0.0.1:40943,DS-cb21a722-5948-431b-9ee2-d887137b3b61,DISK], DatanodeInfoWithStorage[127.0.0.1:44110,DS-4b271749-d7ea-4be5-b811-dbb81ca514e0,DISK], DatanodeInfoWithStorage[127.0.0.1:46807,DS-d6dae195-fd16-4843-b2de-f335f8916f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:44378,DS-b9384d5a-f874-41d1-b2d3-127d9b3b7aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:41563,DS-62930806-5b75-4656-bf6b-7447057fc6a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1547711509-172.17.0.15-1596940479689:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46409,DS-d216b600-12a6-46c6-a442-a9d66ca0df2c,DISK], DatanodeInfoWithStorage[127.0.0.1:39214,DS-58d71c83-ed84-43b5-a4c0-4b87c449a9c8,DISK], DatanodeInfoWithStorage[127.0.0.1:41378,DS-62ec75a5-2349-426e-8422-9f95f0cab7f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41868,DS-6499573e-68ec-4831-bd0d-aa2b532e4ade,DISK], DatanodeInfoWithStorage[127.0.0.1:36361,DS-0270e3b4-fab5-41f5-9f06-856ecb8754b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46759,DS-589fcf35-3e91-4347-a4cd-2a3b5cbb1d97,DISK], DatanodeInfoWithStorage[127.0.0.1:39873,DS-0a059756-e6c2-44d2-85f4-73da3ea0e9ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35775,DS-bc48ddae-d7d5-4aab-ac56-3b6fdcd668c9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1547711509-172.17.0.15-1596940479689:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46409,DS-d216b600-12a6-46c6-a442-a9d66ca0df2c,DISK], DatanodeInfoWithStorage[127.0.0.1:39214,DS-58d71c83-ed84-43b5-a4c0-4b87c449a9c8,DISK], DatanodeInfoWithStorage[127.0.0.1:41378,DS-62ec75a5-2349-426e-8422-9f95f0cab7f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41868,DS-6499573e-68ec-4831-bd0d-aa2b532e4ade,DISK], DatanodeInfoWithStorage[127.0.0.1:36361,DS-0270e3b4-fab5-41f5-9f06-856ecb8754b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46759,DS-589fcf35-3e91-4347-a4cd-2a3b5cbb1d97,DISK], DatanodeInfoWithStorage[127.0.0.1:39873,DS-0a059756-e6c2-44d2-85f4-73da3ea0e9ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35775,DS-bc48ddae-d7d5-4aab-ac56-3b6fdcd668c9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-229390334-172.17.0.15-1596940538271:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41687,DS-65f4e09d-664b-43ce-ab1c-51269b6cecca,DISK], DatanodeInfoWithStorage[127.0.0.1:37688,DS-f2cf8ea2-7e00-4bec-b25e-6ed94c4270bb,DISK], DatanodeInfoWithStorage[127.0.0.1:43440,DS-ad8e4166-2738-4c4f-9d06-a28c460c6afa,DISK], DatanodeInfoWithStorage[127.0.0.1:41699,DS-c3f84432-3688-4d6c-be73-efe518269a98,DISK], DatanodeInfoWithStorage[127.0.0.1:37004,DS-9058ac46-b07a-49d1-a85c-01985b0ebc79,DISK], DatanodeInfoWithStorage[127.0.0.1:36976,DS-8e0cac10-8630-4bea-8502-45e765afddd3,DISK], DatanodeInfoWithStorage[127.0.0.1:42587,DS-a7575cfb-9c2b-4322-9301-d0b7898e2d25,DISK], DatanodeInfoWithStorage[127.0.0.1:39281,DS-228e78a3-9907-4192-a617-398ea51467aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-229390334-172.17.0.15-1596940538271:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41687,DS-65f4e09d-664b-43ce-ab1c-51269b6cecca,DISK], DatanodeInfoWithStorage[127.0.0.1:37688,DS-f2cf8ea2-7e00-4bec-b25e-6ed94c4270bb,DISK], DatanodeInfoWithStorage[127.0.0.1:43440,DS-ad8e4166-2738-4c4f-9d06-a28c460c6afa,DISK], DatanodeInfoWithStorage[127.0.0.1:41699,DS-c3f84432-3688-4d6c-be73-efe518269a98,DISK], DatanodeInfoWithStorage[127.0.0.1:37004,DS-9058ac46-b07a-49d1-a85c-01985b0ebc79,DISK], DatanodeInfoWithStorage[127.0.0.1:36976,DS-8e0cac10-8630-4bea-8502-45e765afddd3,DISK], DatanodeInfoWithStorage[127.0.0.1:42587,DS-a7575cfb-9c2b-4322-9301-d0b7898e2d25,DISK], DatanodeInfoWithStorage[127.0.0.1:39281,DS-228e78a3-9907-4192-a617-398ea51467aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-617059291-172.17.0.15-1596941066772:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35063,DS-9770a945-769d-4192-a27a-577304c8bffc,DISK], DatanodeInfoWithStorage[127.0.0.1:41918,DS-2a7c2b57-9dfd-4d16-b5f3-1777c01cf974,DISK], DatanodeInfoWithStorage[127.0.0.1:36952,DS-43d61e6f-3e70-4a54-b0aa-c62c101a748d,DISK], DatanodeInfoWithStorage[127.0.0.1:42086,DS-8c360c54-e1cb-462b-9e19-a21621e0e7af,DISK], DatanodeInfoWithStorage[127.0.0.1:39800,DS-193cb065-183e-473f-9bfb-f4eb55ae770c,DISK], DatanodeInfoWithStorage[127.0.0.1:38085,DS-69d97bae-7c7a-406f-aa9c-4b63b6aa7525,DISK], DatanodeInfoWithStorage[127.0.0.1:41596,DS-b1df6aa8-de95-46f1-aba2-fb1c9e85341f,DISK], DatanodeInfoWithStorage[127.0.0.1:43949,DS-0235a11f-afb3-4b82-abbf-0779e6e554ce,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-617059291-172.17.0.15-1596941066772:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35063,DS-9770a945-769d-4192-a27a-577304c8bffc,DISK], DatanodeInfoWithStorage[127.0.0.1:41918,DS-2a7c2b57-9dfd-4d16-b5f3-1777c01cf974,DISK], DatanodeInfoWithStorage[127.0.0.1:36952,DS-43d61e6f-3e70-4a54-b0aa-c62c101a748d,DISK], DatanodeInfoWithStorage[127.0.0.1:42086,DS-8c360c54-e1cb-462b-9e19-a21621e0e7af,DISK], DatanodeInfoWithStorage[127.0.0.1:39800,DS-193cb065-183e-473f-9bfb-f4eb55ae770c,DISK], DatanodeInfoWithStorage[127.0.0.1:38085,DS-69d97bae-7c7a-406f-aa9c-4b63b6aa7525,DISK], DatanodeInfoWithStorage[127.0.0.1:41596,DS-b1df6aa8-de95-46f1-aba2-fb1c9e85341f,DISK], DatanodeInfoWithStorage[127.0.0.1:43949,DS-0235a11f-afb3-4b82-abbf-0779e6e554ce,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-86997466-172.17.0.15-1596941194936:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43431,DS-5ccfd7a5-6838-47c6-ac9f-dcb6d641610a,DISK], DatanodeInfoWithStorage[127.0.0.1:38281,DS-4c71ef60-53d8-4c8f-a39e-46c43beb9d1e,DISK], DatanodeInfoWithStorage[127.0.0.1:38895,DS-926f83e1-464d-4342-87a0-68ba64d02252,DISK], DatanodeInfoWithStorage[127.0.0.1:42014,DS-83fadd4b-f9cb-4960-a43c-1cb03f55453c,DISK], DatanodeInfoWithStorage[127.0.0.1:38981,DS-bee314c4-0e2c-4c79-87a2-0c314faa8f5a,DISK], DatanodeInfoWithStorage[127.0.0.1:41625,DS-3ca3f822-4990-4da1-b505-c3813aacfe74,DISK], DatanodeInfoWithStorage[127.0.0.1:40881,DS-431a1f91-2bcd-4750-a880-63a692130cd1,DISK], DatanodeInfoWithStorage[127.0.0.1:34868,DS-f5513cc7-7d6b-4a09-a259-5f234b68b0b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-86997466-172.17.0.15-1596941194936:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43431,DS-5ccfd7a5-6838-47c6-ac9f-dcb6d641610a,DISK], DatanodeInfoWithStorage[127.0.0.1:38281,DS-4c71ef60-53d8-4c8f-a39e-46c43beb9d1e,DISK], DatanodeInfoWithStorage[127.0.0.1:38895,DS-926f83e1-464d-4342-87a0-68ba64d02252,DISK], DatanodeInfoWithStorage[127.0.0.1:42014,DS-83fadd4b-f9cb-4960-a43c-1cb03f55453c,DISK], DatanodeInfoWithStorage[127.0.0.1:38981,DS-bee314c4-0e2c-4c79-87a2-0c314faa8f5a,DISK], DatanodeInfoWithStorage[127.0.0.1:41625,DS-3ca3f822-4990-4da1-b505-c3813aacfe74,DISK], DatanodeInfoWithStorage[127.0.0.1:40881,DS-431a1f91-2bcd-4750-a880-63a692130cd1,DISK], DatanodeInfoWithStorage[127.0.0.1:34868,DS-f5513cc7-7d6b-4a09-a259-5f234b68b0b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-880364856-172.17.0.15-1596941224567:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46447,DS-4ee863ea-5459-4816-82e1-47fd9850dcf1,DISK], DatanodeInfoWithStorage[127.0.0.1:33735,DS-493476f5-dda2-4dcc-b544-11e988c4e5a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35341,DS-9a6fd7f0-714f-417f-949a-095a3cd647f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36691,DS-0ec7b449-965d-4295-b7f8-87f1f52cbfea,DISK], DatanodeInfoWithStorage[127.0.0.1:42327,DS-558fba2b-8b16-4c7b-a613-4d036521ad39,DISK], DatanodeInfoWithStorage[127.0.0.1:41778,DS-2a5824f6-13f9-4b4c-8c5a-f9e9c5695fcc,DISK], DatanodeInfoWithStorage[127.0.0.1:41339,DS-53f09a40-f9a5-477f-b1e1-cc0674e5b2e1,DISK], DatanodeInfoWithStorage[127.0.0.1:44836,DS-73249923-3776-47f7-9e83-97513e9f5b53,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-880364856-172.17.0.15-1596941224567:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46447,DS-4ee863ea-5459-4816-82e1-47fd9850dcf1,DISK], DatanodeInfoWithStorage[127.0.0.1:33735,DS-493476f5-dda2-4dcc-b544-11e988c4e5a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35341,DS-9a6fd7f0-714f-417f-949a-095a3cd647f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36691,DS-0ec7b449-965d-4295-b7f8-87f1f52cbfea,DISK], DatanodeInfoWithStorage[127.0.0.1:42327,DS-558fba2b-8b16-4c7b-a613-4d036521ad39,DISK], DatanodeInfoWithStorage[127.0.0.1:41778,DS-2a5824f6-13f9-4b4c-8c5a-f9e9c5695fcc,DISK], DatanodeInfoWithStorage[127.0.0.1:41339,DS-53f09a40-f9a5-477f-b1e1-cc0674e5b2e1,DISK], DatanodeInfoWithStorage[127.0.0.1:44836,DS-73249923-3776-47f7-9e83-97513e9f5b53,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 4908
