reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1517596766-172.17.0.17-1596960094715:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36244,DS-eb809b90-9cf8-4b84-aca5-7550bfb6e877,DISK], DatanodeInfoWithStorage[127.0.0.1:40809,DS-8c514c6e-83e1-4f2d-b722-1ef9da1a1167,DISK], DatanodeInfoWithStorage[127.0.0.1:35189,DS-edb23ec0-dd19-49d6-8aa9-904d9ca40395,DISK], DatanodeInfoWithStorage[127.0.0.1:43592,DS-4bceb1ad-f6c6-4c51-9052-4d18700daf18,DISK], DatanodeInfoWithStorage[127.0.0.1:38095,DS-a549dce4-fa3f-4d48-aa9c-c3f8fa207dcd,DISK], DatanodeInfoWithStorage[127.0.0.1:39961,DS-6fbcff01-d0c8-4801-8a20-54ab767b5c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:38374,DS-54dc6b65-21ef-4552-ab08-695bcf906c75,DISK], DatanodeInfoWithStorage[127.0.0.1:33965,DS-b1d72e8f-022e-489d-a402-0ae018335069,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1517596766-172.17.0.17-1596960094715:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36244,DS-eb809b90-9cf8-4b84-aca5-7550bfb6e877,DISK], DatanodeInfoWithStorage[127.0.0.1:40809,DS-8c514c6e-83e1-4f2d-b722-1ef9da1a1167,DISK], DatanodeInfoWithStorage[127.0.0.1:35189,DS-edb23ec0-dd19-49d6-8aa9-904d9ca40395,DISK], DatanodeInfoWithStorage[127.0.0.1:43592,DS-4bceb1ad-f6c6-4c51-9052-4d18700daf18,DISK], DatanodeInfoWithStorage[127.0.0.1:38095,DS-a549dce4-fa3f-4d48-aa9c-c3f8fa207dcd,DISK], DatanodeInfoWithStorage[127.0.0.1:39961,DS-6fbcff01-d0c8-4801-8a20-54ab767b5c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:38374,DS-54dc6b65-21ef-4552-ab08-695bcf906c75,DISK], DatanodeInfoWithStorage[127.0.0.1:33965,DS-b1d72e8f-022e-489d-a402-0ae018335069,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-472500667-172.17.0.17-1596960739734:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46647,DS-8fce2cef-8cc5-4c3e-88c5-0a81f56afd08,DISK], DatanodeInfoWithStorage[127.0.0.1:40221,DS-f5daa749-e58d-47ca-8858-6fe4d21ae84a,DISK], DatanodeInfoWithStorage[127.0.0.1:33965,DS-bf6ef2e0-0d59-4af5-ba20-935c9b0fb945,DISK], DatanodeInfoWithStorage[127.0.0.1:45130,DS-a96e41f7-4ef7-45c5-85bf-54cb762afc15,DISK], DatanodeInfoWithStorage[127.0.0.1:39137,DS-2a7900bb-0d1b-4a96-8b27-c459b4b39262,DISK], DatanodeInfoWithStorage[127.0.0.1:38803,DS-b045766d-6071-4045-a6e1-517ce5542375,DISK], DatanodeInfoWithStorage[127.0.0.1:38546,DS-8264f6b3-6d66-4892-9fa2-4279d061e592,DISK], DatanodeInfoWithStorage[127.0.0.1:36867,DS-b795a0f0-33f9-4e46-875d-d882111fcd24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-472500667-172.17.0.17-1596960739734:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46647,DS-8fce2cef-8cc5-4c3e-88c5-0a81f56afd08,DISK], DatanodeInfoWithStorage[127.0.0.1:40221,DS-f5daa749-e58d-47ca-8858-6fe4d21ae84a,DISK], DatanodeInfoWithStorage[127.0.0.1:33965,DS-bf6ef2e0-0d59-4af5-ba20-935c9b0fb945,DISK], DatanodeInfoWithStorage[127.0.0.1:45130,DS-a96e41f7-4ef7-45c5-85bf-54cb762afc15,DISK], DatanodeInfoWithStorage[127.0.0.1:39137,DS-2a7900bb-0d1b-4a96-8b27-c459b4b39262,DISK], DatanodeInfoWithStorage[127.0.0.1:38803,DS-b045766d-6071-4045-a6e1-517ce5542375,DISK], DatanodeInfoWithStorage[127.0.0.1:38546,DS-8264f6b3-6d66-4892-9fa2-4279d061e592,DISK], DatanodeInfoWithStorage[127.0.0.1:36867,DS-b795a0f0-33f9-4e46-875d-d882111fcd24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-327534968-172.17.0.17-1596961037251:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39437,DS-db212e96-a775-4f7d-b03b-bd0993b47aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:41697,DS-61cf52a0-f36d-4e22-9163-68eabe0971a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43789,DS-e2564d75-81ac-4fe7-9f40-5b251488d795,DISK], DatanodeInfoWithStorage[127.0.0.1:45888,DS-2e87e9bb-58e6-4ce4-97af-34e6a6d8ff67,DISK], DatanodeInfoWithStorage[127.0.0.1:37368,DS-9e4d08f2-eb64-4c5c-a2c0-6b9c2a907a61,DISK], DatanodeInfoWithStorage[127.0.0.1:41328,DS-821788af-4820-4293-89fe-99cbdc879d21,DISK], DatanodeInfoWithStorage[127.0.0.1:33691,DS-96192338-868a-4bf6-a90e-fc13c2ccae2e,DISK], DatanodeInfoWithStorage[127.0.0.1:43367,DS-d4056755-81f9-4cae-8de1-659625a87701,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-327534968-172.17.0.17-1596961037251:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39437,DS-db212e96-a775-4f7d-b03b-bd0993b47aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:41697,DS-61cf52a0-f36d-4e22-9163-68eabe0971a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43789,DS-e2564d75-81ac-4fe7-9f40-5b251488d795,DISK], DatanodeInfoWithStorage[127.0.0.1:45888,DS-2e87e9bb-58e6-4ce4-97af-34e6a6d8ff67,DISK], DatanodeInfoWithStorage[127.0.0.1:37368,DS-9e4d08f2-eb64-4c5c-a2c0-6b9c2a907a61,DISK], DatanodeInfoWithStorage[127.0.0.1:41328,DS-821788af-4820-4293-89fe-99cbdc879d21,DISK], DatanodeInfoWithStorage[127.0.0.1:33691,DS-96192338-868a-4bf6-a90e-fc13c2ccae2e,DISK], DatanodeInfoWithStorage[127.0.0.1:43367,DS-d4056755-81f9-4cae-8de1-659625a87701,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1590363988-172.17.0.17-1596961189306:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46665,DS-30736ed3-f146-48ed-97e1-13a742fcf17d,DISK], DatanodeInfoWithStorage[127.0.0.1:37139,DS-c9659fe6-9918-42a3-b67e-c375c670624b,DISK], DatanodeInfoWithStorage[127.0.0.1:44941,DS-8b36f0cd-a58a-434e-92b3-ac7310513726,DISK], DatanodeInfoWithStorage[127.0.0.1:44839,DS-755a87b5-2ace-484f-b1f3-2188ac17b01f,DISK], DatanodeInfoWithStorage[127.0.0.1:36074,DS-c6ddda5c-bc7f-4242-8267-42f94fe59809,DISK], DatanodeInfoWithStorage[127.0.0.1:46160,DS-4efdc337-a9eb-4233-9f49-b16814770faa,DISK], DatanodeInfoWithStorage[127.0.0.1:35885,DS-15353edf-6bd2-4d25-8271-80e273d91b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:37396,DS-b4b2a884-50f3-4791-a441-291cb27348a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1590363988-172.17.0.17-1596961189306:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46665,DS-30736ed3-f146-48ed-97e1-13a742fcf17d,DISK], DatanodeInfoWithStorage[127.0.0.1:37139,DS-c9659fe6-9918-42a3-b67e-c375c670624b,DISK], DatanodeInfoWithStorage[127.0.0.1:44941,DS-8b36f0cd-a58a-434e-92b3-ac7310513726,DISK], DatanodeInfoWithStorage[127.0.0.1:44839,DS-755a87b5-2ace-484f-b1f3-2188ac17b01f,DISK], DatanodeInfoWithStorage[127.0.0.1:36074,DS-c6ddda5c-bc7f-4242-8267-42f94fe59809,DISK], DatanodeInfoWithStorage[127.0.0.1:46160,DS-4efdc337-a9eb-4233-9f49-b16814770faa,DISK], DatanodeInfoWithStorage[127.0.0.1:35885,DS-15353edf-6bd2-4d25-8271-80e273d91b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:37396,DS-b4b2a884-50f3-4791-a441-291cb27348a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1703104242-172.17.0.17-1596961352936:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37038,DS-52605132-5670-457a-9c72-1c91b3d785af,DISK], DatanodeInfoWithStorage[127.0.0.1:43582,DS-0e40bbec-7c88-4e16-91ca-d8c9b236bbaa,DISK], DatanodeInfoWithStorage[127.0.0.1:37180,DS-b37e4389-71af-4acc-98f9-ad9c05acbc3f,DISK], DatanodeInfoWithStorage[127.0.0.1:44611,DS-e8ed2f65-82db-418b-81e3-b43c20ff2ba7,DISK], DatanodeInfoWithStorage[127.0.0.1:33078,DS-8804c35d-4085-41d0-baeb-2bd51a20bd78,DISK], DatanodeInfoWithStorage[127.0.0.1:41330,DS-1dba585e-c5f0-4339-8d79-2b08987ec1f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38274,DS-1727c360-7e0c-409b-a8b9-8e837ee3357f,DISK], DatanodeInfoWithStorage[127.0.0.1:38365,DS-d446b68a-9b55-41d3-bcf4-120a9ba06e10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1703104242-172.17.0.17-1596961352936:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37038,DS-52605132-5670-457a-9c72-1c91b3d785af,DISK], DatanodeInfoWithStorage[127.0.0.1:43582,DS-0e40bbec-7c88-4e16-91ca-d8c9b236bbaa,DISK], DatanodeInfoWithStorage[127.0.0.1:37180,DS-b37e4389-71af-4acc-98f9-ad9c05acbc3f,DISK], DatanodeInfoWithStorage[127.0.0.1:44611,DS-e8ed2f65-82db-418b-81e3-b43c20ff2ba7,DISK], DatanodeInfoWithStorage[127.0.0.1:33078,DS-8804c35d-4085-41d0-baeb-2bd51a20bd78,DISK], DatanodeInfoWithStorage[127.0.0.1:41330,DS-1dba585e-c5f0-4339-8d79-2b08987ec1f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38274,DS-1727c360-7e0c-409b-a8b9-8e837ee3357f,DISK], DatanodeInfoWithStorage[127.0.0.1:38365,DS-d446b68a-9b55-41d3-bcf4-120a9ba06e10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2066318668-172.17.0.17-1596961482631:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33515,DS-9acadd15-82f0-46eb-8df1-8a928c9c20ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42224,DS-f0f0f58a-99c6-4cf6-b9d3-c387c605878f,DISK], DatanodeInfoWithStorage[127.0.0.1:37214,DS-0c350ff6-c257-4faf-98de-4c16a0f112e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35153,DS-1e80be35-b59a-4fd2-90a6-041d29ae56e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37870,DS-8c83cb6a-d80d-436d-8571-bf1e3754b664,DISK], DatanodeInfoWithStorage[127.0.0.1:39580,DS-e787246e-fa43-4cf6-98b4-827cc276ac1a,DISK], DatanodeInfoWithStorage[127.0.0.1:37786,DS-dc4da2a6-fe4a-43ba-a995-f00573660ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:35003,DS-452dcb17-22ab-48e3-9180-3a5f58054876,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2066318668-172.17.0.17-1596961482631:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33515,DS-9acadd15-82f0-46eb-8df1-8a928c9c20ef,DISK], DatanodeInfoWithStorage[127.0.0.1:42224,DS-f0f0f58a-99c6-4cf6-b9d3-c387c605878f,DISK], DatanodeInfoWithStorage[127.0.0.1:37214,DS-0c350ff6-c257-4faf-98de-4c16a0f112e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35153,DS-1e80be35-b59a-4fd2-90a6-041d29ae56e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37870,DS-8c83cb6a-d80d-436d-8571-bf1e3754b664,DISK], DatanodeInfoWithStorage[127.0.0.1:39580,DS-e787246e-fa43-4cf6-98b4-827cc276ac1a,DISK], DatanodeInfoWithStorage[127.0.0.1:37786,DS-dc4da2a6-fe4a-43ba-a995-f00573660ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:35003,DS-452dcb17-22ab-48e3-9180-3a5f58054876,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2039121011-172.17.0.17-1596961680184:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33128,DS-7f6bbbea-d937-4d43-b327-e4718f19f0cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43159,DS-da425f16-782b-418f-885f-9e1663eb0b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:45952,DS-bdd29bec-dae6-4f07-baea-5d1ae35b14c3,DISK], DatanodeInfoWithStorage[127.0.0.1:46485,DS-8095d1ca-a14f-47f9-91c7-0054348a06fc,DISK], DatanodeInfoWithStorage[127.0.0.1:46146,DS-9f2ab8c6-3414-489f-840c-95a1d07fde9b,DISK], DatanodeInfoWithStorage[127.0.0.1:39870,DS-c4188e0c-060a-4f38-bada-1c86ca47526e,DISK], DatanodeInfoWithStorage[127.0.0.1:41963,DS-1241ec4b-6d92-4cfe-91d8-81f9f187b34c,DISK], DatanodeInfoWithStorage[127.0.0.1:33187,DS-b03e9f89-938b-4ac2-af20-986e8759548c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2039121011-172.17.0.17-1596961680184:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33128,DS-7f6bbbea-d937-4d43-b327-e4718f19f0cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43159,DS-da425f16-782b-418f-885f-9e1663eb0b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:45952,DS-bdd29bec-dae6-4f07-baea-5d1ae35b14c3,DISK], DatanodeInfoWithStorage[127.0.0.1:46485,DS-8095d1ca-a14f-47f9-91c7-0054348a06fc,DISK], DatanodeInfoWithStorage[127.0.0.1:46146,DS-9f2ab8c6-3414-489f-840c-95a1d07fde9b,DISK], DatanodeInfoWithStorage[127.0.0.1:39870,DS-c4188e0c-060a-4f38-bada-1c86ca47526e,DISK], DatanodeInfoWithStorage[127.0.0.1:41963,DS-1241ec4b-6d92-4cfe-91d8-81f9f187b34c,DISK], DatanodeInfoWithStorage[127.0.0.1:33187,DS-b03e9f89-938b-4ac2-af20-986e8759548c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-984079476-172.17.0.17-1596961752367:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40208,DS-b1aa85b5-7b16-4c06-902f-e8859d5b5183,DISK], DatanodeInfoWithStorage[127.0.0.1:40548,DS-15803256-aeda-4c1b-b3e7-2ba0eba11773,DISK], DatanodeInfoWithStorage[127.0.0.1:35122,DS-003315d9-c14b-4d23-9935-8b4fc770cfbf,DISK], DatanodeInfoWithStorage[127.0.0.1:46519,DS-324183c4-c43e-44c7-aa92-ab1104089df8,DISK], DatanodeInfoWithStorage[127.0.0.1:43153,DS-3f0ed760-3db4-45f9-b877-63d7a7171ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:46643,DS-dcaa04fc-4fa9-49ae-8f58-ebc07047dc39,DISK], DatanodeInfoWithStorage[127.0.0.1:39347,DS-4753b4e3-ac78-4e81-ac25-46d36c65e00a,DISK], DatanodeInfoWithStorage[127.0.0.1:41929,DS-60166fa6-7978-4e33-972f-f42bd4eff95f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-984079476-172.17.0.17-1596961752367:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40208,DS-b1aa85b5-7b16-4c06-902f-e8859d5b5183,DISK], DatanodeInfoWithStorage[127.0.0.1:40548,DS-15803256-aeda-4c1b-b3e7-2ba0eba11773,DISK], DatanodeInfoWithStorage[127.0.0.1:35122,DS-003315d9-c14b-4d23-9935-8b4fc770cfbf,DISK], DatanodeInfoWithStorage[127.0.0.1:46519,DS-324183c4-c43e-44c7-aa92-ab1104089df8,DISK], DatanodeInfoWithStorage[127.0.0.1:43153,DS-3f0ed760-3db4-45f9-b877-63d7a7171ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:46643,DS-dcaa04fc-4fa9-49ae-8f58-ebc07047dc39,DISK], DatanodeInfoWithStorage[127.0.0.1:39347,DS-4753b4e3-ac78-4e81-ac25-46d36c65e00a,DISK], DatanodeInfoWithStorage[127.0.0.1:41929,DS-60166fa6-7978-4e33-972f-f42bd4eff95f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1495633586-172.17.0.17-1596962421560:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43956,DS-4b4dabc8-3102-4650-b1f3-35ebb91c892f,DISK], DatanodeInfoWithStorage[127.0.0.1:37186,DS-c2abd517-326a-4193-bb29-16f250806a94,DISK], DatanodeInfoWithStorage[127.0.0.1:33083,DS-256df4b2-4128-46fd-af76-11e5c2636f01,DISK], DatanodeInfoWithStorage[127.0.0.1:38307,DS-c670cc89-cc87-46f4-a318-f6c16b984f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:46653,DS-66cfea0b-d24f-4ac3-9eeb-dea525d37699,DISK], DatanodeInfoWithStorage[127.0.0.1:35583,DS-ad155f9f-4998-45b1-a681-cf4d33432d87,DISK], DatanodeInfoWithStorage[127.0.0.1:46400,DS-943d2a28-e552-4479-8476-d82e006e3883,DISK], DatanodeInfoWithStorage[127.0.0.1:37479,DS-7a060163-605a-4c1d-a0cb-207a4de3ef4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1495633586-172.17.0.17-1596962421560:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43956,DS-4b4dabc8-3102-4650-b1f3-35ebb91c892f,DISK], DatanodeInfoWithStorage[127.0.0.1:37186,DS-c2abd517-326a-4193-bb29-16f250806a94,DISK], DatanodeInfoWithStorage[127.0.0.1:33083,DS-256df4b2-4128-46fd-af76-11e5c2636f01,DISK], DatanodeInfoWithStorage[127.0.0.1:38307,DS-c670cc89-cc87-46f4-a318-f6c16b984f2e,DISK], DatanodeInfoWithStorage[127.0.0.1:46653,DS-66cfea0b-d24f-4ac3-9eeb-dea525d37699,DISK], DatanodeInfoWithStorage[127.0.0.1:35583,DS-ad155f9f-4998-45b1-a681-cf4d33432d87,DISK], DatanodeInfoWithStorage[127.0.0.1:46400,DS-943d2a28-e552-4479-8476-d82e006e3883,DISK], DatanodeInfoWithStorage[127.0.0.1:37479,DS-7a060163-605a-4c1d-a0cb-207a4de3ef4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1822491893-172.17.0.17-1596962458742:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41888,DS-ca431cf0-0f37-4c39-aaac-9ac7ff677324,DISK], DatanodeInfoWithStorage[127.0.0.1:37863,DS-1eb8f3e8-4fc3-4756-a69a-e7f5862a23ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34855,DS-6a3145b3-3844-4911-996f-06bee33446db,DISK], DatanodeInfoWithStorage[127.0.0.1:39755,DS-b39b8b7f-f950-4d7f-ae82-3dde3f10d094,DISK], DatanodeInfoWithStorage[127.0.0.1:44000,DS-54964f05-f14d-4b11-8763-d573ed0f18d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34044,DS-3fc9a8b9-29eb-4ea2-8aa9-5da8d3b7ca6b,DISK], DatanodeInfoWithStorage[127.0.0.1:41449,DS-1ecd27c8-856c-4343-a4c2-a39bc43785a7,DISK], DatanodeInfoWithStorage[127.0.0.1:32910,DS-df4fa41b-47b1-4a10-90dd-538879f93b64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1822491893-172.17.0.17-1596962458742:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41888,DS-ca431cf0-0f37-4c39-aaac-9ac7ff677324,DISK], DatanodeInfoWithStorage[127.0.0.1:37863,DS-1eb8f3e8-4fc3-4756-a69a-e7f5862a23ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34855,DS-6a3145b3-3844-4911-996f-06bee33446db,DISK], DatanodeInfoWithStorage[127.0.0.1:39755,DS-b39b8b7f-f950-4d7f-ae82-3dde3f10d094,DISK], DatanodeInfoWithStorage[127.0.0.1:44000,DS-54964f05-f14d-4b11-8763-d573ed0f18d0,DISK], DatanodeInfoWithStorage[127.0.0.1:34044,DS-3fc9a8b9-29eb-4ea2-8aa9-5da8d3b7ca6b,DISK], DatanodeInfoWithStorage[127.0.0.1:41449,DS-1ecd27c8-856c-4343-a4c2-a39bc43785a7,DISK], DatanodeInfoWithStorage[127.0.0.1:32910,DS-df4fa41b-47b1-4a10-90dd-538879f93b64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1264738835-172.17.0.17-1596962732206:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37617,DS-eb6a593d-0336-43a7-81e8-2f6eaf5a86f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38823,DS-de258ddb-24a7-48a0-92ce-6649363a102f,DISK], DatanodeInfoWithStorage[127.0.0.1:34808,DS-72f5a5da-14e5-4057-b34d-d45557c8624a,DISK], DatanodeInfoWithStorage[127.0.0.1:39920,DS-08afc78a-cf70-4227-93b4-dfec7ecaac69,DISK], DatanodeInfoWithStorage[127.0.0.1:46048,DS-f6b8520f-3048-43c8-beda-ba4237841799,DISK], DatanodeInfoWithStorage[127.0.0.1:33524,DS-40f5083d-31be-43aa-9c30-d194fdbafc35,DISK], DatanodeInfoWithStorage[127.0.0.1:46769,DS-b48fbde5-5ae8-437a-a669-bb08e13dcc71,DISK], DatanodeInfoWithStorage[127.0.0.1:46514,DS-db53d69d-aab3-4098-b782-874812dbe837,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1264738835-172.17.0.17-1596962732206:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37617,DS-eb6a593d-0336-43a7-81e8-2f6eaf5a86f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38823,DS-de258ddb-24a7-48a0-92ce-6649363a102f,DISK], DatanodeInfoWithStorage[127.0.0.1:34808,DS-72f5a5da-14e5-4057-b34d-d45557c8624a,DISK], DatanodeInfoWithStorage[127.0.0.1:39920,DS-08afc78a-cf70-4227-93b4-dfec7ecaac69,DISK], DatanodeInfoWithStorage[127.0.0.1:46048,DS-f6b8520f-3048-43c8-beda-ba4237841799,DISK], DatanodeInfoWithStorage[127.0.0.1:33524,DS-40f5083d-31be-43aa-9c30-d194fdbafc35,DISK], DatanodeInfoWithStorage[127.0.0.1:46769,DS-b48fbde5-5ae8-437a-a669-bb08e13dcc71,DISK], DatanodeInfoWithStorage[127.0.0.1:46514,DS-db53d69d-aab3-4098-b782-874812dbe837,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-57617233-172.17.0.17-1596962985981:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40589,DS-0eb72d08-4192-4300-b95d-f7b528fc1c77,DISK], DatanodeInfoWithStorage[127.0.0.1:38365,DS-db4f25a1-b861-40cb-9e3d-24977b73a87c,DISK], DatanodeInfoWithStorage[127.0.0.1:40425,DS-782ad343-1307-419e-a720-1600c57698bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38761,DS-0678f268-c148-4b69-a24a-3ecb02378810,DISK], DatanodeInfoWithStorage[127.0.0.1:44492,DS-c5bb3224-fbc5-4c67-8adc-d0c847ad18be,DISK], DatanodeInfoWithStorage[127.0.0.1:39453,DS-63a92e8b-aadc-4337-b256-3fbbc99547b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37965,DS-7b054b98-d4ae-4c6c-814c-2608207d3ad5,DISK], DatanodeInfoWithStorage[127.0.0.1:34922,DS-71b91c99-52fd-4f1a-bf7e-21a7115da516,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-57617233-172.17.0.17-1596962985981:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40589,DS-0eb72d08-4192-4300-b95d-f7b528fc1c77,DISK], DatanodeInfoWithStorage[127.0.0.1:38365,DS-db4f25a1-b861-40cb-9e3d-24977b73a87c,DISK], DatanodeInfoWithStorage[127.0.0.1:40425,DS-782ad343-1307-419e-a720-1600c57698bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38761,DS-0678f268-c148-4b69-a24a-3ecb02378810,DISK], DatanodeInfoWithStorage[127.0.0.1:44492,DS-c5bb3224-fbc5-4c67-8adc-d0c847ad18be,DISK], DatanodeInfoWithStorage[127.0.0.1:39453,DS-63a92e8b-aadc-4337-b256-3fbbc99547b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37965,DS-7b054b98-d4ae-4c6c-814c-2608207d3ad5,DISK], DatanodeInfoWithStorage[127.0.0.1:34922,DS-71b91c99-52fd-4f1a-bf7e-21a7115da516,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-793361297-172.17.0.17-1596963155743:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34418,DS-384b87ee-be20-46f5-9f6a-5225246e8866,DISK], DatanodeInfoWithStorage[127.0.0.1:40205,DS-7ba60850-83be-4b21-b2ae-5e302af001a5,DISK], DatanodeInfoWithStorage[127.0.0.1:45580,DS-0a766495-79c6-4835-8d43-8bc16389243c,DISK], DatanodeInfoWithStorage[127.0.0.1:34833,DS-7a575270-423a-4453-9855-319cc19a2c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:35815,DS-20ec9cd3-1442-4195-ab55-a27d723b988f,DISK], DatanodeInfoWithStorage[127.0.0.1:46827,DS-abe564fc-7494-4a0c-9ec0-91f6425bffd8,DISK], DatanodeInfoWithStorage[127.0.0.1:41063,DS-13bf4f16-96d5-4fde-be50-84c62574c858,DISK], DatanodeInfoWithStorage[127.0.0.1:38520,DS-090d0425-4482-4110-8313-611d1b474145,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-793361297-172.17.0.17-1596963155743:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34418,DS-384b87ee-be20-46f5-9f6a-5225246e8866,DISK], DatanodeInfoWithStorage[127.0.0.1:40205,DS-7ba60850-83be-4b21-b2ae-5e302af001a5,DISK], DatanodeInfoWithStorage[127.0.0.1:45580,DS-0a766495-79c6-4835-8d43-8bc16389243c,DISK], DatanodeInfoWithStorage[127.0.0.1:34833,DS-7a575270-423a-4453-9855-319cc19a2c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:35815,DS-20ec9cd3-1442-4195-ab55-a27d723b988f,DISK], DatanodeInfoWithStorage[127.0.0.1:46827,DS-abe564fc-7494-4a0c-9ec0-91f6425bffd8,DISK], DatanodeInfoWithStorage[127.0.0.1:41063,DS-13bf4f16-96d5-4fde-be50-84c62574c858,DISK], DatanodeInfoWithStorage[127.0.0.1:38520,DS-090d0425-4482-4110-8313-611d1b474145,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1698204031-172.17.0.17-1596963232816:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38901,DS-b08899a8-c195-44c8-822c-ce85b26c564d,DISK], DatanodeInfoWithStorage[127.0.0.1:43406,DS-5542e56d-d307-4667-84c4-0544d9607ccc,DISK], DatanodeInfoWithStorage[127.0.0.1:42784,DS-e129bae2-c0da-4443-85a2-10281b851712,DISK], DatanodeInfoWithStorage[127.0.0.1:37924,DS-f917c2b9-bae9-47f0-afc6-bee993ffe613,DISK], DatanodeInfoWithStorage[127.0.0.1:46028,DS-21b5a206-a0b8-40b5-baa3-e832f2f7d219,DISK], DatanodeInfoWithStorage[127.0.0.1:40491,DS-06fa9f94-05d4-4266-b4cc-0b7d79d83fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:36205,DS-e226facf-18e5-4f02-8d5d-73028c035fe8,DISK], DatanodeInfoWithStorage[127.0.0.1:39686,DS-d81a6c99-3506-4745-a34d-0cfcc75dde12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1698204031-172.17.0.17-1596963232816:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38901,DS-b08899a8-c195-44c8-822c-ce85b26c564d,DISK], DatanodeInfoWithStorage[127.0.0.1:43406,DS-5542e56d-d307-4667-84c4-0544d9607ccc,DISK], DatanodeInfoWithStorage[127.0.0.1:42784,DS-e129bae2-c0da-4443-85a2-10281b851712,DISK], DatanodeInfoWithStorage[127.0.0.1:37924,DS-f917c2b9-bae9-47f0-afc6-bee993ffe613,DISK], DatanodeInfoWithStorage[127.0.0.1:46028,DS-21b5a206-a0b8-40b5-baa3-e832f2f7d219,DISK], DatanodeInfoWithStorage[127.0.0.1:40491,DS-06fa9f94-05d4-4266-b4cc-0b7d79d83fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:36205,DS-e226facf-18e5-4f02-8d5d-73028c035fe8,DISK], DatanodeInfoWithStorage[127.0.0.1:39686,DS-d81a6c99-3506-4745-a34d-0cfcc75dde12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-204203471-172.17.0.17-1596963274925:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32953,DS-f30b8cbc-7208-41c2-80d6-fa69ebecfc45,DISK], DatanodeInfoWithStorage[127.0.0.1:33391,DS-4a752797-5e59-416a-91ed-5c24e7004dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:33588,DS-1f6532ee-8864-41b3-ae7f-078bf641dca1,DISK], DatanodeInfoWithStorage[127.0.0.1:35771,DS-e64c50d4-762e-4226-a7da-78ca9d273f35,DISK], DatanodeInfoWithStorage[127.0.0.1:37993,DS-acc64b12-8cd0-41b1-b410-d2f2afc5a4ca,DISK], DatanodeInfoWithStorage[127.0.0.1:44724,DS-dfee5748-2e59-48bf-abdb-bb6723abe025,DISK], DatanodeInfoWithStorage[127.0.0.1:35322,DS-b0f68ba1-0ccd-419c-9cbf-b2d0e6a08a82,DISK], DatanodeInfoWithStorage[127.0.0.1:43083,DS-369dc303-406a-4331-8912-787212d1a87f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-204203471-172.17.0.17-1596963274925:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32953,DS-f30b8cbc-7208-41c2-80d6-fa69ebecfc45,DISK], DatanodeInfoWithStorage[127.0.0.1:33391,DS-4a752797-5e59-416a-91ed-5c24e7004dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:33588,DS-1f6532ee-8864-41b3-ae7f-078bf641dca1,DISK], DatanodeInfoWithStorage[127.0.0.1:35771,DS-e64c50d4-762e-4226-a7da-78ca9d273f35,DISK], DatanodeInfoWithStorage[127.0.0.1:37993,DS-acc64b12-8cd0-41b1-b410-d2f2afc5a4ca,DISK], DatanodeInfoWithStorage[127.0.0.1:44724,DS-dfee5748-2e59-48bf-abdb-bb6723abe025,DISK], DatanodeInfoWithStorage[127.0.0.1:35322,DS-b0f68ba1-0ccd-419c-9cbf-b2d0e6a08a82,DISK], DatanodeInfoWithStorage[127.0.0.1:43083,DS-369dc303-406a-4331-8912-787212d1a87f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-422343140-172.17.0.17-1596963526983:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41103,DS-b45ea806-1ca4-427e-af44-2596e144c4c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34563,DS-5acf5c50-0dac-4d62-bb21-f1acc05b0f6a,DISK], DatanodeInfoWithStorage[127.0.0.1:36770,DS-751ec1c8-3f57-4196-b9ea-51b07def982b,DISK], DatanodeInfoWithStorage[127.0.0.1:41859,DS-708c42a9-33b9-4d26-a58b-f54645ff5ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:37612,DS-0308cbc7-f325-4b70-946a-8425eee7e7a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41694,DS-07c0ecb6-2ab3-4891-ad03-ad1ef06e790f,DISK], DatanodeInfoWithStorage[127.0.0.1:41149,DS-91d76a3a-9980-4ad0-9fa4-e8b07169aaf0,DISK], DatanodeInfoWithStorage[127.0.0.1:32769,DS-78ed7993-9956-4920-8548-214347a0e312,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-422343140-172.17.0.17-1596963526983:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41103,DS-b45ea806-1ca4-427e-af44-2596e144c4c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34563,DS-5acf5c50-0dac-4d62-bb21-f1acc05b0f6a,DISK], DatanodeInfoWithStorage[127.0.0.1:36770,DS-751ec1c8-3f57-4196-b9ea-51b07def982b,DISK], DatanodeInfoWithStorage[127.0.0.1:41859,DS-708c42a9-33b9-4d26-a58b-f54645ff5ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:37612,DS-0308cbc7-f325-4b70-946a-8425eee7e7a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41694,DS-07c0ecb6-2ab3-4891-ad03-ad1ef06e790f,DISK], DatanodeInfoWithStorage[127.0.0.1:41149,DS-91d76a3a-9980-4ad0-9fa4-e8b07169aaf0,DISK], DatanodeInfoWithStorage[127.0.0.1:32769,DS-78ed7993-9956-4920-8548-214347a0e312,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-138239275-172.17.0.17-1596964644719:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46823,DS-f30bc8be-cedc-405c-9865-a73d9b9a7c49,DISK], DatanodeInfoWithStorage[127.0.0.1:34067,DS-557598f2-f610-49ea-b5db-8b7c07c68777,DISK], DatanodeInfoWithStorage[127.0.0.1:44735,DS-cb4493b3-50c5-492e-ae2c-9bebaa9dcba1,DISK], DatanodeInfoWithStorage[127.0.0.1:45751,DS-51fef76b-1ff7-4949-99c0-71e03005647e,DISK], DatanodeInfoWithStorage[127.0.0.1:45360,DS-7fcf3f06-ed1c-4b2d-a83a-7301c6420cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:40131,DS-7fed2b88-1a98-4f10-aed1-fa279909a607,DISK], DatanodeInfoWithStorage[127.0.0.1:40234,DS-174c9bcb-2576-48c3-9fc4-27fb6cd51765,DISK], DatanodeInfoWithStorage[127.0.0.1:34105,DS-b5d2dc04-2c74-43b4-a223-bc059eb21793,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-138239275-172.17.0.17-1596964644719:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46823,DS-f30bc8be-cedc-405c-9865-a73d9b9a7c49,DISK], DatanodeInfoWithStorage[127.0.0.1:34067,DS-557598f2-f610-49ea-b5db-8b7c07c68777,DISK], DatanodeInfoWithStorage[127.0.0.1:44735,DS-cb4493b3-50c5-492e-ae2c-9bebaa9dcba1,DISK], DatanodeInfoWithStorage[127.0.0.1:45751,DS-51fef76b-1ff7-4949-99c0-71e03005647e,DISK], DatanodeInfoWithStorage[127.0.0.1:45360,DS-7fcf3f06-ed1c-4b2d-a83a-7301c6420cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:40131,DS-7fed2b88-1a98-4f10-aed1-fa279909a607,DISK], DatanodeInfoWithStorage[127.0.0.1:40234,DS-174c9bcb-2576-48c3-9fc4-27fb6cd51765,DISK], DatanodeInfoWithStorage[127.0.0.1:34105,DS-b5d2dc04-2c74-43b4-a223-bc059eb21793,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-667761585-172.17.0.17-1596964811529:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33933,DS-354fe39d-1257-4a0d-9ecd-9eb7ad31cc45,DISK], DatanodeInfoWithStorage[127.0.0.1:35119,DS-fb9c9468-b7d1-423a-bbd2-e90708fc9b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:38411,DS-b02e4a27-430a-421a-91cf-98b3df429483,DISK], DatanodeInfoWithStorage[127.0.0.1:39707,DS-3910095f-a522-4280-a701-9b91aa3a4e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:33045,DS-668ff103-093b-42b9-b275-70b38a1c4df2,DISK], DatanodeInfoWithStorage[127.0.0.1:39495,DS-70f17dd9-8079-450b-b7a4-494269d016d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41933,DS-651ff53e-c0fb-46d4-a3ed-083d818603bc,DISK], DatanodeInfoWithStorage[127.0.0.1:40397,DS-dc0b757c-e2d9-447a-897c-dc1b1be66999,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-667761585-172.17.0.17-1596964811529:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33933,DS-354fe39d-1257-4a0d-9ecd-9eb7ad31cc45,DISK], DatanodeInfoWithStorage[127.0.0.1:35119,DS-fb9c9468-b7d1-423a-bbd2-e90708fc9b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:38411,DS-b02e4a27-430a-421a-91cf-98b3df429483,DISK], DatanodeInfoWithStorage[127.0.0.1:39707,DS-3910095f-a522-4280-a701-9b91aa3a4e7f,DISK], DatanodeInfoWithStorage[127.0.0.1:33045,DS-668ff103-093b-42b9-b275-70b38a1c4df2,DISK], DatanodeInfoWithStorage[127.0.0.1:39495,DS-70f17dd9-8079-450b-b7a4-494269d016d9,DISK], DatanodeInfoWithStorage[127.0.0.1:41933,DS-651ff53e-c0fb-46d4-a3ed-083d818603bc,DISK], DatanodeInfoWithStorage[127.0.0.1:40397,DS-dc0b757c-e2d9-447a-897c-dc1b1be66999,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-315037432-172.17.0.17-1596964994366:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33242,DS-e704271a-53af-4f89-88cb-210ba42b5d39,DISK], DatanodeInfoWithStorage[127.0.0.1:35938,DS-27e4fe0f-c264-47d6-ac86-b6a2fe421b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:43227,DS-265f5f87-0502-4aac-a20a-877b60848c82,DISK], DatanodeInfoWithStorage[127.0.0.1:37171,DS-1f32a912-f458-41eb-a07f-c085d27b7ec5,DISK], DatanodeInfoWithStorage[127.0.0.1:40310,DS-b512947c-e349-4b38-9482-05ac7a55ee40,DISK], DatanodeInfoWithStorage[127.0.0.1:35158,DS-4c1a0786-ae7b-400b-a37f-f636e3709908,DISK], DatanodeInfoWithStorage[127.0.0.1:46625,DS-8b8ba66a-3372-4a70-8934-5ef917501168,DISK], DatanodeInfoWithStorage[127.0.0.1:33126,DS-0e26a44a-a97f-41ef-b086-894e76bb5126,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-315037432-172.17.0.17-1596964994366:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33242,DS-e704271a-53af-4f89-88cb-210ba42b5d39,DISK], DatanodeInfoWithStorage[127.0.0.1:35938,DS-27e4fe0f-c264-47d6-ac86-b6a2fe421b8d,DISK], DatanodeInfoWithStorage[127.0.0.1:43227,DS-265f5f87-0502-4aac-a20a-877b60848c82,DISK], DatanodeInfoWithStorage[127.0.0.1:37171,DS-1f32a912-f458-41eb-a07f-c085d27b7ec5,DISK], DatanodeInfoWithStorage[127.0.0.1:40310,DS-b512947c-e349-4b38-9482-05ac7a55ee40,DISK], DatanodeInfoWithStorage[127.0.0.1:35158,DS-4c1a0786-ae7b-400b-a37f-f636e3709908,DISK], DatanodeInfoWithStorage[127.0.0.1:46625,DS-8b8ba66a-3372-4a70-8934-5ef917501168,DISK], DatanodeInfoWithStorage[127.0.0.1:33126,DS-0e26a44a-a97f-41ef-b086-894e76bb5126,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-6686240-172.17.0.17-1596965410553:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42151,DS-78ac1bb2-a3d7-413e-8a13-9a3f505d719e,DISK], DatanodeInfoWithStorage[127.0.0.1:38834,DS-61e72fdb-7aa7-41c1-b9c6-7ed820416c62,DISK], DatanodeInfoWithStorage[127.0.0.1:36469,DS-eb9eaa42-e221-40b2-9c8b-8918f75f3dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:40240,DS-704413ed-fdb2-4408-be8e-ccf1f2c63447,DISK], DatanodeInfoWithStorage[127.0.0.1:43636,DS-c007b609-4405-47db-9b56-8cee8238b85b,DISK], DatanodeInfoWithStorage[127.0.0.1:37239,DS-aa9d6c24-5fac-4921-b6b0-2c6186e454fc,DISK], DatanodeInfoWithStorage[127.0.0.1:43720,DS-d8084c19-2608-45a2-99ee-a3ac81d5fca3,DISK], DatanodeInfoWithStorage[127.0.0.1:36205,DS-027701d1-3531-4027-ba45-90c70361348e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-6686240-172.17.0.17-1596965410553:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42151,DS-78ac1bb2-a3d7-413e-8a13-9a3f505d719e,DISK], DatanodeInfoWithStorage[127.0.0.1:38834,DS-61e72fdb-7aa7-41c1-b9c6-7ed820416c62,DISK], DatanodeInfoWithStorage[127.0.0.1:36469,DS-eb9eaa42-e221-40b2-9c8b-8918f75f3dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:40240,DS-704413ed-fdb2-4408-be8e-ccf1f2c63447,DISK], DatanodeInfoWithStorage[127.0.0.1:43636,DS-c007b609-4405-47db-9b56-8cee8238b85b,DISK], DatanodeInfoWithStorage[127.0.0.1:37239,DS-aa9d6c24-5fac-4921-b6b0-2c6186e454fc,DISK], DatanodeInfoWithStorage[127.0.0.1:43720,DS-d8084c19-2608-45a2-99ee-a3ac81d5fca3,DISK], DatanodeInfoWithStorage[127.0.0.1:36205,DS-027701d1-3531-4027-ba45-90c70361348e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1182909643-172.17.0.17-1596965448649:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40739,DS-8a4cbcd6-de09-457b-8e1e-10d770799ff5,DISK], DatanodeInfoWithStorage[127.0.0.1:35582,DS-11953ec1-4e45-408a-b498-9c8908bbbd7a,DISK], DatanodeInfoWithStorage[127.0.0.1:40410,DS-d417ab2e-08e5-47dd-b521-a29ddd29d08a,DISK], DatanodeInfoWithStorage[127.0.0.1:38451,DS-f99bcb69-247d-4eda-9010-ee3bb8d2ac8d,DISK], DatanodeInfoWithStorage[127.0.0.1:37701,DS-728c22c0-5e5f-43bb-baf9-0a657fbb3468,DISK], DatanodeInfoWithStorage[127.0.0.1:42968,DS-839d4379-de73-4246-9087-276a6f24f5f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44256,DS-d73c9ffd-ec63-4634-9adf-0850058b9515,DISK], DatanodeInfoWithStorage[127.0.0.1:34548,DS-1dcd51f2-71ca-4438-a7c8-773babe8bcca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1182909643-172.17.0.17-1596965448649:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40739,DS-8a4cbcd6-de09-457b-8e1e-10d770799ff5,DISK], DatanodeInfoWithStorage[127.0.0.1:35582,DS-11953ec1-4e45-408a-b498-9c8908bbbd7a,DISK], DatanodeInfoWithStorage[127.0.0.1:40410,DS-d417ab2e-08e5-47dd-b521-a29ddd29d08a,DISK], DatanodeInfoWithStorage[127.0.0.1:38451,DS-f99bcb69-247d-4eda-9010-ee3bb8d2ac8d,DISK], DatanodeInfoWithStorage[127.0.0.1:37701,DS-728c22c0-5e5f-43bb-baf9-0a657fbb3468,DISK], DatanodeInfoWithStorage[127.0.0.1:42968,DS-839d4379-de73-4246-9087-276a6f24f5f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44256,DS-d73c9ffd-ec63-4634-9adf-0850058b9515,DISK], DatanodeInfoWithStorage[127.0.0.1:34548,DS-1dcd51f2-71ca-4438-a7c8-773babe8bcca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1473365529-172.17.0.17-1596966180737:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41904,DS-e9f74374-fd6a-45b1-9539-4527a9a9b84c,DISK], DatanodeInfoWithStorage[127.0.0.1:35218,DS-8526f099-4388-4318-8c84-232768f6ae0f,DISK], DatanodeInfoWithStorage[127.0.0.1:46747,DS-dc6a608d-8331-4f5d-82ac-ab54228d0734,DISK], DatanodeInfoWithStorage[127.0.0.1:46707,DS-916376be-e37f-473d-95fd-d86c5af3f0ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45866,DS-a9516432-d0d6-4613-94a0-3cccba7f5b79,DISK], DatanodeInfoWithStorage[127.0.0.1:32982,DS-7a530f1b-2072-4739-a5d5-7cde0d61feb0,DISK], DatanodeInfoWithStorage[127.0.0.1:42743,DS-e3e56d12-7b40-4e13-bba6-7d59d26e8102,DISK], DatanodeInfoWithStorage[127.0.0.1:39330,DS-57cbe063-ff97-470a-8f85-f1043930eed2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1473365529-172.17.0.17-1596966180737:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41904,DS-e9f74374-fd6a-45b1-9539-4527a9a9b84c,DISK], DatanodeInfoWithStorage[127.0.0.1:35218,DS-8526f099-4388-4318-8c84-232768f6ae0f,DISK], DatanodeInfoWithStorage[127.0.0.1:46747,DS-dc6a608d-8331-4f5d-82ac-ab54228d0734,DISK], DatanodeInfoWithStorage[127.0.0.1:46707,DS-916376be-e37f-473d-95fd-d86c5af3f0ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45866,DS-a9516432-d0d6-4613-94a0-3cccba7f5b79,DISK], DatanodeInfoWithStorage[127.0.0.1:32982,DS-7a530f1b-2072-4739-a5d5-7cde0d61feb0,DISK], DatanodeInfoWithStorage[127.0.0.1:42743,DS-e3e56d12-7b40-4e13-bba6-7d59d26e8102,DISK], DatanodeInfoWithStorage[127.0.0.1:39330,DS-57cbe063-ff97-470a-8f85-f1043930eed2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 6429
