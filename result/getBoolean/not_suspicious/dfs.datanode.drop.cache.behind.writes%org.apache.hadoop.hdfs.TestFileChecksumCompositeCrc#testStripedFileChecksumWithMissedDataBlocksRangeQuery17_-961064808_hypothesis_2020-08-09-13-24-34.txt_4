reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-658920097-172.17.0.21-1596979488658:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45071,DS-0c705fc2-2822-41e6-a6da-76874b75d684,DISK], DatanodeInfoWithStorage[127.0.0.1:42095,DS-e78c18f3-3e49-4739-96af-f049145c6e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:45651,DS-8d90ff3f-8595-41f5-a854-c42c2f0a6c78,DISK], DatanodeInfoWithStorage[127.0.0.1:38764,DS-e2128442-79d4-4309-89cd-b08c30ade12d,DISK], DatanodeInfoWithStorage[127.0.0.1:42854,DS-80f7eada-6976-4386-b4ac-48b3589f6f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:35861,DS-54542f53-adbb-4dc1-a4aa-12e8aa43c611,DISK], DatanodeInfoWithStorage[127.0.0.1:36971,DS-65342657-3cd9-44d0-8995-439b5e093554,DISK], DatanodeInfoWithStorage[127.0.0.1:42161,DS-6d5e36af-2086-452f-a4f1-072d94c6a787,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-658920097-172.17.0.21-1596979488658:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45071,DS-0c705fc2-2822-41e6-a6da-76874b75d684,DISK], DatanodeInfoWithStorage[127.0.0.1:42095,DS-e78c18f3-3e49-4739-96af-f049145c6e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:45651,DS-8d90ff3f-8595-41f5-a854-c42c2f0a6c78,DISK], DatanodeInfoWithStorage[127.0.0.1:38764,DS-e2128442-79d4-4309-89cd-b08c30ade12d,DISK], DatanodeInfoWithStorage[127.0.0.1:42854,DS-80f7eada-6976-4386-b4ac-48b3589f6f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:35861,DS-54542f53-adbb-4dc1-a4aa-12e8aa43c611,DISK], DatanodeInfoWithStorage[127.0.0.1:36971,DS-65342657-3cd9-44d0-8995-439b5e093554,DISK], DatanodeInfoWithStorage[127.0.0.1:42161,DS-6d5e36af-2086-452f-a4f1-072d94c6a787,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1854211324-172.17.0.21-1596980048049:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46629,DS-ced11c84-3317-486f-84d2-591b5523299c,DISK], DatanodeInfoWithStorage[127.0.0.1:45789,DS-cf6b86ea-0987-41c3-a684-06a3da0b421a,DISK], DatanodeInfoWithStorage[127.0.0.1:45216,DS-683cf37d-124c-41fd-a4f8-a4ab74dce9c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39616,DS-5a80d86c-c61f-43be-966a-9c98c195c6cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35052,DS-aef30138-30bb-4108-9b03-1a4870776863,DISK], DatanodeInfoWithStorage[127.0.0.1:37422,DS-0b068bb6-4b2e-49f0-b3e3-b593e54dd821,DISK], DatanodeInfoWithStorage[127.0.0.1:39984,DS-10fe6829-b906-4411-845a-82b669c7c4d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41808,DS-56863973-bde1-4bc4-b7f2-f2c2e921663c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1854211324-172.17.0.21-1596980048049:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46629,DS-ced11c84-3317-486f-84d2-591b5523299c,DISK], DatanodeInfoWithStorage[127.0.0.1:45789,DS-cf6b86ea-0987-41c3-a684-06a3da0b421a,DISK], DatanodeInfoWithStorage[127.0.0.1:45216,DS-683cf37d-124c-41fd-a4f8-a4ab74dce9c6,DISK], DatanodeInfoWithStorage[127.0.0.1:39616,DS-5a80d86c-c61f-43be-966a-9c98c195c6cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35052,DS-aef30138-30bb-4108-9b03-1a4870776863,DISK], DatanodeInfoWithStorage[127.0.0.1:37422,DS-0b068bb6-4b2e-49f0-b3e3-b593e54dd821,DISK], DatanodeInfoWithStorage[127.0.0.1:39984,DS-10fe6829-b906-4411-845a-82b669c7c4d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41808,DS-56863973-bde1-4bc4-b7f2-f2c2e921663c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-848398770-172.17.0.21-1596980406074:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41970,DS-3ba629f1-7a36-48f9-9b95-f9a6859b62bf,DISK], DatanodeInfoWithStorage[127.0.0.1:45855,DS-3566aa4c-5240-4494-879f-14c9e3cdf281,DISK], DatanodeInfoWithStorage[127.0.0.1:46645,DS-79170774-c345-46b5-8576-d0c961954543,DISK], DatanodeInfoWithStorage[127.0.0.1:43105,DS-9d28e868-d279-4141-91ab-ba5c11481c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:41857,DS-b58c1dc3-bf6f-4166-bdfe-cfc1394a04dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44456,DS-878c007b-0435-4749-a33b-08b1a487cc6c,DISK], DatanodeInfoWithStorage[127.0.0.1:41242,DS-df4d4839-94d7-4ba7-b7af-610d1c943127,DISK], DatanodeInfoWithStorage[127.0.0.1:32838,DS-5074898e-1637-4eea-b972-bbcbcb22ae60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-848398770-172.17.0.21-1596980406074:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41970,DS-3ba629f1-7a36-48f9-9b95-f9a6859b62bf,DISK], DatanodeInfoWithStorage[127.0.0.1:45855,DS-3566aa4c-5240-4494-879f-14c9e3cdf281,DISK], DatanodeInfoWithStorage[127.0.0.1:46645,DS-79170774-c345-46b5-8576-d0c961954543,DISK], DatanodeInfoWithStorage[127.0.0.1:43105,DS-9d28e868-d279-4141-91ab-ba5c11481c2f,DISK], DatanodeInfoWithStorage[127.0.0.1:41857,DS-b58c1dc3-bf6f-4166-bdfe-cfc1394a04dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44456,DS-878c007b-0435-4749-a33b-08b1a487cc6c,DISK], DatanodeInfoWithStorage[127.0.0.1:41242,DS-df4d4839-94d7-4ba7-b7af-610d1c943127,DISK], DatanodeInfoWithStorage[127.0.0.1:32838,DS-5074898e-1637-4eea-b972-bbcbcb22ae60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1793632851-172.17.0.21-1596980496074:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46485,DS-36368acd-655c-4f0b-a520-cca9b02b4574,DISK], DatanodeInfoWithStorage[127.0.0.1:36283,DS-aa8bc2aa-5fdf-423e-a090-0c2fff78a9de,DISK], DatanodeInfoWithStorage[127.0.0.1:35272,DS-e1f15a9b-bb29-47d4-8db1-9b71190e3243,DISK], DatanodeInfoWithStorage[127.0.0.1:35412,DS-9ffbe91b-7c97-422b-b63d-c15be03ec68c,DISK], DatanodeInfoWithStorage[127.0.0.1:41278,DS-19d50be9-f937-4a06-8ac8-7fa55375a9dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38518,DS-972797a6-ada8-4a36-8f58-d0caa6d5acb9,DISK], DatanodeInfoWithStorage[127.0.0.1:42049,DS-d7395768-5a71-4fad-842f-8f526118e9ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37357,DS-c530000a-00da-4ccb-8f21-998daf7cabb2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1793632851-172.17.0.21-1596980496074:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46485,DS-36368acd-655c-4f0b-a520-cca9b02b4574,DISK], DatanodeInfoWithStorage[127.0.0.1:36283,DS-aa8bc2aa-5fdf-423e-a090-0c2fff78a9de,DISK], DatanodeInfoWithStorage[127.0.0.1:35272,DS-e1f15a9b-bb29-47d4-8db1-9b71190e3243,DISK], DatanodeInfoWithStorage[127.0.0.1:35412,DS-9ffbe91b-7c97-422b-b63d-c15be03ec68c,DISK], DatanodeInfoWithStorage[127.0.0.1:41278,DS-19d50be9-f937-4a06-8ac8-7fa55375a9dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38518,DS-972797a6-ada8-4a36-8f58-d0caa6d5acb9,DISK], DatanodeInfoWithStorage[127.0.0.1:42049,DS-d7395768-5a71-4fad-842f-8f526118e9ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37357,DS-c530000a-00da-4ccb-8f21-998daf7cabb2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2019057735-172.17.0.21-1596980597276:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42370,DS-4a285492-3282-4583-afcb-ce2aa8aa3f57,DISK], DatanodeInfoWithStorage[127.0.0.1:43018,DS-295a086c-41b8-493a-b1b8-dee9737d4098,DISK], DatanodeInfoWithStorage[127.0.0.1:38997,DS-0be63a4c-3722-48f1-be0a-075a4cdecd69,DISK], DatanodeInfoWithStorage[127.0.0.1:36362,DS-f378a691-b39c-4250-acd3-44db043c6618,DISK], DatanodeInfoWithStorage[127.0.0.1:35450,DS-2f473340-af3a-4971-8a85-d2899ac78232,DISK], DatanodeInfoWithStorage[127.0.0.1:44084,DS-ad60e2f3-65b3-4d5e-b930-28ad638c935c,DISK], DatanodeInfoWithStorage[127.0.0.1:42788,DS-d7d37e08-e415-4cd0-97f3-377b5493dada,DISK], DatanodeInfoWithStorage[127.0.0.1:33867,DS-e056de77-0a1a-4334-8ec7-9fad7426f484,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2019057735-172.17.0.21-1596980597276:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42370,DS-4a285492-3282-4583-afcb-ce2aa8aa3f57,DISK], DatanodeInfoWithStorage[127.0.0.1:43018,DS-295a086c-41b8-493a-b1b8-dee9737d4098,DISK], DatanodeInfoWithStorage[127.0.0.1:38997,DS-0be63a4c-3722-48f1-be0a-075a4cdecd69,DISK], DatanodeInfoWithStorage[127.0.0.1:36362,DS-f378a691-b39c-4250-acd3-44db043c6618,DISK], DatanodeInfoWithStorage[127.0.0.1:35450,DS-2f473340-af3a-4971-8a85-d2899ac78232,DISK], DatanodeInfoWithStorage[127.0.0.1:44084,DS-ad60e2f3-65b3-4d5e-b930-28ad638c935c,DISK], DatanodeInfoWithStorage[127.0.0.1:42788,DS-d7d37e08-e415-4cd0-97f3-377b5493dada,DISK], DatanodeInfoWithStorage[127.0.0.1:33867,DS-e056de77-0a1a-4334-8ec7-9fad7426f484,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-67810502-172.17.0.21-1596980659483:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36399,DS-32cc8221-bd88-4ba5-b97c-904cfeeb6c90,DISK], DatanodeInfoWithStorage[127.0.0.1:41794,DS-e11faf60-7552-4e60-816a-7845cd55e7a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36696,DS-1ed07098-e91d-4047-8d0f-12dfc69050c9,DISK], DatanodeInfoWithStorage[127.0.0.1:40249,DS-c754b650-6545-47f7-b650-2a94daa26999,DISK], DatanodeInfoWithStorage[127.0.0.1:34664,DS-2b2e3250-efe6-41bb-8da8-1facfd34b95e,DISK], DatanodeInfoWithStorage[127.0.0.1:42133,DS-32d10769-844e-4225-b9fd-64cd0fdeee65,DISK], DatanodeInfoWithStorage[127.0.0.1:46711,DS-ae772f9e-5a6e-4358-a064-4021b85ea246,DISK], DatanodeInfoWithStorage[127.0.0.1:39177,DS-006f65a0-1ab3-4fd5-9871-fcb253f5aa69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-67810502-172.17.0.21-1596980659483:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36399,DS-32cc8221-bd88-4ba5-b97c-904cfeeb6c90,DISK], DatanodeInfoWithStorage[127.0.0.1:41794,DS-e11faf60-7552-4e60-816a-7845cd55e7a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36696,DS-1ed07098-e91d-4047-8d0f-12dfc69050c9,DISK], DatanodeInfoWithStorage[127.0.0.1:40249,DS-c754b650-6545-47f7-b650-2a94daa26999,DISK], DatanodeInfoWithStorage[127.0.0.1:34664,DS-2b2e3250-efe6-41bb-8da8-1facfd34b95e,DISK], DatanodeInfoWithStorage[127.0.0.1:42133,DS-32d10769-844e-4225-b9fd-64cd0fdeee65,DISK], DatanodeInfoWithStorage[127.0.0.1:46711,DS-ae772f9e-5a6e-4358-a064-4021b85ea246,DISK], DatanodeInfoWithStorage[127.0.0.1:39177,DS-006f65a0-1ab3-4fd5-9871-fcb253f5aa69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-42318660-172.17.0.21-1596980826122:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44926,DS-42c0a9d2-caa5-4137-965e-8a0bcc4246e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44745,DS-3d96b878-b3f2-4f5f-b328-4e3ea23bfda1,DISK], DatanodeInfoWithStorage[127.0.0.1:35600,DS-1e9d7608-0927-4d77-89a4-5e84b2560dee,DISK], DatanodeInfoWithStorage[127.0.0.1:45281,DS-b4aedd13-94c4-4001-816d-232e05e16b33,DISK], DatanodeInfoWithStorage[127.0.0.1:42658,DS-deadea28-f993-45ce-b6ed-648112585e37,DISK], DatanodeInfoWithStorage[127.0.0.1:35472,DS-192ac111-df3e-4a65-a2e2-64626e11583e,DISK], DatanodeInfoWithStorage[127.0.0.1:42086,DS-cf7f46e0-3847-4237-843a-c5dec9a832a6,DISK], DatanodeInfoWithStorage[127.0.0.1:43577,DS-9319e584-4811-483f-a2a6-e4b62cf0d8a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-42318660-172.17.0.21-1596980826122:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44926,DS-42c0a9d2-caa5-4137-965e-8a0bcc4246e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44745,DS-3d96b878-b3f2-4f5f-b328-4e3ea23bfda1,DISK], DatanodeInfoWithStorage[127.0.0.1:35600,DS-1e9d7608-0927-4d77-89a4-5e84b2560dee,DISK], DatanodeInfoWithStorage[127.0.0.1:45281,DS-b4aedd13-94c4-4001-816d-232e05e16b33,DISK], DatanodeInfoWithStorage[127.0.0.1:42658,DS-deadea28-f993-45ce-b6ed-648112585e37,DISK], DatanodeInfoWithStorage[127.0.0.1:35472,DS-192ac111-df3e-4a65-a2e2-64626e11583e,DISK], DatanodeInfoWithStorage[127.0.0.1:42086,DS-cf7f46e0-3847-4237-843a-c5dec9a832a6,DISK], DatanodeInfoWithStorage[127.0.0.1:43577,DS-9319e584-4811-483f-a2a6-e4b62cf0d8a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-964940545-172.17.0.21-1596981252794:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41782,DS-bee46cdf-f942-4518-9ad4-dbffa2dcf9a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39090,DS-f86aaaaf-80e1-4eda-b324-5e04222cfd71,DISK], DatanodeInfoWithStorage[127.0.0.1:38929,DS-c1f3e0b0-29d6-4aeb-9b00-d30231e75585,DISK], DatanodeInfoWithStorage[127.0.0.1:34905,DS-5e054b3a-781a-49c2-9fd0-b752c929e98a,DISK], DatanodeInfoWithStorage[127.0.0.1:42780,DS-530d0f91-a3b6-45f8-9f74-8a64f908321e,DISK], DatanodeInfoWithStorage[127.0.0.1:37504,DS-f69b980d-7a53-4319-902b-15fb99c4561b,DISK], DatanodeInfoWithStorage[127.0.0.1:37021,DS-9aeafa4d-b8b2-48f0-bb7c-b1e275528d4f,DISK], DatanodeInfoWithStorage[127.0.0.1:39370,DS-87c7de32-4556-4864-bea9-95b291325e68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-964940545-172.17.0.21-1596981252794:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41782,DS-bee46cdf-f942-4518-9ad4-dbffa2dcf9a7,DISK], DatanodeInfoWithStorage[127.0.0.1:39090,DS-f86aaaaf-80e1-4eda-b324-5e04222cfd71,DISK], DatanodeInfoWithStorage[127.0.0.1:38929,DS-c1f3e0b0-29d6-4aeb-9b00-d30231e75585,DISK], DatanodeInfoWithStorage[127.0.0.1:34905,DS-5e054b3a-781a-49c2-9fd0-b752c929e98a,DISK], DatanodeInfoWithStorage[127.0.0.1:42780,DS-530d0f91-a3b6-45f8-9f74-8a64f908321e,DISK], DatanodeInfoWithStorage[127.0.0.1:37504,DS-f69b980d-7a53-4319-902b-15fb99c4561b,DISK], DatanodeInfoWithStorage[127.0.0.1:37021,DS-9aeafa4d-b8b2-48f0-bb7c-b1e275528d4f,DISK], DatanodeInfoWithStorage[127.0.0.1:39370,DS-87c7de32-4556-4864-bea9-95b291325e68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1827163747-172.17.0.21-1596982051418:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42329,DS-3bcc27ed-7da8-48c6-ab64-4cf64867c27f,DISK], DatanodeInfoWithStorage[127.0.0.1:34573,DS-20416b1b-a953-4e80-b66b-4c176f861afb,DISK], DatanodeInfoWithStorage[127.0.0.1:33224,DS-93778bec-d782-4a34-8bb4-75031a6e6bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:42436,DS-b004b6bd-6570-40c2-8ece-ad80ce3593d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43892,DS-ec372e95-cd9f-4703-a779-857453439346,DISK], DatanodeInfoWithStorage[127.0.0.1:42645,DS-21a1b082-0459-4a1e-be02-a93127a72769,DISK], DatanodeInfoWithStorage[127.0.0.1:40418,DS-f2d363b0-33e8-4fa9-a201-64e2b7ae259f,DISK], DatanodeInfoWithStorage[127.0.0.1:38903,DS-b9dcc369-47e1-4e28-98db-1c6094864191,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1827163747-172.17.0.21-1596982051418:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42329,DS-3bcc27ed-7da8-48c6-ab64-4cf64867c27f,DISK], DatanodeInfoWithStorage[127.0.0.1:34573,DS-20416b1b-a953-4e80-b66b-4c176f861afb,DISK], DatanodeInfoWithStorage[127.0.0.1:33224,DS-93778bec-d782-4a34-8bb4-75031a6e6bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:42436,DS-b004b6bd-6570-40c2-8ece-ad80ce3593d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43892,DS-ec372e95-cd9f-4703-a779-857453439346,DISK], DatanodeInfoWithStorage[127.0.0.1:42645,DS-21a1b082-0459-4a1e-be02-a93127a72769,DISK], DatanodeInfoWithStorage[127.0.0.1:40418,DS-f2d363b0-33e8-4fa9-a201-64e2b7ae259f,DISK], DatanodeInfoWithStorage[127.0.0.1:38903,DS-b9dcc369-47e1-4e28-98db-1c6094864191,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1958659617-172.17.0.21-1596982174576:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34539,DS-6e16af26-6b92-4921-9fde-d6d2f7ae3930,DISK], DatanodeInfoWithStorage[127.0.0.1:40124,DS-d0945133-db07-4300-8b26-1114ebcf838b,DISK], DatanodeInfoWithStorage[127.0.0.1:38606,DS-4f54419f-b8df-429a-9a16-89b172d43f6a,DISK], DatanodeInfoWithStorage[127.0.0.1:41271,DS-8c824f3c-bdfd-4bf9-b5f9-aff02e807625,DISK], DatanodeInfoWithStorage[127.0.0.1:46553,DS-1c3b15bc-72a1-47b5-8c3d-17ab7891e1d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35618,DS-be4c3fd8-6cd9-4545-a92d-5a62088847f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42983,DS-c482b112-a25a-4cff-ba25-a6082304d8a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39380,DS-a1b0aaff-e7be-461d-a871-ba5dd78d4373,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1958659617-172.17.0.21-1596982174576:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34539,DS-6e16af26-6b92-4921-9fde-d6d2f7ae3930,DISK], DatanodeInfoWithStorage[127.0.0.1:40124,DS-d0945133-db07-4300-8b26-1114ebcf838b,DISK], DatanodeInfoWithStorage[127.0.0.1:38606,DS-4f54419f-b8df-429a-9a16-89b172d43f6a,DISK], DatanodeInfoWithStorage[127.0.0.1:41271,DS-8c824f3c-bdfd-4bf9-b5f9-aff02e807625,DISK], DatanodeInfoWithStorage[127.0.0.1:46553,DS-1c3b15bc-72a1-47b5-8c3d-17ab7891e1d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35618,DS-be4c3fd8-6cd9-4545-a92d-5a62088847f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42983,DS-c482b112-a25a-4cff-ba25-a6082304d8a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39380,DS-a1b0aaff-e7be-461d-a871-ba5dd78d4373,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1251806940-172.17.0.21-1596982424779:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41645,DS-962b9136-4c96-4809-9257-86ec8c842251,DISK], DatanodeInfoWithStorage[127.0.0.1:38465,DS-6ab5620a-2b73-4a70-bdbb-1f73188daeeb,DISK], DatanodeInfoWithStorage[127.0.0.1:45375,DS-bb57956b-0090-4e71-87ae-9e3778378ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:38826,DS-a0bb1610-edd7-42dc-a7e1-97f299f0a379,DISK], DatanodeInfoWithStorage[127.0.0.1:45124,DS-5190e6af-23ea-4bb5-ae27-ba020a911dad,DISK], DatanodeInfoWithStorage[127.0.0.1:35552,DS-97bcc1e6-f0d2-4aaf-9ade-d5de58e1f2c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46361,DS-aa614b81-b5a7-4875-b7b7-880167937ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:42196,DS-edd83d99-1d4b-4cc3-bcad-58e8524c8f42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1251806940-172.17.0.21-1596982424779:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41645,DS-962b9136-4c96-4809-9257-86ec8c842251,DISK], DatanodeInfoWithStorage[127.0.0.1:38465,DS-6ab5620a-2b73-4a70-bdbb-1f73188daeeb,DISK], DatanodeInfoWithStorage[127.0.0.1:45375,DS-bb57956b-0090-4e71-87ae-9e3778378ed8,DISK], DatanodeInfoWithStorage[127.0.0.1:38826,DS-a0bb1610-edd7-42dc-a7e1-97f299f0a379,DISK], DatanodeInfoWithStorage[127.0.0.1:45124,DS-5190e6af-23ea-4bb5-ae27-ba020a911dad,DISK], DatanodeInfoWithStorage[127.0.0.1:35552,DS-97bcc1e6-f0d2-4aaf-9ade-d5de58e1f2c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46361,DS-aa614b81-b5a7-4875-b7b7-880167937ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:42196,DS-edd83d99-1d4b-4cc3-bcad-58e8524c8f42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-493123413-172.17.0.21-1596982458602:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46744,DS-7d27647f-f8db-4e9d-8225-cd6b5a61492a,DISK], DatanodeInfoWithStorage[127.0.0.1:38905,DS-03b970fb-ab51-475d-bbac-4b24bfe3b1e1,DISK], DatanodeInfoWithStorage[127.0.0.1:36257,DS-99c45f2a-1043-4720-bf7e-e189f1805bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:38313,DS-d7090181-fb02-4627-9c68-31852c55aa9d,DISK], DatanodeInfoWithStorage[127.0.0.1:33065,DS-6e055f90-52e6-4d9f-9842-f41997b2d065,DISK], DatanodeInfoWithStorage[127.0.0.1:34785,DS-92d885bd-4bd4-465a-a5af-c6eca9a1776c,DISK], DatanodeInfoWithStorage[127.0.0.1:33009,DS-b96759fb-b339-4dda-8a14-f0c34d5da0ce,DISK], DatanodeInfoWithStorage[127.0.0.1:39635,DS-4524209a-f43c-4375-be70-95ca91781d43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-493123413-172.17.0.21-1596982458602:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46744,DS-7d27647f-f8db-4e9d-8225-cd6b5a61492a,DISK], DatanodeInfoWithStorage[127.0.0.1:38905,DS-03b970fb-ab51-475d-bbac-4b24bfe3b1e1,DISK], DatanodeInfoWithStorage[127.0.0.1:36257,DS-99c45f2a-1043-4720-bf7e-e189f1805bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:38313,DS-d7090181-fb02-4627-9c68-31852c55aa9d,DISK], DatanodeInfoWithStorage[127.0.0.1:33065,DS-6e055f90-52e6-4d9f-9842-f41997b2d065,DISK], DatanodeInfoWithStorage[127.0.0.1:34785,DS-92d885bd-4bd4-465a-a5af-c6eca9a1776c,DISK], DatanodeInfoWithStorage[127.0.0.1:33009,DS-b96759fb-b339-4dda-8a14-f0c34d5da0ce,DISK], DatanodeInfoWithStorage[127.0.0.1:39635,DS-4524209a-f43c-4375-be70-95ca91781d43,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-778240265-172.17.0.21-1596982752131:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35243,DS-e9e4f846-b9ea-4b5d-9b4a-c58d05079ce3,DISK], DatanodeInfoWithStorage[127.0.0.1:37836,DS-e7e89659-a60c-4a78-91f9-c46bcdde5fbd,DISK], DatanodeInfoWithStorage[127.0.0.1:33978,DS-64aa928d-a45e-45e6-b34a-b69a746f1a05,DISK], DatanodeInfoWithStorage[127.0.0.1:42767,DS-61191147-c59c-4d57-9259-3f1677816d98,DISK], DatanodeInfoWithStorage[127.0.0.1:34455,DS-58a27466-de87-4855-961a-40a231f92e55,DISK], DatanodeInfoWithStorage[127.0.0.1:40293,DS-1cf8c8d3-5825-4215-930c-26804ff4d6d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35331,DS-994fd39a-a4bb-41c8-afde-da0eee8156b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36754,DS-d0feeb21-9eee-4fa1-99b8-ad695b509b6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-778240265-172.17.0.21-1596982752131:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35243,DS-e9e4f846-b9ea-4b5d-9b4a-c58d05079ce3,DISK], DatanodeInfoWithStorage[127.0.0.1:37836,DS-e7e89659-a60c-4a78-91f9-c46bcdde5fbd,DISK], DatanodeInfoWithStorage[127.0.0.1:33978,DS-64aa928d-a45e-45e6-b34a-b69a746f1a05,DISK], DatanodeInfoWithStorage[127.0.0.1:42767,DS-61191147-c59c-4d57-9259-3f1677816d98,DISK], DatanodeInfoWithStorage[127.0.0.1:34455,DS-58a27466-de87-4855-961a-40a231f92e55,DISK], DatanodeInfoWithStorage[127.0.0.1:40293,DS-1cf8c8d3-5825-4215-930c-26804ff4d6d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35331,DS-994fd39a-a4bb-41c8-afde-da0eee8156b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36754,DS-d0feeb21-9eee-4fa1-99b8-ad695b509b6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1653980272-172.17.0.21-1596983066248:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38525,DS-8646363e-4d1f-4a50-8305-97df36854925,DISK], DatanodeInfoWithStorage[127.0.0.1:41161,DS-ade799cf-f6f4-47a6-acc3-24b5cd1f4d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:42994,DS-68f09c04-e7d6-40f2-9a15-6d8ae6489016,DISK], DatanodeInfoWithStorage[127.0.0.1:41368,DS-9988ce50-95bc-43cb-a9f2-f0abd22fdeb9,DISK], DatanodeInfoWithStorage[127.0.0.1:40391,DS-5e301b79-f14e-47c6-840a-08bb85211c78,DISK], DatanodeInfoWithStorage[127.0.0.1:37824,DS-7ae394d3-b6b9-4bd3-8739-c249afe4ad85,DISK], DatanodeInfoWithStorage[127.0.0.1:40138,DS-cfa855de-46f4-4020-a81a-c89d8452c1d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35298,DS-e495344f-de49-4dbf-931a-34016cf668ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1653980272-172.17.0.21-1596983066248:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38525,DS-8646363e-4d1f-4a50-8305-97df36854925,DISK], DatanodeInfoWithStorage[127.0.0.1:41161,DS-ade799cf-f6f4-47a6-acc3-24b5cd1f4d9c,DISK], DatanodeInfoWithStorage[127.0.0.1:42994,DS-68f09c04-e7d6-40f2-9a15-6d8ae6489016,DISK], DatanodeInfoWithStorage[127.0.0.1:41368,DS-9988ce50-95bc-43cb-a9f2-f0abd22fdeb9,DISK], DatanodeInfoWithStorage[127.0.0.1:40391,DS-5e301b79-f14e-47c6-840a-08bb85211c78,DISK], DatanodeInfoWithStorage[127.0.0.1:37824,DS-7ae394d3-b6b9-4bd3-8739-c249afe4ad85,DISK], DatanodeInfoWithStorage[127.0.0.1:40138,DS-cfa855de-46f4-4020-a81a-c89d8452c1d8,DISK], DatanodeInfoWithStorage[127.0.0.1:35298,DS-e495344f-de49-4dbf-931a-34016cf668ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1623243003-172.17.0.21-1596983499465:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43826,DS-850af0ab-854f-4e04-93a5-4aaf1534d85a,DISK], DatanodeInfoWithStorage[127.0.0.1:40529,DS-64828f2a-3d05-4937-be8a-849ccf779662,DISK], DatanodeInfoWithStorage[127.0.0.1:39806,DS-b0c24a0e-cc6a-4b93-8b70-9088ccbf601b,DISK], DatanodeInfoWithStorage[127.0.0.1:42249,DS-0e1b508d-44c1-49ba-8ab2-f794de3951bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36791,DS-a076f8ad-bdd6-4bb9-90cd-295548d501a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40759,DS-a40a4912-a53b-43b8-bf3e-3d972d575f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:41287,DS-d5438129-b4a7-4e1f-8a55-9495319a4ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:39415,DS-249f6e9b-f6b7-4321-a53b-78c45a23e047,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1623243003-172.17.0.21-1596983499465:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43826,DS-850af0ab-854f-4e04-93a5-4aaf1534d85a,DISK], DatanodeInfoWithStorage[127.0.0.1:40529,DS-64828f2a-3d05-4937-be8a-849ccf779662,DISK], DatanodeInfoWithStorage[127.0.0.1:39806,DS-b0c24a0e-cc6a-4b93-8b70-9088ccbf601b,DISK], DatanodeInfoWithStorage[127.0.0.1:42249,DS-0e1b508d-44c1-49ba-8ab2-f794de3951bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36791,DS-a076f8ad-bdd6-4bb9-90cd-295548d501a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40759,DS-a40a4912-a53b-43b8-bf3e-3d972d575f6c,DISK], DatanodeInfoWithStorage[127.0.0.1:41287,DS-d5438129-b4a7-4e1f-8a55-9495319a4ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:39415,DS-249f6e9b-f6b7-4321-a53b-78c45a23e047,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1746433309-172.17.0.21-1596984011106:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45654,DS-d19f82cd-dd80-4e1b-a449-fab440a93998,DISK], DatanodeInfoWithStorage[127.0.0.1:44595,DS-8d67b6c8-bc03-4a48-aaed-b8a2aacbd14d,DISK], DatanodeInfoWithStorage[127.0.0.1:36135,DS-3c91b09c-4287-411a-a2d3-8a6e31d6b223,DISK], DatanodeInfoWithStorage[127.0.0.1:36054,DS-114f96e3-ca44-4078-ac11-de355386d9f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42626,DS-55e62b02-5572-44a1-988b-fcbe554cfdb4,DISK], DatanodeInfoWithStorage[127.0.0.1:40529,DS-1e15f461-8533-46f1-924c-16b0a6c085bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35922,DS-e924b02c-5183-4441-b26d-4385722c8075,DISK], DatanodeInfoWithStorage[127.0.0.1:40142,DS-2be5c80a-f91e-41f5-ab34-4fe932972994,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1746433309-172.17.0.21-1596984011106:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45654,DS-d19f82cd-dd80-4e1b-a449-fab440a93998,DISK], DatanodeInfoWithStorage[127.0.0.1:44595,DS-8d67b6c8-bc03-4a48-aaed-b8a2aacbd14d,DISK], DatanodeInfoWithStorage[127.0.0.1:36135,DS-3c91b09c-4287-411a-a2d3-8a6e31d6b223,DISK], DatanodeInfoWithStorage[127.0.0.1:36054,DS-114f96e3-ca44-4078-ac11-de355386d9f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42626,DS-55e62b02-5572-44a1-988b-fcbe554cfdb4,DISK], DatanodeInfoWithStorage[127.0.0.1:40529,DS-1e15f461-8533-46f1-924c-16b0a6c085bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35922,DS-e924b02c-5183-4441-b26d-4385722c8075,DISK], DatanodeInfoWithStorage[127.0.0.1:40142,DS-2be5c80a-f91e-41f5-ab34-4fe932972994,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 4822
