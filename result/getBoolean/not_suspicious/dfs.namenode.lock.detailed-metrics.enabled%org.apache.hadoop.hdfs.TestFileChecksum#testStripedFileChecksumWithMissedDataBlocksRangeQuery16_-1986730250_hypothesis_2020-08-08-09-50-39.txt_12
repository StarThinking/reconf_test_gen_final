reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-27219005-172.17.0.14-1596880503772:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46863,DS-fd174240-cfc4-43ba-8fd0-e422be8d4cad,DISK], DatanodeInfoWithStorage[127.0.0.1:36508,DS-bc60fb15-ce15-45fc-b3b4-6c9eeff0c701,DISK], DatanodeInfoWithStorage[127.0.0.1:40898,DS-e13d1490-af33-44c3-b756-d0686ef8b066,DISK], DatanodeInfoWithStorage[127.0.0.1:46497,DS-ed47b451-e5ef-452c-b918-a4cdcdb2c01d,DISK], DatanodeInfoWithStorage[127.0.0.1:40554,DS-738b52dd-23f0-4136-a73a-292045c5eb05,DISK], DatanodeInfoWithStorage[127.0.0.1:46369,DS-3108a73f-c191-4074-b761-4467dbb27604,DISK], DatanodeInfoWithStorage[127.0.0.1:46533,DS-9bb247e4-f734-40bf-a062-f4714e21193d,DISK], DatanodeInfoWithStorage[127.0.0.1:36397,DS-520edf0a-99df-4d70-9186-9a65f2913f1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-27219005-172.17.0.14-1596880503772:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46863,DS-fd174240-cfc4-43ba-8fd0-e422be8d4cad,DISK], DatanodeInfoWithStorage[127.0.0.1:36508,DS-bc60fb15-ce15-45fc-b3b4-6c9eeff0c701,DISK], DatanodeInfoWithStorage[127.0.0.1:40898,DS-e13d1490-af33-44c3-b756-d0686ef8b066,DISK], DatanodeInfoWithStorage[127.0.0.1:46497,DS-ed47b451-e5ef-452c-b918-a4cdcdb2c01d,DISK], DatanodeInfoWithStorage[127.0.0.1:40554,DS-738b52dd-23f0-4136-a73a-292045c5eb05,DISK], DatanodeInfoWithStorage[127.0.0.1:46369,DS-3108a73f-c191-4074-b761-4467dbb27604,DISK], DatanodeInfoWithStorage[127.0.0.1:46533,DS-9bb247e4-f734-40bf-a062-f4714e21193d,DISK], DatanodeInfoWithStorage[127.0.0.1:36397,DS-520edf0a-99df-4d70-9186-9a65f2913f1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1770283056-172.17.0.14-1596881739495:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40308,DS-23fcdc82-8a6a-4634-b5d6-d9f6745943e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35680,DS-894734e9-8735-4cbb-b52b-8642acb8c11c,DISK], DatanodeInfoWithStorage[127.0.0.1:45354,DS-132db053-c76b-4637-9f92-61c05d01b7e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33978,DS-6d42a005-1027-4275-b166-6bc1a0642f95,DISK], DatanodeInfoWithStorage[127.0.0.1:34841,DS-763d77c5-55db-4eed-965f-fd25fe1c91fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42051,DS-9b06973f-345a-4548-996b-c1d5455e7819,DISK], DatanodeInfoWithStorage[127.0.0.1:38125,DS-74d4cd10-156c-4b32-a305-95ebc6fdf6c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36922,DS-d8f7ca70-7674-4625-84c9-64d4ad0c6592,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1770283056-172.17.0.14-1596881739495:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40308,DS-23fcdc82-8a6a-4634-b5d6-d9f6745943e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35680,DS-894734e9-8735-4cbb-b52b-8642acb8c11c,DISK], DatanodeInfoWithStorage[127.0.0.1:45354,DS-132db053-c76b-4637-9f92-61c05d01b7e4,DISK], DatanodeInfoWithStorage[127.0.0.1:33978,DS-6d42a005-1027-4275-b166-6bc1a0642f95,DISK], DatanodeInfoWithStorage[127.0.0.1:34841,DS-763d77c5-55db-4eed-965f-fd25fe1c91fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42051,DS-9b06973f-345a-4548-996b-c1d5455e7819,DISK], DatanodeInfoWithStorage[127.0.0.1:38125,DS-74d4cd10-156c-4b32-a305-95ebc6fdf6c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36922,DS-d8f7ca70-7674-4625-84c9-64d4ad0c6592,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1299672215-172.17.0.14-1596882626570:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42581,DS-b9cbcf5d-b325-4888-8c44-0880755b84b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42969,DS-de1d2f95-9edb-4f17-8cea-8af917bf0484,DISK], DatanodeInfoWithStorage[127.0.0.1:36426,DS-37213b9b-1d25-439c-8fd9-62f0e0836afd,DISK], DatanodeInfoWithStorage[127.0.0.1:43714,DS-fda8fe9c-d9d1-4490-888e-096aafaee658,DISK], DatanodeInfoWithStorage[127.0.0.1:34395,DS-ed859096-7d8d-43c3-b155-6acb5de35050,DISK], DatanodeInfoWithStorage[127.0.0.1:40034,DS-16a11dd3-2992-469e-86c3-0f5931c9f274,DISK], DatanodeInfoWithStorage[127.0.0.1:35643,DS-a12ce6b6-e2b1-46a9-8139-55dee6562103,DISK], DatanodeInfoWithStorage[127.0.0.1:43968,DS-c1dd3136-caba-4788-8a40-79bb0e19eeda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1299672215-172.17.0.14-1596882626570:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42581,DS-b9cbcf5d-b325-4888-8c44-0880755b84b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42969,DS-de1d2f95-9edb-4f17-8cea-8af917bf0484,DISK], DatanodeInfoWithStorage[127.0.0.1:36426,DS-37213b9b-1d25-439c-8fd9-62f0e0836afd,DISK], DatanodeInfoWithStorage[127.0.0.1:43714,DS-fda8fe9c-d9d1-4490-888e-096aafaee658,DISK], DatanodeInfoWithStorage[127.0.0.1:34395,DS-ed859096-7d8d-43c3-b155-6acb5de35050,DISK], DatanodeInfoWithStorage[127.0.0.1:40034,DS-16a11dd3-2992-469e-86c3-0f5931c9f274,DISK], DatanodeInfoWithStorage[127.0.0.1:35643,DS-a12ce6b6-e2b1-46a9-8139-55dee6562103,DISK], DatanodeInfoWithStorage[127.0.0.1:43968,DS-c1dd3136-caba-4788-8a40-79bb0e19eeda,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1678161178-172.17.0.14-1596882685598:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36302,DS-5fed33be-e85e-4fa9-bb27-fb7eba08e87c,DISK], DatanodeInfoWithStorage[127.0.0.1:41469,DS-e4e02bbc-a65c-439a-8444-86bba7d1a4e6,DISK], DatanodeInfoWithStorage[127.0.0.1:34423,DS-bc9953c4-447f-4848-b05e-66af033cfdbf,DISK], DatanodeInfoWithStorage[127.0.0.1:39553,DS-eea99913-9f22-43dc-9502-755f99c46cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:35861,DS-654ad52f-8b7a-4c61-8ad2-9e1ed387e4ce,DISK], DatanodeInfoWithStorage[127.0.0.1:43138,DS-52d7f804-b50c-4651-9070-d1de05fb5c60,DISK], DatanodeInfoWithStorage[127.0.0.1:45437,DS-c6faec94-7501-4c26-a4eb-d9cce34f1493,DISK], DatanodeInfoWithStorage[127.0.0.1:37803,DS-86bf0d1b-b0d5-4cb5-ac19-6f1c28a35dc6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1678161178-172.17.0.14-1596882685598:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36302,DS-5fed33be-e85e-4fa9-bb27-fb7eba08e87c,DISK], DatanodeInfoWithStorage[127.0.0.1:41469,DS-e4e02bbc-a65c-439a-8444-86bba7d1a4e6,DISK], DatanodeInfoWithStorage[127.0.0.1:34423,DS-bc9953c4-447f-4848-b05e-66af033cfdbf,DISK], DatanodeInfoWithStorage[127.0.0.1:39553,DS-eea99913-9f22-43dc-9502-755f99c46cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:35861,DS-654ad52f-8b7a-4c61-8ad2-9e1ed387e4ce,DISK], DatanodeInfoWithStorage[127.0.0.1:43138,DS-52d7f804-b50c-4651-9070-d1de05fb5c60,DISK], DatanodeInfoWithStorage[127.0.0.1:45437,DS-c6faec94-7501-4c26-a4eb-d9cce34f1493,DISK], DatanodeInfoWithStorage[127.0.0.1:37803,DS-86bf0d1b-b0d5-4cb5-ac19-6f1c28a35dc6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-119199958-172.17.0.14-1596882722229:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45855,DS-bbeec898-6ecf-411f-beb2-6321532dec1b,DISK], DatanodeInfoWithStorage[127.0.0.1:41304,DS-801e3ec9-1250-42e7-a81f-d15d3b1fea61,DISK], DatanodeInfoWithStorage[127.0.0.1:41462,DS-a3338226-8539-496e-9257-5ae93c2301b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39430,DS-b6d0da5d-3799-4212-b147-d4e95b71def4,DISK], DatanodeInfoWithStorage[127.0.0.1:44892,DS-bfce8436-7c7b-4cfd-baa6-3542e153c7b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44897,DS-7f015138-c7a8-49e1-87b4-3848d5ce2f97,DISK], DatanodeInfoWithStorage[127.0.0.1:33616,DS-c7bfe348-efc0-41e0-bbe9-637ebbb6060b,DISK], DatanodeInfoWithStorage[127.0.0.1:39171,DS-4df3eaa4-db8a-4a7d-a4dc-6347dd16ad49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-119199958-172.17.0.14-1596882722229:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45855,DS-bbeec898-6ecf-411f-beb2-6321532dec1b,DISK], DatanodeInfoWithStorage[127.0.0.1:41304,DS-801e3ec9-1250-42e7-a81f-d15d3b1fea61,DISK], DatanodeInfoWithStorage[127.0.0.1:41462,DS-a3338226-8539-496e-9257-5ae93c2301b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39430,DS-b6d0da5d-3799-4212-b147-d4e95b71def4,DISK], DatanodeInfoWithStorage[127.0.0.1:44892,DS-bfce8436-7c7b-4cfd-baa6-3542e153c7b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44897,DS-7f015138-c7a8-49e1-87b4-3848d5ce2f97,DISK], DatanodeInfoWithStorage[127.0.0.1:33616,DS-c7bfe348-efc0-41e0-bbe9-637ebbb6060b,DISK], DatanodeInfoWithStorage[127.0.0.1:39171,DS-4df3eaa4-db8a-4a7d-a4dc-6347dd16ad49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-621174991-172.17.0.14-1596882885853:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43196,DS-c144873c-b8ea-4973-9385-fd0950ac4e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:35247,DS-e2b433e6-cb4c-477f-81a3-f52488347505,DISK], DatanodeInfoWithStorage[127.0.0.1:34952,DS-c9e69a7b-f228-4c2f-ab2a-22dbbcba38ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35263,DS-76445f9f-33ef-44f3-afad-b1597cd58a45,DISK], DatanodeInfoWithStorage[127.0.0.1:46275,DS-b5cac416-45ea-42e0-9fbf-58e716f5e11d,DISK], DatanodeInfoWithStorage[127.0.0.1:34139,DS-020e9b52-bc5e-478e-8988-cf3bdb11d005,DISK], DatanodeInfoWithStorage[127.0.0.1:39360,DS-e7956efb-0f98-40b5-87f8-80c1c649dd5a,DISK], DatanodeInfoWithStorage[127.0.0.1:38780,DS-22bd7916-d86c-4578-b53f-89d2bdaddf07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-621174991-172.17.0.14-1596882885853:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43196,DS-c144873c-b8ea-4973-9385-fd0950ac4e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:35247,DS-e2b433e6-cb4c-477f-81a3-f52488347505,DISK], DatanodeInfoWithStorage[127.0.0.1:34952,DS-c9e69a7b-f228-4c2f-ab2a-22dbbcba38ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35263,DS-76445f9f-33ef-44f3-afad-b1597cd58a45,DISK], DatanodeInfoWithStorage[127.0.0.1:46275,DS-b5cac416-45ea-42e0-9fbf-58e716f5e11d,DISK], DatanodeInfoWithStorage[127.0.0.1:34139,DS-020e9b52-bc5e-478e-8988-cf3bdb11d005,DISK], DatanodeInfoWithStorage[127.0.0.1:39360,DS-e7956efb-0f98-40b5-87f8-80c1c649dd5a,DISK], DatanodeInfoWithStorage[127.0.0.1:38780,DS-22bd7916-d86c-4578-b53f-89d2bdaddf07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-835123180-172.17.0.14-1596883071494:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41633,DS-12b42d66-c416-46a5-b62e-2d7ad668bb17,DISK], DatanodeInfoWithStorage[127.0.0.1:42323,DS-a7e626b2-a451-4e35-bb51-ee3f762c4ef9,DISK], DatanodeInfoWithStorage[127.0.0.1:34632,DS-18c7d59a-b2bd-4676-a2d8-5561f933a4c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38354,DS-68f2ad83-dee0-41bc-a751-2ad38e9cb7b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36503,DS-139142b1-d220-4c74-845f-5cf5fd4ecb43,DISK], DatanodeInfoWithStorage[127.0.0.1:41159,DS-4487ad86-4ed8-4001-958f-8b4094fc8546,DISK], DatanodeInfoWithStorage[127.0.0.1:44114,DS-9e740656-7263-4dc5-8db5-6b3c2b1a3d82,DISK], DatanodeInfoWithStorage[127.0.0.1:37037,DS-945d1f2b-3d18-4998-96ac-484535419628,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-835123180-172.17.0.14-1596883071494:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41633,DS-12b42d66-c416-46a5-b62e-2d7ad668bb17,DISK], DatanodeInfoWithStorage[127.0.0.1:42323,DS-a7e626b2-a451-4e35-bb51-ee3f762c4ef9,DISK], DatanodeInfoWithStorage[127.0.0.1:34632,DS-18c7d59a-b2bd-4676-a2d8-5561f933a4c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38354,DS-68f2ad83-dee0-41bc-a751-2ad38e9cb7b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36503,DS-139142b1-d220-4c74-845f-5cf5fd4ecb43,DISK], DatanodeInfoWithStorage[127.0.0.1:41159,DS-4487ad86-4ed8-4001-958f-8b4094fc8546,DISK], DatanodeInfoWithStorage[127.0.0.1:44114,DS-9e740656-7263-4dc5-8db5-6b3c2b1a3d82,DISK], DatanodeInfoWithStorage[127.0.0.1:37037,DS-945d1f2b-3d18-4998-96ac-484535419628,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1038643582-172.17.0.14-1596883438167:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34561,DS-1659a289-459e-4e59-a069-da8135fe381f,DISK], DatanodeInfoWithStorage[127.0.0.1:36299,DS-b64326af-bd62-49e7-866f-2045dc5b97dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34354,DS-124a7d76-c086-407a-97dc-a46a7939c897,DISK], DatanodeInfoWithStorage[127.0.0.1:46248,DS-e5b6ca39-87a8-44c1-b2e1-50d957f4c5ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34055,DS-6f444599-4ff6-4db8-8663-ecfceb7e63d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40900,DS-2c51e3f1-5ba5-4c66-9578-68fec207213b,DISK], DatanodeInfoWithStorage[127.0.0.1:37273,DS-7ebf1d64-ddc5-4da6-a2cf-94b739a507fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41817,DS-20ff398a-df9b-4a03-9acf-6fc9f1d6837d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1038643582-172.17.0.14-1596883438167:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34561,DS-1659a289-459e-4e59-a069-da8135fe381f,DISK], DatanodeInfoWithStorage[127.0.0.1:36299,DS-b64326af-bd62-49e7-866f-2045dc5b97dd,DISK], DatanodeInfoWithStorage[127.0.0.1:34354,DS-124a7d76-c086-407a-97dc-a46a7939c897,DISK], DatanodeInfoWithStorage[127.0.0.1:46248,DS-e5b6ca39-87a8-44c1-b2e1-50d957f4c5ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34055,DS-6f444599-4ff6-4db8-8663-ecfceb7e63d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40900,DS-2c51e3f1-5ba5-4c66-9578-68fec207213b,DISK], DatanodeInfoWithStorage[127.0.0.1:37273,DS-7ebf1d64-ddc5-4da6-a2cf-94b739a507fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41817,DS-20ff398a-df9b-4a03-9acf-6fc9f1d6837d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1869066937-172.17.0.14-1596883547951:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45212,DS-3aca5a22-8356-4fb7-b2fe-7c78eb3ab558,DISK], DatanodeInfoWithStorage[127.0.0.1:41187,DS-c0dbe080-1c4f-45cd-a038-8d12a67d52d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42098,DS-935238fa-3f19-425c-9b1a-a97537a42c26,DISK], DatanodeInfoWithStorage[127.0.0.1:42454,DS-a1795a23-c172-4713-abae-3684d9b5645c,DISK], DatanodeInfoWithStorage[127.0.0.1:37286,DS-14c35f1b-8552-47ed-b9b3-14015013e566,DISK], DatanodeInfoWithStorage[127.0.0.1:43377,DS-3d526513-92df-4c12-be1a-e4596aef62d6,DISK], DatanodeInfoWithStorage[127.0.0.1:37093,DS-3b36790a-bfc5-481b-9964-50b7477d2d58,DISK], DatanodeInfoWithStorage[127.0.0.1:36321,DS-9b7b4ee7-3c74-4256-8200-20585fb4a99f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1869066937-172.17.0.14-1596883547951:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45212,DS-3aca5a22-8356-4fb7-b2fe-7c78eb3ab558,DISK], DatanodeInfoWithStorage[127.0.0.1:41187,DS-c0dbe080-1c4f-45cd-a038-8d12a67d52d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42098,DS-935238fa-3f19-425c-9b1a-a97537a42c26,DISK], DatanodeInfoWithStorage[127.0.0.1:42454,DS-a1795a23-c172-4713-abae-3684d9b5645c,DISK], DatanodeInfoWithStorage[127.0.0.1:37286,DS-14c35f1b-8552-47ed-b9b3-14015013e566,DISK], DatanodeInfoWithStorage[127.0.0.1:43377,DS-3d526513-92df-4c12-be1a-e4596aef62d6,DISK], DatanodeInfoWithStorage[127.0.0.1:37093,DS-3b36790a-bfc5-481b-9964-50b7477d2d58,DISK], DatanodeInfoWithStorage[127.0.0.1:36321,DS-9b7b4ee7-3c74-4256-8200-20585fb4a99f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-913427052-172.17.0.14-1596883691111:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44106,DS-d442549d-0637-45e6-9e54-adc29aa3a1df,DISK], DatanodeInfoWithStorage[127.0.0.1:34818,DS-d20ab5a5-8ae0-4829-9c5e-afdfe7a53253,DISK], DatanodeInfoWithStorage[127.0.0.1:41551,DS-fe60d505-f4ee-473d-b7b7-9137e6cdcb8b,DISK], DatanodeInfoWithStorage[127.0.0.1:45558,DS-c8c8ff7e-7cac-49b7-9035-f78c03673bfc,DISK], DatanodeInfoWithStorage[127.0.0.1:42008,DS-9269bf32-c5a5-4179-89ae-73f66b49dc02,DISK], DatanodeInfoWithStorage[127.0.0.1:32911,DS-e809943f-1dcf-4e61-9780-1c2c3bcbd5e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35178,DS-0e842558-2f77-4926-b505-77ea73f38265,DISK], DatanodeInfoWithStorage[127.0.0.1:40776,DS-0a33953c-95d5-4ac4-997a-07609e5906ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-913427052-172.17.0.14-1596883691111:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44106,DS-d442549d-0637-45e6-9e54-adc29aa3a1df,DISK], DatanodeInfoWithStorage[127.0.0.1:34818,DS-d20ab5a5-8ae0-4829-9c5e-afdfe7a53253,DISK], DatanodeInfoWithStorage[127.0.0.1:41551,DS-fe60d505-f4ee-473d-b7b7-9137e6cdcb8b,DISK], DatanodeInfoWithStorage[127.0.0.1:45558,DS-c8c8ff7e-7cac-49b7-9035-f78c03673bfc,DISK], DatanodeInfoWithStorage[127.0.0.1:42008,DS-9269bf32-c5a5-4179-89ae-73f66b49dc02,DISK], DatanodeInfoWithStorage[127.0.0.1:32911,DS-e809943f-1dcf-4e61-9780-1c2c3bcbd5e1,DISK], DatanodeInfoWithStorage[127.0.0.1:35178,DS-0e842558-2f77-4926-b505-77ea73f38265,DISK], DatanodeInfoWithStorage[127.0.0.1:40776,DS-0a33953c-95d5-4ac4-997a-07609e5906ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1919227812-172.17.0.14-1596883953688:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36156,DS-92a0e6a3-c1a2-4454-9478-d17d5d968b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:46147,DS-abc34325-951c-411f-a7ee-740c6768b3f9,DISK], DatanodeInfoWithStorage[127.0.0.1:40611,DS-c10f9ff8-cb1c-448b-8aae-53d5e106b1ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42038,DS-deafb03f-e418-45eb-a5b7-b9a110094943,DISK], DatanodeInfoWithStorage[127.0.0.1:38018,DS-171f94b6-f57b-43f6-98c1-d669a6393a50,DISK], DatanodeInfoWithStorage[127.0.0.1:46833,DS-bc3c72bd-bcf2-4b6c-9da1-b3dbf777e204,DISK], DatanodeInfoWithStorage[127.0.0.1:44091,DS-6c31596a-c2f0-419a-83fd-da91f7584c2c,DISK], DatanodeInfoWithStorage[127.0.0.1:33061,DS-793d02c6-30ff-4177-806c-d62d15dda761,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1919227812-172.17.0.14-1596883953688:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36156,DS-92a0e6a3-c1a2-4454-9478-d17d5d968b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:46147,DS-abc34325-951c-411f-a7ee-740c6768b3f9,DISK], DatanodeInfoWithStorage[127.0.0.1:40611,DS-c10f9ff8-cb1c-448b-8aae-53d5e106b1ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42038,DS-deafb03f-e418-45eb-a5b7-b9a110094943,DISK], DatanodeInfoWithStorage[127.0.0.1:38018,DS-171f94b6-f57b-43f6-98c1-d669a6393a50,DISK], DatanodeInfoWithStorage[127.0.0.1:46833,DS-bc3c72bd-bcf2-4b6c-9da1-b3dbf777e204,DISK], DatanodeInfoWithStorage[127.0.0.1:44091,DS-6c31596a-c2f0-419a-83fd-da91f7584c2c,DISK], DatanodeInfoWithStorage[127.0.0.1:33061,DS-793d02c6-30ff-4177-806c-d62d15dda761,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1039697739-172.17.0.14-1596884736418:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42418,DS-ff347022-389f-4d5b-8b77-8aa1f847f2d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44164,DS-5f3d032a-be1c-4864-a7de-5f8d389d306b,DISK], DatanodeInfoWithStorage[127.0.0.1:34186,DS-c9d8a49f-e7ed-42d1-9d0b-abbbbc6c1131,DISK], DatanodeInfoWithStorage[127.0.0.1:43870,DS-a760e21d-77b7-42f2-a00d-b1de02e22861,DISK], DatanodeInfoWithStorage[127.0.0.1:34294,DS-38d2f036-bcde-4b93-badf-24099860a85c,DISK], DatanodeInfoWithStorage[127.0.0.1:36726,DS-3c8e2ea2-b2e4-4a29-aae4-34bad6ec51d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44428,DS-0bfc96e2-2ea2-48b0-ae9b-01ddf5de71cb,DISK], DatanodeInfoWithStorage[127.0.0.1:44058,DS-8403aa63-1d7b-410f-a37f-31cebbd8180f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1039697739-172.17.0.14-1596884736418:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42418,DS-ff347022-389f-4d5b-8b77-8aa1f847f2d3,DISK], DatanodeInfoWithStorage[127.0.0.1:44164,DS-5f3d032a-be1c-4864-a7de-5f8d389d306b,DISK], DatanodeInfoWithStorage[127.0.0.1:34186,DS-c9d8a49f-e7ed-42d1-9d0b-abbbbc6c1131,DISK], DatanodeInfoWithStorage[127.0.0.1:43870,DS-a760e21d-77b7-42f2-a00d-b1de02e22861,DISK], DatanodeInfoWithStorage[127.0.0.1:34294,DS-38d2f036-bcde-4b93-badf-24099860a85c,DISK], DatanodeInfoWithStorage[127.0.0.1:36726,DS-3c8e2ea2-b2e4-4a29-aae4-34bad6ec51d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44428,DS-0bfc96e2-2ea2-48b0-ae9b-01ddf5de71cb,DISK], DatanodeInfoWithStorage[127.0.0.1:44058,DS-8403aa63-1d7b-410f-a37f-31cebbd8180f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-402512763-172.17.0.14-1596884917781:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40977,DS-4ed3f699-5f64-466e-b249-7c835e7f9a27,DISK], DatanodeInfoWithStorage[127.0.0.1:33576,DS-9ad6b26e-55aa-4031-a7c5-9c38b0cefad8,DISK], DatanodeInfoWithStorage[127.0.0.1:37220,DS-e7294be2-3674-4e38-a88a-6316566ade44,DISK], DatanodeInfoWithStorage[127.0.0.1:43309,DS-e1a4eaa7-f0a5-4d08-a323-b2ea2e5fa24e,DISK], DatanodeInfoWithStorage[127.0.0.1:44266,DS-dfcc2423-b6f9-429e-a257-dd749b0e10d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40063,DS-e46e2c54-0a43-447f-aa91-f7e3eb028843,DISK], DatanodeInfoWithStorage[127.0.0.1:46158,DS-eee2aff6-5659-4078-9a91-978975054692,DISK], DatanodeInfoWithStorage[127.0.0.1:42766,DS-6b2ec4a8-f7df-4aea-bb81-cc8d26ff434c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-402512763-172.17.0.14-1596884917781:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40977,DS-4ed3f699-5f64-466e-b249-7c835e7f9a27,DISK], DatanodeInfoWithStorage[127.0.0.1:33576,DS-9ad6b26e-55aa-4031-a7c5-9c38b0cefad8,DISK], DatanodeInfoWithStorage[127.0.0.1:37220,DS-e7294be2-3674-4e38-a88a-6316566ade44,DISK], DatanodeInfoWithStorage[127.0.0.1:43309,DS-e1a4eaa7-f0a5-4d08-a323-b2ea2e5fa24e,DISK], DatanodeInfoWithStorage[127.0.0.1:44266,DS-dfcc2423-b6f9-429e-a257-dd749b0e10d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40063,DS-e46e2c54-0a43-447f-aa91-f7e3eb028843,DISK], DatanodeInfoWithStorage[127.0.0.1:46158,DS-eee2aff6-5659-4078-9a91-978975054692,DISK], DatanodeInfoWithStorage[127.0.0.1:42766,DS-6b2ec4a8-f7df-4aea-bb81-cc8d26ff434c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-206077571-172.17.0.14-1596885099564:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40126,DS-294c9a9d-43e0-4cb1-9403-074f53892040,DISK], DatanodeInfoWithStorage[127.0.0.1:44654,DS-995c2bda-c48a-424d-82c6-f425d00390d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45277,DS-64adb915-bf4d-4ae1-a429-7c7da115ad32,DISK], DatanodeInfoWithStorage[127.0.0.1:36714,DS-02f0d931-d336-42d1-9720-b0b4db27ce4e,DISK], DatanodeInfoWithStorage[127.0.0.1:33983,DS-702a39d0-dcc8-4024-830e-70a9fd5a698f,DISK], DatanodeInfoWithStorage[127.0.0.1:46109,DS-0d9ed6fe-bb0a-4227-83fb-f22f0d5aa0ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45895,DS-39cbfe58-42f8-4e36-8915-e6239d8624b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37578,DS-4915af6c-ad10-430a-90f6-8a490e95bf3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-206077571-172.17.0.14-1596885099564:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40126,DS-294c9a9d-43e0-4cb1-9403-074f53892040,DISK], DatanodeInfoWithStorage[127.0.0.1:44654,DS-995c2bda-c48a-424d-82c6-f425d00390d5,DISK], DatanodeInfoWithStorage[127.0.0.1:45277,DS-64adb915-bf4d-4ae1-a429-7c7da115ad32,DISK], DatanodeInfoWithStorage[127.0.0.1:36714,DS-02f0d931-d336-42d1-9720-b0b4db27ce4e,DISK], DatanodeInfoWithStorage[127.0.0.1:33983,DS-702a39d0-dcc8-4024-830e-70a9fd5a698f,DISK], DatanodeInfoWithStorage[127.0.0.1:46109,DS-0d9ed6fe-bb0a-4227-83fb-f22f0d5aa0ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45895,DS-39cbfe58-42f8-4e36-8915-e6239d8624b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37578,DS-4915af6c-ad10-430a-90f6-8a490e95bf3e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1419244857-172.17.0.14-1596885175279:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33736,DS-5e2c489d-432f-4cd8-9d57-d3720139c28f,DISK], DatanodeInfoWithStorage[127.0.0.1:43949,DS-7ce36489-3f28-4ae6-9dfe-7cd4c5b77cdb,DISK], DatanodeInfoWithStorage[127.0.0.1:43441,DS-28356f9f-637a-4d8d-b68d-90b63b93deb8,DISK], DatanodeInfoWithStorage[127.0.0.1:37697,DS-ed7dae33-ec14-4e59-a763-c8dc440c2dbc,DISK], DatanodeInfoWithStorage[127.0.0.1:38857,DS-e4776362-6dfb-41bf-a34c-edb369c7aff1,DISK], DatanodeInfoWithStorage[127.0.0.1:38236,DS-627a0a54-da8f-4708-9d68-1ee5df3c3532,DISK], DatanodeInfoWithStorage[127.0.0.1:41457,DS-cc4bcba9-dafe-4c77-8b35-d2df92706a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:46609,DS-07dee23f-9745-4e4f-a8d7-3f9613af841a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1419244857-172.17.0.14-1596885175279:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33736,DS-5e2c489d-432f-4cd8-9d57-d3720139c28f,DISK], DatanodeInfoWithStorage[127.0.0.1:43949,DS-7ce36489-3f28-4ae6-9dfe-7cd4c5b77cdb,DISK], DatanodeInfoWithStorage[127.0.0.1:43441,DS-28356f9f-637a-4d8d-b68d-90b63b93deb8,DISK], DatanodeInfoWithStorage[127.0.0.1:37697,DS-ed7dae33-ec14-4e59-a763-c8dc440c2dbc,DISK], DatanodeInfoWithStorage[127.0.0.1:38857,DS-e4776362-6dfb-41bf-a34c-edb369c7aff1,DISK], DatanodeInfoWithStorage[127.0.0.1:38236,DS-627a0a54-da8f-4708-9d68-1ee5df3c3532,DISK], DatanodeInfoWithStorage[127.0.0.1:41457,DS-cc4bcba9-dafe-4c77-8b35-d2df92706a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:46609,DS-07dee23f-9745-4e4f-a8d7-3f9613af841a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1722280336-172.17.0.14-1596885283432:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33588,DS-34da887f-189d-4c59-89c7-19d89f8c2a50,DISK], DatanodeInfoWithStorage[127.0.0.1:39196,DS-b42847b4-fb31-43a1-a37b-f29cab03a72a,DISK], DatanodeInfoWithStorage[127.0.0.1:37593,DS-075e1402-342e-4caf-8765-09504c4f69b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44389,DS-0fbf7607-ece0-40ba-b0d5-f5b393701bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:41546,DS-6dc91d68-8894-417a-b909-0903a6a078f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42404,DS-cace4cfc-7c23-4291-aef4-724b37a20d7a,DISK], DatanodeInfoWithStorage[127.0.0.1:43129,DS-341f1d13-2c41-492a-bc5c-db3323f90faa,DISK], DatanodeInfoWithStorage[127.0.0.1:34284,DS-7b0d99dd-3ca3-4577-b965-96c5734525fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1722280336-172.17.0.14-1596885283432:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33588,DS-34da887f-189d-4c59-89c7-19d89f8c2a50,DISK], DatanodeInfoWithStorage[127.0.0.1:39196,DS-b42847b4-fb31-43a1-a37b-f29cab03a72a,DISK], DatanodeInfoWithStorage[127.0.0.1:37593,DS-075e1402-342e-4caf-8765-09504c4f69b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44389,DS-0fbf7607-ece0-40ba-b0d5-f5b393701bb1,DISK], DatanodeInfoWithStorage[127.0.0.1:41546,DS-6dc91d68-8894-417a-b909-0903a6a078f6,DISK], DatanodeInfoWithStorage[127.0.0.1:42404,DS-cace4cfc-7c23-4291-aef4-724b37a20d7a,DISK], DatanodeInfoWithStorage[127.0.0.1:43129,DS-341f1d13-2c41-492a-bc5c-db3323f90faa,DISK], DatanodeInfoWithStorage[127.0.0.1:34284,DS-7b0d99dd-3ca3-4577-b965-96c5734525fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1193959443-172.17.0.14-1596885460021:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34460,DS-ed345b90-ea53-4772-97d1-a204d8fe569c,DISK], DatanodeInfoWithStorage[127.0.0.1:38435,DS-1fc2c639-71ad-4082-bcfb-828d9a4b3dac,DISK], DatanodeInfoWithStorage[127.0.0.1:40763,DS-6a73cbf2-d129-4aa4-80b6-cf204430656a,DISK], DatanodeInfoWithStorage[127.0.0.1:38522,DS-1cb17cdd-a83e-46b4-b0a7-c24102d6b133,DISK], DatanodeInfoWithStorage[127.0.0.1:38765,DS-e225e9d5-7712-4604-aafe-5e03411cfe2c,DISK], DatanodeInfoWithStorage[127.0.0.1:33592,DS-ee6d4306-5384-47c1-a12f-0caabf09a04d,DISK], DatanodeInfoWithStorage[127.0.0.1:43258,DS-2ff57c9f-52df-4e7e-b667-d34caddd64bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39123,DS-a6b9dd42-ea27-48e0-8731-23fc7ebc215a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1193959443-172.17.0.14-1596885460021:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34460,DS-ed345b90-ea53-4772-97d1-a204d8fe569c,DISK], DatanodeInfoWithStorage[127.0.0.1:38435,DS-1fc2c639-71ad-4082-bcfb-828d9a4b3dac,DISK], DatanodeInfoWithStorage[127.0.0.1:40763,DS-6a73cbf2-d129-4aa4-80b6-cf204430656a,DISK], DatanodeInfoWithStorage[127.0.0.1:38522,DS-1cb17cdd-a83e-46b4-b0a7-c24102d6b133,DISK], DatanodeInfoWithStorage[127.0.0.1:38765,DS-e225e9d5-7712-4604-aafe-5e03411cfe2c,DISK], DatanodeInfoWithStorage[127.0.0.1:33592,DS-ee6d4306-5384-47c1-a12f-0caabf09a04d,DISK], DatanodeInfoWithStorage[127.0.0.1:43258,DS-2ff57c9f-52df-4e7e-b667-d34caddd64bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39123,DS-a6b9dd42-ea27-48e0-8731-23fc7ebc215a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5271
