reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1250771293-172.17.0.10-1596984071176:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45831,DS-ae35cc07-68e9-4778-9562-0355545ed32c,DISK], DatanodeInfoWithStorage[127.0.0.1:39776,DS-ec553186-dcda-4467-9e0e-2fcaa38ae4d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44870,DS-eb0622de-6471-462a-8906-e19ad521168a,DISK], DatanodeInfoWithStorage[127.0.0.1:34384,DS-8ce93492-59ca-4759-a849-d037c7b0a4f4,DISK], DatanodeInfoWithStorage[127.0.0.1:41262,DS-d119483f-4262-412a-bcfd-5a35462a13c4,DISK], DatanodeInfoWithStorage[127.0.0.1:40337,DS-abe4ff9c-55f5-4de3-acf3-c8953d9e9629,DISK], DatanodeInfoWithStorage[127.0.0.1:40267,DS-36d0cf52-dc75-4090-b0a4-de492261e855,DISK], DatanodeInfoWithStorage[127.0.0.1:35020,DS-ae98c7aa-3ddf-40db-926d-8950cf3913fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1250771293-172.17.0.10-1596984071176:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45831,DS-ae35cc07-68e9-4778-9562-0355545ed32c,DISK], DatanodeInfoWithStorage[127.0.0.1:39776,DS-ec553186-dcda-4467-9e0e-2fcaa38ae4d7,DISK], DatanodeInfoWithStorage[127.0.0.1:44870,DS-eb0622de-6471-462a-8906-e19ad521168a,DISK], DatanodeInfoWithStorage[127.0.0.1:34384,DS-8ce93492-59ca-4759-a849-d037c7b0a4f4,DISK], DatanodeInfoWithStorage[127.0.0.1:41262,DS-d119483f-4262-412a-bcfd-5a35462a13c4,DISK], DatanodeInfoWithStorage[127.0.0.1:40337,DS-abe4ff9c-55f5-4de3-acf3-c8953d9e9629,DISK], DatanodeInfoWithStorage[127.0.0.1:40267,DS-36d0cf52-dc75-4090-b0a4-de492261e855,DISK], DatanodeInfoWithStorage[127.0.0.1:35020,DS-ae98c7aa-3ddf-40db-926d-8950cf3913fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-233069813-172.17.0.10-1596984538915:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36371,DS-ec6a7f54-5299-4e0f-9798-54df9782db89,DISK], DatanodeInfoWithStorage[127.0.0.1:44633,DS-02feb089-888a-40c0-a216-cfc962b485c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45335,DS-d520fc38-c977-4616-acbc-031c55a68dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:43018,DS-2a00b148-8931-4a21-a37e-3ffb653876c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42726,DS-72d6565b-37f6-4baa-a7fa-78e900ec68c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43417,DS-197f4c51-207f-4baa-b274-038271b198f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39868,DS-0a84b527-165e-44d4-8037-3e6508fcc19a,DISK], DatanodeInfoWithStorage[127.0.0.1:43329,DS-847d36e0-9878-4888-b99d-c804c0510c7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-233069813-172.17.0.10-1596984538915:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36371,DS-ec6a7f54-5299-4e0f-9798-54df9782db89,DISK], DatanodeInfoWithStorage[127.0.0.1:44633,DS-02feb089-888a-40c0-a216-cfc962b485c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45335,DS-d520fc38-c977-4616-acbc-031c55a68dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:43018,DS-2a00b148-8931-4a21-a37e-3ffb653876c4,DISK], DatanodeInfoWithStorage[127.0.0.1:42726,DS-72d6565b-37f6-4baa-a7fa-78e900ec68c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43417,DS-197f4c51-207f-4baa-b274-038271b198f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39868,DS-0a84b527-165e-44d4-8037-3e6508fcc19a,DISK], DatanodeInfoWithStorage[127.0.0.1:43329,DS-847d36e0-9878-4888-b99d-c804c0510c7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-237924693-172.17.0.10-1596984602886:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45126,DS-581c30a8-30e8-4a97-9265-324cb86f6a3d,DISK], DatanodeInfoWithStorage[127.0.0.1:43405,DS-f9da9da0-62a5-43e5-a123-9c63f485d91d,DISK], DatanodeInfoWithStorage[127.0.0.1:36523,DS-a17fb0cc-486c-4105-8ce2-155b3bebc6c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41640,DS-c7aeb0c1-f449-4f76-a4a2-5d8cea35b24f,DISK], DatanodeInfoWithStorage[127.0.0.1:40597,DS-c2dbd67d-93a4-4481-a297-4327d37a5100,DISK], DatanodeInfoWithStorage[127.0.0.1:42562,DS-4bbfb73a-832e-4315-ab55-8a4c584753da,DISK], DatanodeInfoWithStorage[127.0.0.1:32934,DS-d1cc0528-4f52-4ca2-9f66-5f10032a83ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42735,DS-8ebe0a70-8e3a-45d6-9e58-8afad49ef755,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-237924693-172.17.0.10-1596984602886:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45126,DS-581c30a8-30e8-4a97-9265-324cb86f6a3d,DISK], DatanodeInfoWithStorage[127.0.0.1:43405,DS-f9da9da0-62a5-43e5-a123-9c63f485d91d,DISK], DatanodeInfoWithStorage[127.0.0.1:36523,DS-a17fb0cc-486c-4105-8ce2-155b3bebc6c0,DISK], DatanodeInfoWithStorage[127.0.0.1:41640,DS-c7aeb0c1-f449-4f76-a4a2-5d8cea35b24f,DISK], DatanodeInfoWithStorage[127.0.0.1:40597,DS-c2dbd67d-93a4-4481-a297-4327d37a5100,DISK], DatanodeInfoWithStorage[127.0.0.1:42562,DS-4bbfb73a-832e-4315-ab55-8a4c584753da,DISK], DatanodeInfoWithStorage[127.0.0.1:32934,DS-d1cc0528-4f52-4ca2-9f66-5f10032a83ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42735,DS-8ebe0a70-8e3a-45d6-9e58-8afad49ef755,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1479264923-172.17.0.10-1596984707466:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40810,DS-d7044b4f-b3a9-459f-88f8-538cac17c601,DISK], DatanodeInfoWithStorage[127.0.0.1:39650,DS-ee5d2d9c-4f82-43f3-9f93-839afbd1ad00,DISK], DatanodeInfoWithStorage[127.0.0.1:43907,DS-d4858122-7043-4474-8d85-6c6d290a1352,DISK], DatanodeInfoWithStorage[127.0.0.1:35152,DS-7633f011-6f8d-4528-92ac-4a3318f43c8c,DISK], DatanodeInfoWithStorage[127.0.0.1:34556,DS-2f65ce57-82c9-402d-886c-167d9dd3861a,DISK], DatanodeInfoWithStorage[127.0.0.1:38687,DS-80c79a42-7e4e-4e43-b7b8-809ccf43a763,DISK], DatanodeInfoWithStorage[127.0.0.1:37688,DS-780a7ecc-e07c-4647-a1e7-f67112fd0156,DISK], DatanodeInfoWithStorage[127.0.0.1:37219,DS-55ff75e4-03f7-47a9-8c20-f77d49d18340,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1479264923-172.17.0.10-1596984707466:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40810,DS-d7044b4f-b3a9-459f-88f8-538cac17c601,DISK], DatanodeInfoWithStorage[127.0.0.1:39650,DS-ee5d2d9c-4f82-43f3-9f93-839afbd1ad00,DISK], DatanodeInfoWithStorage[127.0.0.1:43907,DS-d4858122-7043-4474-8d85-6c6d290a1352,DISK], DatanodeInfoWithStorage[127.0.0.1:35152,DS-7633f011-6f8d-4528-92ac-4a3318f43c8c,DISK], DatanodeInfoWithStorage[127.0.0.1:34556,DS-2f65ce57-82c9-402d-886c-167d9dd3861a,DISK], DatanodeInfoWithStorage[127.0.0.1:38687,DS-80c79a42-7e4e-4e43-b7b8-809ccf43a763,DISK], DatanodeInfoWithStorage[127.0.0.1:37688,DS-780a7ecc-e07c-4647-a1e7-f67112fd0156,DISK], DatanodeInfoWithStorage[127.0.0.1:37219,DS-55ff75e4-03f7-47a9-8c20-f77d49d18340,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1436413668-172.17.0.10-1596984854680:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42459,DS-6869d4d9-becb-4405-a453-cc057d306743,DISK], DatanodeInfoWithStorage[127.0.0.1:39441,DS-9f88afe6-3e76-4f3b-ab42-f8112240be68,DISK], DatanodeInfoWithStorage[127.0.0.1:38825,DS-293508e8-7a58-4d55-a336-1a4368e9d22f,DISK], DatanodeInfoWithStorage[127.0.0.1:44963,DS-6bb8360d-4b5a-43a0-b390-5fed5d0e5b18,DISK], DatanodeInfoWithStorage[127.0.0.1:44440,DS-397d3d4e-4310-40dc-82e6-8cc52272dbc9,DISK], DatanodeInfoWithStorage[127.0.0.1:37957,DS-4662de96-e72f-4299-944a-88917014a6d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42393,DS-93aeb14e-c802-4cee-901b-3f112a117e7a,DISK], DatanodeInfoWithStorage[127.0.0.1:33789,DS-bccc5df7-2fc2-42d1-a7ea-8dbca34a28f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1436413668-172.17.0.10-1596984854680:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42459,DS-6869d4d9-becb-4405-a453-cc057d306743,DISK], DatanodeInfoWithStorage[127.0.0.1:39441,DS-9f88afe6-3e76-4f3b-ab42-f8112240be68,DISK], DatanodeInfoWithStorage[127.0.0.1:38825,DS-293508e8-7a58-4d55-a336-1a4368e9d22f,DISK], DatanodeInfoWithStorage[127.0.0.1:44963,DS-6bb8360d-4b5a-43a0-b390-5fed5d0e5b18,DISK], DatanodeInfoWithStorage[127.0.0.1:44440,DS-397d3d4e-4310-40dc-82e6-8cc52272dbc9,DISK], DatanodeInfoWithStorage[127.0.0.1:37957,DS-4662de96-e72f-4299-944a-88917014a6d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42393,DS-93aeb14e-c802-4cee-901b-3f112a117e7a,DISK], DatanodeInfoWithStorage[127.0.0.1:33789,DS-bccc5df7-2fc2-42d1-a7ea-8dbca34a28f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-948715203-172.17.0.10-1596985104530:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39734,DS-64df3765-9b6a-45e5-aa96-5d749e58bddf,DISK], DatanodeInfoWithStorage[127.0.0.1:46055,DS-da5f41e8-370f-46e6-a2f6-22eb58182d03,DISK], DatanodeInfoWithStorage[127.0.0.1:38536,DS-26e3d05f-ec61-46f7-aa09-1d19d5aace49,DISK], DatanodeInfoWithStorage[127.0.0.1:39162,DS-5828e88f-6e0d-4607-8bab-455aa173aa20,DISK], DatanodeInfoWithStorage[127.0.0.1:34649,DS-3de4fc3c-07a6-413f-bc32-0e12c9b9deb9,DISK], DatanodeInfoWithStorage[127.0.0.1:33246,DS-e141dced-70a7-42cb-bff2-313cf4e6485f,DISK], DatanodeInfoWithStorage[127.0.0.1:35960,DS-f19229b8-7f29-40a7-bdae-ef015e99a7b6,DISK], DatanodeInfoWithStorage[127.0.0.1:32866,DS-877082e2-c98b-4cf7-99b3-691545eb2b99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-948715203-172.17.0.10-1596985104530:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39734,DS-64df3765-9b6a-45e5-aa96-5d749e58bddf,DISK], DatanodeInfoWithStorage[127.0.0.1:46055,DS-da5f41e8-370f-46e6-a2f6-22eb58182d03,DISK], DatanodeInfoWithStorage[127.0.0.1:38536,DS-26e3d05f-ec61-46f7-aa09-1d19d5aace49,DISK], DatanodeInfoWithStorage[127.0.0.1:39162,DS-5828e88f-6e0d-4607-8bab-455aa173aa20,DISK], DatanodeInfoWithStorage[127.0.0.1:34649,DS-3de4fc3c-07a6-413f-bc32-0e12c9b9deb9,DISK], DatanodeInfoWithStorage[127.0.0.1:33246,DS-e141dced-70a7-42cb-bff2-313cf4e6485f,DISK], DatanodeInfoWithStorage[127.0.0.1:35960,DS-f19229b8-7f29-40a7-bdae-ef015e99a7b6,DISK], DatanodeInfoWithStorage[127.0.0.1:32866,DS-877082e2-c98b-4cf7-99b3-691545eb2b99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1136961965-172.17.0.10-1596985149084:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46082,DS-92be4815-aa2b-4a71-8f85-3db15aaf9c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:41991,DS-1524bcd1-95fa-4b4b-b931-cfc57b1806bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44274,DS-a4040f0a-71bc-47c0-b0b2-7fff21fa0a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39894,DS-9644719b-46a4-4197-9bda-91c9bb2378eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36933,DS-bce17eef-63b4-42c8-837b-c43d1370a9ee,DISK], DatanodeInfoWithStorage[127.0.0.1:46459,DS-368100c5-28f0-4db0-9e2e-8e0df660585e,DISK], DatanodeInfoWithStorage[127.0.0.1:39531,DS-d5b1a545-663c-47e1-9a53-5abf49d32808,DISK], DatanodeInfoWithStorage[127.0.0.1:40765,DS-dc57aa23-ad31-47dd-accd-00133edb16fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1136961965-172.17.0.10-1596985149084:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46082,DS-92be4815-aa2b-4a71-8f85-3db15aaf9c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:41991,DS-1524bcd1-95fa-4b4b-b931-cfc57b1806bb,DISK], DatanodeInfoWithStorage[127.0.0.1:44274,DS-a4040f0a-71bc-47c0-b0b2-7fff21fa0a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39894,DS-9644719b-46a4-4197-9bda-91c9bb2378eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36933,DS-bce17eef-63b4-42c8-837b-c43d1370a9ee,DISK], DatanodeInfoWithStorage[127.0.0.1:46459,DS-368100c5-28f0-4db0-9e2e-8e0df660585e,DISK], DatanodeInfoWithStorage[127.0.0.1:39531,DS-d5b1a545-663c-47e1-9a53-5abf49d32808,DISK], DatanodeInfoWithStorage[127.0.0.1:40765,DS-dc57aa23-ad31-47dd-accd-00133edb16fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1502593953-172.17.0.10-1596985670104:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40833,DS-d04dd57b-5c4c-4eb1-9af8-1c859e35288d,DISK], DatanodeInfoWithStorage[127.0.0.1:46840,DS-152afb59-bb71-47e3-b1ed-3190ce6fb288,DISK], DatanodeInfoWithStorage[127.0.0.1:40495,DS-21246161-6e68-46ef-87dd-56df8b258c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:32883,DS-4c034b46-dcf6-4cd5-9680-c8bb921ddeb4,DISK], DatanodeInfoWithStorage[127.0.0.1:44725,DS-d984ed4e-1db8-4fe9-b911-cf7ed39f0a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:38295,DS-203f719d-fede-4a77-bf78-7bf891adb33a,DISK], DatanodeInfoWithStorage[127.0.0.1:46345,DS-9a4f4be7-8799-4841-a0ae-41540d5ff869,DISK], DatanodeInfoWithStorage[127.0.0.1:35977,DS-7b050a98-f47e-4837-8fd8-9b3172bf3d28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1502593953-172.17.0.10-1596985670104:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40833,DS-d04dd57b-5c4c-4eb1-9af8-1c859e35288d,DISK], DatanodeInfoWithStorage[127.0.0.1:46840,DS-152afb59-bb71-47e3-b1ed-3190ce6fb288,DISK], DatanodeInfoWithStorage[127.0.0.1:40495,DS-21246161-6e68-46ef-87dd-56df8b258c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:32883,DS-4c034b46-dcf6-4cd5-9680-c8bb921ddeb4,DISK], DatanodeInfoWithStorage[127.0.0.1:44725,DS-d984ed4e-1db8-4fe9-b911-cf7ed39f0a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:38295,DS-203f719d-fede-4a77-bf78-7bf891adb33a,DISK], DatanodeInfoWithStorage[127.0.0.1:46345,DS-9a4f4be7-8799-4841-a0ae-41540d5ff869,DISK], DatanodeInfoWithStorage[127.0.0.1:35977,DS-7b050a98-f47e-4837-8fd8-9b3172bf3d28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-825197311-172.17.0.10-1596985970270:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33683,DS-a6e6fc43-4f20-48df-86ae-bdbf233d2db6,DISK], DatanodeInfoWithStorage[127.0.0.1:45937,DS-73eb400b-d76d-434d-917e-03de53721db2,DISK], DatanodeInfoWithStorage[127.0.0.1:33118,DS-21c7e165-2453-4e55-b004-793782427408,DISK], DatanodeInfoWithStorage[127.0.0.1:45919,DS-4a786e41-d6a1-478d-b29c-065dfd1cf5e6,DISK], DatanodeInfoWithStorage[127.0.0.1:34581,DS-16dace0d-c8f3-4e8b-8f79-31adbcdf2184,DISK], DatanodeInfoWithStorage[127.0.0.1:40721,DS-2b6740cc-c0d0-438b-9b91-7ff00cf65c44,DISK], DatanodeInfoWithStorage[127.0.0.1:42439,DS-972376b1-8fb4-47d7-9a22-1e26943cc693,DISK], DatanodeInfoWithStorage[127.0.0.1:46512,DS-cc4d9d33-a3c5-4c4e-b8dc-12408b4467f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-825197311-172.17.0.10-1596985970270:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33683,DS-a6e6fc43-4f20-48df-86ae-bdbf233d2db6,DISK], DatanodeInfoWithStorage[127.0.0.1:45937,DS-73eb400b-d76d-434d-917e-03de53721db2,DISK], DatanodeInfoWithStorage[127.0.0.1:33118,DS-21c7e165-2453-4e55-b004-793782427408,DISK], DatanodeInfoWithStorage[127.0.0.1:45919,DS-4a786e41-d6a1-478d-b29c-065dfd1cf5e6,DISK], DatanodeInfoWithStorage[127.0.0.1:34581,DS-16dace0d-c8f3-4e8b-8f79-31adbcdf2184,DISK], DatanodeInfoWithStorage[127.0.0.1:40721,DS-2b6740cc-c0d0-438b-9b91-7ff00cf65c44,DISK], DatanodeInfoWithStorage[127.0.0.1:42439,DS-972376b1-8fb4-47d7-9a22-1e26943cc693,DISK], DatanodeInfoWithStorage[127.0.0.1:46512,DS-cc4d9d33-a3c5-4c4e-b8dc-12408b4467f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-669361388-172.17.0.10-1596986294199:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39027,DS-4dd1a3b3-2d11-45bf-9a16-eecdc5a904ce,DISK], DatanodeInfoWithStorage[127.0.0.1:37073,DS-ac5ee825-4f5b-489a-bac3-62647151670f,DISK], DatanodeInfoWithStorage[127.0.0.1:37864,DS-39701771-8248-4205-9ac2-285cbd2173f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40905,DS-33ca814c-9ad5-48e0-8b3e-5e3693213dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:44151,DS-7e968904-cd39-404c-8eb1-95b0ec1e0730,DISK], DatanodeInfoWithStorage[127.0.0.1:35623,DS-8285082b-3add-4b2a-95d9-030b66723886,DISK], DatanodeInfoWithStorage[127.0.0.1:39603,DS-7aed87c1-f43d-412c-acb2-e5f278aadf5c,DISK], DatanodeInfoWithStorage[127.0.0.1:38625,DS-c5202a1e-2410-491e-8652-0fb2aed29fe2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-669361388-172.17.0.10-1596986294199:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39027,DS-4dd1a3b3-2d11-45bf-9a16-eecdc5a904ce,DISK], DatanodeInfoWithStorage[127.0.0.1:37073,DS-ac5ee825-4f5b-489a-bac3-62647151670f,DISK], DatanodeInfoWithStorage[127.0.0.1:37864,DS-39701771-8248-4205-9ac2-285cbd2173f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40905,DS-33ca814c-9ad5-48e0-8b3e-5e3693213dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:44151,DS-7e968904-cd39-404c-8eb1-95b0ec1e0730,DISK], DatanodeInfoWithStorage[127.0.0.1:35623,DS-8285082b-3add-4b2a-95d9-030b66723886,DISK], DatanodeInfoWithStorage[127.0.0.1:39603,DS-7aed87c1-f43d-412c-acb2-e5f278aadf5c,DISK], DatanodeInfoWithStorage[127.0.0.1:38625,DS-c5202a1e-2410-491e-8652-0fb2aed29fe2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1698024860-172.17.0.10-1596986487600:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37045,DS-52910c06-07f3-4827-9bd1-e68be90246a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34020,DS-5e6a8144-325e-467f-8f03-7137e4cfc146,DISK], DatanodeInfoWithStorage[127.0.0.1:37726,DS-5a4d5a60-44f2-4952-8100-c3f0662db9a8,DISK], DatanodeInfoWithStorage[127.0.0.1:33029,DS-d5652275-e18f-4f34-a278-50305382381f,DISK], DatanodeInfoWithStorage[127.0.0.1:44348,DS-0c00535d-4c0d-4380-9934-4835c5a6fdf6,DISK], DatanodeInfoWithStorage[127.0.0.1:46400,DS-ca89039e-12b5-4f2f-82cf-115166d91773,DISK], DatanodeInfoWithStorage[127.0.0.1:39023,DS-24b90734-b3ca-4004-b50b-166c02b94ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:44247,DS-a5516409-f099-4fb1-a7f2-10f1c3e08c28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1698024860-172.17.0.10-1596986487600:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37045,DS-52910c06-07f3-4827-9bd1-e68be90246a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34020,DS-5e6a8144-325e-467f-8f03-7137e4cfc146,DISK], DatanodeInfoWithStorage[127.0.0.1:37726,DS-5a4d5a60-44f2-4952-8100-c3f0662db9a8,DISK], DatanodeInfoWithStorage[127.0.0.1:33029,DS-d5652275-e18f-4f34-a278-50305382381f,DISK], DatanodeInfoWithStorage[127.0.0.1:44348,DS-0c00535d-4c0d-4380-9934-4835c5a6fdf6,DISK], DatanodeInfoWithStorage[127.0.0.1:46400,DS-ca89039e-12b5-4f2f-82cf-115166d91773,DISK], DatanodeInfoWithStorage[127.0.0.1:39023,DS-24b90734-b3ca-4004-b50b-166c02b94ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:44247,DS-a5516409-f099-4fb1-a7f2-10f1c3e08c28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-562844398-172.17.0.10-1596986748100:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38910,DS-4157dda1-3316-4991-8f08-f84b5c21f004,DISK], DatanodeInfoWithStorage[127.0.0.1:39842,DS-49d6ebed-4ffb-4c4e-82d6-3037e0ce3847,DISK], DatanodeInfoWithStorage[127.0.0.1:38684,DS-40404eed-0936-4a44-a002-7e6e61e23f33,DISK], DatanodeInfoWithStorage[127.0.0.1:33610,DS-e1e95cac-4bde-43aa-a3e9-54ec91d10c64,DISK], DatanodeInfoWithStorage[127.0.0.1:37086,DS-acac8981-81e1-4006-a92c-7980f43de819,DISK], DatanodeInfoWithStorage[127.0.0.1:44582,DS-15d72b78-1fab-47a3-bd0f-0438b364b7a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38466,DS-43bd9c96-c8a9-4177-9bac-7bb7f457aec2,DISK], DatanodeInfoWithStorage[127.0.0.1:42844,DS-a8824d2f-d795-4006-a9b3-6bf65b44c344,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-562844398-172.17.0.10-1596986748100:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38910,DS-4157dda1-3316-4991-8f08-f84b5c21f004,DISK], DatanodeInfoWithStorage[127.0.0.1:39842,DS-49d6ebed-4ffb-4c4e-82d6-3037e0ce3847,DISK], DatanodeInfoWithStorage[127.0.0.1:38684,DS-40404eed-0936-4a44-a002-7e6e61e23f33,DISK], DatanodeInfoWithStorage[127.0.0.1:33610,DS-e1e95cac-4bde-43aa-a3e9-54ec91d10c64,DISK], DatanodeInfoWithStorage[127.0.0.1:37086,DS-acac8981-81e1-4006-a92c-7980f43de819,DISK], DatanodeInfoWithStorage[127.0.0.1:44582,DS-15d72b78-1fab-47a3-bd0f-0438b364b7a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38466,DS-43bd9c96-c8a9-4177-9bac-7bb7f457aec2,DISK], DatanodeInfoWithStorage[127.0.0.1:42844,DS-a8824d2f-d795-4006-a9b3-6bf65b44c344,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1485495317-172.17.0.10-1596986827306:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33650,DS-37a111a0-5215-4af3-920a-da09d6ad765c,DISK], DatanodeInfoWithStorage[127.0.0.1:33968,DS-6577b5d4-a0e3-45f8-992d-8f1188019630,DISK], DatanodeInfoWithStorage[127.0.0.1:36062,DS-204bdc96-ee1d-4897-ac4d-0f0319aadf9e,DISK], DatanodeInfoWithStorage[127.0.0.1:39628,DS-94ca0ee0-1ad9-499d-92e1-feb8ea16e3bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44723,DS-252368b0-7b25-43b1-92da-972d9eac108f,DISK], DatanodeInfoWithStorage[127.0.0.1:43512,DS-c5a631b9-f526-4b77-ab1e-c5d13f2d8fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:44697,DS-34b0c25e-9195-4a07-ae9d-4736cb2f545b,DISK], DatanodeInfoWithStorage[127.0.0.1:45467,DS-25bc8847-8f89-4e7f-8e7c-3e046607960b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1485495317-172.17.0.10-1596986827306:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33650,DS-37a111a0-5215-4af3-920a-da09d6ad765c,DISK], DatanodeInfoWithStorage[127.0.0.1:33968,DS-6577b5d4-a0e3-45f8-992d-8f1188019630,DISK], DatanodeInfoWithStorage[127.0.0.1:36062,DS-204bdc96-ee1d-4897-ac4d-0f0319aadf9e,DISK], DatanodeInfoWithStorage[127.0.0.1:39628,DS-94ca0ee0-1ad9-499d-92e1-feb8ea16e3bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44723,DS-252368b0-7b25-43b1-92da-972d9eac108f,DISK], DatanodeInfoWithStorage[127.0.0.1:43512,DS-c5a631b9-f526-4b77-ab1e-c5d13f2d8fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:44697,DS-34b0c25e-9195-4a07-ae9d-4736cb2f545b,DISK], DatanodeInfoWithStorage[127.0.0.1:45467,DS-25bc8847-8f89-4e7f-8e7c-3e046607960b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-743902019-172.17.0.10-1596987018906:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41733,DS-83ac9a6a-a2c0-4b12-972f-e0c558e05213,DISK], DatanodeInfoWithStorage[127.0.0.1:37665,DS-3299fc70-bcec-4102-86c4-2842352a9fa0,DISK], DatanodeInfoWithStorage[127.0.0.1:44424,DS-d61e367b-4cd9-4a80-9090-02c972848acb,DISK], DatanodeInfoWithStorage[127.0.0.1:40293,DS-b9a02739-e761-43b4-9d4d-ea41f9f6da79,DISK], DatanodeInfoWithStorage[127.0.0.1:39717,DS-65d89915-3b8d-49a9-9f12-c86a9944c80b,DISK], DatanodeInfoWithStorage[127.0.0.1:36832,DS-ff57818f-0c2a-449b-a749-f3daf338aa66,DISK], DatanodeInfoWithStorage[127.0.0.1:46222,DS-3764529a-025e-4f2e-b9c3-ec5751bdf363,DISK], DatanodeInfoWithStorage[127.0.0.1:32811,DS-ab4a5115-3145-459b-a61a-aed9c6c0617d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-743902019-172.17.0.10-1596987018906:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41733,DS-83ac9a6a-a2c0-4b12-972f-e0c558e05213,DISK], DatanodeInfoWithStorage[127.0.0.1:37665,DS-3299fc70-bcec-4102-86c4-2842352a9fa0,DISK], DatanodeInfoWithStorage[127.0.0.1:44424,DS-d61e367b-4cd9-4a80-9090-02c972848acb,DISK], DatanodeInfoWithStorage[127.0.0.1:40293,DS-b9a02739-e761-43b4-9d4d-ea41f9f6da79,DISK], DatanodeInfoWithStorage[127.0.0.1:39717,DS-65d89915-3b8d-49a9-9f12-c86a9944c80b,DISK], DatanodeInfoWithStorage[127.0.0.1:36832,DS-ff57818f-0c2a-449b-a749-f3daf338aa66,DISK], DatanodeInfoWithStorage[127.0.0.1:46222,DS-3764529a-025e-4f2e-b9c3-ec5751bdf363,DISK], DatanodeInfoWithStorage[127.0.0.1:32811,DS-ab4a5115-3145-459b-a61a-aed9c6c0617d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2006352538-172.17.0.10-1596987270109:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39756,DS-b39ff775-77d1-4a3d-a277-86cdf33dd421,DISK], DatanodeInfoWithStorage[127.0.0.1:41692,DS-60fabdc0-8c4d-40e6-8326-7c2db8b87660,DISK], DatanodeInfoWithStorage[127.0.0.1:36441,DS-f801055c-7667-47cb-b3d0-d963d17e5923,DISK], DatanodeInfoWithStorage[127.0.0.1:40406,DS-c4c23330-370e-41b4-af9c-266618fecfc1,DISK], DatanodeInfoWithStorage[127.0.0.1:41862,DS-0ec892fa-915f-42d7-951f-d868118a893b,DISK], DatanodeInfoWithStorage[127.0.0.1:45708,DS-2485fc80-067b-4fbc-ae68-3a75a5a6363d,DISK], DatanodeInfoWithStorage[127.0.0.1:33983,DS-fd3b4a28-3fec-4576-af1d-3160d41c3428,DISK], DatanodeInfoWithStorage[127.0.0.1:34446,DS-7211cfde-c437-403e-af8d-c21c6fd4391a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2006352538-172.17.0.10-1596987270109:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39756,DS-b39ff775-77d1-4a3d-a277-86cdf33dd421,DISK], DatanodeInfoWithStorage[127.0.0.1:41692,DS-60fabdc0-8c4d-40e6-8326-7c2db8b87660,DISK], DatanodeInfoWithStorage[127.0.0.1:36441,DS-f801055c-7667-47cb-b3d0-d963d17e5923,DISK], DatanodeInfoWithStorage[127.0.0.1:40406,DS-c4c23330-370e-41b4-af9c-266618fecfc1,DISK], DatanodeInfoWithStorage[127.0.0.1:41862,DS-0ec892fa-915f-42d7-951f-d868118a893b,DISK], DatanodeInfoWithStorage[127.0.0.1:45708,DS-2485fc80-067b-4fbc-ae68-3a75a5a6363d,DISK], DatanodeInfoWithStorage[127.0.0.1:33983,DS-fd3b4a28-3fec-4576-af1d-3160d41c3428,DISK], DatanodeInfoWithStorage[127.0.0.1:34446,DS-7211cfde-c437-403e-af8d-c21c6fd4391a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1447793031-172.17.0.10-1596987286924:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46461,DS-2afdef82-3a96-4265-bb62-0781f6846971,DISK], DatanodeInfoWithStorage[127.0.0.1:35594,DS-0cb1b52d-350d-4560-a332-2dae9dfef607,DISK], DatanodeInfoWithStorage[127.0.0.1:35476,DS-ddbcc0d9-8bc8-4073-81b3-39edfd4f8fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:45431,DS-96008014-9788-4aa5-9882-7a5495461fb5,DISK], DatanodeInfoWithStorage[127.0.0.1:37251,DS-fe8694ab-f3bc-4c5d-af3a-636761e18f69,DISK], DatanodeInfoWithStorage[127.0.0.1:39873,DS-ae61cff0-656f-4d87-abca-a54b7733ddf1,DISK], DatanodeInfoWithStorage[127.0.0.1:40642,DS-edc5577e-63b4-4dc0-bf66-413d63804c6b,DISK], DatanodeInfoWithStorage[127.0.0.1:35976,DS-2a31c303-552a-4d97-b171-60c422fe0ef0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1447793031-172.17.0.10-1596987286924:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46461,DS-2afdef82-3a96-4265-bb62-0781f6846971,DISK], DatanodeInfoWithStorage[127.0.0.1:35594,DS-0cb1b52d-350d-4560-a332-2dae9dfef607,DISK], DatanodeInfoWithStorage[127.0.0.1:35476,DS-ddbcc0d9-8bc8-4073-81b3-39edfd4f8fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:45431,DS-96008014-9788-4aa5-9882-7a5495461fb5,DISK], DatanodeInfoWithStorage[127.0.0.1:37251,DS-fe8694ab-f3bc-4c5d-af3a-636761e18f69,DISK], DatanodeInfoWithStorage[127.0.0.1:39873,DS-ae61cff0-656f-4d87-abca-a54b7733ddf1,DISK], DatanodeInfoWithStorage[127.0.0.1:40642,DS-edc5577e-63b4-4dc0-bf66-413d63804c6b,DISK], DatanodeInfoWithStorage[127.0.0.1:35976,DS-2a31c303-552a-4d97-b171-60c422fe0ef0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 4791
