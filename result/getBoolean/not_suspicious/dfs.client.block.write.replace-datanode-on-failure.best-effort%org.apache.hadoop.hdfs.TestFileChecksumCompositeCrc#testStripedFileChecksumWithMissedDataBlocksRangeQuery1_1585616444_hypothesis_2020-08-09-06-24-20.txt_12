reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1961072852-172.17.0.16-1596954452645:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36886,DS-0d6a5ca0-b7e6-4b0d-9cd7-a6417fd49705,DISK], DatanodeInfoWithStorage[127.0.0.1:46801,DS-2e457b05-32c7-482a-b5b0-770d91f4d3c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37998,DS-484388c9-2ee8-4b5c-b59f-81603ff2d958,DISK], DatanodeInfoWithStorage[127.0.0.1:46743,DS-b6e78ed9-b52c-46e4-9c7d-8d193ca75a59,DISK], DatanodeInfoWithStorage[127.0.0.1:43775,DS-67e0f9cd-d765-4055-9d80-ad24e5a25eff,DISK], DatanodeInfoWithStorage[127.0.0.1:44641,DS-6bb5447d-884e-4710-adf4-2fe445821a64,DISK], DatanodeInfoWithStorage[127.0.0.1:35299,DS-8b1bc3ed-7291-462a-9dd6-547e6895a133,DISK], DatanodeInfoWithStorage[127.0.0.1:44770,DS-05f78dce-3dc2-4074-8126-6d1b01e0d513,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1961072852-172.17.0.16-1596954452645:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36886,DS-0d6a5ca0-b7e6-4b0d-9cd7-a6417fd49705,DISK], DatanodeInfoWithStorage[127.0.0.1:46801,DS-2e457b05-32c7-482a-b5b0-770d91f4d3c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37998,DS-484388c9-2ee8-4b5c-b59f-81603ff2d958,DISK], DatanodeInfoWithStorage[127.0.0.1:46743,DS-b6e78ed9-b52c-46e4-9c7d-8d193ca75a59,DISK], DatanodeInfoWithStorage[127.0.0.1:43775,DS-67e0f9cd-d765-4055-9d80-ad24e5a25eff,DISK], DatanodeInfoWithStorage[127.0.0.1:44641,DS-6bb5447d-884e-4710-adf4-2fe445821a64,DISK], DatanodeInfoWithStorage[127.0.0.1:35299,DS-8b1bc3ed-7291-462a-9dd6-547e6895a133,DISK], DatanodeInfoWithStorage[127.0.0.1:44770,DS-05f78dce-3dc2-4074-8126-6d1b01e0d513,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-751052369-172.17.0.16-1596955164646:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44694,DS-ef1232ee-04af-4fad-9f62-ba3f9597a258,DISK], DatanodeInfoWithStorage[127.0.0.1:40504,DS-f693f95e-206b-4f81-8cbd-f99c6ee66da3,DISK], DatanodeInfoWithStorage[127.0.0.1:39521,DS-758c9051-bd3a-4516-9a1e-d338036971f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36678,DS-d16b9bfd-b81c-4e94-bc14-eeaeb19e6747,DISK], DatanodeInfoWithStorage[127.0.0.1:36807,DS-7e27538f-151d-41ab-87a3-22580e15b5e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39974,DS-f699fb9a-b61b-4eee-b5e6-62324dd25d19,DISK], DatanodeInfoWithStorage[127.0.0.1:37537,DS-f1040cfb-b2f2-4416-b707-9157219f5568,DISK], DatanodeInfoWithStorage[127.0.0.1:40559,DS-844c3cb0-a23a-4a83-84b9-0d8022edd713,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-751052369-172.17.0.16-1596955164646:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44694,DS-ef1232ee-04af-4fad-9f62-ba3f9597a258,DISK], DatanodeInfoWithStorage[127.0.0.1:40504,DS-f693f95e-206b-4f81-8cbd-f99c6ee66da3,DISK], DatanodeInfoWithStorage[127.0.0.1:39521,DS-758c9051-bd3a-4516-9a1e-d338036971f2,DISK], DatanodeInfoWithStorage[127.0.0.1:36678,DS-d16b9bfd-b81c-4e94-bc14-eeaeb19e6747,DISK], DatanodeInfoWithStorage[127.0.0.1:36807,DS-7e27538f-151d-41ab-87a3-22580e15b5e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39974,DS-f699fb9a-b61b-4eee-b5e6-62324dd25d19,DISK], DatanodeInfoWithStorage[127.0.0.1:37537,DS-f1040cfb-b2f2-4416-b707-9157219f5568,DISK], DatanodeInfoWithStorage[127.0.0.1:40559,DS-844c3cb0-a23a-4a83-84b9-0d8022edd713,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1258246478-172.17.0.16-1596955639727:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41166,DS-72d72640-3cb6-4789-bce0-98549a31fb05,DISK], DatanodeInfoWithStorage[127.0.0.1:36770,DS-d4eedd1e-9dd1-4717-b623-051b321dbbd1,DISK], DatanodeInfoWithStorage[127.0.0.1:45594,DS-c5025703-282d-42ee-9445-243914ab5be2,DISK], DatanodeInfoWithStorage[127.0.0.1:42061,DS-b8939925-282d-434d-a685-0a01ae785b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:33764,DS-f2c3d746-7075-4200-9775-572368f4f9c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44476,DS-46ea1c5c-4ce1-416f-b4c1-951617ef5f11,DISK], DatanodeInfoWithStorage[127.0.0.1:45693,DS-baba5117-eec6-4dce-abd8-688cfe53b24b,DISK], DatanodeInfoWithStorage[127.0.0.1:37517,DS-953dc1d3-6940-48a2-8fe4-694c5f2a6fec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1258246478-172.17.0.16-1596955639727:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41166,DS-72d72640-3cb6-4789-bce0-98549a31fb05,DISK], DatanodeInfoWithStorage[127.0.0.1:36770,DS-d4eedd1e-9dd1-4717-b623-051b321dbbd1,DISK], DatanodeInfoWithStorage[127.0.0.1:45594,DS-c5025703-282d-42ee-9445-243914ab5be2,DISK], DatanodeInfoWithStorage[127.0.0.1:42061,DS-b8939925-282d-434d-a685-0a01ae785b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:33764,DS-f2c3d746-7075-4200-9775-572368f4f9c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44476,DS-46ea1c5c-4ce1-416f-b4c1-951617ef5f11,DISK], DatanodeInfoWithStorage[127.0.0.1:45693,DS-baba5117-eec6-4dce-abd8-688cfe53b24b,DISK], DatanodeInfoWithStorage[127.0.0.1:37517,DS-953dc1d3-6940-48a2-8fe4-694c5f2a6fec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-659469718-172.17.0.16-1596956219145:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33850,DS-76f6b898-6264-4cb8-816b-e7b879352215,DISK], DatanodeInfoWithStorage[127.0.0.1:38424,DS-4f835721-903b-4c0c-940d-9cd98f577d92,DISK], DatanodeInfoWithStorage[127.0.0.1:33971,DS-15f98172-285c-4c45-a35e-fa4a2cd19614,DISK], DatanodeInfoWithStorage[127.0.0.1:36379,DS-2dc29b10-db6e-41eb-8d42-f3c2d3399065,DISK], DatanodeInfoWithStorage[127.0.0.1:46325,DS-d705af9f-dca3-4f3a-b3c2-074077fb85ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40133,DS-4817bcd3-727a-4c60-b87b-8545a4361274,DISK], DatanodeInfoWithStorage[127.0.0.1:45937,DS-6617af2b-51d5-47c4-9d42-6c5b984b016d,DISK], DatanodeInfoWithStorage[127.0.0.1:38710,DS-6de915b0-50e6-4d1f-9345-570ac6fddad6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-659469718-172.17.0.16-1596956219145:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33850,DS-76f6b898-6264-4cb8-816b-e7b879352215,DISK], DatanodeInfoWithStorage[127.0.0.1:38424,DS-4f835721-903b-4c0c-940d-9cd98f577d92,DISK], DatanodeInfoWithStorage[127.0.0.1:33971,DS-15f98172-285c-4c45-a35e-fa4a2cd19614,DISK], DatanodeInfoWithStorage[127.0.0.1:36379,DS-2dc29b10-db6e-41eb-8d42-f3c2d3399065,DISK], DatanodeInfoWithStorage[127.0.0.1:46325,DS-d705af9f-dca3-4f3a-b3c2-074077fb85ba,DISK], DatanodeInfoWithStorage[127.0.0.1:40133,DS-4817bcd3-727a-4c60-b87b-8545a4361274,DISK], DatanodeInfoWithStorage[127.0.0.1:45937,DS-6617af2b-51d5-47c4-9d42-6c5b984b016d,DISK], DatanodeInfoWithStorage[127.0.0.1:38710,DS-6de915b0-50e6-4d1f-9345-570ac6fddad6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-16418778-172.17.0.16-1596956834547:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34842,DS-0654c051-d3e8-4e5e-8932-e32807d3f0c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38124,DS-13a7d128-411d-4627-8dc2-22597c046a1f,DISK], DatanodeInfoWithStorage[127.0.0.1:45668,DS-01b0202e-8980-4bf0-bab0-fbf437acdddb,DISK], DatanodeInfoWithStorage[127.0.0.1:43077,DS-57f6124e-0e23-431d-a2d5-a7e08515f998,DISK], DatanodeInfoWithStorage[127.0.0.1:36164,DS-fbbf0aec-d4f8-46a9-b2b4-d42beb16189f,DISK], DatanodeInfoWithStorage[127.0.0.1:46315,DS-e3d5c3a6-3396-4f0a-8f14-52c765d90014,DISK], DatanodeInfoWithStorage[127.0.0.1:40515,DS-a2487a36-1a88-45ef-93aa-922a8f61deae,DISK], DatanodeInfoWithStorage[127.0.0.1:45169,DS-8118e089-9383-450c-a79d-2c3702b91b74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-16418778-172.17.0.16-1596956834547:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34842,DS-0654c051-d3e8-4e5e-8932-e32807d3f0c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38124,DS-13a7d128-411d-4627-8dc2-22597c046a1f,DISK], DatanodeInfoWithStorage[127.0.0.1:45668,DS-01b0202e-8980-4bf0-bab0-fbf437acdddb,DISK], DatanodeInfoWithStorage[127.0.0.1:43077,DS-57f6124e-0e23-431d-a2d5-a7e08515f998,DISK], DatanodeInfoWithStorage[127.0.0.1:36164,DS-fbbf0aec-d4f8-46a9-b2b4-d42beb16189f,DISK], DatanodeInfoWithStorage[127.0.0.1:46315,DS-e3d5c3a6-3396-4f0a-8f14-52c765d90014,DISK], DatanodeInfoWithStorage[127.0.0.1:40515,DS-a2487a36-1a88-45ef-93aa-922a8f61deae,DISK], DatanodeInfoWithStorage[127.0.0.1:45169,DS-8118e089-9383-450c-a79d-2c3702b91b74,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-219438684-172.17.0.16-1596956872113:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36709,DS-86a015ce-9ab5-45f2-90a9-a3a0ff88cd27,DISK], DatanodeInfoWithStorage[127.0.0.1:45591,DS-ff95648e-79fd-46e8-b885-00a69ea4a59c,DISK], DatanodeInfoWithStorage[127.0.0.1:38096,DS-3183f41d-ab93-41c1-b022-7b03a7d00a10,DISK], DatanodeInfoWithStorage[127.0.0.1:44571,DS-b9f84ea1-b650-4170-a85c-739aec31f900,DISK], DatanodeInfoWithStorage[127.0.0.1:44839,DS-769038c0-b720-4d4d-8b26-262ccd3c6b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:33933,DS-13e18195-cfad-46a3-baf6-0e4d8b4e9125,DISK], DatanodeInfoWithStorage[127.0.0.1:43820,DS-562ddd2a-728d-429b-95f7-0c7a2b280613,DISK], DatanodeInfoWithStorage[127.0.0.1:44027,DS-0087e567-8d42-49e0-9efb-0c3594560a0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-219438684-172.17.0.16-1596956872113:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36709,DS-86a015ce-9ab5-45f2-90a9-a3a0ff88cd27,DISK], DatanodeInfoWithStorage[127.0.0.1:45591,DS-ff95648e-79fd-46e8-b885-00a69ea4a59c,DISK], DatanodeInfoWithStorage[127.0.0.1:38096,DS-3183f41d-ab93-41c1-b022-7b03a7d00a10,DISK], DatanodeInfoWithStorage[127.0.0.1:44571,DS-b9f84ea1-b650-4170-a85c-739aec31f900,DISK], DatanodeInfoWithStorage[127.0.0.1:44839,DS-769038c0-b720-4d4d-8b26-262ccd3c6b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:33933,DS-13e18195-cfad-46a3-baf6-0e4d8b4e9125,DISK], DatanodeInfoWithStorage[127.0.0.1:43820,DS-562ddd2a-728d-429b-95f7-0c7a2b280613,DISK], DatanodeInfoWithStorage[127.0.0.1:44027,DS-0087e567-8d42-49e0-9efb-0c3594560a0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2009861316-172.17.0.16-1596957944453:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40101,DS-94199bec-5baa-42a8-8be1-026c32d4b290,DISK], DatanodeInfoWithStorage[127.0.0.1:36713,DS-e41ec626-e058-432a-9163-bff16865aacd,DISK], DatanodeInfoWithStorage[127.0.0.1:38861,DS-443cbdf1-9d35-40ad-a36e-760ce6d419c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42157,DS-878dfd53-e961-4e4e-9b04-4a90f6feed37,DISK], DatanodeInfoWithStorage[127.0.0.1:41045,DS-b740ab7b-b2e6-422b-a383-344ceb479881,DISK], DatanodeInfoWithStorage[127.0.0.1:35971,DS-fafd1ed2-0aea-46c0-8a88-932341b57189,DISK], DatanodeInfoWithStorage[127.0.0.1:37634,DS-548643d6-a755-4574-b617-a401e7bff629,DISK], DatanodeInfoWithStorage[127.0.0.1:34695,DS-c147865b-f59f-49b9-86e3-2800a00495c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2009861316-172.17.0.16-1596957944453:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40101,DS-94199bec-5baa-42a8-8be1-026c32d4b290,DISK], DatanodeInfoWithStorage[127.0.0.1:36713,DS-e41ec626-e058-432a-9163-bff16865aacd,DISK], DatanodeInfoWithStorage[127.0.0.1:38861,DS-443cbdf1-9d35-40ad-a36e-760ce6d419c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42157,DS-878dfd53-e961-4e4e-9b04-4a90f6feed37,DISK], DatanodeInfoWithStorage[127.0.0.1:41045,DS-b740ab7b-b2e6-422b-a383-344ceb479881,DISK], DatanodeInfoWithStorage[127.0.0.1:35971,DS-fafd1ed2-0aea-46c0-8a88-932341b57189,DISK], DatanodeInfoWithStorage[127.0.0.1:37634,DS-548643d6-a755-4574-b617-a401e7bff629,DISK], DatanodeInfoWithStorage[127.0.0.1:34695,DS-c147865b-f59f-49b9-86e3-2800a00495c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1629290661-172.17.0.16-1596958004594:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43647,DS-019f9ac9-0999-47e5-9ae5-c7b54ad47484,DISK], DatanodeInfoWithStorage[127.0.0.1:37841,DS-051c1745-5f91-4269-8dbd-46694bfd1fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:39866,DS-91d9e6d3-8c2b-4799-81c8-cbe69cb9ba39,DISK], DatanodeInfoWithStorage[127.0.0.1:41632,DS-2ba746dc-3b37-4936-9a5e-7275f0e1483f,DISK], DatanodeInfoWithStorage[127.0.0.1:40594,DS-46c7ce6e-1d96-4b08-8e24-b740ebb75436,DISK], DatanodeInfoWithStorage[127.0.0.1:44079,DS-612191c6-0ffd-4b05-b4ae-e71ebdabc069,DISK], DatanodeInfoWithStorage[127.0.0.1:41483,DS-a33539a1-6450-4621-98fb-46320d3d6bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:39252,DS-83ddba48-f395-49a0-9269-5c2d68804c39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1629290661-172.17.0.16-1596958004594:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43647,DS-019f9ac9-0999-47e5-9ae5-c7b54ad47484,DISK], DatanodeInfoWithStorage[127.0.0.1:37841,DS-051c1745-5f91-4269-8dbd-46694bfd1fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:39866,DS-91d9e6d3-8c2b-4799-81c8-cbe69cb9ba39,DISK], DatanodeInfoWithStorage[127.0.0.1:41632,DS-2ba746dc-3b37-4936-9a5e-7275f0e1483f,DISK], DatanodeInfoWithStorage[127.0.0.1:40594,DS-46c7ce6e-1d96-4b08-8e24-b740ebb75436,DISK], DatanodeInfoWithStorage[127.0.0.1:44079,DS-612191c6-0ffd-4b05-b4ae-e71ebdabc069,DISK], DatanodeInfoWithStorage[127.0.0.1:41483,DS-a33539a1-6450-4621-98fb-46320d3d6bd9,DISK], DatanodeInfoWithStorage[127.0.0.1:39252,DS-83ddba48-f395-49a0-9269-5c2d68804c39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1632128873-172.17.0.16-1596958376357:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35309,DS-4316525a-5f96-4067-b8be-bb6ea0218f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:44100,DS-73aa888c-e3f5-4821-88a1-f7ac74b3ecbe,DISK], DatanodeInfoWithStorage[127.0.0.1:35248,DS-bd7aeba4-1714-4043-9204-05507d0b4079,DISK], DatanodeInfoWithStorage[127.0.0.1:42754,DS-79c52f61-a9db-42c9-9400-afdb40d891f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35517,DS-cf701cc4-41c5-4b92-8536-c531616f8cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:42950,DS-edf65fab-5c16-4ed4-9ce4-83d482abd929,DISK], DatanodeInfoWithStorage[127.0.0.1:36413,DS-78e28c9f-390c-49d2-8ffb-73cba1240622,DISK], DatanodeInfoWithStorage[127.0.0.1:45601,DS-cd4743f8-56ef-4def-b058-1e37befd74ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1632128873-172.17.0.16-1596958376357:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35309,DS-4316525a-5f96-4067-b8be-bb6ea0218f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:44100,DS-73aa888c-e3f5-4821-88a1-f7ac74b3ecbe,DISK], DatanodeInfoWithStorage[127.0.0.1:35248,DS-bd7aeba4-1714-4043-9204-05507d0b4079,DISK], DatanodeInfoWithStorage[127.0.0.1:42754,DS-79c52f61-a9db-42c9-9400-afdb40d891f2,DISK], DatanodeInfoWithStorage[127.0.0.1:35517,DS-cf701cc4-41c5-4b92-8536-c531616f8cfc,DISK], DatanodeInfoWithStorage[127.0.0.1:42950,DS-edf65fab-5c16-4ed4-9ce4-83d482abd929,DISK], DatanodeInfoWithStorage[127.0.0.1:36413,DS-78e28c9f-390c-49d2-8ffb-73cba1240622,DISK], DatanodeInfoWithStorage[127.0.0.1:45601,DS-cd4743f8-56ef-4def-b058-1e37befd74ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-354319137-172.17.0.16-1596958470505:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37011,DS-6d3bf485-2ad8-4a08-bf54-ad83f163b6ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45449,DS-7c91ad2b-eaa1-422a-b5f7-e74d17591e10,DISK], DatanodeInfoWithStorage[127.0.0.1:41795,DS-e3a8604b-d05c-4816-bbcd-5cdb88750786,DISK], DatanodeInfoWithStorage[127.0.0.1:33441,DS-62833f7d-707f-4638-9ac6-d1aaa6c03f4a,DISK], DatanodeInfoWithStorage[127.0.0.1:43846,DS-60e4e7f5-f95f-49fa-adb0-85aad5342431,DISK], DatanodeInfoWithStorage[127.0.0.1:46831,DS-1f84b0ad-7519-40a1-8df6-9555160ad96d,DISK], DatanodeInfoWithStorage[127.0.0.1:33656,DS-575b1123-b335-4987-a877-b1ef4b67509f,DISK], DatanodeInfoWithStorage[127.0.0.1:38558,DS-6ad426a9-341a-4c0e-87b9-e5239ec6bd09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-354319137-172.17.0.16-1596958470505:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37011,DS-6d3bf485-2ad8-4a08-bf54-ad83f163b6ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45449,DS-7c91ad2b-eaa1-422a-b5f7-e74d17591e10,DISK], DatanodeInfoWithStorage[127.0.0.1:41795,DS-e3a8604b-d05c-4816-bbcd-5cdb88750786,DISK], DatanodeInfoWithStorage[127.0.0.1:33441,DS-62833f7d-707f-4638-9ac6-d1aaa6c03f4a,DISK], DatanodeInfoWithStorage[127.0.0.1:43846,DS-60e4e7f5-f95f-49fa-adb0-85aad5342431,DISK], DatanodeInfoWithStorage[127.0.0.1:46831,DS-1f84b0ad-7519-40a1-8df6-9555160ad96d,DISK], DatanodeInfoWithStorage[127.0.0.1:33656,DS-575b1123-b335-4987-a877-b1ef4b67509f,DISK], DatanodeInfoWithStorage[127.0.0.1:38558,DS-6ad426a9-341a-4c0e-87b9-e5239ec6bd09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-692311212-172.17.0.16-1596958724672:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43488,DS-1991b49e-26bc-45d9-b057-3891019864c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42746,DS-c9f60ad0-2488-42f3-bff1-2c026c3060e6,DISK], DatanodeInfoWithStorage[127.0.0.1:34718,DS-6a663b28-7d99-4733-aa02-36ce1b0e3e54,DISK], DatanodeInfoWithStorage[127.0.0.1:45299,DS-6a8d09e5-3fe3-44b6-abc1-c2d2ca65ee2d,DISK], DatanodeInfoWithStorage[127.0.0.1:39709,DS-98345d1b-ef94-4f00-9c69-20087defba57,DISK], DatanodeInfoWithStorage[127.0.0.1:32770,DS-081130a2-64ba-4992-84fd-bba4a0302045,DISK], DatanodeInfoWithStorage[127.0.0.1:38577,DS-26e98234-5329-4e40-bd96-87695d3e5ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:38922,DS-259ba17b-c2c3-4edf-9ce7-6b1d9839084c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-692311212-172.17.0.16-1596958724672:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43488,DS-1991b49e-26bc-45d9-b057-3891019864c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42746,DS-c9f60ad0-2488-42f3-bff1-2c026c3060e6,DISK], DatanodeInfoWithStorage[127.0.0.1:34718,DS-6a663b28-7d99-4733-aa02-36ce1b0e3e54,DISK], DatanodeInfoWithStorage[127.0.0.1:45299,DS-6a8d09e5-3fe3-44b6-abc1-c2d2ca65ee2d,DISK], DatanodeInfoWithStorage[127.0.0.1:39709,DS-98345d1b-ef94-4f00-9c69-20087defba57,DISK], DatanodeInfoWithStorage[127.0.0.1:32770,DS-081130a2-64ba-4992-84fd-bba4a0302045,DISK], DatanodeInfoWithStorage[127.0.0.1:38577,DS-26e98234-5329-4e40-bd96-87695d3e5ff2,DISK], DatanodeInfoWithStorage[127.0.0.1:38922,DS-259ba17b-c2c3-4edf-9ce7-6b1d9839084c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-400150213-172.17.0.16-1596958971254:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38955,DS-13afc571-d710-4d76-baa1-f58054711c03,DISK], DatanodeInfoWithStorage[127.0.0.1:40612,DS-2b0206cb-43d9-4d28-b21e-2515f7eca78e,DISK], DatanodeInfoWithStorage[127.0.0.1:41002,DS-700131c3-7a93-441d-a9a8-888ee8275f6a,DISK], DatanodeInfoWithStorage[127.0.0.1:44508,DS-854d5059-0dc9-47e7-8076-754a388e9ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:35916,DS-9f689b17-80d9-4ad1-8a65-eae4a9c8df2c,DISK], DatanodeInfoWithStorage[127.0.0.1:40110,DS-b117e4f5-09eb-4bd1-a0da-717e472289e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45175,DS-7a793c6b-b9ac-4f65-99c0-186b4877a088,DISK], DatanodeInfoWithStorage[127.0.0.1:38207,DS-0f49bf86-a2ae-49f4-92f0-d73385c6287a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-400150213-172.17.0.16-1596958971254:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38955,DS-13afc571-d710-4d76-baa1-f58054711c03,DISK], DatanodeInfoWithStorage[127.0.0.1:40612,DS-2b0206cb-43d9-4d28-b21e-2515f7eca78e,DISK], DatanodeInfoWithStorage[127.0.0.1:41002,DS-700131c3-7a93-441d-a9a8-888ee8275f6a,DISK], DatanodeInfoWithStorage[127.0.0.1:44508,DS-854d5059-0dc9-47e7-8076-754a388e9ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:35916,DS-9f689b17-80d9-4ad1-8a65-eae4a9c8df2c,DISK], DatanodeInfoWithStorage[127.0.0.1:40110,DS-b117e4f5-09eb-4bd1-a0da-717e472289e9,DISK], DatanodeInfoWithStorage[127.0.0.1:45175,DS-7a793c6b-b9ac-4f65-99c0-186b4877a088,DISK], DatanodeInfoWithStorage[127.0.0.1:38207,DS-0f49bf86-a2ae-49f4-92f0-d73385c6287a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-827468407-172.17.0.16-1596959458981:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40561,DS-a5dcfa4a-4156-4e02-8568-8182dc7f3075,DISK], DatanodeInfoWithStorage[127.0.0.1:32867,DS-468435f9-06fa-4b35-b862-1556a3cc998f,DISK], DatanodeInfoWithStorage[127.0.0.1:36222,DS-41a96626-ef16-40c5-ae46-1e30a81541db,DISK], DatanodeInfoWithStorage[127.0.0.1:34127,DS-edc8b86a-e4c8-4437-b147-08585a267a36,DISK], DatanodeInfoWithStorage[127.0.0.1:46172,DS-e05f6b57-62b2-4ba2-a698-0bed71e8c45d,DISK], DatanodeInfoWithStorage[127.0.0.1:37159,DS-6eb9cc26-8dfe-4776-995f-51af8d221391,DISK], DatanodeInfoWithStorage[127.0.0.1:44735,DS-b7d4dba8-e63c-45c3-9b62-a236144806a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39836,DS-abdc74dc-7c6c-44c7-8e71-ebd8df648b75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-827468407-172.17.0.16-1596959458981:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40561,DS-a5dcfa4a-4156-4e02-8568-8182dc7f3075,DISK], DatanodeInfoWithStorage[127.0.0.1:32867,DS-468435f9-06fa-4b35-b862-1556a3cc998f,DISK], DatanodeInfoWithStorage[127.0.0.1:36222,DS-41a96626-ef16-40c5-ae46-1e30a81541db,DISK], DatanodeInfoWithStorage[127.0.0.1:34127,DS-edc8b86a-e4c8-4437-b147-08585a267a36,DISK], DatanodeInfoWithStorage[127.0.0.1:46172,DS-e05f6b57-62b2-4ba2-a698-0bed71e8c45d,DISK], DatanodeInfoWithStorage[127.0.0.1:37159,DS-6eb9cc26-8dfe-4776-995f-51af8d221391,DISK], DatanodeInfoWithStorage[127.0.0.1:44735,DS-b7d4dba8-e63c-45c3-9b62-a236144806a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39836,DS-abdc74dc-7c6c-44c7-8e71-ebd8df648b75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1425014526-172.17.0.16-1596959619501:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36091,DS-83895ff4-563d-4bd1-9177-4a2703739202,DISK], DatanodeInfoWithStorage[127.0.0.1:35102,DS-1503154e-5543-41ef-88a1-089cd04808d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39589,DS-83781c1a-ec8c-4da3-9bec-1c26bec3982e,DISK], DatanodeInfoWithStorage[127.0.0.1:41675,DS-2c4269d8-15df-4f93-8155-65d2f0437d1e,DISK], DatanodeInfoWithStorage[127.0.0.1:45389,DS-7f305450-0c25-48bd-b6c0-224547ae6cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:34816,DS-53e88224-9918-4485-9e7d-bfc5c822431c,DISK], DatanodeInfoWithStorage[127.0.0.1:35045,DS-61b1f968-777e-440e-ab32-97577e756ecd,DISK], DatanodeInfoWithStorage[127.0.0.1:35349,DS-972a97d4-e916-4dc0-9b20-69ff152dccd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1425014526-172.17.0.16-1596959619501:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36091,DS-83895ff4-563d-4bd1-9177-4a2703739202,DISK], DatanodeInfoWithStorage[127.0.0.1:35102,DS-1503154e-5543-41ef-88a1-089cd04808d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39589,DS-83781c1a-ec8c-4da3-9bec-1c26bec3982e,DISK], DatanodeInfoWithStorage[127.0.0.1:41675,DS-2c4269d8-15df-4f93-8155-65d2f0437d1e,DISK], DatanodeInfoWithStorage[127.0.0.1:45389,DS-7f305450-0c25-48bd-b6c0-224547ae6cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:34816,DS-53e88224-9918-4485-9e7d-bfc5c822431c,DISK], DatanodeInfoWithStorage[127.0.0.1:35045,DS-61b1f968-777e-440e-ab32-97577e756ecd,DISK], DatanodeInfoWithStorage[127.0.0.1:35349,DS-972a97d4-e916-4dc0-9b20-69ff152dccd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-686711274-172.17.0.16-1596960509444:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38891,DS-e582548f-55ce-4b31-8250-f7cf6402ebb8,DISK], DatanodeInfoWithStorage[127.0.0.1:40178,DS-2e510437-1989-41e0-950b-d7da60faa0d6,DISK], DatanodeInfoWithStorage[127.0.0.1:36632,DS-6b0d4ff5-750c-4fb3-b054-150bc103b5a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36349,DS-8b954596-ba21-4031-9eb5-7c697cfc79f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40710,DS-3f86daaa-590c-46f0-beb8-b200811f9c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:46184,DS-8bda694f-c2c1-43e8-8e2f-d060dd810499,DISK], DatanodeInfoWithStorage[127.0.0.1:39820,DS-285137e2-dade-4120-a533-103a84553bf9,DISK], DatanodeInfoWithStorage[127.0.0.1:33297,DS-eb919a21-a8fd-4a88-b75b-1d6589ea0f5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-686711274-172.17.0.16-1596960509444:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38891,DS-e582548f-55ce-4b31-8250-f7cf6402ebb8,DISK], DatanodeInfoWithStorage[127.0.0.1:40178,DS-2e510437-1989-41e0-950b-d7da60faa0d6,DISK], DatanodeInfoWithStorage[127.0.0.1:36632,DS-6b0d4ff5-750c-4fb3-b054-150bc103b5a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36349,DS-8b954596-ba21-4031-9eb5-7c697cfc79f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40710,DS-3f86daaa-590c-46f0-beb8-b200811f9c5d,DISK], DatanodeInfoWithStorage[127.0.0.1:46184,DS-8bda694f-c2c1-43e8-8e2f-d060dd810499,DISK], DatanodeInfoWithStorage[127.0.0.1:39820,DS-285137e2-dade-4120-a533-103a84553bf9,DISK], DatanodeInfoWithStorage[127.0.0.1:33297,DS-eb919a21-a8fd-4a88-b75b-1d6589ea0f5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.block.write.replace-datanode-on-failure.best-effort
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-306265499-172.17.0.16-1596960731569:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36905,DS-6fd0dcd4-f571-4354-974a-6991c9fd8a89,DISK], DatanodeInfoWithStorage[127.0.0.1:40844,DS-25c100ee-3745-44b4-8b51-51fc2f5e8e82,DISK], DatanodeInfoWithStorage[127.0.0.1:34253,DS-f686fb84-945c-4232-a82a-ccff79266aac,DISK], DatanodeInfoWithStorage[127.0.0.1:46660,DS-c4f19f92-0f6a-4e69-8b85-9f11bcd9b2c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33386,DS-fbdf535f-0b55-47b8-a6a5-37cac1b4fa45,DISK], DatanodeInfoWithStorage[127.0.0.1:35596,DS-9fa70325-0a54-4523-a1aa-35ddb23a78c2,DISK], DatanodeInfoWithStorage[127.0.0.1:32934,DS-0495243c-b901-40b2-a688-27b69e9643e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45395,DS-ca253f9e-23ee-4dba-9745-0cb55764ab38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-306265499-172.17.0.16-1596960731569:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36905,DS-6fd0dcd4-f571-4354-974a-6991c9fd8a89,DISK], DatanodeInfoWithStorage[127.0.0.1:40844,DS-25c100ee-3745-44b4-8b51-51fc2f5e8e82,DISK], DatanodeInfoWithStorage[127.0.0.1:34253,DS-f686fb84-945c-4232-a82a-ccff79266aac,DISK], DatanodeInfoWithStorage[127.0.0.1:46660,DS-c4f19f92-0f6a-4e69-8b85-9f11bcd9b2c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33386,DS-fbdf535f-0b55-47b8-a6a5-37cac1b4fa45,DISK], DatanodeInfoWithStorage[127.0.0.1:35596,DS-9fa70325-0a54-4523-a1aa-35ddb23a78c2,DISK], DatanodeInfoWithStorage[127.0.0.1:32934,DS-0495243c-b901-40b2-a688-27b69e9643e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45395,DS-ca253f9e-23ee-4dba-9745-0cb55764ab38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 6639
