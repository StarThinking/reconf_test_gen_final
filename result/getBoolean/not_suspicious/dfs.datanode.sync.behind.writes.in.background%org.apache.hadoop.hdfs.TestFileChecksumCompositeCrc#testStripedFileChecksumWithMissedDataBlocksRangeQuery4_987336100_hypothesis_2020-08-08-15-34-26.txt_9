reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-626199632-172.17.0.21-1596900957255:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39116,DS-a0cb5580-ed2c-45e1-a915-64637b9aa8eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35143,DS-012c3d99-7f06-486a-a438-a255ef3c79d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43992,DS-dba8c4ff-9d35-413b-ba0d-6dd956f4bbf1,DISK], DatanodeInfoWithStorage[127.0.0.1:41310,DS-836e5be8-5a7f-4b7c-83ab-0212bcdc6993,DISK], DatanodeInfoWithStorage[127.0.0.1:33247,DS-0d59e17c-754e-4551-b899-9f086b6b862e,DISK], DatanodeInfoWithStorage[127.0.0.1:43781,DS-8c68040f-7b9f-4c70-af08-9a89592c21bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37298,DS-65db66ee-5708-467a-beae-2707ff0bd4d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39720,DS-b41e26fe-b683-4e66-ab0e-21ced70a887d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-626199632-172.17.0.21-1596900957255:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39116,DS-a0cb5580-ed2c-45e1-a915-64637b9aa8eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35143,DS-012c3d99-7f06-486a-a438-a255ef3c79d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43992,DS-dba8c4ff-9d35-413b-ba0d-6dd956f4bbf1,DISK], DatanodeInfoWithStorage[127.0.0.1:41310,DS-836e5be8-5a7f-4b7c-83ab-0212bcdc6993,DISK], DatanodeInfoWithStorage[127.0.0.1:33247,DS-0d59e17c-754e-4551-b899-9f086b6b862e,DISK], DatanodeInfoWithStorage[127.0.0.1:43781,DS-8c68040f-7b9f-4c70-af08-9a89592c21bb,DISK], DatanodeInfoWithStorage[127.0.0.1:37298,DS-65db66ee-5708-467a-beae-2707ff0bd4d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39720,DS-b41e26fe-b683-4e66-ab0e-21ced70a887d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-519162832-172.17.0.21-1596901166424:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33079,DS-0787874e-84dd-46d0-8042-c3c477f8867f,DISK], DatanodeInfoWithStorage[127.0.0.1:39785,DS-007d444e-ccbf-4707-a86a-fe11d69aa8dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35596,DS-848e3eac-079f-4465-a7b2-7e5604be3d7f,DISK], DatanodeInfoWithStorage[127.0.0.1:36883,DS-e86a011a-a2e6-4c01-a474-692cf0a684ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34990,DS-d5d7c001-1593-41ae-ae05-5e6210ded6e6,DISK], DatanodeInfoWithStorage[127.0.0.1:43917,DS-738c35c3-01cd-411b-ac1c-a9babb0e86a0,DISK], DatanodeInfoWithStorage[127.0.0.1:32985,DS-11404e3c-cbd2-4b08-826a-1d8869d32e40,DISK], DatanodeInfoWithStorage[127.0.0.1:46858,DS-051c3ab3-1b74-4d57-97be-d25284620a16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-519162832-172.17.0.21-1596901166424:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33079,DS-0787874e-84dd-46d0-8042-c3c477f8867f,DISK], DatanodeInfoWithStorage[127.0.0.1:39785,DS-007d444e-ccbf-4707-a86a-fe11d69aa8dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35596,DS-848e3eac-079f-4465-a7b2-7e5604be3d7f,DISK], DatanodeInfoWithStorage[127.0.0.1:36883,DS-e86a011a-a2e6-4c01-a474-692cf0a684ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34990,DS-d5d7c001-1593-41ae-ae05-5e6210ded6e6,DISK], DatanodeInfoWithStorage[127.0.0.1:43917,DS-738c35c3-01cd-411b-ac1c-a9babb0e86a0,DISK], DatanodeInfoWithStorage[127.0.0.1:32985,DS-11404e3c-cbd2-4b08-826a-1d8869d32e40,DISK], DatanodeInfoWithStorage[127.0.0.1:46858,DS-051c3ab3-1b74-4d57-97be-d25284620a16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1669810829-172.17.0.21-1596901195491:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36374,DS-ca8110ba-07ce-464d-bf1f-f3485c862b23,DISK], DatanodeInfoWithStorage[127.0.0.1:39222,DS-507e3599-7ca2-4788-923e-59fd58bf7a97,DISK], DatanodeInfoWithStorage[127.0.0.1:43907,DS-dbc093ea-3875-4229-b17b-203096392f5a,DISK], DatanodeInfoWithStorage[127.0.0.1:33094,DS-28b12dac-edad-404d-936b-d8921dfc772f,DISK], DatanodeInfoWithStorage[127.0.0.1:45323,DS-1d573ead-be6b-41a7-817c-63183923529c,DISK], DatanodeInfoWithStorage[127.0.0.1:41079,DS-0b06549b-a252-45fb-831a-aa4493e96134,DISK], DatanodeInfoWithStorage[127.0.0.1:46798,DS-06dff27d-e527-4c1d-b3ee-037c96956eda,DISK], DatanodeInfoWithStorage[127.0.0.1:44293,DS-1281d308-b312-42a2-8a29-dc677eea5958,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1669810829-172.17.0.21-1596901195491:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36374,DS-ca8110ba-07ce-464d-bf1f-f3485c862b23,DISK], DatanodeInfoWithStorage[127.0.0.1:39222,DS-507e3599-7ca2-4788-923e-59fd58bf7a97,DISK], DatanodeInfoWithStorage[127.0.0.1:43907,DS-dbc093ea-3875-4229-b17b-203096392f5a,DISK], DatanodeInfoWithStorage[127.0.0.1:33094,DS-28b12dac-edad-404d-936b-d8921dfc772f,DISK], DatanodeInfoWithStorage[127.0.0.1:45323,DS-1d573ead-be6b-41a7-817c-63183923529c,DISK], DatanodeInfoWithStorage[127.0.0.1:41079,DS-0b06549b-a252-45fb-831a-aa4493e96134,DISK], DatanodeInfoWithStorage[127.0.0.1:46798,DS-06dff27d-e527-4c1d-b3ee-037c96956eda,DISK], DatanodeInfoWithStorage[127.0.0.1:44293,DS-1281d308-b312-42a2-8a29-dc677eea5958,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1130709635-172.17.0.21-1596901334512:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34028,DS-2900a1e2-c3f8-4aeb-ba28-a832986fdc67,DISK], DatanodeInfoWithStorage[127.0.0.1:41165,DS-e0794e45-17ad-4c77-983b-eb166b0a3249,DISK], DatanodeInfoWithStorage[127.0.0.1:39796,DS-ef48d736-421f-4019-bbcb-b0ee86f0b771,DISK], DatanodeInfoWithStorage[127.0.0.1:39030,DS-bb740334-5bd7-4a1a-8881-807be73b724b,DISK], DatanodeInfoWithStorage[127.0.0.1:39438,DS-de3ead76-f5b8-43b8-bb6b-9bbbb520934f,DISK], DatanodeInfoWithStorage[127.0.0.1:41989,DS-a6133c02-b296-4227-9c79-aa84e3714c94,DISK], DatanodeInfoWithStorage[127.0.0.1:44856,DS-80c79384-4b4a-408e-bdbd-d82f9b23e72a,DISK], DatanodeInfoWithStorage[127.0.0.1:36085,DS-d2f8774b-8a92-431a-9730-15482ca2f1b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1130709635-172.17.0.21-1596901334512:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34028,DS-2900a1e2-c3f8-4aeb-ba28-a832986fdc67,DISK], DatanodeInfoWithStorage[127.0.0.1:41165,DS-e0794e45-17ad-4c77-983b-eb166b0a3249,DISK], DatanodeInfoWithStorage[127.0.0.1:39796,DS-ef48d736-421f-4019-bbcb-b0ee86f0b771,DISK], DatanodeInfoWithStorage[127.0.0.1:39030,DS-bb740334-5bd7-4a1a-8881-807be73b724b,DISK], DatanodeInfoWithStorage[127.0.0.1:39438,DS-de3ead76-f5b8-43b8-bb6b-9bbbb520934f,DISK], DatanodeInfoWithStorage[127.0.0.1:41989,DS-a6133c02-b296-4227-9c79-aa84e3714c94,DISK], DatanodeInfoWithStorage[127.0.0.1:44856,DS-80c79384-4b4a-408e-bdbd-d82f9b23e72a,DISK], DatanodeInfoWithStorage[127.0.0.1:36085,DS-d2f8774b-8a92-431a-9730-15482ca2f1b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-892700338-172.17.0.21-1596902146971:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41845,DS-69645a05-1458-4a98-98f8-dac008268503,DISK], DatanodeInfoWithStorage[127.0.0.1:42731,DS-15dc899f-9dde-4338-8e18-9817393b2718,DISK], DatanodeInfoWithStorage[127.0.0.1:43666,DS-efca9e7d-3d95-4616-bc7c-463089ac6acb,DISK], DatanodeInfoWithStorage[127.0.0.1:44133,DS-ad13031d-28cd-465b-b26c-6364b295e66f,DISK], DatanodeInfoWithStorage[127.0.0.1:34117,DS-d6043874-add3-4530-89ed-5ca6620d7560,DISK], DatanodeInfoWithStorage[127.0.0.1:36411,DS-ebe949aa-d066-4b37-8c18-fba9573bc9d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44344,DS-3e4c169e-fff2-41a6-b5f1-3b9a6b0a9c66,DISK], DatanodeInfoWithStorage[127.0.0.1:36142,DS-7d10134f-657a-44ae-855c-f09e781c10b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-892700338-172.17.0.21-1596902146971:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41845,DS-69645a05-1458-4a98-98f8-dac008268503,DISK], DatanodeInfoWithStorage[127.0.0.1:42731,DS-15dc899f-9dde-4338-8e18-9817393b2718,DISK], DatanodeInfoWithStorage[127.0.0.1:43666,DS-efca9e7d-3d95-4616-bc7c-463089ac6acb,DISK], DatanodeInfoWithStorage[127.0.0.1:44133,DS-ad13031d-28cd-465b-b26c-6364b295e66f,DISK], DatanodeInfoWithStorage[127.0.0.1:34117,DS-d6043874-add3-4530-89ed-5ca6620d7560,DISK], DatanodeInfoWithStorage[127.0.0.1:36411,DS-ebe949aa-d066-4b37-8c18-fba9573bc9d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44344,DS-3e4c169e-fff2-41a6-b5f1-3b9a6b0a9c66,DISK], DatanodeInfoWithStorage[127.0.0.1:36142,DS-7d10134f-657a-44ae-855c-f09e781c10b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1413112615-172.17.0.21-1596902467523:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39397,DS-d9c4d7fe-9495-4821-a5a4-6af5aefc94f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44950,DS-605f8212-2fca-4810-af46-159fbc090874,DISK], DatanodeInfoWithStorage[127.0.0.1:42074,DS-5e9bc30b-9f46-4087-aadb-0def32d47009,DISK], DatanodeInfoWithStorage[127.0.0.1:42255,DS-9d69441b-8028-4fa2-a203-8edfe2d88074,DISK], DatanodeInfoWithStorage[127.0.0.1:34398,DS-6d1b62d8-289e-4411-bc15-cff943b290f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38237,DS-b0e60e6d-7041-4180-8398-55387c816dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:40364,DS-e2ce1b5c-9f02-42e7-b833-c59c3cfee308,DISK], DatanodeInfoWithStorage[127.0.0.1:40554,DS-59b0f84b-b99a-489d-aac5-95be55ca4db2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1413112615-172.17.0.21-1596902467523:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39397,DS-d9c4d7fe-9495-4821-a5a4-6af5aefc94f0,DISK], DatanodeInfoWithStorage[127.0.0.1:44950,DS-605f8212-2fca-4810-af46-159fbc090874,DISK], DatanodeInfoWithStorage[127.0.0.1:42074,DS-5e9bc30b-9f46-4087-aadb-0def32d47009,DISK], DatanodeInfoWithStorage[127.0.0.1:42255,DS-9d69441b-8028-4fa2-a203-8edfe2d88074,DISK], DatanodeInfoWithStorage[127.0.0.1:34398,DS-6d1b62d8-289e-4411-bc15-cff943b290f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38237,DS-b0e60e6d-7041-4180-8398-55387c816dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:40364,DS-e2ce1b5c-9f02-42e7-b833-c59c3cfee308,DISK], DatanodeInfoWithStorage[127.0.0.1:40554,DS-59b0f84b-b99a-489d-aac5-95be55ca4db2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1659348753-172.17.0.21-1596902821986:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40680,DS-73080797-e8cf-4c37-845f-cfbfbfbe5667,DISK], DatanodeInfoWithStorage[127.0.0.1:34587,DS-14a7a835-85b8-43df-ada8-4b34353bfb7d,DISK], DatanodeInfoWithStorage[127.0.0.1:43669,DS-8aad1740-f941-4ef9-80c6-8ea54c68039c,DISK], DatanodeInfoWithStorage[127.0.0.1:35719,DS-1ea212ea-c1ac-48c0-a130-b3b5494915c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38616,DS-c56d2790-f0c7-48c9-975d-4fb62491b16b,DISK], DatanodeInfoWithStorage[127.0.0.1:36381,DS-e48477a7-fb8f-4606-be47-0547e224a28b,DISK], DatanodeInfoWithStorage[127.0.0.1:46721,DS-efcde3a4-c609-48d4-a88e-ee488897f176,DISK], DatanodeInfoWithStorage[127.0.0.1:40478,DS-0d3d5f60-87fa-4ef8-bb74-6254edb4530a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1659348753-172.17.0.21-1596902821986:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40680,DS-73080797-e8cf-4c37-845f-cfbfbfbe5667,DISK], DatanodeInfoWithStorage[127.0.0.1:34587,DS-14a7a835-85b8-43df-ada8-4b34353bfb7d,DISK], DatanodeInfoWithStorage[127.0.0.1:43669,DS-8aad1740-f941-4ef9-80c6-8ea54c68039c,DISK], DatanodeInfoWithStorage[127.0.0.1:35719,DS-1ea212ea-c1ac-48c0-a130-b3b5494915c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38616,DS-c56d2790-f0c7-48c9-975d-4fb62491b16b,DISK], DatanodeInfoWithStorage[127.0.0.1:36381,DS-e48477a7-fb8f-4606-be47-0547e224a28b,DISK], DatanodeInfoWithStorage[127.0.0.1:46721,DS-efcde3a4-c609-48d4-a88e-ee488897f176,DISK], DatanodeInfoWithStorage[127.0.0.1:40478,DS-0d3d5f60-87fa-4ef8-bb74-6254edb4530a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-237247951-172.17.0.21-1596903461379:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38487,DS-53fcd9f5-ca7c-4a7f-b4bf-8fd5b64b3c55,DISK], DatanodeInfoWithStorage[127.0.0.1:41884,DS-6a3ba3b2-9fa3-437a-99c1-5d79719a82f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35584,DS-6729efe1-f89e-4f54-9a7d-9b3a0cc2a078,DISK], DatanodeInfoWithStorage[127.0.0.1:39821,DS-a815c6bb-fca9-472d-bff9-64c9af7c4ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:36990,DS-21eda0e9-8084-4d95-ab09-7e701247b5f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41463,DS-86a58ccd-7002-405e-8682-97baf3aa71b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44276,DS-2d2b9efa-9156-40dd-9548-057cebe1b978,DISK], DatanodeInfoWithStorage[127.0.0.1:38858,DS-7f9cdd83-cfbb-4b8c-aace-5e5e1f54b1a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-237247951-172.17.0.21-1596903461379:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38487,DS-53fcd9f5-ca7c-4a7f-b4bf-8fd5b64b3c55,DISK], DatanodeInfoWithStorage[127.0.0.1:41884,DS-6a3ba3b2-9fa3-437a-99c1-5d79719a82f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35584,DS-6729efe1-f89e-4f54-9a7d-9b3a0cc2a078,DISK], DatanodeInfoWithStorage[127.0.0.1:39821,DS-a815c6bb-fca9-472d-bff9-64c9af7c4ec0,DISK], DatanodeInfoWithStorage[127.0.0.1:36990,DS-21eda0e9-8084-4d95-ab09-7e701247b5f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41463,DS-86a58ccd-7002-405e-8682-97baf3aa71b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44276,DS-2d2b9efa-9156-40dd-9548-057cebe1b978,DISK], DatanodeInfoWithStorage[127.0.0.1:38858,DS-7f9cdd83-cfbb-4b8c-aace-5e5e1f54b1a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-947113630-172.17.0.21-1596903782848:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46147,DS-636c15fb-887a-417f-808e-f409054e76ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45446,DS-1d856658-0ce4-4dff-9422-2a778eedb854,DISK], DatanodeInfoWithStorage[127.0.0.1:39019,DS-5c6f9a81-a7f0-48bb-a486-81fec55fbf04,DISK], DatanodeInfoWithStorage[127.0.0.1:43442,DS-65585839-da16-4183-89d8-3b3e4351b4d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35413,DS-a409975c-6e49-443b-b384-8fc5bdc69fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:34913,DS-d7ed3a61-a75d-47b1-895f-4542024bf845,DISK], DatanodeInfoWithStorage[127.0.0.1:44087,DS-96c8efa1-84ba-4f6c-8e24-440467d510e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36994,DS-124351e8-967f-4597-a021-099d47040aee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-947113630-172.17.0.21-1596903782848:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46147,DS-636c15fb-887a-417f-808e-f409054e76ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45446,DS-1d856658-0ce4-4dff-9422-2a778eedb854,DISK], DatanodeInfoWithStorage[127.0.0.1:39019,DS-5c6f9a81-a7f0-48bb-a486-81fec55fbf04,DISK], DatanodeInfoWithStorage[127.0.0.1:43442,DS-65585839-da16-4183-89d8-3b3e4351b4d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35413,DS-a409975c-6e49-443b-b384-8fc5bdc69fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:34913,DS-d7ed3a61-a75d-47b1-895f-4542024bf845,DISK], DatanodeInfoWithStorage[127.0.0.1:44087,DS-96c8efa1-84ba-4f6c-8e24-440467d510e2,DISK], DatanodeInfoWithStorage[127.0.0.1:36994,DS-124351e8-967f-4597-a021-099d47040aee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-481074370-172.17.0.21-1596904369481:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43939,DS-8ff2887d-b724-4271-a814-c0f71340ee45,DISK], DatanodeInfoWithStorage[127.0.0.1:43683,DS-2ebd8d1f-5629-42b0-8bee-9b8150951220,DISK], DatanodeInfoWithStorage[127.0.0.1:38311,DS-08d1aef1-f541-42be-932c-207dd16a6aec,DISK], DatanodeInfoWithStorage[127.0.0.1:33001,DS-f802eeeb-a270-4cf5-9ff7-7e6577545d43,DISK], DatanodeInfoWithStorage[127.0.0.1:45839,DS-0f8052dc-fe64-445a-8aa5-5d54dc44aa82,DISK], DatanodeInfoWithStorage[127.0.0.1:39889,DS-84b9b9f6-9913-4ca0-a22f-c915fb3ac6df,DISK], DatanodeInfoWithStorage[127.0.0.1:35826,DS-269d6252-94c7-4cdc-adad-df1eb0dd97c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42682,DS-df6ac351-c38f-4519-b796-a9c5d7baf514,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-481074370-172.17.0.21-1596904369481:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43939,DS-8ff2887d-b724-4271-a814-c0f71340ee45,DISK], DatanodeInfoWithStorage[127.0.0.1:43683,DS-2ebd8d1f-5629-42b0-8bee-9b8150951220,DISK], DatanodeInfoWithStorage[127.0.0.1:38311,DS-08d1aef1-f541-42be-932c-207dd16a6aec,DISK], DatanodeInfoWithStorage[127.0.0.1:33001,DS-f802eeeb-a270-4cf5-9ff7-7e6577545d43,DISK], DatanodeInfoWithStorage[127.0.0.1:45839,DS-0f8052dc-fe64-445a-8aa5-5d54dc44aa82,DISK], DatanodeInfoWithStorage[127.0.0.1:39889,DS-84b9b9f6-9913-4ca0-a22f-c915fb3ac6df,DISK], DatanodeInfoWithStorage[127.0.0.1:35826,DS-269d6252-94c7-4cdc-adad-df1eb0dd97c2,DISK], DatanodeInfoWithStorage[127.0.0.1:42682,DS-df6ac351-c38f-4519-b796-a9c5d7baf514,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-457632305-172.17.0.21-1596904596204:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32788,DS-1097140d-5630-489f-accc-5fff3745a38b,DISK], DatanodeInfoWithStorage[127.0.0.1:46339,DS-1edd45fb-231c-4118-85b7-15f6366e50d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36956,DS-74c85a92-1907-4673-917b-5105869d5a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:43122,DS-fbff41a4-351b-4747-9c39-835f4ffc6497,DISK], DatanodeInfoWithStorage[127.0.0.1:39862,DS-6d5a31e4-3333-4f49-bb3d-acd493eb1bff,DISK], DatanodeInfoWithStorage[127.0.0.1:35611,DS-c2206dd6-61c6-4727-ac22-a3868680c7d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44004,DS-1f7d17d3-009d-49c5-adfb-9c927a46c296,DISK], DatanodeInfoWithStorage[127.0.0.1:45050,DS-82abf8c4-0123-48a9-8cfe-7fee53d08f2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-457632305-172.17.0.21-1596904596204:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32788,DS-1097140d-5630-489f-accc-5fff3745a38b,DISK], DatanodeInfoWithStorage[127.0.0.1:46339,DS-1edd45fb-231c-4118-85b7-15f6366e50d8,DISK], DatanodeInfoWithStorage[127.0.0.1:36956,DS-74c85a92-1907-4673-917b-5105869d5a5c,DISK], DatanodeInfoWithStorage[127.0.0.1:43122,DS-fbff41a4-351b-4747-9c39-835f4ffc6497,DISK], DatanodeInfoWithStorage[127.0.0.1:39862,DS-6d5a31e4-3333-4f49-bb3d-acd493eb1bff,DISK], DatanodeInfoWithStorage[127.0.0.1:35611,DS-c2206dd6-61c6-4727-ac22-a3868680c7d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44004,DS-1f7d17d3-009d-49c5-adfb-9c927a46c296,DISK], DatanodeInfoWithStorage[127.0.0.1:45050,DS-82abf8c4-0123-48a9-8cfe-7fee53d08f2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1089176120-172.17.0.21-1596905639868:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45569,DS-15cee384-c85e-4250-83ab-395300342867,DISK], DatanodeInfoWithStorage[127.0.0.1:44398,DS-940a0ec9-08e1-44ff-af50-b5186398c1ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45056,DS-ca035e3e-574f-4497-9908-a8ea39a1b399,DISK], DatanodeInfoWithStorage[127.0.0.1:35276,DS-e2bbacb7-3e50-4c86-9e0a-331dc0a05061,DISK], DatanodeInfoWithStorage[127.0.0.1:46168,DS-07f1e420-fe8d-4ab4-ba3d-cee60fcbc793,DISK], DatanodeInfoWithStorage[127.0.0.1:38309,DS-56410ca0-ade6-4c99-89c2-2bcdac3ed676,DISK], DatanodeInfoWithStorage[127.0.0.1:33301,DS-37beeaa8-1f16-452e-b7ac-6d385182b391,DISK], DatanodeInfoWithStorage[127.0.0.1:34672,DS-eb1e2575-3d47-4d47-afd3-a82fb89338d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1089176120-172.17.0.21-1596905639868:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45569,DS-15cee384-c85e-4250-83ab-395300342867,DISK], DatanodeInfoWithStorage[127.0.0.1:44398,DS-940a0ec9-08e1-44ff-af50-b5186398c1ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45056,DS-ca035e3e-574f-4497-9908-a8ea39a1b399,DISK], DatanodeInfoWithStorage[127.0.0.1:35276,DS-e2bbacb7-3e50-4c86-9e0a-331dc0a05061,DISK], DatanodeInfoWithStorage[127.0.0.1:46168,DS-07f1e420-fe8d-4ab4-ba3d-cee60fcbc793,DISK], DatanodeInfoWithStorage[127.0.0.1:38309,DS-56410ca0-ade6-4c99-89c2-2bcdac3ed676,DISK], DatanodeInfoWithStorage[127.0.0.1:33301,DS-37beeaa8-1f16-452e-b7ac-6d385182b391,DISK], DatanodeInfoWithStorage[127.0.0.1:34672,DS-eb1e2575-3d47-4d47-afd3-a82fb89338d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5395
