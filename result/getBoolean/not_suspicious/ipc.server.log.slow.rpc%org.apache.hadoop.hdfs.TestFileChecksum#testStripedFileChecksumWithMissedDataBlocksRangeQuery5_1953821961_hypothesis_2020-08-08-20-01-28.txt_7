reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-979036922-172.17.0.5-1596917151028:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40749,DS-4b782893-6f8e-42e6-8c29-cf17cdc3f61a,DISK], DatanodeInfoWithStorage[127.0.0.1:45129,DS-43e18d55-1170-49c8-9f00-479940e2b313,DISK], DatanodeInfoWithStorage[127.0.0.1:32995,DS-2e1111da-04af-4819-bb5d-09e5acf0e86c,DISK], DatanodeInfoWithStorage[127.0.0.1:33674,DS-608724b0-30b2-497d-955e-3efd2e21f865,DISK], DatanodeInfoWithStorage[127.0.0.1:34530,DS-e4c529cb-7bdb-48ee-8d92-7e67627aa880,DISK], DatanodeInfoWithStorage[127.0.0.1:38257,DS-d385ad27-e138-4e21-abd2-956f69aeab79,DISK], DatanodeInfoWithStorage[127.0.0.1:42119,DS-b9b3464a-5c8b-4dba-a877-7f2f9c175390,DISK], DatanodeInfoWithStorage[127.0.0.1:45452,DS-3514a0e2-0028-4c3a-8a58-7232d399652e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-979036922-172.17.0.5-1596917151028:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40749,DS-4b782893-6f8e-42e6-8c29-cf17cdc3f61a,DISK], DatanodeInfoWithStorage[127.0.0.1:45129,DS-43e18d55-1170-49c8-9f00-479940e2b313,DISK], DatanodeInfoWithStorage[127.0.0.1:32995,DS-2e1111da-04af-4819-bb5d-09e5acf0e86c,DISK], DatanodeInfoWithStorage[127.0.0.1:33674,DS-608724b0-30b2-497d-955e-3efd2e21f865,DISK], DatanodeInfoWithStorage[127.0.0.1:34530,DS-e4c529cb-7bdb-48ee-8d92-7e67627aa880,DISK], DatanodeInfoWithStorage[127.0.0.1:38257,DS-d385ad27-e138-4e21-abd2-956f69aeab79,DISK], DatanodeInfoWithStorage[127.0.0.1:42119,DS-b9b3464a-5c8b-4dba-a877-7f2f9c175390,DISK], DatanodeInfoWithStorage[127.0.0.1:45452,DS-3514a0e2-0028-4c3a-8a58-7232d399652e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-798278823-172.17.0.5-1596917414757:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43428,DS-dcfcabad-dd13-4b4e-8bd9-8b11cad349c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45137,DS-729cd217-89b6-4eb7-a5f8-29639f5366d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39092,DS-020fb71b-8195-4a62-9600-e48d8db59b57,DISK], DatanodeInfoWithStorage[127.0.0.1:43245,DS-ee9c1c0c-97dc-4495-a6c5-37912d864f17,DISK], DatanodeInfoWithStorage[127.0.0.1:43702,DS-3255476e-8a25-4f9e-be43-6ffa1724b7e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39853,DS-7ca851e3-4f9b-4c06-880a-6622b3e78ece,DISK], DatanodeInfoWithStorage[127.0.0.1:35369,DS-25b75a23-ae4f-4635-83d5-2de29473d550,DISK], DatanodeInfoWithStorage[127.0.0.1:33244,DS-8e1097e2-de72-4779-9efe-3e1e93e8cb40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-798278823-172.17.0.5-1596917414757:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43428,DS-dcfcabad-dd13-4b4e-8bd9-8b11cad349c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45137,DS-729cd217-89b6-4eb7-a5f8-29639f5366d7,DISK], DatanodeInfoWithStorage[127.0.0.1:39092,DS-020fb71b-8195-4a62-9600-e48d8db59b57,DISK], DatanodeInfoWithStorage[127.0.0.1:43245,DS-ee9c1c0c-97dc-4495-a6c5-37912d864f17,DISK], DatanodeInfoWithStorage[127.0.0.1:43702,DS-3255476e-8a25-4f9e-be43-6ffa1724b7e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39853,DS-7ca851e3-4f9b-4c06-880a-6622b3e78ece,DISK], DatanodeInfoWithStorage[127.0.0.1:35369,DS-25b75a23-ae4f-4635-83d5-2de29473d550,DISK], DatanodeInfoWithStorage[127.0.0.1:33244,DS-8e1097e2-de72-4779-9efe-3e1e93e8cb40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-21836735-172.17.0.5-1596917549764:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32919,DS-117d59b5-78f8-45da-9ebf-c67ed0c2897a,DISK], DatanodeInfoWithStorage[127.0.0.1:44714,DS-1c87dfda-b2b5-4ed3-bea9-90e4522d3e98,DISK], DatanodeInfoWithStorage[127.0.0.1:36202,DS-20d300df-28e0-4c66-9c3a-1ba14b887771,DISK], DatanodeInfoWithStorage[127.0.0.1:39826,DS-17c34a47-00cf-4f82-bc79-7d8b615e5a06,DISK], DatanodeInfoWithStorage[127.0.0.1:33420,DS-383ccd51-a34e-4ed4-84a0-5527f08846ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44432,DS-b2fe0e33-078e-472c-858f-5e49c1445d19,DISK], DatanodeInfoWithStorage[127.0.0.1:40515,DS-c7348718-81e4-429e-aec4-8f10a35bc47e,DISK], DatanodeInfoWithStorage[127.0.0.1:35557,DS-cddf4754-0d35-4354-8c42-4f8ff2b9d8d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-21836735-172.17.0.5-1596917549764:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32919,DS-117d59b5-78f8-45da-9ebf-c67ed0c2897a,DISK], DatanodeInfoWithStorage[127.0.0.1:44714,DS-1c87dfda-b2b5-4ed3-bea9-90e4522d3e98,DISK], DatanodeInfoWithStorage[127.0.0.1:36202,DS-20d300df-28e0-4c66-9c3a-1ba14b887771,DISK], DatanodeInfoWithStorage[127.0.0.1:39826,DS-17c34a47-00cf-4f82-bc79-7d8b615e5a06,DISK], DatanodeInfoWithStorage[127.0.0.1:33420,DS-383ccd51-a34e-4ed4-84a0-5527f08846ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44432,DS-b2fe0e33-078e-472c-858f-5e49c1445d19,DISK], DatanodeInfoWithStorage[127.0.0.1:40515,DS-c7348718-81e4-429e-aec4-8f10a35bc47e,DISK], DatanodeInfoWithStorage[127.0.0.1:35557,DS-cddf4754-0d35-4354-8c42-4f8ff2b9d8d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-855009586-172.17.0.5-1596917646381:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34982,DS-89a2f817-2d64-435a-970b-315d92e9cbae,DISK], DatanodeInfoWithStorage[127.0.0.1:37746,DS-b9864c17-b6cd-4bb1-b972-1c6851b6cb78,DISK], DatanodeInfoWithStorage[127.0.0.1:38230,DS-856b2d19-4964-46d9-aee4-0c5c87a7f124,DISK], DatanodeInfoWithStorage[127.0.0.1:32790,DS-16fabc62-c1af-4f82-aeef-88376257a7c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45421,DS-95b7fd35-aa02-444d-af65-1db2c2705fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:42373,DS-9a4e70d2-ab10-43bb-9965-787abad5d8b0,DISK], DatanodeInfoWithStorage[127.0.0.1:34576,DS-15afb346-1b24-467c-94ea-2963862772b1,DISK], DatanodeInfoWithStorage[127.0.0.1:38617,DS-5d26ce66-5eb0-4767-a01f-ea817c85afc3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-855009586-172.17.0.5-1596917646381:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34982,DS-89a2f817-2d64-435a-970b-315d92e9cbae,DISK], DatanodeInfoWithStorage[127.0.0.1:37746,DS-b9864c17-b6cd-4bb1-b972-1c6851b6cb78,DISK], DatanodeInfoWithStorage[127.0.0.1:38230,DS-856b2d19-4964-46d9-aee4-0c5c87a7f124,DISK], DatanodeInfoWithStorage[127.0.0.1:32790,DS-16fabc62-c1af-4f82-aeef-88376257a7c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45421,DS-95b7fd35-aa02-444d-af65-1db2c2705fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:42373,DS-9a4e70d2-ab10-43bb-9965-787abad5d8b0,DISK], DatanodeInfoWithStorage[127.0.0.1:34576,DS-15afb346-1b24-467c-94ea-2963862772b1,DISK], DatanodeInfoWithStorage[127.0.0.1:38617,DS-5d26ce66-5eb0-4767-a01f-ea817c85afc3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-811624219-172.17.0.5-1596918116952:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43786,DS-03c0c4fe-f49e-4fbd-9f77-97a5edf7dbbd,DISK], DatanodeInfoWithStorage[127.0.0.1:38142,DS-66ee25fe-1660-4c31-bcde-4f5a8b1cefa9,DISK], DatanodeInfoWithStorage[127.0.0.1:37026,DS-1bf756f8-4933-4812-8f17-61044ed34201,DISK], DatanodeInfoWithStorage[127.0.0.1:42018,DS-518f3eb2-31a1-4f33-9c7d-12b2b906566b,DISK], DatanodeInfoWithStorage[127.0.0.1:35491,DS-67c2853d-0dce-4d46-94de-d592861ab8ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42418,DS-e542df06-cb24-42bf-ab3e-26fafd99434d,DISK], DatanodeInfoWithStorage[127.0.0.1:40935,DS-3c53124b-8232-46c8-b62d-2177c26c4807,DISK], DatanodeInfoWithStorage[127.0.0.1:35784,DS-76845a87-363b-4ffd-9d6c-419d32266db9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-811624219-172.17.0.5-1596918116952:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43786,DS-03c0c4fe-f49e-4fbd-9f77-97a5edf7dbbd,DISK], DatanodeInfoWithStorage[127.0.0.1:38142,DS-66ee25fe-1660-4c31-bcde-4f5a8b1cefa9,DISK], DatanodeInfoWithStorage[127.0.0.1:37026,DS-1bf756f8-4933-4812-8f17-61044ed34201,DISK], DatanodeInfoWithStorage[127.0.0.1:42018,DS-518f3eb2-31a1-4f33-9c7d-12b2b906566b,DISK], DatanodeInfoWithStorage[127.0.0.1:35491,DS-67c2853d-0dce-4d46-94de-d592861ab8ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42418,DS-e542df06-cb24-42bf-ab3e-26fafd99434d,DISK], DatanodeInfoWithStorage[127.0.0.1:40935,DS-3c53124b-8232-46c8-b62d-2177c26c4807,DISK], DatanodeInfoWithStorage[127.0.0.1:35784,DS-76845a87-363b-4ffd-9d6c-419d32266db9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-244627304-172.17.0.5-1596918151023:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35265,DS-97c58c0f-0446-47de-a466-c0c32f0c490b,DISK], DatanodeInfoWithStorage[127.0.0.1:44877,DS-48f15841-3cda-488d-857b-0d8d97548936,DISK], DatanodeInfoWithStorage[127.0.0.1:43716,DS-35dd9e6a-94d2-4934-8c29-7aa8daa2568d,DISK], DatanodeInfoWithStorage[127.0.0.1:36899,DS-7a2a352c-9493-4d1b-a0de-78d20be6aff0,DISK], DatanodeInfoWithStorage[127.0.0.1:44512,DS-e12b93fc-4dad-4303-81d0-1b9717581513,DISK], DatanodeInfoWithStorage[127.0.0.1:34040,DS-53d6b957-3890-40b2-9c08-a91b05229829,DISK], DatanodeInfoWithStorage[127.0.0.1:39996,DS-7635a56a-8613-488a-9917-b054739ba6e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45090,DS-299d8533-5e47-453c-85c5-c3d562d09e95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-244627304-172.17.0.5-1596918151023:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35265,DS-97c58c0f-0446-47de-a466-c0c32f0c490b,DISK], DatanodeInfoWithStorage[127.0.0.1:44877,DS-48f15841-3cda-488d-857b-0d8d97548936,DISK], DatanodeInfoWithStorage[127.0.0.1:43716,DS-35dd9e6a-94d2-4934-8c29-7aa8daa2568d,DISK], DatanodeInfoWithStorage[127.0.0.1:36899,DS-7a2a352c-9493-4d1b-a0de-78d20be6aff0,DISK], DatanodeInfoWithStorage[127.0.0.1:44512,DS-e12b93fc-4dad-4303-81d0-1b9717581513,DISK], DatanodeInfoWithStorage[127.0.0.1:34040,DS-53d6b957-3890-40b2-9c08-a91b05229829,DISK], DatanodeInfoWithStorage[127.0.0.1:39996,DS-7635a56a-8613-488a-9917-b054739ba6e5,DISK], DatanodeInfoWithStorage[127.0.0.1:45090,DS-299d8533-5e47-453c-85c5-c3d562d09e95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-644436798-172.17.0.5-1596918275024:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36443,DS-19a1b693-3c76-47bf-be9c-1c5429bed13a,DISK], DatanodeInfoWithStorage[127.0.0.1:39592,DS-4c6da47a-cd38-44e2-8ca6-80d40823843e,DISK], DatanodeInfoWithStorage[127.0.0.1:38436,DS-a1b63ac1-c62d-475b-8eae-a663ec5a75cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37188,DS-9af8e902-dce4-47b6-924e-845ae31a64b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33120,DS-3d5fb973-b708-4819-b0f9-c9b10eb2cdfc,DISK], DatanodeInfoWithStorage[127.0.0.1:42292,DS-4b648b6b-8e87-4830-84fd-b22fef710048,DISK], DatanodeInfoWithStorage[127.0.0.1:32870,DS-92c678b3-6e10-4c83-9c3b-374a7a07f1f0,DISK], DatanodeInfoWithStorage[127.0.0.1:34210,DS-d53b0540-2616-4fcb-8cca-1fb46253669e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-644436798-172.17.0.5-1596918275024:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36443,DS-19a1b693-3c76-47bf-be9c-1c5429bed13a,DISK], DatanodeInfoWithStorage[127.0.0.1:39592,DS-4c6da47a-cd38-44e2-8ca6-80d40823843e,DISK], DatanodeInfoWithStorage[127.0.0.1:38436,DS-a1b63ac1-c62d-475b-8eae-a663ec5a75cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37188,DS-9af8e902-dce4-47b6-924e-845ae31a64b5,DISK], DatanodeInfoWithStorage[127.0.0.1:33120,DS-3d5fb973-b708-4819-b0f9-c9b10eb2cdfc,DISK], DatanodeInfoWithStorage[127.0.0.1:42292,DS-4b648b6b-8e87-4830-84fd-b22fef710048,DISK], DatanodeInfoWithStorage[127.0.0.1:32870,DS-92c678b3-6e10-4c83-9c3b-374a7a07f1f0,DISK], DatanodeInfoWithStorage[127.0.0.1:34210,DS-d53b0540-2616-4fcb-8cca-1fb46253669e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1273300123-172.17.0.5-1596918379405:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35174,DS-deccd639-3fe1-4e7c-9d22-304ccd092962,DISK], DatanodeInfoWithStorage[127.0.0.1:42459,DS-bd316430-936a-409f-9ef6-206854bc3fd4,DISK], DatanodeInfoWithStorage[127.0.0.1:40755,DS-f375a637-3c19-48bd-972f-f189e9a0a3c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38611,DS-ec26b8ff-8e11-4974-a1e1-8f32145b6b8a,DISK], DatanodeInfoWithStorage[127.0.0.1:42235,DS-87abc93c-f6a4-4798-a45c-c014d21a16ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43201,DS-49023b7e-2841-4dd2-b432-c0d6f39f48c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33740,DS-0246da6f-6beb-40f5-bb8b-a31d39054476,DISK], DatanodeInfoWithStorage[127.0.0.1:44382,DS-c267593e-ef3f-40af-bbae-922813ec87d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1273300123-172.17.0.5-1596918379405:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35174,DS-deccd639-3fe1-4e7c-9d22-304ccd092962,DISK], DatanodeInfoWithStorage[127.0.0.1:42459,DS-bd316430-936a-409f-9ef6-206854bc3fd4,DISK], DatanodeInfoWithStorage[127.0.0.1:40755,DS-f375a637-3c19-48bd-972f-f189e9a0a3c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38611,DS-ec26b8ff-8e11-4974-a1e1-8f32145b6b8a,DISK], DatanodeInfoWithStorage[127.0.0.1:42235,DS-87abc93c-f6a4-4798-a45c-c014d21a16ba,DISK], DatanodeInfoWithStorage[127.0.0.1:43201,DS-49023b7e-2841-4dd2-b432-c0d6f39f48c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33740,DS-0246da6f-6beb-40f5-bb8b-a31d39054476,DISK], DatanodeInfoWithStorage[127.0.0.1:44382,DS-c267593e-ef3f-40af-bbae-922813ec87d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-294188071-172.17.0.5-1596918704112:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43162,DS-830e2d2b-13eb-4498-9962-25df8754d047,DISK], DatanodeInfoWithStorage[127.0.0.1:43078,DS-c6eea90e-2c9f-44a9-ae68-4721cb2310d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35982,DS-b1022fb6-31d9-4ffe-ad3d-480ee2219ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:40112,DS-9f77b3de-1df3-44a0-99f8-ad76519f8ce5,DISK], DatanodeInfoWithStorage[127.0.0.1:36071,DS-6661eec2-adef-4ddd-81b8-ca7a2e20ff33,DISK], DatanodeInfoWithStorage[127.0.0.1:33576,DS-7dd31906-cc3d-4c65-a7b4-9143981f268f,DISK], DatanodeInfoWithStorage[127.0.0.1:38950,DS-7834bc55-e209-473c-a8f0-a407475bb6ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33299,DS-4dad65a3-ab9e-4ce4-ad90-02a530ec3e0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-294188071-172.17.0.5-1596918704112:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43162,DS-830e2d2b-13eb-4498-9962-25df8754d047,DISK], DatanodeInfoWithStorage[127.0.0.1:43078,DS-c6eea90e-2c9f-44a9-ae68-4721cb2310d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35982,DS-b1022fb6-31d9-4ffe-ad3d-480ee2219ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:40112,DS-9f77b3de-1df3-44a0-99f8-ad76519f8ce5,DISK], DatanodeInfoWithStorage[127.0.0.1:36071,DS-6661eec2-adef-4ddd-81b8-ca7a2e20ff33,DISK], DatanodeInfoWithStorage[127.0.0.1:33576,DS-7dd31906-cc3d-4c65-a7b4-9143981f268f,DISK], DatanodeInfoWithStorage[127.0.0.1:38950,DS-7834bc55-e209-473c-a8f0-a407475bb6ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33299,DS-4dad65a3-ab9e-4ce4-ad90-02a530ec3e0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1638395607-172.17.0.5-1596918812420:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45001,DS-5c22355c-50b8-4194-b653-8c40ffe7876d,DISK], DatanodeInfoWithStorage[127.0.0.1:44123,DS-cb557026-acfe-483b-adb4-8d803225a8b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39414,DS-4e255366-2e98-4917-b30a-43372ce86b85,DISK], DatanodeInfoWithStorage[127.0.0.1:44822,DS-296dcb74-62d5-487e-b6d4-997b849373f9,DISK], DatanodeInfoWithStorage[127.0.0.1:46144,DS-38e685d3-428a-4e99-8407-9c6c88eb1c63,DISK], DatanodeInfoWithStorage[127.0.0.1:43568,DS-57975c85-aa75-482a-a2c2-ebc6fd50c2f8,DISK], DatanodeInfoWithStorage[127.0.0.1:39576,DS-4809cbaa-b01c-4dfb-9922-c153b2191d91,DISK], DatanodeInfoWithStorage[127.0.0.1:41753,DS-01b370b5-efa7-49ed-bc54-f71d7847dc26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1638395607-172.17.0.5-1596918812420:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45001,DS-5c22355c-50b8-4194-b653-8c40ffe7876d,DISK], DatanodeInfoWithStorage[127.0.0.1:44123,DS-cb557026-acfe-483b-adb4-8d803225a8b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39414,DS-4e255366-2e98-4917-b30a-43372ce86b85,DISK], DatanodeInfoWithStorage[127.0.0.1:44822,DS-296dcb74-62d5-487e-b6d4-997b849373f9,DISK], DatanodeInfoWithStorage[127.0.0.1:46144,DS-38e685d3-428a-4e99-8407-9c6c88eb1c63,DISK], DatanodeInfoWithStorage[127.0.0.1:43568,DS-57975c85-aa75-482a-a2c2-ebc6fd50c2f8,DISK], DatanodeInfoWithStorage[127.0.0.1:39576,DS-4809cbaa-b01c-4dfb-9922-c153b2191d91,DISK], DatanodeInfoWithStorage[127.0.0.1:41753,DS-01b370b5-efa7-49ed-bc54-f71d7847dc26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-549375947-172.17.0.5-1596919129125:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41722,DS-6fc0877c-370b-467e-87b0-35748a195dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:38874,DS-f030ff03-fa56-4b70-a204-4ccca8f41771,DISK], DatanodeInfoWithStorage[127.0.0.1:34519,DS-0b48ea9a-d7d5-4db1-bd02-d2a357f9cc96,DISK], DatanodeInfoWithStorage[127.0.0.1:37073,DS-a8039ecb-78db-4bf9-856e-646f1073674d,DISK], DatanodeInfoWithStorage[127.0.0.1:38150,DS-dcf33ee4-b0fd-4699-baac-18f965ee0080,DISK], DatanodeInfoWithStorage[127.0.0.1:33349,DS-7989c2eb-dd66-4dc6-86af-376416b835f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37640,DS-dead29f4-fbc7-41b1-a224-55db07564825,DISK], DatanodeInfoWithStorage[127.0.0.1:39881,DS-45604055-f423-4f24-9c9f-66f78a64b022,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-549375947-172.17.0.5-1596919129125:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41722,DS-6fc0877c-370b-467e-87b0-35748a195dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:38874,DS-f030ff03-fa56-4b70-a204-4ccca8f41771,DISK], DatanodeInfoWithStorage[127.0.0.1:34519,DS-0b48ea9a-d7d5-4db1-bd02-d2a357f9cc96,DISK], DatanodeInfoWithStorage[127.0.0.1:37073,DS-a8039ecb-78db-4bf9-856e-646f1073674d,DISK], DatanodeInfoWithStorage[127.0.0.1:38150,DS-dcf33ee4-b0fd-4699-baac-18f965ee0080,DISK], DatanodeInfoWithStorage[127.0.0.1:33349,DS-7989c2eb-dd66-4dc6-86af-376416b835f4,DISK], DatanodeInfoWithStorage[127.0.0.1:37640,DS-dead29f4-fbc7-41b1-a224-55db07564825,DISK], DatanodeInfoWithStorage[127.0.0.1:39881,DS-45604055-f423-4f24-9c9f-66f78a64b022,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1121722207-172.17.0.5-1596919188094:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42294,DS-8727eb95-33e6-411b-9e08-d34b46f3a83d,DISK], DatanodeInfoWithStorage[127.0.0.1:43358,DS-d09e6167-aaed-41f7-99e2-8a0e1e5fb342,DISK], DatanodeInfoWithStorage[127.0.0.1:40827,DS-b1384199-600e-4b12-9749-25524afa8740,DISK], DatanodeInfoWithStorage[127.0.0.1:44134,DS-2bfe4020-2631-42b4-af83-8994ae471b35,DISK], DatanodeInfoWithStorage[127.0.0.1:45455,DS-0451326d-dff3-4804-a8f4-0b80c5a1c476,DISK], DatanodeInfoWithStorage[127.0.0.1:39653,DS-ef95d27e-a80a-4c5b-932a-a1eb8880ed03,DISK], DatanodeInfoWithStorage[127.0.0.1:45063,DS-1cc1147f-e0d4-4e68-b152-692b0000caa9,DISK], DatanodeInfoWithStorage[127.0.0.1:45366,DS-492ac7b5-6ffc-4ef5-871b-46597bfbdd5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1121722207-172.17.0.5-1596919188094:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42294,DS-8727eb95-33e6-411b-9e08-d34b46f3a83d,DISK], DatanodeInfoWithStorage[127.0.0.1:43358,DS-d09e6167-aaed-41f7-99e2-8a0e1e5fb342,DISK], DatanodeInfoWithStorage[127.0.0.1:40827,DS-b1384199-600e-4b12-9749-25524afa8740,DISK], DatanodeInfoWithStorage[127.0.0.1:44134,DS-2bfe4020-2631-42b4-af83-8994ae471b35,DISK], DatanodeInfoWithStorage[127.0.0.1:45455,DS-0451326d-dff3-4804-a8f4-0b80c5a1c476,DISK], DatanodeInfoWithStorage[127.0.0.1:39653,DS-ef95d27e-a80a-4c5b-932a-a1eb8880ed03,DISK], DatanodeInfoWithStorage[127.0.0.1:45063,DS-1cc1147f-e0d4-4e68-b152-692b0000caa9,DISK], DatanodeInfoWithStorage[127.0.0.1:45366,DS-492ac7b5-6ffc-4ef5-871b-46597bfbdd5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-771284199-172.17.0.5-1596919506182:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38890,DS-05eab27d-86c2-45bf-a5c0-5b4ed385b900,DISK], DatanodeInfoWithStorage[127.0.0.1:40416,DS-a3ef07a2-6dff-45fc-a29b-89891f16690c,DISK], DatanodeInfoWithStorage[127.0.0.1:37703,DS-df44100a-5902-409f-9f03-3fbcdb13021c,DISK], DatanodeInfoWithStorage[127.0.0.1:33177,DS-7421714e-1e58-4253-a699-3bc69740daf4,DISK], DatanodeInfoWithStorage[127.0.0.1:34514,DS-b3143767-bc01-40d6-91cb-672ebb6cd2bd,DISK], DatanodeInfoWithStorage[127.0.0.1:46353,DS-a454947b-ac92-4de4-99f9-52515d1351b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40227,DS-a0d202fb-ce74-4b09-a438-5abfe116988f,DISK], DatanodeInfoWithStorage[127.0.0.1:46362,DS-d9753d83-854a-4929-9d1d-3311c31c5470,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-771284199-172.17.0.5-1596919506182:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38890,DS-05eab27d-86c2-45bf-a5c0-5b4ed385b900,DISK], DatanodeInfoWithStorage[127.0.0.1:40416,DS-a3ef07a2-6dff-45fc-a29b-89891f16690c,DISK], DatanodeInfoWithStorage[127.0.0.1:37703,DS-df44100a-5902-409f-9f03-3fbcdb13021c,DISK], DatanodeInfoWithStorage[127.0.0.1:33177,DS-7421714e-1e58-4253-a699-3bc69740daf4,DISK], DatanodeInfoWithStorage[127.0.0.1:34514,DS-b3143767-bc01-40d6-91cb-672ebb6cd2bd,DISK], DatanodeInfoWithStorage[127.0.0.1:46353,DS-a454947b-ac92-4de4-99f9-52515d1351b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40227,DS-a0d202fb-ce74-4b09-a438-5abfe116988f,DISK], DatanodeInfoWithStorage[127.0.0.1:46362,DS-d9753d83-854a-4929-9d1d-3311c31c5470,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1432773728-172.17.0.5-1596919744648:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45274,DS-210380d0-4366-42cc-98be-4341f8c7418b,DISK], DatanodeInfoWithStorage[127.0.0.1:46675,DS-b65e842b-fc8b-4036-be25-fffada06c7a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41432,DS-69184e15-a3fd-48de-a308-380549aa1ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:35206,DS-49bb308f-604d-4e28-8ded-8548c9cf2773,DISK], DatanodeInfoWithStorage[127.0.0.1:40137,DS-83035ff8-2ac6-45db-b3b9-9d4f01b5ca2b,DISK], DatanodeInfoWithStorage[127.0.0.1:39203,DS-3f20f48c-7130-4664-8e01-10fedec6df65,DISK], DatanodeInfoWithStorage[127.0.0.1:33955,DS-ed99d11c-0aa7-484a-9cb9-933631b946bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33574,DS-1ebdfc4f-289d-4859-98be-cd401ec5a852,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1432773728-172.17.0.5-1596919744648:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45274,DS-210380d0-4366-42cc-98be-4341f8c7418b,DISK], DatanodeInfoWithStorage[127.0.0.1:46675,DS-b65e842b-fc8b-4036-be25-fffada06c7a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41432,DS-69184e15-a3fd-48de-a308-380549aa1ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:35206,DS-49bb308f-604d-4e28-8ded-8548c9cf2773,DISK], DatanodeInfoWithStorage[127.0.0.1:40137,DS-83035ff8-2ac6-45db-b3b9-9d4f01b5ca2b,DISK], DatanodeInfoWithStorage[127.0.0.1:39203,DS-3f20f48c-7130-4664-8e01-10fedec6df65,DISK], DatanodeInfoWithStorage[127.0.0.1:33955,DS-ed99d11c-0aa7-484a-9cb9-933631b946bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33574,DS-1ebdfc4f-289d-4859-98be-cd401ec5a852,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-266404408-172.17.0.5-1596919817105:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33361,DS-1f93e0dd-d480-498f-987c-4e2694c33a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:45053,DS-6c738eef-f8fb-4e6a-8bf8-5bea8983090c,DISK], DatanodeInfoWithStorage[127.0.0.1:41995,DS-8afb4d8d-1ee5-4640-90d8-bae67cc02f61,DISK], DatanodeInfoWithStorage[127.0.0.1:46446,DS-5c022de9-91d2-4937-b7e4-678636a58397,DISK], DatanodeInfoWithStorage[127.0.0.1:41027,DS-b1eb004d-1583-460a-ad49-2cf86568818b,DISK], DatanodeInfoWithStorage[127.0.0.1:36846,DS-91821ac3-3b09-4b90-9704-25a71d3d85e7,DISK], DatanodeInfoWithStorage[127.0.0.1:35408,DS-b2431f3c-7e13-4aea-8e03-e70c77882d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:46775,DS-a31ef8cb-5020-4940-b0c1-b5598b71ba7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-266404408-172.17.0.5-1596919817105:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33361,DS-1f93e0dd-d480-498f-987c-4e2694c33a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:45053,DS-6c738eef-f8fb-4e6a-8bf8-5bea8983090c,DISK], DatanodeInfoWithStorage[127.0.0.1:41995,DS-8afb4d8d-1ee5-4640-90d8-bae67cc02f61,DISK], DatanodeInfoWithStorage[127.0.0.1:46446,DS-5c022de9-91d2-4937-b7e4-678636a58397,DISK], DatanodeInfoWithStorage[127.0.0.1:41027,DS-b1eb004d-1583-460a-ad49-2cf86568818b,DISK], DatanodeInfoWithStorage[127.0.0.1:36846,DS-91821ac3-3b09-4b90-9704-25a71d3d85e7,DISK], DatanodeInfoWithStorage[127.0.0.1:35408,DS-b2431f3c-7e13-4aea-8e03-e70c77882d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:46775,DS-a31ef8cb-5020-4940-b0c1-b5598b71ba7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-470706603-172.17.0.5-1596920581464:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40103,DS-4dbd6570-a849-4e84-854e-37e5c4582bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:44396,DS-868f96b2-1495-4719-b686-97bb5611dc26,DISK], DatanodeInfoWithStorage[127.0.0.1:36291,DS-d2645772-2b34-46f6-96c4-0ef603d821bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45001,DS-e824af15-9871-45bb-8c61-7bc77e182da8,DISK], DatanodeInfoWithStorage[127.0.0.1:38005,DS-a473952a-92cf-4ee8-afe8-7d4d67aa67d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34645,DS-ed058164-dafa-4fb0-adc3-98ac4e94e3e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41277,DS-c4d2acf9-38aa-4c57-b914-a86d603c82c4,DISK], DatanodeInfoWithStorage[127.0.0.1:37615,DS-76f5cd2b-707f-4d3e-bd9b-2ddfcc336d26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-470706603-172.17.0.5-1596920581464:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40103,DS-4dbd6570-a849-4e84-854e-37e5c4582bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:44396,DS-868f96b2-1495-4719-b686-97bb5611dc26,DISK], DatanodeInfoWithStorage[127.0.0.1:36291,DS-d2645772-2b34-46f6-96c4-0ef603d821bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45001,DS-e824af15-9871-45bb-8c61-7bc77e182da8,DISK], DatanodeInfoWithStorage[127.0.0.1:38005,DS-a473952a-92cf-4ee8-afe8-7d4d67aa67d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34645,DS-ed058164-dafa-4fb0-adc3-98ac4e94e3e9,DISK], DatanodeInfoWithStorage[127.0.0.1:41277,DS-c4d2acf9-38aa-4c57-b914-a86d603c82c4,DISK], DatanodeInfoWithStorage[127.0.0.1:37615,DS-76f5cd2b-707f-4d3e-bd9b-2ddfcc336d26,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1727278246-172.17.0.5-1596920655977:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43286,DS-8cc89a38-becb-42b3-be7e-916b6902e97f,DISK], DatanodeInfoWithStorage[127.0.0.1:33108,DS-e76933c6-f536-4683-81ed-a2696348a170,DISK], DatanodeInfoWithStorage[127.0.0.1:35540,DS-0e88afc5-fa11-4dba-a8d5-bc36d17b0945,DISK], DatanodeInfoWithStorage[127.0.0.1:40777,DS-c7629f87-cd8b-4a20-bb41-d4204c859338,DISK], DatanodeInfoWithStorage[127.0.0.1:42831,DS-11dfe008-94cf-4bba-a76a-8e742962ee57,DISK], DatanodeInfoWithStorage[127.0.0.1:41029,DS-76b5755b-72ef-4b0d-839e-edc2d57c4eba,DISK], DatanodeInfoWithStorage[127.0.0.1:38861,DS-a4e7404a-863a-4992-b6ce-52e8676fd77a,DISK], DatanodeInfoWithStorage[127.0.0.1:42621,DS-bddece42-130e-4e80-9716-d46799676222,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1727278246-172.17.0.5-1596920655977:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43286,DS-8cc89a38-becb-42b3-be7e-916b6902e97f,DISK], DatanodeInfoWithStorage[127.0.0.1:33108,DS-e76933c6-f536-4683-81ed-a2696348a170,DISK], DatanodeInfoWithStorage[127.0.0.1:35540,DS-0e88afc5-fa11-4dba-a8d5-bc36d17b0945,DISK], DatanodeInfoWithStorage[127.0.0.1:40777,DS-c7629f87-cd8b-4a20-bb41-d4204c859338,DISK], DatanodeInfoWithStorage[127.0.0.1:42831,DS-11dfe008-94cf-4bba-a76a-8e742962ee57,DISK], DatanodeInfoWithStorage[127.0.0.1:41029,DS-76b5755b-72ef-4b0d-839e-edc2d57c4eba,DISK], DatanodeInfoWithStorage[127.0.0.1:38861,DS-a4e7404a-863a-4992-b6ce-52e8676fd77a,DISK], DatanodeInfoWithStorage[127.0.0.1:42621,DS-bddece42-130e-4e80-9716-d46799676222,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-214154550-172.17.0.5-1596921144497:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38577,DS-559d781c-0f2b-405f-9eae-16ee1571fda1,DISK], DatanodeInfoWithStorage[127.0.0.1:42519,DS-eee879fd-f662-4558-bb60-784ef1d87587,DISK], DatanodeInfoWithStorage[127.0.0.1:41070,DS-fb4bb343-45b4-4a1c-8265-5f7fb127ca8a,DISK], DatanodeInfoWithStorage[127.0.0.1:41585,DS-e3a89b05-9c85-408f-bb13-593f3c1ff80c,DISK], DatanodeInfoWithStorage[127.0.0.1:40054,DS-9b65b321-e4bf-42b7-94a9-4ce8f6948644,DISK], DatanodeInfoWithStorage[127.0.0.1:32813,DS-76e5e0ff-33c4-4258-a0e7-f5d3bc0413e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44202,DS-42bd1c81-279f-4bf6-896f-d3e1b02515cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40736,DS-16bfb126-6f10-4ce6-a348-e4b0437c982b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-214154550-172.17.0.5-1596921144497:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38577,DS-559d781c-0f2b-405f-9eae-16ee1571fda1,DISK], DatanodeInfoWithStorage[127.0.0.1:42519,DS-eee879fd-f662-4558-bb60-784ef1d87587,DISK], DatanodeInfoWithStorage[127.0.0.1:41070,DS-fb4bb343-45b4-4a1c-8265-5f7fb127ca8a,DISK], DatanodeInfoWithStorage[127.0.0.1:41585,DS-e3a89b05-9c85-408f-bb13-593f3c1ff80c,DISK], DatanodeInfoWithStorage[127.0.0.1:40054,DS-9b65b321-e4bf-42b7-94a9-4ce8f6948644,DISK], DatanodeInfoWithStorage[127.0.0.1:32813,DS-76e5e0ff-33c4-4258-a0e7-f5d3bc0413e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44202,DS-42bd1c81-279f-4bf6-896f-d3e1b02515cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40736,DS-16bfb126-6f10-4ce6-a348-e4b0437c982b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-49564479-172.17.0.5-1596921293896:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40481,DS-822919c1-fe8d-4d5c-8663-b4c42524fea7,DISK], DatanodeInfoWithStorage[127.0.0.1:44347,DS-b0a2a487-0b87-4ac3-81da-48e879e5c4cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36638,DS-e966daac-d376-4c7b-8305-28e5f24e0374,DISK], DatanodeInfoWithStorage[127.0.0.1:40306,DS-6dbd0cd0-e37c-4692-a4c7-82a9b0d98b9c,DISK], DatanodeInfoWithStorage[127.0.0.1:40688,DS-fcc2398c-02de-469d-af64-54504c2ce844,DISK], DatanodeInfoWithStorage[127.0.0.1:34544,DS-34067154-9a64-4896-aca0-f9f43db9ebcf,DISK], DatanodeInfoWithStorage[127.0.0.1:38760,DS-1ead068a-c310-4f31-a279-1a356183d5f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34520,DS-0674671a-abfa-4d02-bcd1-dd0d7be6b4b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-49564479-172.17.0.5-1596921293896:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40481,DS-822919c1-fe8d-4d5c-8663-b4c42524fea7,DISK], DatanodeInfoWithStorage[127.0.0.1:44347,DS-b0a2a487-0b87-4ac3-81da-48e879e5c4cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36638,DS-e966daac-d376-4c7b-8305-28e5f24e0374,DISK], DatanodeInfoWithStorage[127.0.0.1:40306,DS-6dbd0cd0-e37c-4692-a4c7-82a9b0d98b9c,DISK], DatanodeInfoWithStorage[127.0.0.1:40688,DS-fcc2398c-02de-469d-af64-54504c2ce844,DISK], DatanodeInfoWithStorage[127.0.0.1:34544,DS-34067154-9a64-4896-aca0-f9f43db9ebcf,DISK], DatanodeInfoWithStorage[127.0.0.1:38760,DS-1ead068a-c310-4f31-a279-1a356183d5f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34520,DS-0674671a-abfa-4d02-bcd1-dd0d7be6b4b4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1826049569-172.17.0.5-1596921426837:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42549,DS-c05a3e89-259b-46c9-bc7a-b6f22ae86708,DISK], DatanodeInfoWithStorage[127.0.0.1:33446,DS-e54bf2d6-9aa8-4877-94e3-396b047cc1aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44143,DS-26ac6a1e-beb5-41d3-88ed-f23af89af33c,DISK], DatanodeInfoWithStorage[127.0.0.1:33068,DS-60b183e2-d8ee-470e-9f01-5c83d2642ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:43082,DS-ab2395a5-48e8-41a5-8e4a-8720292e63de,DISK], DatanodeInfoWithStorage[127.0.0.1:42124,DS-de86e0db-66ad-4c4e-b080-72fa0be96a54,DISK], DatanodeInfoWithStorage[127.0.0.1:44438,DS-c7ec18fa-2b15-49b9-aec2-d12ce90b44c3,DISK], DatanodeInfoWithStorage[127.0.0.1:32944,DS-ec9b0b05-cfe5-4469-98be-7900744504aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1826049569-172.17.0.5-1596921426837:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42549,DS-c05a3e89-259b-46c9-bc7a-b6f22ae86708,DISK], DatanodeInfoWithStorage[127.0.0.1:33446,DS-e54bf2d6-9aa8-4877-94e3-396b047cc1aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44143,DS-26ac6a1e-beb5-41d3-88ed-f23af89af33c,DISK], DatanodeInfoWithStorage[127.0.0.1:33068,DS-60b183e2-d8ee-470e-9f01-5c83d2642ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:43082,DS-ab2395a5-48e8-41a5-8e4a-8720292e63de,DISK], DatanodeInfoWithStorage[127.0.0.1:42124,DS-de86e0db-66ad-4c4e-b080-72fa0be96a54,DISK], DatanodeInfoWithStorage[127.0.0.1:44438,DS-c7ec18fa-2b15-49b9-aec2-d12ce90b44c3,DISK], DatanodeInfoWithStorage[127.0.0.1:32944,DS-ec9b0b05-cfe5-4469-98be-7900744504aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2040573027-172.17.0.5-1596921558175:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40696,DS-b12802bc-523a-4a04-9ee5-e7fb304dcf91,DISK], DatanodeInfoWithStorage[127.0.0.1:44119,DS-8d08aaa7-5068-4422-ba6a-8f44cb0a3efe,DISK], DatanodeInfoWithStorage[127.0.0.1:46621,DS-08b98e26-33ce-4dd7-b6e2-4f412681999a,DISK], DatanodeInfoWithStorage[127.0.0.1:33252,DS-6f0c5fd7-1047-473e-9272-d7315e05876f,DISK], DatanodeInfoWithStorage[127.0.0.1:44587,DS-27f1d6c7-7883-42c4-bd71-51b8d3c52102,DISK], DatanodeInfoWithStorage[127.0.0.1:35739,DS-12bf26fb-f771-4e57-ad73-d9e78fefc4ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44208,DS-888625b0-9fc0-460e-8c36-6d9c4626b3c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44677,DS-67ea8d92-27f8-4097-be62-e1dd9245dae6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2040573027-172.17.0.5-1596921558175:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40696,DS-b12802bc-523a-4a04-9ee5-e7fb304dcf91,DISK], DatanodeInfoWithStorage[127.0.0.1:44119,DS-8d08aaa7-5068-4422-ba6a-8f44cb0a3efe,DISK], DatanodeInfoWithStorage[127.0.0.1:46621,DS-08b98e26-33ce-4dd7-b6e2-4f412681999a,DISK], DatanodeInfoWithStorage[127.0.0.1:33252,DS-6f0c5fd7-1047-473e-9272-d7315e05876f,DISK], DatanodeInfoWithStorage[127.0.0.1:44587,DS-27f1d6c7-7883-42c4-bd71-51b8d3c52102,DISK], DatanodeInfoWithStorage[127.0.0.1:35739,DS-12bf26fb-f771-4e57-ad73-d9e78fefc4ee,DISK], DatanodeInfoWithStorage[127.0.0.1:44208,DS-888625b0-9fc0-460e-8c36-6d9c4626b3c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44677,DS-67ea8d92-27f8-4097-be62-e1dd9245dae6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1835629091-172.17.0.5-1596921737401:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35168,DS-6494f232-56de-4f55-887a-01676617143e,DISK], DatanodeInfoWithStorage[127.0.0.1:38077,DS-017460dc-59f9-42ef-b3ae-eb992d348098,DISK], DatanodeInfoWithStorage[127.0.0.1:40868,DS-39c2bf4b-4697-4534-b3bc-0ccc6e53e65d,DISK], DatanodeInfoWithStorage[127.0.0.1:44241,DS-8211344c-f759-4828-99ca-d89912676ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:38063,DS-de4d1dc9-b4c2-4847-9a3c-b4a7d4e640ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35495,DS-6dfc803c-65f4-4d93-a34c-3ef05ee86075,DISK], DatanodeInfoWithStorage[127.0.0.1:41759,DS-7df5d66a-f874-464d-9466-2f771a418719,DISK], DatanodeInfoWithStorage[127.0.0.1:37384,DS-874ef370-4f87-4790-aff2-9b4fa4a25244,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1835629091-172.17.0.5-1596921737401:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35168,DS-6494f232-56de-4f55-887a-01676617143e,DISK], DatanodeInfoWithStorage[127.0.0.1:38077,DS-017460dc-59f9-42ef-b3ae-eb992d348098,DISK], DatanodeInfoWithStorage[127.0.0.1:40868,DS-39c2bf4b-4697-4534-b3bc-0ccc6e53e65d,DISK], DatanodeInfoWithStorage[127.0.0.1:44241,DS-8211344c-f759-4828-99ca-d89912676ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:38063,DS-de4d1dc9-b4c2-4847-9a3c-b4a7d4e640ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35495,DS-6dfc803c-65f4-4d93-a34c-3ef05ee86075,DISK], DatanodeInfoWithStorage[127.0.0.1:41759,DS-7df5d66a-f874-464d-9466-2f771a418719,DISK], DatanodeInfoWithStorage[127.0.0.1:37384,DS-874ef370-4f87-4790-aff2-9b4fa4a25244,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1142878385-172.17.0.5-1596921766288:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32938,DS-97640d43-a858-4902-b607-09f4b8d83c8e,DISK], DatanodeInfoWithStorage[127.0.0.1:46616,DS-8b65431f-83fa-4795-a512-0dfd9246bb21,DISK], DatanodeInfoWithStorage[127.0.0.1:38484,DS-7199801c-f1f3-42e7-b7e6-70d462520586,DISK], DatanodeInfoWithStorage[127.0.0.1:46060,DS-ded239ff-9c51-464a-85e2-fcd3d7e4d807,DISK], DatanodeInfoWithStorage[127.0.0.1:46210,DS-340ad061-fb4b-499e-b07e-e1ad5101ba09,DISK], DatanodeInfoWithStorage[127.0.0.1:35157,DS-e46cfe78-2ed0-4497-a2e7-c2a8a464a35c,DISK], DatanodeInfoWithStorage[127.0.0.1:46091,DS-9cf24f60-1f4a-44ad-b9a1-410dfae4d84b,DISK], DatanodeInfoWithStorage[127.0.0.1:42511,DS-fbb7370d-c4b2-41a1-9806-35e558122865,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1142878385-172.17.0.5-1596921766288:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32938,DS-97640d43-a858-4902-b607-09f4b8d83c8e,DISK], DatanodeInfoWithStorage[127.0.0.1:46616,DS-8b65431f-83fa-4795-a512-0dfd9246bb21,DISK], DatanodeInfoWithStorage[127.0.0.1:38484,DS-7199801c-f1f3-42e7-b7e6-70d462520586,DISK], DatanodeInfoWithStorage[127.0.0.1:46060,DS-ded239ff-9c51-464a-85e2-fcd3d7e4d807,DISK], DatanodeInfoWithStorage[127.0.0.1:46210,DS-340ad061-fb4b-499e-b07e-e1ad5101ba09,DISK], DatanodeInfoWithStorage[127.0.0.1:35157,DS-e46cfe78-2ed0-4497-a2e7-c2a8a464a35c,DISK], DatanodeInfoWithStorage[127.0.0.1:46091,DS-9cf24f60-1f4a-44ad-b9a1-410dfae4d84b,DISK], DatanodeInfoWithStorage[127.0.0.1:42511,DS-fbb7370d-c4b2-41a1-9806-35e558122865,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 18 out of 50
result: false positive !!!
Total execution time in seconds : 5154
