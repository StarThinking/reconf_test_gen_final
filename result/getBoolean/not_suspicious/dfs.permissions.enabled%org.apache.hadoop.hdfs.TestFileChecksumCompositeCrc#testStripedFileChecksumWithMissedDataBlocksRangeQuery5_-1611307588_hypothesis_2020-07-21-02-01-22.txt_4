reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-981355322-172.17.0.11-1595297104776:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42357,DS-2440881c-1e30-4d78-9f31-c85a2fb5658a,DISK], DatanodeInfoWithStorage[127.0.0.1:38576,DS-2c257a74-3c9d-45e5-a348-62bf731aa335,DISK], DatanodeInfoWithStorage[127.0.0.1:34964,DS-92607229-5445-4e93-b5ad-4964c3d4d831,DISK], DatanodeInfoWithStorage[127.0.0.1:36937,DS-5e4622f5-39e4-4e0b-af47-db63fe0a3d67,DISK], DatanodeInfoWithStorage[127.0.0.1:38224,DS-a258379e-8bf2-4efd-aea1-d60fbb2a2d73,DISK], DatanodeInfoWithStorage[127.0.0.1:37264,DS-3efd8a4c-8f6d-4f83-adf8-c3bf663a8407,DISK], DatanodeInfoWithStorage[127.0.0.1:44812,DS-d70172df-fadb-4b89-99ed-f341bb039a20,DISK], DatanodeInfoWithStorage[127.0.0.1:34097,DS-a9f34f85-9526-49e3-a303-f3e2888eff6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-981355322-172.17.0.11-1595297104776:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42357,DS-2440881c-1e30-4d78-9f31-c85a2fb5658a,DISK], DatanodeInfoWithStorage[127.0.0.1:38576,DS-2c257a74-3c9d-45e5-a348-62bf731aa335,DISK], DatanodeInfoWithStorage[127.0.0.1:34964,DS-92607229-5445-4e93-b5ad-4964c3d4d831,DISK], DatanodeInfoWithStorage[127.0.0.1:36937,DS-5e4622f5-39e4-4e0b-af47-db63fe0a3d67,DISK], DatanodeInfoWithStorage[127.0.0.1:38224,DS-a258379e-8bf2-4efd-aea1-d60fbb2a2d73,DISK], DatanodeInfoWithStorage[127.0.0.1:37264,DS-3efd8a4c-8f6d-4f83-adf8-c3bf663a8407,DISK], DatanodeInfoWithStorage[127.0.0.1:44812,DS-d70172df-fadb-4b89-99ed-f341bb039a20,DISK], DatanodeInfoWithStorage[127.0.0.1:34097,DS-a9f34f85-9526-49e3-a303-f3e2888eff6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-435537694-172.17.0.11-1595297149584:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44159,DS-fd9bc0be-e197-4789-b382-7ac46a36f0e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34321,DS-ef0b6186-0045-46e3-87f2-accb3a2f6b12,DISK], DatanodeInfoWithStorage[127.0.0.1:34265,DS-35245dc1-4b39-46ca-ba34-5aaba86871ed,DISK], DatanodeInfoWithStorage[127.0.0.1:45091,DS-2a8e5e32-1ce0-412a-8b5e-40068b1fad77,DISK], DatanodeInfoWithStorage[127.0.0.1:36318,DS-bcb76bd3-701d-46e5-a316-25635e8cde30,DISK], DatanodeInfoWithStorage[127.0.0.1:35704,DS-55741b11-24db-417a-8003-5d54d52c039f,DISK], DatanodeInfoWithStorage[127.0.0.1:40626,DS-7548a1b1-1a4a-419f-af5c-2960968f8144,DISK], DatanodeInfoWithStorage[127.0.0.1:33434,DS-07967d5d-60cf-4e9d-b502-049b9b9ca804,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-435537694-172.17.0.11-1595297149584:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44159,DS-fd9bc0be-e197-4789-b382-7ac46a36f0e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34321,DS-ef0b6186-0045-46e3-87f2-accb3a2f6b12,DISK], DatanodeInfoWithStorage[127.0.0.1:34265,DS-35245dc1-4b39-46ca-ba34-5aaba86871ed,DISK], DatanodeInfoWithStorage[127.0.0.1:45091,DS-2a8e5e32-1ce0-412a-8b5e-40068b1fad77,DISK], DatanodeInfoWithStorage[127.0.0.1:36318,DS-bcb76bd3-701d-46e5-a316-25635e8cde30,DISK], DatanodeInfoWithStorage[127.0.0.1:35704,DS-55741b11-24db-417a-8003-5d54d52c039f,DISK], DatanodeInfoWithStorage[127.0.0.1:40626,DS-7548a1b1-1a4a-419f-af5c-2960968f8144,DISK], DatanodeInfoWithStorage[127.0.0.1:33434,DS-07967d5d-60cf-4e9d-b502-049b9b9ca804,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-177337299-172.17.0.11-1595297268020:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33902,DS-24b6df99-0869-41bb-abde-4a4e42378887,DISK], DatanodeInfoWithStorage[127.0.0.1:33567,DS-45cc15ef-3b14-42fc-87f1-5365cc8cf21d,DISK], DatanodeInfoWithStorage[127.0.0.1:46862,DS-e50bb1fd-084c-48e3-9ac5-1a61073b8b6c,DISK], DatanodeInfoWithStorage[127.0.0.1:46099,DS-671fec22-e878-45be-837d-dd8316977821,DISK], DatanodeInfoWithStorage[127.0.0.1:34824,DS-0bc0ca88-fad9-491a-a559-a53c652b218d,DISK], DatanodeInfoWithStorage[127.0.0.1:35243,DS-1a13f5f1-0470-4ff0-8319-e2725ab4efda,DISK], DatanodeInfoWithStorage[127.0.0.1:42086,DS-795593ac-0dbb-4d32-8f4e-7462919c3982,DISK], DatanodeInfoWithStorage[127.0.0.1:45244,DS-649ae28c-63c9-44bd-ad0a-883771b1c70f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-177337299-172.17.0.11-1595297268020:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33902,DS-24b6df99-0869-41bb-abde-4a4e42378887,DISK], DatanodeInfoWithStorage[127.0.0.1:33567,DS-45cc15ef-3b14-42fc-87f1-5365cc8cf21d,DISK], DatanodeInfoWithStorage[127.0.0.1:46862,DS-e50bb1fd-084c-48e3-9ac5-1a61073b8b6c,DISK], DatanodeInfoWithStorage[127.0.0.1:46099,DS-671fec22-e878-45be-837d-dd8316977821,DISK], DatanodeInfoWithStorage[127.0.0.1:34824,DS-0bc0ca88-fad9-491a-a559-a53c652b218d,DISK], DatanodeInfoWithStorage[127.0.0.1:35243,DS-1a13f5f1-0470-4ff0-8319-e2725ab4efda,DISK], DatanodeInfoWithStorage[127.0.0.1:42086,DS-795593ac-0dbb-4d32-8f4e-7462919c3982,DISK], DatanodeInfoWithStorage[127.0.0.1:45244,DS-649ae28c-63c9-44bd-ad0a-883771b1c70f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2059197160-172.17.0.11-1595297342712:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41785,DS-b956b3a1-5cf2-4f6a-9c09-740538ac2e60,DISK], DatanodeInfoWithStorage[127.0.0.1:35142,DS-e5d44662-0527-4651-aef0-90caa14e5dee,DISK], DatanodeInfoWithStorage[127.0.0.1:36637,DS-b51fb59c-2432-44c2-bed2-d60f0114db93,DISK], DatanodeInfoWithStorage[127.0.0.1:36313,DS-dd03975f-8d18-40a0-8ddd-9aa83a674068,DISK], DatanodeInfoWithStorage[127.0.0.1:36869,DS-39ae50f3-b6cd-4d76-b0f2-86717d822032,DISK], DatanodeInfoWithStorage[127.0.0.1:35025,DS-d663ae53-e646-484b-b346-0ea2c744ed2c,DISK], DatanodeInfoWithStorage[127.0.0.1:44387,DS-739e7042-9d46-40be-a95e-7cd8003f204f,DISK], DatanodeInfoWithStorage[127.0.0.1:46589,DS-5ee92593-c145-48bb-bcc6-feaed2d1eeca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2059197160-172.17.0.11-1595297342712:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41785,DS-b956b3a1-5cf2-4f6a-9c09-740538ac2e60,DISK], DatanodeInfoWithStorage[127.0.0.1:35142,DS-e5d44662-0527-4651-aef0-90caa14e5dee,DISK], DatanodeInfoWithStorage[127.0.0.1:36637,DS-b51fb59c-2432-44c2-bed2-d60f0114db93,DISK], DatanodeInfoWithStorage[127.0.0.1:36313,DS-dd03975f-8d18-40a0-8ddd-9aa83a674068,DISK], DatanodeInfoWithStorage[127.0.0.1:36869,DS-39ae50f3-b6cd-4d76-b0f2-86717d822032,DISK], DatanodeInfoWithStorage[127.0.0.1:35025,DS-d663ae53-e646-484b-b346-0ea2c744ed2c,DISK], DatanodeInfoWithStorage[127.0.0.1:44387,DS-739e7042-9d46-40be-a95e-7cd8003f204f,DISK], DatanodeInfoWithStorage[127.0.0.1:46589,DS-5ee92593-c145-48bb-bcc6-feaed2d1eeca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-396846554-172.17.0.11-1595297643884:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38180,DS-5d77d6e9-7c4b-4b73-8ee2-2795590020df,DISK], DatanodeInfoWithStorage[127.0.0.1:43827,DS-6452f20c-574f-4d6b-99be-00ee834b6ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:33904,DS-a846aa42-23bc-4ded-81e4-f2f2a2f9c11d,DISK], DatanodeInfoWithStorage[127.0.0.1:46755,DS-1b09cea1-9fd8-40fe-804c-786fb3b77743,DISK], DatanodeInfoWithStorage[127.0.0.1:33178,DS-03bb0802-718b-463a-a174-ce5855ef3aff,DISK], DatanodeInfoWithStorage[127.0.0.1:36350,DS-cf08c603-e040-4dec-8b0f-ea328d3f6207,DISK], DatanodeInfoWithStorage[127.0.0.1:37724,DS-49c38853-62f7-4873-8133-fab3ce3e22a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40514,DS-92ff6b78-6672-4d6c-85d9-0f1fa3d2a16b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-396846554-172.17.0.11-1595297643884:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38180,DS-5d77d6e9-7c4b-4b73-8ee2-2795590020df,DISK], DatanodeInfoWithStorage[127.0.0.1:43827,DS-6452f20c-574f-4d6b-99be-00ee834b6ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:33904,DS-a846aa42-23bc-4ded-81e4-f2f2a2f9c11d,DISK], DatanodeInfoWithStorage[127.0.0.1:46755,DS-1b09cea1-9fd8-40fe-804c-786fb3b77743,DISK], DatanodeInfoWithStorage[127.0.0.1:33178,DS-03bb0802-718b-463a-a174-ce5855ef3aff,DISK], DatanodeInfoWithStorage[127.0.0.1:36350,DS-cf08c603-e040-4dec-8b0f-ea328d3f6207,DISK], DatanodeInfoWithStorage[127.0.0.1:37724,DS-49c38853-62f7-4873-8133-fab3ce3e22a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40514,DS-92ff6b78-6672-4d6c-85d9-0f1fa3d2a16b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2073193062-172.17.0.11-1595298362508:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38787,DS-d5363499-4cf6-48f9-8b4e-14016c9e2845,DISK], DatanodeInfoWithStorage[127.0.0.1:36854,DS-4a24bc4a-42b6-4e28-aeef-d6ae6ea6984d,DISK], DatanodeInfoWithStorage[127.0.0.1:33072,DS-dbd3fac7-2a3b-45a5-9140-cb5980459dc1,DISK], DatanodeInfoWithStorage[127.0.0.1:42306,DS-44f2a9a2-fe6c-4340-b100-ca9359e30e34,DISK], DatanodeInfoWithStorage[127.0.0.1:46781,DS-2c0752c1-aaf2-47c8-a8a9-7b2f155e30f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37456,DS-13b69297-07a0-44e9-9c8f-ac007cf4bbd9,DISK], DatanodeInfoWithStorage[127.0.0.1:41622,DS-e0e33eb6-86e7-4330-a66b-2eb77a766d09,DISK], DatanodeInfoWithStorage[127.0.0.1:43417,DS-aa7cde78-7a85-466b-b4f3-f430498c178f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2073193062-172.17.0.11-1595298362508:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38787,DS-d5363499-4cf6-48f9-8b4e-14016c9e2845,DISK], DatanodeInfoWithStorage[127.0.0.1:36854,DS-4a24bc4a-42b6-4e28-aeef-d6ae6ea6984d,DISK], DatanodeInfoWithStorage[127.0.0.1:33072,DS-dbd3fac7-2a3b-45a5-9140-cb5980459dc1,DISK], DatanodeInfoWithStorage[127.0.0.1:42306,DS-44f2a9a2-fe6c-4340-b100-ca9359e30e34,DISK], DatanodeInfoWithStorage[127.0.0.1:46781,DS-2c0752c1-aaf2-47c8-a8a9-7b2f155e30f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37456,DS-13b69297-07a0-44e9-9c8f-ac007cf4bbd9,DISK], DatanodeInfoWithStorage[127.0.0.1:41622,DS-e0e33eb6-86e7-4330-a66b-2eb77a766d09,DISK], DatanodeInfoWithStorage[127.0.0.1:43417,DS-aa7cde78-7a85-466b-b4f3-f430498c178f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1549827432-172.17.0.11-1595298660476:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40957,DS-7a18fa5d-86fb-4562-847c-422c4bc55500,DISK], DatanodeInfoWithStorage[127.0.0.1:42657,DS-0e102938-4ecc-4ff7-abd3-94b344d98353,DISK], DatanodeInfoWithStorage[127.0.0.1:40757,DS-0ffb0c9f-9d20-4a71-9dec-8f49c25865d9,DISK], DatanodeInfoWithStorage[127.0.0.1:37902,DS-36c4ccad-32f0-464a-b012-48831fccf06d,DISK], DatanodeInfoWithStorage[127.0.0.1:36492,DS-04648089-0da8-4289-9443-8bd6eb27e793,DISK], DatanodeInfoWithStorage[127.0.0.1:46175,DS-41e6be38-0f84-43d2-b5d0-8a3f4d7059eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36298,DS-1dd43e37-0c83-482b-9077-52deca755d7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36463,DS-709f8a15-cb5a-4929-ada5-97e96c17e932,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1549827432-172.17.0.11-1595298660476:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40957,DS-7a18fa5d-86fb-4562-847c-422c4bc55500,DISK], DatanodeInfoWithStorage[127.0.0.1:42657,DS-0e102938-4ecc-4ff7-abd3-94b344d98353,DISK], DatanodeInfoWithStorage[127.0.0.1:40757,DS-0ffb0c9f-9d20-4a71-9dec-8f49c25865d9,DISK], DatanodeInfoWithStorage[127.0.0.1:37902,DS-36c4ccad-32f0-464a-b012-48831fccf06d,DISK], DatanodeInfoWithStorage[127.0.0.1:36492,DS-04648089-0da8-4289-9443-8bd6eb27e793,DISK], DatanodeInfoWithStorage[127.0.0.1:46175,DS-41e6be38-0f84-43d2-b5d0-8a3f4d7059eb,DISK], DatanodeInfoWithStorage[127.0.0.1:36298,DS-1dd43e37-0c83-482b-9077-52deca755d7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36463,DS-709f8a15-cb5a-4929-ada5-97e96c17e932,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-445051362-172.17.0.11-1595299111807:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42539,DS-8407fbd5-d7a8-4cd9-899d-4f8f2e2f5b59,DISK], DatanodeInfoWithStorage[127.0.0.1:45892,DS-d15709e0-573f-4bce-a1ba-e98f71e4b336,DISK], DatanodeInfoWithStorage[127.0.0.1:35897,DS-92f234e9-5d88-49c1-81cc-aa6043d0e337,DISK], DatanodeInfoWithStorage[127.0.0.1:40417,DS-7b465a84-f73d-4cc9-8432-79a4f880a62b,DISK], DatanodeInfoWithStorage[127.0.0.1:35543,DS-09a344c2-9dd1-4b79-a5f0-45a3315d10b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37084,DS-593989cd-adef-472c-998f-81d8550d883d,DISK], DatanodeInfoWithStorage[127.0.0.1:36620,DS-4dd97978-bfb1-4f47-b48a-ade782e00591,DISK], DatanodeInfoWithStorage[127.0.0.1:39543,DS-bb36c443-d544-4a51-b83e-ba4f43147518,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-445051362-172.17.0.11-1595299111807:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42539,DS-8407fbd5-d7a8-4cd9-899d-4f8f2e2f5b59,DISK], DatanodeInfoWithStorage[127.0.0.1:45892,DS-d15709e0-573f-4bce-a1ba-e98f71e4b336,DISK], DatanodeInfoWithStorage[127.0.0.1:35897,DS-92f234e9-5d88-49c1-81cc-aa6043d0e337,DISK], DatanodeInfoWithStorage[127.0.0.1:40417,DS-7b465a84-f73d-4cc9-8432-79a4f880a62b,DISK], DatanodeInfoWithStorage[127.0.0.1:35543,DS-09a344c2-9dd1-4b79-a5f0-45a3315d10b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37084,DS-593989cd-adef-472c-998f-81d8550d883d,DISK], DatanodeInfoWithStorage[127.0.0.1:36620,DS-4dd97978-bfb1-4f47-b48a-ade782e00591,DISK], DatanodeInfoWithStorage[127.0.0.1:39543,DS-bb36c443-d544-4a51-b83e-ba4f43147518,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1828686550-172.17.0.11-1595299261200:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44032,DS-cbdc69ab-bc3e-4ec3-896f-b8bf66059f54,DISK], DatanodeInfoWithStorage[127.0.0.1:42235,DS-178281ba-1ea8-4dac-9ee8-c65000dc3e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:33935,DS-1244ab33-d160-4a8d-9455-41cb17acd60c,DISK], DatanodeInfoWithStorage[127.0.0.1:41371,DS-c00b3434-a37c-4e33-bfdf-f60c6ede93ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35156,DS-48b6c878-09fe-465c-a041-97befcde25bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33332,DS-3fe07b6e-58a2-4b0c-bbd6-168d1c306090,DISK], DatanodeInfoWithStorage[127.0.0.1:46862,DS-d3489f5a-6f9d-4a65-a0e6-ce2057e79c44,DISK], DatanodeInfoWithStorage[127.0.0.1:35975,DS-acefabc9-0d2f-46f8-9b26-b7f5cf109e40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1828686550-172.17.0.11-1595299261200:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44032,DS-cbdc69ab-bc3e-4ec3-896f-b8bf66059f54,DISK], DatanodeInfoWithStorage[127.0.0.1:42235,DS-178281ba-1ea8-4dac-9ee8-c65000dc3e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:33935,DS-1244ab33-d160-4a8d-9455-41cb17acd60c,DISK], DatanodeInfoWithStorage[127.0.0.1:41371,DS-c00b3434-a37c-4e33-bfdf-f60c6ede93ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35156,DS-48b6c878-09fe-465c-a041-97befcde25bd,DISK], DatanodeInfoWithStorage[127.0.0.1:33332,DS-3fe07b6e-58a2-4b0c-bbd6-168d1c306090,DISK], DatanodeInfoWithStorage[127.0.0.1:46862,DS-d3489f5a-6f9d-4a65-a0e6-ce2057e79c44,DISK], DatanodeInfoWithStorage[127.0.0.1:35975,DS-acefabc9-0d2f-46f8-9b26-b7f5cf109e40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-713633876-172.17.0.11-1595299293772:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34144,DS-e0be89de-8788-48d5-a89f-ef350cbc0a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:45761,DS-f15bcfd8-6c53-4691-83e6-831252082567,DISK], DatanodeInfoWithStorage[127.0.0.1:44997,DS-ab1d844c-eb3a-4aa8-8a8b-7c3d3f94e1c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42278,DS-b3866f41-490b-46ee-8c3d-dafb18258219,DISK], DatanodeInfoWithStorage[127.0.0.1:45019,DS-33c9192f-fa67-4812-acb8-b6b20d360b04,DISK], DatanodeInfoWithStorage[127.0.0.1:37991,DS-0196de0c-12d9-4c60-8cb2-07fe77bf8c29,DISK], DatanodeInfoWithStorage[127.0.0.1:44700,DS-8066caac-bc1b-47d7-b409-18bd9b63ac66,DISK], DatanodeInfoWithStorage[127.0.0.1:44819,DS-2444f078-ca33-441f-bde8-f14aba15a12c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-713633876-172.17.0.11-1595299293772:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34144,DS-e0be89de-8788-48d5-a89f-ef350cbc0a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:45761,DS-f15bcfd8-6c53-4691-83e6-831252082567,DISK], DatanodeInfoWithStorage[127.0.0.1:44997,DS-ab1d844c-eb3a-4aa8-8a8b-7c3d3f94e1c5,DISK], DatanodeInfoWithStorage[127.0.0.1:42278,DS-b3866f41-490b-46ee-8c3d-dafb18258219,DISK], DatanodeInfoWithStorage[127.0.0.1:45019,DS-33c9192f-fa67-4812-acb8-b6b20d360b04,DISK], DatanodeInfoWithStorage[127.0.0.1:37991,DS-0196de0c-12d9-4c60-8cb2-07fe77bf8c29,DISK], DatanodeInfoWithStorage[127.0.0.1:44700,DS-8066caac-bc1b-47d7-b409-18bd9b63ac66,DISK], DatanodeInfoWithStorage[127.0.0.1:44819,DS-2444f078-ca33-441f-bde8-f14aba15a12c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1825764031-172.17.0.11-1595299722988:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35248,DS-8dc0a21c-f387-4a4b-b65c-84fb7a384fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:39915,DS-4432c269-50dd-473b-8647-4a65753bdcc9,DISK], DatanodeInfoWithStorage[127.0.0.1:33321,DS-256739e4-b5d9-4b11-9d23-a1c405ea10ca,DISK], DatanodeInfoWithStorage[127.0.0.1:44104,DS-8b93d57a-a35b-4871-9721-bd7b68c1d13d,DISK], DatanodeInfoWithStorage[127.0.0.1:40584,DS-b8cd4deb-7ac0-41d6-becd-79549666c9e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36355,DS-5a51d5b8-ca90-4e11-b20a-ec300887fc1c,DISK], DatanodeInfoWithStorage[127.0.0.1:41408,DS-1a35404a-410f-4287-8740-1c3e01afc33c,DISK], DatanodeInfoWithStorage[127.0.0.1:43392,DS-857583df-197f-4148-86b6-a4a4e251dfea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1825764031-172.17.0.11-1595299722988:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35248,DS-8dc0a21c-f387-4a4b-b65c-84fb7a384fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:39915,DS-4432c269-50dd-473b-8647-4a65753bdcc9,DISK], DatanodeInfoWithStorage[127.0.0.1:33321,DS-256739e4-b5d9-4b11-9d23-a1c405ea10ca,DISK], DatanodeInfoWithStorage[127.0.0.1:44104,DS-8b93d57a-a35b-4871-9721-bd7b68c1d13d,DISK], DatanodeInfoWithStorage[127.0.0.1:40584,DS-b8cd4deb-7ac0-41d6-becd-79549666c9e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36355,DS-5a51d5b8-ca90-4e11-b20a-ec300887fc1c,DISK], DatanodeInfoWithStorage[127.0.0.1:41408,DS-1a35404a-410f-4287-8740-1c3e01afc33c,DISK], DatanodeInfoWithStorage[127.0.0.1:43392,DS-857583df-197f-4148-86b6-a4a4e251dfea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-971261526-172.17.0.11-1595300477661:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39627,DS-688be256-e457-44b6-8768-f2386845b888,DISK], DatanodeInfoWithStorage[127.0.0.1:40218,DS-3259e115-beef-4cb9-8903-3320d8711a1e,DISK], DatanodeInfoWithStorage[127.0.0.1:43578,DS-9cee08bb-233c-4e96-8230-4797748288e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41858,DS-b0cfe771-c2c2-4275-84bc-0b58a03d7a06,DISK], DatanodeInfoWithStorage[127.0.0.1:39545,DS-f1442bef-55cf-4cfc-a2fd-775fb38a48e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36942,DS-a1726386-d8af-481a-9f74-59ea8ef5822b,DISK], DatanodeInfoWithStorage[127.0.0.1:38512,DS-cb475b22-2be1-4af2-875e-53f879ac81dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42303,DS-db62a04a-d363-448e-bfc7-2ca9f430ee3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-971261526-172.17.0.11-1595300477661:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39627,DS-688be256-e457-44b6-8768-f2386845b888,DISK], DatanodeInfoWithStorage[127.0.0.1:40218,DS-3259e115-beef-4cb9-8903-3320d8711a1e,DISK], DatanodeInfoWithStorage[127.0.0.1:43578,DS-9cee08bb-233c-4e96-8230-4797748288e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41858,DS-b0cfe771-c2c2-4275-84bc-0b58a03d7a06,DISK], DatanodeInfoWithStorage[127.0.0.1:39545,DS-f1442bef-55cf-4cfc-a2fd-775fb38a48e4,DISK], DatanodeInfoWithStorage[127.0.0.1:36942,DS-a1726386-d8af-481a-9f74-59ea8ef5822b,DISK], DatanodeInfoWithStorage[127.0.0.1:38512,DS-cb475b22-2be1-4af2-875e-53f879ac81dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42303,DS-db62a04a-d363-448e-bfc7-2ca9f430ee3b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1729969821-172.17.0.11-1595300514144:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46514,DS-f9f95b2c-446c-45df-9afa-9914cf4bf91b,DISK], DatanodeInfoWithStorage[127.0.0.1:33130,DS-cabfbcb9-ce7c-43b4-aa57-7b6d772c8563,DISK], DatanodeInfoWithStorage[127.0.0.1:33186,DS-ecc1374b-6d6b-42c7-b2aa-18369a8f5fc0,DISK], DatanodeInfoWithStorage[127.0.0.1:40459,DS-1902cc06-c77f-407e-bf7c-33cce815a010,DISK], DatanodeInfoWithStorage[127.0.0.1:34411,DS-5fe5672a-5963-4bec-806a-c03a71d0b409,DISK], DatanodeInfoWithStorage[127.0.0.1:34057,DS-90cf9a30-c04e-4959-aaa4-daa6e3cc8478,DISK], DatanodeInfoWithStorage[127.0.0.1:33748,DS-7c050378-6792-4603-9198-dc59c007330e,DISK], DatanodeInfoWithStorage[127.0.0.1:37742,DS-123f7394-0c36-4757-b5f2-d092c7abbb1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1729969821-172.17.0.11-1595300514144:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46514,DS-f9f95b2c-446c-45df-9afa-9914cf4bf91b,DISK], DatanodeInfoWithStorage[127.0.0.1:33130,DS-cabfbcb9-ce7c-43b4-aa57-7b6d772c8563,DISK], DatanodeInfoWithStorage[127.0.0.1:33186,DS-ecc1374b-6d6b-42c7-b2aa-18369a8f5fc0,DISK], DatanodeInfoWithStorage[127.0.0.1:40459,DS-1902cc06-c77f-407e-bf7c-33cce815a010,DISK], DatanodeInfoWithStorage[127.0.0.1:34411,DS-5fe5672a-5963-4bec-806a-c03a71d0b409,DISK], DatanodeInfoWithStorage[127.0.0.1:34057,DS-90cf9a30-c04e-4959-aaa4-daa6e3cc8478,DISK], DatanodeInfoWithStorage[127.0.0.1:33748,DS-7c050378-6792-4603-9198-dc59c007330e,DISK], DatanodeInfoWithStorage[127.0.0.1:37742,DS-123f7394-0c36-4757-b5f2-d092c7abbb1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-514877214-172.17.0.11-1595300629250:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40528,DS-144954ef-5f94-499d-8d73-94f94545e61a,DISK], DatanodeInfoWithStorage[127.0.0.1:34479,DS-aba75a55-4392-4319-a93b-3f1e83c4ce69,DISK], DatanodeInfoWithStorage[127.0.0.1:37086,DS-88973a30-ea8c-4c1d-8ff6-912d6b5896d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44744,DS-b7f7e9a3-577b-4990-8683-a9a74f63ce07,DISK], DatanodeInfoWithStorage[127.0.0.1:40326,DS-85a74bcf-1daf-47fd-af10-ce52b5d1c187,DISK], DatanodeInfoWithStorage[127.0.0.1:36643,DS-7dfb11c6-c4b7-444e-9ed5-0281aa062ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:34944,DS-47f38017-438a-4ba3-b1fc-985d57df4948,DISK], DatanodeInfoWithStorage[127.0.0.1:35687,DS-9bf0777e-8b95-4c02-8580-d93cd23df660,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-514877214-172.17.0.11-1595300629250:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40528,DS-144954ef-5f94-499d-8d73-94f94545e61a,DISK], DatanodeInfoWithStorage[127.0.0.1:34479,DS-aba75a55-4392-4319-a93b-3f1e83c4ce69,DISK], DatanodeInfoWithStorage[127.0.0.1:37086,DS-88973a30-ea8c-4c1d-8ff6-912d6b5896d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44744,DS-b7f7e9a3-577b-4990-8683-a9a74f63ce07,DISK], DatanodeInfoWithStorage[127.0.0.1:40326,DS-85a74bcf-1daf-47fd-af10-ce52b5d1c187,DISK], DatanodeInfoWithStorage[127.0.0.1:36643,DS-7dfb11c6-c4b7-444e-9ed5-0281aa062ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:34944,DS-47f38017-438a-4ba3-b1fc-985d57df4948,DISK], DatanodeInfoWithStorage[127.0.0.1:35687,DS-9bf0777e-8b95-4c02-8580-d93cd23df660,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-376048225-172.17.0.11-1595300700815:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36210,DS-5c0d9f66-0c26-426c-b265-8bc203ef2231,DISK], DatanodeInfoWithStorage[127.0.0.1:41132,DS-d3ebf0bb-6a9c-41cc-b926-52d570aed7a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39588,DS-eef6759c-1acb-4e80-8251-9b94dc435f5b,DISK], DatanodeInfoWithStorage[127.0.0.1:42521,DS-59331fcd-c551-4913-b24c-58b00843bf0c,DISK], DatanodeInfoWithStorage[127.0.0.1:43354,DS-9fb76185-3b24-41e8-a7f6-afa314cc8af7,DISK], DatanodeInfoWithStorage[127.0.0.1:36410,DS-3cd848d6-e9cd-4a32-abe3-b57a997dab6d,DISK], DatanodeInfoWithStorage[127.0.0.1:39370,DS-0070dc85-0ce4-45ae-b513-0c013747adc5,DISK], DatanodeInfoWithStorage[127.0.0.1:35088,DS-f9a92f80-5665-4150-b834-fa9792ed3f70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-376048225-172.17.0.11-1595300700815:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36210,DS-5c0d9f66-0c26-426c-b265-8bc203ef2231,DISK], DatanodeInfoWithStorage[127.0.0.1:41132,DS-d3ebf0bb-6a9c-41cc-b926-52d570aed7a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39588,DS-eef6759c-1acb-4e80-8251-9b94dc435f5b,DISK], DatanodeInfoWithStorage[127.0.0.1:42521,DS-59331fcd-c551-4913-b24c-58b00843bf0c,DISK], DatanodeInfoWithStorage[127.0.0.1:43354,DS-9fb76185-3b24-41e8-a7f6-afa314cc8af7,DISK], DatanodeInfoWithStorage[127.0.0.1:36410,DS-3cd848d6-e9cd-4a32-abe3-b57a997dab6d,DISK], DatanodeInfoWithStorage[127.0.0.1:39370,DS-0070dc85-0ce4-45ae-b513-0c013747adc5,DISK], DatanodeInfoWithStorage[127.0.0.1:35088,DS-f9a92f80-5665-4150-b834-fa9792ed3f70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-291154425-172.17.0.11-1595301021535:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38642,DS-a9e19e76-a06b-4219-8c07-23121a083f28,DISK], DatanodeInfoWithStorage[127.0.0.1:44700,DS-af03c02f-e938-445b-9aba-767f76b6a5b9,DISK], DatanodeInfoWithStorage[127.0.0.1:40448,DS-83d4bb78-0441-4f57-a477-92816216d7ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35253,DS-092fb9a5-554a-478f-a521-a3d2e3139ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:41483,DS-c3febb32-e483-41f9-8ea1-f6f792f7c7e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37648,DS-a002fac9-aa3f-4fe8-a335-ee0d72060162,DISK], DatanodeInfoWithStorage[127.0.0.1:41150,DS-5ba3939b-5c96-4693-bde5-16f4a0b03c42,DISK], DatanodeInfoWithStorage[127.0.0.1:39897,DS-358c1b9b-e57a-4438-a2b8-78963086dea1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-291154425-172.17.0.11-1595301021535:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38642,DS-a9e19e76-a06b-4219-8c07-23121a083f28,DISK], DatanodeInfoWithStorage[127.0.0.1:44700,DS-af03c02f-e938-445b-9aba-767f76b6a5b9,DISK], DatanodeInfoWithStorage[127.0.0.1:40448,DS-83d4bb78-0441-4f57-a477-92816216d7ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35253,DS-092fb9a5-554a-478f-a521-a3d2e3139ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:41483,DS-c3febb32-e483-41f9-8ea1-f6f792f7c7e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37648,DS-a002fac9-aa3f-4fe8-a335-ee0d72060162,DISK], DatanodeInfoWithStorage[127.0.0.1:41150,DS-5ba3939b-5c96-4693-bde5-16f4a0b03c42,DISK], DatanodeInfoWithStorage[127.0.0.1:39897,DS-358c1b9b-e57a-4438-a2b8-78963086dea1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-325527048-172.17.0.11-1595301147464:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44746,DS-6ae3d71d-ca96-443c-b30d-4ae595ef9dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:39859,DS-27d041db-5ae3-4cca-8639-6a31eeb4417b,DISK], DatanodeInfoWithStorage[127.0.0.1:34451,DS-088f5ef4-da60-47e2-a9d9-f444c0ede1a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42317,DS-bc3721be-02fb-4476-bd73-ff597c006608,DISK], DatanodeInfoWithStorage[127.0.0.1:33643,DS-28f5ce63-3791-4b1f-a388-6d7256ef1f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:37460,DS-81640763-1d29-4242-9350-9bd9103a44fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46867,DS-18719015-6fd6-4d95-8950-c51fe3f944b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34067,DS-bd49b99e-d616-459f-aefd-b5e5eaf3da88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-325527048-172.17.0.11-1595301147464:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44746,DS-6ae3d71d-ca96-443c-b30d-4ae595ef9dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:39859,DS-27d041db-5ae3-4cca-8639-6a31eeb4417b,DISK], DatanodeInfoWithStorage[127.0.0.1:34451,DS-088f5ef4-da60-47e2-a9d9-f444c0ede1a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42317,DS-bc3721be-02fb-4476-bd73-ff597c006608,DISK], DatanodeInfoWithStorage[127.0.0.1:33643,DS-28f5ce63-3791-4b1f-a388-6d7256ef1f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:37460,DS-81640763-1d29-4242-9350-9bd9103a44fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46867,DS-18719015-6fd6-4d95-8950-c51fe3f944b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34067,DS-bd49b99e-d616-459f-aefd-b5e5eaf3da88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-308982510-172.17.0.11-1595301185632:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42571,DS-8555ce76-d993-4542-af17-b7aa77fa3290,DISK], DatanodeInfoWithStorage[127.0.0.1:40607,DS-84daea15-2c9c-43d2-80a4-99871c883425,DISK], DatanodeInfoWithStorage[127.0.0.1:46118,DS-a081da4f-1a7a-46c0-bc17-f6e3a58c42a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33289,DS-1a7104f9-d221-4c87-9dda-68668531714d,DISK], DatanodeInfoWithStorage[127.0.0.1:36898,DS-14431cac-7255-4efd-bd3f-9fe1fd02025b,DISK], DatanodeInfoWithStorage[127.0.0.1:35683,DS-fd4ceca6-2c04-412d-b3ce-09b6c11ce210,DISK], DatanodeInfoWithStorage[127.0.0.1:42428,DS-644a75a7-f4ab-4f54-a308-5f7e33a0e214,DISK], DatanodeInfoWithStorage[127.0.0.1:40777,DS-705390c1-5de7-4639-b688-78aedcdee701,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-308982510-172.17.0.11-1595301185632:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42571,DS-8555ce76-d993-4542-af17-b7aa77fa3290,DISK], DatanodeInfoWithStorage[127.0.0.1:40607,DS-84daea15-2c9c-43d2-80a4-99871c883425,DISK], DatanodeInfoWithStorage[127.0.0.1:46118,DS-a081da4f-1a7a-46c0-bc17-f6e3a58c42a1,DISK], DatanodeInfoWithStorage[127.0.0.1:33289,DS-1a7104f9-d221-4c87-9dda-68668531714d,DISK], DatanodeInfoWithStorage[127.0.0.1:36898,DS-14431cac-7255-4efd-bd3f-9fe1fd02025b,DISK], DatanodeInfoWithStorage[127.0.0.1:35683,DS-fd4ceca6-2c04-412d-b3ce-09b6c11ce210,DISK], DatanodeInfoWithStorage[127.0.0.1:42428,DS-644a75a7-f4ab-4f54-a308-5f7e33a0e214,DISK], DatanodeInfoWithStorage[127.0.0.1:40777,DS-705390c1-5de7-4639-b688-78aedcdee701,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-581922572-172.17.0.11-1595301311435:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36011,DS-040f6779-ef09-495e-a894-1476720f816a,DISK], DatanodeInfoWithStorage[127.0.0.1:44232,DS-1f357395-815d-40db-a779-c42f2b2e04b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42811,DS-26ff581e-e2dc-4265-95c7-94509ae63b1c,DISK], DatanodeInfoWithStorage[127.0.0.1:39137,DS-6fa465c6-1402-443a-a394-c43df9f79871,DISK], DatanodeInfoWithStorage[127.0.0.1:36115,DS-d2ebe136-aee5-4c75-8046-33e174ff9701,DISK], DatanodeInfoWithStorage[127.0.0.1:33801,DS-1dccaa4f-2a9b-4a5d-a1f1-70c9a0734a72,DISK], DatanodeInfoWithStorage[127.0.0.1:42096,DS-a4c36e30-8cb5-462c-b7db-bcfc767e5521,DISK], DatanodeInfoWithStorage[127.0.0.1:35479,DS-6840c456-94f1-4dba-b8ae-62f46198f6cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-581922572-172.17.0.11-1595301311435:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36011,DS-040f6779-ef09-495e-a894-1476720f816a,DISK], DatanodeInfoWithStorage[127.0.0.1:44232,DS-1f357395-815d-40db-a779-c42f2b2e04b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42811,DS-26ff581e-e2dc-4265-95c7-94509ae63b1c,DISK], DatanodeInfoWithStorage[127.0.0.1:39137,DS-6fa465c6-1402-443a-a394-c43df9f79871,DISK], DatanodeInfoWithStorage[127.0.0.1:36115,DS-d2ebe136-aee5-4c75-8046-33e174ff9701,DISK], DatanodeInfoWithStorage[127.0.0.1:33801,DS-1dccaa4f-2a9b-4a5d-a1f1-70c9a0734a72,DISK], DatanodeInfoWithStorage[127.0.0.1:42096,DS-a4c36e30-8cb5-462c-b7db-bcfc767e5521,DISK], DatanodeInfoWithStorage[127.0.0.1:35479,DS-6840c456-94f1-4dba-b8ae-62f46198f6cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1504824489-172.17.0.11-1595301446474:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37390,DS-1ef0592e-1f00-4f2a-9932-0df18d6cc331,DISK], DatanodeInfoWithStorage[127.0.0.1:39457,DS-c8c15fe3-2ab6-456c-b70e-2f415aadfb3e,DISK], DatanodeInfoWithStorage[127.0.0.1:35683,DS-b315cf21-3416-42d8-a653-d1c2b16ca5dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44515,DS-06188017-2c08-48bc-addf-1858bcd3037d,DISK], DatanodeInfoWithStorage[127.0.0.1:37197,DS-3fec811b-6291-4b02-8d7c-fa5d6385367d,DISK], DatanodeInfoWithStorage[127.0.0.1:33930,DS-a69cefb5-dadc-4fd1-a0cf-e02051b0de66,DISK], DatanodeInfoWithStorage[127.0.0.1:35345,DS-1b73bcd9-d93f-4e11-b2a3-02b7871bebdb,DISK], DatanodeInfoWithStorage[127.0.0.1:45512,DS-b9b15387-bb4e-4608-b0bb-80f552c04d0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1504824489-172.17.0.11-1595301446474:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37390,DS-1ef0592e-1f00-4f2a-9932-0df18d6cc331,DISK], DatanodeInfoWithStorage[127.0.0.1:39457,DS-c8c15fe3-2ab6-456c-b70e-2f415aadfb3e,DISK], DatanodeInfoWithStorage[127.0.0.1:35683,DS-b315cf21-3416-42d8-a653-d1c2b16ca5dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44515,DS-06188017-2c08-48bc-addf-1858bcd3037d,DISK], DatanodeInfoWithStorage[127.0.0.1:37197,DS-3fec811b-6291-4b02-8d7c-fa5d6385367d,DISK], DatanodeInfoWithStorage[127.0.0.1:33930,DS-a69cefb5-dadc-4fd1-a0cf-e02051b0de66,DISK], DatanodeInfoWithStorage[127.0.0.1:35345,DS-1b73bcd9-d93f-4e11-b2a3-02b7871bebdb,DISK], DatanodeInfoWithStorage[127.0.0.1:45512,DS-b9b15387-bb4e-4608-b0bb-80f552c04d0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1989062349-172.17.0.11-1595301598884:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33089,DS-0d300dca-3efb-4d05-845e-589d3a26ed0b,DISK], DatanodeInfoWithStorage[127.0.0.1:45787,DS-b80e2c24-2a07-4421-9def-dfe1162a8601,DISK], DatanodeInfoWithStorage[127.0.0.1:35759,DS-7692e555-49b2-4491-b9d5-74735c95e12f,DISK], DatanodeInfoWithStorage[127.0.0.1:37491,DS-fabca55d-a92c-4abb-a811-6aaf8e6b5874,DISK], DatanodeInfoWithStorage[127.0.0.1:46382,DS-81df6e87-407d-4e4c-9899-7cde3daefbff,DISK], DatanodeInfoWithStorage[127.0.0.1:33396,DS-be43788f-631a-4fb3-9d17-2ffdf0eb2268,DISK], DatanodeInfoWithStorage[127.0.0.1:35466,DS-39448b09-c38e-4862-a652-5a7defc75790,DISK], DatanodeInfoWithStorage[127.0.0.1:40160,DS-8e25bf5d-be19-4686-bb67-6d09635bff24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1989062349-172.17.0.11-1595301598884:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33089,DS-0d300dca-3efb-4d05-845e-589d3a26ed0b,DISK], DatanodeInfoWithStorage[127.0.0.1:45787,DS-b80e2c24-2a07-4421-9def-dfe1162a8601,DISK], DatanodeInfoWithStorage[127.0.0.1:35759,DS-7692e555-49b2-4491-b9d5-74735c95e12f,DISK], DatanodeInfoWithStorage[127.0.0.1:37491,DS-fabca55d-a92c-4abb-a811-6aaf8e6b5874,DISK], DatanodeInfoWithStorage[127.0.0.1:46382,DS-81df6e87-407d-4e4c-9899-7cde3daefbff,DISK], DatanodeInfoWithStorage[127.0.0.1:33396,DS-be43788f-631a-4fb3-9d17-2ffdf0eb2268,DISK], DatanodeInfoWithStorage[127.0.0.1:35466,DS-39448b09-c38e-4862-a652-5a7defc75790,DISK], DatanodeInfoWithStorage[127.0.0.1:40160,DS-8e25bf5d-be19-4686-bb67-6d09635bff24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-404991999-172.17.0.11-1595301706245:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46849,DS-58c6ad8a-8026-48c9-b53b-ceb014d005c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43021,DS-3fae72b5-c6d0-441a-8327-eed685ccd7f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36056,DS-64a5774f-598d-47eb-97f3-4029dc806539,DISK], DatanodeInfoWithStorage[127.0.0.1:39363,DS-e0b975ef-2a3e-4ded-9ea0-d6d573094a09,DISK], DatanodeInfoWithStorage[127.0.0.1:45488,DS-4e4977fe-aa71-4014-97da-cda489d98109,DISK], DatanodeInfoWithStorage[127.0.0.1:36920,DS-f6825790-61a1-48a6-9a61-85062f7197ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40463,DS-8e9cb38a-e504-4d8d-af4d-fb7a4087f2a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39542,DS-ea369bbe-2d68-45ed-90eb-9b0057796f19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-404991999-172.17.0.11-1595301706245:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46849,DS-58c6ad8a-8026-48c9-b53b-ceb014d005c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43021,DS-3fae72b5-c6d0-441a-8327-eed685ccd7f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36056,DS-64a5774f-598d-47eb-97f3-4029dc806539,DISK], DatanodeInfoWithStorage[127.0.0.1:39363,DS-e0b975ef-2a3e-4ded-9ea0-d6d573094a09,DISK], DatanodeInfoWithStorage[127.0.0.1:45488,DS-4e4977fe-aa71-4014-97da-cda489d98109,DISK], DatanodeInfoWithStorage[127.0.0.1:36920,DS-f6825790-61a1-48a6-9a61-85062f7197ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40463,DS-8e9cb38a-e504-4d8d-af4d-fb7a4087f2a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39542,DS-ea369bbe-2d68-45ed-90eb-9b0057796f19,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5234
