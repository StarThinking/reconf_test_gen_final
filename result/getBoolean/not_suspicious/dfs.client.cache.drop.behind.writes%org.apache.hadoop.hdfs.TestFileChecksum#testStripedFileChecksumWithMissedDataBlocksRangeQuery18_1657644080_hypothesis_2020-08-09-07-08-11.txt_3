reconf_parameter: dfs.client.cache.drop.behind.writes
component: hdfs:NameNode
v1: null
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.writes
component: hdfs:NameNode
v1: null
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1601814874-172.17.0.3-1596956947594:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37819,DS-dc044f35-450c-460e-a4bc-6b6a5ac759ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33387,DS-8ac1931b-3547-4687-8a85-935f68faa8a3,DISK], DatanodeInfoWithStorage[127.0.0.1:46877,DS-8196a289-ce3c-4c83-a1e8-ddaa2b8575c8,DISK], DatanodeInfoWithStorage[127.0.0.1:46537,DS-d70cd8c4-4573-43ec-a288-85c85e4f3040,DISK], DatanodeInfoWithStorage[127.0.0.1:39584,DS-640dc691-55f7-4a41-9e48-aae4e2fbf986,DISK], DatanodeInfoWithStorage[127.0.0.1:44813,DS-4778887a-d695-48bd-9e77-90112e253922,DISK], DatanodeInfoWithStorage[127.0.0.1:46851,DS-0cbf8811-ad8a-47a3-a3fb-bae0a539335b,DISK], DatanodeInfoWithStorage[127.0.0.1:41247,DS-8eb7308e-850f-48df-b170-e3cc89891d2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1601814874-172.17.0.3-1596956947594:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37819,DS-dc044f35-450c-460e-a4bc-6b6a5ac759ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33387,DS-8ac1931b-3547-4687-8a85-935f68faa8a3,DISK], DatanodeInfoWithStorage[127.0.0.1:46877,DS-8196a289-ce3c-4c83-a1e8-ddaa2b8575c8,DISK], DatanodeInfoWithStorage[127.0.0.1:46537,DS-d70cd8c4-4573-43ec-a288-85c85e4f3040,DISK], DatanodeInfoWithStorage[127.0.0.1:39584,DS-640dc691-55f7-4a41-9e48-aae4e2fbf986,DISK], DatanodeInfoWithStorage[127.0.0.1:44813,DS-4778887a-d695-48bd-9e77-90112e253922,DISK], DatanodeInfoWithStorage[127.0.0.1:46851,DS-0cbf8811-ad8a-47a3-a3fb-bae0a539335b,DISK], DatanodeInfoWithStorage[127.0.0.1:41247,DS-8eb7308e-850f-48df-b170-e3cc89891d2d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.writes
component: hdfs:NameNode
v1: null
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1501904309-172.17.0.3-1596957218792:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40206,DS-30f328f7-5f2c-4370-bb53-9a3278a949d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33870,DS-88244173-0735-44ff-8a61-9934a300849b,DISK], DatanodeInfoWithStorage[127.0.0.1:35293,DS-0feb8995-506c-4d08-af1a-d690c87c67c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35493,DS-d2028011-ed5d-4dda-957d-9670f49b5fbf,DISK], DatanodeInfoWithStorage[127.0.0.1:36954,DS-fe31bc85-b865-4685-90a2-778266b47c5a,DISK], DatanodeInfoWithStorage[127.0.0.1:45590,DS-5484adf9-6d37-40bc-86a5-80a49befae46,DISK], DatanodeInfoWithStorage[127.0.0.1:37693,DS-4de4b17b-3474-4a19-8d7b-91a323ebc93a,DISK], DatanodeInfoWithStorage[127.0.0.1:38451,DS-0be76dfe-b678-48fd-895f-3e3be5692bc6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1501904309-172.17.0.3-1596957218792:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40206,DS-30f328f7-5f2c-4370-bb53-9a3278a949d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33870,DS-88244173-0735-44ff-8a61-9934a300849b,DISK], DatanodeInfoWithStorage[127.0.0.1:35293,DS-0feb8995-506c-4d08-af1a-d690c87c67c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35493,DS-d2028011-ed5d-4dda-957d-9670f49b5fbf,DISK], DatanodeInfoWithStorage[127.0.0.1:36954,DS-fe31bc85-b865-4685-90a2-778266b47c5a,DISK], DatanodeInfoWithStorage[127.0.0.1:45590,DS-5484adf9-6d37-40bc-86a5-80a49befae46,DISK], DatanodeInfoWithStorage[127.0.0.1:37693,DS-4de4b17b-3474-4a19-8d7b-91a323ebc93a,DISK], DatanodeInfoWithStorage[127.0.0.1:38451,DS-0be76dfe-b678-48fd-895f-3e3be5692bc6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.writes
component: hdfs:NameNode
v1: null
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-858761654-172.17.0.3-1596957324276:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38226,DS-a8ad2429-41cd-43fc-a1f8-50a79aef159e,DISK], DatanodeInfoWithStorage[127.0.0.1:37807,DS-3a78a2b3-d186-40d3-a99c-d5cb92724050,DISK], DatanodeInfoWithStorage[127.0.0.1:43689,DS-4e28de56-0c81-48d8-8e61-6585e9e9634e,DISK], DatanodeInfoWithStorage[127.0.0.1:33028,DS-7f9e4885-1ae0-4b32-9068-55c3011fd6b9,DISK], DatanodeInfoWithStorage[127.0.0.1:32768,DS-33f13d30-42a1-4f70-b5f0-586239dddb58,DISK], DatanodeInfoWithStorage[127.0.0.1:40291,DS-da66eb54-04ca-4eb6-ba6c-a9409a1ab108,DISK], DatanodeInfoWithStorage[127.0.0.1:46074,DS-7ba12732-7042-43f2-98d0-2ffb314117cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38306,DS-fa377b3f-7c86-43d7-bce9-f611ea3e48fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-858761654-172.17.0.3-1596957324276:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38226,DS-a8ad2429-41cd-43fc-a1f8-50a79aef159e,DISK], DatanodeInfoWithStorage[127.0.0.1:37807,DS-3a78a2b3-d186-40d3-a99c-d5cb92724050,DISK], DatanodeInfoWithStorage[127.0.0.1:43689,DS-4e28de56-0c81-48d8-8e61-6585e9e9634e,DISK], DatanodeInfoWithStorage[127.0.0.1:33028,DS-7f9e4885-1ae0-4b32-9068-55c3011fd6b9,DISK], DatanodeInfoWithStorage[127.0.0.1:32768,DS-33f13d30-42a1-4f70-b5f0-586239dddb58,DISK], DatanodeInfoWithStorage[127.0.0.1:40291,DS-da66eb54-04ca-4eb6-ba6c-a9409a1ab108,DISK], DatanodeInfoWithStorage[127.0.0.1:46074,DS-7ba12732-7042-43f2-98d0-2ffb314117cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38306,DS-fa377b3f-7c86-43d7-bce9-f611ea3e48fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.writes
component: hdfs:NameNode
v1: null
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1988546037-172.17.0.3-1596957390712:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39975,DS-b7777ebb-7610-4be6-b6fd-c36ab63ab3df,DISK], DatanodeInfoWithStorage[127.0.0.1:37095,DS-15a5477b-e174-434f-b3bb-970d7793c853,DISK], DatanodeInfoWithStorage[127.0.0.1:41327,DS-0a262393-8a75-4ee5-bc86-921186b68cce,DISK], DatanodeInfoWithStorage[127.0.0.1:41126,DS-53f8f774-f001-4be8-b9ed-370e9d886063,DISK], DatanodeInfoWithStorage[127.0.0.1:39337,DS-09d763e1-9022-4955-86f0-2f8254d857d5,DISK], DatanodeInfoWithStorage[127.0.0.1:37045,DS-e007108d-9eff-48db-b03a-0674a3fcceea,DISK], DatanodeInfoWithStorage[127.0.0.1:37842,DS-e8ed3d76-2378-4521-a528-19d9c3247595,DISK], DatanodeInfoWithStorage[127.0.0.1:37603,DS-f44a2828-60fb-450a-a684-a8ea9b4b2d58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1988546037-172.17.0.3-1596957390712:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39975,DS-b7777ebb-7610-4be6-b6fd-c36ab63ab3df,DISK], DatanodeInfoWithStorage[127.0.0.1:37095,DS-15a5477b-e174-434f-b3bb-970d7793c853,DISK], DatanodeInfoWithStorage[127.0.0.1:41327,DS-0a262393-8a75-4ee5-bc86-921186b68cce,DISK], DatanodeInfoWithStorage[127.0.0.1:41126,DS-53f8f774-f001-4be8-b9ed-370e9d886063,DISK], DatanodeInfoWithStorage[127.0.0.1:39337,DS-09d763e1-9022-4955-86f0-2f8254d857d5,DISK], DatanodeInfoWithStorage[127.0.0.1:37045,DS-e007108d-9eff-48db-b03a-0674a3fcceea,DISK], DatanodeInfoWithStorage[127.0.0.1:37842,DS-e8ed3d76-2378-4521-a528-19d9c3247595,DISK], DatanodeInfoWithStorage[127.0.0.1:37603,DS-f44a2828-60fb-450a-a684-a8ea9b4b2d58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.writes
component: hdfs:NameNode
v1: null
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-57672952-172.17.0.3-1596958225930:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35712,DS-a835184f-96ba-45d2-b633-6aba79e6f788,DISK], DatanodeInfoWithStorage[127.0.0.1:34499,DS-9849fb0c-836a-48d8-b448-677e37760ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:44718,DS-5cac77dd-caaf-4f38-8274-2c37ac1f143a,DISK], DatanodeInfoWithStorage[127.0.0.1:45708,DS-103a98de-6b74-4e95-9e63-11efa49cb5c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44784,DS-d40111b6-8c73-45c5-b0e0-e3e53361b4e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37446,DS-02cf729a-2d9e-4315-874c-280746bb679b,DISK], DatanodeInfoWithStorage[127.0.0.1:41489,DS-7cd45126-e9cf-467b-84c7-ae060723ddf9,DISK], DatanodeInfoWithStorage[127.0.0.1:43647,DS-34bab722-0562-4d1e-816b-50821d2afd04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-57672952-172.17.0.3-1596958225930:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35712,DS-a835184f-96ba-45d2-b633-6aba79e6f788,DISK], DatanodeInfoWithStorage[127.0.0.1:34499,DS-9849fb0c-836a-48d8-b448-677e37760ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:44718,DS-5cac77dd-caaf-4f38-8274-2c37ac1f143a,DISK], DatanodeInfoWithStorage[127.0.0.1:45708,DS-103a98de-6b74-4e95-9e63-11efa49cb5c3,DISK], DatanodeInfoWithStorage[127.0.0.1:44784,DS-d40111b6-8c73-45c5-b0e0-e3e53361b4e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37446,DS-02cf729a-2d9e-4315-874c-280746bb679b,DISK], DatanodeInfoWithStorage[127.0.0.1:41489,DS-7cd45126-e9cf-467b-84c7-ae060723ddf9,DISK], DatanodeInfoWithStorage[127.0.0.1:43647,DS-34bab722-0562-4d1e-816b-50821d2afd04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.writes
component: hdfs:NameNode
v1: null
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1912314278-172.17.0.3-1596958458099:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39255,DS-37095abb-e5a9-4140-929c-278382512c37,DISK], DatanodeInfoWithStorage[127.0.0.1:39442,DS-52228c02-eb60-4f31-b3de-0b31a003daa3,DISK], DatanodeInfoWithStorage[127.0.0.1:41754,DS-faff1ee5-2485-42bc-9a24-5afdf60700f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44798,DS-0a0afe94-0053-446f-8288-5ec73b73e853,DISK], DatanodeInfoWithStorage[127.0.0.1:37958,DS-b764a4f1-dd20-481b-bb09-fa34713d8882,DISK], DatanodeInfoWithStorage[127.0.0.1:44381,DS-f9b543f8-be3e-4522-8e43-4c39b48cb351,DISK], DatanodeInfoWithStorage[127.0.0.1:35648,DS-56dbef0b-eff0-4ef7-a015-59feff264723,DISK], DatanodeInfoWithStorage[127.0.0.1:33524,DS-7c2a2bd3-4fef-4cfc-a9d4-b10542c676dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1912314278-172.17.0.3-1596958458099:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39255,DS-37095abb-e5a9-4140-929c-278382512c37,DISK], DatanodeInfoWithStorage[127.0.0.1:39442,DS-52228c02-eb60-4f31-b3de-0b31a003daa3,DISK], DatanodeInfoWithStorage[127.0.0.1:41754,DS-faff1ee5-2485-42bc-9a24-5afdf60700f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44798,DS-0a0afe94-0053-446f-8288-5ec73b73e853,DISK], DatanodeInfoWithStorage[127.0.0.1:37958,DS-b764a4f1-dd20-481b-bb09-fa34713d8882,DISK], DatanodeInfoWithStorage[127.0.0.1:44381,DS-f9b543f8-be3e-4522-8e43-4c39b48cb351,DISK], DatanodeInfoWithStorage[127.0.0.1:35648,DS-56dbef0b-eff0-4ef7-a015-59feff264723,DISK], DatanodeInfoWithStorage[127.0.0.1:33524,DS-7c2a2bd3-4fef-4cfc-a9d4-b10542c676dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.writes
component: hdfs:NameNode
v1: null
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1614800672-172.17.0.3-1596958491389:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45505,DS-13970693-36ff-40d4-a716-e4e820cf054e,DISK], DatanodeInfoWithStorage[127.0.0.1:45340,DS-c53dd237-01cf-4efd-ae42-5a6c3505f00a,DISK], DatanodeInfoWithStorage[127.0.0.1:45805,DS-79908dd8-33ff-4e91-b972-47a6c0c8fc45,DISK], DatanodeInfoWithStorage[127.0.0.1:41590,DS-5113415a-7112-4042-b6b4-d19437f1288a,DISK], DatanodeInfoWithStorage[127.0.0.1:44751,DS-c2d17af4-44fe-42c6-9e17-805be1af4ec5,DISK], DatanodeInfoWithStorage[127.0.0.1:33490,DS-02f3d801-3716-46fa-b599-2a751546ef35,DISK], DatanodeInfoWithStorage[127.0.0.1:42141,DS-3dca4111-a391-45b5-8ebf-d1bddfb3e20b,DISK], DatanodeInfoWithStorage[127.0.0.1:36547,DS-51d0f004-5217-4d0b-8a4c-47223fd6a580,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1614800672-172.17.0.3-1596958491389:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45505,DS-13970693-36ff-40d4-a716-e4e820cf054e,DISK], DatanodeInfoWithStorage[127.0.0.1:45340,DS-c53dd237-01cf-4efd-ae42-5a6c3505f00a,DISK], DatanodeInfoWithStorage[127.0.0.1:45805,DS-79908dd8-33ff-4e91-b972-47a6c0c8fc45,DISK], DatanodeInfoWithStorage[127.0.0.1:41590,DS-5113415a-7112-4042-b6b4-d19437f1288a,DISK], DatanodeInfoWithStorage[127.0.0.1:44751,DS-c2d17af4-44fe-42c6-9e17-805be1af4ec5,DISK], DatanodeInfoWithStorage[127.0.0.1:33490,DS-02f3d801-3716-46fa-b599-2a751546ef35,DISK], DatanodeInfoWithStorage[127.0.0.1:42141,DS-3dca4111-a391-45b5-8ebf-d1bddfb3e20b,DISK], DatanodeInfoWithStorage[127.0.0.1:36547,DS-51d0f004-5217-4d0b-8a4c-47223fd6a580,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.writes
component: hdfs:NameNode
v1: null
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-602138328-172.17.0.3-1596958752069:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44319,DS-93a75b39-d0f2-427d-ae76-498d954c3787,DISK], DatanodeInfoWithStorage[127.0.0.1:43595,DS-f41b4670-8a96-416d-8927-4b78354c52ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43591,DS-901a6e3e-39a1-4f1e-a9f7-4dae32362b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:33198,DS-39b297df-1c92-44db-8040-af5855433098,DISK], DatanodeInfoWithStorage[127.0.0.1:37267,DS-7f6b0ff2-dfc8-4467-9c2e-e707eaea52a4,DISK], DatanodeInfoWithStorage[127.0.0.1:46095,DS-192e01cb-1bdc-447c-83c7-ac13c0b8ffe0,DISK], DatanodeInfoWithStorage[127.0.0.1:35199,DS-0b7e4f59-3a64-4ed9-8c9b-05bf3389bec0,DISK], DatanodeInfoWithStorage[127.0.0.1:41099,DS-ab71dd17-3913-4558-a276-da6ad865d557,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-602138328-172.17.0.3-1596958752069:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44319,DS-93a75b39-d0f2-427d-ae76-498d954c3787,DISK], DatanodeInfoWithStorage[127.0.0.1:43595,DS-f41b4670-8a96-416d-8927-4b78354c52ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43591,DS-901a6e3e-39a1-4f1e-a9f7-4dae32362b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:33198,DS-39b297df-1c92-44db-8040-af5855433098,DISK], DatanodeInfoWithStorage[127.0.0.1:37267,DS-7f6b0ff2-dfc8-4467-9c2e-e707eaea52a4,DISK], DatanodeInfoWithStorage[127.0.0.1:46095,DS-192e01cb-1bdc-447c-83c7-ac13c0b8ffe0,DISK], DatanodeInfoWithStorage[127.0.0.1:35199,DS-0b7e4f59-3a64-4ed9-8c9b-05bf3389bec0,DISK], DatanodeInfoWithStorage[127.0.0.1:41099,DS-ab71dd17-3913-4558-a276-da6ad865d557,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.writes
component: hdfs:NameNode
v1: null
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1335342099-172.17.0.3-1596959104658:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44085,DS-af8f7a85-bc7c-4e10-9f60-65d211e9925b,DISK], DatanodeInfoWithStorage[127.0.0.1:42555,DS-b8f78b6d-f296-4450-9b90-4fbbcabf759c,DISK], DatanodeInfoWithStorage[127.0.0.1:34294,DS-7aea98c0-c493-44b3-aaee-6a47b7719fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:45364,DS-c3201574-dbbe-4eb9-a081-84cf5f81773a,DISK], DatanodeInfoWithStorage[127.0.0.1:40190,DS-0e6b2834-4e34-4f63-acda-bdd95bac6a2c,DISK], DatanodeInfoWithStorage[127.0.0.1:33646,DS-b9a49166-053b-42f1-b261-6d059c8c481f,DISK], DatanodeInfoWithStorage[127.0.0.1:35781,DS-7e8f1293-4482-4eff-9b59-865534ade496,DISK], DatanodeInfoWithStorage[127.0.0.1:33436,DS-1f8ed75b-9607-483a-a764-beaace1e1b3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1335342099-172.17.0.3-1596959104658:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44085,DS-af8f7a85-bc7c-4e10-9f60-65d211e9925b,DISK], DatanodeInfoWithStorage[127.0.0.1:42555,DS-b8f78b6d-f296-4450-9b90-4fbbcabf759c,DISK], DatanodeInfoWithStorage[127.0.0.1:34294,DS-7aea98c0-c493-44b3-aaee-6a47b7719fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:45364,DS-c3201574-dbbe-4eb9-a081-84cf5f81773a,DISK], DatanodeInfoWithStorage[127.0.0.1:40190,DS-0e6b2834-4e34-4f63-acda-bdd95bac6a2c,DISK], DatanodeInfoWithStorage[127.0.0.1:33646,DS-b9a49166-053b-42f1-b261-6d059c8c481f,DISK], DatanodeInfoWithStorage[127.0.0.1:35781,DS-7e8f1293-4482-4eff-9b59-865534ade496,DISK], DatanodeInfoWithStorage[127.0.0.1:33436,DS-1f8ed75b-9607-483a-a764-beaace1e1b3c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.writes
component: hdfs:NameNode
v1: null
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1415220773-172.17.0.3-1596959431012:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39539,DS-8330ddfe-ab0b-4f8e-a086-56adbd7d0599,DISK], DatanodeInfoWithStorage[127.0.0.1:40289,DS-152d6472-d350-4b6b-a41d-740f31bc7b63,DISK], DatanodeInfoWithStorage[127.0.0.1:38377,DS-4619b227-4603-43d7-8dc7-7d3b3d922c25,DISK], DatanodeInfoWithStorage[127.0.0.1:40930,DS-e22018b6-4b93-493d-9267-e4915b852aba,DISK], DatanodeInfoWithStorage[127.0.0.1:40204,DS-798b857c-237f-4a00-b7a2-9f2eae0eea1c,DISK], DatanodeInfoWithStorage[127.0.0.1:36837,DS-d2c2738a-5a01-491d-b3fb-f3742bcb3f6a,DISK], DatanodeInfoWithStorage[127.0.0.1:46419,DS-dd438d3e-3d96-4cc1-97b5-ca772eb7d28e,DISK], DatanodeInfoWithStorage[127.0.0.1:34176,DS-68210dfc-f01f-4771-979b-0d9c8bf44d1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1415220773-172.17.0.3-1596959431012:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39539,DS-8330ddfe-ab0b-4f8e-a086-56adbd7d0599,DISK], DatanodeInfoWithStorage[127.0.0.1:40289,DS-152d6472-d350-4b6b-a41d-740f31bc7b63,DISK], DatanodeInfoWithStorage[127.0.0.1:38377,DS-4619b227-4603-43d7-8dc7-7d3b3d922c25,DISK], DatanodeInfoWithStorage[127.0.0.1:40930,DS-e22018b6-4b93-493d-9267-e4915b852aba,DISK], DatanodeInfoWithStorage[127.0.0.1:40204,DS-798b857c-237f-4a00-b7a2-9f2eae0eea1c,DISK], DatanodeInfoWithStorage[127.0.0.1:36837,DS-d2c2738a-5a01-491d-b3fb-f3742bcb3f6a,DISK], DatanodeInfoWithStorage[127.0.0.1:46419,DS-dd438d3e-3d96-4cc1-97b5-ca772eb7d28e,DISK], DatanodeInfoWithStorage[127.0.0.1:34176,DS-68210dfc-f01f-4771-979b-0d9c8bf44d1a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.writes
component: hdfs:NameNode
v1: null
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2012015023-172.17.0.3-1596959603170:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33395,DS-ba8787ea-2da1-4ee4-a3c1-d889b5e0fb31,DISK], DatanodeInfoWithStorage[127.0.0.1:44722,DS-aef52287-b251-4b8b-873c-62ab7da7035f,DISK], DatanodeInfoWithStorage[127.0.0.1:39517,DS-8d50e57a-4a75-46fa-b1e2-8fb3b06d0a06,DISK], DatanodeInfoWithStorage[127.0.0.1:35455,DS-34bdcd06-e36b-453c-8344-6a7d0a45d2b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39208,DS-40812c78-c4fb-4c87-92cd-f053a1d05a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:39143,DS-85db0841-e46d-4404-88fe-68eb2734502d,DISK], DatanodeInfoWithStorage[127.0.0.1:36881,DS-b04e8fb7-f1bd-4a96-aab3-8ae20830a902,DISK], DatanodeInfoWithStorage[127.0.0.1:46855,DS-9957eedc-51ea-415f-a513-69e42c70f70d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2012015023-172.17.0.3-1596959603170:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33395,DS-ba8787ea-2da1-4ee4-a3c1-d889b5e0fb31,DISK], DatanodeInfoWithStorage[127.0.0.1:44722,DS-aef52287-b251-4b8b-873c-62ab7da7035f,DISK], DatanodeInfoWithStorage[127.0.0.1:39517,DS-8d50e57a-4a75-46fa-b1e2-8fb3b06d0a06,DISK], DatanodeInfoWithStorage[127.0.0.1:35455,DS-34bdcd06-e36b-453c-8344-6a7d0a45d2b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39208,DS-40812c78-c4fb-4c87-92cd-f053a1d05a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:39143,DS-85db0841-e46d-4404-88fe-68eb2734502d,DISK], DatanodeInfoWithStorage[127.0.0.1:36881,DS-b04e8fb7-f1bd-4a96-aab3-8ae20830a902,DISK], DatanodeInfoWithStorage[127.0.0.1:46855,DS-9957eedc-51ea-415f-a513-69e42c70f70d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.writes
component: hdfs:NameNode
v1: null
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-565030104-172.17.0.3-1596959926519:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45338,DS-35178b20-ca13-4872-a110-e2d26bef80cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34468,DS-2961edbe-8ccf-4de7-8ec3-43015ce5cb9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45147,DS-0e6fa5c9-5c02-4643-ab7b-7fc3f78c74f5,DISK], DatanodeInfoWithStorage[127.0.0.1:46247,DS-71841d89-0c43-453f-8659-bfc7fa904630,DISK], DatanodeInfoWithStorage[127.0.0.1:38052,DS-b79951f4-272a-445b-907f-85149118e936,DISK], DatanodeInfoWithStorage[127.0.0.1:33673,DS-76ac314b-3493-46a9-8428-c2f0ac75f943,DISK], DatanodeInfoWithStorage[127.0.0.1:41487,DS-7d163db1-5ee9-45de-99e8-f0e435f08562,DISK], DatanodeInfoWithStorage[127.0.0.1:41953,DS-465b41cb-3fe2-493d-bfbc-461be4be06d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-565030104-172.17.0.3-1596959926519:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45338,DS-35178b20-ca13-4872-a110-e2d26bef80cb,DISK], DatanodeInfoWithStorage[127.0.0.1:34468,DS-2961edbe-8ccf-4de7-8ec3-43015ce5cb9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45147,DS-0e6fa5c9-5c02-4643-ab7b-7fc3f78c74f5,DISK], DatanodeInfoWithStorage[127.0.0.1:46247,DS-71841d89-0c43-453f-8659-bfc7fa904630,DISK], DatanodeInfoWithStorage[127.0.0.1:38052,DS-b79951f4-272a-445b-907f-85149118e936,DISK], DatanodeInfoWithStorage[127.0.0.1:33673,DS-76ac314b-3493-46a9-8428-c2f0ac75f943,DISK], DatanodeInfoWithStorage[127.0.0.1:41487,DS-7d163db1-5ee9-45de-99e8-f0e435f08562,DISK], DatanodeInfoWithStorage[127.0.0.1:41953,DS-465b41cb-3fe2-493d-bfbc-461be4be06d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.writes
component: hdfs:NameNode
v1: null
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1851840324-172.17.0.3-1596959968007:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37353,DS-8dccd87c-64b3-440f-8821-438f3b8d9497,DISK], DatanodeInfoWithStorage[127.0.0.1:36344,DS-5b19958c-8512-45dc-b719-143b1bd39d14,DISK], DatanodeInfoWithStorage[127.0.0.1:44050,DS-dc5c24b0-eebb-46bb-96f3-e72082eaf895,DISK], DatanodeInfoWithStorage[127.0.0.1:38446,DS-cddce5fe-d6d6-42de-bada-753d0c495504,DISK], DatanodeInfoWithStorage[127.0.0.1:46368,DS-f91d5702-3984-4e7e-b856-f8ee3e4946c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40782,DS-ae9f396d-d76b-4a12-9ea4-60015c131098,DISK], DatanodeInfoWithStorage[127.0.0.1:41545,DS-f50e1952-cfdc-47bd-ab1a-2eb17c41b8eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33219,DS-d034d696-e9de-4618-bf31-b6c05a4ccfb1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1851840324-172.17.0.3-1596959968007:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37353,DS-8dccd87c-64b3-440f-8821-438f3b8d9497,DISK], DatanodeInfoWithStorage[127.0.0.1:36344,DS-5b19958c-8512-45dc-b719-143b1bd39d14,DISK], DatanodeInfoWithStorage[127.0.0.1:44050,DS-dc5c24b0-eebb-46bb-96f3-e72082eaf895,DISK], DatanodeInfoWithStorage[127.0.0.1:38446,DS-cddce5fe-d6d6-42de-bada-753d0c495504,DISK], DatanodeInfoWithStorage[127.0.0.1:46368,DS-f91d5702-3984-4e7e-b856-f8ee3e4946c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40782,DS-ae9f396d-d76b-4a12-9ea4-60015c131098,DISK], DatanodeInfoWithStorage[127.0.0.1:41545,DS-f50e1952-cfdc-47bd-ab1a-2eb17c41b8eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33219,DS-d034d696-e9de-4618-bf31-b6c05a4ccfb1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.writes
component: hdfs:NameNode
v1: null
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-309876388-172.17.0.3-1596960702844:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35141,DS-c3f5e52f-313d-4b36-b3bc-f152a5df6e6d,DISK], DatanodeInfoWithStorage[127.0.0.1:46604,DS-c98090b8-8c45-4f2a-912f-d7bd8ceb8099,DISK], DatanodeInfoWithStorage[127.0.0.1:40127,DS-15cb3d2d-273c-449d-a4ff-a756ff65c409,DISK], DatanodeInfoWithStorage[127.0.0.1:38164,DS-9cb173e1-9d54-4e87-817a-b4952e98911d,DISK], DatanodeInfoWithStorage[127.0.0.1:33945,DS-e237f3a5-fe29-4047-9cf8-827d0cbf0b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:39142,DS-ef3ff1ca-00b2-4f52-9cc6-2d6762354021,DISK], DatanodeInfoWithStorage[127.0.0.1:38091,DS-2502da22-c7f0-4f8a-a487-14e0e2fe20b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36860,DS-7698e2dc-02c8-40fd-9ba6-845d3af33d7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-309876388-172.17.0.3-1596960702844:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35141,DS-c3f5e52f-313d-4b36-b3bc-f152a5df6e6d,DISK], DatanodeInfoWithStorage[127.0.0.1:46604,DS-c98090b8-8c45-4f2a-912f-d7bd8ceb8099,DISK], DatanodeInfoWithStorage[127.0.0.1:40127,DS-15cb3d2d-273c-449d-a4ff-a756ff65c409,DISK], DatanodeInfoWithStorage[127.0.0.1:38164,DS-9cb173e1-9d54-4e87-817a-b4952e98911d,DISK], DatanodeInfoWithStorage[127.0.0.1:33945,DS-e237f3a5-fe29-4047-9cf8-827d0cbf0b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:39142,DS-ef3ff1ca-00b2-4f52-9cc6-2d6762354021,DISK], DatanodeInfoWithStorage[127.0.0.1:38091,DS-2502da22-c7f0-4f8a-a487-14e0e2fe20b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36860,DS-7698e2dc-02c8-40fd-9ba6-845d3af33d7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.writes
component: hdfs:NameNode
v1: null
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-624400269-172.17.0.3-1596960776728:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44288,DS-56de385b-8b7e-4ddf-8fec-699529536cf2,DISK], DatanodeInfoWithStorage[127.0.0.1:36051,DS-208140e5-e239-43ea-aea9-7d1d0454882e,DISK], DatanodeInfoWithStorage[127.0.0.1:33058,DS-c09eb0dc-abdc-415f-b1c7-77efbae64b16,DISK], DatanodeInfoWithStorage[127.0.0.1:40068,DS-cb910044-f088-4c20-b9b2-8b65924371cd,DISK], DatanodeInfoWithStorage[127.0.0.1:36227,DS-95ec7420-2fda-4b18-99a3-602fb3cbe188,DISK], DatanodeInfoWithStorage[127.0.0.1:34098,DS-02fb7a33-b1e0-4561-85e5-9f4c60f791ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43866,DS-c99274a9-516f-4deb-8a84-f33fb680879a,DISK], DatanodeInfoWithStorage[127.0.0.1:36094,DS-5f184ada-67fd-4b23-905b-eed303cadef7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-624400269-172.17.0.3-1596960776728:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44288,DS-56de385b-8b7e-4ddf-8fec-699529536cf2,DISK], DatanodeInfoWithStorage[127.0.0.1:36051,DS-208140e5-e239-43ea-aea9-7d1d0454882e,DISK], DatanodeInfoWithStorage[127.0.0.1:33058,DS-c09eb0dc-abdc-415f-b1c7-77efbae64b16,DISK], DatanodeInfoWithStorage[127.0.0.1:40068,DS-cb910044-f088-4c20-b9b2-8b65924371cd,DISK], DatanodeInfoWithStorage[127.0.0.1:36227,DS-95ec7420-2fda-4b18-99a3-602fb3cbe188,DISK], DatanodeInfoWithStorage[127.0.0.1:34098,DS-02fb7a33-b1e0-4561-85e5-9f4c60f791ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43866,DS-c99274a9-516f-4deb-8a84-f33fb680879a,DISK], DatanodeInfoWithStorage[127.0.0.1:36094,DS-5f184ada-67fd-4b23-905b-eed303cadef7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.writes
component: hdfs:NameNode
v1: null
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1723642107-172.17.0.3-1596961202376:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44515,DS-3332685b-1d67-4480-bace-191676b94423,DISK], DatanodeInfoWithStorage[127.0.0.1:35458,DS-d1f7f485-c127-442e-9f6c-7cdffb253514,DISK], DatanodeInfoWithStorage[127.0.0.1:35149,DS-0eb5763d-3af2-43ad-8983-f8d42204fc50,DISK], DatanodeInfoWithStorage[127.0.0.1:35883,DS-7ffcd3b1-32ae-4cf4-97c9-8c5bf6603950,DISK], DatanodeInfoWithStorage[127.0.0.1:45550,DS-c2b43305-de23-4f1a-8266-06f1b4d4b452,DISK], DatanodeInfoWithStorage[127.0.0.1:45869,DS-3702bbd1-7806-4a48-897c-24529c60126f,DISK], DatanodeInfoWithStorage[127.0.0.1:42553,DS-3bff788b-c9b1-48c9-bd1d-23a426c22240,DISK], DatanodeInfoWithStorage[127.0.0.1:44564,DS-3ba9bf58-d978-4bb7-be19-b01039a95b75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1723642107-172.17.0.3-1596961202376:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44515,DS-3332685b-1d67-4480-bace-191676b94423,DISK], DatanodeInfoWithStorage[127.0.0.1:35458,DS-d1f7f485-c127-442e-9f6c-7cdffb253514,DISK], DatanodeInfoWithStorage[127.0.0.1:35149,DS-0eb5763d-3af2-43ad-8983-f8d42204fc50,DISK], DatanodeInfoWithStorage[127.0.0.1:35883,DS-7ffcd3b1-32ae-4cf4-97c9-8c5bf6603950,DISK], DatanodeInfoWithStorage[127.0.0.1:45550,DS-c2b43305-de23-4f1a-8266-06f1b4d4b452,DISK], DatanodeInfoWithStorage[127.0.0.1:45869,DS-3702bbd1-7806-4a48-897c-24529c60126f,DISK], DatanodeInfoWithStorage[127.0.0.1:42553,DS-3bff788b-c9b1-48c9-bd1d-23a426c22240,DISK], DatanodeInfoWithStorage[127.0.0.1:44564,DS-3ba9bf58-d978-4bb7-be19-b01039a95b75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.writes
component: hdfs:NameNode
v1: null
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2081765793-172.17.0.3-1596962043839:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34235,DS-44d0c1df-0e9f-4fca-9c03-766462166f7c,DISK], DatanodeInfoWithStorage[127.0.0.1:36072,DS-3eda44d6-331c-4823-ac52-bc42fa2a4902,DISK], DatanodeInfoWithStorage[127.0.0.1:44604,DS-01a018fd-784f-4fcd-9436-143abab5f242,DISK], DatanodeInfoWithStorage[127.0.0.1:35307,DS-67585f82-a2d0-4639-91e5-d13b2ded13bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37134,DS-719b7802-b158-463d-8022-9e770166cf29,DISK], DatanodeInfoWithStorage[127.0.0.1:43684,DS-e171b12f-0c75-4b4e-9f19-6757ee4fa8bf,DISK], DatanodeInfoWithStorage[127.0.0.1:45445,DS-35919ecc-d3c5-4230-874d-3e4b2608c206,DISK], DatanodeInfoWithStorage[127.0.0.1:38773,DS-05c41da7-f211-47c2-b090-3a9e1ed6149f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2081765793-172.17.0.3-1596962043839:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34235,DS-44d0c1df-0e9f-4fca-9c03-766462166f7c,DISK], DatanodeInfoWithStorage[127.0.0.1:36072,DS-3eda44d6-331c-4823-ac52-bc42fa2a4902,DISK], DatanodeInfoWithStorage[127.0.0.1:44604,DS-01a018fd-784f-4fcd-9436-143abab5f242,DISK], DatanodeInfoWithStorage[127.0.0.1:35307,DS-67585f82-a2d0-4639-91e5-d13b2ded13bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37134,DS-719b7802-b158-463d-8022-9e770166cf29,DISK], DatanodeInfoWithStorage[127.0.0.1:43684,DS-e171b12f-0c75-4b4e-9f19-6757ee4fa8bf,DISK], DatanodeInfoWithStorage[127.0.0.1:45445,DS-35919ecc-d3c5-4230-874d-3e4b2608c206,DISK], DatanodeInfoWithStorage[127.0.0.1:38773,DS-05c41da7-f211-47c2-b090-3a9e1ed6149f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5367
