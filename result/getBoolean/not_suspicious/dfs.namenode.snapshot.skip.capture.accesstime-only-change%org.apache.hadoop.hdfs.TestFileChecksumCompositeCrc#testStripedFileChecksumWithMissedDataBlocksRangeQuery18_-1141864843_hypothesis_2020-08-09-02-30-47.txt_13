reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-724415206-172.17.0.13-1596940920030:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41722,DS-163f3b92-3265-4a94-a55a-e08c54a50032,DISK], DatanodeInfoWithStorage[127.0.0.1:41493,DS-cef04006-2dbb-4406-adf9-37d59321ae2d,DISK], DatanodeInfoWithStorage[127.0.0.1:45801,DS-c5bbfa3c-7077-4269-b1fe-ec203f9588b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33068,DS-983477ab-ee0e-44d4-ae8a-0bf5a224dda4,DISK], DatanodeInfoWithStorage[127.0.0.1:36314,DS-4a24ec5d-4002-438a-bd3e-573059e1030c,DISK], DatanodeInfoWithStorage[127.0.0.1:43029,DS-d99d97cd-82ad-4c83-a86f-7741f407a73e,DISK], DatanodeInfoWithStorage[127.0.0.1:46046,DS-436fd38c-e63a-4fc0-b898-ed10f7f78687,DISK], DatanodeInfoWithStorage[127.0.0.1:38372,DS-99cc655f-06c0-447e-a817-077baf63e055,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-724415206-172.17.0.13-1596940920030:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41722,DS-163f3b92-3265-4a94-a55a-e08c54a50032,DISK], DatanodeInfoWithStorage[127.0.0.1:41493,DS-cef04006-2dbb-4406-adf9-37d59321ae2d,DISK], DatanodeInfoWithStorage[127.0.0.1:45801,DS-c5bbfa3c-7077-4269-b1fe-ec203f9588b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33068,DS-983477ab-ee0e-44d4-ae8a-0bf5a224dda4,DISK], DatanodeInfoWithStorage[127.0.0.1:36314,DS-4a24ec5d-4002-438a-bd3e-573059e1030c,DISK], DatanodeInfoWithStorage[127.0.0.1:43029,DS-d99d97cd-82ad-4c83-a86f-7741f407a73e,DISK], DatanodeInfoWithStorage[127.0.0.1:46046,DS-436fd38c-e63a-4fc0-b898-ed10f7f78687,DISK], DatanodeInfoWithStorage[127.0.0.1:38372,DS-99cc655f-06c0-447e-a817-077baf63e055,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-682282025-172.17.0.13-1596940955773:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36964,DS-c7c9798e-468d-4b5e-980e-be9f4c9abf90,DISK], DatanodeInfoWithStorage[127.0.0.1:34102,DS-53aa0652-8980-4c0c-b4ea-5e36c6bc30c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36000,DS-96a212c5-6f4e-4490-a2b0-30cb857780c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35228,DS-3d1a53f9-9585-4bc3-a11e-c08d9dc9b718,DISK], DatanodeInfoWithStorage[127.0.0.1:38883,DS-b6a9bee1-9696-4266-b56b-1157a3ecee38,DISK], DatanodeInfoWithStorage[127.0.0.1:43666,DS-3edbec33-63a2-4328-88c0-12179e479487,DISK], DatanodeInfoWithStorage[127.0.0.1:41704,DS-286f6adf-b027-4218-af61-52ebe8b83bf2,DISK], DatanodeInfoWithStorage[127.0.0.1:46506,DS-dc0266b6-b154-4588-b1b0-abfa6fa77f94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-682282025-172.17.0.13-1596940955773:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36964,DS-c7c9798e-468d-4b5e-980e-be9f4c9abf90,DISK], DatanodeInfoWithStorage[127.0.0.1:34102,DS-53aa0652-8980-4c0c-b4ea-5e36c6bc30c0,DISK], DatanodeInfoWithStorage[127.0.0.1:36000,DS-96a212c5-6f4e-4490-a2b0-30cb857780c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35228,DS-3d1a53f9-9585-4bc3-a11e-c08d9dc9b718,DISK], DatanodeInfoWithStorage[127.0.0.1:38883,DS-b6a9bee1-9696-4266-b56b-1157a3ecee38,DISK], DatanodeInfoWithStorage[127.0.0.1:43666,DS-3edbec33-63a2-4328-88c0-12179e479487,DISK], DatanodeInfoWithStorage[127.0.0.1:41704,DS-286f6adf-b027-4218-af61-52ebe8b83bf2,DISK], DatanodeInfoWithStorage[127.0.0.1:46506,DS-dc0266b6-b154-4588-b1b0-abfa6fa77f94,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1238393616-172.17.0.13-1596940992443:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38229,DS-b0dd9f1e-a8d4-4c8a-b338-a36fbf8939ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45483,DS-719a2e04-755c-4a88-9047-71b52b993c64,DISK], DatanodeInfoWithStorage[127.0.0.1:34271,DS-4a63e61d-8539-4771-b4d8-de3c32bb380f,DISK], DatanodeInfoWithStorage[127.0.0.1:35413,DS-8c5a8f09-53f7-4a40-9417-359962b0c5ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34873,DS-4f1be1bc-edba-455b-8c95-d6d004ab21c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42460,DS-b45f7e63-5980-4ecf-af68-8a1f7e6c73c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40375,DS-3e3ae49e-fcc9-40b9-b025-c0fabe484761,DISK], DatanodeInfoWithStorage[127.0.0.1:37194,DS-39b28be7-5f9b-42c7-9fb1-32aa817ef8ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1238393616-172.17.0.13-1596940992443:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38229,DS-b0dd9f1e-a8d4-4c8a-b338-a36fbf8939ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45483,DS-719a2e04-755c-4a88-9047-71b52b993c64,DISK], DatanodeInfoWithStorage[127.0.0.1:34271,DS-4a63e61d-8539-4771-b4d8-de3c32bb380f,DISK], DatanodeInfoWithStorage[127.0.0.1:35413,DS-8c5a8f09-53f7-4a40-9417-359962b0c5ab,DISK], DatanodeInfoWithStorage[127.0.0.1:34873,DS-4f1be1bc-edba-455b-8c95-d6d004ab21c3,DISK], DatanodeInfoWithStorage[127.0.0.1:42460,DS-b45f7e63-5980-4ecf-af68-8a1f7e6c73c1,DISK], DatanodeInfoWithStorage[127.0.0.1:40375,DS-3e3ae49e-fcc9-40b9-b025-c0fabe484761,DISK], DatanodeInfoWithStorage[127.0.0.1:37194,DS-39b28be7-5f9b-42c7-9fb1-32aa817ef8ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-255421888-172.17.0.13-1596941314611:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41422,DS-715f063c-e282-49fc-bff8-8d33000977e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41865,DS-dc215985-6435-42d3-a9f6-e38702d00c84,DISK], DatanodeInfoWithStorage[127.0.0.1:37163,DS-70300a43-809c-4bce-8372-9fc35401876c,DISK], DatanodeInfoWithStorage[127.0.0.1:37059,DS-18b010e8-11b0-4b72-be3b-7fd15afa21e3,DISK], DatanodeInfoWithStorage[127.0.0.1:32849,DS-0316e9c3-dc6c-45b4-94a5-9b93dd8b6eb6,DISK], DatanodeInfoWithStorage[127.0.0.1:44618,DS-a223125e-6767-4a2c-99b5-6ac7aa5301c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45359,DS-3c7d6e10-b46e-4fed-9340-e12d38228edb,DISK], DatanodeInfoWithStorage[127.0.0.1:41194,DS-53f57e22-8f5c-4a6a-956d-c0bd592d3692,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-255421888-172.17.0.13-1596941314611:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41422,DS-715f063c-e282-49fc-bff8-8d33000977e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41865,DS-dc215985-6435-42d3-a9f6-e38702d00c84,DISK], DatanodeInfoWithStorage[127.0.0.1:37163,DS-70300a43-809c-4bce-8372-9fc35401876c,DISK], DatanodeInfoWithStorage[127.0.0.1:37059,DS-18b010e8-11b0-4b72-be3b-7fd15afa21e3,DISK], DatanodeInfoWithStorage[127.0.0.1:32849,DS-0316e9c3-dc6c-45b4-94a5-9b93dd8b6eb6,DISK], DatanodeInfoWithStorage[127.0.0.1:44618,DS-a223125e-6767-4a2c-99b5-6ac7aa5301c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45359,DS-3c7d6e10-b46e-4fed-9340-e12d38228edb,DISK], DatanodeInfoWithStorage[127.0.0.1:41194,DS-53f57e22-8f5c-4a6a-956d-c0bd592d3692,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1261628124-172.17.0.13-1596941691141:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43120,DS-e8c5db77-31ac-4aee-b407-18e1bc730d48,DISK], DatanodeInfoWithStorage[127.0.0.1:45936,DS-fd54bbe1-e9db-478b-b622-3e35a4a5608c,DISK], DatanodeInfoWithStorage[127.0.0.1:45455,DS-439084fc-7d36-4fa3-afdd-f90c8f042be2,DISK], DatanodeInfoWithStorage[127.0.0.1:43361,DS-9a5fca50-dddb-42f9-8884-6ae409573622,DISK], DatanodeInfoWithStorage[127.0.0.1:45372,DS-2c569a7a-c590-4fa7-9628-6f33e6c75ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:33052,DS-c003e859-64ca-46e1-9d40-b5fe7967a17f,DISK], DatanodeInfoWithStorage[127.0.0.1:45007,DS-1f96a0ac-2419-459d-9f64-d9afc746fc69,DISK], DatanodeInfoWithStorage[127.0.0.1:36554,DS-735e4ee1-9de4-433a-aad5-39347cdf1517,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1261628124-172.17.0.13-1596941691141:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43120,DS-e8c5db77-31ac-4aee-b407-18e1bc730d48,DISK], DatanodeInfoWithStorage[127.0.0.1:45936,DS-fd54bbe1-e9db-478b-b622-3e35a4a5608c,DISK], DatanodeInfoWithStorage[127.0.0.1:45455,DS-439084fc-7d36-4fa3-afdd-f90c8f042be2,DISK], DatanodeInfoWithStorage[127.0.0.1:43361,DS-9a5fca50-dddb-42f9-8884-6ae409573622,DISK], DatanodeInfoWithStorage[127.0.0.1:45372,DS-2c569a7a-c590-4fa7-9628-6f33e6c75ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:33052,DS-c003e859-64ca-46e1-9d40-b5fe7967a17f,DISK], DatanodeInfoWithStorage[127.0.0.1:45007,DS-1f96a0ac-2419-459d-9f64-d9afc746fc69,DISK], DatanodeInfoWithStorage[127.0.0.1:36554,DS-735e4ee1-9de4-433a-aad5-39347cdf1517,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-251678120-172.17.0.13-1596941727533:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44503,DS-c12fa2a2-6ae3-4fdb-8363-03ed61b6e7c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43133,DS-41a2dbdb-28a5-41c2-9eae-483b6874781f,DISK], DatanodeInfoWithStorage[127.0.0.1:44792,DS-b5412c1c-e48c-44bd-848d-c6d7b6e81547,DISK], DatanodeInfoWithStorage[127.0.0.1:39133,DS-61fc6fef-9316-4a16-b8bb-0aa6af692646,DISK], DatanodeInfoWithStorage[127.0.0.1:32814,DS-16254063-84c9-4f82-b1f0-f2cd1ef35f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:33960,DS-237a08f2-22db-464e-9ec1-d1087cc67b3d,DISK], DatanodeInfoWithStorage[127.0.0.1:37414,DS-6b751533-da7f-474a-9a32-feb25715feb5,DISK], DatanodeInfoWithStorage[127.0.0.1:42691,DS-7dfb89f5-6224-413c-a7df-6e7f8ff706e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-251678120-172.17.0.13-1596941727533:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44503,DS-c12fa2a2-6ae3-4fdb-8363-03ed61b6e7c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43133,DS-41a2dbdb-28a5-41c2-9eae-483b6874781f,DISK], DatanodeInfoWithStorage[127.0.0.1:44792,DS-b5412c1c-e48c-44bd-848d-c6d7b6e81547,DISK], DatanodeInfoWithStorage[127.0.0.1:39133,DS-61fc6fef-9316-4a16-b8bb-0aa6af692646,DISK], DatanodeInfoWithStorage[127.0.0.1:32814,DS-16254063-84c9-4f82-b1f0-f2cd1ef35f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:33960,DS-237a08f2-22db-464e-9ec1-d1087cc67b3d,DISK], DatanodeInfoWithStorage[127.0.0.1:37414,DS-6b751533-da7f-474a-9a32-feb25715feb5,DISK], DatanodeInfoWithStorage[127.0.0.1:42691,DS-7dfb89f5-6224-413c-a7df-6e7f8ff706e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1111806096-172.17.0.13-1596941971527:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45614,DS-bd831a7d-cb17-4ccc-b81c-f9d5d7e2efe1,DISK], DatanodeInfoWithStorage[127.0.0.1:44948,DS-d9d29a80-07b8-4c86-92ec-fa98cd3565ad,DISK], DatanodeInfoWithStorage[127.0.0.1:43526,DS-efeb01f1-583a-43fc-9956-7b96ec4f2b94,DISK], DatanodeInfoWithStorage[127.0.0.1:40117,DS-a44e680c-1664-442a-9c57-4b1ee1951766,DISK], DatanodeInfoWithStorage[127.0.0.1:34361,DS-fa4da6b1-86d8-4ee2-8d0f-0303b4781bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:37856,DS-d6238954-4954-45ed-8a81-7bbda2d0ae19,DISK], DatanodeInfoWithStorage[127.0.0.1:39978,DS-354ac00b-9049-4f54-b139-8661d696ec84,DISK], DatanodeInfoWithStorage[127.0.0.1:35204,DS-87c164b0-014f-4e0f-8bd5-50dfd8b62ffe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1111806096-172.17.0.13-1596941971527:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45614,DS-bd831a7d-cb17-4ccc-b81c-f9d5d7e2efe1,DISK], DatanodeInfoWithStorage[127.0.0.1:44948,DS-d9d29a80-07b8-4c86-92ec-fa98cd3565ad,DISK], DatanodeInfoWithStorage[127.0.0.1:43526,DS-efeb01f1-583a-43fc-9956-7b96ec4f2b94,DISK], DatanodeInfoWithStorage[127.0.0.1:40117,DS-a44e680c-1664-442a-9c57-4b1ee1951766,DISK], DatanodeInfoWithStorage[127.0.0.1:34361,DS-fa4da6b1-86d8-4ee2-8d0f-0303b4781bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:37856,DS-d6238954-4954-45ed-8a81-7bbda2d0ae19,DISK], DatanodeInfoWithStorage[127.0.0.1:39978,DS-354ac00b-9049-4f54-b139-8661d696ec84,DISK], DatanodeInfoWithStorage[127.0.0.1:35204,DS-87c164b0-014f-4e0f-8bd5-50dfd8b62ffe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-656768252-172.17.0.13-1596942614499:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45770,DS-10776a9d-8628-4b1e-83ad-0f0ae024f7b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40021,DS-d19cac34-11a6-434c-9ccc-72761c5e286d,DISK], DatanodeInfoWithStorage[127.0.0.1:37172,DS-e43c5ba1-06ae-4795-b097-d879e6b6ccec,DISK], DatanodeInfoWithStorage[127.0.0.1:34466,DS-5959433f-129e-4d73-8781-a537569a3e83,DISK], DatanodeInfoWithStorage[127.0.0.1:46345,DS-1eff72f9-5fb9-4b7b-9edd-c7d81d7e701f,DISK], DatanodeInfoWithStorage[127.0.0.1:36504,DS-d4a0ba3d-2f86-4257-86e7-10578e586a76,DISK], DatanodeInfoWithStorage[127.0.0.1:42032,DS-8b78668e-bf3a-477a-a21f-37ccfe24b49d,DISK], DatanodeInfoWithStorage[127.0.0.1:35232,DS-539b6cfc-faac-4df1-a184-38abe76eedd4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-656768252-172.17.0.13-1596942614499:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45770,DS-10776a9d-8628-4b1e-83ad-0f0ae024f7b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40021,DS-d19cac34-11a6-434c-9ccc-72761c5e286d,DISK], DatanodeInfoWithStorage[127.0.0.1:37172,DS-e43c5ba1-06ae-4795-b097-d879e6b6ccec,DISK], DatanodeInfoWithStorage[127.0.0.1:34466,DS-5959433f-129e-4d73-8781-a537569a3e83,DISK], DatanodeInfoWithStorage[127.0.0.1:46345,DS-1eff72f9-5fb9-4b7b-9edd-c7d81d7e701f,DISK], DatanodeInfoWithStorage[127.0.0.1:36504,DS-d4a0ba3d-2f86-4257-86e7-10578e586a76,DISK], DatanodeInfoWithStorage[127.0.0.1:42032,DS-8b78668e-bf3a-477a-a21f-37ccfe24b49d,DISK], DatanodeInfoWithStorage[127.0.0.1:35232,DS-539b6cfc-faac-4df1-a184-38abe76eedd4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-583681668-172.17.0.13-1596942842803:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37716,DS-5f19bcd9-32a1-45a2-8e72-2e8190343e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:33814,DS-4ae2837a-9024-4d0d-8c63-14c6b035217f,DISK], DatanodeInfoWithStorage[127.0.0.1:39158,DS-2619196e-b439-4c40-97a8-e31b44622e63,DISK], DatanodeInfoWithStorage[127.0.0.1:45844,DS-8c812883-a78e-45ae-81c5-35c122b99012,DISK], DatanodeInfoWithStorage[127.0.0.1:43654,DS-e6f82e6a-1557-4b87-8d5f-d1f59c3242d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36669,DS-dcb32c6a-0647-44f0-86b9-d75fa899bcdd,DISK], DatanodeInfoWithStorage[127.0.0.1:44254,DS-be540968-4256-4f13-a531-e33573a8e978,DISK], DatanodeInfoWithStorage[127.0.0.1:44276,DS-9f012796-ed40-40d6-bb8f-00c72fcf4df2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-583681668-172.17.0.13-1596942842803:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37716,DS-5f19bcd9-32a1-45a2-8e72-2e8190343e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:33814,DS-4ae2837a-9024-4d0d-8c63-14c6b035217f,DISK], DatanodeInfoWithStorage[127.0.0.1:39158,DS-2619196e-b439-4c40-97a8-e31b44622e63,DISK], DatanodeInfoWithStorage[127.0.0.1:45844,DS-8c812883-a78e-45ae-81c5-35c122b99012,DISK], DatanodeInfoWithStorage[127.0.0.1:43654,DS-e6f82e6a-1557-4b87-8d5f-d1f59c3242d9,DISK], DatanodeInfoWithStorage[127.0.0.1:36669,DS-dcb32c6a-0647-44f0-86b9-d75fa899bcdd,DISK], DatanodeInfoWithStorage[127.0.0.1:44254,DS-be540968-4256-4f13-a531-e33573a8e978,DISK], DatanodeInfoWithStorage[127.0.0.1:44276,DS-9f012796-ed40-40d6-bb8f-00c72fcf4df2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-370037663-172.17.0.13-1596942970618:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39657,DS-049a37df-95c3-411f-8a48-b016ce0b84cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40610,DS-def1d5fa-c80f-4c9e-a687-746f27fe3bd2,DISK], DatanodeInfoWithStorage[127.0.0.1:39322,DS-36292c4c-abf9-49ac-a172-bd9886ad8bf7,DISK], DatanodeInfoWithStorage[127.0.0.1:45481,DS-1870cfcd-c3dd-4404-8020-cb37cd837a27,DISK], DatanodeInfoWithStorage[127.0.0.1:32903,DS-5e645aa7-c149-4a6d-a905-e0e90f6482b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35303,DS-3ed4eae1-f9fe-4e09-ba4c-6f1f75268ac1,DISK], DatanodeInfoWithStorage[127.0.0.1:45698,DS-087493d7-16e2-4dee-be53-1dfedad4352d,DISK], DatanodeInfoWithStorage[127.0.0.1:46775,DS-9b7ba399-d7c0-4fad-a4fa-c9274e65052b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-370037663-172.17.0.13-1596942970618:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39657,DS-049a37df-95c3-411f-8a48-b016ce0b84cd,DISK], DatanodeInfoWithStorage[127.0.0.1:40610,DS-def1d5fa-c80f-4c9e-a687-746f27fe3bd2,DISK], DatanodeInfoWithStorage[127.0.0.1:39322,DS-36292c4c-abf9-49ac-a172-bd9886ad8bf7,DISK], DatanodeInfoWithStorage[127.0.0.1:45481,DS-1870cfcd-c3dd-4404-8020-cb37cd837a27,DISK], DatanodeInfoWithStorage[127.0.0.1:32903,DS-5e645aa7-c149-4a6d-a905-e0e90f6482b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35303,DS-3ed4eae1-f9fe-4e09-ba4c-6f1f75268ac1,DISK], DatanodeInfoWithStorage[127.0.0.1:45698,DS-087493d7-16e2-4dee-be53-1dfedad4352d,DISK], DatanodeInfoWithStorage[127.0.0.1:46775,DS-9b7ba399-d7c0-4fad-a4fa-c9274e65052b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1658246353-172.17.0.13-1596943082234:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35317,DS-5ef90d77-1c23-4e85-a25f-c4c8e06b61aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45945,DS-130d071b-461f-4a10-9bf1-36f74c58dd57,DISK], DatanodeInfoWithStorage[127.0.0.1:44306,DS-b7da440e-277f-44da-83cd-0e7531b15ca6,DISK], DatanodeInfoWithStorage[127.0.0.1:42026,DS-4d7e690f-33af-4428-be79-031a49b2302c,DISK], DatanodeInfoWithStorage[127.0.0.1:44040,DS-f7952282-eaa9-4384-a591-21213e45fce6,DISK], DatanodeInfoWithStorage[127.0.0.1:39587,DS-0770a9f7-077b-4429-948d-cb742eb589b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39313,DS-a3d0926f-425a-43ab-a1eb-e5ee2b609960,DISK], DatanodeInfoWithStorage[127.0.0.1:36681,DS-1b720a4e-d55c-4d04-8840-9d8d39155ca2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1658246353-172.17.0.13-1596943082234:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35317,DS-5ef90d77-1c23-4e85-a25f-c4c8e06b61aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45945,DS-130d071b-461f-4a10-9bf1-36f74c58dd57,DISK], DatanodeInfoWithStorage[127.0.0.1:44306,DS-b7da440e-277f-44da-83cd-0e7531b15ca6,DISK], DatanodeInfoWithStorage[127.0.0.1:42026,DS-4d7e690f-33af-4428-be79-031a49b2302c,DISK], DatanodeInfoWithStorage[127.0.0.1:44040,DS-f7952282-eaa9-4384-a591-21213e45fce6,DISK], DatanodeInfoWithStorage[127.0.0.1:39587,DS-0770a9f7-077b-4429-948d-cb742eb589b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39313,DS-a3d0926f-425a-43ab-a1eb-e5ee2b609960,DISK], DatanodeInfoWithStorage[127.0.0.1:36681,DS-1b720a4e-d55c-4d04-8840-9d8d39155ca2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1754973127-172.17.0.13-1596943269547:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40195,DS-19c7e458-4c78-41f4-b905-4ffa4c868df1,DISK], DatanodeInfoWithStorage[127.0.0.1:37908,DS-06209e20-3f21-42f7-bc96-0652a44da6cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46145,DS-26024464-2887-4df8-9ace-fbc018d7f27f,DISK], DatanodeInfoWithStorage[127.0.0.1:43067,DS-7862ecf9-b4a8-47c9-8659-ad699348a974,DISK], DatanodeInfoWithStorage[127.0.0.1:36829,DS-caa4c357-bafa-45ca-b0fe-a9254796e0ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37877,DS-9627d52c-ab2d-4521-bc65-8fcf020a8642,DISK], DatanodeInfoWithStorage[127.0.0.1:35831,DS-12d74fb3-bec6-433a-94a3-1e184dd856e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38957,DS-85fe1c98-ed2f-4616-8d9f-dd25c09a1830,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1754973127-172.17.0.13-1596943269547:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40195,DS-19c7e458-4c78-41f4-b905-4ffa4c868df1,DISK], DatanodeInfoWithStorage[127.0.0.1:37908,DS-06209e20-3f21-42f7-bc96-0652a44da6cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46145,DS-26024464-2887-4df8-9ace-fbc018d7f27f,DISK], DatanodeInfoWithStorage[127.0.0.1:43067,DS-7862ecf9-b4a8-47c9-8659-ad699348a974,DISK], DatanodeInfoWithStorage[127.0.0.1:36829,DS-caa4c357-bafa-45ca-b0fe-a9254796e0ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37877,DS-9627d52c-ab2d-4521-bc65-8fcf020a8642,DISK], DatanodeInfoWithStorage[127.0.0.1:35831,DS-12d74fb3-bec6-433a-94a3-1e184dd856e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38957,DS-85fe1c98-ed2f-4616-8d9f-dd25c09a1830,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-922358088-172.17.0.13-1596943380375:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36414,DS-a87fad5b-e199-415b-bef9-d15c0aaf2896,DISK], DatanodeInfoWithStorage[127.0.0.1:44736,DS-f8536ca4-f51f-435d-a762-938920e5a6c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35604,DS-482c9466-7dbd-4bf0-a854-a4371b1c9250,DISK], DatanodeInfoWithStorage[127.0.0.1:41074,DS-4197c0d4-653e-4a58-8ec6-f6c6712e76e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40157,DS-15ad3ecd-e3a8-4ada-99ae-a5a58ea629aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38445,DS-3bda9b06-0031-48d2-9ee7-c91d0e8f665c,DISK], DatanodeInfoWithStorage[127.0.0.1:42412,DS-7a32f681-e59a-418d-a0be-c26d7af0b26a,DISK], DatanodeInfoWithStorage[127.0.0.1:40612,DS-95989271-2b74-4e5c-b8d4-cf02b90819d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-922358088-172.17.0.13-1596943380375:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36414,DS-a87fad5b-e199-415b-bef9-d15c0aaf2896,DISK], DatanodeInfoWithStorage[127.0.0.1:44736,DS-f8536ca4-f51f-435d-a762-938920e5a6c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35604,DS-482c9466-7dbd-4bf0-a854-a4371b1c9250,DISK], DatanodeInfoWithStorage[127.0.0.1:41074,DS-4197c0d4-653e-4a58-8ec6-f6c6712e76e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40157,DS-15ad3ecd-e3a8-4ada-99ae-a5a58ea629aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38445,DS-3bda9b06-0031-48d2-9ee7-c91d0e8f665c,DISK], DatanodeInfoWithStorage[127.0.0.1:42412,DS-7a32f681-e59a-418d-a0be-c26d7af0b26a,DISK], DatanodeInfoWithStorage[127.0.0.1:40612,DS-95989271-2b74-4e5c-b8d4-cf02b90819d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2146755553-172.17.0.13-1596943510072:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37365,DS-ad3526e0-6cfa-42c7-b449-788e1cbae88e,DISK], DatanodeInfoWithStorage[127.0.0.1:32972,DS-b3bda632-96a2-45dc-ab19-d26362eb00f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37288,DS-53aec2f2-a573-42c2-819c-f9c852b1eda6,DISK], DatanodeInfoWithStorage[127.0.0.1:44920,DS-85bcf6f0-33fb-42a4-be69-4a6bc1a226f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44277,DS-c14823c3-2b56-4d5d-a43f-afa56f61e5a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46219,DS-b9386ab0-167f-40f9-8ae6-8905d53ba20d,DISK], DatanodeInfoWithStorage[127.0.0.1:46796,DS-93b5954b-2ec4-4b74-be02-b36a455f1265,DISK], DatanodeInfoWithStorage[127.0.0.1:45436,DS-3146ab2c-4dd0-4089-9c31-b55db6be2849,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2146755553-172.17.0.13-1596943510072:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37365,DS-ad3526e0-6cfa-42c7-b449-788e1cbae88e,DISK], DatanodeInfoWithStorage[127.0.0.1:32972,DS-b3bda632-96a2-45dc-ab19-d26362eb00f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37288,DS-53aec2f2-a573-42c2-819c-f9c852b1eda6,DISK], DatanodeInfoWithStorage[127.0.0.1:44920,DS-85bcf6f0-33fb-42a4-be69-4a6bc1a226f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44277,DS-c14823c3-2b56-4d5d-a43f-afa56f61e5a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46219,DS-b9386ab0-167f-40f9-8ae6-8905d53ba20d,DISK], DatanodeInfoWithStorage[127.0.0.1:46796,DS-93b5954b-2ec4-4b74-be02-b36a455f1265,DISK], DatanodeInfoWithStorage[127.0.0.1:45436,DS-3146ab2c-4dd0-4089-9c31-b55db6be2849,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1237566519-172.17.0.13-1596944080548:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40001,DS-fd3ddc75-8542-4df7-b19a-910801c64bba,DISK], DatanodeInfoWithStorage[127.0.0.1:36942,DS-74069970-ea4c-401e-a3da-175f506da491,DISK], DatanodeInfoWithStorage[127.0.0.1:42958,DS-c443e318-54c3-40bb-848a-f9ea00987077,DISK], DatanodeInfoWithStorage[127.0.0.1:43472,DS-323537db-6031-4c56-b09b-fa6f4ef72a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:37613,DS-8f35e567-73e0-4351-811f-e8154e01ddb0,DISK], DatanodeInfoWithStorage[127.0.0.1:39251,DS-b25b130a-70a9-455b-9059-8267fef2a0f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44237,DS-1d9b6a79-6e7a-447c-b2c4-09276650ae43,DISK], DatanodeInfoWithStorage[127.0.0.1:36810,DS-f4e3ecac-851d-41d2-8fc0-75eed693ab75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1237566519-172.17.0.13-1596944080548:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40001,DS-fd3ddc75-8542-4df7-b19a-910801c64bba,DISK], DatanodeInfoWithStorage[127.0.0.1:36942,DS-74069970-ea4c-401e-a3da-175f506da491,DISK], DatanodeInfoWithStorage[127.0.0.1:42958,DS-c443e318-54c3-40bb-848a-f9ea00987077,DISK], DatanodeInfoWithStorage[127.0.0.1:43472,DS-323537db-6031-4c56-b09b-fa6f4ef72a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:37613,DS-8f35e567-73e0-4351-811f-e8154e01ddb0,DISK], DatanodeInfoWithStorage[127.0.0.1:39251,DS-b25b130a-70a9-455b-9059-8267fef2a0f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44237,DS-1d9b6a79-6e7a-447c-b2c4-09276650ae43,DISK], DatanodeInfoWithStorage[127.0.0.1:36810,DS-f4e3ecac-851d-41d2-8fc0-75eed693ab75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2042399751-172.17.0.13-1596944346650:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37567,DS-8de585ca-df87-4fd1-bc7d-479f919c8242,DISK], DatanodeInfoWithStorage[127.0.0.1:44369,DS-eb335ab1-6f59-4a90-8954-f03e953cee20,DISK], DatanodeInfoWithStorage[127.0.0.1:45835,DS-caa0b097-4c1b-4217-8dba-297f5824d0ce,DISK], DatanodeInfoWithStorage[127.0.0.1:37669,DS-064b53fa-e82b-4b1a-9228-32ca94c959b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38355,DS-42671f99-5e0b-4cb9-8cd1-c30bcca7e3c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33710,DS-3c899306-ac54-4075-bd4f-f4a061dbb256,DISK], DatanodeInfoWithStorage[127.0.0.1:38961,DS-080db992-c411-4e3a-ac35-44889fe78913,DISK], DatanodeInfoWithStorage[127.0.0.1:34977,DS-85f048b1-f10e-4590-8770-31881851529f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2042399751-172.17.0.13-1596944346650:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37567,DS-8de585ca-df87-4fd1-bc7d-479f919c8242,DISK], DatanodeInfoWithStorage[127.0.0.1:44369,DS-eb335ab1-6f59-4a90-8954-f03e953cee20,DISK], DatanodeInfoWithStorage[127.0.0.1:45835,DS-caa0b097-4c1b-4217-8dba-297f5824d0ce,DISK], DatanodeInfoWithStorage[127.0.0.1:37669,DS-064b53fa-e82b-4b1a-9228-32ca94c959b2,DISK], DatanodeInfoWithStorage[127.0.0.1:38355,DS-42671f99-5e0b-4cb9-8cd1-c30bcca7e3c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33710,DS-3c899306-ac54-4075-bd4f-f4a061dbb256,DISK], DatanodeInfoWithStorage[127.0.0.1:38961,DS-080db992-c411-4e3a-ac35-44889fe78913,DISK], DatanodeInfoWithStorage[127.0.0.1:34977,DS-85f048b1-f10e-4590-8770-31881851529f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-25065151-172.17.0.13-1596945047516:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46807,DS-d7be651d-dc89-4595-85c6-8da58c0b25ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34727,DS-bd24dd58-af7a-40a8-a9b9-24e590e90555,DISK], DatanodeInfoWithStorage[127.0.0.1:40958,DS-e566bbbd-afa0-454e-9289-aae3f0b0cfbc,DISK], DatanodeInfoWithStorage[127.0.0.1:33483,DS-05672ddb-b994-415a-87bf-93aeb6c41090,DISK], DatanodeInfoWithStorage[127.0.0.1:39226,DS-efa4bf51-b080-4d89-bd7b-8b23d3c1df71,DISK], DatanodeInfoWithStorage[127.0.0.1:37196,DS-eb03224d-798a-4f67-b35c-fcac1848c33a,DISK], DatanodeInfoWithStorage[127.0.0.1:38174,DS-ee87677b-229b-4ce7-9003-98eeaab0471c,DISK], DatanodeInfoWithStorage[127.0.0.1:42745,DS-f6ab8585-cfec-4336-9f25-b1873a81bebe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-25065151-172.17.0.13-1596945047516:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46807,DS-d7be651d-dc89-4595-85c6-8da58c0b25ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34727,DS-bd24dd58-af7a-40a8-a9b9-24e590e90555,DISK], DatanodeInfoWithStorage[127.0.0.1:40958,DS-e566bbbd-afa0-454e-9289-aae3f0b0cfbc,DISK], DatanodeInfoWithStorage[127.0.0.1:33483,DS-05672ddb-b994-415a-87bf-93aeb6c41090,DISK], DatanodeInfoWithStorage[127.0.0.1:39226,DS-efa4bf51-b080-4d89-bd7b-8b23d3c1df71,DISK], DatanodeInfoWithStorage[127.0.0.1:37196,DS-eb03224d-798a-4f67-b35c-fcac1848c33a,DISK], DatanodeInfoWithStorage[127.0.0.1:38174,DS-ee87677b-229b-4ce7-9003-98eeaab0471c,DISK], DatanodeInfoWithStorage[127.0.0.1:42745,DS-f6ab8585-cfec-4336-9f25-b1873a81bebe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1455970645-172.17.0.13-1596945082199:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34801,DS-bbba6083-8681-4c95-b592-0efc58ce3f7c,DISK], DatanodeInfoWithStorage[127.0.0.1:45943,DS-bae7c690-6ad9-4d13-ad67-b02e0931c803,DISK], DatanodeInfoWithStorage[127.0.0.1:45902,DS-87b9666d-4d5f-4431-bfd7-609abcb1c6e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45773,DS-61b27a8b-1748-4bec-975b-e880c3bc82b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33718,DS-8e26e510-8ef4-414f-a66b-8e48b43aad3a,DISK], DatanodeInfoWithStorage[127.0.0.1:35549,DS-cb69e699-e007-4367-b406-0f50c2a3b51a,DISK], DatanodeInfoWithStorage[127.0.0.1:46858,DS-511879f8-6e8e-4afb-b59e-4e715e80ce10,DISK], DatanodeInfoWithStorage[127.0.0.1:45797,DS-7329088e-04f1-4172-ac04-3707513f944c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1455970645-172.17.0.13-1596945082199:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34801,DS-bbba6083-8681-4c95-b592-0efc58ce3f7c,DISK], DatanodeInfoWithStorage[127.0.0.1:45943,DS-bae7c690-6ad9-4d13-ad67-b02e0931c803,DISK], DatanodeInfoWithStorage[127.0.0.1:45902,DS-87b9666d-4d5f-4431-bfd7-609abcb1c6e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45773,DS-61b27a8b-1748-4bec-975b-e880c3bc82b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33718,DS-8e26e510-8ef4-414f-a66b-8e48b43aad3a,DISK], DatanodeInfoWithStorage[127.0.0.1:35549,DS-cb69e699-e007-4367-b406-0f50c2a3b51a,DISK], DatanodeInfoWithStorage[127.0.0.1:46858,DS-511879f8-6e8e-4afb-b59e-4e715e80ce10,DISK], DatanodeInfoWithStorage[127.0.0.1:45797,DS-7329088e-04f1-4172-ac04-3707513f944c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5123
