reconf_parameter: dfs.client.use.legacy.blockreader.local
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.use.legacy.blockreader.local
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1902161658-172.17.0.15-1595338547306:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33986,DS-b25c7df9-cffe-4741-81e7-0a3841871f09,DISK], DatanodeInfoWithStorage[127.0.0.1:46543,DS-071fac9c-7309-4179-bfb8-0b925bbbfa86,DISK], DatanodeInfoWithStorage[127.0.0.1:37878,DS-510d4ab1-602a-40d5-9227-18e3b8da4c8e,DISK], DatanodeInfoWithStorage[127.0.0.1:34448,DS-605ca35e-6e20-4847-aa3e-64b259b23c49,DISK], DatanodeInfoWithStorage[127.0.0.1:46863,DS-fd6bd02f-d023-4448-b9f0-967e755bba97,DISK], DatanodeInfoWithStorage[127.0.0.1:41862,DS-3649ff36-6905-498a-b180-9c8763a6b413,DISK], DatanodeInfoWithStorage[127.0.0.1:40206,DS-67f6e8a0-14b2-4165-9e49-0b047be54872,DISK], DatanodeInfoWithStorage[127.0.0.1:38151,DS-648cd7d4-4469-4fc0-aaea-a985b85294a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1902161658-172.17.0.15-1595338547306:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33986,DS-b25c7df9-cffe-4741-81e7-0a3841871f09,DISK], DatanodeInfoWithStorage[127.0.0.1:46543,DS-071fac9c-7309-4179-bfb8-0b925bbbfa86,DISK], DatanodeInfoWithStorage[127.0.0.1:37878,DS-510d4ab1-602a-40d5-9227-18e3b8da4c8e,DISK], DatanodeInfoWithStorage[127.0.0.1:34448,DS-605ca35e-6e20-4847-aa3e-64b259b23c49,DISK], DatanodeInfoWithStorage[127.0.0.1:46863,DS-fd6bd02f-d023-4448-b9f0-967e755bba97,DISK], DatanodeInfoWithStorage[127.0.0.1:41862,DS-3649ff36-6905-498a-b180-9c8763a6b413,DISK], DatanodeInfoWithStorage[127.0.0.1:40206,DS-67f6e8a0-14b2-4165-9e49-0b047be54872,DISK], DatanodeInfoWithStorage[127.0.0.1:38151,DS-648cd7d4-4469-4fc0-aaea-a985b85294a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.legacy.blockreader.local
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-555716248-172.17.0.15-1595338730517:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40876,DS-e4459336-858b-4ec5-8037-2d69f1df4307,DISK], DatanodeInfoWithStorage[127.0.0.1:38213,DS-18bfe4e8-6e91-468e-91c7-a195f44e5fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:40957,DS-c9205d20-ce3a-4b7f-aff6-68e624cfe6e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40788,DS-facf0065-e6b1-45f5-bd24-88cd3ac5958e,DISK], DatanodeInfoWithStorage[127.0.0.1:35110,DS-82b8be47-a2b7-495a-bcb1-7d63912176b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36126,DS-14beb4f7-98a5-4f17-be83-d58f0594204f,DISK], DatanodeInfoWithStorage[127.0.0.1:43945,DS-b0c11d85-0b58-4487-abce-4e570bf695dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42954,DS-a2109b89-c332-400d-83f6-b5d692441580,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-555716248-172.17.0.15-1595338730517:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40876,DS-e4459336-858b-4ec5-8037-2d69f1df4307,DISK], DatanodeInfoWithStorage[127.0.0.1:38213,DS-18bfe4e8-6e91-468e-91c7-a195f44e5fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:40957,DS-c9205d20-ce3a-4b7f-aff6-68e624cfe6e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40788,DS-facf0065-e6b1-45f5-bd24-88cd3ac5958e,DISK], DatanodeInfoWithStorage[127.0.0.1:35110,DS-82b8be47-a2b7-495a-bcb1-7d63912176b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36126,DS-14beb4f7-98a5-4f17-be83-d58f0594204f,DISK], DatanodeInfoWithStorage[127.0.0.1:43945,DS-b0c11d85-0b58-4487-abce-4e570bf695dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42954,DS-a2109b89-c332-400d-83f6-b5d692441580,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.legacy.blockreader.local
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-605670682-172.17.0.15-1595339070982:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44446,DS-0189e2a2-d161-4b51-ba27-341dea0420d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44400,DS-edef8f3c-7f97-4aff-862c-3208f7983f69,DISK], DatanodeInfoWithStorage[127.0.0.1:33426,DS-09ac4cfb-a90c-43ee-8cda-f3d7733d1cb5,DISK], DatanodeInfoWithStorage[127.0.0.1:44150,DS-fd17b9dd-532d-4ccc-b51a-e55de3e67c2d,DISK], DatanodeInfoWithStorage[127.0.0.1:42900,DS-1b295e0a-cb22-4796-958a-181e732271a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42326,DS-d33733cc-760b-4932-b8ce-214a9def7aca,DISK], DatanodeInfoWithStorage[127.0.0.1:39936,DS-994e6468-efa3-43fe-b03a-18561aa5be8d,DISK], DatanodeInfoWithStorage[127.0.0.1:43649,DS-6b59ecd3-53b4-40a3-a9cb-5cc01bee0268,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-605670682-172.17.0.15-1595339070982:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44446,DS-0189e2a2-d161-4b51-ba27-341dea0420d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44400,DS-edef8f3c-7f97-4aff-862c-3208f7983f69,DISK], DatanodeInfoWithStorage[127.0.0.1:33426,DS-09ac4cfb-a90c-43ee-8cda-f3d7733d1cb5,DISK], DatanodeInfoWithStorage[127.0.0.1:44150,DS-fd17b9dd-532d-4ccc-b51a-e55de3e67c2d,DISK], DatanodeInfoWithStorage[127.0.0.1:42900,DS-1b295e0a-cb22-4796-958a-181e732271a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42326,DS-d33733cc-760b-4932-b8ce-214a9def7aca,DISK], DatanodeInfoWithStorage[127.0.0.1:39936,DS-994e6468-efa3-43fe-b03a-18561aa5be8d,DISK], DatanodeInfoWithStorage[127.0.0.1:43649,DS-6b59ecd3-53b4-40a3-a9cb-5cc01bee0268,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.use.legacy.blockreader.local
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-808712202-172.17.0.15-1595339106367:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45912,DS-c6096359-5367-40e1-b46b-2414908879f8,DISK], DatanodeInfoWithStorage[127.0.0.1:42392,DS-4a694efc-0e21-42d6-ae6e-64b7819473f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41858,DS-ad56417e-e47d-41c0-867d-73e50cee2d63,DISK], DatanodeInfoWithStorage[127.0.0.1:43651,DS-57cf9a42-d0cd-44e3-8e91-5bf0da9d8fb5,DISK], DatanodeInfoWithStorage[127.0.0.1:34021,DS-cafc8af3-0361-48c7-aadf-59b4d7345bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:36005,DS-bba52838-206a-44bf-be08-01911d8909da,DISK], DatanodeInfoWithStorage[127.0.0.1:42426,DS-00e4a5e4-8c85-4ca5-9a1b-bf298fd3893a,DISK], DatanodeInfoWithStorage[127.0.0.1:36172,DS-bb5eac22-865f-4995-a71b-157f6f2f01cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-808712202-172.17.0.15-1595339106367:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45912,DS-c6096359-5367-40e1-b46b-2414908879f8,DISK], DatanodeInfoWithStorage[127.0.0.1:42392,DS-4a694efc-0e21-42d6-ae6e-64b7819473f8,DISK], DatanodeInfoWithStorage[127.0.0.1:41858,DS-ad56417e-e47d-41c0-867d-73e50cee2d63,DISK], DatanodeInfoWithStorage[127.0.0.1:43651,DS-57cf9a42-d0cd-44e3-8e91-5bf0da9d8fb5,DISK], DatanodeInfoWithStorage[127.0.0.1:34021,DS-cafc8af3-0361-48c7-aadf-59b4d7345bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:36005,DS-bba52838-206a-44bf-be08-01911d8909da,DISK], DatanodeInfoWithStorage[127.0.0.1:42426,DS-00e4a5e4-8c85-4ca5-9a1b-bf298fd3893a,DISK], DatanodeInfoWithStorage[127.0.0.1:36172,DS-bb5eac22-865f-4995-a71b-157f6f2f01cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.legacy.blockreader.local
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1451051827-172.17.0.15-1595339487373:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44495,DS-9433abab-7447-463d-b16e-6f33e7e76537,DISK], DatanodeInfoWithStorage[127.0.0.1:34519,DS-9ea99b7b-5b93-4f1f-b6a9-d60eda845ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:36916,DS-4127fdea-e400-4f67-a99b-466b76da7ba7,DISK], DatanodeInfoWithStorage[127.0.0.1:45663,DS-af01ac8a-d3e8-49d1-a920-d3c97f6eaeeb,DISK], DatanodeInfoWithStorage[127.0.0.1:38145,DS-0cfc4a69-83a9-4d14-b267-4f40c5b5ce2f,DISK], DatanodeInfoWithStorage[127.0.0.1:45326,DS-4384a407-d94b-48d1-9170-7dee351a3193,DISK], DatanodeInfoWithStorage[127.0.0.1:36666,DS-b4d87915-0649-4332-b929-a2fe97c9375b,DISK], DatanodeInfoWithStorage[127.0.0.1:42296,DS-eacbd908-e111-499f-a01b-ccb27d1a86fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1451051827-172.17.0.15-1595339487373:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44495,DS-9433abab-7447-463d-b16e-6f33e7e76537,DISK], DatanodeInfoWithStorage[127.0.0.1:34519,DS-9ea99b7b-5b93-4f1f-b6a9-d60eda845ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:36916,DS-4127fdea-e400-4f67-a99b-466b76da7ba7,DISK], DatanodeInfoWithStorage[127.0.0.1:45663,DS-af01ac8a-d3e8-49d1-a920-d3c97f6eaeeb,DISK], DatanodeInfoWithStorage[127.0.0.1:38145,DS-0cfc4a69-83a9-4d14-b267-4f40c5b5ce2f,DISK], DatanodeInfoWithStorage[127.0.0.1:45326,DS-4384a407-d94b-48d1-9170-7dee351a3193,DISK], DatanodeInfoWithStorage[127.0.0.1:36666,DS-b4d87915-0649-4332-b929-a2fe97c9375b,DISK], DatanodeInfoWithStorage[127.0.0.1:42296,DS-eacbd908-e111-499f-a01b-ccb27d1a86fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.use.legacy.blockreader.local
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-434567160-172.17.0.15-1595339530620:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37708,DS-fd96b50b-03b3-4f8b-a8d0-0e6e4db8eeb1,DISK], DatanodeInfoWithStorage[127.0.0.1:46263,DS-8decec0c-f7a8-471a-a80a-1547b7adb955,DISK], DatanodeInfoWithStorage[127.0.0.1:40032,DS-6082510c-dca2-4361-b148-cd89d01777bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42407,DS-52b8a15a-93da-44cd-894c-8d08f66c6aed,DISK], DatanodeInfoWithStorage[127.0.0.1:41962,DS-9cc20944-7973-442c-952e-8e34487d11da,DISK], DatanodeInfoWithStorage[127.0.0.1:39737,DS-d4622798-6a80-4316-af8d-039211683286,DISK], DatanodeInfoWithStorage[127.0.0.1:40712,DS-2d75fa6a-27f9-496c-a7fd-232eb272ce8d,DISK], DatanodeInfoWithStorage[127.0.0.1:39592,DS-4b6ee1af-d6c5-49f2-a3c5-be3ac932dd51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-434567160-172.17.0.15-1595339530620:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37708,DS-fd96b50b-03b3-4f8b-a8d0-0e6e4db8eeb1,DISK], DatanodeInfoWithStorage[127.0.0.1:46263,DS-8decec0c-f7a8-471a-a80a-1547b7adb955,DISK], DatanodeInfoWithStorage[127.0.0.1:40032,DS-6082510c-dca2-4361-b148-cd89d01777bf,DISK], DatanodeInfoWithStorage[127.0.0.1:42407,DS-52b8a15a-93da-44cd-894c-8d08f66c6aed,DISK], DatanodeInfoWithStorage[127.0.0.1:41962,DS-9cc20944-7973-442c-952e-8e34487d11da,DISK], DatanodeInfoWithStorage[127.0.0.1:39737,DS-d4622798-6a80-4316-af8d-039211683286,DISK], DatanodeInfoWithStorage[127.0.0.1:40712,DS-2d75fa6a-27f9-496c-a7fd-232eb272ce8d,DISK], DatanodeInfoWithStorage[127.0.0.1:39592,DS-4b6ee1af-d6c5-49f2-a3c5-be3ac932dd51,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.legacy.blockreader.local
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-633221942-172.17.0.15-1595340140852:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41828,DS-0a1eb150-0784-41ce-8f7f-b7bfaab84587,DISK], DatanodeInfoWithStorage[127.0.0.1:36568,DS-b7273d08-6a51-4aa7-8359-31e9b182e649,DISK], DatanodeInfoWithStorage[127.0.0.1:39963,DS-9d254b14-f0c5-4850-ae09-8c4ad3e4cfea,DISK], DatanodeInfoWithStorage[127.0.0.1:44402,DS-09b63ee7-b7e9-4d8d-b76a-0652443f8e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:35922,DS-7753dea2-bc33-4ec5-95ac-ac23b1697136,DISK], DatanodeInfoWithStorage[127.0.0.1:43854,DS-efd9ad98-8e94-4d4e-bf01-f4c9b648391d,DISK], DatanodeInfoWithStorage[127.0.0.1:38968,DS-c5171eea-6ce0-4d45-bbcd-85f7fea53e80,DISK], DatanodeInfoWithStorage[127.0.0.1:40045,DS-414b194d-a4b1-4faa-8fe1-0552ddf7c7e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-633221942-172.17.0.15-1595340140852:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41828,DS-0a1eb150-0784-41ce-8f7f-b7bfaab84587,DISK], DatanodeInfoWithStorage[127.0.0.1:36568,DS-b7273d08-6a51-4aa7-8359-31e9b182e649,DISK], DatanodeInfoWithStorage[127.0.0.1:39963,DS-9d254b14-f0c5-4850-ae09-8c4ad3e4cfea,DISK], DatanodeInfoWithStorage[127.0.0.1:44402,DS-09b63ee7-b7e9-4d8d-b76a-0652443f8e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:35922,DS-7753dea2-bc33-4ec5-95ac-ac23b1697136,DISK], DatanodeInfoWithStorage[127.0.0.1:43854,DS-efd9ad98-8e94-4d4e-bf01-f4c9b648391d,DISK], DatanodeInfoWithStorage[127.0.0.1:38968,DS-c5171eea-6ce0-4d45-bbcd-85f7fea53e80,DISK], DatanodeInfoWithStorage[127.0.0.1:40045,DS-414b194d-a4b1-4faa-8fe1-0552ddf7c7e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.legacy.blockreader.local
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1470838869-172.17.0.15-1595341281703:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39600,DS-7f91c001-b39b-4729-a360-cf81b996dd73,DISK], DatanodeInfoWithStorage[127.0.0.1:38533,DS-39ab8230-1e09-4799-9a51-44425b49448a,DISK], DatanodeInfoWithStorage[127.0.0.1:37489,DS-6e6603bb-5371-453d-ac0f-1419a254cec7,DISK], DatanodeInfoWithStorage[127.0.0.1:35733,DS-c4bb41be-1600-47b9-9e66-e2f6de19e9cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37389,DS-31406c81-368f-4f49-9e0f-0c1428fe97f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44938,DS-2fd3c555-0de1-48b4-bf31-28191065e0b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38495,DS-5e6083c2-563d-4c55-9a58-5451c3fdab9b,DISK], DatanodeInfoWithStorage[127.0.0.1:40164,DS-04f43ba9-0d6d-4927-8c89-2abcca385716,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1470838869-172.17.0.15-1595341281703:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39600,DS-7f91c001-b39b-4729-a360-cf81b996dd73,DISK], DatanodeInfoWithStorage[127.0.0.1:38533,DS-39ab8230-1e09-4799-9a51-44425b49448a,DISK], DatanodeInfoWithStorage[127.0.0.1:37489,DS-6e6603bb-5371-453d-ac0f-1419a254cec7,DISK], DatanodeInfoWithStorage[127.0.0.1:35733,DS-c4bb41be-1600-47b9-9e66-e2f6de19e9cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37389,DS-31406c81-368f-4f49-9e0f-0c1428fe97f1,DISK], DatanodeInfoWithStorage[127.0.0.1:44938,DS-2fd3c555-0de1-48b4-bf31-28191065e0b9,DISK], DatanodeInfoWithStorage[127.0.0.1:38495,DS-5e6083c2-563d-4c55-9a58-5451c3fdab9b,DISK], DatanodeInfoWithStorage[127.0.0.1:40164,DS-04f43ba9-0d6d-4927-8c89-2abcca385716,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.legacy.blockreader.local
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-973920536-172.17.0.15-1595341916192:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44297,DS-d520f379-3dad-4028-8099-e0fdab68d9ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41667,DS-22c4b8fe-5633-47eb-8918-ffb3ac2e5e78,DISK], DatanodeInfoWithStorage[127.0.0.1:45726,DS-81c8700b-6c95-48ee-8843-75506f2e024b,DISK], DatanodeInfoWithStorage[127.0.0.1:45883,DS-714f9e05-576e-46b7-99ed-53bf6acd9161,DISK], DatanodeInfoWithStorage[127.0.0.1:46586,DS-321985f0-a407-4726-bbb6-ef222e5d70e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40450,DS-f4ef51ee-a2f2-444c-ad4a-35c31e89c507,DISK], DatanodeInfoWithStorage[127.0.0.1:39675,DS-fc71cda3-f2b1-4163-8923-b91f21703a68,DISK], DatanodeInfoWithStorage[127.0.0.1:45588,DS-2026fd0a-2737-4d91-8659-41d17e14fe14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-973920536-172.17.0.15-1595341916192:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44297,DS-d520f379-3dad-4028-8099-e0fdab68d9ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41667,DS-22c4b8fe-5633-47eb-8918-ffb3ac2e5e78,DISK], DatanodeInfoWithStorage[127.0.0.1:45726,DS-81c8700b-6c95-48ee-8843-75506f2e024b,DISK], DatanodeInfoWithStorage[127.0.0.1:45883,DS-714f9e05-576e-46b7-99ed-53bf6acd9161,DISK], DatanodeInfoWithStorage[127.0.0.1:46586,DS-321985f0-a407-4726-bbb6-ef222e5d70e2,DISK], DatanodeInfoWithStorage[127.0.0.1:40450,DS-f4ef51ee-a2f2-444c-ad4a-35c31e89c507,DISK], DatanodeInfoWithStorage[127.0.0.1:39675,DS-fc71cda3-f2b1-4163-8923-b91f21703a68,DISK], DatanodeInfoWithStorage[127.0.0.1:45588,DS-2026fd0a-2737-4d91-8659-41d17e14fe14,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.legacy.blockreader.local
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1232923061-172.17.0.15-1595342343389:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35066,DS-ac70cde3-feb8-4bd0-b7f1-693200cb6a61,DISK], DatanodeInfoWithStorage[127.0.0.1:43105,DS-d26f1c89-3420-475f-aec4-dd645e524d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:37548,DS-7e3386f5-8bbd-49ac-b150-0a7df063d07a,DISK], DatanodeInfoWithStorage[127.0.0.1:34939,DS-dc5a7eff-8fde-444b-b65e-f2d96c869e5d,DISK], DatanodeInfoWithStorage[127.0.0.1:39167,DS-6f26640b-8727-4a29-b804-05f3bb86a557,DISK], DatanodeInfoWithStorage[127.0.0.1:36464,DS-08cba121-3c15-4667-8f59-60b65d0da610,DISK], DatanodeInfoWithStorage[127.0.0.1:44046,DS-d361b16e-208f-4eef-bb18-cee4b9b05005,DISK], DatanodeInfoWithStorage[127.0.0.1:40774,DS-7aab458e-146a-4235-a53c-57c43d1e8b2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1232923061-172.17.0.15-1595342343389:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35066,DS-ac70cde3-feb8-4bd0-b7f1-693200cb6a61,DISK], DatanodeInfoWithStorage[127.0.0.1:43105,DS-d26f1c89-3420-475f-aec4-dd645e524d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:37548,DS-7e3386f5-8bbd-49ac-b150-0a7df063d07a,DISK], DatanodeInfoWithStorage[127.0.0.1:34939,DS-dc5a7eff-8fde-444b-b65e-f2d96c869e5d,DISK], DatanodeInfoWithStorage[127.0.0.1:39167,DS-6f26640b-8727-4a29-b804-05f3bb86a557,DISK], DatanodeInfoWithStorage[127.0.0.1:36464,DS-08cba121-3c15-4667-8f59-60b65d0da610,DISK], DatanodeInfoWithStorage[127.0.0.1:44046,DS-d361b16e-208f-4eef-bb18-cee4b9b05005,DISK], DatanodeInfoWithStorage[127.0.0.1:40774,DS-7aab458e-146a-4235-a53c-57c43d1e8b2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.use.legacy.blockreader.local
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1520578098-172.17.0.15-1595342517957:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42931,DS-d7b914c0-65c7-44a6-8bd0-c318f83cbdc0,DISK], DatanodeInfoWithStorage[127.0.0.1:43286,DS-8b93d2fa-7468-445c-8d8d-992a9db2a908,DISK], DatanodeInfoWithStorage[127.0.0.1:44603,DS-6f2f2f84-00e3-4bd6-ad6f-b5ac774d8c2d,DISK], DatanodeInfoWithStorage[127.0.0.1:38350,DS-64a2898a-0472-405e-9df0-44f0218e235d,DISK], DatanodeInfoWithStorage[127.0.0.1:40880,DS-31ede5a3-b790-4ced-8c67-4f5aaf943ae6,DISK], DatanodeInfoWithStorage[127.0.0.1:34879,DS-341e9399-5431-4ab5-9f9f-3ed35c72842e,DISK], DatanodeInfoWithStorage[127.0.0.1:40714,DS-7cc9b6f5-2de5-4e4c-bfb3-4f29c5273f10,DISK], DatanodeInfoWithStorage[127.0.0.1:33845,DS-20c38478-cf11-48a0-be68-4757ee3e37c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1520578098-172.17.0.15-1595342517957:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42931,DS-d7b914c0-65c7-44a6-8bd0-c318f83cbdc0,DISK], DatanodeInfoWithStorage[127.0.0.1:43286,DS-8b93d2fa-7468-445c-8d8d-992a9db2a908,DISK], DatanodeInfoWithStorage[127.0.0.1:44603,DS-6f2f2f84-00e3-4bd6-ad6f-b5ac774d8c2d,DISK], DatanodeInfoWithStorage[127.0.0.1:38350,DS-64a2898a-0472-405e-9df0-44f0218e235d,DISK], DatanodeInfoWithStorage[127.0.0.1:40880,DS-31ede5a3-b790-4ced-8c67-4f5aaf943ae6,DISK], DatanodeInfoWithStorage[127.0.0.1:34879,DS-341e9399-5431-4ab5-9f9f-3ed35c72842e,DISK], DatanodeInfoWithStorage[127.0.0.1:40714,DS-7cc9b6f5-2de5-4e4c-bfb3-4f29c5273f10,DISK], DatanodeInfoWithStorage[127.0.0.1:33845,DS-20c38478-cf11-48a0-be68-4757ee3e37c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.use.legacy.blockreader.local
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-51632096-172.17.0.15-1595342693385:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40177,DS-f4c476c0-e422-429a-8b2c-6c8c546c150f,DISK], DatanodeInfoWithStorage[127.0.0.1:35856,DS-80e99385-ccdb-4b1a-a43f-e4de5f7f8ead,DISK], DatanodeInfoWithStorage[127.0.0.1:42399,DS-ab16e50c-9d32-42f7-86a8-5b95c90bcd26,DISK], DatanodeInfoWithStorage[127.0.0.1:36507,DS-277747b6-f02b-489b-baa2-4bf39656f0f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33121,DS-0d4c0a4f-e903-4c66-a362-c938d6ad6256,DISK], DatanodeInfoWithStorage[127.0.0.1:36073,DS-39ceeaa1-81ab-4fdc-91dd-e9be07b204db,DISK], DatanodeInfoWithStorage[127.0.0.1:34519,DS-63452c7f-565e-4ab9-873c-82574acc025b,DISK], DatanodeInfoWithStorage[127.0.0.1:43136,DS-ed46ec83-b35b-40c2-81d0-d8f47444f3cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-51632096-172.17.0.15-1595342693385:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40177,DS-f4c476c0-e422-429a-8b2c-6c8c546c150f,DISK], DatanodeInfoWithStorage[127.0.0.1:35856,DS-80e99385-ccdb-4b1a-a43f-e4de5f7f8ead,DISK], DatanodeInfoWithStorage[127.0.0.1:42399,DS-ab16e50c-9d32-42f7-86a8-5b95c90bcd26,DISK], DatanodeInfoWithStorage[127.0.0.1:36507,DS-277747b6-f02b-489b-baa2-4bf39656f0f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33121,DS-0d4c0a4f-e903-4c66-a362-c938d6ad6256,DISK], DatanodeInfoWithStorage[127.0.0.1:36073,DS-39ceeaa1-81ab-4fdc-91dd-e9be07b204db,DISK], DatanodeInfoWithStorage[127.0.0.1:34519,DS-63452c7f-565e-4ab9-873c-82574acc025b,DISK], DatanodeInfoWithStorage[127.0.0.1:43136,DS-ed46ec83-b35b-40c2-81d0-d8f47444f3cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5320
