reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1560933101-172.17.0.6-1596984208695:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37246,DS-88e203fa-8a7f-4ca7-8c9a-6ec3bdbfd3a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42823,DS-b9c91933-7d74-4200-83de-9497f04e002f,DISK], DatanodeInfoWithStorage[127.0.0.1:39666,DS-bcdf45dc-4080-47c3-b872-8139e7323d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:45842,DS-102a50bb-cb1a-4e2b-b8b1-0ed9ca5be2e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45731,DS-e7f2f7ec-309d-4903-9bf4-1ab83f815a80,DISK], DatanodeInfoWithStorage[127.0.0.1:38219,DS-4744750a-848e-4468-bc13-3b4453b05c48,DISK], DatanodeInfoWithStorage[127.0.0.1:34049,DS-8b212b95-235c-4447-a058-01ee64a95f61,DISK], DatanodeInfoWithStorage[127.0.0.1:39010,DS-7792d3d1-8f04-41be-88e2-f4ce5b2e09b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1560933101-172.17.0.6-1596984208695:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37246,DS-88e203fa-8a7f-4ca7-8c9a-6ec3bdbfd3a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42823,DS-b9c91933-7d74-4200-83de-9497f04e002f,DISK], DatanodeInfoWithStorage[127.0.0.1:39666,DS-bcdf45dc-4080-47c3-b872-8139e7323d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:45842,DS-102a50bb-cb1a-4e2b-b8b1-0ed9ca5be2e6,DISK], DatanodeInfoWithStorage[127.0.0.1:45731,DS-e7f2f7ec-309d-4903-9bf4-1ab83f815a80,DISK], DatanodeInfoWithStorage[127.0.0.1:38219,DS-4744750a-848e-4468-bc13-3b4453b05c48,DISK], DatanodeInfoWithStorage[127.0.0.1:34049,DS-8b212b95-235c-4447-a058-01ee64a95f61,DISK], DatanodeInfoWithStorage[127.0.0.1:39010,DS-7792d3d1-8f04-41be-88e2-f4ce5b2e09b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1697750041-172.17.0.6-1596984872029:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46725,DS-84135171-2fdd-4fc1-98aa-0c65530fec5b,DISK], DatanodeInfoWithStorage[127.0.0.1:44379,DS-01b6afdd-a19f-4bd4-9653-960f2f7dc09e,DISK], DatanodeInfoWithStorage[127.0.0.1:32951,DS-05410045-89b2-4cb2-8f8c-7a1b3d1855a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37902,DS-6b71ec4e-fb3f-4433-902c-e956a5c23bff,DISK], DatanodeInfoWithStorage[127.0.0.1:36983,DS-9d68429d-0b18-4d7e-81fc-966d81d8fcfc,DISK], DatanodeInfoWithStorage[127.0.0.1:45741,DS-e428e77e-2679-4083-896d-038d2825631d,DISK], DatanodeInfoWithStorage[127.0.0.1:35111,DS-5c7204b6-51bb-45b1-9464-593ced17eb0a,DISK], DatanodeInfoWithStorage[127.0.0.1:36026,DS-d4ef14d1-db6b-4269-8f0d-209dec508cdf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1697750041-172.17.0.6-1596984872029:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46725,DS-84135171-2fdd-4fc1-98aa-0c65530fec5b,DISK], DatanodeInfoWithStorage[127.0.0.1:44379,DS-01b6afdd-a19f-4bd4-9653-960f2f7dc09e,DISK], DatanodeInfoWithStorage[127.0.0.1:32951,DS-05410045-89b2-4cb2-8f8c-7a1b3d1855a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37902,DS-6b71ec4e-fb3f-4433-902c-e956a5c23bff,DISK], DatanodeInfoWithStorage[127.0.0.1:36983,DS-9d68429d-0b18-4d7e-81fc-966d81d8fcfc,DISK], DatanodeInfoWithStorage[127.0.0.1:45741,DS-e428e77e-2679-4083-896d-038d2825631d,DISK], DatanodeInfoWithStorage[127.0.0.1:35111,DS-5c7204b6-51bb-45b1-9464-593ced17eb0a,DISK], DatanodeInfoWithStorage[127.0.0.1:36026,DS-d4ef14d1-db6b-4269-8f0d-209dec508cdf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1889597112-172.17.0.6-1596985180184:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46449,DS-1252648b-dbf4-4ba9-8dcf-e5ea9ebb9912,DISK], DatanodeInfoWithStorage[127.0.0.1:46667,DS-da64a049-fe88-4a41-9cec-776d22f11065,DISK], DatanodeInfoWithStorage[127.0.0.1:46285,DS-f97fb783-ed67-4288-adf2-d0c5439f429b,DISK], DatanodeInfoWithStorage[127.0.0.1:35355,DS-94cacffc-7005-4934-9ed2-dcc1c111a9fb,DISK], DatanodeInfoWithStorage[127.0.0.1:33423,DS-f64a7796-bf9f-43a3-807e-6f250a26a149,DISK], DatanodeInfoWithStorage[127.0.0.1:41192,DS-4d2dba03-8daa-4084-afcc-47651c9be2bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41141,DS-93549630-93bc-4afb-a03f-a152c37634fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46598,DS-a20ea046-ab6f-4110-b018-b94a0824fa45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1889597112-172.17.0.6-1596985180184:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46449,DS-1252648b-dbf4-4ba9-8dcf-e5ea9ebb9912,DISK], DatanodeInfoWithStorage[127.0.0.1:46667,DS-da64a049-fe88-4a41-9cec-776d22f11065,DISK], DatanodeInfoWithStorage[127.0.0.1:46285,DS-f97fb783-ed67-4288-adf2-d0c5439f429b,DISK], DatanodeInfoWithStorage[127.0.0.1:35355,DS-94cacffc-7005-4934-9ed2-dcc1c111a9fb,DISK], DatanodeInfoWithStorage[127.0.0.1:33423,DS-f64a7796-bf9f-43a3-807e-6f250a26a149,DISK], DatanodeInfoWithStorage[127.0.0.1:41192,DS-4d2dba03-8daa-4084-afcc-47651c9be2bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41141,DS-93549630-93bc-4afb-a03f-a152c37634fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46598,DS-a20ea046-ab6f-4110-b018-b94a0824fa45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-993489594-172.17.0.6-1596985635910:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36804,DS-64c0c21e-db0d-44e5-9410-800a330c3059,DISK], DatanodeInfoWithStorage[127.0.0.1:44535,DS-2c8607fb-564c-4521-aa12-ca0d240255b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42158,DS-8564f4d4-98f0-41dd-8c6a-68ff1c53b200,DISK], DatanodeInfoWithStorage[127.0.0.1:34212,DS-317cfc74-d70f-43f7-8785-f474e7bd108a,DISK], DatanodeInfoWithStorage[127.0.0.1:38108,DS-cf19e35b-087b-48aa-8dc1-cb5da8cb88a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35808,DS-e5a5fb20-612a-482d-96a9-5f2a5dd4e523,DISK], DatanodeInfoWithStorage[127.0.0.1:46557,DS-8571aa40-d7e4-4508-9f48-2521101c7b6c,DISK], DatanodeInfoWithStorage[127.0.0.1:35312,DS-4d6ef99b-294b-457d-bd3c-b4ded59fef24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-993489594-172.17.0.6-1596985635910:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36804,DS-64c0c21e-db0d-44e5-9410-800a330c3059,DISK], DatanodeInfoWithStorage[127.0.0.1:44535,DS-2c8607fb-564c-4521-aa12-ca0d240255b1,DISK], DatanodeInfoWithStorage[127.0.0.1:42158,DS-8564f4d4-98f0-41dd-8c6a-68ff1c53b200,DISK], DatanodeInfoWithStorage[127.0.0.1:34212,DS-317cfc74-d70f-43f7-8785-f474e7bd108a,DISK], DatanodeInfoWithStorage[127.0.0.1:38108,DS-cf19e35b-087b-48aa-8dc1-cb5da8cb88a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35808,DS-e5a5fb20-612a-482d-96a9-5f2a5dd4e523,DISK], DatanodeInfoWithStorage[127.0.0.1:46557,DS-8571aa40-d7e4-4508-9f48-2521101c7b6c,DISK], DatanodeInfoWithStorage[127.0.0.1:35312,DS-4d6ef99b-294b-457d-bd3c-b4ded59fef24,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1188499793-172.17.0.6-1596986486643:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40215,DS-b85fef2d-22b1-472f-89d5-374d300e9861,DISK], DatanodeInfoWithStorage[127.0.0.1:41664,DS-45e64d52-538e-4db8-be64-96b012aac159,DISK], DatanodeInfoWithStorage[127.0.0.1:38723,DS-ca19ec3c-7435-4a22-8541-2e8cfba39bff,DISK], DatanodeInfoWithStorage[127.0.0.1:44030,DS-9f0b0a13-f541-406c-a3b0-7f71d10e64a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38207,DS-f1c86f44-4c0a-43da-b960-9b339897787f,DISK], DatanodeInfoWithStorage[127.0.0.1:43653,DS-1c851ab6-bffe-4a4b-8169-ee56596b0a6f,DISK], DatanodeInfoWithStorage[127.0.0.1:37287,DS-6fa99487-9972-494a-bfac-cd190c88d2fc,DISK], DatanodeInfoWithStorage[127.0.0.1:41003,DS-083ef30c-d873-414b-b9af-64bd43254afa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1188499793-172.17.0.6-1596986486643:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40215,DS-b85fef2d-22b1-472f-89d5-374d300e9861,DISK], DatanodeInfoWithStorage[127.0.0.1:41664,DS-45e64d52-538e-4db8-be64-96b012aac159,DISK], DatanodeInfoWithStorage[127.0.0.1:38723,DS-ca19ec3c-7435-4a22-8541-2e8cfba39bff,DISK], DatanodeInfoWithStorage[127.0.0.1:44030,DS-9f0b0a13-f541-406c-a3b0-7f71d10e64a5,DISK], DatanodeInfoWithStorage[127.0.0.1:38207,DS-f1c86f44-4c0a-43da-b960-9b339897787f,DISK], DatanodeInfoWithStorage[127.0.0.1:43653,DS-1c851ab6-bffe-4a4b-8169-ee56596b0a6f,DISK], DatanodeInfoWithStorage[127.0.0.1:37287,DS-6fa99487-9972-494a-bfac-cd190c88d2fc,DISK], DatanodeInfoWithStorage[127.0.0.1:41003,DS-083ef30c-d873-414b-b9af-64bd43254afa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-776105270-172.17.0.6-1596986573457:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43154,DS-13817585-6d2e-4d1e-bfaf-6a4587ce332e,DISK], DatanodeInfoWithStorage[127.0.0.1:40982,DS-99c9022a-82d4-4498-ab7e-17199df805d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37034,DS-0e09df9c-cca5-4c4e-bd09-3239c2acd90f,DISK], DatanodeInfoWithStorage[127.0.0.1:33452,DS-bb8cb960-5e30-4189-9da6-e244cbfc96b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36861,DS-6da21ba7-39bc-4911-b9da-53f5dafe331c,DISK], DatanodeInfoWithStorage[127.0.0.1:44875,DS-af0c1e45-2ea8-464f-b3b2-b56119b79e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:37225,DS-67813c13-2537-48e7-b40b-7fc9d7d80755,DISK], DatanodeInfoWithStorage[127.0.0.1:40067,DS-bdf46ddc-f18d-47dc-af63-15e4452ba076,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-776105270-172.17.0.6-1596986573457:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43154,DS-13817585-6d2e-4d1e-bfaf-6a4587ce332e,DISK], DatanodeInfoWithStorage[127.0.0.1:40982,DS-99c9022a-82d4-4498-ab7e-17199df805d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37034,DS-0e09df9c-cca5-4c4e-bd09-3239c2acd90f,DISK], DatanodeInfoWithStorage[127.0.0.1:33452,DS-bb8cb960-5e30-4189-9da6-e244cbfc96b9,DISK], DatanodeInfoWithStorage[127.0.0.1:36861,DS-6da21ba7-39bc-4911-b9da-53f5dafe331c,DISK], DatanodeInfoWithStorage[127.0.0.1:44875,DS-af0c1e45-2ea8-464f-b3b2-b56119b79e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:37225,DS-67813c13-2537-48e7-b40b-7fc9d7d80755,DISK], DatanodeInfoWithStorage[127.0.0.1:40067,DS-bdf46ddc-f18d-47dc-af63-15e4452ba076,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1260436301-172.17.0.6-1596987654096:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38401,DS-b9046fc7-1c26-4731-ae4c-e5541331db61,DISK], DatanodeInfoWithStorage[127.0.0.1:37366,DS-7132604b-086c-40f8-b4e9-47fb8bd87eda,DISK], DatanodeInfoWithStorage[127.0.0.1:38181,DS-5495e818-8618-4719-80ca-4b1efcb57db8,DISK], DatanodeInfoWithStorage[127.0.0.1:34226,DS-0ae44799-0999-4122-8e23-5d5e2c903b38,DISK], DatanodeInfoWithStorage[127.0.0.1:46620,DS-5618f498-7d56-45f7-9081-3bc8dc69271a,DISK], DatanodeInfoWithStorage[127.0.0.1:38968,DS-7d393b3c-cf76-43a6-86a6-bf1586339379,DISK], DatanodeInfoWithStorage[127.0.0.1:45569,DS-51b3cb8b-851c-4000-b5e6-3722533967c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39189,DS-39987ab1-4c92-4997-bc04-3cd7dc210185,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1260436301-172.17.0.6-1596987654096:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38401,DS-b9046fc7-1c26-4731-ae4c-e5541331db61,DISK], DatanodeInfoWithStorage[127.0.0.1:37366,DS-7132604b-086c-40f8-b4e9-47fb8bd87eda,DISK], DatanodeInfoWithStorage[127.0.0.1:38181,DS-5495e818-8618-4719-80ca-4b1efcb57db8,DISK], DatanodeInfoWithStorage[127.0.0.1:34226,DS-0ae44799-0999-4122-8e23-5d5e2c903b38,DISK], DatanodeInfoWithStorage[127.0.0.1:46620,DS-5618f498-7d56-45f7-9081-3bc8dc69271a,DISK], DatanodeInfoWithStorage[127.0.0.1:38968,DS-7d393b3c-cf76-43a6-86a6-bf1586339379,DISK], DatanodeInfoWithStorage[127.0.0.1:45569,DS-51b3cb8b-851c-4000-b5e6-3722533967c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39189,DS-39987ab1-4c92-4997-bc04-3cd7dc210185,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-666703011-172.17.0.6-1596987927803:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46019,DS-adbf56c0-a7ba-472d-b82c-771af843003b,DISK], DatanodeInfoWithStorage[127.0.0.1:45232,DS-700795e4-b34a-4917-bbd4-d58fca14ae36,DISK], DatanodeInfoWithStorage[127.0.0.1:32907,DS-ffeebdee-04e6-4bd7-9e39-45599c9eaf60,DISK], DatanodeInfoWithStorage[127.0.0.1:46205,DS-33b37db8-975b-4f79-8edc-f0f3669d982e,DISK], DatanodeInfoWithStorage[127.0.0.1:33245,DS-2306e471-51a0-4388-953a-c045383bf5a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44722,DS-2552af90-a426-4523-82b9-c8ca0bb750b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45430,DS-8f4e0ebe-d299-44c3-b979-bbf9ff52e727,DISK], DatanodeInfoWithStorage[127.0.0.1:46770,DS-5573d8ac-6604-442d-8d87-327ab378700a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-666703011-172.17.0.6-1596987927803:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46019,DS-adbf56c0-a7ba-472d-b82c-771af843003b,DISK], DatanodeInfoWithStorage[127.0.0.1:45232,DS-700795e4-b34a-4917-bbd4-d58fca14ae36,DISK], DatanodeInfoWithStorage[127.0.0.1:32907,DS-ffeebdee-04e6-4bd7-9e39-45599c9eaf60,DISK], DatanodeInfoWithStorage[127.0.0.1:46205,DS-33b37db8-975b-4f79-8edc-f0f3669d982e,DISK], DatanodeInfoWithStorage[127.0.0.1:33245,DS-2306e471-51a0-4388-953a-c045383bf5a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44722,DS-2552af90-a426-4523-82b9-c8ca0bb750b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45430,DS-8f4e0ebe-d299-44c3-b979-bbf9ff52e727,DISK], DatanodeInfoWithStorage[127.0.0.1:46770,DS-5573d8ac-6604-442d-8d87-327ab378700a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-948462598-172.17.0.6-1596988588748:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38880,DS-cc56b9e5-ba07-4e8d-b1dd-30aecd701f84,DISK], DatanodeInfoWithStorage[127.0.0.1:39583,DS-bedc9456-d762-4a80-9519-fb0ad034b055,DISK], DatanodeInfoWithStorage[127.0.0.1:45562,DS-0a01239e-8452-498e-80cc-7884a7c41f51,DISK], DatanodeInfoWithStorage[127.0.0.1:36136,DS-d77836a7-f645-4546-9a97-a06e4cabba0b,DISK], DatanodeInfoWithStorage[127.0.0.1:33021,DS-c8abb18f-f1ca-4835-a739-8322dadec6b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43892,DS-ea30873f-4b14-4a9a-b067-02e3dff573d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46747,DS-00aef71f-c3ad-48e3-b24c-ab3a7105a4b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40307,DS-1dbae838-4073-4ea6-ab71-be6b042043b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-948462598-172.17.0.6-1596988588748:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38880,DS-cc56b9e5-ba07-4e8d-b1dd-30aecd701f84,DISK], DatanodeInfoWithStorage[127.0.0.1:39583,DS-bedc9456-d762-4a80-9519-fb0ad034b055,DISK], DatanodeInfoWithStorage[127.0.0.1:45562,DS-0a01239e-8452-498e-80cc-7884a7c41f51,DISK], DatanodeInfoWithStorage[127.0.0.1:36136,DS-d77836a7-f645-4546-9a97-a06e4cabba0b,DISK], DatanodeInfoWithStorage[127.0.0.1:33021,DS-c8abb18f-f1ca-4835-a739-8322dadec6b9,DISK], DatanodeInfoWithStorage[127.0.0.1:43892,DS-ea30873f-4b14-4a9a-b067-02e3dff573d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46747,DS-00aef71f-c3ad-48e3-b24c-ab3a7105a4b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40307,DS-1dbae838-4073-4ea6-ab71-be6b042043b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1464162798-172.17.0.6-1596988722513:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38400,DS-34346331-4280-4bed-a0bb-b944df154e01,DISK], DatanodeInfoWithStorage[127.0.0.1:40327,DS-8d00c79c-a0e0-40ad-a1aa-92cedf208c8e,DISK], DatanodeInfoWithStorage[127.0.0.1:40845,DS-15452647-6c58-4969-adc5-79340f733b57,DISK], DatanodeInfoWithStorage[127.0.0.1:34705,DS-566519f3-efa9-4f32-90b1-0824df27a91e,DISK], DatanodeInfoWithStorage[127.0.0.1:39909,DS-cbd9c5c1-703f-4261-9165-5cbad6a1c9fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42623,DS-22ea014b-ab32-4f02-9dde-ebc4b048822b,DISK], DatanodeInfoWithStorage[127.0.0.1:35409,DS-9f6d80ad-437b-4dc9-8f37-3507d955bd36,DISK], DatanodeInfoWithStorage[127.0.0.1:36134,DS-a558e49d-6ac1-4256-98b0-77a50a339f1f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1464162798-172.17.0.6-1596988722513:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38400,DS-34346331-4280-4bed-a0bb-b944df154e01,DISK], DatanodeInfoWithStorage[127.0.0.1:40327,DS-8d00c79c-a0e0-40ad-a1aa-92cedf208c8e,DISK], DatanodeInfoWithStorage[127.0.0.1:40845,DS-15452647-6c58-4969-adc5-79340f733b57,DISK], DatanodeInfoWithStorage[127.0.0.1:34705,DS-566519f3-efa9-4f32-90b1-0824df27a91e,DISK], DatanodeInfoWithStorage[127.0.0.1:39909,DS-cbd9c5c1-703f-4261-9165-5cbad6a1c9fd,DISK], DatanodeInfoWithStorage[127.0.0.1:42623,DS-22ea014b-ab32-4f02-9dde-ebc4b048822b,DISK], DatanodeInfoWithStorage[127.0.0.1:35409,DS-9f6d80ad-437b-4dc9-8f37-3507d955bd36,DISK], DatanodeInfoWithStorage[127.0.0.1:36134,DS-a558e49d-6ac1-4256-98b0-77a50a339f1f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1662501501-172.17.0.6-1596988951461:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44816,DS-a932ee7f-85f0-41c9-a409-6cc97c91a90f,DISK], DatanodeInfoWithStorage[127.0.0.1:40163,DS-f3d9098f-9112-457d-b44c-7b5971d549bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38370,DS-e2cd8c03-7123-4839-a55f-3ca1adc8d489,DISK], DatanodeInfoWithStorage[127.0.0.1:34800,DS-9cef9173-0a84-4c03-bf44-0d781f4caccf,DISK], DatanodeInfoWithStorage[127.0.0.1:41566,DS-dc918586-a200-41e2-a910-5ce1f80b3eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:42796,DS-b6e53233-40c0-4002-9614-201ac02006dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38287,DS-4d9e9e84-3989-4c04-afc0-3dc2ed214f03,DISK], DatanodeInfoWithStorage[127.0.0.1:46619,DS-d0e9a930-d1c6-4b92-83bf-5ecd39ddec86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1662501501-172.17.0.6-1596988951461:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44816,DS-a932ee7f-85f0-41c9-a409-6cc97c91a90f,DISK], DatanodeInfoWithStorage[127.0.0.1:40163,DS-f3d9098f-9112-457d-b44c-7b5971d549bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38370,DS-e2cd8c03-7123-4839-a55f-3ca1adc8d489,DISK], DatanodeInfoWithStorage[127.0.0.1:34800,DS-9cef9173-0a84-4c03-bf44-0d781f4caccf,DISK], DatanodeInfoWithStorage[127.0.0.1:41566,DS-dc918586-a200-41e2-a910-5ce1f80b3eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:42796,DS-b6e53233-40c0-4002-9614-201ac02006dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38287,DS-4d9e9e84-3989-4c04-afc0-3dc2ed214f03,DISK], DatanodeInfoWithStorage[127.0.0.1:46619,DS-d0e9a930-d1c6-4b92-83bf-5ecd39ddec86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-637163239-172.17.0.6-1596989110861:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39538,DS-dc47b68f-a8eb-4a0c-b53e-f73df0bc0d75,DISK], DatanodeInfoWithStorage[127.0.0.1:36152,DS-6fbb07fe-00fd-49ef-b3d6-949a0286d2c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43133,DS-898e36b1-9153-4c75-8030-a1cb55d59abf,DISK], DatanodeInfoWithStorage[127.0.0.1:36630,DS-9dff9416-de45-4ca6-82fd-234a120ccd12,DISK], DatanodeInfoWithStorage[127.0.0.1:33280,DS-bfe006a2-2b76-4c07-a64e-024c32670c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:34969,DS-2afddf7c-af71-45ea-bcac-e35a54ad76aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45500,DS-ad42846c-1af7-44d3-a9db-e5e2cf25bdd0,DISK], DatanodeInfoWithStorage[127.0.0.1:34135,DS-79c416a2-d704-45ae-80e1-adf3d83d89da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-637163239-172.17.0.6-1596989110861:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39538,DS-dc47b68f-a8eb-4a0c-b53e-f73df0bc0d75,DISK], DatanodeInfoWithStorage[127.0.0.1:36152,DS-6fbb07fe-00fd-49ef-b3d6-949a0286d2c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43133,DS-898e36b1-9153-4c75-8030-a1cb55d59abf,DISK], DatanodeInfoWithStorage[127.0.0.1:36630,DS-9dff9416-de45-4ca6-82fd-234a120ccd12,DISK], DatanodeInfoWithStorage[127.0.0.1:33280,DS-bfe006a2-2b76-4c07-a64e-024c32670c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:34969,DS-2afddf7c-af71-45ea-bcac-e35a54ad76aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45500,DS-ad42846c-1af7-44d3-a9db-e5e2cf25bdd0,DISK], DatanodeInfoWithStorage[127.0.0.1:34135,DS-79c416a2-d704-45ae-80e1-adf3d83d89da,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 6789
