reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1248798984-172.17.0.9-1596923780007:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40611,DS-77a889c2-be5d-4795-908f-ab80d93f883d,DISK], DatanodeInfoWithStorage[127.0.0.1:46651,DS-627f7a66-38f2-4991-9630-9749dd14f628,DISK], DatanodeInfoWithStorage[127.0.0.1:37897,DS-990d8ba1-a24a-4874-b840-9f7eeaf28ffd,DISK], DatanodeInfoWithStorage[127.0.0.1:45460,DS-0048040b-5aa3-4b69-8f0b-a2c00399d246,DISK], DatanodeInfoWithStorage[127.0.0.1:36093,DS-895e5a99-9c6a-4e6c-96b9-0aa5821336a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34035,DS-10b45b37-0473-4b10-9af8-c4ba92c8a8cc,DISK], DatanodeInfoWithStorage[127.0.0.1:32791,DS-35bb8216-c6be-4912-95ae-e12cd0d3b185,DISK], DatanodeInfoWithStorage[127.0.0.1:45214,DS-8097a8d7-4e63-4d87-a983-124e169f13d3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1248798984-172.17.0.9-1596923780007:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40611,DS-77a889c2-be5d-4795-908f-ab80d93f883d,DISK], DatanodeInfoWithStorage[127.0.0.1:46651,DS-627f7a66-38f2-4991-9630-9749dd14f628,DISK], DatanodeInfoWithStorage[127.0.0.1:37897,DS-990d8ba1-a24a-4874-b840-9f7eeaf28ffd,DISK], DatanodeInfoWithStorage[127.0.0.1:45460,DS-0048040b-5aa3-4b69-8f0b-a2c00399d246,DISK], DatanodeInfoWithStorage[127.0.0.1:36093,DS-895e5a99-9c6a-4e6c-96b9-0aa5821336a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34035,DS-10b45b37-0473-4b10-9af8-c4ba92c8a8cc,DISK], DatanodeInfoWithStorage[127.0.0.1:32791,DS-35bb8216-c6be-4912-95ae-e12cd0d3b185,DISK], DatanodeInfoWithStorage[127.0.0.1:45214,DS-8097a8d7-4e63-4d87-a983-124e169f13d3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1094150652-172.17.0.9-1596924307479:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40462,DS-b16bde61-ca4c-47e9-9cf8-f121e2104fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:38701,DS-c64d8d5a-5c0e-46b4-ae63-b3a975796237,DISK], DatanodeInfoWithStorage[127.0.0.1:34079,DS-6119d64b-e10a-4ade-b9b5-00322990e221,DISK], DatanodeInfoWithStorage[127.0.0.1:34075,DS-3b65a237-9572-4d12-ae7f-58402612ac01,DISK], DatanodeInfoWithStorage[127.0.0.1:41735,DS-2039090a-237f-4dcb-a3ce-667feda92418,DISK], DatanodeInfoWithStorage[127.0.0.1:35125,DS-ce7b03b5-05b3-4aef-a0c4-a94b9be8646f,DISK], DatanodeInfoWithStorage[127.0.0.1:38767,DS-a5857580-b35a-4f62-a76d-40ffd179226a,DISK], DatanodeInfoWithStorage[127.0.0.1:45579,DS-ca8fd350-e641-4004-8447-ae999fd74144,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1094150652-172.17.0.9-1596924307479:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40462,DS-b16bde61-ca4c-47e9-9cf8-f121e2104fd7,DISK], DatanodeInfoWithStorage[127.0.0.1:38701,DS-c64d8d5a-5c0e-46b4-ae63-b3a975796237,DISK], DatanodeInfoWithStorage[127.0.0.1:34079,DS-6119d64b-e10a-4ade-b9b5-00322990e221,DISK], DatanodeInfoWithStorage[127.0.0.1:34075,DS-3b65a237-9572-4d12-ae7f-58402612ac01,DISK], DatanodeInfoWithStorage[127.0.0.1:41735,DS-2039090a-237f-4dcb-a3ce-667feda92418,DISK], DatanodeInfoWithStorage[127.0.0.1:35125,DS-ce7b03b5-05b3-4aef-a0c4-a94b9be8646f,DISK], DatanodeInfoWithStorage[127.0.0.1:38767,DS-a5857580-b35a-4f62-a76d-40ffd179226a,DISK], DatanodeInfoWithStorage[127.0.0.1:45579,DS-ca8fd350-e641-4004-8447-ae999fd74144,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-894795278-172.17.0.9-1596924341642:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34752,DS-ec9cb51b-5a03-4525-bd5b-5d4808e847fa,DISK], DatanodeInfoWithStorage[127.0.0.1:32776,DS-2b7e3c97-6c18-4812-9287-3881290f3629,DISK], DatanodeInfoWithStorage[127.0.0.1:40869,DS-ab837014-c73f-476d-ab53-4bcf6d038470,DISK], DatanodeInfoWithStorage[127.0.0.1:41464,DS-7baaa021-44fc-4c03-8915-4ce09cf8e425,DISK], DatanodeInfoWithStorage[127.0.0.1:34202,DS-b919a9b6-cd4d-4aa5-b336-7d31200f8e39,DISK], DatanodeInfoWithStorage[127.0.0.1:33015,DS-19c18867-b6ec-4273-8adf-4177dd23bd8b,DISK], DatanodeInfoWithStorage[127.0.0.1:46288,DS-70c9094b-cddc-46e7-bdc1-765aef602b84,DISK], DatanodeInfoWithStorage[127.0.0.1:41642,DS-5e67c904-c9c2-4415-b7fc-96b2873097d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-894795278-172.17.0.9-1596924341642:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34752,DS-ec9cb51b-5a03-4525-bd5b-5d4808e847fa,DISK], DatanodeInfoWithStorage[127.0.0.1:32776,DS-2b7e3c97-6c18-4812-9287-3881290f3629,DISK], DatanodeInfoWithStorage[127.0.0.1:40869,DS-ab837014-c73f-476d-ab53-4bcf6d038470,DISK], DatanodeInfoWithStorage[127.0.0.1:41464,DS-7baaa021-44fc-4c03-8915-4ce09cf8e425,DISK], DatanodeInfoWithStorage[127.0.0.1:34202,DS-b919a9b6-cd4d-4aa5-b336-7d31200f8e39,DISK], DatanodeInfoWithStorage[127.0.0.1:33015,DS-19c18867-b6ec-4273-8adf-4177dd23bd8b,DISK], DatanodeInfoWithStorage[127.0.0.1:46288,DS-70c9094b-cddc-46e7-bdc1-765aef602b84,DISK], DatanodeInfoWithStorage[127.0.0.1:41642,DS-5e67c904-c9c2-4415-b7fc-96b2873097d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-25960420-172.17.0.9-1596924419517:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35047,DS-e472210d-c10a-4e12-83cf-f127117370a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36165,DS-03804cbd-94f6-4039-9f3d-413f1c1b961a,DISK], DatanodeInfoWithStorage[127.0.0.1:32775,DS-f4b2f02c-55fa-40e7-a91f-f8255dec5943,DISK], DatanodeInfoWithStorage[127.0.0.1:43608,DS-4538b879-ef91-47e3-9d46-09e08959b28f,DISK], DatanodeInfoWithStorage[127.0.0.1:37777,DS-bbeb3142-a6df-4412-bab4-7e35d35b0ca0,DISK], DatanodeInfoWithStorage[127.0.0.1:37079,DS-b780829d-42f8-494c-9e4a-b79920c69561,DISK], DatanodeInfoWithStorage[127.0.0.1:45285,DS-775d52cf-9f3e-4da4-8742-2962b2897a21,DISK], DatanodeInfoWithStorage[127.0.0.1:34639,DS-e8f7f159-ffac-444b-a804-cf208f0d89bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-25960420-172.17.0.9-1596924419517:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35047,DS-e472210d-c10a-4e12-83cf-f127117370a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36165,DS-03804cbd-94f6-4039-9f3d-413f1c1b961a,DISK], DatanodeInfoWithStorage[127.0.0.1:32775,DS-f4b2f02c-55fa-40e7-a91f-f8255dec5943,DISK], DatanodeInfoWithStorage[127.0.0.1:43608,DS-4538b879-ef91-47e3-9d46-09e08959b28f,DISK], DatanodeInfoWithStorage[127.0.0.1:37777,DS-bbeb3142-a6df-4412-bab4-7e35d35b0ca0,DISK], DatanodeInfoWithStorage[127.0.0.1:37079,DS-b780829d-42f8-494c-9e4a-b79920c69561,DISK], DatanodeInfoWithStorage[127.0.0.1:45285,DS-775d52cf-9f3e-4da4-8742-2962b2897a21,DISK], DatanodeInfoWithStorage[127.0.0.1:34639,DS-e8f7f159-ffac-444b-a804-cf208f0d89bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-282408600-172.17.0.9-1596924986539:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35706,DS-767cf1d3-9f58-44b8-87a4-04363670e924,DISK], DatanodeInfoWithStorage[127.0.0.1:35570,DS-0555f822-5958-4159-a574-b972adcc321f,DISK], DatanodeInfoWithStorage[127.0.0.1:38764,DS-1e31e2a6-f303-4abf-8e72-0c24400c8c77,DISK], DatanodeInfoWithStorage[127.0.0.1:35141,DS-bf6827ba-fb87-4c8a-a67c-d029580a2f97,DISK], DatanodeInfoWithStorage[127.0.0.1:42349,DS-72caf327-4eb6-47c9-a956-a56e311700de,DISK], DatanodeInfoWithStorage[127.0.0.1:34345,DS-40d8e02b-985a-4884-a488-b4f9c0e8a559,DISK], DatanodeInfoWithStorage[127.0.0.1:35692,DS-7e592b2d-eecc-4650-a684-1bf11d45450b,DISK], DatanodeInfoWithStorage[127.0.0.1:33172,DS-49070718-f264-4ba3-8049-a1cae7e9cce0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-282408600-172.17.0.9-1596924986539:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35706,DS-767cf1d3-9f58-44b8-87a4-04363670e924,DISK], DatanodeInfoWithStorage[127.0.0.1:35570,DS-0555f822-5958-4159-a574-b972adcc321f,DISK], DatanodeInfoWithStorage[127.0.0.1:38764,DS-1e31e2a6-f303-4abf-8e72-0c24400c8c77,DISK], DatanodeInfoWithStorage[127.0.0.1:35141,DS-bf6827ba-fb87-4c8a-a67c-d029580a2f97,DISK], DatanodeInfoWithStorage[127.0.0.1:42349,DS-72caf327-4eb6-47c9-a956-a56e311700de,DISK], DatanodeInfoWithStorage[127.0.0.1:34345,DS-40d8e02b-985a-4884-a488-b4f9c0e8a559,DISK], DatanodeInfoWithStorage[127.0.0.1:35692,DS-7e592b2d-eecc-4650-a684-1bf11d45450b,DISK], DatanodeInfoWithStorage[127.0.0.1:33172,DS-49070718-f264-4ba3-8049-a1cae7e9cce0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-813417532-172.17.0.9-1596925196179:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34530,DS-f0f80c94-51b2-42d0-8d0c-a5e35f5ca072,DISK], DatanodeInfoWithStorage[127.0.0.1:40852,DS-26c6728c-2e9e-493d-9b75-3e6700933283,DISK], DatanodeInfoWithStorage[127.0.0.1:42681,DS-8f76412b-3a55-4789-96b1-cdc67b9faf93,DISK], DatanodeInfoWithStorage[127.0.0.1:44088,DS-d84db2e2-2c27-4340-83d1-4a88cca22e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:46649,DS-6b5abd60-c84c-4568-808c-4fa311a7bbf6,DISK], DatanodeInfoWithStorage[127.0.0.1:35443,DS-89d6a64b-09fb-4501-a039-1a54592c3aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:45366,DS-d1f374f4-c7b5-4350-b2c2-7a934b216d33,DISK], DatanodeInfoWithStorage[127.0.0.1:33314,DS-e508070a-cd16-4dd0-9cca-daeb85427970,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-813417532-172.17.0.9-1596925196179:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34530,DS-f0f80c94-51b2-42d0-8d0c-a5e35f5ca072,DISK], DatanodeInfoWithStorage[127.0.0.1:40852,DS-26c6728c-2e9e-493d-9b75-3e6700933283,DISK], DatanodeInfoWithStorage[127.0.0.1:42681,DS-8f76412b-3a55-4789-96b1-cdc67b9faf93,DISK], DatanodeInfoWithStorage[127.0.0.1:44088,DS-d84db2e2-2c27-4340-83d1-4a88cca22e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:46649,DS-6b5abd60-c84c-4568-808c-4fa311a7bbf6,DISK], DatanodeInfoWithStorage[127.0.0.1:35443,DS-89d6a64b-09fb-4501-a039-1a54592c3aa1,DISK], DatanodeInfoWithStorage[127.0.0.1:45366,DS-d1f374f4-c7b5-4350-b2c2-7a934b216d33,DISK], DatanodeInfoWithStorage[127.0.0.1:33314,DS-e508070a-cd16-4dd0-9cca-daeb85427970,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-909146720-172.17.0.9-1596925411601:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42001,DS-4ea64af1-f36b-48ef-bf57-d567ba43e433,DISK], DatanodeInfoWithStorage[127.0.0.1:42691,DS-1650cb96-e88f-4f23-9266-c4fa23505976,DISK], DatanodeInfoWithStorage[127.0.0.1:37729,DS-91e88518-9638-423e-94ac-b8e5bd3bf077,DISK], DatanodeInfoWithStorage[127.0.0.1:45134,DS-2d6f8592-ef56-4694-a6ce-a217aa5d1217,DISK], DatanodeInfoWithStorage[127.0.0.1:33561,DS-f1fefa95-4efa-4386-ae7e-5ecbd3da2119,DISK], DatanodeInfoWithStorage[127.0.0.1:33679,DS-7d3209b2-e15a-4784-85f4-ae0c66e0fa7d,DISK], DatanodeInfoWithStorage[127.0.0.1:36655,DS-6672ce58-81ba-4a11-bb46-37ff3c634b48,DISK], DatanodeInfoWithStorage[127.0.0.1:33929,DS-e74aeeab-1955-4fe1-9059-e1e7bc41b797,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-909146720-172.17.0.9-1596925411601:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42001,DS-4ea64af1-f36b-48ef-bf57-d567ba43e433,DISK], DatanodeInfoWithStorage[127.0.0.1:42691,DS-1650cb96-e88f-4f23-9266-c4fa23505976,DISK], DatanodeInfoWithStorage[127.0.0.1:37729,DS-91e88518-9638-423e-94ac-b8e5bd3bf077,DISK], DatanodeInfoWithStorage[127.0.0.1:45134,DS-2d6f8592-ef56-4694-a6ce-a217aa5d1217,DISK], DatanodeInfoWithStorage[127.0.0.1:33561,DS-f1fefa95-4efa-4386-ae7e-5ecbd3da2119,DISK], DatanodeInfoWithStorage[127.0.0.1:33679,DS-7d3209b2-e15a-4784-85f4-ae0c66e0fa7d,DISK], DatanodeInfoWithStorage[127.0.0.1:36655,DS-6672ce58-81ba-4a11-bb46-37ff3c634b48,DISK], DatanodeInfoWithStorage[127.0.0.1:33929,DS-e74aeeab-1955-4fe1-9059-e1e7bc41b797,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1378339531-172.17.0.9-1596925447738:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46658,DS-7a247cad-dee1-42d1-a472-1b8f383c1803,DISK], DatanodeInfoWithStorage[127.0.0.1:37089,DS-d7e1f9a3-e52c-4448-995d-dc80afc7bd73,DISK], DatanodeInfoWithStorage[127.0.0.1:40258,DS-edba5429-13aa-4432-afe7-6fe821cec99c,DISK], DatanodeInfoWithStorage[127.0.0.1:32797,DS-dddcd4a4-0ddb-4254-99c8-3e299be66c73,DISK], DatanodeInfoWithStorage[127.0.0.1:44739,DS-7f256cdc-07d3-41c1-994b-77714efc8c9a,DISK], DatanodeInfoWithStorage[127.0.0.1:34513,DS-c30d2b55-da7e-4378-9b06-84b474fabdb7,DISK], DatanodeInfoWithStorage[127.0.0.1:41971,DS-d357b79f-6ac7-4a75-8e6c-723ebd47d3e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39176,DS-b194a867-cd16-433a-92b1-451d39feb04c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1378339531-172.17.0.9-1596925447738:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46658,DS-7a247cad-dee1-42d1-a472-1b8f383c1803,DISK], DatanodeInfoWithStorage[127.0.0.1:37089,DS-d7e1f9a3-e52c-4448-995d-dc80afc7bd73,DISK], DatanodeInfoWithStorage[127.0.0.1:40258,DS-edba5429-13aa-4432-afe7-6fe821cec99c,DISK], DatanodeInfoWithStorage[127.0.0.1:32797,DS-dddcd4a4-0ddb-4254-99c8-3e299be66c73,DISK], DatanodeInfoWithStorage[127.0.0.1:44739,DS-7f256cdc-07d3-41c1-994b-77714efc8c9a,DISK], DatanodeInfoWithStorage[127.0.0.1:34513,DS-c30d2b55-da7e-4378-9b06-84b474fabdb7,DISK], DatanodeInfoWithStorage[127.0.0.1:41971,DS-d357b79f-6ac7-4a75-8e6c-723ebd47d3e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39176,DS-b194a867-cd16-433a-92b1-451d39feb04c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-219276630-172.17.0.9-1596925552959:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41203,DS-48de2183-fd2d-4daf-95a8-3f498836221d,DISK], DatanodeInfoWithStorage[127.0.0.1:44608,DS-8abd0608-57c5-4909-9b68-7f4a8af6dce3,DISK], DatanodeInfoWithStorage[127.0.0.1:39444,DS-b9d34b95-e0db-4598-b3e7-a96190b76f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:32774,DS-27419e32-b24b-45e3-9b85-3345e7b76d81,DISK], DatanodeInfoWithStorage[127.0.0.1:46453,DS-e26d5521-b050-4f4f-b8ce-c3f7d7f0ed08,DISK], DatanodeInfoWithStorage[127.0.0.1:33915,DS-85c896bc-d1b4-4096-bdf7-4b367e780ad4,DISK], DatanodeInfoWithStorage[127.0.0.1:39833,DS-efbcb176-768d-46b3-bf98-df936f7a9785,DISK], DatanodeInfoWithStorage[127.0.0.1:33371,DS-aa237e82-bfca-4ca1-ab2c-e26e0d276b00,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-219276630-172.17.0.9-1596925552959:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41203,DS-48de2183-fd2d-4daf-95a8-3f498836221d,DISK], DatanodeInfoWithStorage[127.0.0.1:44608,DS-8abd0608-57c5-4909-9b68-7f4a8af6dce3,DISK], DatanodeInfoWithStorage[127.0.0.1:39444,DS-b9d34b95-e0db-4598-b3e7-a96190b76f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:32774,DS-27419e32-b24b-45e3-9b85-3345e7b76d81,DISK], DatanodeInfoWithStorage[127.0.0.1:46453,DS-e26d5521-b050-4f4f-b8ce-c3f7d7f0ed08,DISK], DatanodeInfoWithStorage[127.0.0.1:33915,DS-85c896bc-d1b4-4096-bdf7-4b367e780ad4,DISK], DatanodeInfoWithStorage[127.0.0.1:39833,DS-efbcb176-768d-46b3-bf98-df936f7a9785,DISK], DatanodeInfoWithStorage[127.0.0.1:33371,DS-aa237e82-bfca-4ca1-ab2c-e26e0d276b00,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1764528327-172.17.0.9-1596925787304:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43660,DS-eb500ded-be46-4e45-a24d-c2ae6a7cadca,DISK], DatanodeInfoWithStorage[127.0.0.1:39568,DS-ff166e1c-18b2-4dc5-b4f2-9b537f907590,DISK], DatanodeInfoWithStorage[127.0.0.1:37778,DS-fd5ab3b9-07de-45af-a67e-b589fd23d2d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34741,DS-cfcce736-8bee-4586-a500-5e4b13e593ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43586,DS-4cc77640-dfc4-4836-ba67-f992c076c690,DISK], DatanodeInfoWithStorage[127.0.0.1:43722,DS-dd637ff6-444d-4979-90ee-be823a47704d,DISK], DatanodeInfoWithStorage[127.0.0.1:45914,DS-90346bb4-25d9-46a8-9528-80b300e10b81,DISK], DatanodeInfoWithStorage[127.0.0.1:34328,DS-0585d613-6047-4718-9061-d6a26da1ffb9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1764528327-172.17.0.9-1596925787304:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43660,DS-eb500ded-be46-4e45-a24d-c2ae6a7cadca,DISK], DatanodeInfoWithStorage[127.0.0.1:39568,DS-ff166e1c-18b2-4dc5-b4f2-9b537f907590,DISK], DatanodeInfoWithStorage[127.0.0.1:37778,DS-fd5ab3b9-07de-45af-a67e-b589fd23d2d9,DISK], DatanodeInfoWithStorage[127.0.0.1:34741,DS-cfcce736-8bee-4586-a500-5e4b13e593ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43586,DS-4cc77640-dfc4-4836-ba67-f992c076c690,DISK], DatanodeInfoWithStorage[127.0.0.1:43722,DS-dd637ff6-444d-4979-90ee-be823a47704d,DISK], DatanodeInfoWithStorage[127.0.0.1:45914,DS-90346bb4-25d9-46a8-9528-80b300e10b81,DISK], DatanodeInfoWithStorage[127.0.0.1:34328,DS-0585d613-6047-4718-9061-d6a26da1ffb9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-901713536-172.17.0.9-1596925846414:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37315,DS-4f469a90-49e9-4fe9-acf8-9591c0456ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:41268,DS-47bb03e2-fad3-4222-8943-058856c8a048,DISK], DatanodeInfoWithStorage[127.0.0.1:46607,DS-3b7ff5fb-e768-4bcc-aef3-5d053fcec1cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35776,DS-381aeb29-a933-4f05-9959-cb77637d1037,DISK], DatanodeInfoWithStorage[127.0.0.1:34582,DS-39803000-3f7a-4cd6-8816-eb957dace760,DISK], DatanodeInfoWithStorage[127.0.0.1:39490,DS-952b8f09-6bdc-4682-8d27-9e946bfe5448,DISK], DatanodeInfoWithStorage[127.0.0.1:33832,DS-1fa5ad2b-f6dd-43f6-ae76-fbaf3a2aab8d,DISK], DatanodeInfoWithStorage[127.0.0.1:39693,DS-678da525-64fd-491a-ba55-2674e687f836,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-901713536-172.17.0.9-1596925846414:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37315,DS-4f469a90-49e9-4fe9-acf8-9591c0456ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:41268,DS-47bb03e2-fad3-4222-8943-058856c8a048,DISK], DatanodeInfoWithStorage[127.0.0.1:46607,DS-3b7ff5fb-e768-4bcc-aef3-5d053fcec1cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35776,DS-381aeb29-a933-4f05-9959-cb77637d1037,DISK], DatanodeInfoWithStorage[127.0.0.1:34582,DS-39803000-3f7a-4cd6-8816-eb957dace760,DISK], DatanodeInfoWithStorage[127.0.0.1:39490,DS-952b8f09-6bdc-4682-8d27-9e946bfe5448,DISK], DatanodeInfoWithStorage[127.0.0.1:33832,DS-1fa5ad2b-f6dd-43f6-ae76-fbaf3a2aab8d,DISK], DatanodeInfoWithStorage[127.0.0.1:39693,DS-678da525-64fd-491a-ba55-2674e687f836,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1485105999-172.17.0.9-1596925882599:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40525,DS-ab7c0d6c-4a3b-4175-a912-5a43c70b29d1,DISK], DatanodeInfoWithStorage[127.0.0.1:33004,DS-9800dee9-8dc0-4748-96ca-9359ce1ba2ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36461,DS-6997c2b7-230d-47db-be3a-c6dba9df580b,DISK], DatanodeInfoWithStorage[127.0.0.1:34573,DS-9987524b-ee38-48a9-af1c-67a6957b1500,DISK], DatanodeInfoWithStorage[127.0.0.1:43736,DS-bb8afacc-efc1-4af9-9c3c-078a6d5627df,DISK], DatanodeInfoWithStorage[127.0.0.1:46250,DS-bdb9e739-51c8-4433-beaf-11395c8feabc,DISK], DatanodeInfoWithStorage[127.0.0.1:41988,DS-f6488140-aad9-4269-a6d0-a2ddf74fecc9,DISK], DatanodeInfoWithStorage[127.0.0.1:42598,DS-dd74dd82-878c-4f63-b845-c624cbe68097,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1485105999-172.17.0.9-1596925882599:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40525,DS-ab7c0d6c-4a3b-4175-a912-5a43c70b29d1,DISK], DatanodeInfoWithStorage[127.0.0.1:33004,DS-9800dee9-8dc0-4748-96ca-9359ce1ba2ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36461,DS-6997c2b7-230d-47db-be3a-c6dba9df580b,DISK], DatanodeInfoWithStorage[127.0.0.1:34573,DS-9987524b-ee38-48a9-af1c-67a6957b1500,DISK], DatanodeInfoWithStorage[127.0.0.1:43736,DS-bb8afacc-efc1-4af9-9c3c-078a6d5627df,DISK], DatanodeInfoWithStorage[127.0.0.1:46250,DS-bdb9e739-51c8-4433-beaf-11395c8feabc,DISK], DatanodeInfoWithStorage[127.0.0.1:41988,DS-f6488140-aad9-4269-a6d0-a2ddf74fecc9,DISK], DatanodeInfoWithStorage[127.0.0.1:42598,DS-dd74dd82-878c-4f63-b845-c624cbe68097,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1029487733-172.17.0.9-1596926102013:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39677,DS-274ee161-42f1-4c34-a49f-ceffaf460725,DISK], DatanodeInfoWithStorage[127.0.0.1:35875,DS-0bd032e2-8003-4940-b426-c10f0809a974,DISK], DatanodeInfoWithStorage[127.0.0.1:32783,DS-749182b0-b25e-4c24-af02-7be31db1922b,DISK], DatanodeInfoWithStorage[127.0.0.1:38053,DS-f4b5d0fc-c6c2-4d70-9634-5d6d821551f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44556,DS-6e5e21bc-96a5-4ea6-9a29-17e39c7bef2a,DISK], DatanodeInfoWithStorage[127.0.0.1:45011,DS-3a781c76-aab2-4c5e-9f8f-b09e345a3bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:41557,DS-2d2eec5f-ec4a-406b-b93b-32678dffaafa,DISK], DatanodeInfoWithStorage[127.0.0.1:44604,DS-c3c3a8a0-141a-49f5-86fa-f070f8ae24f0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1029487733-172.17.0.9-1596926102013:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39677,DS-274ee161-42f1-4c34-a49f-ceffaf460725,DISK], DatanodeInfoWithStorage[127.0.0.1:35875,DS-0bd032e2-8003-4940-b426-c10f0809a974,DISK], DatanodeInfoWithStorage[127.0.0.1:32783,DS-749182b0-b25e-4c24-af02-7be31db1922b,DISK], DatanodeInfoWithStorage[127.0.0.1:38053,DS-f4b5d0fc-c6c2-4d70-9634-5d6d821551f9,DISK], DatanodeInfoWithStorage[127.0.0.1:44556,DS-6e5e21bc-96a5-4ea6-9a29-17e39c7bef2a,DISK], DatanodeInfoWithStorage[127.0.0.1:45011,DS-3a781c76-aab2-4c5e-9f8f-b09e345a3bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:41557,DS-2d2eec5f-ec4a-406b-b93b-32678dffaafa,DISK], DatanodeInfoWithStorage[127.0.0.1:44604,DS-c3c3a8a0-141a-49f5-86fa-f070f8ae24f0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-439877326-172.17.0.9-1596926130952:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45828,DS-7d69f19b-f24f-47ba-b87e-a7c4ba542659,DISK], DatanodeInfoWithStorage[127.0.0.1:33215,DS-b480ec41-77fd-4078-a03c-03af859aeb14,DISK], DatanodeInfoWithStorage[127.0.0.1:46781,DS-ae544e6b-980f-484d-a165-c33829c50043,DISK], DatanodeInfoWithStorage[127.0.0.1:38516,DS-c7d9d0a4-ca2a-4872-8499-4b937f7740a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42585,DS-8f2ade78-aee6-45c6-b23d-78a8b7db7c34,DISK], DatanodeInfoWithStorage[127.0.0.1:44530,DS-f7031f25-4fbf-439e-8f8a-45ec2678dece,DISK], DatanodeInfoWithStorage[127.0.0.1:40272,DS-6af46d76-9336-4fff-a955-db2799097e55,DISK], DatanodeInfoWithStorage[127.0.0.1:41339,DS-d1bbf39e-1048-4dc8-90ab-0c8b317692f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-439877326-172.17.0.9-1596926130952:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45828,DS-7d69f19b-f24f-47ba-b87e-a7c4ba542659,DISK], DatanodeInfoWithStorage[127.0.0.1:33215,DS-b480ec41-77fd-4078-a03c-03af859aeb14,DISK], DatanodeInfoWithStorage[127.0.0.1:46781,DS-ae544e6b-980f-484d-a165-c33829c50043,DISK], DatanodeInfoWithStorage[127.0.0.1:38516,DS-c7d9d0a4-ca2a-4872-8499-4b937f7740a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42585,DS-8f2ade78-aee6-45c6-b23d-78a8b7db7c34,DISK], DatanodeInfoWithStorage[127.0.0.1:44530,DS-f7031f25-4fbf-439e-8f8a-45ec2678dece,DISK], DatanodeInfoWithStorage[127.0.0.1:40272,DS-6af46d76-9336-4fff-a955-db2799097e55,DISK], DatanodeInfoWithStorage[127.0.0.1:41339,DS-d1bbf39e-1048-4dc8-90ab-0c8b317692f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-957230940-172.17.0.9-1596926219132:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41432,DS-7e502716-7ef1-4838-9d5d-6240ab1ca3bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41002,DS-5041b27b-b9e6-4e71-b2db-0d428e2ebed4,DISK], DatanodeInfoWithStorage[127.0.0.1:40515,DS-c5652ede-c8bd-4582-8c1e-04b4cfda164b,DISK], DatanodeInfoWithStorage[127.0.0.1:40056,DS-e1d07879-10c3-4a01-8147-eb874b0849ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43360,DS-e5fc2346-1fe1-4a07-b256-bebef6bb2261,DISK], DatanodeInfoWithStorage[127.0.0.1:38158,DS-a1410c7c-a552-4fed-b84f-c3cf3d21ca09,DISK], DatanodeInfoWithStorage[127.0.0.1:36526,DS-741c93d2-be0d-4bc1-abdc-b3a14468bee4,DISK], DatanodeInfoWithStorage[127.0.0.1:43038,DS-b04f2c0e-fd0e-4f6f-a200-f6bf5b31cb1f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-957230940-172.17.0.9-1596926219132:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41432,DS-7e502716-7ef1-4838-9d5d-6240ab1ca3bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41002,DS-5041b27b-b9e6-4e71-b2db-0d428e2ebed4,DISK], DatanodeInfoWithStorage[127.0.0.1:40515,DS-c5652ede-c8bd-4582-8c1e-04b4cfda164b,DISK], DatanodeInfoWithStorage[127.0.0.1:40056,DS-e1d07879-10c3-4a01-8147-eb874b0849ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43360,DS-e5fc2346-1fe1-4a07-b256-bebef6bb2261,DISK], DatanodeInfoWithStorage[127.0.0.1:38158,DS-a1410c7c-a552-4fed-b84f-c3cf3d21ca09,DISK], DatanodeInfoWithStorage[127.0.0.1:36526,DS-741c93d2-be0d-4bc1-abdc-b3a14468bee4,DISK], DatanodeInfoWithStorage[127.0.0.1:43038,DS-b04f2c0e-fd0e-4f6f-a200-f6bf5b31cb1f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-236524333-172.17.0.9-1596926771884:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44458,DS-76ad282e-77b0-4db1-a2fc-fea0c1a5c00d,DISK], DatanodeInfoWithStorage[127.0.0.1:40763,DS-abb6ef63-2ddd-490c-8a53-e13d8727bf4e,DISK], DatanodeInfoWithStorage[127.0.0.1:39593,DS-cddcdce0-abc5-489c-a6ec-bd94c4bebb7e,DISK], DatanodeInfoWithStorage[127.0.0.1:43405,DS-5066498f-d577-4683-8c9c-5f87d1ec1dc4,DISK], DatanodeInfoWithStorage[127.0.0.1:42502,DS-3f3b4e2c-3eb0-43b2-bd42-15b8221891ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35286,DS-1db6e0f9-9743-4491-b5be-6ecf49369edf,DISK], DatanodeInfoWithStorage[127.0.0.1:42835,DS-abd50d07-05c9-4dd1-99b7-24b007d71ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:34499,DS-8180abc9-e921-47fb-a261-0e96d8e0b705,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-236524333-172.17.0.9-1596926771884:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44458,DS-76ad282e-77b0-4db1-a2fc-fea0c1a5c00d,DISK], DatanodeInfoWithStorage[127.0.0.1:40763,DS-abb6ef63-2ddd-490c-8a53-e13d8727bf4e,DISK], DatanodeInfoWithStorage[127.0.0.1:39593,DS-cddcdce0-abc5-489c-a6ec-bd94c4bebb7e,DISK], DatanodeInfoWithStorage[127.0.0.1:43405,DS-5066498f-d577-4683-8c9c-5f87d1ec1dc4,DISK], DatanodeInfoWithStorage[127.0.0.1:42502,DS-3f3b4e2c-3eb0-43b2-bd42-15b8221891ec,DISK], DatanodeInfoWithStorage[127.0.0.1:35286,DS-1db6e0f9-9743-4491-b5be-6ecf49369edf,DISK], DatanodeInfoWithStorage[127.0.0.1:42835,DS-abd50d07-05c9-4dd1-99b7-24b007d71ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:34499,DS-8180abc9-e921-47fb-a261-0e96d8e0b705,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1552557549-172.17.0.9-1596926948324:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35124,DS-b914f26c-a9da-4b37-9921-cc123374e55b,DISK], DatanodeInfoWithStorage[127.0.0.1:34631,DS-11785b18-529f-4ea4-85d3-6e284b3c6e10,DISK], DatanodeInfoWithStorage[127.0.0.1:42606,DS-911c5eaa-4565-47b6-93e7-f810bf730771,DISK], DatanodeInfoWithStorage[127.0.0.1:42698,DS-2c558fec-94b9-415c-beb1-fd768fea3334,DISK], DatanodeInfoWithStorage[127.0.0.1:41396,DS-5a3ab028-a283-41e9-8c91-67429c33a17c,DISK], DatanodeInfoWithStorage[127.0.0.1:36572,DS-cbee5563-597c-480b-8a1d-5049c108e9df,DISK], DatanodeInfoWithStorage[127.0.0.1:42237,DS-d5743b25-9806-4c47-9437-c2a2cfd5e0fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42860,DS-cac869c6-2ee7-474e-beed-e7e7c20d98e2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1552557549-172.17.0.9-1596926948324:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35124,DS-b914f26c-a9da-4b37-9921-cc123374e55b,DISK], DatanodeInfoWithStorage[127.0.0.1:34631,DS-11785b18-529f-4ea4-85d3-6e284b3c6e10,DISK], DatanodeInfoWithStorage[127.0.0.1:42606,DS-911c5eaa-4565-47b6-93e7-f810bf730771,DISK], DatanodeInfoWithStorage[127.0.0.1:42698,DS-2c558fec-94b9-415c-beb1-fd768fea3334,DISK], DatanodeInfoWithStorage[127.0.0.1:41396,DS-5a3ab028-a283-41e9-8c91-67429c33a17c,DISK], DatanodeInfoWithStorage[127.0.0.1:36572,DS-cbee5563-597c-480b-8a1d-5049c108e9df,DISK], DatanodeInfoWithStorage[127.0.0.1:42237,DS-d5743b25-9806-4c47-9437-c2a2cfd5e0fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42860,DS-cac869c6-2ee7-474e-beed-e7e7c20d98e2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-72935074-172.17.0.9-1596927020912:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44965,DS-beddfd76-f1e1-4f01-aaa0-afc431fa4d22,DISK], DatanodeInfoWithStorage[127.0.0.1:46511,DS-3beff8d7-0078-492c-b43c-3d633e93222b,DISK], DatanodeInfoWithStorage[127.0.0.1:42450,DS-b5018106-9098-4792-8bea-8abe12f2a313,DISK], DatanodeInfoWithStorage[127.0.0.1:38070,DS-fd86fb21-eeef-4b48-bdbe-720242edd3b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35459,DS-082a01fb-411f-46cf-9792-1e9dd594b303,DISK], DatanodeInfoWithStorage[127.0.0.1:39405,DS-b7397901-01d6-49a8-9d72-b6c39ca89e27,DISK], DatanodeInfoWithStorage[127.0.0.1:37482,DS-28926c35-996f-482e-9baf-a0352ed5d0e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41662,DS-4fe5726b-542b-44c6-8319-aeb28a1dcc22,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-72935074-172.17.0.9-1596927020912:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44965,DS-beddfd76-f1e1-4f01-aaa0-afc431fa4d22,DISK], DatanodeInfoWithStorage[127.0.0.1:46511,DS-3beff8d7-0078-492c-b43c-3d633e93222b,DISK], DatanodeInfoWithStorage[127.0.0.1:42450,DS-b5018106-9098-4792-8bea-8abe12f2a313,DISK], DatanodeInfoWithStorage[127.0.0.1:38070,DS-fd86fb21-eeef-4b48-bdbe-720242edd3b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35459,DS-082a01fb-411f-46cf-9792-1e9dd594b303,DISK], DatanodeInfoWithStorage[127.0.0.1:39405,DS-b7397901-01d6-49a8-9d72-b6c39ca89e27,DISK], DatanodeInfoWithStorage[127.0.0.1:37482,DS-28926c35-996f-482e-9baf-a0352ed5d0e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41662,DS-4fe5726b-542b-44c6-8319-aeb28a1dcc22,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-418143425-172.17.0.9-1596927158936:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39097,DS-f6cb6ba4-eec2-4196-bade-1950bbccf77e,DISK], DatanodeInfoWithStorage[127.0.0.1:35086,DS-3b76c387-95b7-4567-8c6e-6c49ad7d64a4,DISK], DatanodeInfoWithStorage[127.0.0.1:38764,DS-f5b35c0c-bcff-42fb-9842-a0c2765efe3d,DISK], DatanodeInfoWithStorage[127.0.0.1:34954,DS-2152a3cb-8516-4d33-bc4b-ea5a0eec7602,DISK], DatanodeInfoWithStorage[127.0.0.1:45829,DS-5f664c3a-432c-4fd2-ba56-d97b887c628d,DISK], DatanodeInfoWithStorage[127.0.0.1:43424,DS-06227d1d-4e4e-468e-8254-74c35b2df0be,DISK], DatanodeInfoWithStorage[127.0.0.1:42698,DS-5ad892ba-6059-4b8b-84ad-3ce19ac363a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46665,DS-45bd5cb6-38a2-4e64-b116-204203a95aee,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-418143425-172.17.0.9-1596927158936:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39097,DS-f6cb6ba4-eec2-4196-bade-1950bbccf77e,DISK], DatanodeInfoWithStorage[127.0.0.1:35086,DS-3b76c387-95b7-4567-8c6e-6c49ad7d64a4,DISK], DatanodeInfoWithStorage[127.0.0.1:38764,DS-f5b35c0c-bcff-42fb-9842-a0c2765efe3d,DISK], DatanodeInfoWithStorage[127.0.0.1:34954,DS-2152a3cb-8516-4d33-bc4b-ea5a0eec7602,DISK], DatanodeInfoWithStorage[127.0.0.1:45829,DS-5f664c3a-432c-4fd2-ba56-d97b887c628d,DISK], DatanodeInfoWithStorage[127.0.0.1:43424,DS-06227d1d-4e4e-468e-8254-74c35b2df0be,DISK], DatanodeInfoWithStorage[127.0.0.1:42698,DS-5ad892ba-6059-4b8b-84ad-3ce19ac363a9,DISK], DatanodeInfoWithStorage[127.0.0.1:46665,DS-45bd5cb6-38a2-4e64-b116-204203a95aee,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1296686598-172.17.0.9-1596927259123:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38998,DS-eff12ab1-4ee2-471d-9815-c70f86d3601a,DISK], DatanodeInfoWithStorage[127.0.0.1:40472,DS-9f4ffe72-1ec7-481c-b726-3b1f45aaf9a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46511,DS-4bf655d8-b87a-45e8-8ce8-2f5e886a0ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:43312,DS-dd15c1b5-7e77-4e31-90a7-c5a201406b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:45762,DS-76efcd87-b0b3-4ece-876e-34f0693d2667,DISK], DatanodeInfoWithStorage[127.0.0.1:37320,DS-5866b661-2100-47fb-8603-aef3a9f8d070,DISK], DatanodeInfoWithStorage[127.0.0.1:40734,DS-8434347c-2c89-4671-9e19-89f4444b10e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39738,DS-3dfc7978-d7e7-4696-8a3f-318f1bdfc402,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1296686598-172.17.0.9-1596927259123:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38998,DS-eff12ab1-4ee2-471d-9815-c70f86d3601a,DISK], DatanodeInfoWithStorage[127.0.0.1:40472,DS-9f4ffe72-1ec7-481c-b726-3b1f45aaf9a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46511,DS-4bf655d8-b87a-45e8-8ce8-2f5e886a0ed7,DISK], DatanodeInfoWithStorage[127.0.0.1:43312,DS-dd15c1b5-7e77-4e31-90a7-c5a201406b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:45762,DS-76efcd87-b0b3-4ece-876e-34f0693d2667,DISK], DatanodeInfoWithStorage[127.0.0.1:37320,DS-5866b661-2100-47fb-8603-aef3a9f8d070,DISK], DatanodeInfoWithStorage[127.0.0.1:40734,DS-8434347c-2c89-4671-9e19-89f4444b10e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39738,DS-3dfc7978-d7e7-4696-8a3f-318f1bdfc402,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1332311837-172.17.0.9-1596927335550:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32988,DS-62223707-7603-41e2-9ce6-4069ee57d726,DISK], DatanodeInfoWithStorage[127.0.0.1:45195,DS-3f252da3-5c6a-4142-8c54-8dd92e03bad9,DISK], DatanodeInfoWithStorage[127.0.0.1:40063,DS-74c251fa-d62d-472f-b7f7-7818581521d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46079,DS-e7218947-3f85-4cfd-bd5f-dc37ff49e763,DISK], DatanodeInfoWithStorage[127.0.0.1:38045,DS-00c399a5-b58c-458d-a4c3-24e831387b56,DISK], DatanodeInfoWithStorage[127.0.0.1:32979,DS-947183f8-606d-4aca-845b-583ea5517ac0,DISK], DatanodeInfoWithStorage[127.0.0.1:33694,DS-fee319ac-a349-4886-92e8-85a3d7a50e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:35554,DS-de342389-d3af-4817-92af-9aa68637fa84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1332311837-172.17.0.9-1596927335550:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32988,DS-62223707-7603-41e2-9ce6-4069ee57d726,DISK], DatanodeInfoWithStorage[127.0.0.1:45195,DS-3f252da3-5c6a-4142-8c54-8dd92e03bad9,DISK], DatanodeInfoWithStorage[127.0.0.1:40063,DS-74c251fa-d62d-472f-b7f7-7818581521d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46079,DS-e7218947-3f85-4cfd-bd5f-dc37ff49e763,DISK], DatanodeInfoWithStorage[127.0.0.1:38045,DS-00c399a5-b58c-458d-a4c3-24e831387b56,DISK], DatanodeInfoWithStorage[127.0.0.1:32979,DS-947183f8-606d-4aca-845b-583ea5517ac0,DISK], DatanodeInfoWithStorage[127.0.0.1:33694,DS-fee319ac-a349-4886-92e8-85a3d7a50e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:35554,DS-de342389-d3af-4817-92af-9aa68637fa84,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-986468098-172.17.0.9-1596927472893:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41340,DS-105d5c1c-be78-47bf-b1bd-b43771377732,DISK], DatanodeInfoWithStorage[127.0.0.1:42034,DS-cd4be00c-c8c1-422b-a2eb-42c73f479f85,DISK], DatanodeInfoWithStorage[127.0.0.1:34995,DS-23726f14-5aac-4577-9f3f-a84b7e9eb75d,DISK], DatanodeInfoWithStorage[127.0.0.1:34502,DS-7ce1478e-060c-4b1e-96df-7f5050d3c7ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40980,DS-52199bdb-2f95-46ce-8456-14ad7f9dfc0d,DISK], DatanodeInfoWithStorage[127.0.0.1:37007,DS-b39b16f7-e7d7-4b0a-91d4-4d6fd77e39db,DISK], DatanodeInfoWithStorage[127.0.0.1:33528,DS-0b1ded05-d022-4cd1-a06d-f5ab8264c9d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46242,DS-d063d749-621a-4a94-99a0-cdadcfd04a5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-986468098-172.17.0.9-1596927472893:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41340,DS-105d5c1c-be78-47bf-b1bd-b43771377732,DISK], DatanodeInfoWithStorage[127.0.0.1:42034,DS-cd4be00c-c8c1-422b-a2eb-42c73f479f85,DISK], DatanodeInfoWithStorage[127.0.0.1:34995,DS-23726f14-5aac-4577-9f3f-a84b7e9eb75d,DISK], DatanodeInfoWithStorage[127.0.0.1:34502,DS-7ce1478e-060c-4b1e-96df-7f5050d3c7ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40980,DS-52199bdb-2f95-46ce-8456-14ad7f9dfc0d,DISK], DatanodeInfoWithStorage[127.0.0.1:37007,DS-b39b16f7-e7d7-4b0a-91d4-4d6fd77e39db,DISK], DatanodeInfoWithStorage[127.0.0.1:33528,DS-0b1ded05-d022-4cd1-a06d-f5ab8264c9d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46242,DS-d063d749-621a-4a94-99a0-cdadcfd04a5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1590171600-172.17.0.9-1596927580132:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37054,DS-e9f246df-5f97-4dc7-9150-4f6358b67870,DISK], DatanodeInfoWithStorage[127.0.0.1:41594,DS-8451de0c-b6c9-4d1d-945b-f1ba3d5db03e,DISK], DatanodeInfoWithStorage[127.0.0.1:38965,DS-2d82e61e-fafb-4a8a-bb3b-2bee4d35a855,DISK], DatanodeInfoWithStorage[127.0.0.1:38487,DS-5c95015c-ae08-4ff4-9c73-6f43b8112394,DISK], DatanodeInfoWithStorage[127.0.0.1:39385,DS-5693c6d8-53ba-44d3-8b74-fdc0cd9b5b82,DISK], DatanodeInfoWithStorage[127.0.0.1:33259,DS-aa939c7d-e5bc-4f99-8ee7-161331c1e2c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41038,DS-b0c3a601-3617-4a54-b4cc-7eaec557556e,DISK], DatanodeInfoWithStorage[127.0.0.1:36268,DS-86931e00-92d0-4ff6-adcc-8b1ceb8b2978,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1590171600-172.17.0.9-1596927580132:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37054,DS-e9f246df-5f97-4dc7-9150-4f6358b67870,DISK], DatanodeInfoWithStorage[127.0.0.1:41594,DS-8451de0c-b6c9-4d1d-945b-f1ba3d5db03e,DISK], DatanodeInfoWithStorage[127.0.0.1:38965,DS-2d82e61e-fafb-4a8a-bb3b-2bee4d35a855,DISK], DatanodeInfoWithStorage[127.0.0.1:38487,DS-5c95015c-ae08-4ff4-9c73-6f43b8112394,DISK], DatanodeInfoWithStorage[127.0.0.1:39385,DS-5693c6d8-53ba-44d3-8b74-fdc0cd9b5b82,DISK], DatanodeInfoWithStorage[127.0.0.1:33259,DS-aa939c7d-e5bc-4f99-8ee7-161331c1e2c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41038,DS-b0c3a601-3617-4a54-b4cc-7eaec557556e,DISK], DatanodeInfoWithStorage[127.0.0.1:36268,DS-86931e00-92d0-4ff6-adcc-8b1ceb8b2978,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1426979704-172.17.0.9-1596927734926:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34764,DS-1ac34ee1-c9d3-4388-8370-ebb64d7fda57,DISK], DatanodeInfoWithStorage[127.0.0.1:46531,DS-0b0b48d7-eef5-47b1-ac97-2667ba0b07d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44169,DS-0c00d0cd-9999-420f-be95-8d3a40bbf6a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44577,DS-a32c3ae4-680f-429c-a704-cc07cd63e020,DISK], DatanodeInfoWithStorage[127.0.0.1:38055,DS-ab905882-1249-4240-acc8-7eec28767e8d,DISK], DatanodeInfoWithStorage[127.0.0.1:45943,DS-21a68633-3fb7-429d-b046-5d5ceae6eaa7,DISK], DatanodeInfoWithStorage[127.0.0.1:34479,DS-5a65cba0-a61e-469a-b4d8-fc15b264a3f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37508,DS-e925ab9f-288c-4191-a71b-fffc0fd82dbb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1426979704-172.17.0.9-1596927734926:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34764,DS-1ac34ee1-c9d3-4388-8370-ebb64d7fda57,DISK], DatanodeInfoWithStorage[127.0.0.1:46531,DS-0b0b48d7-eef5-47b1-ac97-2667ba0b07d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44169,DS-0c00d0cd-9999-420f-be95-8d3a40bbf6a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44577,DS-a32c3ae4-680f-429c-a704-cc07cd63e020,DISK], DatanodeInfoWithStorage[127.0.0.1:38055,DS-ab905882-1249-4240-acc8-7eec28767e8d,DISK], DatanodeInfoWithStorage[127.0.0.1:45943,DS-21a68633-3fb7-429d-b046-5d5ceae6eaa7,DISK], DatanodeInfoWithStorage[127.0.0.1:34479,DS-5a65cba0-a61e-469a-b4d8-fc15b264a3f7,DISK], DatanodeInfoWithStorage[127.0.0.1:37508,DS-e925ab9f-288c-4191-a71b-fffc0fd82dbb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-949728100-172.17.0.9-1596928103254:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33857,DS-5bed586f-37c3-44ab-90d0-90851bc6f274,DISK], DatanodeInfoWithStorage[127.0.0.1:35551,DS-70b2fdc4-2725-45b2-9923-40d19d6b8ee1,DISK], DatanodeInfoWithStorage[127.0.0.1:35452,DS-f4fb18ed-c768-4cd8-8434-0a201c493b46,DISK], DatanodeInfoWithStorage[127.0.0.1:43170,DS-9b8678a9-7b48-40dd-9bff-efb6dc788076,DISK], DatanodeInfoWithStorage[127.0.0.1:34487,DS-2c76bc54-ec1a-403a-a497-4c8e938fb251,DISK], DatanodeInfoWithStorage[127.0.0.1:45402,DS-cd7d7913-915a-46bc-bff0-d443f3d804ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37015,DS-032a6356-64cd-47f5-a2ae-dfb8c0d68ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:35775,DS-9a882549-e210-40aa-8101-5ee454e9d63f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-949728100-172.17.0.9-1596928103254:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33857,DS-5bed586f-37c3-44ab-90d0-90851bc6f274,DISK], DatanodeInfoWithStorage[127.0.0.1:35551,DS-70b2fdc4-2725-45b2-9923-40d19d6b8ee1,DISK], DatanodeInfoWithStorage[127.0.0.1:35452,DS-f4fb18ed-c768-4cd8-8434-0a201c493b46,DISK], DatanodeInfoWithStorage[127.0.0.1:43170,DS-9b8678a9-7b48-40dd-9bff-efb6dc788076,DISK], DatanodeInfoWithStorage[127.0.0.1:34487,DS-2c76bc54-ec1a-403a-a497-4c8e938fb251,DISK], DatanodeInfoWithStorage[127.0.0.1:45402,DS-cd7d7913-915a-46bc-bff0-d443f3d804ae,DISK], DatanodeInfoWithStorage[127.0.0.1:37015,DS-032a6356-64cd-47f5-a2ae-dfb8c0d68ba1,DISK], DatanodeInfoWithStorage[127.0.0.1:35775,DS-9a882549-e210-40aa-8101-5ee454e9d63f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1304988879-172.17.0.9-1596928244669:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45872,DS-55018a7c-a4f5-41a0-a0a9-3075ac2be460,DISK], DatanodeInfoWithStorage[127.0.0.1:34031,DS-f2a3c681-80c1-491b-a072-4d95a021a139,DISK], DatanodeInfoWithStorage[127.0.0.1:39961,DS-55fa0ff7-abe1-4a27-a46c-a8fdfa53caee,DISK], DatanodeInfoWithStorage[127.0.0.1:38171,DS-a4feaf16-0a25-4ac6-bd2c-8adf8512f00e,DISK], DatanodeInfoWithStorage[127.0.0.1:37781,DS-cf59121c-2e7a-4f12-991e-a4c69ffbfa15,DISK], DatanodeInfoWithStorage[127.0.0.1:33251,DS-0aa095ba-6f4d-48ad-8129-86bdddb78fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:36413,DS-9b57b830-b102-4c60-9003-d30038d7023f,DISK], DatanodeInfoWithStorage[127.0.0.1:41808,DS-e190de54-9c2e-45f0-ad1d-53dc29d802f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1304988879-172.17.0.9-1596928244669:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45872,DS-55018a7c-a4f5-41a0-a0a9-3075ac2be460,DISK], DatanodeInfoWithStorage[127.0.0.1:34031,DS-f2a3c681-80c1-491b-a072-4d95a021a139,DISK], DatanodeInfoWithStorage[127.0.0.1:39961,DS-55fa0ff7-abe1-4a27-a46c-a8fdfa53caee,DISK], DatanodeInfoWithStorage[127.0.0.1:38171,DS-a4feaf16-0a25-4ac6-bd2c-8adf8512f00e,DISK], DatanodeInfoWithStorage[127.0.0.1:37781,DS-cf59121c-2e7a-4f12-991e-a4c69ffbfa15,DISK], DatanodeInfoWithStorage[127.0.0.1:33251,DS-0aa095ba-6f4d-48ad-8129-86bdddb78fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:36413,DS-9b57b830-b102-4c60-9003-d30038d7023f,DISK], DatanodeInfoWithStorage[127.0.0.1:41808,DS-e190de54-9c2e-45f0-ad1d-53dc29d802f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-60785180-172.17.0.9-1596928282424:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43230,DS-f97e5094-fc3f-4f85-b676-dbc81140f018,DISK], DatanodeInfoWithStorage[127.0.0.1:38284,DS-3bd80718-1cad-48f2-b070-5793fd0ca396,DISK], DatanodeInfoWithStorage[127.0.0.1:45366,DS-80e7f691-cf50-46e3-acef-78570e285211,DISK], DatanodeInfoWithStorage[127.0.0.1:43681,DS-c742e2e5-fd6f-4b6d-bf69-fcb4d4128528,DISK], DatanodeInfoWithStorage[127.0.0.1:37549,DS-b0691af7-4b2b-4987-abc5-d8af0f22e643,DISK], DatanodeInfoWithStorage[127.0.0.1:46433,DS-b9e2047b-fc4a-4cff-af14-eda8a1464ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:45891,DS-b973a445-0ce5-4d3f-a011-ce910bf3f46d,DISK], DatanodeInfoWithStorage[127.0.0.1:42595,DS-b9fa5f2b-6693-4e77-9811-734afbe7de7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-60785180-172.17.0.9-1596928282424:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43230,DS-f97e5094-fc3f-4f85-b676-dbc81140f018,DISK], DatanodeInfoWithStorage[127.0.0.1:38284,DS-3bd80718-1cad-48f2-b070-5793fd0ca396,DISK], DatanodeInfoWithStorage[127.0.0.1:45366,DS-80e7f691-cf50-46e3-acef-78570e285211,DISK], DatanodeInfoWithStorage[127.0.0.1:43681,DS-c742e2e5-fd6f-4b6d-bf69-fcb4d4128528,DISK], DatanodeInfoWithStorage[127.0.0.1:37549,DS-b0691af7-4b2b-4987-abc5-d8af0f22e643,DISK], DatanodeInfoWithStorage[127.0.0.1:46433,DS-b9e2047b-fc4a-4cff-af14-eda8a1464ae3,DISK], DatanodeInfoWithStorage[127.0.0.1:45891,DS-b973a445-0ce5-4d3f-a011-ce910bf3f46d,DISK], DatanodeInfoWithStorage[127.0.0.1:42595,DS-b9fa5f2b-6693-4e77-9811-734afbe7de7a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-757393386-172.17.0.9-1596928604119:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39907,DS-76b05194-e5b7-4e29-99c3-dbfb07f678b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37576,DS-b6c63d78-2e92-4fb3-acd2-5fee965406ca,DISK], DatanodeInfoWithStorage[127.0.0.1:44000,DS-70e7bb7f-85a8-42c5-9246-008f9de3d66d,DISK], DatanodeInfoWithStorage[127.0.0.1:37926,DS-dade0c04-5940-4a42-8ca3-bb6352a904b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44140,DS-e1afdf3d-0997-4e50-8c92-6ff75e0c6770,DISK], DatanodeInfoWithStorage[127.0.0.1:34047,DS-725e7339-329d-4aaa-a5c5-3a732f93e5d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43057,DS-011a18a4-e6a8-480f-8f07-a5bfce53272b,DISK], DatanodeInfoWithStorage[127.0.0.1:45207,DS-46b35f04-9645-4028-8e41-871d5904d9ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-757393386-172.17.0.9-1596928604119:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39907,DS-76b05194-e5b7-4e29-99c3-dbfb07f678b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37576,DS-b6c63d78-2e92-4fb3-acd2-5fee965406ca,DISK], DatanodeInfoWithStorage[127.0.0.1:44000,DS-70e7bb7f-85a8-42c5-9246-008f9de3d66d,DISK], DatanodeInfoWithStorage[127.0.0.1:37926,DS-dade0c04-5940-4a42-8ca3-bb6352a904b7,DISK], DatanodeInfoWithStorage[127.0.0.1:44140,DS-e1afdf3d-0997-4e50-8c92-6ff75e0c6770,DISK], DatanodeInfoWithStorage[127.0.0.1:34047,DS-725e7339-329d-4aaa-a5c5-3a732f93e5d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43057,DS-011a18a4-e6a8-480f-8f07-a5bfce53272b,DISK], DatanodeInfoWithStorage[127.0.0.1:45207,DS-46b35f04-9645-4028-8e41-871d5904d9ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1174841070-172.17.0.9-1596928720616:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35966,DS-2bc7face-4f5f-47bd-8136-62c5d30f50d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39074,DS-739700f3-5f56-478b-8f48-eabab2d6029d,DISK], DatanodeInfoWithStorage[127.0.0.1:36054,DS-5ce77eb2-f6f8-4b38-bf95-5b68f5efb07f,DISK], DatanodeInfoWithStorage[127.0.0.1:46684,DS-4c2bc253-bf31-4127-afa3-9272bb78a19b,DISK], DatanodeInfoWithStorage[127.0.0.1:34914,DS-c6154530-d810-4f42-9413-7183bae45a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:36805,DS-158fa11d-0a61-4815-ba47-171292cb1808,DISK], DatanodeInfoWithStorage[127.0.0.1:33904,DS-f50be8f8-1619-4623-a67d-e91ae6e1b587,DISK], DatanodeInfoWithStorage[127.0.0.1:42881,DS-6e772d03-7709-4cd1-bf9c-071b81e24ca4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1174841070-172.17.0.9-1596928720616:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35966,DS-2bc7face-4f5f-47bd-8136-62c5d30f50d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39074,DS-739700f3-5f56-478b-8f48-eabab2d6029d,DISK], DatanodeInfoWithStorage[127.0.0.1:36054,DS-5ce77eb2-f6f8-4b38-bf95-5b68f5efb07f,DISK], DatanodeInfoWithStorage[127.0.0.1:46684,DS-4c2bc253-bf31-4127-afa3-9272bb78a19b,DISK], DatanodeInfoWithStorage[127.0.0.1:34914,DS-c6154530-d810-4f42-9413-7183bae45a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:36805,DS-158fa11d-0a61-4815-ba47-171292cb1808,DISK], DatanodeInfoWithStorage[127.0.0.1:33904,DS-f50be8f8-1619-4623-a67d-e91ae6e1b587,DISK], DatanodeInfoWithStorage[127.0.0.1:42881,DS-6e772d03-7709-4cd1-bf9c-071b81e24ca4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.server.log.slow.rpc
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-772037651-172.17.0.9-1596928827582:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46435,DS-a2eaae7b-70a6-4427-93c6-ce34c188564d,DISK], DatanodeInfoWithStorage[127.0.0.1:36451,DS-59cb5e17-c702-43d2-88e1-b67b60b38b39,DISK], DatanodeInfoWithStorage[127.0.0.1:42576,DS-01e9c1b6-1366-4b5f-a272-2c9347c0b0b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36917,DS-c6419ce4-2f42-4fd9-8c97-65ec7e0dea83,DISK], DatanodeInfoWithStorage[127.0.0.1:34484,DS-bdc4d821-7d55-4a25-ab5b-6dcccebd9345,DISK], DatanodeInfoWithStorage[127.0.0.1:40004,DS-71683629-930f-429f-bdd8-6da8c4f36534,DISK], DatanodeInfoWithStorage[127.0.0.1:37360,DS-207be3a0-86de-4e0f-ab82-b824a3c7b339,DISK], DatanodeInfoWithStorage[127.0.0.1:35363,DS-56a63a96-e17f-427b-81d0-4de9b373659b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-772037651-172.17.0.9-1596928827582:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46435,DS-a2eaae7b-70a6-4427-93c6-ce34c188564d,DISK], DatanodeInfoWithStorage[127.0.0.1:36451,DS-59cb5e17-c702-43d2-88e1-b67b60b38b39,DISK], DatanodeInfoWithStorage[127.0.0.1:42576,DS-01e9c1b6-1366-4b5f-a272-2c9347c0b0b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36917,DS-c6419ce4-2f42-4fd9-8c97-65ec7e0dea83,DISK], DatanodeInfoWithStorage[127.0.0.1:34484,DS-bdc4d821-7d55-4a25-ab5b-6dcccebd9345,DISK], DatanodeInfoWithStorage[127.0.0.1:40004,DS-71683629-930f-429f-bdd8-6da8c4f36534,DISK], DatanodeInfoWithStorage[127.0.0.1:37360,DS-207be3a0-86de-4e0f-ab82-b824a3c7b339,DISK], DatanodeInfoWithStorage[127.0.0.1:35363,DS-56a63a96-e17f-427b-81d0-4de9b373659b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 20 out of 50
result: false positive !!!
Total execution time in seconds : 5239
