reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1316008988-172.17.0.14-1596959525146:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37011,DS-8362f41a-a730-40bc-b05d-c38afd6efa4b,DISK], DatanodeInfoWithStorage[127.0.0.1:42652,DS-5f3c445f-2c5d-465b-8aa7-cea33af116dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45262,DS-696ef66e-51b6-4214-a23f-92b9aab46117,DISK], DatanodeInfoWithStorage[127.0.0.1:38072,DS-96327302-c5f2-4d6c-a5e2-9a199c02fc04,DISK], DatanodeInfoWithStorage[127.0.0.1:40369,DS-2de41a24-8813-4aef-99d1-15986f60c7d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37014,DS-49898cd5-8a9e-4cdb-877a-11e4c6faf5c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45885,DS-ca8b6e19-06d4-4bac-97a0-96dc069a1ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:39128,DS-a17efd49-dbe8-4b03-98ac-b1d19ced5b19,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1316008988-172.17.0.14-1596959525146:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37011,DS-8362f41a-a730-40bc-b05d-c38afd6efa4b,DISK], DatanodeInfoWithStorage[127.0.0.1:42652,DS-5f3c445f-2c5d-465b-8aa7-cea33af116dc,DISK], DatanodeInfoWithStorage[127.0.0.1:45262,DS-696ef66e-51b6-4214-a23f-92b9aab46117,DISK], DatanodeInfoWithStorage[127.0.0.1:38072,DS-96327302-c5f2-4d6c-a5e2-9a199c02fc04,DISK], DatanodeInfoWithStorage[127.0.0.1:40369,DS-2de41a24-8813-4aef-99d1-15986f60c7d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37014,DS-49898cd5-8a9e-4cdb-877a-11e4c6faf5c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45885,DS-ca8b6e19-06d4-4bac-97a0-96dc069a1ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:39128,DS-a17efd49-dbe8-4b03-98ac-b1d19ced5b19,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-618775813-172.17.0.14-1596959562173:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33239,DS-046b0cdd-f3fd-49f3-baf4-479dec5c7020,DISK], DatanodeInfoWithStorage[127.0.0.1:45373,DS-4f708606-99e1-402e-a547-86c30113b214,DISK], DatanodeInfoWithStorage[127.0.0.1:41559,DS-f722cd71-c544-4ff4-ad95-1a0d20bc43d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40491,DS-02186f6f-86b6-4fa3-a3a0-ea2f4a7a84e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37659,DS-59f5ff5b-9dbb-4e0a-be96-b1c65ea195c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36604,DS-07b02754-4984-4a62-b78f-0bbbb92ca767,DISK], DatanodeInfoWithStorage[127.0.0.1:34915,DS-1ba74de9-07a0-40e3-ad21-956a4dc19aed,DISK], DatanodeInfoWithStorage[127.0.0.1:38752,DS-be2ee629-7a2b-4d3c-a1bd-dfc2d834f6b8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-618775813-172.17.0.14-1596959562173:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33239,DS-046b0cdd-f3fd-49f3-baf4-479dec5c7020,DISK], DatanodeInfoWithStorage[127.0.0.1:45373,DS-4f708606-99e1-402e-a547-86c30113b214,DISK], DatanodeInfoWithStorage[127.0.0.1:41559,DS-f722cd71-c544-4ff4-ad95-1a0d20bc43d1,DISK], DatanodeInfoWithStorage[127.0.0.1:40491,DS-02186f6f-86b6-4fa3-a3a0-ea2f4a7a84e1,DISK], DatanodeInfoWithStorage[127.0.0.1:37659,DS-59f5ff5b-9dbb-4e0a-be96-b1c65ea195c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36604,DS-07b02754-4984-4a62-b78f-0bbbb92ca767,DISK], DatanodeInfoWithStorage[127.0.0.1:34915,DS-1ba74de9-07a0-40e3-ad21-956a4dc19aed,DISK], DatanodeInfoWithStorage[127.0.0.1:38752,DS-be2ee629-7a2b-4d3c-a1bd-dfc2d834f6b8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2141362981-172.17.0.14-1596959595272:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35112,DS-8cfad123-6859-4d05-b2a2-829529301cfd,DISK], DatanodeInfoWithStorage[127.0.0.1:37835,DS-b543199e-8b71-4b84-a613-dfb23e27197d,DISK], DatanodeInfoWithStorage[127.0.0.1:38660,DS-3fcae6e4-fa80-4b19-9404-80ac7c5b1647,DISK], DatanodeInfoWithStorage[127.0.0.1:45326,DS-f19cce43-46ad-4268-abf7-86f8fc81c8e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44149,DS-cd814c16-aac5-4705-a0d1-9134a59839cc,DISK], DatanodeInfoWithStorage[127.0.0.1:41362,DS-50f79eef-f253-4003-a36a-4cf4994658f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37143,DS-f5a9bba5-48da-4557-ab33-08542ae29145,DISK], DatanodeInfoWithStorage[127.0.0.1:39724,DS-7f9ea8f5-3787-4688-8b6b-0cf16b08c5f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2141362981-172.17.0.14-1596959595272:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35112,DS-8cfad123-6859-4d05-b2a2-829529301cfd,DISK], DatanodeInfoWithStorage[127.0.0.1:37835,DS-b543199e-8b71-4b84-a613-dfb23e27197d,DISK], DatanodeInfoWithStorage[127.0.0.1:38660,DS-3fcae6e4-fa80-4b19-9404-80ac7c5b1647,DISK], DatanodeInfoWithStorage[127.0.0.1:45326,DS-f19cce43-46ad-4268-abf7-86f8fc81c8e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44149,DS-cd814c16-aac5-4705-a0d1-9134a59839cc,DISK], DatanodeInfoWithStorage[127.0.0.1:41362,DS-50f79eef-f253-4003-a36a-4cf4994658f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37143,DS-f5a9bba5-48da-4557-ab33-08542ae29145,DISK], DatanodeInfoWithStorage[127.0.0.1:39724,DS-7f9ea8f5-3787-4688-8b6b-0cf16b08c5f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-490097460-172.17.0.14-1596959635101:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43333,DS-538a6dd3-6c1a-4f96-9d65-1a902fb1a484,DISK], DatanodeInfoWithStorage[127.0.0.1:40720,DS-8e1276cf-4d27-452c-9358-2eff4480e83d,DISK], DatanodeInfoWithStorage[127.0.0.1:33857,DS-004187ab-90a3-42f5-96e4-af792d87e9b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36316,DS-1da6b649-c5eb-4468-82de-68c3799f05f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35671,DS-ada9ce20-e396-4f66-bb97-13de8744295f,DISK], DatanodeInfoWithStorage[127.0.0.1:39341,DS-0a4d549d-cc03-4d70-8cda-b449090c58b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37694,DS-84164c4d-36d2-46a7-ad74-77a2b3a5b266,DISK], DatanodeInfoWithStorage[127.0.0.1:39701,DS-a80a7151-0013-4ba0-8c24-b9f5a01c09d7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-490097460-172.17.0.14-1596959635101:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43333,DS-538a6dd3-6c1a-4f96-9d65-1a902fb1a484,DISK], DatanodeInfoWithStorage[127.0.0.1:40720,DS-8e1276cf-4d27-452c-9358-2eff4480e83d,DISK], DatanodeInfoWithStorage[127.0.0.1:33857,DS-004187ab-90a3-42f5-96e4-af792d87e9b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36316,DS-1da6b649-c5eb-4468-82de-68c3799f05f1,DISK], DatanodeInfoWithStorage[127.0.0.1:35671,DS-ada9ce20-e396-4f66-bb97-13de8744295f,DISK], DatanodeInfoWithStorage[127.0.0.1:39341,DS-0a4d549d-cc03-4d70-8cda-b449090c58b4,DISK], DatanodeInfoWithStorage[127.0.0.1:37694,DS-84164c4d-36d2-46a7-ad74-77a2b3a5b266,DISK], DatanodeInfoWithStorage[127.0.0.1:39701,DS-a80a7151-0013-4ba0-8c24-b9f5a01c09d7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-600596778-172.17.0.14-1596959707488:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37346,DS-6c175848-a97b-44c2-8502-9012882c1183,DISK], DatanodeInfoWithStorage[127.0.0.1:37572,DS-0999ac33-685f-41af-bdee-142ba83e993e,DISK], DatanodeInfoWithStorage[127.0.0.1:36450,DS-826cf518-e37d-462a-97b5-b45a413265f1,DISK], DatanodeInfoWithStorage[127.0.0.1:45244,DS-969ba115-dfd7-4e28-a415-6a736efa6d05,DISK], DatanodeInfoWithStorage[127.0.0.1:43403,DS-12fa2738-1e40-44e3-9528-b983e8c4c26b,DISK], DatanodeInfoWithStorage[127.0.0.1:39937,DS-d19ba855-d5d4-4f0d-8c2e-247c64f09e7b,DISK], DatanodeInfoWithStorage[127.0.0.1:43285,DS-4505f375-c956-4adf-940b-99e748db8004,DISK], DatanodeInfoWithStorage[127.0.0.1:36327,DS-d70e036c-c6d6-4f0e-a480-f2d9a87e952d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-600596778-172.17.0.14-1596959707488:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37346,DS-6c175848-a97b-44c2-8502-9012882c1183,DISK], DatanodeInfoWithStorage[127.0.0.1:37572,DS-0999ac33-685f-41af-bdee-142ba83e993e,DISK], DatanodeInfoWithStorage[127.0.0.1:36450,DS-826cf518-e37d-462a-97b5-b45a413265f1,DISK], DatanodeInfoWithStorage[127.0.0.1:45244,DS-969ba115-dfd7-4e28-a415-6a736efa6d05,DISK], DatanodeInfoWithStorage[127.0.0.1:43403,DS-12fa2738-1e40-44e3-9528-b983e8c4c26b,DISK], DatanodeInfoWithStorage[127.0.0.1:39937,DS-d19ba855-d5d4-4f0d-8c2e-247c64f09e7b,DISK], DatanodeInfoWithStorage[127.0.0.1:43285,DS-4505f375-c956-4adf-940b-99e748db8004,DISK], DatanodeInfoWithStorage[127.0.0.1:36327,DS-d70e036c-c6d6-4f0e-a480-f2d9a87e952d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1587262191-172.17.0.14-1596959790143:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33685,DS-468379c7-cdc4-4ad8-ba70-cfb643828799,DISK], DatanodeInfoWithStorage[127.0.0.1:34198,DS-75a42277-52b1-462b-8bd8-0c7ba9c698ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33985,DS-8981d5b6-1674-4435-acf4-d3f78f5a6ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:35133,DS-3cae31b9-136f-40d6-bde1-e7451c636137,DISK], DatanodeInfoWithStorage[127.0.0.1:33994,DS-5d13793a-700b-4223-9c41-1c7de3d9755c,DISK], DatanodeInfoWithStorage[127.0.0.1:33761,DS-84fb14d5-e082-4cc0-9467-37e443332903,DISK], DatanodeInfoWithStorage[127.0.0.1:44229,DS-c44cbce9-b6ea-4025-8039-9995c647d3b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42316,DS-53f56372-659e-4d96-9097-093ce60cdeda,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1587262191-172.17.0.14-1596959790143:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33685,DS-468379c7-cdc4-4ad8-ba70-cfb643828799,DISK], DatanodeInfoWithStorage[127.0.0.1:34198,DS-75a42277-52b1-462b-8bd8-0c7ba9c698ef,DISK], DatanodeInfoWithStorage[127.0.0.1:33985,DS-8981d5b6-1674-4435-acf4-d3f78f5a6ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:35133,DS-3cae31b9-136f-40d6-bde1-e7451c636137,DISK], DatanodeInfoWithStorage[127.0.0.1:33994,DS-5d13793a-700b-4223-9c41-1c7de3d9755c,DISK], DatanodeInfoWithStorage[127.0.0.1:33761,DS-84fb14d5-e082-4cc0-9467-37e443332903,DISK], DatanodeInfoWithStorage[127.0.0.1:44229,DS-c44cbce9-b6ea-4025-8039-9995c647d3b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42316,DS-53f56372-659e-4d96-9097-093ce60cdeda,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-815205851-172.17.0.14-1596960029313:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43593,DS-1be5e5fa-5872-4541-ad22-13c561347ada,DISK], DatanodeInfoWithStorage[127.0.0.1:35743,DS-a5296a03-2823-4a43-b80a-a457108f882e,DISK], DatanodeInfoWithStorage[127.0.0.1:36087,DS-0fb3bae1-94fe-4202-bdee-be617011afb2,DISK], DatanodeInfoWithStorage[127.0.0.1:33509,DS-51272262-8313-45cf-8e06-75319650ef25,DISK], DatanodeInfoWithStorage[127.0.0.1:42652,DS-b96e2c4b-9f73-4230-95c8-77b7cbd0c0d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40124,DS-7c37a6a3-5f42-4e77-bf85-afe97285ea61,DISK], DatanodeInfoWithStorage[127.0.0.1:44521,DS-bbd34b70-cdac-481c-84b7-25c4552ecd8d,DISK], DatanodeInfoWithStorage[127.0.0.1:42431,DS-5c3c081a-2ff3-4a93-8757-142dafb60666,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-815205851-172.17.0.14-1596960029313:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43593,DS-1be5e5fa-5872-4541-ad22-13c561347ada,DISK], DatanodeInfoWithStorage[127.0.0.1:35743,DS-a5296a03-2823-4a43-b80a-a457108f882e,DISK], DatanodeInfoWithStorage[127.0.0.1:36087,DS-0fb3bae1-94fe-4202-bdee-be617011afb2,DISK], DatanodeInfoWithStorage[127.0.0.1:33509,DS-51272262-8313-45cf-8e06-75319650ef25,DISK], DatanodeInfoWithStorage[127.0.0.1:42652,DS-b96e2c4b-9f73-4230-95c8-77b7cbd0c0d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40124,DS-7c37a6a3-5f42-4e77-bf85-afe97285ea61,DISK], DatanodeInfoWithStorage[127.0.0.1:44521,DS-bbd34b70-cdac-481c-84b7-25c4552ecd8d,DISK], DatanodeInfoWithStorage[127.0.0.1:42431,DS-5c3c081a-2ff3-4a93-8757-142dafb60666,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-61308215-172.17.0.14-1596960057646:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33223,DS-49486e87-39e6-4407-862d-b028d9834a57,DISK], DatanodeInfoWithStorage[127.0.0.1:37766,DS-bb737b90-98de-4164-9aca-3c250293db97,DISK], DatanodeInfoWithStorage[127.0.0.1:46777,DS-8dc0e477-5935-4d8e-aeb9-164609c8d013,DISK], DatanodeInfoWithStorage[127.0.0.1:33991,DS-6660f7ce-a180-4c0e-b79d-90e102ed0863,DISK], DatanodeInfoWithStorage[127.0.0.1:43757,DS-4d7aaa74-c3f0-4535-b7aa-18c2503653aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44340,DS-bb61cd06-0b22-43c1-a35a-09ab7b1b7ee2,DISK], DatanodeInfoWithStorage[127.0.0.1:44151,DS-36be2ee5-03a8-4509-8f17-ba56b7c51e86,DISK], DatanodeInfoWithStorage[127.0.0.1:46555,DS-a008f15c-6ab9-47bf-8a41-0e700c2e73e4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-61308215-172.17.0.14-1596960057646:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33223,DS-49486e87-39e6-4407-862d-b028d9834a57,DISK], DatanodeInfoWithStorage[127.0.0.1:37766,DS-bb737b90-98de-4164-9aca-3c250293db97,DISK], DatanodeInfoWithStorage[127.0.0.1:46777,DS-8dc0e477-5935-4d8e-aeb9-164609c8d013,DISK], DatanodeInfoWithStorage[127.0.0.1:33991,DS-6660f7ce-a180-4c0e-b79d-90e102ed0863,DISK], DatanodeInfoWithStorage[127.0.0.1:43757,DS-4d7aaa74-c3f0-4535-b7aa-18c2503653aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44340,DS-bb61cd06-0b22-43c1-a35a-09ab7b1b7ee2,DISK], DatanodeInfoWithStorage[127.0.0.1:44151,DS-36be2ee5-03a8-4509-8f17-ba56b7c51e86,DISK], DatanodeInfoWithStorage[127.0.0.1:46555,DS-a008f15c-6ab9-47bf-8a41-0e700c2e73e4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-23238540-172.17.0.14-1596960094774:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37157,DS-89b2462d-82b5-4769-8b08-9e2a3d04e41b,DISK], DatanodeInfoWithStorage[127.0.0.1:36807,DS-1367ba48-2d76-4cfd-9842-3bcb27e54956,DISK], DatanodeInfoWithStorage[127.0.0.1:45617,DS-2352d0a2-91c7-491c-8cef-0695f0e63226,DISK], DatanodeInfoWithStorage[127.0.0.1:36603,DS-e9fad741-b530-4e49-91d4-9bbe5892b24f,DISK], DatanodeInfoWithStorage[127.0.0.1:46839,DS-405ecf85-50f4-4201-b443-1a13c75f6828,DISK], DatanodeInfoWithStorage[127.0.0.1:40784,DS-097e7cd4-a33b-44d5-b02e-6d574412191c,DISK], DatanodeInfoWithStorage[127.0.0.1:33528,DS-2804546e-1e90-4be5-b7c6-cd767e00b337,DISK], DatanodeInfoWithStorage[127.0.0.1:35876,DS-994d8d60-489a-44e1-b291-fec94be2f512,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-23238540-172.17.0.14-1596960094774:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37157,DS-89b2462d-82b5-4769-8b08-9e2a3d04e41b,DISK], DatanodeInfoWithStorage[127.0.0.1:36807,DS-1367ba48-2d76-4cfd-9842-3bcb27e54956,DISK], DatanodeInfoWithStorage[127.0.0.1:45617,DS-2352d0a2-91c7-491c-8cef-0695f0e63226,DISK], DatanodeInfoWithStorage[127.0.0.1:36603,DS-e9fad741-b530-4e49-91d4-9bbe5892b24f,DISK], DatanodeInfoWithStorage[127.0.0.1:46839,DS-405ecf85-50f4-4201-b443-1a13c75f6828,DISK], DatanodeInfoWithStorage[127.0.0.1:40784,DS-097e7cd4-a33b-44d5-b02e-6d574412191c,DISK], DatanodeInfoWithStorage[127.0.0.1:33528,DS-2804546e-1e90-4be5-b7c6-cd767e00b337,DISK], DatanodeInfoWithStorage[127.0.0.1:35876,DS-994d8d60-489a-44e1-b291-fec94be2f512,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1615423964-172.17.0.14-1596960322371:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36905,DS-c7e466d4-b41e-49ae-a021-77427f62d893,DISK], DatanodeInfoWithStorage[127.0.0.1:36960,DS-a8e21ca5-25b1-4632-888d-ef254417dde7,DISK], DatanodeInfoWithStorage[127.0.0.1:38171,DS-f07edb42-5dd0-43a7-8448-9de79e119ef7,DISK], DatanodeInfoWithStorage[127.0.0.1:40325,DS-9061db28-1d4a-4974-b4a7-ecd3f151381c,DISK], DatanodeInfoWithStorage[127.0.0.1:44197,DS-8baa3cbb-06d9-408f-b8d4-e81f12d3c773,DISK], DatanodeInfoWithStorage[127.0.0.1:42370,DS-b11a85c3-5261-4d9c-9a48-f0b58c09417e,DISK], DatanodeInfoWithStorage[127.0.0.1:37255,DS-8285e95d-40e3-4af1-b5c5-dda95d80238e,DISK], DatanodeInfoWithStorage[127.0.0.1:35419,DS-26639416-27a7-4769-b815-8c5355af19b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1615423964-172.17.0.14-1596960322371:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36905,DS-c7e466d4-b41e-49ae-a021-77427f62d893,DISK], DatanodeInfoWithStorage[127.0.0.1:36960,DS-a8e21ca5-25b1-4632-888d-ef254417dde7,DISK], DatanodeInfoWithStorage[127.0.0.1:38171,DS-f07edb42-5dd0-43a7-8448-9de79e119ef7,DISK], DatanodeInfoWithStorage[127.0.0.1:40325,DS-9061db28-1d4a-4974-b4a7-ecd3f151381c,DISK], DatanodeInfoWithStorage[127.0.0.1:44197,DS-8baa3cbb-06d9-408f-b8d4-e81f12d3c773,DISK], DatanodeInfoWithStorage[127.0.0.1:42370,DS-b11a85c3-5261-4d9c-9a48-f0b58c09417e,DISK], DatanodeInfoWithStorage[127.0.0.1:37255,DS-8285e95d-40e3-4af1-b5c5-dda95d80238e,DISK], DatanodeInfoWithStorage[127.0.0.1:35419,DS-26639416-27a7-4769-b815-8c5355af19b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1379702963-172.17.0.14-1596960454186:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34247,DS-e90f8ba4-3b6a-49fd-8d88-dd69d1c6d037,DISK], DatanodeInfoWithStorage[127.0.0.1:40180,DS-39699efb-d20f-4d0a-92c8-7b971ff0dd30,DISK], DatanodeInfoWithStorage[127.0.0.1:37579,DS-f94a007d-c9c2-46d2-9c94-677c72bd7c58,DISK], DatanodeInfoWithStorage[127.0.0.1:40938,DS-e254d65d-6e3a-4c21-932b-f83774cd89c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37921,DS-ae3a06be-60bb-4091-b8c4-4ca66638d883,DISK], DatanodeInfoWithStorage[127.0.0.1:46801,DS-0c8c86d6-5219-4fe4-82db-7b3162157213,DISK], DatanodeInfoWithStorage[127.0.0.1:43301,DS-66b3ffd5-b0f2-40f7-978e-727ba9d26832,DISK], DatanodeInfoWithStorage[127.0.0.1:46838,DS-eb1e0fe4-c978-42e9-aec2-d7dfe3f92ef8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1379702963-172.17.0.14-1596960454186:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34247,DS-e90f8ba4-3b6a-49fd-8d88-dd69d1c6d037,DISK], DatanodeInfoWithStorage[127.0.0.1:40180,DS-39699efb-d20f-4d0a-92c8-7b971ff0dd30,DISK], DatanodeInfoWithStorage[127.0.0.1:37579,DS-f94a007d-c9c2-46d2-9c94-677c72bd7c58,DISK], DatanodeInfoWithStorage[127.0.0.1:40938,DS-e254d65d-6e3a-4c21-932b-f83774cd89c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37921,DS-ae3a06be-60bb-4091-b8c4-4ca66638d883,DISK], DatanodeInfoWithStorage[127.0.0.1:46801,DS-0c8c86d6-5219-4fe4-82db-7b3162157213,DISK], DatanodeInfoWithStorage[127.0.0.1:43301,DS-66b3ffd5-b0f2-40f7-978e-727ba9d26832,DISK], DatanodeInfoWithStorage[127.0.0.1:46838,DS-eb1e0fe4-c978-42e9-aec2-d7dfe3f92ef8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-24007711-172.17.0.14-1596960597294:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33160,DS-ee42f7fe-373d-46af-96c2-3ab9098eaac1,DISK], DatanodeInfoWithStorage[127.0.0.1:43315,DS-41dbf374-38aa-48e9-a705-511c58fe98cf,DISK], DatanodeInfoWithStorage[127.0.0.1:44354,DS-9bb98836-13bc-4197-9ac7-14d7c6f82776,DISK], DatanodeInfoWithStorage[127.0.0.1:45697,DS-2d593101-b552-41e4-aae3-cf3455b175ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45016,DS-5a94652f-a6ae-470c-86ff-ba059cf23c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:44724,DS-0790901f-5a1c-45de-bd05-239ebe98a58a,DISK], DatanodeInfoWithStorage[127.0.0.1:36006,DS-4e21e3db-6c71-453a-abe6-b28af510d921,DISK], DatanodeInfoWithStorage[127.0.0.1:38583,DS-f064736a-0e67-4b79-bdd0-780f28e950fb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-24007711-172.17.0.14-1596960597294:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33160,DS-ee42f7fe-373d-46af-96c2-3ab9098eaac1,DISK], DatanodeInfoWithStorage[127.0.0.1:43315,DS-41dbf374-38aa-48e9-a705-511c58fe98cf,DISK], DatanodeInfoWithStorage[127.0.0.1:44354,DS-9bb98836-13bc-4197-9ac7-14d7c6f82776,DISK], DatanodeInfoWithStorage[127.0.0.1:45697,DS-2d593101-b552-41e4-aae3-cf3455b175ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45016,DS-5a94652f-a6ae-470c-86ff-ba059cf23c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:44724,DS-0790901f-5a1c-45de-bd05-239ebe98a58a,DISK], DatanodeInfoWithStorage[127.0.0.1:36006,DS-4e21e3db-6c71-453a-abe6-b28af510d921,DISK], DatanodeInfoWithStorage[127.0.0.1:38583,DS-f064736a-0e67-4b79-bdd0-780f28e950fb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-355620583-172.17.0.14-1596960763059:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33810,DS-89faad49-906a-41d8-8d65-ac5b62181a52,DISK], DatanodeInfoWithStorage[127.0.0.1:41864,DS-bd927c27-2406-4375-ba09-1d96c300377c,DISK], DatanodeInfoWithStorage[127.0.0.1:44513,DS-1d2fa22b-2416-477c-aaa5-985a01f18b26,DISK], DatanodeInfoWithStorage[127.0.0.1:37851,DS-24d8d236-1dbd-40ea-8a69-112f8e205974,DISK], DatanodeInfoWithStorage[127.0.0.1:40561,DS-0906eeb8-7d14-47f8-a0e2-8559847587e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42274,DS-170074cd-118c-435e-8f8a-2979945ca844,DISK], DatanodeInfoWithStorage[127.0.0.1:41855,DS-f80d1fe5-4af6-4b2e-948e-67234ae894b3,DISK], DatanodeInfoWithStorage[127.0.0.1:43026,DS-1d746be8-144e-4d66-849c-b5d6f5fea500,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-355620583-172.17.0.14-1596960763059:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33810,DS-89faad49-906a-41d8-8d65-ac5b62181a52,DISK], DatanodeInfoWithStorage[127.0.0.1:41864,DS-bd927c27-2406-4375-ba09-1d96c300377c,DISK], DatanodeInfoWithStorage[127.0.0.1:44513,DS-1d2fa22b-2416-477c-aaa5-985a01f18b26,DISK], DatanodeInfoWithStorage[127.0.0.1:37851,DS-24d8d236-1dbd-40ea-8a69-112f8e205974,DISK], DatanodeInfoWithStorage[127.0.0.1:40561,DS-0906eeb8-7d14-47f8-a0e2-8559847587e8,DISK], DatanodeInfoWithStorage[127.0.0.1:42274,DS-170074cd-118c-435e-8f8a-2979945ca844,DISK], DatanodeInfoWithStorage[127.0.0.1:41855,DS-f80d1fe5-4af6-4b2e-948e-67234ae894b3,DISK], DatanodeInfoWithStorage[127.0.0.1:43026,DS-1d746be8-144e-4d66-849c-b5d6f5fea500,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1980486116-172.17.0.14-1596960801873:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40075,DS-4d521624-8892-49c1-8a94-fb5f2b660c0c,DISK], DatanodeInfoWithStorage[127.0.0.1:38066,DS-21d3e478-3779-4ee4-91ab-f211ed7e07eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39096,DS-d838bd5a-3c26-4c76-8212-7ba175b16a69,DISK], DatanodeInfoWithStorage[127.0.0.1:39949,DS-f7ec7abc-279d-423c-92f3-86f419c1571e,DISK], DatanodeInfoWithStorage[127.0.0.1:43136,DS-65cb199c-4a88-4f1b-b404-6e13f8f0a763,DISK], DatanodeInfoWithStorage[127.0.0.1:33634,DS-e430f03b-5846-4301-9723-c836d8dc35b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44166,DS-3fad9c8e-ecb1-4430-8638-a63fc7bc3f27,DISK], DatanodeInfoWithStorage[127.0.0.1:39071,DS-26ecf39b-c869-4948-aeeb-71d71c0236e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1980486116-172.17.0.14-1596960801873:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40075,DS-4d521624-8892-49c1-8a94-fb5f2b660c0c,DISK], DatanodeInfoWithStorage[127.0.0.1:38066,DS-21d3e478-3779-4ee4-91ab-f211ed7e07eb,DISK], DatanodeInfoWithStorage[127.0.0.1:39096,DS-d838bd5a-3c26-4c76-8212-7ba175b16a69,DISK], DatanodeInfoWithStorage[127.0.0.1:39949,DS-f7ec7abc-279d-423c-92f3-86f419c1571e,DISK], DatanodeInfoWithStorage[127.0.0.1:43136,DS-65cb199c-4a88-4f1b-b404-6e13f8f0a763,DISK], DatanodeInfoWithStorage[127.0.0.1:33634,DS-e430f03b-5846-4301-9723-c836d8dc35b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44166,DS-3fad9c8e-ecb1-4430-8638-a63fc7bc3f27,DISK], DatanodeInfoWithStorage[127.0.0.1:39071,DS-26ecf39b-c869-4948-aeeb-71d71c0236e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-89839171-172.17.0.14-1596960833847:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46263,DS-c74a69a8-1da1-4c45-a0e4-8e9e4266f181,DISK], DatanodeInfoWithStorage[127.0.0.1:44823,DS-45ceb103-a578-49b0-aa2e-c606fe39d163,DISK], DatanodeInfoWithStorage[127.0.0.1:43036,DS-d16bdd3c-ab15-4af3-a99a-2629b40abd48,DISK], DatanodeInfoWithStorage[127.0.0.1:38401,DS-0912e017-0ad5-4340-bfff-7e7448cd8420,DISK], DatanodeInfoWithStorage[127.0.0.1:44985,DS-49f7d99a-b756-41e9-a205-b1dc28cfb8ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33866,DS-bb281695-f22e-4bb0-a097-3e2f15bcc2fb,DISK], DatanodeInfoWithStorage[127.0.0.1:35896,DS-ae65d468-0984-4711-ac55-19a37b874351,DISK], DatanodeInfoWithStorage[127.0.0.1:45573,DS-0d68ba0d-a837-45e1-9af9-45164179fc11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-89839171-172.17.0.14-1596960833847:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46263,DS-c74a69a8-1da1-4c45-a0e4-8e9e4266f181,DISK], DatanodeInfoWithStorage[127.0.0.1:44823,DS-45ceb103-a578-49b0-aa2e-c606fe39d163,DISK], DatanodeInfoWithStorage[127.0.0.1:43036,DS-d16bdd3c-ab15-4af3-a99a-2629b40abd48,DISK], DatanodeInfoWithStorage[127.0.0.1:38401,DS-0912e017-0ad5-4340-bfff-7e7448cd8420,DISK], DatanodeInfoWithStorage[127.0.0.1:44985,DS-49f7d99a-b756-41e9-a205-b1dc28cfb8ed,DISK], DatanodeInfoWithStorage[127.0.0.1:33866,DS-bb281695-f22e-4bb0-a097-3e2f15bcc2fb,DISK], DatanodeInfoWithStorage[127.0.0.1:35896,DS-ae65d468-0984-4711-ac55-19a37b874351,DISK], DatanodeInfoWithStorage[127.0.0.1:45573,DS-0d68ba0d-a837-45e1-9af9-45164179fc11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1902373234-172.17.0.14-1596960872017:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38019,DS-ee6c9538-1c76-4eb2-8012-b352bf5c899b,DISK], DatanodeInfoWithStorage[127.0.0.1:35100,DS-641bb820-0eb2-484b-a2c9-54950884f43e,DISK], DatanodeInfoWithStorage[127.0.0.1:34891,DS-b039e657-d4d9-4730-8c4d-8d8c2e79e8f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35346,DS-1fc89c3a-e423-4fab-99c6-4e82b5136fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:40379,DS-273c65cf-1abc-4af0-b4b4-21c22b9d1f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:44386,DS-06f72601-0ae2-4cdb-be57-873ec65aa6fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44203,DS-181ae564-b86f-448c-ba33-3759d4b5fcd0,DISK], DatanodeInfoWithStorage[127.0.0.1:35087,DS-28cc0744-5c07-4da9-879a-c5320bd4a126,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1902373234-172.17.0.14-1596960872017:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38019,DS-ee6c9538-1c76-4eb2-8012-b352bf5c899b,DISK], DatanodeInfoWithStorage[127.0.0.1:35100,DS-641bb820-0eb2-484b-a2c9-54950884f43e,DISK], DatanodeInfoWithStorage[127.0.0.1:34891,DS-b039e657-d4d9-4730-8c4d-8d8c2e79e8f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35346,DS-1fc89c3a-e423-4fab-99c6-4e82b5136fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:40379,DS-273c65cf-1abc-4af0-b4b4-21c22b9d1f7e,DISK], DatanodeInfoWithStorage[127.0.0.1:44386,DS-06f72601-0ae2-4cdb-be57-873ec65aa6fd,DISK], DatanodeInfoWithStorage[127.0.0.1:44203,DS-181ae564-b86f-448c-ba33-3759d4b5fcd0,DISK], DatanodeInfoWithStorage[127.0.0.1:35087,DS-28cc0744-5c07-4da9-879a-c5320bd4a126,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-885989836-172.17.0.14-1596961116346:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39086,DS-5c1302b2-ebc9-477f-8ae2-e4061c9320dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33627,DS-8ea49ac9-0a57-4fcb-a67d-c99755c64f96,DISK], DatanodeInfoWithStorage[127.0.0.1:43710,DS-3155d1ed-549b-4541-9003-2b60d7caed0a,DISK], DatanodeInfoWithStorage[127.0.0.1:42340,DS-21375b29-126e-4c1e-97af-32c77dd2be91,DISK], DatanodeInfoWithStorage[127.0.0.1:38410,DS-3b59649e-c53b-4c9f-b43d-17a34b24aef3,DISK], DatanodeInfoWithStorage[127.0.0.1:41531,DS-e28b0ee9-ed85-404d-870f-31e1f4b11ef8,DISK], DatanodeInfoWithStorage[127.0.0.1:42334,DS-64b06582-0575-4436-80ab-2d4e5fc32ce0,DISK], DatanodeInfoWithStorage[127.0.0.1:42407,DS-923dd591-f497-4647-8e48-d077d3b67e1f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-885989836-172.17.0.14-1596961116346:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39086,DS-5c1302b2-ebc9-477f-8ae2-e4061c9320dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33627,DS-8ea49ac9-0a57-4fcb-a67d-c99755c64f96,DISK], DatanodeInfoWithStorage[127.0.0.1:43710,DS-3155d1ed-549b-4541-9003-2b60d7caed0a,DISK], DatanodeInfoWithStorage[127.0.0.1:42340,DS-21375b29-126e-4c1e-97af-32c77dd2be91,DISK], DatanodeInfoWithStorage[127.0.0.1:38410,DS-3b59649e-c53b-4c9f-b43d-17a34b24aef3,DISK], DatanodeInfoWithStorage[127.0.0.1:41531,DS-e28b0ee9-ed85-404d-870f-31e1f4b11ef8,DISK], DatanodeInfoWithStorage[127.0.0.1:42334,DS-64b06582-0575-4436-80ab-2d4e5fc32ce0,DISK], DatanodeInfoWithStorage[127.0.0.1:42407,DS-923dd591-f497-4647-8e48-d077d3b67e1f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-476138145-172.17.0.14-1596961355503:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45963,DS-2bb57c9c-2b5e-4589-ad98-38ffc6c19276,DISK], DatanodeInfoWithStorage[127.0.0.1:39296,DS-a2929cb7-927f-43bc-93d8-87d668b74be5,DISK], DatanodeInfoWithStorage[127.0.0.1:46595,DS-d218189c-257b-4612-ac01-aaf22daaf8ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45370,DS-a801926f-279e-47cd-a7d2-23c855af49ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44738,DS-f07847cc-17f2-4ad4-9498-84897370b098,DISK], DatanodeInfoWithStorage[127.0.0.1:46546,DS-b9c98e7e-c0bc-403c-bc36-db81f0be6236,DISK], DatanodeInfoWithStorage[127.0.0.1:36398,DS-448378b4-35fd-4972-816c-ab3674219eb5,DISK], DatanodeInfoWithStorage[127.0.0.1:41259,DS-c61364e4-e038-4c36-a44a-10ec4dd17fb8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-476138145-172.17.0.14-1596961355503:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45963,DS-2bb57c9c-2b5e-4589-ad98-38ffc6c19276,DISK], DatanodeInfoWithStorage[127.0.0.1:39296,DS-a2929cb7-927f-43bc-93d8-87d668b74be5,DISK], DatanodeInfoWithStorage[127.0.0.1:46595,DS-d218189c-257b-4612-ac01-aaf22daaf8ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45370,DS-a801926f-279e-47cd-a7d2-23c855af49ab,DISK], DatanodeInfoWithStorage[127.0.0.1:44738,DS-f07847cc-17f2-4ad4-9498-84897370b098,DISK], DatanodeInfoWithStorage[127.0.0.1:46546,DS-b9c98e7e-c0bc-403c-bc36-db81f0be6236,DISK], DatanodeInfoWithStorage[127.0.0.1:36398,DS-448378b4-35fd-4972-816c-ab3674219eb5,DISK], DatanodeInfoWithStorage[127.0.0.1:41259,DS-c61364e4-e038-4c36-a44a-10ec4dd17fb8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1900899918-172.17.0.14-1596961700835:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39849,DS-d9593ee4-fe39-49af-baab-0cdad99a5dac,DISK], DatanodeInfoWithStorage[127.0.0.1:38970,DS-a0942fad-d6d9-47ce-b90d-4d410b856bab,DISK], DatanodeInfoWithStorage[127.0.0.1:39922,DS-948e36b0-80ca-4d98-a148-0dda1c290e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:35921,DS-35f20b03-4cd9-4b4a-83fa-4ee701253271,DISK], DatanodeInfoWithStorage[127.0.0.1:39617,DS-de277d21-2727-4f66-95cb-262e45643d51,DISK], DatanodeInfoWithStorage[127.0.0.1:39465,DS-8d23f958-410d-401b-b981-f4f1b557a86e,DISK], DatanodeInfoWithStorage[127.0.0.1:36328,DS-0b56de3e-7909-44bf-b7af-83120f0b0f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:38266,DS-af250374-73c7-46e4-a340-431c2a8f85fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1900899918-172.17.0.14-1596961700835:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39849,DS-d9593ee4-fe39-49af-baab-0cdad99a5dac,DISK], DatanodeInfoWithStorage[127.0.0.1:38970,DS-a0942fad-d6d9-47ce-b90d-4d410b856bab,DISK], DatanodeInfoWithStorage[127.0.0.1:39922,DS-948e36b0-80ca-4d98-a148-0dda1c290e3a,DISK], DatanodeInfoWithStorage[127.0.0.1:35921,DS-35f20b03-4cd9-4b4a-83fa-4ee701253271,DISK], DatanodeInfoWithStorage[127.0.0.1:39617,DS-de277d21-2727-4f66-95cb-262e45643d51,DISK], DatanodeInfoWithStorage[127.0.0.1:39465,DS-8d23f958-410d-401b-b981-f4f1b557a86e,DISK], DatanodeInfoWithStorage[127.0.0.1:36328,DS-0b56de3e-7909-44bf-b7af-83120f0b0f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:38266,DS-af250374-73c7-46e4-a340-431c2a8f85fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-27998023-172.17.0.14-1596961731785:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41799,DS-410dc8af-a26f-4889-8ad3-05617a0ed0c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41850,DS-9d99bc68-ead2-4df1-a099-ebc2ba9177c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34058,DS-2c599de2-bbe2-4be7-9826-9450d583c280,DISK], DatanodeInfoWithStorage[127.0.0.1:43791,DS-a3ce71b6-beff-4d3c-a9e1-f3b16cdee277,DISK], DatanodeInfoWithStorage[127.0.0.1:42425,DS-29f449b0-07db-473f-b378-db7c0c796db0,DISK], DatanodeInfoWithStorage[127.0.0.1:43011,DS-d5ccd97b-69dd-4d73-aa41-9125de6c9138,DISK], DatanodeInfoWithStorage[127.0.0.1:45158,DS-f3b141d2-0931-47ec-964d-43f7fa216319,DISK], DatanodeInfoWithStorage[127.0.0.1:39701,DS-ea63b4aa-9a13-42dd-9f46-36053072699f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-27998023-172.17.0.14-1596961731785:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41799,DS-410dc8af-a26f-4889-8ad3-05617a0ed0c5,DISK], DatanodeInfoWithStorage[127.0.0.1:41850,DS-9d99bc68-ead2-4df1-a099-ebc2ba9177c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34058,DS-2c599de2-bbe2-4be7-9826-9450d583c280,DISK], DatanodeInfoWithStorage[127.0.0.1:43791,DS-a3ce71b6-beff-4d3c-a9e1-f3b16cdee277,DISK], DatanodeInfoWithStorage[127.0.0.1:42425,DS-29f449b0-07db-473f-b378-db7c0c796db0,DISK], DatanodeInfoWithStorage[127.0.0.1:43011,DS-d5ccd97b-69dd-4d73-aa41-9125de6c9138,DISK], DatanodeInfoWithStorage[127.0.0.1:45158,DS-f3b141d2-0931-47ec-964d-43f7fa216319,DISK], DatanodeInfoWithStorage[127.0.0.1:39701,DS-ea63b4aa-9a13-42dd-9f46-36053072699f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1757567277-172.17.0.14-1596962134261:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36657,DS-ac00f900-344e-48c9-a158-0b0562c21be2,DISK], DatanodeInfoWithStorage[127.0.0.1:45917,DS-757b534b-99c0-493c-9bd7-336a4b47b525,DISK], DatanodeInfoWithStorage[127.0.0.1:43125,DS-c7934a8e-06c8-4855-bf3b-75e6680e603c,DISK], DatanodeInfoWithStorage[127.0.0.1:38835,DS-f9f95605-b2d6-4c4c-8183-b4e90d3ed09d,DISK], DatanodeInfoWithStorage[127.0.0.1:41886,DS-1f84d4cc-e282-4095-8e63-bdc442f7b85a,DISK], DatanodeInfoWithStorage[127.0.0.1:45045,DS-48d20d19-a9b0-4a35-9d3d-ba58421467cb,DISK], DatanodeInfoWithStorage[127.0.0.1:46566,DS-c6057470-01b7-4f75-93b2-cd0f8eb5f030,DISK], DatanodeInfoWithStorage[127.0.0.1:40317,DS-b5e09888-261b-4120-ac0f-259b19bcbb5c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1757567277-172.17.0.14-1596962134261:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36657,DS-ac00f900-344e-48c9-a158-0b0562c21be2,DISK], DatanodeInfoWithStorage[127.0.0.1:45917,DS-757b534b-99c0-493c-9bd7-336a4b47b525,DISK], DatanodeInfoWithStorage[127.0.0.1:43125,DS-c7934a8e-06c8-4855-bf3b-75e6680e603c,DISK], DatanodeInfoWithStorage[127.0.0.1:38835,DS-f9f95605-b2d6-4c4c-8183-b4e90d3ed09d,DISK], DatanodeInfoWithStorage[127.0.0.1:41886,DS-1f84d4cc-e282-4095-8e63-bdc442f7b85a,DISK], DatanodeInfoWithStorage[127.0.0.1:45045,DS-48d20d19-a9b0-4a35-9d3d-ba58421467cb,DISK], DatanodeInfoWithStorage[127.0.0.1:46566,DS-c6057470-01b7-4f75-93b2-cd0f8eb5f030,DISK], DatanodeInfoWithStorage[127.0.0.1:40317,DS-b5e09888-261b-4120-ac0f-259b19bcbb5c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-289846339-172.17.0.14-1596962346643:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42652,DS-87b0074f-c993-4597-9067-538bc0bfce26,DISK], DatanodeInfoWithStorage[127.0.0.1:43822,DS-c5f29ce9-1909-4d70-abf1-3c54fa2556b6,DISK], DatanodeInfoWithStorage[127.0.0.1:35857,DS-ab642854-64ee-4ecc-96d0-7cd78178201f,DISK], DatanodeInfoWithStorage[127.0.0.1:39298,DS-e3897ac2-3d58-46cc-8329-89176e43c4ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33624,DS-bb211fd3-9097-4954-a304-6f96cec28f14,DISK], DatanodeInfoWithStorage[127.0.0.1:38705,DS-9adc3f01-20fb-41b2-8f2d-89ba87c10d89,DISK], DatanodeInfoWithStorage[127.0.0.1:42860,DS-0e341a12-1efa-42ee-94ee-1b7d32c9d871,DISK], DatanodeInfoWithStorage[127.0.0.1:41362,DS-897428a5-2895-48eb-bed2-5d46d0a38a57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-289846339-172.17.0.14-1596962346643:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42652,DS-87b0074f-c993-4597-9067-538bc0bfce26,DISK], DatanodeInfoWithStorage[127.0.0.1:43822,DS-c5f29ce9-1909-4d70-abf1-3c54fa2556b6,DISK], DatanodeInfoWithStorage[127.0.0.1:35857,DS-ab642854-64ee-4ecc-96d0-7cd78178201f,DISK], DatanodeInfoWithStorage[127.0.0.1:39298,DS-e3897ac2-3d58-46cc-8329-89176e43c4ab,DISK], DatanodeInfoWithStorage[127.0.0.1:33624,DS-bb211fd3-9097-4954-a304-6f96cec28f14,DISK], DatanodeInfoWithStorage[127.0.0.1:38705,DS-9adc3f01-20fb-41b2-8f2d-89ba87c10d89,DISK], DatanodeInfoWithStorage[127.0.0.1:42860,DS-0e341a12-1efa-42ee-94ee-1b7d32c9d871,DISK], DatanodeInfoWithStorage[127.0.0.1:41362,DS-897428a5-2895-48eb-bed2-5d46d0a38a57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1421178824-172.17.0.14-1596962382744:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37551,DS-c0b4e6d4-c700-4648-89d2-00e4fcde6d63,DISK], DatanodeInfoWithStorage[127.0.0.1:45216,DS-09ce3696-ce8e-4697-91a1-f2c17bc72ede,DISK], DatanodeInfoWithStorage[127.0.0.1:40186,DS-c59ebd94-7d52-43bb-a866-e95bfb13644d,DISK], DatanodeInfoWithStorage[127.0.0.1:37668,DS-d47f1221-3419-45ef-8564-17d07c01cb19,DISK], DatanodeInfoWithStorage[127.0.0.1:41831,DS-dfdf4606-9ee7-45d2-93bc-e5db4195369c,DISK], DatanodeInfoWithStorage[127.0.0.1:35050,DS-dbd7ce1a-ac7d-44fa-9cdd-91e4cfaa1d92,DISK], DatanodeInfoWithStorage[127.0.0.1:44430,DS-aab2bfa7-96cb-4a2f-a985-fcd68d440ed3,DISK], DatanodeInfoWithStorage[127.0.0.1:41858,DS-d6b86333-e6d6-47e5-8e0c-5e070d79b2e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1421178824-172.17.0.14-1596962382744:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37551,DS-c0b4e6d4-c700-4648-89d2-00e4fcde6d63,DISK], DatanodeInfoWithStorage[127.0.0.1:45216,DS-09ce3696-ce8e-4697-91a1-f2c17bc72ede,DISK], DatanodeInfoWithStorage[127.0.0.1:40186,DS-c59ebd94-7d52-43bb-a866-e95bfb13644d,DISK], DatanodeInfoWithStorage[127.0.0.1:37668,DS-d47f1221-3419-45ef-8564-17d07c01cb19,DISK], DatanodeInfoWithStorage[127.0.0.1:41831,DS-dfdf4606-9ee7-45d2-93bc-e5db4195369c,DISK], DatanodeInfoWithStorage[127.0.0.1:35050,DS-dbd7ce1a-ac7d-44fa-9cdd-91e4cfaa1d92,DISK], DatanodeInfoWithStorage[127.0.0.1:44430,DS-aab2bfa7-96cb-4a2f-a985-fcd68d440ed3,DISK], DatanodeInfoWithStorage[127.0.0.1:41858,DS-d6b86333-e6d6-47e5-8e0c-5e070d79b2e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-353508352-172.17.0.14-1596962422768:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39227,DS-f6aadfc6-64c3-4bc7-86fd-92b41e32ac61,DISK], DatanodeInfoWithStorage[127.0.0.1:37544,DS-a4b3140f-9e76-43f4-a11c-4ac27267a2c7,DISK], DatanodeInfoWithStorage[127.0.0.1:44975,DS-8c2f8c5a-e766-4cee-8272-57b8fea55972,DISK], DatanodeInfoWithStorage[127.0.0.1:36295,DS-a4a7d3fe-c149-4857-afdb-b079bffbb2a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34968,DS-b750e566-537c-412e-b3bf-d7d98a359574,DISK], DatanodeInfoWithStorage[127.0.0.1:38071,DS-676bcb60-cf0e-4a17-a1fe-ce68a18c79c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41450,DS-ea4bdc66-c062-40ef-9e59-96f4c6698110,DISK], DatanodeInfoWithStorage[127.0.0.1:46418,DS-9fa51d4e-974e-493e-a60d-f211817c3cbb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-353508352-172.17.0.14-1596962422768:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39227,DS-f6aadfc6-64c3-4bc7-86fd-92b41e32ac61,DISK], DatanodeInfoWithStorage[127.0.0.1:37544,DS-a4b3140f-9e76-43f4-a11c-4ac27267a2c7,DISK], DatanodeInfoWithStorage[127.0.0.1:44975,DS-8c2f8c5a-e766-4cee-8272-57b8fea55972,DISK], DatanodeInfoWithStorage[127.0.0.1:36295,DS-a4a7d3fe-c149-4857-afdb-b079bffbb2a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34968,DS-b750e566-537c-412e-b3bf-d7d98a359574,DISK], DatanodeInfoWithStorage[127.0.0.1:38071,DS-676bcb60-cf0e-4a17-a1fe-ce68a18c79c9,DISK], DatanodeInfoWithStorage[127.0.0.1:41450,DS-ea4bdc66-c062-40ef-9e59-96f4c6698110,DISK], DatanodeInfoWithStorage[127.0.0.1:46418,DS-9fa51d4e-974e-493e-a60d-f211817c3cbb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1375121627-172.17.0.14-1596962600124:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35438,DS-a7a5aab2-b84b-4012-8e42-98761ced8c89,DISK], DatanodeInfoWithStorage[127.0.0.1:36546,DS-9c5bd843-ac2c-45e6-931b-6eb7fb3cb125,DISK], DatanodeInfoWithStorage[127.0.0.1:42205,DS-99bfcf4e-c2b4-499e-94a6-a4018cef646f,DISK], DatanodeInfoWithStorage[127.0.0.1:45089,DS-cab35d3d-e884-47a3-a0cf-0f0b6f6e2323,DISK], DatanodeInfoWithStorage[127.0.0.1:36592,DS-51ad2245-6d35-44b8-a771-49c117c3ed86,DISK], DatanodeInfoWithStorage[127.0.0.1:38787,DS-7ffeae9c-1bd8-427e-b53d-668cf5183b80,DISK], DatanodeInfoWithStorage[127.0.0.1:39700,DS-fe3a1473-2871-412d-a710-c2da7f33b4ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38418,DS-002f6fef-5049-4f17-812e-4eaec5307c9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1375121627-172.17.0.14-1596962600124:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35438,DS-a7a5aab2-b84b-4012-8e42-98761ced8c89,DISK], DatanodeInfoWithStorage[127.0.0.1:36546,DS-9c5bd843-ac2c-45e6-931b-6eb7fb3cb125,DISK], DatanodeInfoWithStorage[127.0.0.1:42205,DS-99bfcf4e-c2b4-499e-94a6-a4018cef646f,DISK], DatanodeInfoWithStorage[127.0.0.1:45089,DS-cab35d3d-e884-47a3-a0cf-0f0b6f6e2323,DISK], DatanodeInfoWithStorage[127.0.0.1:36592,DS-51ad2245-6d35-44b8-a771-49c117c3ed86,DISK], DatanodeInfoWithStorage[127.0.0.1:38787,DS-7ffeae9c-1bd8-427e-b53d-668cf5183b80,DISK], DatanodeInfoWithStorage[127.0.0.1:39700,DS-fe3a1473-2871-412d-a710-c2da7f33b4ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38418,DS-002f6fef-5049-4f17-812e-4eaec5307c9a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-849189598-172.17.0.14-1596962666184:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43986,DS-623111e8-43b7-4308-bcd8-09a1398f1e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:35161,DS-8258943c-729a-4a9a-8768-5e33a117e9bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43038,DS-6a7a02d5-aab5-4c5d-84f9-4f33b001946c,DISK], DatanodeInfoWithStorage[127.0.0.1:37686,DS-2ed313c4-b26b-488b-a6f5-2b69cf5200df,DISK], DatanodeInfoWithStorage[127.0.0.1:43576,DS-45e75063-0a98-4579-80b1-adefeb0fb571,DISK], DatanodeInfoWithStorage[127.0.0.1:36875,DS-7c056713-f11e-485c-85c4-bacb1329d803,DISK], DatanodeInfoWithStorage[127.0.0.1:32822,DS-febe5d50-5b1d-4d60-b369-61c11c0f24b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45858,DS-860064e8-f4da-47c0-a981-cf03a1487822,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-849189598-172.17.0.14-1596962666184:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43986,DS-623111e8-43b7-4308-bcd8-09a1398f1e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:35161,DS-8258943c-729a-4a9a-8768-5e33a117e9bc,DISK], DatanodeInfoWithStorage[127.0.0.1:43038,DS-6a7a02d5-aab5-4c5d-84f9-4f33b001946c,DISK], DatanodeInfoWithStorage[127.0.0.1:37686,DS-2ed313c4-b26b-488b-a6f5-2b69cf5200df,DISK], DatanodeInfoWithStorage[127.0.0.1:43576,DS-45e75063-0a98-4579-80b1-adefeb0fb571,DISK], DatanodeInfoWithStorage[127.0.0.1:36875,DS-7c056713-f11e-485c-85c4-bacb1329d803,DISK], DatanodeInfoWithStorage[127.0.0.1:32822,DS-febe5d50-5b1d-4d60-b369-61c11c0f24b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45858,DS-860064e8-f4da-47c0-a981-cf03a1487822,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-926641813-172.17.0.14-1596962984241:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40547,DS-d49144d7-1d6c-4515-8012-e9c95b42c521,DISK], DatanodeInfoWithStorage[127.0.0.1:36540,DS-d14b24bc-26a1-4820-bdf7-324a2cb06fea,DISK], DatanodeInfoWithStorage[127.0.0.1:42665,DS-eda377ae-f00d-4825-92bd-df6f13ac5310,DISK], DatanodeInfoWithStorage[127.0.0.1:35572,DS-e20d6d3c-9c7d-4795-b880-cde885aa9182,DISK], DatanodeInfoWithStorage[127.0.0.1:35911,DS-4681ba77-d129-4b34-b60a-eeefd772d71d,DISK], DatanodeInfoWithStorage[127.0.0.1:46595,DS-5d52a40f-b7a6-4ae2-8b97-2b75032c7793,DISK], DatanodeInfoWithStorage[127.0.0.1:33058,DS-b950e9c9-d51e-4c63-ab8c-24af2f971858,DISK], DatanodeInfoWithStorage[127.0.0.1:38735,DS-9b6ada3a-97fe-45fa-a80a-712b1bdabd0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-926641813-172.17.0.14-1596962984241:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40547,DS-d49144d7-1d6c-4515-8012-e9c95b42c521,DISK], DatanodeInfoWithStorage[127.0.0.1:36540,DS-d14b24bc-26a1-4820-bdf7-324a2cb06fea,DISK], DatanodeInfoWithStorage[127.0.0.1:42665,DS-eda377ae-f00d-4825-92bd-df6f13ac5310,DISK], DatanodeInfoWithStorage[127.0.0.1:35572,DS-e20d6d3c-9c7d-4795-b880-cde885aa9182,DISK], DatanodeInfoWithStorage[127.0.0.1:35911,DS-4681ba77-d129-4b34-b60a-eeefd772d71d,DISK], DatanodeInfoWithStorage[127.0.0.1:46595,DS-5d52a40f-b7a6-4ae2-8b97-2b75032c7793,DISK], DatanodeInfoWithStorage[127.0.0.1:33058,DS-b950e9c9-d51e-4c63-ab8c-24af2f971858,DISK], DatanodeInfoWithStorage[127.0.0.1:38735,DS-9b6ada3a-97fe-45fa-a80a-712b1bdabd0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-946733869-172.17.0.14-1596963116288:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33208,DS-b9321e1b-eb4f-4d31-9ae8-f79f568db1bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37332,DS-10792048-7e0c-48a9-9b5e-2363bae8766d,DISK], DatanodeInfoWithStorage[127.0.0.1:46683,DS-1234a3d9-5835-4fa1-bb75-f30f79ce7319,DISK], DatanodeInfoWithStorage[127.0.0.1:38691,DS-55a3785e-0f4f-4b33-94c0-3b7c84b45676,DISK], DatanodeInfoWithStorage[127.0.0.1:45202,DS-4b2bdbed-c59a-4b5a-9153-cf096fcce5f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36041,DS-a133a83f-7f35-41ad-abfe-cfc11b801009,DISK], DatanodeInfoWithStorage[127.0.0.1:42331,DS-fb9b061c-69c6-4734-a218-e7b14b2410da,DISK], DatanodeInfoWithStorage[127.0.0.1:36927,DS-5d29251f-89f6-47aa-bf59-8f96d4cfd962,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-946733869-172.17.0.14-1596963116288:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33208,DS-b9321e1b-eb4f-4d31-9ae8-f79f568db1bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37332,DS-10792048-7e0c-48a9-9b5e-2363bae8766d,DISK], DatanodeInfoWithStorage[127.0.0.1:46683,DS-1234a3d9-5835-4fa1-bb75-f30f79ce7319,DISK], DatanodeInfoWithStorage[127.0.0.1:38691,DS-55a3785e-0f4f-4b33-94c0-3b7c84b45676,DISK], DatanodeInfoWithStorage[127.0.0.1:45202,DS-4b2bdbed-c59a-4b5a-9153-cf096fcce5f5,DISK], DatanodeInfoWithStorage[127.0.0.1:36041,DS-a133a83f-7f35-41ad-abfe-cfc11b801009,DISK], DatanodeInfoWithStorage[127.0.0.1:42331,DS-fb9b061c-69c6-4734-a218-e7b14b2410da,DISK], DatanodeInfoWithStorage[127.0.0.1:36927,DS-5d29251f-89f6-47aa-bf59-8f96d4cfd962,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1364235172-172.17.0.14-1596963157665:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43037,DS-c7cdf9ef-a075-4b9c-8fc5-e23cfe15330a,DISK], DatanodeInfoWithStorage[127.0.0.1:36643,DS-f0b79c6c-cd3e-44ad-91c5-2146a8288357,DISK], DatanodeInfoWithStorage[127.0.0.1:37588,DS-d3f668a7-5456-4d8b-8c9b-ebede5d8d79f,DISK], DatanodeInfoWithStorage[127.0.0.1:34418,DS-acaf3cb2-9eb4-485a-a30b-3eba03bd4d5b,DISK], DatanodeInfoWithStorage[127.0.0.1:36367,DS-aa093ef3-e436-4ac0-8192-97d7c8c10a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:45916,DS-de93f33d-c546-4a61-876c-9c67c75644e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39918,DS-579fc458-56b9-49b5-8fed-5a570db0d33a,DISK], DatanodeInfoWithStorage[127.0.0.1:32846,DS-13c02a1c-d6ef-45b4-b9e1-60bedec9e1b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1364235172-172.17.0.14-1596963157665:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43037,DS-c7cdf9ef-a075-4b9c-8fc5-e23cfe15330a,DISK], DatanodeInfoWithStorage[127.0.0.1:36643,DS-f0b79c6c-cd3e-44ad-91c5-2146a8288357,DISK], DatanodeInfoWithStorage[127.0.0.1:37588,DS-d3f668a7-5456-4d8b-8c9b-ebede5d8d79f,DISK], DatanodeInfoWithStorage[127.0.0.1:34418,DS-acaf3cb2-9eb4-485a-a30b-3eba03bd4d5b,DISK], DatanodeInfoWithStorage[127.0.0.1:36367,DS-aa093ef3-e436-4ac0-8192-97d7c8c10a0e,DISK], DatanodeInfoWithStorage[127.0.0.1:45916,DS-de93f33d-c546-4a61-876c-9c67c75644e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39918,DS-579fc458-56b9-49b5-8fed-5a570db0d33a,DISK], DatanodeInfoWithStorage[127.0.0.1:32846,DS-13c02a1c-d6ef-45b4-b9e1-60bedec9e1b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1519458186-172.17.0.14-1596963411207:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33932,DS-d5b4b69a-3723-4bc2-b441-b95224baebe3,DISK], DatanodeInfoWithStorage[127.0.0.1:33811,DS-077eab79-d8f8-4fda-bb1a-8349c16eb8c1,DISK], DatanodeInfoWithStorage[127.0.0.1:32882,DS-efc6ae6d-7315-4324-b000-6ee0fd77ba32,DISK], DatanodeInfoWithStorage[127.0.0.1:44403,DS-d8a26fea-15bd-47a3-9163-17b48933ebfd,DISK], DatanodeInfoWithStorage[127.0.0.1:43598,DS-819c42e3-7b24-4241-a302-7c488a8381b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45238,DS-1c2fe090-3cd5-4769-87ef-60fcef6c971e,DISK], DatanodeInfoWithStorage[127.0.0.1:34702,DS-d8fdc644-f603-4777-908b-f188684c6309,DISK], DatanodeInfoWithStorage[127.0.0.1:43403,DS-58486385-dc95-4d54-9ac7-354b0d5ce6c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1519458186-172.17.0.14-1596963411207:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33932,DS-d5b4b69a-3723-4bc2-b441-b95224baebe3,DISK], DatanodeInfoWithStorage[127.0.0.1:33811,DS-077eab79-d8f8-4fda-bb1a-8349c16eb8c1,DISK], DatanodeInfoWithStorage[127.0.0.1:32882,DS-efc6ae6d-7315-4324-b000-6ee0fd77ba32,DISK], DatanodeInfoWithStorage[127.0.0.1:44403,DS-d8a26fea-15bd-47a3-9163-17b48933ebfd,DISK], DatanodeInfoWithStorage[127.0.0.1:43598,DS-819c42e3-7b24-4241-a302-7c488a8381b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45238,DS-1c2fe090-3cd5-4769-87ef-60fcef6c971e,DISK], DatanodeInfoWithStorage[127.0.0.1:34702,DS-d8fdc644-f603-4777-908b-f188684c6309,DISK], DatanodeInfoWithStorage[127.0.0.1:43403,DS-58486385-dc95-4d54-9ac7-354b0d5ce6c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-930484421-172.17.0.14-1596963520328:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39772,DS-d3b46cf7-4af1-4e08-9613-d1bb062dbfdb,DISK], DatanodeInfoWithStorage[127.0.0.1:39164,DS-214e4f81-1f46-44e3-933c-bbad35a1104c,DISK], DatanodeInfoWithStorage[127.0.0.1:43679,DS-965bc3ff-20aa-48ce-8f9a-19a21ec331ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38131,DS-b701819a-86f1-461d-b725-bedcf19d4c6b,DISK], DatanodeInfoWithStorage[127.0.0.1:42820,DS-c8ae08e8-52e4-48ea-8292-d421aef47d51,DISK], DatanodeInfoWithStorage[127.0.0.1:35934,DS-f085cac2-9cc4-44d0-a522-0df88426633a,DISK], DatanodeInfoWithStorage[127.0.0.1:38231,DS-4d995f37-72d1-4fcf-b305-a82ab154b3fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36950,DS-854f252c-7b21-4010-ae81-7844dfdfae4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-930484421-172.17.0.14-1596963520328:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39772,DS-d3b46cf7-4af1-4e08-9613-d1bb062dbfdb,DISK], DatanodeInfoWithStorage[127.0.0.1:39164,DS-214e4f81-1f46-44e3-933c-bbad35a1104c,DISK], DatanodeInfoWithStorage[127.0.0.1:43679,DS-965bc3ff-20aa-48ce-8f9a-19a21ec331ff,DISK], DatanodeInfoWithStorage[127.0.0.1:38131,DS-b701819a-86f1-461d-b725-bedcf19d4c6b,DISK], DatanodeInfoWithStorage[127.0.0.1:42820,DS-c8ae08e8-52e4-48ea-8292-d421aef47d51,DISK], DatanodeInfoWithStorage[127.0.0.1:35934,DS-f085cac2-9cc4-44d0-a522-0df88426633a,DISK], DatanodeInfoWithStorage[127.0.0.1:38231,DS-4d995f37-72d1-4fcf-b305-a82ab154b3fb,DISK], DatanodeInfoWithStorage[127.0.0.1:36950,DS-854f252c-7b21-4010-ae81-7844dfdfae4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1020355123-172.17.0.14-1596963592747:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38709,DS-a3d4b27f-1d03-43bd-9efc-17d26b5fdb83,DISK], DatanodeInfoWithStorage[127.0.0.1:37639,DS-889d5e90-b2f0-4b32-91d7-173e4dea3ef1,DISK], DatanodeInfoWithStorage[127.0.0.1:43052,DS-5558b053-d3f6-4154-88e7-ba60768f591d,DISK], DatanodeInfoWithStorage[127.0.0.1:43251,DS-ec5d57c3-b813-4666-a8a6-a683fc2021bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35870,DS-618841bd-9539-4245-b9a4-2a71b916089b,DISK], DatanodeInfoWithStorage[127.0.0.1:40850,DS-3b37b2bb-8e69-4b2e-8d1d-36f6556dad5e,DISK], DatanodeInfoWithStorage[127.0.0.1:37518,DS-05e79223-2bdd-4ad6-9490-dd628fee5721,DISK], DatanodeInfoWithStorage[127.0.0.1:46677,DS-d2d456d7-1052-464b-bc67-88f0e782f3af,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1020355123-172.17.0.14-1596963592747:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38709,DS-a3d4b27f-1d03-43bd-9efc-17d26b5fdb83,DISK], DatanodeInfoWithStorage[127.0.0.1:37639,DS-889d5e90-b2f0-4b32-91d7-173e4dea3ef1,DISK], DatanodeInfoWithStorage[127.0.0.1:43052,DS-5558b053-d3f6-4154-88e7-ba60768f591d,DISK], DatanodeInfoWithStorage[127.0.0.1:43251,DS-ec5d57c3-b813-4666-a8a6-a683fc2021bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35870,DS-618841bd-9539-4245-b9a4-2a71b916089b,DISK], DatanodeInfoWithStorage[127.0.0.1:40850,DS-3b37b2bb-8e69-4b2e-8d1d-36f6556dad5e,DISK], DatanodeInfoWithStorage[127.0.0.1:37518,DS-05e79223-2bdd-4ad6-9490-dd628fee5721,DISK], DatanodeInfoWithStorage[127.0.0.1:46677,DS-d2d456d7-1052-464b-bc67-88f0e782f3af,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1034887547-172.17.0.14-1596963918928:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46469,DS-9559d579-45b5-4bae-937b-811eba8831bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34346,DS-dead64a5-ebfd-413b-a8d8-f9a95db43e7a,DISK], DatanodeInfoWithStorage[127.0.0.1:34293,DS-a80f9946-ecf9-4e9b-bed3-d18d71a8a22e,DISK], DatanodeInfoWithStorage[127.0.0.1:39846,DS-058241a3-033b-4c15-908b-1c90328d7923,DISK], DatanodeInfoWithStorage[127.0.0.1:39205,DS-481da71c-e740-4b34-8d4b-fbce3640b3ec,DISK], DatanodeInfoWithStorage[127.0.0.1:42019,DS-16b3e012-00e4-4851-9167-499349256422,DISK], DatanodeInfoWithStorage[127.0.0.1:44139,DS-8e2bb84d-a032-4f72-ad17-7169cd0a23a3,DISK], DatanodeInfoWithStorage[127.0.0.1:38735,DS-02683af3-9d31-4584-963d-e1fe24175b9d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1034887547-172.17.0.14-1596963918928:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46469,DS-9559d579-45b5-4bae-937b-811eba8831bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34346,DS-dead64a5-ebfd-413b-a8d8-f9a95db43e7a,DISK], DatanodeInfoWithStorage[127.0.0.1:34293,DS-a80f9946-ecf9-4e9b-bed3-d18d71a8a22e,DISK], DatanodeInfoWithStorage[127.0.0.1:39846,DS-058241a3-033b-4c15-908b-1c90328d7923,DISK], DatanodeInfoWithStorage[127.0.0.1:39205,DS-481da71c-e740-4b34-8d4b-fbce3640b3ec,DISK], DatanodeInfoWithStorage[127.0.0.1:42019,DS-16b3e012-00e4-4851-9167-499349256422,DISK], DatanodeInfoWithStorage[127.0.0.1:44139,DS-8e2bb84d-a032-4f72-ad17-7169cd0a23a3,DISK], DatanodeInfoWithStorage[127.0.0.1:38735,DS-02683af3-9d31-4584-963d-e1fe24175b9d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-203337641-172.17.0.14-1596963955965:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38916,DS-f8d95f21-4fba-452a-910c-67b25a9ad624,DISK], DatanodeInfoWithStorage[127.0.0.1:39452,DS-619ab3d7-c3eb-4b55-ac4e-9b061c663b64,DISK], DatanodeInfoWithStorage[127.0.0.1:34133,DS-f0a4a540-72e3-4501-8cc3-405cc2884865,DISK], DatanodeInfoWithStorage[127.0.0.1:39933,DS-d97027d4-2e4a-4b30-8251-0b99272a3687,DISK], DatanodeInfoWithStorage[127.0.0.1:35166,DS-27b1fcb1-2726-41ce-95e3-595ada820150,DISK], DatanodeInfoWithStorage[127.0.0.1:39224,DS-91efc06e-7e6c-454e-94e5-f3919db28cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:39973,DS-1e3f892a-5913-4dcc-99dd-472a039a5625,DISK], DatanodeInfoWithStorage[127.0.0.1:34355,DS-534c161d-666c-4a6e-bce3-796ab0c0ed36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-203337641-172.17.0.14-1596963955965:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38916,DS-f8d95f21-4fba-452a-910c-67b25a9ad624,DISK], DatanodeInfoWithStorage[127.0.0.1:39452,DS-619ab3d7-c3eb-4b55-ac4e-9b061c663b64,DISK], DatanodeInfoWithStorage[127.0.0.1:34133,DS-f0a4a540-72e3-4501-8cc3-405cc2884865,DISK], DatanodeInfoWithStorage[127.0.0.1:39933,DS-d97027d4-2e4a-4b30-8251-0b99272a3687,DISK], DatanodeInfoWithStorage[127.0.0.1:35166,DS-27b1fcb1-2726-41ce-95e3-595ada820150,DISK], DatanodeInfoWithStorage[127.0.0.1:39224,DS-91efc06e-7e6c-454e-94e5-f3919db28cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:39973,DS-1e3f892a-5913-4dcc-99dd-472a039a5625,DISK], DatanodeInfoWithStorage[127.0.0.1:34355,DS-534c161d-666c-4a6e-bce3-796ab0c0ed36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.disk.balancer.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1598482747-172.17.0.14-1596964158350:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39478,DS-60e66d93-9ec7-4fa3-b504-d53501859e16,DISK], DatanodeInfoWithStorage[127.0.0.1:38787,DS-2cdaa7cb-a632-4dd6-ab81-6e3f6866279e,DISK], DatanodeInfoWithStorage[127.0.0.1:33402,DS-cfc0dddd-5891-4f99-b33a-a0550908bbbd,DISK], DatanodeInfoWithStorage[127.0.0.1:38483,DS-0e9aa1c0-9c21-482c-8953-dd18a957d0c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34325,DS-07de48b9-68e2-4a9e-a35a-ee408117c593,DISK], DatanodeInfoWithStorage[127.0.0.1:45793,DS-6c7437fa-9f7a-42bd-a457-a7ad3ab5c72e,DISK], DatanodeInfoWithStorage[127.0.0.1:44063,DS-c1578bb6-d8ed-4f9c-bf62-4147b05504b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34036,DS-dfddbeba-2b8a-4753-bfbb-ceaccb250b10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1598482747-172.17.0.14-1596964158350:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39478,DS-60e66d93-9ec7-4fa3-b504-d53501859e16,DISK], DatanodeInfoWithStorage[127.0.0.1:38787,DS-2cdaa7cb-a632-4dd6-ab81-6e3f6866279e,DISK], DatanodeInfoWithStorage[127.0.0.1:33402,DS-cfc0dddd-5891-4f99-b33a-a0550908bbbd,DISK], DatanodeInfoWithStorage[127.0.0.1:38483,DS-0e9aa1c0-9c21-482c-8953-dd18a957d0c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34325,DS-07de48b9-68e2-4a9e-a35a-ee408117c593,DISK], DatanodeInfoWithStorage[127.0.0.1:45793,DS-6c7437fa-9f7a-42bd-a457-a7ad3ab5c72e,DISK], DatanodeInfoWithStorage[127.0.0.1:44063,DS-c1578bb6-d8ed-4f9c-bf62-4147b05504b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34036,DS-dfddbeba-2b8a-4753-bfbb-ceaccb250b10,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 20 out of 50
result: false positive !!!
Total execution time in seconds : 5243
