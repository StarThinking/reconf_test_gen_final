reconf_parameter: dfs.namenode.top.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.top.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-920638366-172.17.0.17-1595314606446:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40633,DS-eb786e4f-f77f-488d-8cb6-121015c2fc01,DISK], DatanodeInfoWithStorage[127.0.0.1:41186,DS-e2915067-af4f-488d-b176-7800a231ecb3,DISK], DatanodeInfoWithStorage[127.0.0.1:37509,DS-822c4f47-aeb8-4f1a-aa1f-4981c4494bae,DISK], DatanodeInfoWithStorage[127.0.0.1:39269,DS-99eaf42b-634b-409a-b71d-ad9a82c5df2e,DISK], DatanodeInfoWithStorage[127.0.0.1:32963,DS-8c8da6e6-f734-40f9-a1f0-2be0bb2643cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42221,DS-54cc5076-1099-4d5a-a19a-f0d712960b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:38367,DS-fd015093-8efd-443c-9620-bb4fe69b6b79,DISK], DatanodeInfoWithStorage[127.0.0.1:44741,DS-a7e0630e-c029-4546-bb90-c93b31a2dab1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-920638366-172.17.0.17-1595314606446:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40633,DS-eb786e4f-f77f-488d-8cb6-121015c2fc01,DISK], DatanodeInfoWithStorage[127.0.0.1:41186,DS-e2915067-af4f-488d-b176-7800a231ecb3,DISK], DatanodeInfoWithStorage[127.0.0.1:37509,DS-822c4f47-aeb8-4f1a-aa1f-4981c4494bae,DISK], DatanodeInfoWithStorage[127.0.0.1:39269,DS-99eaf42b-634b-409a-b71d-ad9a82c5df2e,DISK], DatanodeInfoWithStorage[127.0.0.1:32963,DS-8c8da6e6-f734-40f9-a1f0-2be0bb2643cd,DISK], DatanodeInfoWithStorage[127.0.0.1:42221,DS-54cc5076-1099-4d5a-a19a-f0d712960b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:38367,DS-fd015093-8efd-443c-9620-bb4fe69b6b79,DISK], DatanodeInfoWithStorage[127.0.0.1:44741,DS-a7e0630e-c029-4546-bb90-c93b31a2dab1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.top.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1918004097-172.17.0.17-1595314927112:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35434,DS-aa98c719-0c9f-4749-ab51-bacdba6b04cc,DISK], DatanodeInfoWithStorage[127.0.0.1:40906,DS-f6f18f9a-0154-4f19-b7ea-180627787b71,DISK], DatanodeInfoWithStorage[127.0.0.1:46153,DS-95a4cbcc-125c-417a-a73a-e1ea97538373,DISK], DatanodeInfoWithStorage[127.0.0.1:43158,DS-5c23c1e8-6048-45c9-be58-9a72b4738ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:45626,DS-b1b2e87c-0bf2-43ad-ab21-954ab3feaae4,DISK], DatanodeInfoWithStorage[127.0.0.1:38247,DS-86c52018-de74-4a10-9a0d-1dd9e82c4d31,DISK], DatanodeInfoWithStorage[127.0.0.1:35044,DS-7e639f38-74fb-466a-9ae5-a7a8fc4bf3f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38802,DS-e9a9bfe7-ca62-42a6-a123-b647505270a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1918004097-172.17.0.17-1595314927112:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35434,DS-aa98c719-0c9f-4749-ab51-bacdba6b04cc,DISK], DatanodeInfoWithStorage[127.0.0.1:40906,DS-f6f18f9a-0154-4f19-b7ea-180627787b71,DISK], DatanodeInfoWithStorage[127.0.0.1:46153,DS-95a4cbcc-125c-417a-a73a-e1ea97538373,DISK], DatanodeInfoWithStorage[127.0.0.1:43158,DS-5c23c1e8-6048-45c9-be58-9a72b4738ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:45626,DS-b1b2e87c-0bf2-43ad-ab21-954ab3feaae4,DISK], DatanodeInfoWithStorage[127.0.0.1:38247,DS-86c52018-de74-4a10-9a0d-1dd9e82c4d31,DISK], DatanodeInfoWithStorage[127.0.0.1:35044,DS-7e639f38-74fb-466a-9ae5-a7a8fc4bf3f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38802,DS-e9a9bfe7-ca62-42a6-a123-b647505270a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1645372097-172.17.0.17-1595315512652:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35919,DS-bca61a81-5da4-4e7c-a17c-891ed68d1850,DISK], DatanodeInfoWithStorage[127.0.0.1:45931,DS-d406ef3a-1d6c-45c0-8ede-d1643968d833,DISK], DatanodeInfoWithStorage[127.0.0.1:33654,DS-aeb731e9-2dea-4b7c-9be8-d3e76df1b6b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44283,DS-1486a371-ae5a-4499-8401-98ee41bde6ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43321,DS-6f851651-42df-42e9-989b-f881aacfe1e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40775,DS-c03d0015-8609-4176-a38a-cc83e7abd188,DISK], DatanodeInfoWithStorage[127.0.0.1:44005,DS-481268d6-bd2e-4275-9ea8-b0c0eebfed26,DISK], DatanodeInfoWithStorage[127.0.0.1:37194,DS-a2d75956-114e-4cff-99ca-211216337e89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1645372097-172.17.0.17-1595315512652:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35919,DS-bca61a81-5da4-4e7c-a17c-891ed68d1850,DISK], DatanodeInfoWithStorage[127.0.0.1:45931,DS-d406ef3a-1d6c-45c0-8ede-d1643968d833,DISK], DatanodeInfoWithStorage[127.0.0.1:33654,DS-aeb731e9-2dea-4b7c-9be8-d3e76df1b6b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44283,DS-1486a371-ae5a-4499-8401-98ee41bde6ae,DISK], DatanodeInfoWithStorage[127.0.0.1:43321,DS-6f851651-42df-42e9-989b-f881aacfe1e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40775,DS-c03d0015-8609-4176-a38a-cc83e7abd188,DISK], DatanodeInfoWithStorage[127.0.0.1:44005,DS-481268d6-bd2e-4275-9ea8-b0c0eebfed26,DISK], DatanodeInfoWithStorage[127.0.0.1:37194,DS-a2d75956-114e-4cff-99ca-211216337e89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1478583066-172.17.0.17-1595315782154:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34609,DS-31b298fe-31f8-4863-91c4-e41e0f0f1e28,DISK], DatanodeInfoWithStorage[127.0.0.1:38872,DS-3c3cd38c-baab-42c8-b07e-d5cf4cce70a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33508,DS-462c1491-91b6-4fbc-a5d1-32599e9bc3b2,DISK], DatanodeInfoWithStorage[127.0.0.1:46553,DS-b0ee7869-107d-4af2-8ea0-5dec84dfc072,DISK], DatanodeInfoWithStorage[127.0.0.1:32812,DS-7f745144-eea2-4929-8480-da2de949a6b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41406,DS-286320f9-b1d4-4253-9e1d-c7e0cf9833f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42656,DS-a7c969b8-7734-4e84-8b82-23a5956c857f,DISK], DatanodeInfoWithStorage[127.0.0.1:43324,DS-394dbd0f-dfaf-4954-9cb5-fd270fd534d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1478583066-172.17.0.17-1595315782154:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34609,DS-31b298fe-31f8-4863-91c4-e41e0f0f1e28,DISK], DatanodeInfoWithStorage[127.0.0.1:38872,DS-3c3cd38c-baab-42c8-b07e-d5cf4cce70a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33508,DS-462c1491-91b6-4fbc-a5d1-32599e9bc3b2,DISK], DatanodeInfoWithStorage[127.0.0.1:46553,DS-b0ee7869-107d-4af2-8ea0-5dec84dfc072,DISK], DatanodeInfoWithStorage[127.0.0.1:32812,DS-7f745144-eea2-4929-8480-da2de949a6b0,DISK], DatanodeInfoWithStorage[127.0.0.1:41406,DS-286320f9-b1d4-4253-9e1d-c7e0cf9833f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42656,DS-a7c969b8-7734-4e84-8b82-23a5956c857f,DISK], DatanodeInfoWithStorage[127.0.0.1:43324,DS-394dbd0f-dfaf-4954-9cb5-fd270fd534d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.top.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-933597127-172.17.0.17-1595316274546:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43764,DS-1af5b2c5-a049-43ea-b3eb-225e5a42643e,DISK], DatanodeInfoWithStorage[127.0.0.1:45763,DS-3b5fa958-1d5a-4879-bd03-33fc0d8a5bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:45732,DS-bcc98834-c3fe-4a0d-85d2-c8683e9466a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35077,DS-05ea6603-1778-4ba8-a9db-a7b00b9de40c,DISK], DatanodeInfoWithStorage[127.0.0.1:39547,DS-72cc62b0-da4d-45f8-8e6d-e351bc2dee6a,DISK], DatanodeInfoWithStorage[127.0.0.1:40223,DS-3bcd08af-1955-476a-85f7-f68a83ddb4b0,DISK], DatanodeInfoWithStorage[127.0.0.1:34263,DS-0a21e44c-16b7-42e4-994a-0f72bd2fb22c,DISK], DatanodeInfoWithStorage[127.0.0.1:41667,DS-71e07bd3-960c-4730-b39c-5e7e7574cf8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-933597127-172.17.0.17-1595316274546:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43764,DS-1af5b2c5-a049-43ea-b3eb-225e5a42643e,DISK], DatanodeInfoWithStorage[127.0.0.1:45763,DS-3b5fa958-1d5a-4879-bd03-33fc0d8a5bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:45732,DS-bcc98834-c3fe-4a0d-85d2-c8683e9466a1,DISK], DatanodeInfoWithStorage[127.0.0.1:35077,DS-05ea6603-1778-4ba8-a9db-a7b00b9de40c,DISK], DatanodeInfoWithStorage[127.0.0.1:39547,DS-72cc62b0-da4d-45f8-8e6d-e351bc2dee6a,DISK], DatanodeInfoWithStorage[127.0.0.1:40223,DS-3bcd08af-1955-476a-85f7-f68a83ddb4b0,DISK], DatanodeInfoWithStorage[127.0.0.1:34263,DS-0a21e44c-16b7-42e4-994a-0f72bd2fb22c,DISK], DatanodeInfoWithStorage[127.0.0.1:41667,DS-71e07bd3-960c-4730-b39c-5e7e7574cf8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1335425746-172.17.0.17-1595316345519:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43508,DS-32fe223e-4b82-44db-828c-93820a499544,DISK], DatanodeInfoWithStorage[127.0.0.1:41958,DS-12aef38a-ffbb-487e-bf69-76b24c8104ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43603,DS-1a3462eb-d1da-4729-b881-8c4601217499,DISK], DatanodeInfoWithStorage[127.0.0.1:43168,DS-6f4f82f7-35c7-4c66-8f6d-d9c0ba18f8c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45673,DS-f2fbcb92-9b54-40b5-acaa-eeb654f03b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:46110,DS-8e7afc51-6f8f-477a-bf5b-24e09844bdc5,DISK], DatanodeInfoWithStorage[127.0.0.1:36352,DS-802d1b13-5a52-4b0b-8203-f1372317ddc9,DISK], DatanodeInfoWithStorage[127.0.0.1:36602,DS-33494606-fd30-4b74-a563-493dc819e049,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1335425746-172.17.0.17-1595316345519:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43508,DS-32fe223e-4b82-44db-828c-93820a499544,DISK], DatanodeInfoWithStorage[127.0.0.1:41958,DS-12aef38a-ffbb-487e-bf69-76b24c8104ac,DISK], DatanodeInfoWithStorage[127.0.0.1:43603,DS-1a3462eb-d1da-4729-b881-8c4601217499,DISK], DatanodeInfoWithStorage[127.0.0.1:43168,DS-6f4f82f7-35c7-4c66-8f6d-d9c0ba18f8c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45673,DS-f2fbcb92-9b54-40b5-acaa-eeb654f03b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:46110,DS-8e7afc51-6f8f-477a-bf5b-24e09844bdc5,DISK], DatanodeInfoWithStorage[127.0.0.1:36352,DS-802d1b13-5a52-4b0b-8203-f1372317ddc9,DISK], DatanodeInfoWithStorage[127.0.0.1:36602,DS-33494606-fd30-4b74-a563-493dc819e049,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-610722127-172.17.0.17-1595316451681:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40406,DS-ef5ecf7b-7a00-4b60-829a-47948dbcfe17,DISK], DatanodeInfoWithStorage[127.0.0.1:41181,DS-ca59e525-2f0e-4b61-8ec6-3203a1daefa8,DISK], DatanodeInfoWithStorage[127.0.0.1:39077,DS-e61786c2-eeb2-47e3-9aad-73d10ca18e61,DISK], DatanodeInfoWithStorage[127.0.0.1:36343,DS-0d9e917e-a40e-44cb-a82b-bf2d33d094de,DISK], DatanodeInfoWithStorage[127.0.0.1:37206,DS-63dbd316-a4d7-434c-90ac-1e753734e392,DISK], DatanodeInfoWithStorage[127.0.0.1:42101,DS-9d25151a-3332-45c0-8810-8829117d242a,DISK], DatanodeInfoWithStorage[127.0.0.1:37809,DS-d9063356-725d-4952-9352-f6b493a2d4b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37757,DS-616f0a78-075f-4aeb-a135-df355719054d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-610722127-172.17.0.17-1595316451681:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40406,DS-ef5ecf7b-7a00-4b60-829a-47948dbcfe17,DISK], DatanodeInfoWithStorage[127.0.0.1:41181,DS-ca59e525-2f0e-4b61-8ec6-3203a1daefa8,DISK], DatanodeInfoWithStorage[127.0.0.1:39077,DS-e61786c2-eeb2-47e3-9aad-73d10ca18e61,DISK], DatanodeInfoWithStorage[127.0.0.1:36343,DS-0d9e917e-a40e-44cb-a82b-bf2d33d094de,DISK], DatanodeInfoWithStorage[127.0.0.1:37206,DS-63dbd316-a4d7-434c-90ac-1e753734e392,DISK], DatanodeInfoWithStorage[127.0.0.1:42101,DS-9d25151a-3332-45c0-8810-8829117d242a,DISK], DatanodeInfoWithStorage[127.0.0.1:37809,DS-d9063356-725d-4952-9352-f6b493a2d4b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37757,DS-616f0a78-075f-4aeb-a135-df355719054d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-824724524-172.17.0.17-1595316565363:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38131,DS-4f92e70d-c8b1-44b4-895e-17e3d149054b,DISK], DatanodeInfoWithStorage[127.0.0.1:33494,DS-b949162f-9080-47c2-8b5e-df1d14801130,DISK], DatanodeInfoWithStorage[127.0.0.1:45847,DS-1bbb80b9-abfa-4465-bac7-331cae927efd,DISK], DatanodeInfoWithStorage[127.0.0.1:40793,DS-2b41e18a-400e-4b8d-baa2-44869f50e9ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42167,DS-563b17ff-b8d7-4965-8cb3-45ca9c4c8d57,DISK], DatanodeInfoWithStorage[127.0.0.1:36779,DS-7d6a6790-ee17-4ebd-bae8-c90f2c3338d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36690,DS-b275a3fb-0cc0-4726-9a17-130ad66f2ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:33459,DS-02be4900-2399-4230-b8cb-8b02b0ac7a68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-824724524-172.17.0.17-1595316565363:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38131,DS-4f92e70d-c8b1-44b4-895e-17e3d149054b,DISK], DatanodeInfoWithStorage[127.0.0.1:33494,DS-b949162f-9080-47c2-8b5e-df1d14801130,DISK], DatanodeInfoWithStorage[127.0.0.1:45847,DS-1bbb80b9-abfa-4465-bac7-331cae927efd,DISK], DatanodeInfoWithStorage[127.0.0.1:40793,DS-2b41e18a-400e-4b8d-baa2-44869f50e9ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42167,DS-563b17ff-b8d7-4965-8cb3-45ca9c4c8d57,DISK], DatanodeInfoWithStorage[127.0.0.1:36779,DS-7d6a6790-ee17-4ebd-bae8-c90f2c3338d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36690,DS-b275a3fb-0cc0-4726-9a17-130ad66f2ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:33459,DS-02be4900-2399-4230-b8cb-8b02b0ac7a68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1625379266-172.17.0.17-1595316645290:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42569,DS-33d7585f-6b97-47cc-8afc-c3b09bcb1910,DISK], DatanodeInfoWithStorage[127.0.0.1:37939,DS-b7043942-0b41-4f59-98de-ca6c78915736,DISK], DatanodeInfoWithStorage[127.0.0.1:45853,DS-051ca0d0-0f94-4695-969a-605a643974e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40011,DS-9b3fd46e-1380-4f83-8235-29124a4cee5a,DISK], DatanodeInfoWithStorage[127.0.0.1:37384,DS-fc0b9c6d-ae9b-4f3f-b871-c5c58920472f,DISK], DatanodeInfoWithStorage[127.0.0.1:37054,DS-05f6ca3b-9cb0-4965-8485-431301ada92a,DISK], DatanodeInfoWithStorage[127.0.0.1:46472,DS-de21ad9c-3047-4618-8663-5b7943a53c33,DISK], DatanodeInfoWithStorage[127.0.0.1:42762,DS-f7054b88-3366-4b3f-871f-9fe1a516e8bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1625379266-172.17.0.17-1595316645290:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42569,DS-33d7585f-6b97-47cc-8afc-c3b09bcb1910,DISK], DatanodeInfoWithStorage[127.0.0.1:37939,DS-b7043942-0b41-4f59-98de-ca6c78915736,DISK], DatanodeInfoWithStorage[127.0.0.1:45853,DS-051ca0d0-0f94-4695-969a-605a643974e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40011,DS-9b3fd46e-1380-4f83-8235-29124a4cee5a,DISK], DatanodeInfoWithStorage[127.0.0.1:37384,DS-fc0b9c6d-ae9b-4f3f-b871-c5c58920472f,DISK], DatanodeInfoWithStorage[127.0.0.1:37054,DS-05f6ca3b-9cb0-4965-8485-431301ada92a,DISK], DatanodeInfoWithStorage[127.0.0.1:46472,DS-de21ad9c-3047-4618-8663-5b7943a53c33,DISK], DatanodeInfoWithStorage[127.0.0.1:42762,DS-f7054b88-3366-4b3f-871f-9fe1a516e8bd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1254879123-172.17.0.17-1595316914915:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34967,DS-f8ebf2de-b659-4877-ab3b-e3b1136c599f,DISK], DatanodeInfoWithStorage[127.0.0.1:37682,DS-250949fb-3ef2-4354-96d0-29f015b4d614,DISK], DatanodeInfoWithStorage[127.0.0.1:41698,DS-1b35e1c8-8236-40b6-a362-0d547bc68640,DISK], DatanodeInfoWithStorage[127.0.0.1:36532,DS-5e904f9a-dba5-41b6-911d-ccd3e4f5392c,DISK], DatanodeInfoWithStorage[127.0.0.1:44875,DS-6b56cac8-db3d-42ec-85be-c2e6051802c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40863,DS-a6da3d65-4873-495c-bf18-0ed328f9f23f,DISK], DatanodeInfoWithStorage[127.0.0.1:39640,DS-a72a8771-6ef6-41c2-be28-e32015371e38,DISK], DatanodeInfoWithStorage[127.0.0.1:46007,DS-e596f26c-ded9-47c5-a03d-feaf6309def2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1254879123-172.17.0.17-1595316914915:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34967,DS-f8ebf2de-b659-4877-ab3b-e3b1136c599f,DISK], DatanodeInfoWithStorage[127.0.0.1:37682,DS-250949fb-3ef2-4354-96d0-29f015b4d614,DISK], DatanodeInfoWithStorage[127.0.0.1:41698,DS-1b35e1c8-8236-40b6-a362-0d547bc68640,DISK], DatanodeInfoWithStorage[127.0.0.1:36532,DS-5e904f9a-dba5-41b6-911d-ccd3e4f5392c,DISK], DatanodeInfoWithStorage[127.0.0.1:44875,DS-6b56cac8-db3d-42ec-85be-c2e6051802c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40863,DS-a6da3d65-4873-495c-bf18-0ed328f9f23f,DISK], DatanodeInfoWithStorage[127.0.0.1:39640,DS-a72a8771-6ef6-41c2-be28-e32015371e38,DISK], DatanodeInfoWithStorage[127.0.0.1:46007,DS-e596f26c-ded9-47c5-a03d-feaf6309def2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1621920974-172.17.0.17-1595317039455:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38930,DS-41bc3744-3e42-4890-bab3-66f9dac860a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43528,DS-6ea134b7-10bd-4523-a3da-fe369423970f,DISK], DatanodeInfoWithStorage[127.0.0.1:42994,DS-145cbb50-39f1-4b73-8397-8467cbba6197,DISK], DatanodeInfoWithStorage[127.0.0.1:42986,DS-b536e80e-3cd1-4632-8ade-d83941bac567,DISK], DatanodeInfoWithStorage[127.0.0.1:46446,DS-89a949a3-b6ea-45d4-a64c-cc426b24e0d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44118,DS-d1cf772f-ce94-4ff2-b9f3-382cd162c3d6,DISK], DatanodeInfoWithStorage[127.0.0.1:36665,DS-00ff458f-a825-4636-bd06-49d77a4a06ef,DISK], DatanodeInfoWithStorage[127.0.0.1:32894,DS-501a9294-cd3a-4740-839a-b2fe066d31cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1621920974-172.17.0.17-1595317039455:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38930,DS-41bc3744-3e42-4890-bab3-66f9dac860a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43528,DS-6ea134b7-10bd-4523-a3da-fe369423970f,DISK], DatanodeInfoWithStorage[127.0.0.1:42994,DS-145cbb50-39f1-4b73-8397-8467cbba6197,DISK], DatanodeInfoWithStorage[127.0.0.1:42986,DS-b536e80e-3cd1-4632-8ade-d83941bac567,DISK], DatanodeInfoWithStorage[127.0.0.1:46446,DS-89a949a3-b6ea-45d4-a64c-cc426b24e0d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44118,DS-d1cf772f-ce94-4ff2-b9f3-382cd162c3d6,DISK], DatanodeInfoWithStorage[127.0.0.1:36665,DS-00ff458f-a825-4636-bd06-49d77a4a06ef,DISK], DatanodeInfoWithStorage[127.0.0.1:32894,DS-501a9294-cd3a-4740-839a-b2fe066d31cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1457478828-172.17.0.17-1595317369812:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44798,DS-1939e9bf-7ce3-4a56-8ad8-539b48525f8c,DISK], DatanodeInfoWithStorage[127.0.0.1:36745,DS-50f548f1-533a-48f7-85f0-3cbdbac97984,DISK], DatanodeInfoWithStorage[127.0.0.1:35599,DS-5565f795-e6ad-45dd-8d35-588453f2d8a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40542,DS-310669ab-bf89-4d22-892e-04a4386af8e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40964,DS-9bd324fa-fc3e-4726-97f3-ef9efebbaf33,DISK], DatanodeInfoWithStorage[127.0.0.1:46748,DS-d0136f78-38a4-4804-be27-c90cada2ebc0,DISK], DatanodeInfoWithStorage[127.0.0.1:42885,DS-cf14830b-7140-4596-bd70-0bcf4a1b2a49,DISK], DatanodeInfoWithStorage[127.0.0.1:44531,DS-4b0a81d3-614d-49b5-b014-791728f9b27a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1457478828-172.17.0.17-1595317369812:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44798,DS-1939e9bf-7ce3-4a56-8ad8-539b48525f8c,DISK], DatanodeInfoWithStorage[127.0.0.1:36745,DS-50f548f1-533a-48f7-85f0-3cbdbac97984,DISK], DatanodeInfoWithStorage[127.0.0.1:35599,DS-5565f795-e6ad-45dd-8d35-588453f2d8a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40542,DS-310669ab-bf89-4d22-892e-04a4386af8e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40964,DS-9bd324fa-fc3e-4726-97f3-ef9efebbaf33,DISK], DatanodeInfoWithStorage[127.0.0.1:46748,DS-d0136f78-38a4-4804-be27-c90cada2ebc0,DISK], DatanodeInfoWithStorage[127.0.0.1:42885,DS-cf14830b-7140-4596-bd70-0bcf4a1b2a49,DISK], DatanodeInfoWithStorage[127.0.0.1:44531,DS-4b0a81d3-614d-49b5-b014-791728f9b27a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.top.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-999565676-172.17.0.17-1595317834825:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38179,DS-7f8b226c-3b06-436c-8b5b-2ee4b5a00390,DISK], DatanodeInfoWithStorage[127.0.0.1:43389,DS-39dd1c1c-a6d2-42b0-a5c0-30951cb98189,DISK], DatanodeInfoWithStorage[127.0.0.1:37864,DS-c7aca624-3100-40d2-81ae-66c160c56ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:34327,DS-dbc5c221-a783-49d2-9eda-70326a33eb5c,DISK], DatanodeInfoWithStorage[127.0.0.1:34587,DS-3e5dd406-2c73-4087-aa25-bec32ee6420e,DISK], DatanodeInfoWithStorage[127.0.0.1:39164,DS-ee631707-5a92-4d2a-a0a6-7d8d398c7a02,DISK], DatanodeInfoWithStorage[127.0.0.1:40480,DS-ada193f0-953a-4cee-92d0-e14679c1b441,DISK], DatanodeInfoWithStorage[127.0.0.1:43380,DS-702b8d24-50df-4453-bfd8-ba6361aec4bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-999565676-172.17.0.17-1595317834825:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38179,DS-7f8b226c-3b06-436c-8b5b-2ee4b5a00390,DISK], DatanodeInfoWithStorage[127.0.0.1:43389,DS-39dd1c1c-a6d2-42b0-a5c0-30951cb98189,DISK], DatanodeInfoWithStorage[127.0.0.1:37864,DS-c7aca624-3100-40d2-81ae-66c160c56ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:34327,DS-dbc5c221-a783-49d2-9eda-70326a33eb5c,DISK], DatanodeInfoWithStorage[127.0.0.1:34587,DS-3e5dd406-2c73-4087-aa25-bec32ee6420e,DISK], DatanodeInfoWithStorage[127.0.0.1:39164,DS-ee631707-5a92-4d2a-a0a6-7d8d398c7a02,DISK], DatanodeInfoWithStorage[127.0.0.1:40480,DS-ada193f0-953a-4cee-92d0-e14679c1b441,DISK], DatanodeInfoWithStorage[127.0.0.1:43380,DS-702b8d24-50df-4453-bfd8-ba6361aec4bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.top.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1821908373-172.17.0.17-1595318679722:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44649,DS-3545eeac-4415-41e1-9cad-252ef9da8e83,DISK], DatanodeInfoWithStorage[127.0.0.1:43207,DS-92ebd8b4-178f-4381-b53d-cd5790a5ec1b,DISK], DatanodeInfoWithStorage[127.0.0.1:40945,DS-afc821eb-1d6a-437e-abe6-1ba583d1ff57,DISK], DatanodeInfoWithStorage[127.0.0.1:46882,DS-408bf64c-5805-4c5e-897f-37c952c6a1e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38734,DS-500cd136-578f-424d-bfa0-edb8bb439afa,DISK], DatanodeInfoWithStorage[127.0.0.1:33806,DS-22613802-b405-492d-8592-da5a799b67ff,DISK], DatanodeInfoWithStorage[127.0.0.1:34748,DS-a8f8e4c5-4b1d-4216-a3dc-fbe48a3242a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44161,DS-7fa7a4e0-6fbc-419d-b533-c8175ca2146b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1821908373-172.17.0.17-1595318679722:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44649,DS-3545eeac-4415-41e1-9cad-252ef9da8e83,DISK], DatanodeInfoWithStorage[127.0.0.1:43207,DS-92ebd8b4-178f-4381-b53d-cd5790a5ec1b,DISK], DatanodeInfoWithStorage[127.0.0.1:40945,DS-afc821eb-1d6a-437e-abe6-1ba583d1ff57,DISK], DatanodeInfoWithStorage[127.0.0.1:46882,DS-408bf64c-5805-4c5e-897f-37c952c6a1e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38734,DS-500cd136-578f-424d-bfa0-edb8bb439afa,DISK], DatanodeInfoWithStorage[127.0.0.1:33806,DS-22613802-b405-492d-8592-da5a799b67ff,DISK], DatanodeInfoWithStorage[127.0.0.1:34748,DS-a8f8e4c5-4b1d-4216-a3dc-fbe48a3242a6,DISK], DatanodeInfoWithStorage[127.0.0.1:44161,DS-7fa7a4e0-6fbc-419d-b533-c8175ca2146b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5611
