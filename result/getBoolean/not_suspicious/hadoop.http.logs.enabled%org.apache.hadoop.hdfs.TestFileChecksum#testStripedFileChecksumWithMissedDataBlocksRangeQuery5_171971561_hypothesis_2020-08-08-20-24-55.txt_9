reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1425200294-172.17.0.2-1596918572269:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33574,DS-86ec4da7-4e6a-46d4-9c14-64ac447010f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40937,DS-d12d8dd3-9141-4f0c-8464-bb518943f84f,DISK], DatanodeInfoWithStorage[127.0.0.1:38156,DS-6a9dd44d-0d29-47c6-9c06-2d87cc48cd15,DISK], DatanodeInfoWithStorage[127.0.0.1:38316,DS-977f865e-205e-459d-8c56-07aac8e1ab82,DISK], DatanodeInfoWithStorage[127.0.0.1:40993,DS-a9366b33-cfb0-4981-8142-1edc1cd1137f,DISK], DatanodeInfoWithStorage[127.0.0.1:43377,DS-38580d91-73d0-4955-b5b0-596a4d41d5bb,DISK], DatanodeInfoWithStorage[127.0.0.1:46093,DS-ee5f0734-26e3-411b-80d1-0e90b024c53c,DISK], DatanodeInfoWithStorage[127.0.0.1:38216,DS-dc409a75-464e-4e6c-a5e7-f6e378e5ae5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1425200294-172.17.0.2-1596918572269:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33574,DS-86ec4da7-4e6a-46d4-9c14-64ac447010f2,DISK], DatanodeInfoWithStorage[127.0.0.1:40937,DS-d12d8dd3-9141-4f0c-8464-bb518943f84f,DISK], DatanodeInfoWithStorage[127.0.0.1:38156,DS-6a9dd44d-0d29-47c6-9c06-2d87cc48cd15,DISK], DatanodeInfoWithStorage[127.0.0.1:38316,DS-977f865e-205e-459d-8c56-07aac8e1ab82,DISK], DatanodeInfoWithStorage[127.0.0.1:40993,DS-a9366b33-cfb0-4981-8142-1edc1cd1137f,DISK], DatanodeInfoWithStorage[127.0.0.1:43377,DS-38580d91-73d0-4955-b5b0-596a4d41d5bb,DISK], DatanodeInfoWithStorage[127.0.0.1:46093,DS-ee5f0734-26e3-411b-80d1-0e90b024c53c,DISK], DatanodeInfoWithStorage[127.0.0.1:38216,DS-dc409a75-464e-4e6c-a5e7-f6e378e5ae5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-890361731-172.17.0.2-1596918602671:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46249,DS-0d37a1fd-f7d6-419d-87bf-a24a3b3b83c0,DISK], DatanodeInfoWithStorage[127.0.0.1:44913,DS-95b3fce9-213e-4131-a8ee-5117a207cec3,DISK], DatanodeInfoWithStorage[127.0.0.1:34964,DS-0e652035-f579-446b-b1bf-d4d57a541fef,DISK], DatanodeInfoWithStorage[127.0.0.1:41890,DS-68b162b0-b2bf-4c60-9cbd-d4a3e3ec7767,DISK], DatanodeInfoWithStorage[127.0.0.1:44206,DS-d8ee0023-8b77-4ab3-bbb6-9f96f1dbe972,DISK], DatanodeInfoWithStorage[127.0.0.1:43816,DS-04145780-f34a-45a9-bdda-80d6e8bac728,DISK], DatanodeInfoWithStorage[127.0.0.1:33015,DS-949d19d9-f359-43d4-8abf-0e382761f750,DISK], DatanodeInfoWithStorage[127.0.0.1:33204,DS-deeaf0d1-9f81-40b3-a22a-378a5d8f9dca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-890361731-172.17.0.2-1596918602671:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46249,DS-0d37a1fd-f7d6-419d-87bf-a24a3b3b83c0,DISK], DatanodeInfoWithStorage[127.0.0.1:44913,DS-95b3fce9-213e-4131-a8ee-5117a207cec3,DISK], DatanodeInfoWithStorage[127.0.0.1:34964,DS-0e652035-f579-446b-b1bf-d4d57a541fef,DISK], DatanodeInfoWithStorage[127.0.0.1:41890,DS-68b162b0-b2bf-4c60-9cbd-d4a3e3ec7767,DISK], DatanodeInfoWithStorage[127.0.0.1:44206,DS-d8ee0023-8b77-4ab3-bbb6-9f96f1dbe972,DISK], DatanodeInfoWithStorage[127.0.0.1:43816,DS-04145780-f34a-45a9-bdda-80d6e8bac728,DISK], DatanodeInfoWithStorage[127.0.0.1:33015,DS-949d19d9-f359-43d4-8abf-0e382761f750,DISK], DatanodeInfoWithStorage[127.0.0.1:33204,DS-deeaf0d1-9f81-40b3-a22a-378a5d8f9dca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1549418344-172.17.0.2-1596918846818:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38951,DS-7390439e-2026-4602-9eeb-b188b0da4ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:38863,DS-6e458cd9-b7c7-4165-b3b0-d3a694db2a3f,DISK], DatanodeInfoWithStorage[127.0.0.1:43007,DS-2888ebcf-b98b-44e5-b240-1fd239992698,DISK], DatanodeInfoWithStorage[127.0.0.1:45661,DS-97155c93-9da4-4fa2-8d66-79aee73569ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40137,DS-8ed55126-cbb6-4827-9b8b-7be83534c652,DISK], DatanodeInfoWithStorage[127.0.0.1:34201,DS-67f746f6-14fa-47e2-9050-7217f5bd6be9,DISK], DatanodeInfoWithStorage[127.0.0.1:41286,DS-9b526bef-33fc-42ec-a0e4-4653a5959f5b,DISK], DatanodeInfoWithStorage[127.0.0.1:42078,DS-6607467c-e6c0-4d0c-b565-9b0cce374c27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1549418344-172.17.0.2-1596918846818:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38951,DS-7390439e-2026-4602-9eeb-b188b0da4ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:38863,DS-6e458cd9-b7c7-4165-b3b0-d3a694db2a3f,DISK], DatanodeInfoWithStorage[127.0.0.1:43007,DS-2888ebcf-b98b-44e5-b240-1fd239992698,DISK], DatanodeInfoWithStorage[127.0.0.1:45661,DS-97155c93-9da4-4fa2-8d66-79aee73569ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40137,DS-8ed55126-cbb6-4827-9b8b-7be83534c652,DISK], DatanodeInfoWithStorage[127.0.0.1:34201,DS-67f746f6-14fa-47e2-9050-7217f5bd6be9,DISK], DatanodeInfoWithStorage[127.0.0.1:41286,DS-9b526bef-33fc-42ec-a0e4-4653a5959f5b,DISK], DatanodeInfoWithStorage[127.0.0.1:42078,DS-6607467c-e6c0-4d0c-b565-9b0cce374c27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1653614999-172.17.0.2-1596919339082:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38252,DS-720ad373-12d4-4f55-92ef-c521bc652cac,DISK], DatanodeInfoWithStorage[127.0.0.1:41300,DS-fec389b4-b512-40da-a995-8fde4abc04bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39295,DS-f871a0aa-c5cd-4f5d-afa3-d5e2e4368a8b,DISK], DatanodeInfoWithStorage[127.0.0.1:45095,DS-892a6a60-41f9-4e80-bf7f-93bce53bf0a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46846,DS-dbfcba95-0832-4fe9-9b35-728a95f5f553,DISK], DatanodeInfoWithStorage[127.0.0.1:40961,DS-d3874be3-c5ca-4dcd-b247-e684d5316580,DISK], DatanodeInfoWithStorage[127.0.0.1:36520,DS-4c52d979-7b00-447d-bf61-b6a738f8948a,DISK], DatanodeInfoWithStorage[127.0.0.1:38092,DS-be4d2868-d17d-4d4f-830a-09388db18830,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1653614999-172.17.0.2-1596919339082:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38252,DS-720ad373-12d4-4f55-92ef-c521bc652cac,DISK], DatanodeInfoWithStorage[127.0.0.1:41300,DS-fec389b4-b512-40da-a995-8fde4abc04bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39295,DS-f871a0aa-c5cd-4f5d-afa3-d5e2e4368a8b,DISK], DatanodeInfoWithStorage[127.0.0.1:45095,DS-892a6a60-41f9-4e80-bf7f-93bce53bf0a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46846,DS-dbfcba95-0832-4fe9-9b35-728a95f5f553,DISK], DatanodeInfoWithStorage[127.0.0.1:40961,DS-d3874be3-c5ca-4dcd-b247-e684d5316580,DISK], DatanodeInfoWithStorage[127.0.0.1:36520,DS-4c52d979-7b00-447d-bf61-b6a738f8948a,DISK], DatanodeInfoWithStorage[127.0.0.1:38092,DS-be4d2868-d17d-4d4f-830a-09388db18830,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1323284432-172.17.0.2-1596919450041:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36553,DS-5182a6f9-80c5-40b4-b8bb-d1f2a60ee1cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41022,DS-dfa54a38-9650-437f-801c-f38fe3cc6b3a,DISK], DatanodeInfoWithStorage[127.0.0.1:37295,DS-55023fe3-2a5c-47d3-97de-901821ac24ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45390,DS-1f996e78-cd99-4021-906c-5cdb3558d8c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43527,DS-14caebb1-6fa2-493a-bc57-64c035f902f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41431,DS-f4136eb6-3c4a-4795-9add-58935ed64c24,DISK], DatanodeInfoWithStorage[127.0.0.1:44189,DS-6a5b7c89-38bc-412d-b8ef-b922e143e83e,DISK], DatanodeInfoWithStorage[127.0.0.1:44856,DS-d614a2ab-89fe-4b96-afd8-85cfe966bc89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1323284432-172.17.0.2-1596919450041:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36553,DS-5182a6f9-80c5-40b4-b8bb-d1f2a60ee1cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41022,DS-dfa54a38-9650-437f-801c-f38fe3cc6b3a,DISK], DatanodeInfoWithStorage[127.0.0.1:37295,DS-55023fe3-2a5c-47d3-97de-901821ac24ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45390,DS-1f996e78-cd99-4021-906c-5cdb3558d8c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43527,DS-14caebb1-6fa2-493a-bc57-64c035f902f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41431,DS-f4136eb6-3c4a-4795-9add-58935ed64c24,DISK], DatanodeInfoWithStorage[127.0.0.1:44189,DS-6a5b7c89-38bc-412d-b8ef-b922e143e83e,DISK], DatanodeInfoWithStorage[127.0.0.1:44856,DS-d614a2ab-89fe-4b96-afd8-85cfe966bc89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1060662538-172.17.0.2-1596920044496:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36361,DS-4de216ad-04f9-4726-8ad7-0435024dd7bc,DISK], DatanodeInfoWithStorage[127.0.0.1:36504,DS-29b01832-027f-48b7-a43a-503d927bbf12,DISK], DatanodeInfoWithStorage[127.0.0.1:42446,DS-e4d99674-1e54-46d9-adac-828b57d8ab3a,DISK], DatanodeInfoWithStorage[127.0.0.1:40845,DS-e7bf00f7-4c1a-4be6-8daa-f6447c18649e,DISK], DatanodeInfoWithStorage[127.0.0.1:39742,DS-44338511-989e-4a21-8cf0-63b495bf8fc0,DISK], DatanodeInfoWithStorage[127.0.0.1:41677,DS-63abac91-a116-40a4-b4c3-5d15a4eab94b,DISK], DatanodeInfoWithStorage[127.0.0.1:37706,DS-07c75847-0376-4781-b08f-056ec2725c36,DISK], DatanodeInfoWithStorage[127.0.0.1:42578,DS-25680934-3b86-4954-9ede-e46396a54a99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1060662538-172.17.0.2-1596920044496:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36361,DS-4de216ad-04f9-4726-8ad7-0435024dd7bc,DISK], DatanodeInfoWithStorage[127.0.0.1:36504,DS-29b01832-027f-48b7-a43a-503d927bbf12,DISK], DatanodeInfoWithStorage[127.0.0.1:42446,DS-e4d99674-1e54-46d9-adac-828b57d8ab3a,DISK], DatanodeInfoWithStorage[127.0.0.1:40845,DS-e7bf00f7-4c1a-4be6-8daa-f6447c18649e,DISK], DatanodeInfoWithStorage[127.0.0.1:39742,DS-44338511-989e-4a21-8cf0-63b495bf8fc0,DISK], DatanodeInfoWithStorage[127.0.0.1:41677,DS-63abac91-a116-40a4-b4c3-5d15a4eab94b,DISK], DatanodeInfoWithStorage[127.0.0.1:37706,DS-07c75847-0376-4781-b08f-056ec2725c36,DISK], DatanodeInfoWithStorage[127.0.0.1:42578,DS-25680934-3b86-4954-9ede-e46396a54a99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-651605047-172.17.0.2-1596920807716:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46827,DS-34c9e2b0-dd65-466c-a046-bcfbd1ebdd2c,DISK], DatanodeInfoWithStorage[127.0.0.1:37856,DS-6e854382-d048-44fa-b4c5-4107835f05b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33883,DS-794c9f97-2c48-4d07-942e-5091f9031ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:38688,DS-93c0d794-970a-4b1e-9f09-b43c87f5b3ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38912,DS-b2ab1d8d-7201-45c8-b793-036c98d6ca0c,DISK], DatanodeInfoWithStorage[127.0.0.1:37476,DS-3ae1f04f-30bf-4b93-89c3-1e5ec061f4ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44414,DS-fa3a3c0e-05c6-4b66-9b96-edb85a0831b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42636,DS-88554a18-78e8-4cea-868d-0733d2b794df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-651605047-172.17.0.2-1596920807716:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46827,DS-34c9e2b0-dd65-466c-a046-bcfbd1ebdd2c,DISK], DatanodeInfoWithStorage[127.0.0.1:37856,DS-6e854382-d048-44fa-b4c5-4107835f05b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33883,DS-794c9f97-2c48-4d07-942e-5091f9031ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:38688,DS-93c0d794-970a-4b1e-9f09-b43c87f5b3ec,DISK], DatanodeInfoWithStorage[127.0.0.1:38912,DS-b2ab1d8d-7201-45c8-b793-036c98d6ca0c,DISK], DatanodeInfoWithStorage[127.0.0.1:37476,DS-3ae1f04f-30bf-4b93-89c3-1e5ec061f4ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44414,DS-fa3a3c0e-05c6-4b66-9b96-edb85a0831b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42636,DS-88554a18-78e8-4cea-868d-0733d2b794df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1326924845-172.17.0.2-1596921128926:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35371,DS-140bffaa-7a10-4d0d-9be1-c1fd55e8c9a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46258,DS-7b6f94c5-4c97-44ae-afe4-c46d1225b07e,DISK], DatanodeInfoWithStorage[127.0.0.1:38254,DS-2211ed0c-a30a-4d4d-ab49-491fd031fae1,DISK], DatanodeInfoWithStorage[127.0.0.1:38872,DS-2cfb83e4-9d3b-4803-ba62-4b03aee5f1df,DISK], DatanodeInfoWithStorage[127.0.0.1:39675,DS-f071ab47-ceb6-40c0-800d-2df5a21e1f98,DISK], DatanodeInfoWithStorage[127.0.0.1:45515,DS-6c2f2b44-2c29-4737-be05-ef1b07093d70,DISK], DatanodeInfoWithStorage[127.0.0.1:44169,DS-af93f1a4-427d-4cb8-a80b-2b94cb01fa1c,DISK], DatanodeInfoWithStorage[127.0.0.1:41276,DS-028fe3ff-2781-4d37-83b6-7183bb949dab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1326924845-172.17.0.2-1596921128926:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35371,DS-140bffaa-7a10-4d0d-9be1-c1fd55e8c9a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46258,DS-7b6f94c5-4c97-44ae-afe4-c46d1225b07e,DISK], DatanodeInfoWithStorage[127.0.0.1:38254,DS-2211ed0c-a30a-4d4d-ab49-491fd031fae1,DISK], DatanodeInfoWithStorage[127.0.0.1:38872,DS-2cfb83e4-9d3b-4803-ba62-4b03aee5f1df,DISK], DatanodeInfoWithStorage[127.0.0.1:39675,DS-f071ab47-ceb6-40c0-800d-2df5a21e1f98,DISK], DatanodeInfoWithStorage[127.0.0.1:45515,DS-6c2f2b44-2c29-4737-be05-ef1b07093d70,DISK], DatanodeInfoWithStorage[127.0.0.1:44169,DS-af93f1a4-427d-4cb8-a80b-2b94cb01fa1c,DISK], DatanodeInfoWithStorage[127.0.0.1:41276,DS-028fe3ff-2781-4d37-83b6-7183bb949dab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-865423640-172.17.0.2-1596921529809:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37218,DS-5234ee81-a28e-4c20-83c4-e46e96f91c8a,DISK], DatanodeInfoWithStorage[127.0.0.1:42258,DS-f17c914e-23cd-4ab4-977d-7d2f4d188401,DISK], DatanodeInfoWithStorage[127.0.0.1:41878,DS-0c1fd33c-d3bd-4708-aefe-a7b8b070082d,DISK], DatanodeInfoWithStorage[127.0.0.1:35770,DS-98232c20-9e36-4419-a19d-d6feb39d89d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41164,DS-2d8a47a4-590f-4cc9-b72f-0bf01b44e144,DISK], DatanodeInfoWithStorage[127.0.0.1:42440,DS-eeed5cf0-0e7b-48d8-a0a9-7b1c480ec4d5,DISK], DatanodeInfoWithStorage[127.0.0.1:37959,DS-9e61cd82-ea22-4f96-9d22-cd3448c604ea,DISK], DatanodeInfoWithStorage[127.0.0.1:46640,DS-fe41d15a-2e66-4403-85b7-863c2dca65f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-865423640-172.17.0.2-1596921529809:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37218,DS-5234ee81-a28e-4c20-83c4-e46e96f91c8a,DISK], DatanodeInfoWithStorage[127.0.0.1:42258,DS-f17c914e-23cd-4ab4-977d-7d2f4d188401,DISK], DatanodeInfoWithStorage[127.0.0.1:41878,DS-0c1fd33c-d3bd-4708-aefe-a7b8b070082d,DISK], DatanodeInfoWithStorage[127.0.0.1:35770,DS-98232c20-9e36-4419-a19d-d6feb39d89d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41164,DS-2d8a47a4-590f-4cc9-b72f-0bf01b44e144,DISK], DatanodeInfoWithStorage[127.0.0.1:42440,DS-eeed5cf0-0e7b-48d8-a0a9-7b1c480ec4d5,DISK], DatanodeInfoWithStorage[127.0.0.1:37959,DS-9e61cd82-ea22-4f96-9d22-cd3448c604ea,DISK], DatanodeInfoWithStorage[127.0.0.1:46640,DS-fe41d15a-2e66-4403-85b7-863c2dca65f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-917287055-172.17.0.2-1596921783161:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39103,DS-eebd4839-29a1-4cb1-8ce8-fa47b169341a,DISK], DatanodeInfoWithStorage[127.0.0.1:37969,DS-e462ec17-3b31-4cd0-b71c-f30172cb64c0,DISK], DatanodeInfoWithStorage[127.0.0.1:44645,DS-aeda2f84-592d-4d4a-a700-95d576bd0fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:40451,DS-5b99771f-4290-473f-b5b7-81d6ffb87f81,DISK], DatanodeInfoWithStorage[127.0.0.1:33049,DS-7ad12fe8-8daa-4f4a-b701-f9ac5e33b7e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37572,DS-0b756082-77f0-4a22-8a97-909c72a82b40,DISK], DatanodeInfoWithStorage[127.0.0.1:36243,DS-b65df314-819d-463c-9389-c1b2eeab670a,DISK], DatanodeInfoWithStorage[127.0.0.1:43518,DS-187fe69f-8698-4415-b6c6-866a887d285e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-917287055-172.17.0.2-1596921783161:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39103,DS-eebd4839-29a1-4cb1-8ce8-fa47b169341a,DISK], DatanodeInfoWithStorage[127.0.0.1:37969,DS-e462ec17-3b31-4cd0-b71c-f30172cb64c0,DISK], DatanodeInfoWithStorage[127.0.0.1:44645,DS-aeda2f84-592d-4d4a-a700-95d576bd0fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:40451,DS-5b99771f-4290-473f-b5b7-81d6ffb87f81,DISK], DatanodeInfoWithStorage[127.0.0.1:33049,DS-7ad12fe8-8daa-4f4a-b701-f9ac5e33b7e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37572,DS-0b756082-77f0-4a22-8a97-909c72a82b40,DISK], DatanodeInfoWithStorage[127.0.0.1:36243,DS-b65df314-819d-463c-9389-c1b2eeab670a,DISK], DatanodeInfoWithStorage[127.0.0.1:43518,DS-187fe69f-8698-4415-b6c6-866a887d285e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1300216382-172.17.0.2-1596921899578:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40073,DS-6a518bac-8de3-4abd-9187-cc4fc2863e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:44362,DS-46db2c7e-ed6a-49e4-a27b-2d11cbde9845,DISK], DatanodeInfoWithStorage[127.0.0.1:45455,DS-39efdc46-7a23-4afb-804d-740e6b4d5111,DISK], DatanodeInfoWithStorage[127.0.0.1:36899,DS-2a1ed29d-66e5-466f-b298-d721d9beabc6,DISK], DatanodeInfoWithStorage[127.0.0.1:38264,DS-47f3124d-5ced-4cff-96f9-71e45abed854,DISK], DatanodeInfoWithStorage[127.0.0.1:44136,DS-fc1d9912-0e8d-442b-9e23-d3254631b07e,DISK], DatanodeInfoWithStorage[127.0.0.1:35420,DS-13240437-4933-4e7a-a642-415116889e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:40668,DS-41b15600-ee25-4a9a-91f1-1db3aef44660,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1300216382-172.17.0.2-1596921899578:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40073,DS-6a518bac-8de3-4abd-9187-cc4fc2863e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:44362,DS-46db2c7e-ed6a-49e4-a27b-2d11cbde9845,DISK], DatanodeInfoWithStorage[127.0.0.1:45455,DS-39efdc46-7a23-4afb-804d-740e6b4d5111,DISK], DatanodeInfoWithStorage[127.0.0.1:36899,DS-2a1ed29d-66e5-466f-b298-d721d9beabc6,DISK], DatanodeInfoWithStorage[127.0.0.1:38264,DS-47f3124d-5ced-4cff-96f9-71e45abed854,DISK], DatanodeInfoWithStorage[127.0.0.1:44136,DS-fc1d9912-0e8d-442b-9e23-d3254631b07e,DISK], DatanodeInfoWithStorage[127.0.0.1:35420,DS-13240437-4933-4e7a-a642-415116889e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:40668,DS-41b15600-ee25-4a9a-91f1-1db3aef44660,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-369400510-172.17.0.2-1596922403447:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44219,DS-3ca133a3-9fce-46a2-905d-f250c0473fa7,DISK], DatanodeInfoWithStorage[127.0.0.1:33436,DS-8da99421-c582-41f4-96a8-ca87c3dbde57,DISK], DatanodeInfoWithStorage[127.0.0.1:36034,DS-0952c513-bf52-4b56-88df-a8efd7e0afff,DISK], DatanodeInfoWithStorage[127.0.0.1:44733,DS-09b09b36-4bed-47cd-b077-c1f831ed5ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:41260,DS-1a760ed4-b89d-40ff-8ca7-79713295c1eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40030,DS-ba7ca795-2f55-46da-9584-4674dc0a3a92,DISK], DatanodeInfoWithStorage[127.0.0.1:40976,DS-97eb253b-4311-4d1d-b8ba-26d4ed88ce78,DISK], DatanodeInfoWithStorage[127.0.0.1:35169,DS-39bcc046-7d9c-4ba1-b49b-5eed3e981185,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-369400510-172.17.0.2-1596922403447:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44219,DS-3ca133a3-9fce-46a2-905d-f250c0473fa7,DISK], DatanodeInfoWithStorage[127.0.0.1:33436,DS-8da99421-c582-41f4-96a8-ca87c3dbde57,DISK], DatanodeInfoWithStorage[127.0.0.1:36034,DS-0952c513-bf52-4b56-88df-a8efd7e0afff,DISK], DatanodeInfoWithStorage[127.0.0.1:44733,DS-09b09b36-4bed-47cd-b077-c1f831ed5ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:41260,DS-1a760ed4-b89d-40ff-8ca7-79713295c1eb,DISK], DatanodeInfoWithStorage[127.0.0.1:40030,DS-ba7ca795-2f55-46da-9584-4674dc0a3a92,DISK], DatanodeInfoWithStorage[127.0.0.1:40976,DS-97eb253b-4311-4d1d-b8ba-26d4ed88ce78,DISK], DatanodeInfoWithStorage[127.0.0.1:35169,DS-39bcc046-7d9c-4ba1-b49b-5eed3e981185,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1365243500-172.17.0.2-1596922731142:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39028,DS-53bed47c-d304-4d81-b6ee-8ed0e48a9711,DISK], DatanodeInfoWithStorage[127.0.0.1:45928,DS-df819943-e130-4f7c-bfe9-3f71a62eb6c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39306,DS-751e2f8c-9239-46bc-ae95-95470f3cf7ac,DISK], DatanodeInfoWithStorage[127.0.0.1:33724,DS-dd04f1ac-74a1-4558-8622-b74506eeda6d,DISK], DatanodeInfoWithStorage[127.0.0.1:40095,DS-5cd8ba5f-196a-47aa-ab3d-de1fa2c5e451,DISK], DatanodeInfoWithStorage[127.0.0.1:41593,DS-2fd0490d-c789-4c33-ae8d-0cbc307b441b,DISK], DatanodeInfoWithStorage[127.0.0.1:34946,DS-a855fb1e-250d-4465-8394-7dcd3c804c75,DISK], DatanodeInfoWithStorage[127.0.0.1:40296,DS-f3b853f6-0392-42b5-b258-73e8df28b391,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1365243500-172.17.0.2-1596922731142:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39028,DS-53bed47c-d304-4d81-b6ee-8ed0e48a9711,DISK], DatanodeInfoWithStorage[127.0.0.1:45928,DS-df819943-e130-4f7c-bfe9-3f71a62eb6c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39306,DS-751e2f8c-9239-46bc-ae95-95470f3cf7ac,DISK], DatanodeInfoWithStorage[127.0.0.1:33724,DS-dd04f1ac-74a1-4558-8622-b74506eeda6d,DISK], DatanodeInfoWithStorage[127.0.0.1:40095,DS-5cd8ba5f-196a-47aa-ab3d-de1fa2c5e451,DISK], DatanodeInfoWithStorage[127.0.0.1:41593,DS-2fd0490d-c789-4c33-ae8d-0cbc307b441b,DISK], DatanodeInfoWithStorage[127.0.0.1:34946,DS-a855fb1e-250d-4465-8394-7dcd3c804c75,DISK], DatanodeInfoWithStorage[127.0.0.1:40296,DS-f3b853f6-0392-42b5-b258-73e8df28b391,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1586793321-172.17.0.2-1596923547989:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37775,DS-fef44db4-e4c3-4e0a-90e4-be09862d6673,DISK], DatanodeInfoWithStorage[127.0.0.1:36641,DS-375ea383-ab2f-4e7d-b768-db31bce015b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45905,DS-e6c44aa5-c241-4d63-bcd4-ada14b9249d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40845,DS-c54d7bd8-328c-48b1-bf9f-d1387391fbd6,DISK], DatanodeInfoWithStorage[127.0.0.1:43395,DS-19f6df8a-e52f-4c36-b42d-09073e0f1ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:33009,DS-ed2db9b8-b4b6-4c29-8f3c-ac6a6f33fb32,DISK], DatanodeInfoWithStorage[127.0.0.1:42442,DS-67a6b3a3-202c-4d94-bf96-6a27b70b78fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34509,DS-885daf1c-9be0-4c2c-94a9-8da5edd4815d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1586793321-172.17.0.2-1596923547989:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37775,DS-fef44db4-e4c3-4e0a-90e4-be09862d6673,DISK], DatanodeInfoWithStorage[127.0.0.1:36641,DS-375ea383-ab2f-4e7d-b768-db31bce015b6,DISK], DatanodeInfoWithStorage[127.0.0.1:45905,DS-e6c44aa5-c241-4d63-bcd4-ada14b9249d0,DISK], DatanodeInfoWithStorage[127.0.0.1:40845,DS-c54d7bd8-328c-48b1-bf9f-d1387391fbd6,DISK], DatanodeInfoWithStorage[127.0.0.1:43395,DS-19f6df8a-e52f-4c36-b42d-09073e0f1ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:33009,DS-ed2db9b8-b4b6-4c29-8f3c-ac6a6f33fb32,DISK], DatanodeInfoWithStorage[127.0.0.1:42442,DS-67a6b3a3-202c-4d94-bf96-6a27b70b78fd,DISK], DatanodeInfoWithStorage[127.0.0.1:34509,DS-885daf1c-9be0-4c2c-94a9-8da5edd4815d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5404
