reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-556505416-172.17.0.5-1596948346717:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40692,DS-a027bb37-55b7-4014-88d9-8f2284c195a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33259,DS-b32c2182-f0a3-4346-be21-783b2f34d434,DISK], DatanodeInfoWithStorage[127.0.0.1:37602,DS-3d2aaa7f-1f39-4085-ac29-ff0ee2a168c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46610,DS-e620d72e-939e-411c-b946-e2ec7fc459cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40671,DS-26b112fa-2515-4569-827e-80cfa5e824a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37672,DS-57cf41ea-d64e-4574-8a80-6da0ae7f2416,DISK], DatanodeInfoWithStorage[127.0.0.1:42033,DS-0be69a91-5bc7-42b9-aa6b-cec1d89423ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37706,DS-e5415293-8185-4559-98e9-ab7cb790df54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-556505416-172.17.0.5-1596948346717:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40692,DS-a027bb37-55b7-4014-88d9-8f2284c195a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33259,DS-b32c2182-f0a3-4346-be21-783b2f34d434,DISK], DatanodeInfoWithStorage[127.0.0.1:37602,DS-3d2aaa7f-1f39-4085-ac29-ff0ee2a168c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46610,DS-e620d72e-939e-411c-b946-e2ec7fc459cf,DISK], DatanodeInfoWithStorage[127.0.0.1:40671,DS-26b112fa-2515-4569-827e-80cfa5e824a8,DISK], DatanodeInfoWithStorage[127.0.0.1:37672,DS-57cf41ea-d64e-4574-8a80-6da0ae7f2416,DISK], DatanodeInfoWithStorage[127.0.0.1:42033,DS-0be69a91-5bc7-42b9-aa6b-cec1d89423ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37706,DS-e5415293-8185-4559-98e9-ab7cb790df54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1832885036-172.17.0.5-1596948382827:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40740,DS-9073c242-e233-46c0-9938-83cc3aa575c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44314,DS-93d272a7-19a0-48d2-9a5b-c43d8c4367e2,DISK], DatanodeInfoWithStorage[127.0.0.1:43502,DS-6ab2903e-d96b-4228-a8dd-7910ec358f43,DISK], DatanodeInfoWithStorage[127.0.0.1:43486,DS-aee538cd-80a8-4973-850f-546710cbbcc1,DISK], DatanodeInfoWithStorage[127.0.0.1:40156,DS-5816ce3b-7a10-4b79-bcea-eb475bbaf412,DISK], DatanodeInfoWithStorage[127.0.0.1:38684,DS-d4c27bdd-d2f8-4a14-bee4-26c42babd4f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38856,DS-8e33e17f-b3e1-4502-958b-5af8d8d02242,DISK], DatanodeInfoWithStorage[127.0.0.1:42140,DS-0184b3a3-f66e-4cfa-8fab-1bc94575a948,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1832885036-172.17.0.5-1596948382827:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40740,DS-9073c242-e233-46c0-9938-83cc3aa575c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44314,DS-93d272a7-19a0-48d2-9a5b-c43d8c4367e2,DISK], DatanodeInfoWithStorage[127.0.0.1:43502,DS-6ab2903e-d96b-4228-a8dd-7910ec358f43,DISK], DatanodeInfoWithStorage[127.0.0.1:43486,DS-aee538cd-80a8-4973-850f-546710cbbcc1,DISK], DatanodeInfoWithStorage[127.0.0.1:40156,DS-5816ce3b-7a10-4b79-bcea-eb475bbaf412,DISK], DatanodeInfoWithStorage[127.0.0.1:38684,DS-d4c27bdd-d2f8-4a14-bee4-26c42babd4f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38856,DS-8e33e17f-b3e1-4502-958b-5af8d8d02242,DISK], DatanodeInfoWithStorage[127.0.0.1:42140,DS-0184b3a3-f66e-4cfa-8fab-1bc94575a948,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-615700291-172.17.0.5-1596948490065:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44314,DS-893f6727-8d79-42af-a4ff-03b020b51c59,DISK], DatanodeInfoWithStorage[127.0.0.1:34007,DS-39ba4616-effe-4aac-9f80-4d0753bdd57b,DISK], DatanodeInfoWithStorage[127.0.0.1:34904,DS-13da9d5c-fc93-4967-8eef-7f5a52fd54e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40104,DS-b03e4542-ef9f-47d6-83e1-7e6d9208d15d,DISK], DatanodeInfoWithStorage[127.0.0.1:38581,DS-76d67a16-990e-4272-9af7-ccf08a7e5787,DISK], DatanodeInfoWithStorage[127.0.0.1:37336,DS-844feb14-38e4-46a9-b4f0-f808a98d0769,DISK], DatanodeInfoWithStorage[127.0.0.1:40619,DS-46679e87-abb2-4ece-af0a-3b5f727b0965,DISK], DatanodeInfoWithStorage[127.0.0.1:41475,DS-62686173-6878-4095-89e6-f03fcec04cff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-615700291-172.17.0.5-1596948490065:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44314,DS-893f6727-8d79-42af-a4ff-03b020b51c59,DISK], DatanodeInfoWithStorage[127.0.0.1:34007,DS-39ba4616-effe-4aac-9f80-4d0753bdd57b,DISK], DatanodeInfoWithStorage[127.0.0.1:34904,DS-13da9d5c-fc93-4967-8eef-7f5a52fd54e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40104,DS-b03e4542-ef9f-47d6-83e1-7e6d9208d15d,DISK], DatanodeInfoWithStorage[127.0.0.1:38581,DS-76d67a16-990e-4272-9af7-ccf08a7e5787,DISK], DatanodeInfoWithStorage[127.0.0.1:37336,DS-844feb14-38e4-46a9-b4f0-f808a98d0769,DISK], DatanodeInfoWithStorage[127.0.0.1:40619,DS-46679e87-abb2-4ece-af0a-3b5f727b0965,DISK], DatanodeInfoWithStorage[127.0.0.1:41475,DS-62686173-6878-4095-89e6-f03fcec04cff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1686462181-172.17.0.5-1596948625703:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43888,DS-b490dc47-499e-4c4c-ad95-c05436d94ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:37776,DS-ab635f6b-f5d7-4cfa-a6d0-d2c21d945bed,DISK], DatanodeInfoWithStorage[127.0.0.1:39956,DS-fbe36985-4a68-4d95-b301-b7317f71124c,DISK], DatanodeInfoWithStorage[127.0.0.1:41033,DS-4307dfec-2563-4dc5-afaa-3da08230a551,DISK], DatanodeInfoWithStorage[127.0.0.1:40229,DS-329c42cb-62bb-4974-ac8c-276510638adc,DISK], DatanodeInfoWithStorage[127.0.0.1:41982,DS-6955debc-9812-4200-b0f2-699328d40613,DISK], DatanodeInfoWithStorage[127.0.0.1:46635,DS-ffbc28e2-b4ea-4979-a94a-6d0f9a96afd1,DISK], DatanodeInfoWithStorage[127.0.0.1:35666,DS-3a8f9c0d-15cb-4da5-a072-e28349f6fcab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1686462181-172.17.0.5-1596948625703:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43888,DS-b490dc47-499e-4c4c-ad95-c05436d94ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:37776,DS-ab635f6b-f5d7-4cfa-a6d0-d2c21d945bed,DISK], DatanodeInfoWithStorage[127.0.0.1:39956,DS-fbe36985-4a68-4d95-b301-b7317f71124c,DISK], DatanodeInfoWithStorage[127.0.0.1:41033,DS-4307dfec-2563-4dc5-afaa-3da08230a551,DISK], DatanodeInfoWithStorage[127.0.0.1:40229,DS-329c42cb-62bb-4974-ac8c-276510638adc,DISK], DatanodeInfoWithStorage[127.0.0.1:41982,DS-6955debc-9812-4200-b0f2-699328d40613,DISK], DatanodeInfoWithStorage[127.0.0.1:46635,DS-ffbc28e2-b4ea-4979-a94a-6d0f9a96afd1,DISK], DatanodeInfoWithStorage[127.0.0.1:35666,DS-3a8f9c0d-15cb-4da5-a072-e28349f6fcab,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-306122011-172.17.0.5-1596949312022:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43690,DS-7724f840-f5f8-4bea-984d-13528ee7585d,DISK], DatanodeInfoWithStorage[127.0.0.1:46569,DS-d1433331-df50-45dd-bd1f-c8e4a27e1447,DISK], DatanodeInfoWithStorage[127.0.0.1:35170,DS-e2e2198a-306d-41aa-9fb3-a51d649d182c,DISK], DatanodeInfoWithStorage[127.0.0.1:33569,DS-f1fa98c4-df74-462a-ab1b-7e983ac6517a,DISK], DatanodeInfoWithStorage[127.0.0.1:34900,DS-3e58b16f-741b-4916-a9b7-4ac74980633c,DISK], DatanodeInfoWithStorage[127.0.0.1:43480,DS-ae9f45d2-9045-44a4-b715-9ba781183ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:44673,DS-989a2f74-e98f-4de8-8a9d-a729888f6620,DISK], DatanodeInfoWithStorage[127.0.0.1:33052,DS-d73c23af-e9fd-4be6-b8e6-be8252ea63e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-306122011-172.17.0.5-1596949312022:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43690,DS-7724f840-f5f8-4bea-984d-13528ee7585d,DISK], DatanodeInfoWithStorage[127.0.0.1:46569,DS-d1433331-df50-45dd-bd1f-c8e4a27e1447,DISK], DatanodeInfoWithStorage[127.0.0.1:35170,DS-e2e2198a-306d-41aa-9fb3-a51d649d182c,DISK], DatanodeInfoWithStorage[127.0.0.1:33569,DS-f1fa98c4-df74-462a-ab1b-7e983ac6517a,DISK], DatanodeInfoWithStorage[127.0.0.1:34900,DS-3e58b16f-741b-4916-a9b7-4ac74980633c,DISK], DatanodeInfoWithStorage[127.0.0.1:43480,DS-ae9f45d2-9045-44a4-b715-9ba781183ad2,DISK], DatanodeInfoWithStorage[127.0.0.1:44673,DS-989a2f74-e98f-4de8-8a9d-a729888f6620,DISK], DatanodeInfoWithStorage[127.0.0.1:33052,DS-d73c23af-e9fd-4be6-b8e6-be8252ea63e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1060028738-172.17.0.5-1596949427370:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35177,DS-885885df-cdfb-4731-abee-7076c1c3b21f,DISK], DatanodeInfoWithStorage[127.0.0.1:37166,DS-0a721aca-7b89-4e33-8c6b-72386c6e7ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:42543,DS-4436fb00-d47d-4487-b898-61abf3d55450,DISK], DatanodeInfoWithStorage[127.0.0.1:39469,DS-86d6b123-40c3-48aa-8697-644496648d7c,DISK], DatanodeInfoWithStorage[127.0.0.1:46458,DS-54c51542-94c2-43aa-8714-b913731bbbde,DISK], DatanodeInfoWithStorage[127.0.0.1:35812,DS-eea58789-daff-4fe3-a9b1-9603c469f356,DISK], DatanodeInfoWithStorage[127.0.0.1:44396,DS-763f66e6-ef58-4da6-bc9f-96deae4d1e51,DISK], DatanodeInfoWithStorage[127.0.0.1:46176,DS-7b0cbbc4-f312-4e7a-bde8-28e6a3a3ccef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1060028738-172.17.0.5-1596949427370:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35177,DS-885885df-cdfb-4731-abee-7076c1c3b21f,DISK], DatanodeInfoWithStorage[127.0.0.1:37166,DS-0a721aca-7b89-4e33-8c6b-72386c6e7ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:42543,DS-4436fb00-d47d-4487-b898-61abf3d55450,DISK], DatanodeInfoWithStorage[127.0.0.1:39469,DS-86d6b123-40c3-48aa-8697-644496648d7c,DISK], DatanodeInfoWithStorage[127.0.0.1:46458,DS-54c51542-94c2-43aa-8714-b913731bbbde,DISK], DatanodeInfoWithStorage[127.0.0.1:35812,DS-eea58789-daff-4fe3-a9b1-9603c469f356,DISK], DatanodeInfoWithStorage[127.0.0.1:44396,DS-763f66e6-ef58-4da6-bc9f-96deae4d1e51,DISK], DatanodeInfoWithStorage[127.0.0.1:46176,DS-7b0cbbc4-f312-4e7a-bde8-28e6a3a3ccef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1968965159-172.17.0.5-1596949759849:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43151,DS-e0a0c085-cd1f-4d3c-ab81-ba2c3c407e18,DISK], DatanodeInfoWithStorage[127.0.0.1:38514,DS-a58698a5-d298-4517-998e-0c91a235f243,DISK], DatanodeInfoWithStorage[127.0.0.1:36317,DS-5f9c934b-345c-47f7-8183-5b3eedd5bc8a,DISK], DatanodeInfoWithStorage[127.0.0.1:38638,DS-e58bf6c8-b540-4b61-aa91-303e6c182a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:34617,DS-4fb49dd6-bb1a-45e4-9cbf-64d1a637e28f,DISK], DatanodeInfoWithStorage[127.0.0.1:35629,DS-6e05bd9c-cb26-4530-9b23-6dfd12da505a,DISK], DatanodeInfoWithStorage[127.0.0.1:35664,DS-ac3c0692-2688-46b5-a26c-cc7baee08e59,DISK], DatanodeInfoWithStorage[127.0.0.1:46644,DS-30cefc03-152d-4844-ad8a-b1eb811f6da6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1968965159-172.17.0.5-1596949759849:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43151,DS-e0a0c085-cd1f-4d3c-ab81-ba2c3c407e18,DISK], DatanodeInfoWithStorage[127.0.0.1:38514,DS-a58698a5-d298-4517-998e-0c91a235f243,DISK], DatanodeInfoWithStorage[127.0.0.1:36317,DS-5f9c934b-345c-47f7-8183-5b3eedd5bc8a,DISK], DatanodeInfoWithStorage[127.0.0.1:38638,DS-e58bf6c8-b540-4b61-aa91-303e6c182a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:34617,DS-4fb49dd6-bb1a-45e4-9cbf-64d1a637e28f,DISK], DatanodeInfoWithStorage[127.0.0.1:35629,DS-6e05bd9c-cb26-4530-9b23-6dfd12da505a,DISK], DatanodeInfoWithStorage[127.0.0.1:35664,DS-ac3c0692-2688-46b5-a26c-cc7baee08e59,DISK], DatanodeInfoWithStorage[127.0.0.1:46644,DS-30cefc03-152d-4844-ad8a-b1eb811f6da6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-177047724-172.17.0.5-1596949796105:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44967,DS-1b987321-ae92-4685-bef0-8b11df58967f,DISK], DatanodeInfoWithStorage[127.0.0.1:38869,DS-a5c8380c-fecf-4a3d-ac1d-fc8b0d522101,DISK], DatanodeInfoWithStorage[127.0.0.1:39757,DS-ba519ac7-39e9-464a-9cdf-becf6edf2a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:33258,DS-0ee44355-5f45-470e-a48b-647d9775dd5e,DISK], DatanodeInfoWithStorage[127.0.0.1:41197,DS-0b975c3d-5180-4d88-bc1a-3eff4f99aaab,DISK], DatanodeInfoWithStorage[127.0.0.1:33169,DS-e16fe5f2-a02d-48fc-b768-8f12a74b93c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34547,DS-2172a59f-ae8d-4255-a9ce-f8d3a6849813,DISK], DatanodeInfoWithStorage[127.0.0.1:42915,DS-6ca4faf5-a64f-485a-8f23-0803c88eeb2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-177047724-172.17.0.5-1596949796105:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44967,DS-1b987321-ae92-4685-bef0-8b11df58967f,DISK], DatanodeInfoWithStorage[127.0.0.1:38869,DS-a5c8380c-fecf-4a3d-ac1d-fc8b0d522101,DISK], DatanodeInfoWithStorage[127.0.0.1:39757,DS-ba519ac7-39e9-464a-9cdf-becf6edf2a8a,DISK], DatanodeInfoWithStorage[127.0.0.1:33258,DS-0ee44355-5f45-470e-a48b-647d9775dd5e,DISK], DatanodeInfoWithStorage[127.0.0.1:41197,DS-0b975c3d-5180-4d88-bc1a-3eff4f99aaab,DISK], DatanodeInfoWithStorage[127.0.0.1:33169,DS-e16fe5f2-a02d-48fc-b768-8f12a74b93c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34547,DS-2172a59f-ae8d-4255-a9ce-f8d3a6849813,DISK], DatanodeInfoWithStorage[127.0.0.1:42915,DS-6ca4faf5-a64f-485a-8f23-0803c88eeb2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1764209860-172.17.0.5-1596949858046:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37579,DS-ee3b1e27-cd9d-4763-b525-abbbabc566d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37370,DS-e97e4021-e83d-43c3-a2da-94f5b3748d08,DISK], DatanodeInfoWithStorage[127.0.0.1:44977,DS-7ef66f0d-9b33-4d7c-8142-17562d15deac,DISK], DatanodeInfoWithStorage[127.0.0.1:33200,DS-6606aa9b-b788-438c-b6f5-d6026a8e52a6,DISK], DatanodeInfoWithStorage[127.0.0.1:32777,DS-4cdf9468-c9ff-4f2b-a70b-c909127f1263,DISK], DatanodeInfoWithStorage[127.0.0.1:43271,DS-a5ef6163-4dfe-4b4f-940b-7bff0c947caa,DISK], DatanodeInfoWithStorage[127.0.0.1:41492,DS-4999e11b-d03f-4f23-af44-825d394f31b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44234,DS-5e7bc837-91e6-4309-a44d-24255deb3304,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1764209860-172.17.0.5-1596949858046:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37579,DS-ee3b1e27-cd9d-4763-b525-abbbabc566d4,DISK], DatanodeInfoWithStorage[127.0.0.1:37370,DS-e97e4021-e83d-43c3-a2da-94f5b3748d08,DISK], DatanodeInfoWithStorage[127.0.0.1:44977,DS-7ef66f0d-9b33-4d7c-8142-17562d15deac,DISK], DatanodeInfoWithStorage[127.0.0.1:33200,DS-6606aa9b-b788-438c-b6f5-d6026a8e52a6,DISK], DatanodeInfoWithStorage[127.0.0.1:32777,DS-4cdf9468-c9ff-4f2b-a70b-c909127f1263,DISK], DatanodeInfoWithStorage[127.0.0.1:43271,DS-a5ef6163-4dfe-4b4f-940b-7bff0c947caa,DISK], DatanodeInfoWithStorage[127.0.0.1:41492,DS-4999e11b-d03f-4f23-af44-825d394f31b6,DISK], DatanodeInfoWithStorage[127.0.0.1:44234,DS-5e7bc837-91e6-4309-a44d-24255deb3304,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2065208910-172.17.0.5-1596949998793:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44824,DS-ca0dd2a5-c3eb-406e-a809-cb4f5cdbf321,DISK], DatanodeInfoWithStorage[127.0.0.1:42580,DS-1acf174d-41d4-48fb-91db-d1b2b49cf6cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45784,DS-35e824b2-571d-425b-9bda-0a42312eccc1,DISK], DatanodeInfoWithStorage[127.0.0.1:35842,DS-eee83d84-0b52-48ba-bdaa-f9e8457f8c01,DISK], DatanodeInfoWithStorage[127.0.0.1:40778,DS-50ecb32b-5c43-4d15-9adc-c7bbebca3d62,DISK], DatanodeInfoWithStorage[127.0.0.1:39785,DS-c6c3db80-ec07-453d-8973-067900e975bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37805,DS-e59ccc69-beac-4261-8021-92f2019f6a76,DISK], DatanodeInfoWithStorage[127.0.0.1:35456,DS-a76c04a8-edde-4049-8193-aa2dc85fe070,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2065208910-172.17.0.5-1596949998793:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44824,DS-ca0dd2a5-c3eb-406e-a809-cb4f5cdbf321,DISK], DatanodeInfoWithStorage[127.0.0.1:42580,DS-1acf174d-41d4-48fb-91db-d1b2b49cf6cc,DISK], DatanodeInfoWithStorage[127.0.0.1:45784,DS-35e824b2-571d-425b-9bda-0a42312eccc1,DISK], DatanodeInfoWithStorage[127.0.0.1:35842,DS-eee83d84-0b52-48ba-bdaa-f9e8457f8c01,DISK], DatanodeInfoWithStorage[127.0.0.1:40778,DS-50ecb32b-5c43-4d15-9adc-c7bbebca3d62,DISK], DatanodeInfoWithStorage[127.0.0.1:39785,DS-c6c3db80-ec07-453d-8973-067900e975bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37805,DS-e59ccc69-beac-4261-8021-92f2019f6a76,DISK], DatanodeInfoWithStorage[127.0.0.1:35456,DS-a76c04a8-edde-4049-8193-aa2dc85fe070,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-124798200-172.17.0.5-1596950069049:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36738,DS-5dc1a324-5116-40e2-9028-866af6bc6b92,DISK], DatanodeInfoWithStorage[127.0.0.1:39823,DS-fdc78fb7-7a00-4ac9-860a-b58d4185aa80,DISK], DatanodeInfoWithStorage[127.0.0.1:41434,DS-b1b52313-4f4e-4b5d-8549-4774a798ec85,DISK], DatanodeInfoWithStorage[127.0.0.1:39324,DS-1c288a8d-20e7-441c-a786-898009312353,DISK], DatanodeInfoWithStorage[127.0.0.1:45266,DS-262ac86a-a09c-443c-9314-4384d70708d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44138,DS-20924736-5209-4b4f-b2ee-2b3563821274,DISK], DatanodeInfoWithStorage[127.0.0.1:41303,DS-bc649db1-0941-4383-95c4-7114a92db733,DISK], DatanodeInfoWithStorage[127.0.0.1:41937,DS-c370254f-9e3b-4422-99f1-f04b2b185c39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-124798200-172.17.0.5-1596950069049:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36738,DS-5dc1a324-5116-40e2-9028-866af6bc6b92,DISK], DatanodeInfoWithStorage[127.0.0.1:39823,DS-fdc78fb7-7a00-4ac9-860a-b58d4185aa80,DISK], DatanodeInfoWithStorage[127.0.0.1:41434,DS-b1b52313-4f4e-4b5d-8549-4774a798ec85,DISK], DatanodeInfoWithStorage[127.0.0.1:39324,DS-1c288a8d-20e7-441c-a786-898009312353,DISK], DatanodeInfoWithStorage[127.0.0.1:45266,DS-262ac86a-a09c-443c-9314-4384d70708d5,DISK], DatanodeInfoWithStorage[127.0.0.1:44138,DS-20924736-5209-4b4f-b2ee-2b3563821274,DISK], DatanodeInfoWithStorage[127.0.0.1:41303,DS-bc649db1-0941-4383-95c4-7114a92db733,DISK], DatanodeInfoWithStorage[127.0.0.1:41937,DS-c370254f-9e3b-4422-99f1-f04b2b185c39,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1570737718-172.17.0.5-1596950104720:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37646,DS-af81ad23-7322-4a15-b9a1-cd8307b06b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:43516,DS-d9eee77b-2170-4afa-b0a8-e94a2f88ea5f,DISK], DatanodeInfoWithStorage[127.0.0.1:40624,DS-2fc9c24c-c41a-497b-aa76-d7f167b62df6,DISK], DatanodeInfoWithStorage[127.0.0.1:46054,DS-012f2811-a9dc-4d0d-9a62-8cb5c884cd08,DISK], DatanodeInfoWithStorage[127.0.0.1:42850,DS-ebe6e415-c7cb-452e-9779-306f41c7c067,DISK], DatanodeInfoWithStorage[127.0.0.1:36283,DS-cdc7e9b0-c9d1-4241-9ab7-55da40d16a87,DISK], DatanodeInfoWithStorage[127.0.0.1:42314,DS-d8ad0dd9-2f12-4adf-b9f3-896047ad77c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42492,DS-24dce355-be0f-4110-8883-3fb9f9723dc4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1570737718-172.17.0.5-1596950104720:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37646,DS-af81ad23-7322-4a15-b9a1-cd8307b06b3c,DISK], DatanodeInfoWithStorage[127.0.0.1:43516,DS-d9eee77b-2170-4afa-b0a8-e94a2f88ea5f,DISK], DatanodeInfoWithStorage[127.0.0.1:40624,DS-2fc9c24c-c41a-497b-aa76-d7f167b62df6,DISK], DatanodeInfoWithStorage[127.0.0.1:46054,DS-012f2811-a9dc-4d0d-9a62-8cb5c884cd08,DISK], DatanodeInfoWithStorage[127.0.0.1:42850,DS-ebe6e415-c7cb-452e-9779-306f41c7c067,DISK], DatanodeInfoWithStorage[127.0.0.1:36283,DS-cdc7e9b0-c9d1-4241-9ab7-55da40d16a87,DISK], DatanodeInfoWithStorage[127.0.0.1:42314,DS-d8ad0dd9-2f12-4adf-b9f3-896047ad77c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42492,DS-24dce355-be0f-4110-8883-3fb9f9723dc4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-593734050-172.17.0.5-1596950140661:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45870,DS-26cb60db-3017-41f2-aa90-5af317453cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:45601,DS-13dddf80-85c6-470e-aaa3-cfe2d9014fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:39169,DS-56cfd971-2e01-4362-acdc-8b7aff03f6c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40427,DS-d60ddbb3-5094-43cd-b485-b363e1661808,DISK], DatanodeInfoWithStorage[127.0.0.1:41229,DS-d8767a45-4a88-4626-aa1f-95ec52a86933,DISK], DatanodeInfoWithStorage[127.0.0.1:46485,DS-9a5594c2-883e-4e87-8147-44ed85bf96c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42609,DS-aba09c15-842e-4524-a9e0-71643ff488c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35156,DS-b67abb3c-1b09-412d-ac81-c54dab2d7343,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-593734050-172.17.0.5-1596950140661:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45870,DS-26cb60db-3017-41f2-aa90-5af317453cdd,DISK], DatanodeInfoWithStorage[127.0.0.1:45601,DS-13dddf80-85c6-470e-aaa3-cfe2d9014fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:39169,DS-56cfd971-2e01-4362-acdc-8b7aff03f6c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40427,DS-d60ddbb3-5094-43cd-b485-b363e1661808,DISK], DatanodeInfoWithStorage[127.0.0.1:41229,DS-d8767a45-4a88-4626-aa1f-95ec52a86933,DISK], DatanodeInfoWithStorage[127.0.0.1:46485,DS-9a5594c2-883e-4e87-8147-44ed85bf96c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42609,DS-aba09c15-842e-4524-a9e0-71643ff488c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35156,DS-b67abb3c-1b09-412d-ac81-c54dab2d7343,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-631989399-172.17.0.5-1596950232782:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37361,DS-3ff6383e-b083-48d9-afcd-5203ff4f065f,DISK], DatanodeInfoWithStorage[127.0.0.1:42692,DS-bb85cac2-281f-4df7-bc9c-4394ee0ad7f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38969,DS-eec9c054-53c4-4ff6-92a8-42d946c4b429,DISK], DatanodeInfoWithStorage[127.0.0.1:44527,DS-4d2480b4-4d31-4c92-959e-74b79184de09,DISK], DatanodeInfoWithStorage[127.0.0.1:38144,DS-a560b119-b8f0-45cf-a70c-c393f4b3f9ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35918,DS-60e5e2ea-8a10-4c6a-9ea6-addd0f08cd3b,DISK], DatanodeInfoWithStorage[127.0.0.1:34560,DS-29b75337-a90e-43ce-8281-2085786450d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39597,DS-cb6df848-b7ea-476f-a1e3-f0c63e7779c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-631989399-172.17.0.5-1596950232782:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37361,DS-3ff6383e-b083-48d9-afcd-5203ff4f065f,DISK], DatanodeInfoWithStorage[127.0.0.1:42692,DS-bb85cac2-281f-4df7-bc9c-4394ee0ad7f9,DISK], DatanodeInfoWithStorage[127.0.0.1:38969,DS-eec9c054-53c4-4ff6-92a8-42d946c4b429,DISK], DatanodeInfoWithStorage[127.0.0.1:44527,DS-4d2480b4-4d31-4c92-959e-74b79184de09,DISK], DatanodeInfoWithStorage[127.0.0.1:38144,DS-a560b119-b8f0-45cf-a70c-c393f4b3f9ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35918,DS-60e5e2ea-8a10-4c6a-9ea6-addd0f08cd3b,DISK], DatanodeInfoWithStorage[127.0.0.1:34560,DS-29b75337-a90e-43ce-8281-2085786450d0,DISK], DatanodeInfoWithStorage[127.0.0.1:39597,DS-cb6df848-b7ea-476f-a1e3-f0c63e7779c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1053294294-172.17.0.5-1596950265848:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46034,DS-c86d48f4-77f1-450c-b3c5-fb367f0ef096,DISK], DatanodeInfoWithStorage[127.0.0.1:41092,DS-7f6625a7-279a-4e06-a43c-29136266d5fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37565,DS-1184a1d3-41ad-47ce-a71b-6c994b8a6f25,DISK], DatanodeInfoWithStorage[127.0.0.1:39778,DS-2d693582-5585-4aa5-982a-dbb52e5ead10,DISK], DatanodeInfoWithStorage[127.0.0.1:44765,DS-eb7352a7-97be-4733-9834-0594724d2580,DISK], DatanodeInfoWithStorage[127.0.0.1:42958,DS-c891ce92-06d5-4a12-90a9-cbee4f9263e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38751,DS-1f1e2fe6-444d-4ca5-a73b-a538c58c4236,DISK], DatanodeInfoWithStorage[127.0.0.1:42611,DS-f8a8d649-e0b0-41cd-aac8-b043f9f8f2a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1053294294-172.17.0.5-1596950265848:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46034,DS-c86d48f4-77f1-450c-b3c5-fb367f0ef096,DISK], DatanodeInfoWithStorage[127.0.0.1:41092,DS-7f6625a7-279a-4e06-a43c-29136266d5fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37565,DS-1184a1d3-41ad-47ce-a71b-6c994b8a6f25,DISK], DatanodeInfoWithStorage[127.0.0.1:39778,DS-2d693582-5585-4aa5-982a-dbb52e5ead10,DISK], DatanodeInfoWithStorage[127.0.0.1:44765,DS-eb7352a7-97be-4733-9834-0594724d2580,DISK], DatanodeInfoWithStorage[127.0.0.1:42958,DS-c891ce92-06d5-4a12-90a9-cbee4f9263e4,DISK], DatanodeInfoWithStorage[127.0.0.1:38751,DS-1f1e2fe6-444d-4ca5-a73b-a538c58c4236,DISK], DatanodeInfoWithStorage[127.0.0.1:42611,DS-f8a8d649-e0b0-41cd-aac8-b043f9f8f2a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-801185200-172.17.0.5-1596950517153:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36817,DS-3ed04dc3-b921-4add-9fa0-728e0215fb5d,DISK], DatanodeInfoWithStorage[127.0.0.1:33456,DS-86dce3c0-73e6-47de-96a3-78fd716b8a4e,DISK], DatanodeInfoWithStorage[127.0.0.1:46774,DS-9b25c7b5-00fb-4af1-86ca-1294b605fc5e,DISK], DatanodeInfoWithStorage[127.0.0.1:40146,DS-931ced91-0bab-464f-aab3-dd15e0e6f4ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35856,DS-91798b8d-60f5-4520-bef9-3a1cfe995dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:38712,DS-5d136892-1470-4428-9d4e-792bf89c26f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41094,DS-5d7693b0-9831-4ac0-991a-309ad8f32ca4,DISK], DatanodeInfoWithStorage[127.0.0.1:41393,DS-cf1665af-70b3-40e6-b219-22210c25b3d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-801185200-172.17.0.5-1596950517153:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36817,DS-3ed04dc3-b921-4add-9fa0-728e0215fb5d,DISK], DatanodeInfoWithStorage[127.0.0.1:33456,DS-86dce3c0-73e6-47de-96a3-78fd716b8a4e,DISK], DatanodeInfoWithStorage[127.0.0.1:46774,DS-9b25c7b5-00fb-4af1-86ca-1294b605fc5e,DISK], DatanodeInfoWithStorage[127.0.0.1:40146,DS-931ced91-0bab-464f-aab3-dd15e0e6f4ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35856,DS-91798b8d-60f5-4520-bef9-3a1cfe995dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:38712,DS-5d136892-1470-4428-9d4e-792bf89c26f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41094,DS-5d7693b0-9831-4ac0-991a-309ad8f32ca4,DISK], DatanodeInfoWithStorage[127.0.0.1:41393,DS-cf1665af-70b3-40e6-b219-22210c25b3d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-917089699-172.17.0.5-1596950628313:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33652,DS-781b3d9b-ea2e-473b-9275-952bde2847f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45717,DS-6e6dbc3e-c95a-4911-8210-ec749e7775f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38126,DS-ef4565fa-c053-480d-ab28-714229f9fbe3,DISK], DatanodeInfoWithStorage[127.0.0.1:37632,DS-10d5f96c-eca5-4d78-84f2-b34754923ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:36344,DS-71ac9e27-b611-4c43-8af8-a923b56c8a36,DISK], DatanodeInfoWithStorage[127.0.0.1:45340,DS-5304da44-8e71-4baa-8636-662f83586fa0,DISK], DatanodeInfoWithStorage[127.0.0.1:38324,DS-9a0a7c55-2871-4696-8f2e-5f3e0573aa22,DISK], DatanodeInfoWithStorage[127.0.0.1:43635,DS-4ba64b0b-7592-442e-939d-06f47cf31417,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-917089699-172.17.0.5-1596950628313:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33652,DS-781b3d9b-ea2e-473b-9275-952bde2847f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45717,DS-6e6dbc3e-c95a-4911-8210-ec749e7775f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38126,DS-ef4565fa-c053-480d-ab28-714229f9fbe3,DISK], DatanodeInfoWithStorage[127.0.0.1:37632,DS-10d5f96c-eca5-4d78-84f2-b34754923ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:36344,DS-71ac9e27-b611-4c43-8af8-a923b56c8a36,DISK], DatanodeInfoWithStorage[127.0.0.1:45340,DS-5304da44-8e71-4baa-8636-662f83586fa0,DISK], DatanodeInfoWithStorage[127.0.0.1:38324,DS-9a0a7c55-2871-4696-8f2e-5f3e0573aa22,DISK], DatanodeInfoWithStorage[127.0.0.1:43635,DS-4ba64b0b-7592-442e-939d-06f47cf31417,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-312271161-172.17.0.5-1596950840000:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40746,DS-bbb85aaa-d3ec-4b11-b563-613fb3b5c444,DISK], DatanodeInfoWithStorage[127.0.0.1:32941,DS-de38664d-8c97-44eb-acb4-9fb19c31ee7c,DISK], DatanodeInfoWithStorage[127.0.0.1:46217,DS-becc933a-c85b-45c6-84e0-20ab71bc4e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:42589,DS-db7e8e7a-948f-452d-88b7-08c9627ec57b,DISK], DatanodeInfoWithStorage[127.0.0.1:38294,DS-19e8d255-c514-42a3-b579-ace7d9373910,DISK], DatanodeInfoWithStorage[127.0.0.1:36423,DS-15897df2-88d8-41a0-9550-8ff62bb3d5d8,DISK], DatanodeInfoWithStorage[127.0.0.1:34951,DS-41d78d5b-1ba4-4393-bf59-42b008d87c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:37338,DS-3b561cd8-2228-4282-aa60-8c55d63082d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-312271161-172.17.0.5-1596950840000:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40746,DS-bbb85aaa-d3ec-4b11-b563-613fb3b5c444,DISK], DatanodeInfoWithStorage[127.0.0.1:32941,DS-de38664d-8c97-44eb-acb4-9fb19c31ee7c,DISK], DatanodeInfoWithStorage[127.0.0.1:46217,DS-becc933a-c85b-45c6-84e0-20ab71bc4e9f,DISK], DatanodeInfoWithStorage[127.0.0.1:42589,DS-db7e8e7a-948f-452d-88b7-08c9627ec57b,DISK], DatanodeInfoWithStorage[127.0.0.1:38294,DS-19e8d255-c514-42a3-b579-ace7d9373910,DISK], DatanodeInfoWithStorage[127.0.0.1:36423,DS-15897df2-88d8-41a0-9550-8ff62bb3d5d8,DISK], DatanodeInfoWithStorage[127.0.0.1:34951,DS-41d78d5b-1ba4-4393-bf59-42b008d87c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:37338,DS-3b561cd8-2228-4282-aa60-8c55d63082d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-590644445-172.17.0.5-1596951051655:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40712,DS-a1a0fa00-7741-4e87-a27f-037529f1c163,DISK], DatanodeInfoWithStorage[127.0.0.1:36381,DS-393a0bf4-e8f9-4c6a-a077-a9916b29e062,DISK], DatanodeInfoWithStorage[127.0.0.1:39656,DS-1990e81a-68be-4e3f-ab50-32b3e24f87d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39930,DS-3cf13379-f829-4f00-a3a5-bff523705fd4,DISK], DatanodeInfoWithStorage[127.0.0.1:42355,DS-f7465e47-5109-4e43-8a78-fbce75c8fdf0,DISK], DatanodeInfoWithStorage[127.0.0.1:38134,DS-a430e0f7-c438-4497-ae11-eccb047c6a49,DISK], DatanodeInfoWithStorage[127.0.0.1:37640,DS-c5626aee-13d1-42b5-9218-05cd8be13656,DISK], DatanodeInfoWithStorage[127.0.0.1:43246,DS-3b23cb8a-132a-4809-b208-777b07a41271,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-590644445-172.17.0.5-1596951051655:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40712,DS-a1a0fa00-7741-4e87-a27f-037529f1c163,DISK], DatanodeInfoWithStorage[127.0.0.1:36381,DS-393a0bf4-e8f9-4c6a-a077-a9916b29e062,DISK], DatanodeInfoWithStorage[127.0.0.1:39656,DS-1990e81a-68be-4e3f-ab50-32b3e24f87d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39930,DS-3cf13379-f829-4f00-a3a5-bff523705fd4,DISK], DatanodeInfoWithStorage[127.0.0.1:42355,DS-f7465e47-5109-4e43-8a78-fbce75c8fdf0,DISK], DatanodeInfoWithStorage[127.0.0.1:38134,DS-a430e0f7-c438-4497-ae11-eccb047c6a49,DISK], DatanodeInfoWithStorage[127.0.0.1:37640,DS-c5626aee-13d1-42b5-9218-05cd8be13656,DISK], DatanodeInfoWithStorage[127.0.0.1:43246,DS-3b23cb8a-132a-4809-b208-777b07a41271,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1389328848-172.17.0.5-1596951226921:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46879,DS-8f3046b5-9d9d-47b9-b44c-96e4633a4805,DISK], DatanodeInfoWithStorage[127.0.0.1:44717,DS-2af0504b-a471-4e27-a954-2f2a2ec473ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35571,DS-601dddb9-0715-4be6-a016-096d363acd12,DISK], DatanodeInfoWithStorage[127.0.0.1:41189,DS-a2c45578-2c74-40ee-8c5b-fdb96f7b6b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:44727,DS-634157e4-1cb0-4ce3-a3aa-2ce6be513eeb,DISK], DatanodeInfoWithStorage[127.0.0.1:44158,DS-a2fa91d5-b7c5-47c9-8463-7d63f93111da,DISK], DatanodeInfoWithStorage[127.0.0.1:45816,DS-8f0af400-cb5a-43a4-a396-9022b400670e,DISK], DatanodeInfoWithStorage[127.0.0.1:40364,DS-476fc451-a5cd-43e6-8b0f-198c4c3d9caf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1389328848-172.17.0.5-1596951226921:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46879,DS-8f3046b5-9d9d-47b9-b44c-96e4633a4805,DISK], DatanodeInfoWithStorage[127.0.0.1:44717,DS-2af0504b-a471-4e27-a954-2f2a2ec473ab,DISK], DatanodeInfoWithStorage[127.0.0.1:35571,DS-601dddb9-0715-4be6-a016-096d363acd12,DISK], DatanodeInfoWithStorage[127.0.0.1:41189,DS-a2c45578-2c74-40ee-8c5b-fdb96f7b6b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:44727,DS-634157e4-1cb0-4ce3-a3aa-2ce6be513eeb,DISK], DatanodeInfoWithStorage[127.0.0.1:44158,DS-a2fa91d5-b7c5-47c9-8463-7d63f93111da,DISK], DatanodeInfoWithStorage[127.0.0.1:45816,DS-8f0af400-cb5a-43a4-a396-9022b400670e,DISK], DatanodeInfoWithStorage[127.0.0.1:40364,DS-476fc451-a5cd-43e6-8b0f-198c4c3d9caf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1559498289-172.17.0.5-1596951303102:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40863,DS-e83898be-69e2-404c-8341-7a9d2d51f206,DISK], DatanodeInfoWithStorage[127.0.0.1:40979,DS-31ee44a2-f41e-4c19-84ec-3b7443e0b402,DISK], DatanodeInfoWithStorage[127.0.0.1:37734,DS-9a9ff74d-25bd-4a6f-89ed-a56ee8299210,DISK], DatanodeInfoWithStorage[127.0.0.1:45715,DS-c35ba621-911c-4f3d-a0ee-c58b9b6a8f93,DISK], DatanodeInfoWithStorage[127.0.0.1:45316,DS-8e5a04d6-1b18-4ab7-91c9-7ac832e1f30f,DISK], DatanodeInfoWithStorage[127.0.0.1:46193,DS-cdebc97a-56d4-4111-9d03-438c441493bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39420,DS-4de4554f-c325-4377-9550-714aa92876e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44609,DS-f1759e13-93ba-44e5-b247-bfda9fb5cc7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1559498289-172.17.0.5-1596951303102:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40863,DS-e83898be-69e2-404c-8341-7a9d2d51f206,DISK], DatanodeInfoWithStorage[127.0.0.1:40979,DS-31ee44a2-f41e-4c19-84ec-3b7443e0b402,DISK], DatanodeInfoWithStorage[127.0.0.1:37734,DS-9a9ff74d-25bd-4a6f-89ed-a56ee8299210,DISK], DatanodeInfoWithStorage[127.0.0.1:45715,DS-c35ba621-911c-4f3d-a0ee-c58b9b6a8f93,DISK], DatanodeInfoWithStorage[127.0.0.1:45316,DS-8e5a04d6-1b18-4ab7-91c9-7ac832e1f30f,DISK], DatanodeInfoWithStorage[127.0.0.1:46193,DS-cdebc97a-56d4-4111-9d03-438c441493bd,DISK], DatanodeInfoWithStorage[127.0.0.1:39420,DS-4de4554f-c325-4377-9550-714aa92876e5,DISK], DatanodeInfoWithStorage[127.0.0.1:44609,DS-f1759e13-93ba-44e5-b247-bfda9fb5cc7c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1101584272-172.17.0.5-1596951612011:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44263,DS-bf06453e-ec95-45ef-acfc-cd175cc52b5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39315,DS-ebd1267f-0d31-4302-8a88-9ba03cf6eb29,DISK], DatanodeInfoWithStorage[127.0.0.1:37496,DS-357a8ce2-65d6-4a2a-9835-0560cade00c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35306,DS-ca73d6e0-a585-4afd-92d1-ddccc16a0687,DISK], DatanodeInfoWithStorage[127.0.0.1:44223,DS-7708c174-0e27-467b-9c99-f6b644e394a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43388,DS-0544d0e7-69cb-431c-ab23-87578f28a27e,DISK], DatanodeInfoWithStorage[127.0.0.1:44566,DS-c772f452-0e23-4b41-9b6c-620050ede2ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39431,DS-85e9dbcf-1912-49cb-9aba-9dfa0139a016,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1101584272-172.17.0.5-1596951612011:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44263,DS-bf06453e-ec95-45ef-acfc-cd175cc52b5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39315,DS-ebd1267f-0d31-4302-8a88-9ba03cf6eb29,DISK], DatanodeInfoWithStorage[127.0.0.1:37496,DS-357a8ce2-65d6-4a2a-9835-0560cade00c7,DISK], DatanodeInfoWithStorage[127.0.0.1:35306,DS-ca73d6e0-a585-4afd-92d1-ddccc16a0687,DISK], DatanodeInfoWithStorage[127.0.0.1:44223,DS-7708c174-0e27-467b-9c99-f6b644e394a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43388,DS-0544d0e7-69cb-431c-ab23-87578f28a27e,DISK], DatanodeInfoWithStorage[127.0.0.1:44566,DS-c772f452-0e23-4b41-9b6c-620050ede2ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39431,DS-85e9dbcf-1912-49cb-9aba-9dfa0139a016,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-911395308-172.17.0.5-1596952489794:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34029,DS-2d0bfc0f-8aa8-4aca-8fa0-8fd4fef847ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40285,DS-d1511865-e7ce-47a3-901b-73b957c95da9,DISK], DatanodeInfoWithStorage[127.0.0.1:45701,DS-41374fbe-51b8-48e5-930f-317683a08226,DISK], DatanodeInfoWithStorage[127.0.0.1:38125,DS-d5178be5-6e0e-480b-b1d7-b5264465ba66,DISK], DatanodeInfoWithStorage[127.0.0.1:33041,DS-8713d045-58d9-405a-bb14-7c5ddb354d22,DISK], DatanodeInfoWithStorage[127.0.0.1:42219,DS-b7d0ba9a-72a3-4546-98a0-a83f75f0429e,DISK], DatanodeInfoWithStorage[127.0.0.1:43338,DS-bbb74e42-7299-4e02-afc1-8cb1c3addacd,DISK], DatanodeInfoWithStorage[127.0.0.1:33663,DS-aafbff87-d965-4e4b-a76b-1008dfebf2ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-911395308-172.17.0.5-1596952489794:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34029,DS-2d0bfc0f-8aa8-4aca-8fa0-8fd4fef847ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40285,DS-d1511865-e7ce-47a3-901b-73b957c95da9,DISK], DatanodeInfoWithStorage[127.0.0.1:45701,DS-41374fbe-51b8-48e5-930f-317683a08226,DISK], DatanodeInfoWithStorage[127.0.0.1:38125,DS-d5178be5-6e0e-480b-b1d7-b5264465ba66,DISK], DatanodeInfoWithStorage[127.0.0.1:33041,DS-8713d045-58d9-405a-bb14-7c5ddb354d22,DISK], DatanodeInfoWithStorage[127.0.0.1:42219,DS-b7d0ba9a-72a3-4546-98a0-a83f75f0429e,DISK], DatanodeInfoWithStorage[127.0.0.1:43338,DS-bbb74e42-7299-4e02-afc1-8cb1c3addacd,DISK], DatanodeInfoWithStorage[127.0.0.1:33663,DS-aafbff87-d965-4e4b-a76b-1008dfebf2ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-117118452-172.17.0.5-1596953304685:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34175,DS-b8c57f89-fd7a-4917-a30d-e4a8b65fec3e,DISK], DatanodeInfoWithStorage[127.0.0.1:36259,DS-c735d80d-b160-49ca-bc0e-b5a689f885f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45927,DS-3134d31d-a137-48f7-8b48-fc54d84e0e65,DISK], DatanodeInfoWithStorage[127.0.0.1:42109,DS-ead05a92-f860-4628-9186-4462a56c4b11,DISK], DatanodeInfoWithStorage[127.0.0.1:42481,DS-3ce81bad-0a2d-459c-acca-74fdf4e9a798,DISK], DatanodeInfoWithStorage[127.0.0.1:37731,DS-4c4ae380-52b6-4e3d-a9cb-4fa67d64cdc4,DISK], DatanodeInfoWithStorage[127.0.0.1:43693,DS-fbe86a91-8fc4-4317-bee5-59eb4d5ca671,DISK], DatanodeInfoWithStorage[127.0.0.1:43761,DS-1d639f16-e5c0-4968-b43e-4fac04b44b98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-117118452-172.17.0.5-1596953304685:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34175,DS-b8c57f89-fd7a-4917-a30d-e4a8b65fec3e,DISK], DatanodeInfoWithStorage[127.0.0.1:36259,DS-c735d80d-b160-49ca-bc0e-b5a689f885f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45927,DS-3134d31d-a137-48f7-8b48-fc54d84e0e65,DISK], DatanodeInfoWithStorage[127.0.0.1:42109,DS-ead05a92-f860-4628-9186-4462a56c4b11,DISK], DatanodeInfoWithStorage[127.0.0.1:42481,DS-3ce81bad-0a2d-459c-acca-74fdf4e9a798,DISK], DatanodeInfoWithStorage[127.0.0.1:37731,DS-4c4ae380-52b6-4e3d-a9cb-4fa67d64cdc4,DISK], DatanodeInfoWithStorage[127.0.0.1:43693,DS-fbe86a91-8fc4-4317-bee5-59eb4d5ca671,DISK], DatanodeInfoWithStorage[127.0.0.1:43761,DS-1d639f16-e5c0-4968-b43e-4fac04b44b98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 5223
