reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2027474379-172.17.0.15-1595298862176:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39443,DS-13ec8b6f-dc45-446e-b980-6a242cabdb09,DISK], DatanodeInfoWithStorage[127.0.0.1:38702,DS-1de1d691-a567-476a-b889-264f7a0ee161,DISK], DatanodeInfoWithStorage[127.0.0.1:33007,DS-aa87cf3c-d837-4cb3-b6c0-2d943b4d7bac,DISK], DatanodeInfoWithStorage[127.0.0.1:44992,DS-27d1c08c-d50a-41cd-899d-2bbd5986bf86,DISK], DatanodeInfoWithStorage[127.0.0.1:36963,DS-35987112-395c-4f09-a99e-29206c57e76c,DISK], DatanodeInfoWithStorage[127.0.0.1:43293,DS-90a684c5-3737-4cf5-abf4-1e5edd374fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:36563,DS-7a6913d5-4d35-421d-a14f-f92e338fd2b9,DISK], DatanodeInfoWithStorage[127.0.0.1:40452,DS-2e50cd92-f7e0-413a-b560-cd367a9dc7ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2027474379-172.17.0.15-1595298862176:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39443,DS-13ec8b6f-dc45-446e-b980-6a242cabdb09,DISK], DatanodeInfoWithStorage[127.0.0.1:38702,DS-1de1d691-a567-476a-b889-264f7a0ee161,DISK], DatanodeInfoWithStorage[127.0.0.1:33007,DS-aa87cf3c-d837-4cb3-b6c0-2d943b4d7bac,DISK], DatanodeInfoWithStorage[127.0.0.1:44992,DS-27d1c08c-d50a-41cd-899d-2bbd5986bf86,DISK], DatanodeInfoWithStorage[127.0.0.1:36963,DS-35987112-395c-4f09-a99e-29206c57e76c,DISK], DatanodeInfoWithStorage[127.0.0.1:43293,DS-90a684c5-3737-4cf5-abf4-1e5edd374fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:36563,DS-7a6913d5-4d35-421d-a14f-f92e338fd2b9,DISK], DatanodeInfoWithStorage[127.0.0.1:40452,DS-2e50cd92-f7e0-413a-b560-cd367a9dc7ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1008071672-172.17.0.15-1595299270044:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33280,DS-104e5550-1abd-467b-a673-8b4a136be556,DISK], DatanodeInfoWithStorage[127.0.0.1:42831,DS-ac066a3a-df4e-4bd8-8915-71ea7ab9ad25,DISK], DatanodeInfoWithStorage[127.0.0.1:45209,DS-51c240d3-90c9-4a90-8fb9-1fefa9cba7b3,DISK], DatanodeInfoWithStorage[127.0.0.1:46364,DS-b4615d76-2898-45cd-bd04-f11e0470a096,DISK], DatanodeInfoWithStorage[127.0.0.1:33197,DS-1f0a2ee3-ee65-4d36-a1ae-aea42c30f55e,DISK], DatanodeInfoWithStorage[127.0.0.1:36349,DS-bae455cf-30aa-4c28-8695-52a5b7588784,DISK], DatanodeInfoWithStorage[127.0.0.1:41476,DS-6bcaa2d5-1979-45b8-9396-1aa25bab3d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:46375,DS-ee991530-c570-4ade-9902-3a26605187e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1008071672-172.17.0.15-1595299270044:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33280,DS-104e5550-1abd-467b-a673-8b4a136be556,DISK], DatanodeInfoWithStorage[127.0.0.1:42831,DS-ac066a3a-df4e-4bd8-8915-71ea7ab9ad25,DISK], DatanodeInfoWithStorage[127.0.0.1:45209,DS-51c240d3-90c9-4a90-8fb9-1fefa9cba7b3,DISK], DatanodeInfoWithStorage[127.0.0.1:46364,DS-b4615d76-2898-45cd-bd04-f11e0470a096,DISK], DatanodeInfoWithStorage[127.0.0.1:33197,DS-1f0a2ee3-ee65-4d36-a1ae-aea42c30f55e,DISK], DatanodeInfoWithStorage[127.0.0.1:36349,DS-bae455cf-30aa-4c28-8695-52a5b7588784,DISK], DatanodeInfoWithStorage[127.0.0.1:41476,DS-6bcaa2d5-1979-45b8-9396-1aa25bab3d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:46375,DS-ee991530-c570-4ade-9902-3a26605187e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1661191633-172.17.0.15-1595299446336:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46676,DS-bb6e6dae-ed78-472f-89f3-fb3da3480388,DISK], DatanodeInfoWithStorage[127.0.0.1:34633,DS-7cd096e1-00e7-47b7-be8b-b81f59d2fe82,DISK], DatanodeInfoWithStorage[127.0.0.1:41512,DS-5bd628c6-88e1-47ce-9231-4d141d88af0b,DISK], DatanodeInfoWithStorage[127.0.0.1:33120,DS-f9a5c1c9-c25b-4500-8657-1cc04085a9e7,DISK], DatanodeInfoWithStorage[127.0.0.1:35278,DS-28d268c4-d952-4627-a474-6bacb8cf64f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40024,DS-fc12f22a-78bf-4ed8-a65b-355b65c72a8b,DISK], DatanodeInfoWithStorage[127.0.0.1:33542,DS-7c7c327e-77fa-4d69-ae94-4a3a3053dd8b,DISK], DatanodeInfoWithStorage[127.0.0.1:40971,DS-2bc1a639-24a3-4c87-abcf-54d82b2052a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1661191633-172.17.0.15-1595299446336:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46676,DS-bb6e6dae-ed78-472f-89f3-fb3da3480388,DISK], DatanodeInfoWithStorage[127.0.0.1:34633,DS-7cd096e1-00e7-47b7-be8b-b81f59d2fe82,DISK], DatanodeInfoWithStorage[127.0.0.1:41512,DS-5bd628c6-88e1-47ce-9231-4d141d88af0b,DISK], DatanodeInfoWithStorage[127.0.0.1:33120,DS-f9a5c1c9-c25b-4500-8657-1cc04085a9e7,DISK], DatanodeInfoWithStorage[127.0.0.1:35278,DS-28d268c4-d952-4627-a474-6bacb8cf64f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40024,DS-fc12f22a-78bf-4ed8-a65b-355b65c72a8b,DISK], DatanodeInfoWithStorage[127.0.0.1:33542,DS-7c7c327e-77fa-4d69-ae94-4a3a3053dd8b,DISK], DatanodeInfoWithStorage[127.0.0.1:40971,DS-2bc1a639-24a3-4c87-abcf-54d82b2052a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1815085038-172.17.0.15-1595299676943:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43124,DS-063fff4d-ee5c-48b1-b0fd-23113638db67,DISK], DatanodeInfoWithStorage[127.0.0.1:46504,DS-ef993ed8-b9e7-4e68-b933-77515c20d53b,DISK], DatanodeInfoWithStorage[127.0.0.1:42254,DS-20f8a9bc-5462-4921-942d-7c614d3c3354,DISK], DatanodeInfoWithStorage[127.0.0.1:33013,DS-50cda486-8884-428b-82de-20fc80e9e624,DISK], DatanodeInfoWithStorage[127.0.0.1:35011,DS-abb71546-3716-477f-9781-9676c38b7ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:40346,DS-e4c96742-34c9-42bf-bed8-2f32e245f9f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38029,DS-3a990854-650c-4251-b0db-8730ecdf1533,DISK], DatanodeInfoWithStorage[127.0.0.1:32902,DS-a8be7331-30b3-48fb-8cdf-d7462ea0b27a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1815085038-172.17.0.15-1595299676943:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43124,DS-063fff4d-ee5c-48b1-b0fd-23113638db67,DISK], DatanodeInfoWithStorage[127.0.0.1:46504,DS-ef993ed8-b9e7-4e68-b933-77515c20d53b,DISK], DatanodeInfoWithStorage[127.0.0.1:42254,DS-20f8a9bc-5462-4921-942d-7c614d3c3354,DISK], DatanodeInfoWithStorage[127.0.0.1:33013,DS-50cda486-8884-428b-82de-20fc80e9e624,DISK], DatanodeInfoWithStorage[127.0.0.1:35011,DS-abb71546-3716-477f-9781-9676c38b7ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:40346,DS-e4c96742-34c9-42bf-bed8-2f32e245f9f8,DISK], DatanodeInfoWithStorage[127.0.0.1:38029,DS-3a990854-650c-4251-b0db-8730ecdf1533,DISK], DatanodeInfoWithStorage[127.0.0.1:32902,DS-a8be7331-30b3-48fb-8cdf-d7462ea0b27a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1565606371-172.17.0.15-1595299834798:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39043,DS-af60b497-b864-48ff-bffa-ea1494d6c0e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45930,DS-6701ca25-a6b8-4d30-ad14-e8bf0f6b4744,DISK], DatanodeInfoWithStorage[127.0.0.1:40293,DS-dd74e44d-75fa-4c96-b7ac-37f5ecd32075,DISK], DatanodeInfoWithStorage[127.0.0.1:36751,DS-a11048f0-5481-4e08-b239-a27cdbbd8aa8,DISK], DatanodeInfoWithStorage[127.0.0.1:33431,DS-40afaaf2-acab-4833-b514-bb96eb3eda37,DISK], DatanodeInfoWithStorage[127.0.0.1:44874,DS-319b95b1-93b7-49fa-9984-3a5dea515bc2,DISK], DatanodeInfoWithStorage[127.0.0.1:42567,DS-b4c4d73b-b946-44e3-b846-a316a7ddaba9,DISK], DatanodeInfoWithStorage[127.0.0.1:46071,DS-e91a089f-c916-4406-8784-d3b966ccc8d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1565606371-172.17.0.15-1595299834798:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39043,DS-af60b497-b864-48ff-bffa-ea1494d6c0e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45930,DS-6701ca25-a6b8-4d30-ad14-e8bf0f6b4744,DISK], DatanodeInfoWithStorage[127.0.0.1:40293,DS-dd74e44d-75fa-4c96-b7ac-37f5ecd32075,DISK], DatanodeInfoWithStorage[127.0.0.1:36751,DS-a11048f0-5481-4e08-b239-a27cdbbd8aa8,DISK], DatanodeInfoWithStorage[127.0.0.1:33431,DS-40afaaf2-acab-4833-b514-bb96eb3eda37,DISK], DatanodeInfoWithStorage[127.0.0.1:44874,DS-319b95b1-93b7-49fa-9984-3a5dea515bc2,DISK], DatanodeInfoWithStorage[127.0.0.1:42567,DS-b4c4d73b-b946-44e3-b846-a316a7ddaba9,DISK], DatanodeInfoWithStorage[127.0.0.1:46071,DS-e91a089f-c916-4406-8784-d3b966ccc8d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1180014226-172.17.0.15-1595300137490:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37449,DS-3e3a29a3-cd84-4e0e-8f91-d33d1060e7e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37582,DS-8383719f-b648-45d1-9ca4-b5c69e6be0d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33752,DS-76b5a026-aeb0-423e-86a7-892ee5b8badf,DISK], DatanodeInfoWithStorage[127.0.0.1:45947,DS-dc912a70-7028-4bac-a727-e02ce9bdfd93,DISK], DatanodeInfoWithStorage[127.0.0.1:41639,DS-a8ec49bb-7f26-4e72-bb18-d1cefabae3dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44476,DS-2213f96e-3eea-46dd-a42e-c6b0dd81009c,DISK], DatanodeInfoWithStorage[127.0.0.1:46495,DS-247a95d3-394d-4167-9de5-c88386840f2b,DISK], DatanodeInfoWithStorage[127.0.0.1:38764,DS-e5c51946-0dd0-44c4-bb76-06157e81c608,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1180014226-172.17.0.15-1595300137490:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37449,DS-3e3a29a3-cd84-4e0e-8f91-d33d1060e7e0,DISK], DatanodeInfoWithStorage[127.0.0.1:37582,DS-8383719f-b648-45d1-9ca4-b5c69e6be0d0,DISK], DatanodeInfoWithStorage[127.0.0.1:33752,DS-76b5a026-aeb0-423e-86a7-892ee5b8badf,DISK], DatanodeInfoWithStorage[127.0.0.1:45947,DS-dc912a70-7028-4bac-a727-e02ce9bdfd93,DISK], DatanodeInfoWithStorage[127.0.0.1:41639,DS-a8ec49bb-7f26-4e72-bb18-d1cefabae3dd,DISK], DatanodeInfoWithStorage[127.0.0.1:44476,DS-2213f96e-3eea-46dd-a42e-c6b0dd81009c,DISK], DatanodeInfoWithStorage[127.0.0.1:46495,DS-247a95d3-394d-4167-9de5-c88386840f2b,DISK], DatanodeInfoWithStorage[127.0.0.1:38764,DS-e5c51946-0dd0-44c4-bb76-06157e81c608,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1762732658-172.17.0.15-1595300510992:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36838,DS-686285e1-056c-4b4b-bd4b-f328212390ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40333,DS-5defa305-077e-49d4-ab85-ba0c7e81e730,DISK], DatanodeInfoWithStorage[127.0.0.1:40354,DS-dcea24e6-5dfc-4c1c-b6a0-34f280eb7e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:35492,DS-4256dd80-d135-449b-a785-d1f96bdeecaa,DISK], DatanodeInfoWithStorage[127.0.0.1:34468,DS-d3ed9ca7-a1d5-42b4-a64f-ced6002a7e17,DISK], DatanodeInfoWithStorage[127.0.0.1:42185,DS-7a3f4153-4c98-4f56-a594-24f5d7aec5cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42316,DS-4c3f36f8-20ce-4035-adb9-1b22cc15a1a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33887,DS-cfb49c17-40a4-4b43-9cb8-142de0b288ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1762732658-172.17.0.15-1595300510992:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36838,DS-686285e1-056c-4b4b-bd4b-f328212390ab,DISK], DatanodeInfoWithStorage[127.0.0.1:40333,DS-5defa305-077e-49d4-ab85-ba0c7e81e730,DISK], DatanodeInfoWithStorage[127.0.0.1:40354,DS-dcea24e6-5dfc-4c1c-b6a0-34f280eb7e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:35492,DS-4256dd80-d135-449b-a785-d1f96bdeecaa,DISK], DatanodeInfoWithStorage[127.0.0.1:34468,DS-d3ed9ca7-a1d5-42b4-a64f-ced6002a7e17,DISK], DatanodeInfoWithStorage[127.0.0.1:42185,DS-7a3f4153-4c98-4f56-a594-24f5d7aec5cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42316,DS-4c3f36f8-20ce-4035-adb9-1b22cc15a1a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33887,DS-cfb49c17-40a4-4b43-9cb8-142de0b288ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1437511977-172.17.0.15-1595300800925:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41296,DS-f7ae4f2b-033f-480f-a874-b35ff14edad6,DISK], DatanodeInfoWithStorage[127.0.0.1:38793,DS-8d61489c-5f7a-4327-861d-c9b5272bbced,DISK], DatanodeInfoWithStorage[127.0.0.1:38061,DS-3a7acade-a320-46e1-aa85-327c5f80704e,DISK], DatanodeInfoWithStorage[127.0.0.1:42183,DS-3e72180e-633e-45e1-be31-8b9c1f80c99c,DISK], DatanodeInfoWithStorage[127.0.0.1:33393,DS-11bd81ab-1bce-4f44-9b4f-4fc58c75e074,DISK], DatanodeInfoWithStorage[127.0.0.1:32811,DS-76e6a461-8d28-426f-b14c-83d0e07e5b48,DISK], DatanodeInfoWithStorage[127.0.0.1:44160,DS-e184c53e-8033-4e6d-bf49-8f88be67e28a,DISK], DatanodeInfoWithStorage[127.0.0.1:42274,DS-6924387e-ea9c-465a-a164-3ed769d962fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1437511977-172.17.0.15-1595300800925:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41296,DS-f7ae4f2b-033f-480f-a874-b35ff14edad6,DISK], DatanodeInfoWithStorage[127.0.0.1:38793,DS-8d61489c-5f7a-4327-861d-c9b5272bbced,DISK], DatanodeInfoWithStorage[127.0.0.1:38061,DS-3a7acade-a320-46e1-aa85-327c5f80704e,DISK], DatanodeInfoWithStorage[127.0.0.1:42183,DS-3e72180e-633e-45e1-be31-8b9c1f80c99c,DISK], DatanodeInfoWithStorage[127.0.0.1:33393,DS-11bd81ab-1bce-4f44-9b4f-4fc58c75e074,DISK], DatanodeInfoWithStorage[127.0.0.1:32811,DS-76e6a461-8d28-426f-b14c-83d0e07e5b48,DISK], DatanodeInfoWithStorage[127.0.0.1:44160,DS-e184c53e-8033-4e6d-bf49-8f88be67e28a,DISK], DatanodeInfoWithStorage[127.0.0.1:42274,DS-6924387e-ea9c-465a-a164-3ed769d962fc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2016238224-172.17.0.15-1595301116436:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33288,DS-6e7e5695-3fc8-4e00-94d3-b6b956da28f8,DISK], DatanodeInfoWithStorage[127.0.0.1:39304,DS-c014dd65-ea46-4677-83f1-7c81f03715c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45938,DS-61622e18-1877-4586-b420-08fc78525e97,DISK], DatanodeInfoWithStorage[127.0.0.1:41093,DS-6ae49ea2-bafa-4b71-8ab3-30da5ddc78ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44175,DS-d9f93db3-516b-4f43-8563-0b39eac944e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45867,DS-53e75f48-7d94-47ea-a4ae-a120d2a39b26,DISK], DatanodeInfoWithStorage[127.0.0.1:42986,DS-4deed613-37bb-4e51-85cb-732a78d7c6e6,DISK], DatanodeInfoWithStorage[127.0.0.1:34946,DS-d2ee3aff-1366-4d56-bb78-7972c7330e82,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2016238224-172.17.0.15-1595301116436:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33288,DS-6e7e5695-3fc8-4e00-94d3-b6b956da28f8,DISK], DatanodeInfoWithStorage[127.0.0.1:39304,DS-c014dd65-ea46-4677-83f1-7c81f03715c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45938,DS-61622e18-1877-4586-b420-08fc78525e97,DISK], DatanodeInfoWithStorage[127.0.0.1:41093,DS-6ae49ea2-bafa-4b71-8ab3-30da5ddc78ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44175,DS-d9f93db3-516b-4f43-8563-0b39eac944e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45867,DS-53e75f48-7d94-47ea-a4ae-a120d2a39b26,DISK], DatanodeInfoWithStorage[127.0.0.1:42986,DS-4deed613-37bb-4e51-85cb-732a78d7c6e6,DISK], DatanodeInfoWithStorage[127.0.0.1:34946,DS-d2ee3aff-1366-4d56-bb78-7972c7330e82,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-190319323-172.17.0.15-1595301460614:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39167,DS-7bb15efd-e440-448c-96bd-49c2c2b42a62,DISK], DatanodeInfoWithStorage[127.0.0.1:41375,DS-830f5022-58ff-48b2-a445-74412358a49d,DISK], DatanodeInfoWithStorage[127.0.0.1:42895,DS-ae782cb1-3567-4cb4-8976-5172fe21e606,DISK], DatanodeInfoWithStorage[127.0.0.1:43680,DS-011ba7bc-6df8-4255-b9e0-25f20965abfd,DISK], DatanodeInfoWithStorage[127.0.0.1:44894,DS-82b87108-261c-4fa6-b208-4b11f733a25e,DISK], DatanodeInfoWithStorage[127.0.0.1:33785,DS-6c6bf2d4-121b-435b-9259-4c76e0f8d82e,DISK], DatanodeInfoWithStorage[127.0.0.1:46176,DS-d0e17dba-3137-4f12-9d0a-3034b074b0b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41424,DS-d81bd1b5-ab61-4773-aa10-b34a278ebc5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-190319323-172.17.0.15-1595301460614:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39167,DS-7bb15efd-e440-448c-96bd-49c2c2b42a62,DISK], DatanodeInfoWithStorage[127.0.0.1:41375,DS-830f5022-58ff-48b2-a445-74412358a49d,DISK], DatanodeInfoWithStorage[127.0.0.1:42895,DS-ae782cb1-3567-4cb4-8976-5172fe21e606,DISK], DatanodeInfoWithStorage[127.0.0.1:43680,DS-011ba7bc-6df8-4255-b9e0-25f20965abfd,DISK], DatanodeInfoWithStorage[127.0.0.1:44894,DS-82b87108-261c-4fa6-b208-4b11f733a25e,DISK], DatanodeInfoWithStorage[127.0.0.1:33785,DS-6c6bf2d4-121b-435b-9259-4c76e0f8d82e,DISK], DatanodeInfoWithStorage[127.0.0.1:46176,DS-d0e17dba-3137-4f12-9d0a-3034b074b0b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41424,DS-d81bd1b5-ab61-4773-aa10-b34a278ebc5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1698522900-172.17.0.15-1595301895549:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37863,DS-382e344e-196a-4461-a1d5-25a882243a67,DISK], DatanodeInfoWithStorage[127.0.0.1:46330,DS-2d62743f-e605-4a2e-9f4b-3ed5b04c7eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:34458,DS-cb3b3e6a-bdd9-4d8e-b1b3-55410f64245c,DISK], DatanodeInfoWithStorage[127.0.0.1:35357,DS-b274e186-6e7e-4f94-980e-001d7dc46c42,DISK], DatanodeInfoWithStorage[127.0.0.1:37056,DS-23c20bcc-e084-428b-8bbd-02069c698ab0,DISK], DatanodeInfoWithStorage[127.0.0.1:37555,DS-4e27ac6d-98d6-4355-8a52-9a7684c411d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46082,DS-4a6cb17a-4bb3-4783-bf11-c52ef9ebacd7,DISK], DatanodeInfoWithStorage[127.0.0.1:39367,DS-2630de91-602b-4417-a361-b55afc8bbb8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1698522900-172.17.0.15-1595301895549:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37863,DS-382e344e-196a-4461-a1d5-25a882243a67,DISK], DatanodeInfoWithStorage[127.0.0.1:46330,DS-2d62743f-e605-4a2e-9f4b-3ed5b04c7eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:34458,DS-cb3b3e6a-bdd9-4d8e-b1b3-55410f64245c,DISK], DatanodeInfoWithStorage[127.0.0.1:35357,DS-b274e186-6e7e-4f94-980e-001d7dc46c42,DISK], DatanodeInfoWithStorage[127.0.0.1:37056,DS-23c20bcc-e084-428b-8bbd-02069c698ab0,DISK], DatanodeInfoWithStorage[127.0.0.1:37555,DS-4e27ac6d-98d6-4355-8a52-9a7684c411d4,DISK], DatanodeInfoWithStorage[127.0.0.1:46082,DS-4a6cb17a-4bb3-4783-bf11-c52ef9ebacd7,DISK], DatanodeInfoWithStorage[127.0.0.1:39367,DS-2630de91-602b-4417-a361-b55afc8bbb8e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1201455560-172.17.0.15-1595302740375:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42110,DS-4663e268-a744-4229-85e8-2be662630539,DISK], DatanodeInfoWithStorage[127.0.0.1:36514,DS-5d40370d-d2fd-4b4d-9c84-1283963af39a,DISK], DatanodeInfoWithStorage[127.0.0.1:43995,DS-9a3f058d-54a3-4e8e-9fc6-bd0ff8ef8dec,DISK], DatanodeInfoWithStorage[127.0.0.1:45603,DS-90cf2718-19c4-4356-a484-e1ba017d5bc6,DISK], DatanodeInfoWithStorage[127.0.0.1:40760,DS-d975c6ae-4d41-4f6d-a6d8-fc5a53682f44,DISK], DatanodeInfoWithStorage[127.0.0.1:41235,DS-6851a1fc-848c-4267-a035-92751519da9d,DISK], DatanodeInfoWithStorage[127.0.0.1:44113,DS-e94ccf18-e3ce-4be3-b21e-0c7c2a5da4b4,DISK], DatanodeInfoWithStorage[127.0.0.1:32806,DS-49cb73c4-1eb9-469e-8c22-fd1612df786a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1201455560-172.17.0.15-1595302740375:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42110,DS-4663e268-a744-4229-85e8-2be662630539,DISK], DatanodeInfoWithStorage[127.0.0.1:36514,DS-5d40370d-d2fd-4b4d-9c84-1283963af39a,DISK], DatanodeInfoWithStorage[127.0.0.1:43995,DS-9a3f058d-54a3-4e8e-9fc6-bd0ff8ef8dec,DISK], DatanodeInfoWithStorage[127.0.0.1:45603,DS-90cf2718-19c4-4356-a484-e1ba017d5bc6,DISK], DatanodeInfoWithStorage[127.0.0.1:40760,DS-d975c6ae-4d41-4f6d-a6d8-fc5a53682f44,DISK], DatanodeInfoWithStorage[127.0.0.1:41235,DS-6851a1fc-848c-4267-a035-92751519da9d,DISK], DatanodeInfoWithStorage[127.0.0.1:44113,DS-e94ccf18-e3ce-4be3-b21e-0c7c2a5da4b4,DISK], DatanodeInfoWithStorage[127.0.0.1:32806,DS-49cb73c4-1eb9-469e-8c22-fd1612df786a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1284811466-172.17.0.15-1595303121648:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41290,DS-bbd33af5-bab6-4edc-9f18-9470ddd36744,DISK], DatanodeInfoWithStorage[127.0.0.1:44335,DS-5d8cd524-79c4-4159-85ff-282b0179cb3e,DISK], DatanodeInfoWithStorage[127.0.0.1:45897,DS-c7409acc-1dd7-496b-93f1-5b5f71f2cff5,DISK], DatanodeInfoWithStorage[127.0.0.1:41018,DS-57d5949a-bc5b-4ab7-b706-66562bed2b10,DISK], DatanodeInfoWithStorage[127.0.0.1:40598,DS-23f197e3-a897-4591-948c-f3d74f267ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:37084,DS-55249288-0ba6-468f-bcc7-6ea364076b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:33352,DS-d309af88-e0c7-44bc-a5b9-4376b6daf237,DISK], DatanodeInfoWithStorage[127.0.0.1:40818,DS-cb2f31ec-c156-4cd2-a2f1-b9219c3179fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1284811466-172.17.0.15-1595303121648:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41290,DS-bbd33af5-bab6-4edc-9f18-9470ddd36744,DISK], DatanodeInfoWithStorage[127.0.0.1:44335,DS-5d8cd524-79c4-4159-85ff-282b0179cb3e,DISK], DatanodeInfoWithStorage[127.0.0.1:45897,DS-c7409acc-1dd7-496b-93f1-5b5f71f2cff5,DISK], DatanodeInfoWithStorage[127.0.0.1:41018,DS-57d5949a-bc5b-4ab7-b706-66562bed2b10,DISK], DatanodeInfoWithStorage[127.0.0.1:40598,DS-23f197e3-a897-4591-948c-f3d74f267ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:37084,DS-55249288-0ba6-468f-bcc7-6ea364076b9e,DISK], DatanodeInfoWithStorage[127.0.0.1:33352,DS-d309af88-e0c7-44bc-a5b9-4376b6daf237,DISK], DatanodeInfoWithStorage[127.0.0.1:40818,DS-cb2f31ec-c156-4cd2-a2f1-b9219c3179fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1056296768-172.17.0.15-1595303465698:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33720,DS-5ef4f4eb-8eab-41b5-97b6-6fe6751721a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45928,DS-429d7d82-7eb6-4a18-aee4-e5c0358a996e,DISK], DatanodeInfoWithStorage[127.0.0.1:35614,DS-29e98b96-67d6-41d8-9bc2-249adeffc3c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34837,DS-b37a9997-73b7-4d44-ae9b-61b6f37f7cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:45393,DS-026cd19b-7eb8-4e5c-9639-4459d9a76350,DISK], DatanodeInfoWithStorage[127.0.0.1:43065,DS-9606290a-b7f8-44ea-84d4-f98ddf30eedd,DISK], DatanodeInfoWithStorage[127.0.0.1:33417,DS-6e4f5b26-a6bb-429f-8a07-1cd170d1b945,DISK], DatanodeInfoWithStorage[127.0.0.1:32771,DS-8efaa241-a8bb-450c-99a3-d56297056c96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1056296768-172.17.0.15-1595303465698:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33720,DS-5ef4f4eb-8eab-41b5-97b6-6fe6751721a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45928,DS-429d7d82-7eb6-4a18-aee4-e5c0358a996e,DISK], DatanodeInfoWithStorage[127.0.0.1:35614,DS-29e98b96-67d6-41d8-9bc2-249adeffc3c0,DISK], DatanodeInfoWithStorage[127.0.0.1:34837,DS-b37a9997-73b7-4d44-ae9b-61b6f37f7cbc,DISK], DatanodeInfoWithStorage[127.0.0.1:45393,DS-026cd19b-7eb8-4e5c-9639-4459d9a76350,DISK], DatanodeInfoWithStorage[127.0.0.1:43065,DS-9606290a-b7f8-44ea-84d4-f98ddf30eedd,DISK], DatanodeInfoWithStorage[127.0.0.1:33417,DS-6e4f5b26-a6bb-429f-8a07-1cd170d1b945,DISK], DatanodeInfoWithStorage[127.0.0.1:32771,DS-8efaa241-a8bb-450c-99a3-d56297056c96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-239970382-172.17.0.15-1595303751828:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46389,DS-6c3fa8ae-f7d2-423c-997f-630234e28bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:37664,DS-9528805c-01f0-44f8-a36a-c5241e813692,DISK], DatanodeInfoWithStorage[127.0.0.1:32844,DS-fd9e8436-db93-4168-9489-4f255cec0946,DISK], DatanodeInfoWithStorage[127.0.0.1:44826,DS-bab3753a-5550-4fb2-86d9-142676fdb55d,DISK], DatanodeInfoWithStorage[127.0.0.1:35227,DS-8f961b44-2899-46ce-b3a4-1a8ed1f86808,DISK], DatanodeInfoWithStorage[127.0.0.1:34842,DS-5c8dc3f5-eb8e-4b74-ad31-f857311cf819,DISK], DatanodeInfoWithStorage[127.0.0.1:36688,DS-6a31ab3b-ff43-4d93-95e5-2e47aa1af67c,DISK], DatanodeInfoWithStorage[127.0.0.1:33582,DS-06b21149-718a-4285-a98d-afe561d6e66d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-239970382-172.17.0.15-1595303751828:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46389,DS-6c3fa8ae-f7d2-423c-997f-630234e28bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:37664,DS-9528805c-01f0-44f8-a36a-c5241e813692,DISK], DatanodeInfoWithStorage[127.0.0.1:32844,DS-fd9e8436-db93-4168-9489-4f255cec0946,DISK], DatanodeInfoWithStorage[127.0.0.1:44826,DS-bab3753a-5550-4fb2-86d9-142676fdb55d,DISK], DatanodeInfoWithStorage[127.0.0.1:35227,DS-8f961b44-2899-46ce-b3a4-1a8ed1f86808,DISK], DatanodeInfoWithStorage[127.0.0.1:34842,DS-5c8dc3f5-eb8e-4b74-ad31-f857311cf819,DISK], DatanodeInfoWithStorage[127.0.0.1:36688,DS-6a31ab3b-ff43-4d93-95e5-2e47aa1af67c,DISK], DatanodeInfoWithStorage[127.0.0.1:33582,DS-06b21149-718a-4285-a98d-afe561d6e66d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-522072567-172.17.0.15-1595304278492:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44604,DS-3a9d13a3-727a-49f0-84aa-664edb821fe8,DISK], DatanodeInfoWithStorage[127.0.0.1:46127,DS-0c3ffaeb-81df-4a2c-9933-5a6e692cb766,DISK], DatanodeInfoWithStorage[127.0.0.1:44523,DS-d50dc18e-b399-4883-a103-b8c7405f95f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34564,DS-d056189b-4643-4104-b9a6-4fc75f378ab3,DISK], DatanodeInfoWithStorage[127.0.0.1:44621,DS-531c618b-69e9-4124-8c5a-ed203dc185e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35665,DS-8345cd06-b92d-4d61-b58a-943dbb831764,DISK], DatanodeInfoWithStorage[127.0.0.1:35762,DS-760fbba7-d0c6-4609-8144-89356871ae65,DISK], DatanodeInfoWithStorage[127.0.0.1:36833,DS-251a5a2a-ffa1-40c2-be50-0399c703564c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-522072567-172.17.0.15-1595304278492:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44604,DS-3a9d13a3-727a-49f0-84aa-664edb821fe8,DISK], DatanodeInfoWithStorage[127.0.0.1:46127,DS-0c3ffaeb-81df-4a2c-9933-5a6e692cb766,DISK], DatanodeInfoWithStorage[127.0.0.1:44523,DS-d50dc18e-b399-4883-a103-b8c7405f95f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34564,DS-d056189b-4643-4104-b9a6-4fc75f378ab3,DISK], DatanodeInfoWithStorage[127.0.0.1:44621,DS-531c618b-69e9-4124-8c5a-ed203dc185e4,DISK], DatanodeInfoWithStorage[127.0.0.1:35665,DS-8345cd06-b92d-4d61-b58a-943dbb831764,DISK], DatanodeInfoWithStorage[127.0.0.1:35762,DS-760fbba7-d0c6-4609-8144-89356871ae65,DISK], DatanodeInfoWithStorage[127.0.0.1:36833,DS-251a5a2a-ffa1-40c2-be50-0399c703564c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-18478042-172.17.0.15-1595304327132:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35272,DS-e681f51e-fccd-435c-b963-a4261705fccf,DISK], DatanodeInfoWithStorage[127.0.0.1:46108,DS-a5315823-740a-45f9-b487-8348b35d958a,DISK], DatanodeInfoWithStorage[127.0.0.1:40161,DS-b4a3cac0-17be-4af5-ad25-d3c008fdd3de,DISK], DatanodeInfoWithStorage[127.0.0.1:41364,DS-a6c36296-2551-4576-ac94-6ae3b11e29a4,DISK], DatanodeInfoWithStorage[127.0.0.1:38561,DS-1b5306ab-bc27-4968-9bb1-1464a69441a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39621,DS-62267451-77fa-4d62-8c5a-10cdf0415f21,DISK], DatanodeInfoWithStorage[127.0.0.1:45567,DS-34da3bf5-ab8e-4771-8aa6-ee393bd0e280,DISK], DatanodeInfoWithStorage[127.0.0.1:44901,DS-862fdd9a-aab4-4353-b8f9-60d96d291289,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-18478042-172.17.0.15-1595304327132:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35272,DS-e681f51e-fccd-435c-b963-a4261705fccf,DISK], DatanodeInfoWithStorage[127.0.0.1:46108,DS-a5315823-740a-45f9-b487-8348b35d958a,DISK], DatanodeInfoWithStorage[127.0.0.1:40161,DS-b4a3cac0-17be-4af5-ad25-d3c008fdd3de,DISK], DatanodeInfoWithStorage[127.0.0.1:41364,DS-a6c36296-2551-4576-ac94-6ae3b11e29a4,DISK], DatanodeInfoWithStorage[127.0.0.1:38561,DS-1b5306ab-bc27-4968-9bb1-1464a69441a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39621,DS-62267451-77fa-4d62-8c5a-10cdf0415f21,DISK], DatanodeInfoWithStorage[127.0.0.1:45567,DS-34da3bf5-ab8e-4771-8aa6-ee393bd0e280,DISK], DatanodeInfoWithStorage[127.0.0.1:44901,DS-862fdd9a-aab4-4353-b8f9-60d96d291289,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-493081417-172.17.0.15-1595305207614:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39006,DS-3ab3caaa-3aab-41d6-adf8-d348ee870cee,DISK], DatanodeInfoWithStorage[127.0.0.1:37139,DS-a2e9dd1f-3f50-4a4d-8164-2673a947bef5,DISK], DatanodeInfoWithStorage[127.0.0.1:38915,DS-ca5dbaa7-59e7-4c89-a635-ccc6557d370f,DISK], DatanodeInfoWithStorage[127.0.0.1:44468,DS-d2d7a779-8b09-4636-8552-2d7469a7ec5d,DISK], DatanodeInfoWithStorage[127.0.0.1:44395,DS-4e65d616-269c-420d-8315-ff40995267ed,DISK], DatanodeInfoWithStorage[127.0.0.1:45878,DS-d569824e-8ac4-4d1e-b3a9-a1e5ef7525a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44961,DS-945ab598-4fc3-475d-9bbd-ea2288c2c6df,DISK], DatanodeInfoWithStorage[127.0.0.1:40314,DS-06d017d0-d0bd-4b84-9b1f-2e2d02ca120a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-493081417-172.17.0.15-1595305207614:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39006,DS-3ab3caaa-3aab-41d6-adf8-d348ee870cee,DISK], DatanodeInfoWithStorage[127.0.0.1:37139,DS-a2e9dd1f-3f50-4a4d-8164-2673a947bef5,DISK], DatanodeInfoWithStorage[127.0.0.1:38915,DS-ca5dbaa7-59e7-4c89-a635-ccc6557d370f,DISK], DatanodeInfoWithStorage[127.0.0.1:44468,DS-d2d7a779-8b09-4636-8552-2d7469a7ec5d,DISK], DatanodeInfoWithStorage[127.0.0.1:44395,DS-4e65d616-269c-420d-8315-ff40995267ed,DISK], DatanodeInfoWithStorage[127.0.0.1:45878,DS-d569824e-8ac4-4d1e-b3a9-a1e5ef7525a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44961,DS-945ab598-4fc3-475d-9bbd-ea2288c2c6df,DISK], DatanodeInfoWithStorage[127.0.0.1:40314,DS-06d017d0-d0bd-4b84-9b1f-2e2d02ca120a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.peer.stats.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-766944480-172.17.0.15-1595305246081:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33114,DS-1534eb88-681b-46da-b21f-f1feca91fa3a,DISK], DatanodeInfoWithStorage[127.0.0.1:40567,DS-94abd6b9-7e53-4082-b621-b194cb5e60a9,DISK], DatanodeInfoWithStorage[127.0.0.1:40746,DS-d234acfe-65ba-4d57-aff9-84de67982440,DISK], DatanodeInfoWithStorage[127.0.0.1:37852,DS-4fd0528d-2410-4b71-960d-8cc9f4f754cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45124,DS-2639db42-9820-4121-b901-881f2e1c903c,DISK], DatanodeInfoWithStorage[127.0.0.1:42032,DS-7cbaecde-b5d7-43c8-99c5-7435e4920262,DISK], DatanodeInfoWithStorage[127.0.0.1:39260,DS-9376b240-9e3f-4b15-971a-bc0eed7a2785,DISK], DatanodeInfoWithStorage[127.0.0.1:44493,DS-c14ffcca-03e3-4417-8637-919cef457c55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-766944480-172.17.0.15-1595305246081:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33114,DS-1534eb88-681b-46da-b21f-f1feca91fa3a,DISK], DatanodeInfoWithStorage[127.0.0.1:40567,DS-94abd6b9-7e53-4082-b621-b194cb5e60a9,DISK], DatanodeInfoWithStorage[127.0.0.1:40746,DS-d234acfe-65ba-4d57-aff9-84de67982440,DISK], DatanodeInfoWithStorage[127.0.0.1:37852,DS-4fd0528d-2410-4b71-960d-8cc9f4f754cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45124,DS-2639db42-9820-4121-b901-881f2e1c903c,DISK], DatanodeInfoWithStorage[127.0.0.1:42032,DS-7cbaecde-b5d7-43c8-99c5-7435e4920262,DISK], DatanodeInfoWithStorage[127.0.0.1:39260,DS-9376b240-9e3f-4b15-971a-bc0eed7a2785,DISK], DatanodeInfoWithStorage[127.0.0.1:44493,DS-c14ffcca-03e3-4417-8637-919cef457c55,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 6950
