reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2147059899-172.17.0.9-1595385978329:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46523,DS-d6b7cf2a-a381-4005-95e2-a50f45fc1c32,DISK], DatanodeInfoWithStorage[127.0.0.1:33565,DS-c87cbb1d-868e-44c9-bee9-63b9b4090c67,DISK], DatanodeInfoWithStorage[127.0.0.1:35288,DS-d31a549f-7109-476d-af9d-c386ae80a746,DISK], DatanodeInfoWithStorage[127.0.0.1:45927,DS-0a1ed206-136c-4e46-b13e-e925e0ea4798,DISK], DatanodeInfoWithStorage[127.0.0.1:35742,DS-9b810d55-e882-4056-a989-96c9b2050a1b,DISK], DatanodeInfoWithStorage[127.0.0.1:46437,DS-2d7e532f-bbbc-42f5-9998-e38deb259b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38005,DS-9d3e58a6-9597-4864-be22-2833fe9f4a40,DISK], DatanodeInfoWithStorage[127.0.0.1:35071,DS-8aa31134-592a-471b-a84a-7208646e8192,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2147059899-172.17.0.9-1595385978329:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46523,DS-d6b7cf2a-a381-4005-95e2-a50f45fc1c32,DISK], DatanodeInfoWithStorage[127.0.0.1:33565,DS-c87cbb1d-868e-44c9-bee9-63b9b4090c67,DISK], DatanodeInfoWithStorage[127.0.0.1:35288,DS-d31a549f-7109-476d-af9d-c386ae80a746,DISK], DatanodeInfoWithStorage[127.0.0.1:45927,DS-0a1ed206-136c-4e46-b13e-e925e0ea4798,DISK], DatanodeInfoWithStorage[127.0.0.1:35742,DS-9b810d55-e882-4056-a989-96c9b2050a1b,DISK], DatanodeInfoWithStorage[127.0.0.1:46437,DS-2d7e532f-bbbc-42f5-9998-e38deb259b0f,DISK], DatanodeInfoWithStorage[127.0.0.1:38005,DS-9d3e58a6-9597-4864-be22-2833fe9f4a40,DISK], DatanodeInfoWithStorage[127.0.0.1:35071,DS-8aa31134-592a-471b-a84a-7208646e8192,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2114179062-172.17.0.9-1595386057985:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43737,DS-0d8b7003-1e75-4493-bf72-716fd6b4c1dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42170,DS-fe3d614e-bc2c-4a51-8c0e-e95d1820d9fe,DISK], DatanodeInfoWithStorage[127.0.0.1:44788,DS-81318dd3-0e5d-4578-8ecf-2b150fafd396,DISK], DatanodeInfoWithStorage[127.0.0.1:37169,DS-74d29ca4-9247-4e46-b315-3f4745537ed4,DISK], DatanodeInfoWithStorage[127.0.0.1:38739,DS-a1c1a7a1-dd6f-4903-8272-52f1e324098b,DISK], DatanodeInfoWithStorage[127.0.0.1:34685,DS-607c2d96-fc59-40d8-bcbe-abec92f32197,DISK], DatanodeInfoWithStorage[127.0.0.1:41555,DS-811319d4-8bc4-40a1-908b-4a928953fee4,DISK], DatanodeInfoWithStorage[127.0.0.1:46059,DS-f4b57867-7fb0-403d-9f90-9bbe34013ce6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2114179062-172.17.0.9-1595386057985:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43737,DS-0d8b7003-1e75-4493-bf72-716fd6b4c1dd,DISK], DatanodeInfoWithStorage[127.0.0.1:42170,DS-fe3d614e-bc2c-4a51-8c0e-e95d1820d9fe,DISK], DatanodeInfoWithStorage[127.0.0.1:44788,DS-81318dd3-0e5d-4578-8ecf-2b150fafd396,DISK], DatanodeInfoWithStorage[127.0.0.1:37169,DS-74d29ca4-9247-4e46-b315-3f4745537ed4,DISK], DatanodeInfoWithStorage[127.0.0.1:38739,DS-a1c1a7a1-dd6f-4903-8272-52f1e324098b,DISK], DatanodeInfoWithStorage[127.0.0.1:34685,DS-607c2d96-fc59-40d8-bcbe-abec92f32197,DISK], DatanodeInfoWithStorage[127.0.0.1:41555,DS-811319d4-8bc4-40a1-908b-4a928953fee4,DISK], DatanodeInfoWithStorage[127.0.0.1:46059,DS-f4b57867-7fb0-403d-9f90-9bbe34013ce6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-8213017-172.17.0.9-1595386438055:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35457,DS-ca625d6e-e494-477a-b184-232bb08f7979,DISK], DatanodeInfoWithStorage[127.0.0.1:44385,DS-631a8b18-5d5c-451d-9d34-f6ad9e208d22,DISK], DatanodeInfoWithStorage[127.0.0.1:37672,DS-a3a6bc2e-e1d6-4303-a5c2-d65f6f01464c,DISK], DatanodeInfoWithStorage[127.0.0.1:46615,DS-15fdb955-2846-4246-b5af-49fccc0962ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39085,DS-ce88009f-c2b5-42f9-9d64-17d18b5ff4a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33234,DS-cefaf464-135b-44eb-96bb-8c3cba7020b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37252,DS-ba725cc5-0da6-42fc-826a-4736de48a59d,DISK], DatanodeInfoWithStorage[127.0.0.1:36256,DS-ad8b1c32-ca37-4724-ae36-889ea8e77011,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-8213017-172.17.0.9-1595386438055:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35457,DS-ca625d6e-e494-477a-b184-232bb08f7979,DISK], DatanodeInfoWithStorage[127.0.0.1:44385,DS-631a8b18-5d5c-451d-9d34-f6ad9e208d22,DISK], DatanodeInfoWithStorage[127.0.0.1:37672,DS-a3a6bc2e-e1d6-4303-a5c2-d65f6f01464c,DISK], DatanodeInfoWithStorage[127.0.0.1:46615,DS-15fdb955-2846-4246-b5af-49fccc0962ab,DISK], DatanodeInfoWithStorage[127.0.0.1:39085,DS-ce88009f-c2b5-42f9-9d64-17d18b5ff4a9,DISK], DatanodeInfoWithStorage[127.0.0.1:33234,DS-cefaf464-135b-44eb-96bb-8c3cba7020b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37252,DS-ba725cc5-0da6-42fc-826a-4736de48a59d,DISK], DatanodeInfoWithStorage[127.0.0.1:36256,DS-ad8b1c32-ca37-4724-ae36-889ea8e77011,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-783484963-172.17.0.9-1595387573958:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41877,DS-9dfe80cd-b048-43bf-b778-03b993ce5a74,DISK], DatanodeInfoWithStorage[127.0.0.1:43060,DS-dca2cc01-ef08-487d-9c7e-46ea5a55e652,DISK], DatanodeInfoWithStorage[127.0.0.1:44275,DS-7afd1ebe-5144-4f16-b92b-59c9cfe4fb25,DISK], DatanodeInfoWithStorage[127.0.0.1:33323,DS-4593b81e-74bc-46f2-a0ec-9a318aa3c018,DISK], DatanodeInfoWithStorage[127.0.0.1:44380,DS-19bb95af-6c91-49c4-ab7d-0a47e4ef314b,DISK], DatanodeInfoWithStorage[127.0.0.1:44587,DS-0e641a79-d6cb-4686-9f4e-616f841fbd8e,DISK], DatanodeInfoWithStorage[127.0.0.1:39151,DS-554a4d49-2fab-487e-b1e1-69c9445751b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39862,DS-5b4d75ce-d0d5-4240-85c2-71d32e9f9ea0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-783484963-172.17.0.9-1595387573958:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41877,DS-9dfe80cd-b048-43bf-b778-03b993ce5a74,DISK], DatanodeInfoWithStorage[127.0.0.1:43060,DS-dca2cc01-ef08-487d-9c7e-46ea5a55e652,DISK], DatanodeInfoWithStorage[127.0.0.1:44275,DS-7afd1ebe-5144-4f16-b92b-59c9cfe4fb25,DISK], DatanodeInfoWithStorage[127.0.0.1:33323,DS-4593b81e-74bc-46f2-a0ec-9a318aa3c018,DISK], DatanodeInfoWithStorage[127.0.0.1:44380,DS-19bb95af-6c91-49c4-ab7d-0a47e4ef314b,DISK], DatanodeInfoWithStorage[127.0.0.1:44587,DS-0e641a79-d6cb-4686-9f4e-616f841fbd8e,DISK], DatanodeInfoWithStorage[127.0.0.1:39151,DS-554a4d49-2fab-487e-b1e1-69c9445751b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39862,DS-5b4d75ce-d0d5-4240-85c2-71d32e9f9ea0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-349692558-172.17.0.9-1595388303302:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45212,DS-2500a608-fd34-4675-b06b-5e3a1bedf9b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36720,DS-11c34f29-8f7b-4e27-b33d-4a4af1934b28,DISK], DatanodeInfoWithStorage[127.0.0.1:37626,DS-3045c3d8-85b3-4292-95fe-9b694c798310,DISK], DatanodeInfoWithStorage[127.0.0.1:34715,DS-b949c240-ecea-4766-b95c-6fa4066019d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40625,DS-3f2ba772-ba41-4cb7-9420-00634ed0df1b,DISK], DatanodeInfoWithStorage[127.0.0.1:34629,DS-7416ddab-9250-4dc8-ba73-fa0b14122f16,DISK], DatanodeInfoWithStorage[127.0.0.1:43735,DS-1e0235b4-a985-4651-bc67-48e089bc7050,DISK], DatanodeInfoWithStorage[127.0.0.1:41308,DS-74ac20d7-4a59-445c-8d26-00b50c0b88c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-349692558-172.17.0.9-1595388303302:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45212,DS-2500a608-fd34-4675-b06b-5e3a1bedf9b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36720,DS-11c34f29-8f7b-4e27-b33d-4a4af1934b28,DISK], DatanodeInfoWithStorage[127.0.0.1:37626,DS-3045c3d8-85b3-4292-95fe-9b694c798310,DISK], DatanodeInfoWithStorage[127.0.0.1:34715,DS-b949c240-ecea-4766-b95c-6fa4066019d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40625,DS-3f2ba772-ba41-4cb7-9420-00634ed0df1b,DISK], DatanodeInfoWithStorage[127.0.0.1:34629,DS-7416ddab-9250-4dc8-ba73-fa0b14122f16,DISK], DatanodeInfoWithStorage[127.0.0.1:43735,DS-1e0235b4-a985-4651-bc67-48e089bc7050,DISK], DatanodeInfoWithStorage[127.0.0.1:41308,DS-74ac20d7-4a59-445c-8d26-00b50c0b88c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1284034112-172.17.0.9-1595389244521:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40259,DS-b9d6909d-c984-4ca8-830e-79327a86ba12,DISK], DatanodeInfoWithStorage[127.0.0.1:44548,DS-1414f7cd-0e82-4a2c-8f69-652aa285899e,DISK], DatanodeInfoWithStorage[127.0.0.1:40285,DS-c61e2f8c-a66d-4681-b148-b4426c65668f,DISK], DatanodeInfoWithStorage[127.0.0.1:43066,DS-b24cb7c0-7643-4dea-99f4-fbf5182c3a7b,DISK], DatanodeInfoWithStorage[127.0.0.1:37308,DS-9e8df302-4548-4863-8af8-9cee3fd00cdf,DISK], DatanodeInfoWithStorage[127.0.0.1:36257,DS-b8362843-7dcc-47cf-b496-e38ef674b6d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42209,DS-813de63e-53ee-4eb0-a42b-dd531e0e2e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:39755,DS-9228bbb5-49a9-4d0f-9a21-4773bafd9d4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1284034112-172.17.0.9-1595389244521:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40259,DS-b9d6909d-c984-4ca8-830e-79327a86ba12,DISK], DatanodeInfoWithStorage[127.0.0.1:44548,DS-1414f7cd-0e82-4a2c-8f69-652aa285899e,DISK], DatanodeInfoWithStorage[127.0.0.1:40285,DS-c61e2f8c-a66d-4681-b148-b4426c65668f,DISK], DatanodeInfoWithStorage[127.0.0.1:43066,DS-b24cb7c0-7643-4dea-99f4-fbf5182c3a7b,DISK], DatanodeInfoWithStorage[127.0.0.1:37308,DS-9e8df302-4548-4863-8af8-9cee3fd00cdf,DISK], DatanodeInfoWithStorage[127.0.0.1:36257,DS-b8362843-7dcc-47cf-b496-e38ef674b6d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42209,DS-813de63e-53ee-4eb0-a42b-dd531e0e2e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:39755,DS-9228bbb5-49a9-4d0f-9a21-4773bafd9d4d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-603214112-172.17.0.9-1595389547907:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40468,DS-9f77028c-8dc0-4e96-b73f-2c589d90b18c,DISK], DatanodeInfoWithStorage[127.0.0.1:43786,DS-c9592628-70eb-43f1-af6d-5447f9baf039,DISK], DatanodeInfoWithStorage[127.0.0.1:40997,DS-f6e97f96-4d7b-429a-af1b-1a81387e4827,DISK], DatanodeInfoWithStorage[127.0.0.1:44301,DS-84aba010-4b8f-464f-a447-ea4a3f77578a,DISK], DatanodeInfoWithStorage[127.0.0.1:45174,DS-6f52c4dc-5518-4283-9cf9-0a52a0394beb,DISK], DatanodeInfoWithStorage[127.0.0.1:41814,DS-2115fe1f-177c-4d93-a4ff-422d88d29e69,DISK], DatanodeInfoWithStorage[127.0.0.1:35157,DS-64745c2f-e000-4a39-ab3b-e5e43dea5a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:34177,DS-c123c3d9-bf64-4449-9148-7111a46404f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-603214112-172.17.0.9-1595389547907:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40468,DS-9f77028c-8dc0-4e96-b73f-2c589d90b18c,DISK], DatanodeInfoWithStorage[127.0.0.1:43786,DS-c9592628-70eb-43f1-af6d-5447f9baf039,DISK], DatanodeInfoWithStorage[127.0.0.1:40997,DS-f6e97f96-4d7b-429a-af1b-1a81387e4827,DISK], DatanodeInfoWithStorage[127.0.0.1:44301,DS-84aba010-4b8f-464f-a447-ea4a3f77578a,DISK], DatanodeInfoWithStorage[127.0.0.1:45174,DS-6f52c4dc-5518-4283-9cf9-0a52a0394beb,DISK], DatanodeInfoWithStorage[127.0.0.1:41814,DS-2115fe1f-177c-4d93-a4ff-422d88d29e69,DISK], DatanodeInfoWithStorage[127.0.0.1:35157,DS-64745c2f-e000-4a39-ab3b-e5e43dea5a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:34177,DS-c123c3d9-bf64-4449-9148-7111a46404f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1616098263-172.17.0.9-1595389859764:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35733,DS-e66fae68-2140-4938-ac1c-c75af50c33c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40950,DS-ff4d86f5-0e23-489d-9487-07e666ecf79f,DISK], DatanodeInfoWithStorage[127.0.0.1:44906,DS-df77f243-2e3b-4282-ba6e-9670e0a825ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40040,DS-b7471020-f739-44b6-91ae-cccaa7c5ca20,DISK], DatanodeInfoWithStorage[127.0.0.1:41484,DS-126a8524-2f6b-4967-a01c-9180b4296cd3,DISK], DatanodeInfoWithStorage[127.0.0.1:39854,DS-d225f99d-e279-4b49-8440-72a10862833c,DISK], DatanodeInfoWithStorage[127.0.0.1:37257,DS-8cc4008e-bd41-442c-8ebc-7e42e4eccea7,DISK], DatanodeInfoWithStorage[127.0.0.1:34595,DS-86d13489-f144-4484-844c-244d46665165,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1616098263-172.17.0.9-1595389859764:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35733,DS-e66fae68-2140-4938-ac1c-c75af50c33c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40950,DS-ff4d86f5-0e23-489d-9487-07e666ecf79f,DISK], DatanodeInfoWithStorage[127.0.0.1:44906,DS-df77f243-2e3b-4282-ba6e-9670e0a825ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40040,DS-b7471020-f739-44b6-91ae-cccaa7c5ca20,DISK], DatanodeInfoWithStorage[127.0.0.1:41484,DS-126a8524-2f6b-4967-a01c-9180b4296cd3,DISK], DatanodeInfoWithStorage[127.0.0.1:39854,DS-d225f99d-e279-4b49-8440-72a10862833c,DISK], DatanodeInfoWithStorage[127.0.0.1:37257,DS-8cc4008e-bd41-442c-8ebc-7e42e4eccea7,DISK], DatanodeInfoWithStorage[127.0.0.1:34595,DS-86d13489-f144-4484-844c-244d46665165,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1439586429-172.17.0.9-1595390350517:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40523,DS-af11c381-fcc8-40cf-84b6-0855bcd1dcfb,DISK], DatanodeInfoWithStorage[127.0.0.1:41806,DS-2ae24f2d-cca8-4641-8fe1-29bd3a5d2a6d,DISK], DatanodeInfoWithStorage[127.0.0.1:35654,DS-36594b7b-1b43-4f10-9df5-ecc8f38a3327,DISK], DatanodeInfoWithStorage[127.0.0.1:36920,DS-c8ae14d9-6e14-4b08-9746-645818f606ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42764,DS-0259dd1f-bdc2-46f9-9fcc-4da5780e5aa4,DISK], DatanodeInfoWithStorage[127.0.0.1:38050,DS-24f46fa3-dcb3-4fd4-9161-4e73b87421fd,DISK], DatanodeInfoWithStorage[127.0.0.1:38403,DS-fd773eed-935e-45c8-aa6d-da9df3deac9b,DISK], DatanodeInfoWithStorage[127.0.0.1:36581,DS-912ec1bc-8c08-4fa3-ba23-37ca168d85fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1439586429-172.17.0.9-1595390350517:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40523,DS-af11c381-fcc8-40cf-84b6-0855bcd1dcfb,DISK], DatanodeInfoWithStorage[127.0.0.1:41806,DS-2ae24f2d-cca8-4641-8fe1-29bd3a5d2a6d,DISK], DatanodeInfoWithStorage[127.0.0.1:35654,DS-36594b7b-1b43-4f10-9df5-ecc8f38a3327,DISK], DatanodeInfoWithStorage[127.0.0.1:36920,DS-c8ae14d9-6e14-4b08-9746-645818f606ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42764,DS-0259dd1f-bdc2-46f9-9fcc-4da5780e5aa4,DISK], DatanodeInfoWithStorage[127.0.0.1:38050,DS-24f46fa3-dcb3-4fd4-9161-4e73b87421fd,DISK], DatanodeInfoWithStorage[127.0.0.1:38403,DS-fd773eed-935e-45c8-aa6d-da9df3deac9b,DISK], DatanodeInfoWithStorage[127.0.0.1:36581,DS-912ec1bc-8c08-4fa3-ba23-37ca168d85fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-939782977-172.17.0.9-1595390574405:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46466,DS-7bc5ea39-716c-43a7-859e-a847000cc7c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41307,DS-2f65ae7e-23fc-483d-9c09-264ffcba06c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45983,DS-d078bae9-533a-451a-a56d-f6eef2c360ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41222,DS-2a708468-1159-4166-9039-308351be7576,DISK], DatanodeInfoWithStorage[127.0.0.1:38413,DS-1cbc396b-43bf-4dae-9fe9-c7ff18121d01,DISK], DatanodeInfoWithStorage[127.0.0.1:37301,DS-b4b90c4b-ba5e-4a48-8ab5-96a3e04fa8d5,DISK], DatanodeInfoWithStorage[127.0.0.1:37451,DS-d21a9cb1-07af-423c-b5d2-a107bbf010a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41858,DS-96065099-6609-49a7-a17a-a6148a4c4616,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-939782977-172.17.0.9-1595390574405:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46466,DS-7bc5ea39-716c-43a7-859e-a847000cc7c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41307,DS-2f65ae7e-23fc-483d-9c09-264ffcba06c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45983,DS-d078bae9-533a-451a-a56d-f6eef2c360ce,DISK], DatanodeInfoWithStorage[127.0.0.1:41222,DS-2a708468-1159-4166-9039-308351be7576,DISK], DatanodeInfoWithStorage[127.0.0.1:38413,DS-1cbc396b-43bf-4dae-9fe9-c7ff18121d01,DISK], DatanodeInfoWithStorage[127.0.0.1:37301,DS-b4b90c4b-ba5e-4a48-8ab5-96a3e04fa8d5,DISK], DatanodeInfoWithStorage[127.0.0.1:37451,DS-d21a9cb1-07af-423c-b5d2-a107bbf010a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41858,DS-96065099-6609-49a7-a17a-a6148a4c4616,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-952567589-172.17.0.9-1595390697442:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36791,DS-63c4dcd8-79d2-4ae0-99a8-066cd7ac1ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:45241,DS-9803ed8b-c027-437a-8b2f-559879214abb,DISK], DatanodeInfoWithStorage[127.0.0.1:32850,DS-996c0c13-fad9-45f4-8b76-dbd8d841426d,DISK], DatanodeInfoWithStorage[127.0.0.1:36052,DS-bc5a1c74-4158-415f-949f-cd26bab5db21,DISK], DatanodeInfoWithStorage[127.0.0.1:41492,DS-8c14ab8e-f328-49c8-aaf7-626a1099f544,DISK], DatanodeInfoWithStorage[127.0.0.1:33610,DS-2ebb6552-ecb1-43ca-9d01-b12a7287bd82,DISK], DatanodeInfoWithStorage[127.0.0.1:34308,DS-47a4b0e2-c89e-4120-a774-745fac6affe1,DISK], DatanodeInfoWithStorage[127.0.0.1:42352,DS-80c29aef-8588-4a81-9b5f-837db80827c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-952567589-172.17.0.9-1595390697442:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36791,DS-63c4dcd8-79d2-4ae0-99a8-066cd7ac1ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:45241,DS-9803ed8b-c027-437a-8b2f-559879214abb,DISK], DatanodeInfoWithStorage[127.0.0.1:32850,DS-996c0c13-fad9-45f4-8b76-dbd8d841426d,DISK], DatanodeInfoWithStorage[127.0.0.1:36052,DS-bc5a1c74-4158-415f-949f-cd26bab5db21,DISK], DatanodeInfoWithStorage[127.0.0.1:41492,DS-8c14ab8e-f328-49c8-aaf7-626a1099f544,DISK], DatanodeInfoWithStorage[127.0.0.1:33610,DS-2ebb6552-ecb1-43ca-9d01-b12a7287bd82,DISK], DatanodeInfoWithStorage[127.0.0.1:34308,DS-47a4b0e2-c89e-4120-a774-745fac6affe1,DISK], DatanodeInfoWithStorage[127.0.0.1:42352,DS-80c29aef-8588-4a81-9b5f-837db80827c8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1718199212-172.17.0.9-1595391651270:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35993,DS-150ea8f7-68da-4dfc-a845-5a76a27c487f,DISK], DatanodeInfoWithStorage[127.0.0.1:38672,DS-3bb5dab8-aa17-4d49-bd68-ef095df6eb19,DISK], DatanodeInfoWithStorage[127.0.0.1:42738,DS-00b54554-c712-44be-a366-e6c072cfa5d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36403,DS-4b616d59-56c7-41d4-8375-7b10e332fd04,DISK], DatanodeInfoWithStorage[127.0.0.1:45106,DS-132b6829-5921-46bb-bcae-130f572f7634,DISK], DatanodeInfoWithStorage[127.0.0.1:45078,DS-f26919aa-6fb3-4546-ba05-ffe1959b258b,DISK], DatanodeInfoWithStorage[127.0.0.1:38215,DS-6627bfe7-f875-4d0c-8079-edd411c55900,DISK], DatanodeInfoWithStorage[127.0.0.1:34124,DS-4e76716f-85b1-4175-85a3-40febe1e2da7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1718199212-172.17.0.9-1595391651270:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35993,DS-150ea8f7-68da-4dfc-a845-5a76a27c487f,DISK], DatanodeInfoWithStorage[127.0.0.1:38672,DS-3bb5dab8-aa17-4d49-bd68-ef095df6eb19,DISK], DatanodeInfoWithStorage[127.0.0.1:42738,DS-00b54554-c712-44be-a366-e6c072cfa5d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36403,DS-4b616d59-56c7-41d4-8375-7b10e332fd04,DISK], DatanodeInfoWithStorage[127.0.0.1:45106,DS-132b6829-5921-46bb-bcae-130f572f7634,DISK], DatanodeInfoWithStorage[127.0.0.1:45078,DS-f26919aa-6fb3-4546-ba05-ffe1959b258b,DISK], DatanodeInfoWithStorage[127.0.0.1:38215,DS-6627bfe7-f875-4d0c-8079-edd411c55900,DISK], DatanodeInfoWithStorage[127.0.0.1:34124,DS-4e76716f-85b1-4175-85a3-40febe1e2da7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1404864832-172.17.0.9-1595391765154:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33887,DS-24dd44db-c179-441c-8d40-0930aad7fd11,DISK], DatanodeInfoWithStorage[127.0.0.1:44647,DS-4b81d0af-8cb1-4d39-b610-9b06884f8a1b,DISK], DatanodeInfoWithStorage[127.0.0.1:45446,DS-9ba1b547-b70c-4263-8e69-efc99fbf05ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45165,DS-c6059229-275a-4afd-8421-0cd7c1bf0a68,DISK], DatanodeInfoWithStorage[127.0.0.1:37187,DS-1a662733-7326-4363-b3d7-f25d80e1ba4b,DISK], DatanodeInfoWithStorage[127.0.0.1:41764,DS-f823fc25-0944-4272-8f21-df7374abcb87,DISK], DatanodeInfoWithStorage[127.0.0.1:42875,DS-d6019a5a-d55c-44ae-bf5b-6c168f653fcf,DISK], DatanodeInfoWithStorage[127.0.0.1:38078,DS-aba9060a-ba55-499f-93c2-2472e18cefc5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1404864832-172.17.0.9-1595391765154:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33887,DS-24dd44db-c179-441c-8d40-0930aad7fd11,DISK], DatanodeInfoWithStorage[127.0.0.1:44647,DS-4b81d0af-8cb1-4d39-b610-9b06884f8a1b,DISK], DatanodeInfoWithStorage[127.0.0.1:45446,DS-9ba1b547-b70c-4263-8e69-efc99fbf05ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45165,DS-c6059229-275a-4afd-8421-0cd7c1bf0a68,DISK], DatanodeInfoWithStorage[127.0.0.1:37187,DS-1a662733-7326-4363-b3d7-f25d80e1ba4b,DISK], DatanodeInfoWithStorage[127.0.0.1:41764,DS-f823fc25-0944-4272-8f21-df7374abcb87,DISK], DatanodeInfoWithStorage[127.0.0.1:42875,DS-d6019a5a-d55c-44ae-bf5b-6c168f653fcf,DISK], DatanodeInfoWithStorage[127.0.0.1:38078,DS-aba9060a-ba55-499f-93c2-2472e18cefc5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.low-latency
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1159866309-172.17.0.9-1595392020697:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33040,DS-5cdb15bc-1a30-423f-813f-8898173dc604,DISK], DatanodeInfoWithStorage[127.0.0.1:35663,DS-fe32999e-cba9-4b7e-af2f-4b6ea39ae9d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41440,DS-a084e5d0-9b5e-499b-a34c-84739ce7301d,DISK], DatanodeInfoWithStorage[127.0.0.1:33298,DS-ff02b749-5ff4-4c20-9251-b298d86365f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33278,DS-0c80ab79-ea8d-4581-906e-d9eca3df0982,DISK], DatanodeInfoWithStorage[127.0.0.1:46649,DS-4af6b027-3fc8-4941-9335-e729ba775914,DISK], DatanodeInfoWithStorage[127.0.0.1:37150,DS-8c96dbb5-cbd2-4348-a064-82d1d22803aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44651,DS-d3ec6f18-6be4-43e8-ab44-207d7e5e38e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1159866309-172.17.0.9-1595392020697:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33040,DS-5cdb15bc-1a30-423f-813f-8898173dc604,DISK], DatanodeInfoWithStorage[127.0.0.1:35663,DS-fe32999e-cba9-4b7e-af2f-4b6ea39ae9d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41440,DS-a084e5d0-9b5e-499b-a34c-84739ce7301d,DISK], DatanodeInfoWithStorage[127.0.0.1:33298,DS-ff02b749-5ff4-4c20-9251-b298d86365f7,DISK], DatanodeInfoWithStorage[127.0.0.1:33278,DS-0c80ab79-ea8d-4581-906e-d9eca3df0982,DISK], DatanodeInfoWithStorage[127.0.0.1:46649,DS-4af6b027-3fc8-4941-9335-e729ba775914,DISK], DatanodeInfoWithStorage[127.0.0.1:37150,DS-8c96dbb5-cbd2-4348-a064-82d1d22803aa,DISK], DatanodeInfoWithStorage[127.0.0.1:44651,DS-d3ec6f18-6be4-43e8-ab44-207d7e5e38e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 6446
