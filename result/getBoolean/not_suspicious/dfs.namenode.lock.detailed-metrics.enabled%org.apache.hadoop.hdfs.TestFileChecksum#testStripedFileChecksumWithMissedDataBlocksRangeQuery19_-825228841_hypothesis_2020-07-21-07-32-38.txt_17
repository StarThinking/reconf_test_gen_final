reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1201103565-172.17.0.12-1595317386247:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43640,DS-9c23851d-2ee8-4c50-aa52-b1d57b7ac67b,DISK], DatanodeInfoWithStorage[127.0.0.1:40819,DS-1a919e51-b602-43c0-953f-9b8934c0168a,DISK], DatanodeInfoWithStorage[127.0.0.1:34029,DS-8db2a3ef-eb65-4789-a8a8-2e39b662f1ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33262,DS-8b9a06bd-cb5b-4feb-a332-409625d1c825,DISK], DatanodeInfoWithStorage[127.0.0.1:44161,DS-51189abc-93e1-456e-a97a-e5539d450f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:43421,DS-37c17fdd-e340-49bb-a4fb-1381e1a66adb,DISK], DatanodeInfoWithStorage[127.0.0.1:37055,DS-d0443ad3-a731-4bb9-85de-7ba2e7bce672,DISK], DatanodeInfoWithStorage[127.0.0.1:37876,DS-3c3712c7-d89f-4937-a6b0-7bea1738cb03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1201103565-172.17.0.12-1595317386247:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43640,DS-9c23851d-2ee8-4c50-aa52-b1d57b7ac67b,DISK], DatanodeInfoWithStorage[127.0.0.1:40819,DS-1a919e51-b602-43c0-953f-9b8934c0168a,DISK], DatanodeInfoWithStorage[127.0.0.1:34029,DS-8db2a3ef-eb65-4789-a8a8-2e39b662f1ea,DISK], DatanodeInfoWithStorage[127.0.0.1:33262,DS-8b9a06bd-cb5b-4feb-a332-409625d1c825,DISK], DatanodeInfoWithStorage[127.0.0.1:44161,DS-51189abc-93e1-456e-a97a-e5539d450f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:43421,DS-37c17fdd-e340-49bb-a4fb-1381e1a66adb,DISK], DatanodeInfoWithStorage[127.0.0.1:37055,DS-d0443ad3-a731-4bb9-85de-7ba2e7bce672,DISK], DatanodeInfoWithStorage[127.0.0.1:37876,DS-3c3712c7-d89f-4937-a6b0-7bea1738cb03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-10532938-172.17.0.12-1595317553122:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45890,DS-03cdca30-b6ed-4c72-869f-0eb9d50fe429,DISK], DatanodeInfoWithStorage[127.0.0.1:44173,DS-348c726d-9587-4cdc-9fbb-3127183aa53b,DISK], DatanodeInfoWithStorage[127.0.0.1:46749,DS-60148771-4546-4fd0-b3a9-3507abd3263e,DISK], DatanodeInfoWithStorage[127.0.0.1:45853,DS-bb735fa8-d575-4a72-ab12-f8f8b9f52097,DISK], DatanodeInfoWithStorage[127.0.0.1:37793,DS-3b98fb04-0370-495c-9c0a-7afd9c704e94,DISK], DatanodeInfoWithStorage[127.0.0.1:40092,DS-0b18e7dd-ea1c-4c97-a2b6-84d058b06ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:35803,DS-6e266712-cf8c-46f5-b506-5b1dc233a92e,DISK], DatanodeInfoWithStorage[127.0.0.1:34842,DS-9784fde8-087f-417e-93d0-5ae73eda0b04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-10532938-172.17.0.12-1595317553122:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45890,DS-03cdca30-b6ed-4c72-869f-0eb9d50fe429,DISK], DatanodeInfoWithStorage[127.0.0.1:44173,DS-348c726d-9587-4cdc-9fbb-3127183aa53b,DISK], DatanodeInfoWithStorage[127.0.0.1:46749,DS-60148771-4546-4fd0-b3a9-3507abd3263e,DISK], DatanodeInfoWithStorage[127.0.0.1:45853,DS-bb735fa8-d575-4a72-ab12-f8f8b9f52097,DISK], DatanodeInfoWithStorage[127.0.0.1:37793,DS-3b98fb04-0370-495c-9c0a-7afd9c704e94,DISK], DatanodeInfoWithStorage[127.0.0.1:40092,DS-0b18e7dd-ea1c-4c97-a2b6-84d058b06ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:35803,DS-6e266712-cf8c-46f5-b506-5b1dc233a92e,DISK], DatanodeInfoWithStorage[127.0.0.1:34842,DS-9784fde8-087f-417e-93d0-5ae73eda0b04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1254255983-172.17.0.12-1595317593826:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41865,DS-495a5a75-21be-4906-be85-cc66180d5cc0,DISK], DatanodeInfoWithStorage[127.0.0.1:45419,DS-db35f704-f9a8-4948-b96d-c8513c563ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:44639,DS-161be5ac-43ef-4d01-b5ef-1d0a8bffb80f,DISK], DatanodeInfoWithStorage[127.0.0.1:33273,DS-f63a8ab4-959d-4ba7-aa20-8d84f39f7961,DISK], DatanodeInfoWithStorage[127.0.0.1:41105,DS-0191a9bc-7f1e-4dff-b837-a49a27573dda,DISK], DatanodeInfoWithStorage[127.0.0.1:35925,DS-13db8df4-201f-467f-a6f1-43bb6d20ed7b,DISK], DatanodeInfoWithStorage[127.0.0.1:40496,DS-f09a7a82-51d3-4a9f-bb03-1be81b834833,DISK], DatanodeInfoWithStorage[127.0.0.1:33212,DS-cb55b52b-3b04-45d2-9669-5bee972fef78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1254255983-172.17.0.12-1595317593826:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41865,DS-495a5a75-21be-4906-be85-cc66180d5cc0,DISK], DatanodeInfoWithStorage[127.0.0.1:45419,DS-db35f704-f9a8-4948-b96d-c8513c563ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:44639,DS-161be5ac-43ef-4d01-b5ef-1d0a8bffb80f,DISK], DatanodeInfoWithStorage[127.0.0.1:33273,DS-f63a8ab4-959d-4ba7-aa20-8d84f39f7961,DISK], DatanodeInfoWithStorage[127.0.0.1:41105,DS-0191a9bc-7f1e-4dff-b837-a49a27573dda,DISK], DatanodeInfoWithStorage[127.0.0.1:35925,DS-13db8df4-201f-467f-a6f1-43bb6d20ed7b,DISK], DatanodeInfoWithStorage[127.0.0.1:40496,DS-f09a7a82-51d3-4a9f-bb03-1be81b834833,DISK], DatanodeInfoWithStorage[127.0.0.1:33212,DS-cb55b52b-3b04-45d2-9669-5bee972fef78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-793771251-172.17.0.12-1595317990902:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46199,DS-5ed746b8-94a4-4481-ac0e-bbb9daf84830,DISK], DatanodeInfoWithStorage[127.0.0.1:40513,DS-f78ed7cd-a2ba-42ee-a67b-d0f128d4ba15,DISK], DatanodeInfoWithStorage[127.0.0.1:39611,DS-e763b779-7435-4b80-bd40-4612ae3dad36,DISK], DatanodeInfoWithStorage[127.0.0.1:35467,DS-b96c5813-d0b2-494c-bad3-e9fe9cb862f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43391,DS-23689b70-2c32-499f-8a86-ad652593bca5,DISK], DatanodeInfoWithStorage[127.0.0.1:40265,DS-f61832de-104b-4c04-b31c-eaeb294e8733,DISK], DatanodeInfoWithStorage[127.0.0.1:45196,DS-9917c132-42c3-4309-8e74-509eec0bebac,DISK], DatanodeInfoWithStorage[127.0.0.1:36276,DS-5ac46c33-9fc4-4413-9da3-1711cc266fdc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-793771251-172.17.0.12-1595317990902:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46199,DS-5ed746b8-94a4-4481-ac0e-bbb9daf84830,DISK], DatanodeInfoWithStorage[127.0.0.1:40513,DS-f78ed7cd-a2ba-42ee-a67b-d0f128d4ba15,DISK], DatanodeInfoWithStorage[127.0.0.1:39611,DS-e763b779-7435-4b80-bd40-4612ae3dad36,DISK], DatanodeInfoWithStorage[127.0.0.1:35467,DS-b96c5813-d0b2-494c-bad3-e9fe9cb862f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43391,DS-23689b70-2c32-499f-8a86-ad652593bca5,DISK], DatanodeInfoWithStorage[127.0.0.1:40265,DS-f61832de-104b-4c04-b31c-eaeb294e8733,DISK], DatanodeInfoWithStorage[127.0.0.1:45196,DS-9917c132-42c3-4309-8e74-509eec0bebac,DISK], DatanodeInfoWithStorage[127.0.0.1:36276,DS-5ac46c33-9fc4-4413-9da3-1711cc266fdc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-829778806-172.17.0.12-1595318037423:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45272,DS-36d93dad-eb47-4dc4-a754-d7d9ccfb4c78,DISK], DatanodeInfoWithStorage[127.0.0.1:41350,DS-d117c9ee-dc1f-4ff3-811c-49ef82c6d430,DISK], DatanodeInfoWithStorage[127.0.0.1:45973,DS-393f6875-a077-43e7-869c-f0d4e5a051a5,DISK], DatanodeInfoWithStorage[127.0.0.1:45365,DS-9b832540-2da7-4dce-8319-6565979b168a,DISK], DatanodeInfoWithStorage[127.0.0.1:33052,DS-32fbef80-ee1a-46d7-8718-0d33e0a0b350,DISK], DatanodeInfoWithStorage[127.0.0.1:37513,DS-2c23d3d3-a18c-43da-b447-6411d3f4fb69,DISK], DatanodeInfoWithStorage[127.0.0.1:42023,DS-ef5925cd-9c77-491d-96bc-3f23968d3867,DISK], DatanodeInfoWithStorage[127.0.0.1:38106,DS-9d288b0b-e475-4b49-b3b7-3b1624055422,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-829778806-172.17.0.12-1595318037423:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45272,DS-36d93dad-eb47-4dc4-a754-d7d9ccfb4c78,DISK], DatanodeInfoWithStorage[127.0.0.1:41350,DS-d117c9ee-dc1f-4ff3-811c-49ef82c6d430,DISK], DatanodeInfoWithStorage[127.0.0.1:45973,DS-393f6875-a077-43e7-869c-f0d4e5a051a5,DISK], DatanodeInfoWithStorage[127.0.0.1:45365,DS-9b832540-2da7-4dce-8319-6565979b168a,DISK], DatanodeInfoWithStorage[127.0.0.1:33052,DS-32fbef80-ee1a-46d7-8718-0d33e0a0b350,DISK], DatanodeInfoWithStorage[127.0.0.1:37513,DS-2c23d3d3-a18c-43da-b447-6411d3f4fb69,DISK], DatanodeInfoWithStorage[127.0.0.1:42023,DS-ef5925cd-9c77-491d-96bc-3f23968d3867,DISK], DatanodeInfoWithStorage[127.0.0.1:38106,DS-9d288b0b-e475-4b49-b3b7-3b1624055422,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-994806278-172.17.0.12-1595318113976:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36797,DS-d60f8e52-b609-4551-9b58-db30a09c4782,DISK], DatanodeInfoWithStorage[127.0.0.1:39884,DS-77f29be4-8401-43a7-8980-78c594f19be9,DISK], DatanodeInfoWithStorage[127.0.0.1:38151,DS-35dc55cd-124e-4b55-8414-6617437f5b9a,DISK], DatanodeInfoWithStorage[127.0.0.1:35649,DS-2baebfca-550d-41de-aa73-9c27c56c7b68,DISK], DatanodeInfoWithStorage[127.0.0.1:40921,DS-990860bf-a7d8-477e-b6bb-a38c54458337,DISK], DatanodeInfoWithStorage[127.0.0.1:34474,DS-6f2776e2-7e27-40d3-8355-630df9fc4ee2,DISK], DatanodeInfoWithStorage[127.0.0.1:41096,DS-801b80fd-7fb1-4cd9-a2e6-a6bbe07506d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42457,DS-6d0ebd9e-e77a-4a34-8814-24a0b3aed8f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-994806278-172.17.0.12-1595318113976:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36797,DS-d60f8e52-b609-4551-9b58-db30a09c4782,DISK], DatanodeInfoWithStorage[127.0.0.1:39884,DS-77f29be4-8401-43a7-8980-78c594f19be9,DISK], DatanodeInfoWithStorage[127.0.0.1:38151,DS-35dc55cd-124e-4b55-8414-6617437f5b9a,DISK], DatanodeInfoWithStorage[127.0.0.1:35649,DS-2baebfca-550d-41de-aa73-9c27c56c7b68,DISK], DatanodeInfoWithStorage[127.0.0.1:40921,DS-990860bf-a7d8-477e-b6bb-a38c54458337,DISK], DatanodeInfoWithStorage[127.0.0.1:34474,DS-6f2776e2-7e27-40d3-8355-630df9fc4ee2,DISK], DatanodeInfoWithStorage[127.0.0.1:41096,DS-801b80fd-7fb1-4cd9-a2e6-a6bbe07506d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42457,DS-6d0ebd9e-e77a-4a34-8814-24a0b3aed8f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-831455376-172.17.0.12-1595318148430:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36826,DS-f9fa1f97-de80-497c-9637-281e7f40b39b,DISK], DatanodeInfoWithStorage[127.0.0.1:40043,DS-369f389e-e017-40d4-b23b-907a3815541c,DISK], DatanodeInfoWithStorage[127.0.0.1:33911,DS-416338bf-69af-40a5-b727-98bd240f5d3f,DISK], DatanodeInfoWithStorage[127.0.0.1:33727,DS-dff609e8-87e6-4e61-972f-c9b71ce33af2,DISK], DatanodeInfoWithStorage[127.0.0.1:37882,DS-b77686f3-c295-4964-90bc-794829f31887,DISK], DatanodeInfoWithStorage[127.0.0.1:43010,DS-b3afb916-d4a3-4310-9049-b5c558282057,DISK], DatanodeInfoWithStorage[127.0.0.1:43838,DS-d50df608-62d5-4ae5-b1cd-679042a5ded6,DISK], DatanodeInfoWithStorage[127.0.0.1:38188,DS-34dfae79-3cb4-43c7-b33b-725f40fd5c0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-831455376-172.17.0.12-1595318148430:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36826,DS-f9fa1f97-de80-497c-9637-281e7f40b39b,DISK], DatanodeInfoWithStorage[127.0.0.1:40043,DS-369f389e-e017-40d4-b23b-907a3815541c,DISK], DatanodeInfoWithStorage[127.0.0.1:33911,DS-416338bf-69af-40a5-b727-98bd240f5d3f,DISK], DatanodeInfoWithStorage[127.0.0.1:33727,DS-dff609e8-87e6-4e61-972f-c9b71ce33af2,DISK], DatanodeInfoWithStorage[127.0.0.1:37882,DS-b77686f3-c295-4964-90bc-794829f31887,DISK], DatanodeInfoWithStorage[127.0.0.1:43010,DS-b3afb916-d4a3-4310-9049-b5c558282057,DISK], DatanodeInfoWithStorage[127.0.0.1:43838,DS-d50df608-62d5-4ae5-b1cd-679042a5ded6,DISK], DatanodeInfoWithStorage[127.0.0.1:38188,DS-34dfae79-3cb4-43c7-b33b-725f40fd5c0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-314105647-172.17.0.12-1595318538378:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40575,DS-395dca24-8fcc-44c9-8b08-f9f7a80ffd36,DISK], DatanodeInfoWithStorage[127.0.0.1:40953,DS-9530b542-b1eb-46a6-928d-0941a7f6cb9c,DISK], DatanodeInfoWithStorage[127.0.0.1:36700,DS-4dcd6af6-9a20-4918-b636-79954ae15c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:46625,DS-789fa3e0-0f59-4d27-8c49-3b1715c5d63c,DISK], DatanodeInfoWithStorage[127.0.0.1:41030,DS-0cc2a066-8038-4f51-9c28-b16251727b48,DISK], DatanodeInfoWithStorage[127.0.0.1:45057,DS-8391c0f4-c5fb-4a85-8cdf-0fdcd2654ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:45137,DS-dc8ff50f-c2f2-467f-a41f-69e8d3073716,DISK], DatanodeInfoWithStorage[127.0.0.1:42602,DS-3dccd7bc-2326-4943-a0ee-85d9d62c772d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-314105647-172.17.0.12-1595318538378:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40575,DS-395dca24-8fcc-44c9-8b08-f9f7a80ffd36,DISK], DatanodeInfoWithStorage[127.0.0.1:40953,DS-9530b542-b1eb-46a6-928d-0941a7f6cb9c,DISK], DatanodeInfoWithStorage[127.0.0.1:36700,DS-4dcd6af6-9a20-4918-b636-79954ae15c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:46625,DS-789fa3e0-0f59-4d27-8c49-3b1715c5d63c,DISK], DatanodeInfoWithStorage[127.0.0.1:41030,DS-0cc2a066-8038-4f51-9c28-b16251727b48,DISK], DatanodeInfoWithStorage[127.0.0.1:45057,DS-8391c0f4-c5fb-4a85-8cdf-0fdcd2654ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:45137,DS-dc8ff50f-c2f2-467f-a41f-69e8d3073716,DISK], DatanodeInfoWithStorage[127.0.0.1:42602,DS-3dccd7bc-2326-4943-a0ee-85d9d62c772d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-41171582-172.17.0.12-1595318652253:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39143,DS-3a0d7632-6dab-47ee-af46-a6649fdb58b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44989,DS-6a867295-ed07-44cf-8d2a-a0e5dc421a15,DISK], DatanodeInfoWithStorage[127.0.0.1:36627,DS-4e5e9ae6-4241-4022-90d9-7062febb05ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42596,DS-2305c882-345b-4f4d-a72e-f4add0ce7cdb,DISK], DatanodeInfoWithStorage[127.0.0.1:33067,DS-1d7367ee-d766-402c-bfde-7737279cdfb1,DISK], DatanodeInfoWithStorage[127.0.0.1:34021,DS-f791f9c4-7510-4e93-a1a6-ea1a795264b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40280,DS-101c3f5c-99d6-4911-9c47-03a484717100,DISK], DatanodeInfoWithStorage[127.0.0.1:41636,DS-d7a49682-c8fc-46cc-8213-708cba149842,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-41171582-172.17.0.12-1595318652253:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39143,DS-3a0d7632-6dab-47ee-af46-a6649fdb58b1,DISK], DatanodeInfoWithStorage[127.0.0.1:44989,DS-6a867295-ed07-44cf-8d2a-a0e5dc421a15,DISK], DatanodeInfoWithStorage[127.0.0.1:36627,DS-4e5e9ae6-4241-4022-90d9-7062febb05ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42596,DS-2305c882-345b-4f4d-a72e-f4add0ce7cdb,DISK], DatanodeInfoWithStorage[127.0.0.1:33067,DS-1d7367ee-d766-402c-bfde-7737279cdfb1,DISK], DatanodeInfoWithStorage[127.0.0.1:34021,DS-f791f9c4-7510-4e93-a1a6-ea1a795264b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40280,DS-101c3f5c-99d6-4911-9c47-03a484717100,DISK], DatanodeInfoWithStorage[127.0.0.1:41636,DS-d7a49682-c8fc-46cc-8213-708cba149842,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-174769222-172.17.0.12-1595319153504:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32899,DS-4abffbb5-768e-4631-8e04-388adbd99c57,DISK], DatanodeInfoWithStorage[127.0.0.1:42199,DS-1ed0def4-d86f-425e-97a0-4fc9681bb0f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43864,DS-818bf159-5dad-4957-ba2c-a1edd6694e91,DISK], DatanodeInfoWithStorage[127.0.0.1:46847,DS-e01895f6-1e48-424b-b3da-fd0c4491b47f,DISK], DatanodeInfoWithStorage[127.0.0.1:44725,DS-e68c0987-ed38-4609-bafa-84178671084a,DISK], DatanodeInfoWithStorage[127.0.0.1:40829,DS-146d2588-f066-439f-ad6f-f7ca49b5257e,DISK], DatanodeInfoWithStorage[127.0.0.1:38096,DS-0a7ed207-0aa6-4f60-bf58-1bc1f629e3ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41298,DS-895b923b-6448-4e63-aad4-709fcff903dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-174769222-172.17.0.12-1595319153504:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32899,DS-4abffbb5-768e-4631-8e04-388adbd99c57,DISK], DatanodeInfoWithStorage[127.0.0.1:42199,DS-1ed0def4-d86f-425e-97a0-4fc9681bb0f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43864,DS-818bf159-5dad-4957-ba2c-a1edd6694e91,DISK], DatanodeInfoWithStorage[127.0.0.1:46847,DS-e01895f6-1e48-424b-b3da-fd0c4491b47f,DISK], DatanodeInfoWithStorage[127.0.0.1:44725,DS-e68c0987-ed38-4609-bafa-84178671084a,DISK], DatanodeInfoWithStorage[127.0.0.1:40829,DS-146d2588-f066-439f-ad6f-f7ca49b5257e,DISK], DatanodeInfoWithStorage[127.0.0.1:38096,DS-0a7ed207-0aa6-4f60-bf58-1bc1f629e3ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41298,DS-895b923b-6448-4e63-aad4-709fcff903dd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1190335125-172.17.0.12-1595319658702:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42864,DS-71e5328b-833d-4536-b9ac-6b48833fbc59,DISK], DatanodeInfoWithStorage[127.0.0.1:41183,DS-bf71f8a4-2989-4507-ba9e-2c51158c15c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34948,DS-a37216de-a37b-45be-a867-4320da30ba4c,DISK], DatanodeInfoWithStorage[127.0.0.1:45248,DS-13f102ea-e9ce-43c5-bcd0-cdce8d0eaf97,DISK], DatanodeInfoWithStorage[127.0.0.1:46497,DS-8259f6da-e54a-4608-8eaf-f7888e882e47,DISK], DatanodeInfoWithStorage[127.0.0.1:39263,DS-3ddcd2b3-de38-4a7c-8848-adf57d5300ec,DISK], DatanodeInfoWithStorage[127.0.0.1:43163,DS-90822717-e6b5-47d8-bf90-c8572697d501,DISK], DatanodeInfoWithStorage[127.0.0.1:44773,DS-ec0318d1-9243-49a0-b32b-172475fed075,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1190335125-172.17.0.12-1595319658702:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42864,DS-71e5328b-833d-4536-b9ac-6b48833fbc59,DISK], DatanodeInfoWithStorage[127.0.0.1:41183,DS-bf71f8a4-2989-4507-ba9e-2c51158c15c3,DISK], DatanodeInfoWithStorage[127.0.0.1:34948,DS-a37216de-a37b-45be-a867-4320da30ba4c,DISK], DatanodeInfoWithStorage[127.0.0.1:45248,DS-13f102ea-e9ce-43c5-bcd0-cdce8d0eaf97,DISK], DatanodeInfoWithStorage[127.0.0.1:46497,DS-8259f6da-e54a-4608-8eaf-f7888e882e47,DISK], DatanodeInfoWithStorage[127.0.0.1:39263,DS-3ddcd2b3-de38-4a7c-8848-adf57d5300ec,DISK], DatanodeInfoWithStorage[127.0.0.1:43163,DS-90822717-e6b5-47d8-bf90-c8572697d501,DISK], DatanodeInfoWithStorage[127.0.0.1:44773,DS-ec0318d1-9243-49a0-b32b-172475fed075,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1184153182-172.17.0.12-1595319699701:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41556,DS-1e74be02-08de-4458-87e1-4f5d503f8938,DISK], DatanodeInfoWithStorage[127.0.0.1:33854,DS-5f7016e8-7b87-46fb-a473-506142867f16,DISK], DatanodeInfoWithStorage[127.0.0.1:44043,DS-70174b2a-5d5f-47f8-ad6f-4873d62bbfeb,DISK], DatanodeInfoWithStorage[127.0.0.1:34942,DS-2009cfbf-0d77-41fc-8bb4-7b7c2f34b52a,DISK], DatanodeInfoWithStorage[127.0.0.1:35084,DS-79c80d4b-e79e-4355-bd1e-6f99103e1d41,DISK], DatanodeInfoWithStorage[127.0.0.1:34031,DS-af6c06da-a1e3-4115-98e3-e283fd4f29ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36777,DS-8fa0cefd-57e2-4dfc-a090-828abeb686bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35364,DS-55bf581a-0cfa-4c3f-9f73-bd0b3e23829c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1184153182-172.17.0.12-1595319699701:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41556,DS-1e74be02-08de-4458-87e1-4f5d503f8938,DISK], DatanodeInfoWithStorage[127.0.0.1:33854,DS-5f7016e8-7b87-46fb-a473-506142867f16,DISK], DatanodeInfoWithStorage[127.0.0.1:44043,DS-70174b2a-5d5f-47f8-ad6f-4873d62bbfeb,DISK], DatanodeInfoWithStorage[127.0.0.1:34942,DS-2009cfbf-0d77-41fc-8bb4-7b7c2f34b52a,DISK], DatanodeInfoWithStorage[127.0.0.1:35084,DS-79c80d4b-e79e-4355-bd1e-6f99103e1d41,DISK], DatanodeInfoWithStorage[127.0.0.1:34031,DS-af6c06da-a1e3-4115-98e3-e283fd4f29ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36777,DS-8fa0cefd-57e2-4dfc-a090-828abeb686bc,DISK], DatanodeInfoWithStorage[127.0.0.1:35364,DS-55bf581a-0cfa-4c3f-9f73-bd0b3e23829c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1464437285-172.17.0.12-1595320187010:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36954,DS-684ec99c-106d-44b3-ab8d-afde58126239,DISK], DatanodeInfoWithStorage[127.0.0.1:38883,DS-9e59a3fb-b488-449c-acb6-8034937a5304,DISK], DatanodeInfoWithStorage[127.0.0.1:37280,DS-1d3e34e7-b486-4d42-aca7-a984888f1211,DISK], DatanodeInfoWithStorage[127.0.0.1:38953,DS-2dba64bc-bda1-45e8-a636-715fb8ec5f6b,DISK], DatanodeInfoWithStorage[127.0.0.1:36001,DS-443c1944-27c4-409f-a762-46652811084f,DISK], DatanodeInfoWithStorage[127.0.0.1:41286,DS-cefe0364-56e1-4245-aaa2-432943a55471,DISK], DatanodeInfoWithStorage[127.0.0.1:40290,DS-32f7b190-c0ec-45f3-a269-1653ebcc5338,DISK], DatanodeInfoWithStorage[127.0.0.1:46609,DS-c7ae64df-856b-47e7-949d-e654ad60f6d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1464437285-172.17.0.12-1595320187010:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36954,DS-684ec99c-106d-44b3-ab8d-afde58126239,DISK], DatanodeInfoWithStorage[127.0.0.1:38883,DS-9e59a3fb-b488-449c-acb6-8034937a5304,DISK], DatanodeInfoWithStorage[127.0.0.1:37280,DS-1d3e34e7-b486-4d42-aca7-a984888f1211,DISK], DatanodeInfoWithStorage[127.0.0.1:38953,DS-2dba64bc-bda1-45e8-a636-715fb8ec5f6b,DISK], DatanodeInfoWithStorage[127.0.0.1:36001,DS-443c1944-27c4-409f-a762-46652811084f,DISK], DatanodeInfoWithStorage[127.0.0.1:41286,DS-cefe0364-56e1-4245-aaa2-432943a55471,DISK], DatanodeInfoWithStorage[127.0.0.1:40290,DS-32f7b190-c0ec-45f3-a269-1653ebcc5338,DISK], DatanodeInfoWithStorage[127.0.0.1:46609,DS-c7ae64df-856b-47e7-949d-e654ad60f6d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1442679139-172.17.0.12-1595320493023:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41629,DS-24618e63-9ec8-44c3-837c-c31718d8a3e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38299,DS-71bf0442-fbc0-4dfb-bd71-343e55c7d25d,DISK], DatanodeInfoWithStorage[127.0.0.1:37268,DS-02df4f62-36e0-4f47-b202-0f43b6d35953,DISK], DatanodeInfoWithStorage[127.0.0.1:40234,DS-650a357d-60ff-484f-8c09-8a96d6556f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:44747,DS-1623d252-d98c-49b7-ab39-9de38e9bb219,DISK], DatanodeInfoWithStorage[127.0.0.1:43756,DS-a6e0e82b-fedd-44ca-aff6-7a6cd5bb222b,DISK], DatanodeInfoWithStorage[127.0.0.1:34434,DS-daf097ce-09a1-475c-a34d-ae64bf9e6ab1,DISK], DatanodeInfoWithStorage[127.0.0.1:37537,DS-39b92049-77fa-4d6c-acc4-1cb65b1dd18c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1442679139-172.17.0.12-1595320493023:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41629,DS-24618e63-9ec8-44c3-837c-c31718d8a3e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38299,DS-71bf0442-fbc0-4dfb-bd71-343e55c7d25d,DISK], DatanodeInfoWithStorage[127.0.0.1:37268,DS-02df4f62-36e0-4f47-b202-0f43b6d35953,DISK], DatanodeInfoWithStorage[127.0.0.1:40234,DS-650a357d-60ff-484f-8c09-8a96d6556f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:44747,DS-1623d252-d98c-49b7-ab39-9de38e9bb219,DISK], DatanodeInfoWithStorage[127.0.0.1:43756,DS-a6e0e82b-fedd-44ca-aff6-7a6cd5bb222b,DISK], DatanodeInfoWithStorage[127.0.0.1:34434,DS-daf097ce-09a1-475c-a34d-ae64bf9e6ab1,DISK], DatanodeInfoWithStorage[127.0.0.1:37537,DS-39b92049-77fa-4d6c-acc4-1cb65b1dd18c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1192591342-172.17.0.12-1595320619763:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38387,DS-9f6327b2-d88d-4ca4-a2e8-61534d63e212,DISK], DatanodeInfoWithStorage[127.0.0.1:37830,DS-5fb6697c-24a2-4076-9839-3b3f0efc6ba3,DISK], DatanodeInfoWithStorage[127.0.0.1:34152,DS-c4c21138-29ed-4b61-b9f3-464f4f8d1975,DISK], DatanodeInfoWithStorage[127.0.0.1:40180,DS-ce550a56-49f4-4a7f-94b8-ad19e38a4cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:40715,DS-bb108de2-812e-40b8-83b2-056e9dfb251a,DISK], DatanodeInfoWithStorage[127.0.0.1:45419,DS-5ccd31c1-9d4f-4bca-bd95-443e9f99d5ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41142,DS-a47abc3f-ab30-4b7a-bece-4ea3f09213c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35490,DS-211f0903-b881-45c6-93cc-c78843819ed0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1192591342-172.17.0.12-1595320619763:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38387,DS-9f6327b2-d88d-4ca4-a2e8-61534d63e212,DISK], DatanodeInfoWithStorage[127.0.0.1:37830,DS-5fb6697c-24a2-4076-9839-3b3f0efc6ba3,DISK], DatanodeInfoWithStorage[127.0.0.1:34152,DS-c4c21138-29ed-4b61-b9f3-464f4f8d1975,DISK], DatanodeInfoWithStorage[127.0.0.1:40180,DS-ce550a56-49f4-4a7f-94b8-ad19e38a4cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:40715,DS-bb108de2-812e-40b8-83b2-056e9dfb251a,DISK], DatanodeInfoWithStorage[127.0.0.1:45419,DS-5ccd31c1-9d4f-4bca-bd95-443e9f99d5ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41142,DS-a47abc3f-ab30-4b7a-bece-4ea3f09213c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35490,DS-211f0903-b881-45c6-93cc-c78843819ed0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1457429436-172.17.0.12-1595320786112:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34356,DS-51e72fd9-d678-491d-bd21-ab9cb1dbad4d,DISK], DatanodeInfoWithStorage[127.0.0.1:32826,DS-1b2ed8a9-8697-4694-b278-76716bf607a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36236,DS-1cd17b6e-4918-480e-b39b-114f808a296b,DISK], DatanodeInfoWithStorage[127.0.0.1:33300,DS-d66ae4d6-77ba-46f3-ab62-f4ff7e745c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:41210,DS-9e1ccbf3-0d7b-44d6-a882-33ff9e664ab0,DISK], DatanodeInfoWithStorage[127.0.0.1:38068,DS-6fe2afe3-1de5-4c5f-a9c9-ccd8440f561b,DISK], DatanodeInfoWithStorage[127.0.0.1:36021,DS-a3d1d0bc-8134-4742-a3b8-9963bba47d2e,DISK], DatanodeInfoWithStorage[127.0.0.1:38467,DS-d45092ea-534f-469e-b46c-db5c02f975a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1457429436-172.17.0.12-1595320786112:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34356,DS-51e72fd9-d678-491d-bd21-ab9cb1dbad4d,DISK], DatanodeInfoWithStorage[127.0.0.1:32826,DS-1b2ed8a9-8697-4694-b278-76716bf607a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36236,DS-1cd17b6e-4918-480e-b39b-114f808a296b,DISK], DatanodeInfoWithStorage[127.0.0.1:33300,DS-d66ae4d6-77ba-46f3-ab62-f4ff7e745c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:41210,DS-9e1ccbf3-0d7b-44d6-a882-33ff9e664ab0,DISK], DatanodeInfoWithStorage[127.0.0.1:38068,DS-6fe2afe3-1de5-4c5f-a9c9-ccd8440f561b,DISK], DatanodeInfoWithStorage[127.0.0.1:36021,DS-a3d1d0bc-8134-4742-a3b8-9963bba47d2e,DISK], DatanodeInfoWithStorage[127.0.0.1:38467,DS-d45092ea-534f-469e-b46c-db5c02f975a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-568803689-172.17.0.12-1595320825489:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45760,DS-e96ddd26-0be1-4b2a-89df-c9c689bd4582,DISK], DatanodeInfoWithStorage[127.0.0.1:38836,DS-ad54196c-b560-45fe-8f2f-6b743ae64999,DISK], DatanodeInfoWithStorage[127.0.0.1:44398,DS-81ac030c-458e-4b2d-ac1d-1c4f6c6fc224,DISK], DatanodeInfoWithStorage[127.0.0.1:33419,DS-7c1235d5-8c54-498c-8ea2-84dfcbda1cad,DISK], DatanodeInfoWithStorage[127.0.0.1:43177,DS-c71f1008-6673-4b65-b7dd-df228874243d,DISK], DatanodeInfoWithStorage[127.0.0.1:42920,DS-694431bf-63c8-401a-91e2-31caf18fd957,DISK], DatanodeInfoWithStorage[127.0.0.1:36427,DS-42f5910a-cd45-49e9-bffd-2fbf5eaa6755,DISK], DatanodeInfoWithStorage[127.0.0.1:42212,DS-1c092f83-e642-4592-8b8b-432d63b0755a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-568803689-172.17.0.12-1595320825489:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45760,DS-e96ddd26-0be1-4b2a-89df-c9c689bd4582,DISK], DatanodeInfoWithStorage[127.0.0.1:38836,DS-ad54196c-b560-45fe-8f2f-6b743ae64999,DISK], DatanodeInfoWithStorage[127.0.0.1:44398,DS-81ac030c-458e-4b2d-ac1d-1c4f6c6fc224,DISK], DatanodeInfoWithStorage[127.0.0.1:33419,DS-7c1235d5-8c54-498c-8ea2-84dfcbda1cad,DISK], DatanodeInfoWithStorage[127.0.0.1:43177,DS-c71f1008-6673-4b65-b7dd-df228874243d,DISK], DatanodeInfoWithStorage[127.0.0.1:42920,DS-694431bf-63c8-401a-91e2-31caf18fd957,DISK], DatanodeInfoWithStorage[127.0.0.1:36427,DS-42f5910a-cd45-49e9-bffd-2fbf5eaa6755,DISK], DatanodeInfoWithStorage[127.0.0.1:42212,DS-1c092f83-e642-4592-8b8b-432d63b0755a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2032237593-172.17.0.12-1595321161916:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34607,DS-be3ae336-95a3-47ab-bfbc-397e3201aec0,DISK], DatanodeInfoWithStorage[127.0.0.1:37328,DS-9f2f0524-82d8-496d-b021-e6f3475e5b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:44151,DS-13857a67-183b-4ee9-bc48-6fa6605c6eba,DISK], DatanodeInfoWithStorage[127.0.0.1:38835,DS-d072ef9b-88bc-4513-8263-14bf146986b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44735,DS-3159ce95-19bb-4d3a-aea8-f7fd10a1eb88,DISK], DatanodeInfoWithStorage[127.0.0.1:34829,DS-86bcab59-0c9f-40b9-8220-e580fa9d0761,DISK], DatanodeInfoWithStorage[127.0.0.1:43494,DS-a1f6a9df-ef24-4b67-8840-3b7dcba6f9b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43438,DS-31500c3f-eff9-4cc7-bee9-e66331f4327b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2032237593-172.17.0.12-1595321161916:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34607,DS-be3ae336-95a3-47ab-bfbc-397e3201aec0,DISK], DatanodeInfoWithStorage[127.0.0.1:37328,DS-9f2f0524-82d8-496d-b021-e6f3475e5b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:44151,DS-13857a67-183b-4ee9-bc48-6fa6605c6eba,DISK], DatanodeInfoWithStorage[127.0.0.1:38835,DS-d072ef9b-88bc-4513-8263-14bf146986b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44735,DS-3159ce95-19bb-4d3a-aea8-f7fd10a1eb88,DISK], DatanodeInfoWithStorage[127.0.0.1:34829,DS-86bcab59-0c9f-40b9-8220-e580fa9d0761,DISK], DatanodeInfoWithStorage[127.0.0.1:43494,DS-a1f6a9df-ef24-4b67-8840-3b7dcba6f9b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43438,DS-31500c3f-eff9-4cc7-bee9-e66331f4327b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1381697171-172.17.0.12-1595321607779:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41419,DS-5897a98b-29ae-4d09-bbb4-f5b9044eacf3,DISK], DatanodeInfoWithStorage[127.0.0.1:36558,DS-98750fe6-7aca-4954-97f6-ad89373bdde0,DISK], DatanodeInfoWithStorage[127.0.0.1:35348,DS-4c7131c2-70cf-417e-8184-8ca48ae01b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:36248,DS-758b01b3-b609-4d33-bb69-e98b7d065ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:44912,DS-cbe51920-6cfb-42ab-a99b-b0b6fc628e99,DISK], DatanodeInfoWithStorage[127.0.0.1:38454,DS-d19b47f9-b3ed-4825-9c5a-21a3e20ae032,DISK], DatanodeInfoWithStorage[127.0.0.1:41990,DS-d7cfac74-7717-47ee-a4ed-b73742708ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:35720,DS-c76784ae-a8d6-404b-b9ca-f90edd92242a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1381697171-172.17.0.12-1595321607779:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41419,DS-5897a98b-29ae-4d09-bbb4-f5b9044eacf3,DISK], DatanodeInfoWithStorage[127.0.0.1:36558,DS-98750fe6-7aca-4954-97f6-ad89373bdde0,DISK], DatanodeInfoWithStorage[127.0.0.1:35348,DS-4c7131c2-70cf-417e-8184-8ca48ae01b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:36248,DS-758b01b3-b609-4d33-bb69-e98b7d065ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:44912,DS-cbe51920-6cfb-42ab-a99b-b0b6fc628e99,DISK], DatanodeInfoWithStorage[127.0.0.1:38454,DS-d19b47f9-b3ed-4825-9c5a-21a3e20ae032,DISK], DatanodeInfoWithStorage[127.0.0.1:41990,DS-d7cfac74-7717-47ee-a4ed-b73742708ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:35720,DS-c76784ae-a8d6-404b-b9ca-f90edd92242a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-70447571-172.17.0.12-1595322159292:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44138,DS-990fc357-d2d1-419f-a1d3-e361b873357f,DISK], DatanodeInfoWithStorage[127.0.0.1:44589,DS-c39130ea-e47e-47f5-9e18-9d141c7829ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42885,DS-1f49fda0-6643-4c83-9f41-7cb7888fce5a,DISK], DatanodeInfoWithStorage[127.0.0.1:37996,DS-47282acd-c004-4d09-9aef-ee80d2ec7c3c,DISK], DatanodeInfoWithStorage[127.0.0.1:37112,DS-cae0bf30-36a0-47ae-b418-80ab39af12b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42319,DS-4f4bbf4e-ffe2-4cee-a418-cf73ed96e48b,DISK], DatanodeInfoWithStorage[127.0.0.1:34549,DS-bcfb7224-a168-4751-9748-18bebd195757,DISK], DatanodeInfoWithStorage[127.0.0.1:41229,DS-68d44746-e3ef-4215-b72b-7c9d6d50d0fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-70447571-172.17.0.12-1595322159292:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44138,DS-990fc357-d2d1-419f-a1d3-e361b873357f,DISK], DatanodeInfoWithStorage[127.0.0.1:44589,DS-c39130ea-e47e-47f5-9e18-9d141c7829ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42885,DS-1f49fda0-6643-4c83-9f41-7cb7888fce5a,DISK], DatanodeInfoWithStorage[127.0.0.1:37996,DS-47282acd-c004-4d09-9aef-ee80d2ec7c3c,DISK], DatanodeInfoWithStorage[127.0.0.1:37112,DS-cae0bf30-36a0-47ae-b418-80ab39af12b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42319,DS-4f4bbf4e-ffe2-4cee-a418-cf73ed96e48b,DISK], DatanodeInfoWithStorage[127.0.0.1:34549,DS-bcfb7224-a168-4751-9748-18bebd195757,DISK], DatanodeInfoWithStorage[127.0.0.1:41229,DS-68d44746-e3ef-4215-b72b-7c9d6d50d0fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-377753333-172.17.0.12-1595322204592:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43535,DS-abf364e2-c638-4495-8918-703767ac806c,DISK], DatanodeInfoWithStorage[127.0.0.1:39195,DS-4b23be0d-97c6-4638-8575-638deb651af5,DISK], DatanodeInfoWithStorage[127.0.0.1:36394,DS-4c56b75d-ce58-448a-b029-b0c8f48fe2a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34869,DS-aa9897ff-2268-481d-99c2-c5b422b39b48,DISK], DatanodeInfoWithStorage[127.0.0.1:40975,DS-8d18368d-8608-44d5-8ace-580915bea5bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39544,DS-9b1029f7-ddc6-4e8f-b964-8e7feb172316,DISK], DatanodeInfoWithStorage[127.0.0.1:40235,DS-af100828-788f-4bab-aad4-ab01d8b88a93,DISK], DatanodeInfoWithStorage[127.0.0.1:42977,DS-e4f14da0-4613-4557-aed3-d135319e7cea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-377753333-172.17.0.12-1595322204592:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43535,DS-abf364e2-c638-4495-8918-703767ac806c,DISK], DatanodeInfoWithStorage[127.0.0.1:39195,DS-4b23be0d-97c6-4638-8575-638deb651af5,DISK], DatanodeInfoWithStorage[127.0.0.1:36394,DS-4c56b75d-ce58-448a-b029-b0c8f48fe2a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34869,DS-aa9897ff-2268-481d-99c2-c5b422b39b48,DISK], DatanodeInfoWithStorage[127.0.0.1:40975,DS-8d18368d-8608-44d5-8ace-580915bea5bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39544,DS-9b1029f7-ddc6-4e8f-b964-8e7feb172316,DISK], DatanodeInfoWithStorage[127.0.0.1:40235,DS-af100828-788f-4bab-aad4-ab01d8b88a93,DISK], DatanodeInfoWithStorage[127.0.0.1:42977,DS-e4f14da0-4613-4557-aed3-d135319e7cea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1173017962-172.17.0.12-1595322295551:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32839,DS-86b3ced7-5c0e-4ea6-9b19-cb563fd70e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:45402,DS-b5955568-69cf-4eb1-a13c-448bd4bcee6d,DISK], DatanodeInfoWithStorage[127.0.0.1:42302,DS-19e4db2a-698d-483c-aabd-808eb0354dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:38080,DS-2f6f5d5b-89e2-4758-b3a1-a8dd64f71869,DISK], DatanodeInfoWithStorage[127.0.0.1:37138,DS-d283bda8-5390-4e6a-aba8-a35b880bdf75,DISK], DatanodeInfoWithStorage[127.0.0.1:40776,DS-ffb3b2ed-781d-4b49-a715-513ccf5fb8e5,DISK], DatanodeInfoWithStorage[127.0.0.1:33620,DS-e56738a3-cb3a-4d5b-a65e-1c13a59fa52c,DISK], DatanodeInfoWithStorage[127.0.0.1:44139,DS-c5a9451a-e02e-410b-b287-a7e219cec87b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1173017962-172.17.0.12-1595322295551:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32839,DS-86b3ced7-5c0e-4ea6-9b19-cb563fd70e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:45402,DS-b5955568-69cf-4eb1-a13c-448bd4bcee6d,DISK], DatanodeInfoWithStorage[127.0.0.1:42302,DS-19e4db2a-698d-483c-aabd-808eb0354dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:38080,DS-2f6f5d5b-89e2-4758-b3a1-a8dd64f71869,DISK], DatanodeInfoWithStorage[127.0.0.1:37138,DS-d283bda8-5390-4e6a-aba8-a35b880bdf75,DISK], DatanodeInfoWithStorage[127.0.0.1:40776,DS-ffb3b2ed-781d-4b49-a715-513ccf5fb8e5,DISK], DatanodeInfoWithStorage[127.0.0.1:33620,DS-e56738a3-cb3a-4d5b-a65e-1c13a59fa52c,DISK], DatanodeInfoWithStorage[127.0.0.1:44139,DS-c5a9451a-e02e-410b-b287-a7e219cec87b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.lock.detailed-metrics.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1828148663-172.17.0.12-1595322750666:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43339,DS-473c4534-19b5-4f3a-a74a-0725c326fe3b,DISK], DatanodeInfoWithStorage[127.0.0.1:39591,DS-10c28cd5-1730-4ff4-949d-5c3a95395783,DISK], DatanodeInfoWithStorage[127.0.0.1:39538,DS-2eff6852-2736-40c0-81a9-cee4fded7dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:43527,DS-07b7337d-54f1-4c22-8e5c-c6b54c01c2b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37893,DS-2cdeffbe-d03a-43e3-b724-c6f9b57de684,DISK], DatanodeInfoWithStorage[127.0.0.1:39544,DS-2982de23-70bd-4c3e-9a76-cf4299ce2d09,DISK], DatanodeInfoWithStorage[127.0.0.1:42251,DS-f25b8ea3-b645-438b-997b-9e2644475ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:43619,DS-00402c6b-b6a5-4cf1-be01-e8f6c35f2a31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1828148663-172.17.0.12-1595322750666:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43339,DS-473c4534-19b5-4f3a-a74a-0725c326fe3b,DISK], DatanodeInfoWithStorage[127.0.0.1:39591,DS-10c28cd5-1730-4ff4-949d-5c3a95395783,DISK], DatanodeInfoWithStorage[127.0.0.1:39538,DS-2eff6852-2736-40c0-81a9-cee4fded7dd6,DISK], DatanodeInfoWithStorage[127.0.0.1:43527,DS-07b7337d-54f1-4c22-8e5c-c6b54c01c2b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37893,DS-2cdeffbe-d03a-43e3-b724-c6f9b57de684,DISK], DatanodeInfoWithStorage[127.0.0.1:39544,DS-2982de23-70bd-4c3e-9a76-cf4299ce2d09,DISK], DatanodeInfoWithStorage[127.0.0.1:42251,DS-f25b8ea3-b645-438b-997b-9e2644475ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:43619,DS-00402c6b-b6a5-4cf1-be01-e8f6c35f2a31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 6375
