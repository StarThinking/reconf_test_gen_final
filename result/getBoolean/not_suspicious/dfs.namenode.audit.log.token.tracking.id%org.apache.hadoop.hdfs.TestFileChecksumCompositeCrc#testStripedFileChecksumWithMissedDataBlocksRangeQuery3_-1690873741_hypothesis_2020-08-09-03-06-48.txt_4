reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2055892849-172.17.0.21-1596942423516:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35944,DS-bb2bae9b-ad7d-470f-a862-5f35fc64b03d,DISK], DatanodeInfoWithStorage[127.0.0.1:44426,DS-d722a4df-5eed-40a9-afdf-f27f5b4a3b47,DISK], DatanodeInfoWithStorage[127.0.0.1:44349,DS-c92a5382-1985-4bf0-8d11-ce4567f60db5,DISK], DatanodeInfoWithStorage[127.0.0.1:46458,DS-09d30219-825d-4280-b752-1c0c46f16e94,DISK], DatanodeInfoWithStorage[127.0.0.1:43299,DS-aaddae8a-bf61-4cd2-8924-cc976adeee80,DISK], DatanodeInfoWithStorage[127.0.0.1:40533,DS-71d406fd-cac1-496f-a1ea-a44a003cd3f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35397,DS-3e88edfb-6c1c-49d3-aba1-c0eb58cc0a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:36861,DS-ec8dc6b0-ca98-4d36-8f31-7d89339f0bfe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2055892849-172.17.0.21-1596942423516:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35944,DS-bb2bae9b-ad7d-470f-a862-5f35fc64b03d,DISK], DatanodeInfoWithStorage[127.0.0.1:44426,DS-d722a4df-5eed-40a9-afdf-f27f5b4a3b47,DISK], DatanodeInfoWithStorage[127.0.0.1:44349,DS-c92a5382-1985-4bf0-8d11-ce4567f60db5,DISK], DatanodeInfoWithStorage[127.0.0.1:46458,DS-09d30219-825d-4280-b752-1c0c46f16e94,DISK], DatanodeInfoWithStorage[127.0.0.1:43299,DS-aaddae8a-bf61-4cd2-8924-cc976adeee80,DISK], DatanodeInfoWithStorage[127.0.0.1:40533,DS-71d406fd-cac1-496f-a1ea-a44a003cd3f5,DISK], DatanodeInfoWithStorage[127.0.0.1:35397,DS-3e88edfb-6c1c-49d3-aba1-c0eb58cc0a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:36861,DS-ec8dc6b0-ca98-4d36-8f31-7d89339f0bfe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1964001785-172.17.0.21-1596942515828:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36950,DS-d7207c48-b003-4f98-ae13-2ffa6ab00abe,DISK], DatanodeInfoWithStorage[127.0.0.1:35715,DS-7ba7b6fa-7921-453a-8c8a-55996714a0ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38914,DS-f1aa0b6c-94e8-4e7c-a80f-10e83e9567a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41802,DS-e581c822-eb15-4187-ae40-b843c0bc97c3,DISK], DatanodeInfoWithStorage[127.0.0.1:36937,DS-3e1edc75-d4a2-4e3b-b392-ce9b96ed97a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40097,DS-a80ed266-4192-4207-9dec-f19392011aea,DISK], DatanodeInfoWithStorage[127.0.0.1:40775,DS-4e300494-b3d1-4217-aeb0-43002e23a4ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39444,DS-19c5a563-fe9b-4c3f-88da-7258556fcfb3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1964001785-172.17.0.21-1596942515828:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36950,DS-d7207c48-b003-4f98-ae13-2ffa6ab00abe,DISK], DatanodeInfoWithStorage[127.0.0.1:35715,DS-7ba7b6fa-7921-453a-8c8a-55996714a0ea,DISK], DatanodeInfoWithStorage[127.0.0.1:38914,DS-f1aa0b6c-94e8-4e7c-a80f-10e83e9567a2,DISK], DatanodeInfoWithStorage[127.0.0.1:41802,DS-e581c822-eb15-4187-ae40-b843c0bc97c3,DISK], DatanodeInfoWithStorage[127.0.0.1:36937,DS-3e1edc75-d4a2-4e3b-b392-ce9b96ed97a6,DISK], DatanodeInfoWithStorage[127.0.0.1:40097,DS-a80ed266-4192-4207-9dec-f19392011aea,DISK], DatanodeInfoWithStorage[127.0.0.1:40775,DS-4e300494-b3d1-4217-aeb0-43002e23a4ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39444,DS-19c5a563-fe9b-4c3f-88da-7258556fcfb3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-573278522-172.17.0.21-1596942549503:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35966,DS-51aa955b-2853-4bb2-b704-36948790ce38,DISK], DatanodeInfoWithStorage[127.0.0.1:38590,DS-bc608604-b8de-4248-9315-e34a0c8cabf8,DISK], DatanodeInfoWithStorage[127.0.0.1:36256,DS-8f7e9dd8-fbba-4635-9e66-1efa17afcb4b,DISK], DatanodeInfoWithStorage[127.0.0.1:39626,DS-c412b2f1-c636-4e2e-abfb-a437584f1839,DISK], DatanodeInfoWithStorage[127.0.0.1:40067,DS-abf73aaf-32b4-4a2a-bb72-ee503b75816b,DISK], DatanodeInfoWithStorage[127.0.0.1:33664,DS-8901092f-06ff-4faf-a7e5-259517773099,DISK], DatanodeInfoWithStorage[127.0.0.1:34371,DS-61780764-97d8-4705-921c-f60896804ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:35863,DS-7cee72e6-8d02-4b4b-853b-d4dd880f98c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-573278522-172.17.0.21-1596942549503:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35966,DS-51aa955b-2853-4bb2-b704-36948790ce38,DISK], DatanodeInfoWithStorage[127.0.0.1:38590,DS-bc608604-b8de-4248-9315-e34a0c8cabf8,DISK], DatanodeInfoWithStorage[127.0.0.1:36256,DS-8f7e9dd8-fbba-4635-9e66-1efa17afcb4b,DISK], DatanodeInfoWithStorage[127.0.0.1:39626,DS-c412b2f1-c636-4e2e-abfb-a437584f1839,DISK], DatanodeInfoWithStorage[127.0.0.1:40067,DS-abf73aaf-32b4-4a2a-bb72-ee503b75816b,DISK], DatanodeInfoWithStorage[127.0.0.1:33664,DS-8901092f-06ff-4faf-a7e5-259517773099,DISK], DatanodeInfoWithStorage[127.0.0.1:34371,DS-61780764-97d8-4705-921c-f60896804ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:35863,DS-7cee72e6-8d02-4b4b-853b-d4dd880f98c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-620880790-172.17.0.21-1596943052804:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33454,DS-8db5a738-bb52-4f19-bbeb-b707199f6eab,DISK], DatanodeInfoWithStorage[127.0.0.1:41159,DS-3f24e1f4-51eb-4260-8d61-4b62b1c8f4b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33588,DS-66ee583c-9dbe-462b-bc67-a14e4cf5c02d,DISK], DatanodeInfoWithStorage[127.0.0.1:41279,DS-ebd81ea6-7cf5-4fc4-84fb-dd7f715ee3ac,DISK], DatanodeInfoWithStorage[127.0.0.1:33550,DS-0c2f9123-c542-4ec2-b4b4-5e5ab54db537,DISK], DatanodeInfoWithStorage[127.0.0.1:46016,DS-d7ea85f8-286d-4915-9f42-faaceba047b3,DISK], DatanodeInfoWithStorage[127.0.0.1:43722,DS-b8b27c58-53d5-40bf-9331-7e80d121ed7c,DISK], DatanodeInfoWithStorage[127.0.0.1:46684,DS-c39e1e7f-a9e6-4929-8c30-ce027a5d5c0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-620880790-172.17.0.21-1596943052804:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33454,DS-8db5a738-bb52-4f19-bbeb-b707199f6eab,DISK], DatanodeInfoWithStorage[127.0.0.1:41159,DS-3f24e1f4-51eb-4260-8d61-4b62b1c8f4b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33588,DS-66ee583c-9dbe-462b-bc67-a14e4cf5c02d,DISK], DatanodeInfoWithStorage[127.0.0.1:41279,DS-ebd81ea6-7cf5-4fc4-84fb-dd7f715ee3ac,DISK], DatanodeInfoWithStorage[127.0.0.1:33550,DS-0c2f9123-c542-4ec2-b4b4-5e5ab54db537,DISK], DatanodeInfoWithStorage[127.0.0.1:46016,DS-d7ea85f8-286d-4915-9f42-faaceba047b3,DISK], DatanodeInfoWithStorage[127.0.0.1:43722,DS-b8b27c58-53d5-40bf-9331-7e80d121ed7c,DISK], DatanodeInfoWithStorage[127.0.0.1:46684,DS-c39e1e7f-a9e6-4929-8c30-ce027a5d5c0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1803737558-172.17.0.21-1596943195780:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38008,DS-ae651382-7435-4c02-978e-82f1cfcc2039,DISK], DatanodeInfoWithStorage[127.0.0.1:44650,DS-252c6a2c-7c7c-4e52-9928-2828c7fc8ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:42466,DS-1064c2b0-651a-4ca6-a375-6b81fb9510a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34518,DS-74797b19-179e-420d-a09f-9a6031adbe38,DISK], DatanodeInfoWithStorage[127.0.0.1:40823,DS-68a9d572-3070-4fe7-bb3c-4cc57f9a9d68,DISK], DatanodeInfoWithStorage[127.0.0.1:42722,DS-864a4c04-c0e4-431f-a156-f31d254212ed,DISK], DatanodeInfoWithStorage[127.0.0.1:46356,DS-56202ce3-6508-4728-a573-15140fee5832,DISK], DatanodeInfoWithStorage[127.0.0.1:34811,DS-e372b3d7-6602-44fd-ad83-04381f473224,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1803737558-172.17.0.21-1596943195780:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38008,DS-ae651382-7435-4c02-978e-82f1cfcc2039,DISK], DatanodeInfoWithStorage[127.0.0.1:44650,DS-252c6a2c-7c7c-4e52-9928-2828c7fc8ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:42466,DS-1064c2b0-651a-4ca6-a375-6b81fb9510a4,DISK], DatanodeInfoWithStorage[127.0.0.1:34518,DS-74797b19-179e-420d-a09f-9a6031adbe38,DISK], DatanodeInfoWithStorage[127.0.0.1:40823,DS-68a9d572-3070-4fe7-bb3c-4cc57f9a9d68,DISK], DatanodeInfoWithStorage[127.0.0.1:42722,DS-864a4c04-c0e4-431f-a156-f31d254212ed,DISK], DatanodeInfoWithStorage[127.0.0.1:46356,DS-56202ce3-6508-4728-a573-15140fee5832,DISK], DatanodeInfoWithStorage[127.0.0.1:34811,DS-e372b3d7-6602-44fd-ad83-04381f473224,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1189299850-172.17.0.21-1596943561233:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46815,DS-f326e175-bece-4103-9526-78b424ee6f14,DISK], DatanodeInfoWithStorage[127.0.0.1:39918,DS-d4d194bc-94e6-4d27-914c-b362cf385917,DISK], DatanodeInfoWithStorage[127.0.0.1:34376,DS-73e4442a-7d25-412c-af3b-b41a0578eefc,DISK], DatanodeInfoWithStorage[127.0.0.1:33820,DS-3119418f-90d5-4032-b9f8-8131d7b8827c,DISK], DatanodeInfoWithStorage[127.0.0.1:40798,DS-0b5c0f6b-26c7-409c-a83c-aeee6b2893b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43399,DS-ce4779a3-1090-431a-99dc-4f1c8c4c3b48,DISK], DatanodeInfoWithStorage[127.0.0.1:44803,DS-36526ccf-118f-40fe-b357-1b8bf5263986,DISK], DatanodeInfoWithStorage[127.0.0.1:46622,DS-1922232d-12b7-40a7-a3bd-0fdcac8519e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1189299850-172.17.0.21-1596943561233:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46815,DS-f326e175-bece-4103-9526-78b424ee6f14,DISK], DatanodeInfoWithStorage[127.0.0.1:39918,DS-d4d194bc-94e6-4d27-914c-b362cf385917,DISK], DatanodeInfoWithStorage[127.0.0.1:34376,DS-73e4442a-7d25-412c-af3b-b41a0578eefc,DISK], DatanodeInfoWithStorage[127.0.0.1:33820,DS-3119418f-90d5-4032-b9f8-8131d7b8827c,DISK], DatanodeInfoWithStorage[127.0.0.1:40798,DS-0b5c0f6b-26c7-409c-a83c-aeee6b2893b7,DISK], DatanodeInfoWithStorage[127.0.0.1:43399,DS-ce4779a3-1090-431a-99dc-4f1c8c4c3b48,DISK], DatanodeInfoWithStorage[127.0.0.1:44803,DS-36526ccf-118f-40fe-b357-1b8bf5263986,DISK], DatanodeInfoWithStorage[127.0.0.1:46622,DS-1922232d-12b7-40a7-a3bd-0fdcac8519e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2096095813-172.17.0.21-1596943747355:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37825,DS-3429b2b0-9db3-405f-8a74-e1569d249667,DISK], DatanodeInfoWithStorage[127.0.0.1:37345,DS-61825aaf-3b63-4728-bfb2-a215910c69f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35447,DS-442d5b08-9e69-40eb-8f4a-39edc4cb22cb,DISK], DatanodeInfoWithStorage[127.0.0.1:42143,DS-47ff1ce7-c0be-491b-b845-c062a830baec,DISK], DatanodeInfoWithStorage[127.0.0.1:39377,DS-de2a3329-c486-452c-9ad4-5b1579b349db,DISK], DatanodeInfoWithStorage[127.0.0.1:38666,DS-84f914d9-b6e0-4ae7-876a-8d0cfe8c780a,DISK], DatanodeInfoWithStorage[127.0.0.1:46075,DS-6cd0b2d7-3246-4b96-8933-5ac570ab3ac7,DISK], DatanodeInfoWithStorage[127.0.0.1:45142,DS-4e91bc36-f022-4417-a5c8-27c8594df35a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2096095813-172.17.0.21-1596943747355:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37825,DS-3429b2b0-9db3-405f-8a74-e1569d249667,DISK], DatanodeInfoWithStorage[127.0.0.1:37345,DS-61825aaf-3b63-4728-bfb2-a215910c69f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35447,DS-442d5b08-9e69-40eb-8f4a-39edc4cb22cb,DISK], DatanodeInfoWithStorage[127.0.0.1:42143,DS-47ff1ce7-c0be-491b-b845-c062a830baec,DISK], DatanodeInfoWithStorage[127.0.0.1:39377,DS-de2a3329-c486-452c-9ad4-5b1579b349db,DISK], DatanodeInfoWithStorage[127.0.0.1:38666,DS-84f914d9-b6e0-4ae7-876a-8d0cfe8c780a,DISK], DatanodeInfoWithStorage[127.0.0.1:46075,DS-6cd0b2d7-3246-4b96-8933-5ac570ab3ac7,DISK], DatanodeInfoWithStorage[127.0.0.1:45142,DS-4e91bc36-f022-4417-a5c8-27c8594df35a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-750896724-172.17.0.21-1596944182291:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36866,DS-6c388e38-f331-4bab-8b61-0a9b38ec4d11,DISK], DatanodeInfoWithStorage[127.0.0.1:45649,DS-1065cb65-5425-44d5-9c64-03c439a7e189,DISK], DatanodeInfoWithStorage[127.0.0.1:43143,DS-f9fe5790-9e41-418a-949b-c7666378b750,DISK], DatanodeInfoWithStorage[127.0.0.1:41148,DS-7b7c1d64-1750-4aba-ae7b-c1d232683905,DISK], DatanodeInfoWithStorage[127.0.0.1:36903,DS-671fde59-0372-479e-9672-e4d56874f78e,DISK], DatanodeInfoWithStorage[127.0.0.1:43557,DS-281772f7-abce-4c51-97e7-9fd57bb49b53,DISK], DatanodeInfoWithStorage[127.0.0.1:46645,DS-81649e0b-1481-4360-ab40-07636d6bc8eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38898,DS-0d6943c6-4b6d-40c7-b17c-00604bce4c49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-750896724-172.17.0.21-1596944182291:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36866,DS-6c388e38-f331-4bab-8b61-0a9b38ec4d11,DISK], DatanodeInfoWithStorage[127.0.0.1:45649,DS-1065cb65-5425-44d5-9c64-03c439a7e189,DISK], DatanodeInfoWithStorage[127.0.0.1:43143,DS-f9fe5790-9e41-418a-949b-c7666378b750,DISK], DatanodeInfoWithStorage[127.0.0.1:41148,DS-7b7c1d64-1750-4aba-ae7b-c1d232683905,DISK], DatanodeInfoWithStorage[127.0.0.1:36903,DS-671fde59-0372-479e-9672-e4d56874f78e,DISK], DatanodeInfoWithStorage[127.0.0.1:43557,DS-281772f7-abce-4c51-97e7-9fd57bb49b53,DISK], DatanodeInfoWithStorage[127.0.0.1:46645,DS-81649e0b-1481-4360-ab40-07636d6bc8eb,DISK], DatanodeInfoWithStorage[127.0.0.1:38898,DS-0d6943c6-4b6d-40c7-b17c-00604bce4c49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1522779462-172.17.0.21-1596944339412:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45835,DS-4e58b995-bcd2-4a32-ab79-08406eb9ca7f,DISK], DatanodeInfoWithStorage[127.0.0.1:38351,DS-dba0e9a0-dcb3-4d85-b4a0-f0fac309110b,DISK], DatanodeInfoWithStorage[127.0.0.1:39829,DS-b9a70ff9-7b7b-45b7-b00e-bbd11d98dab5,DISK], DatanodeInfoWithStorage[127.0.0.1:37902,DS-17753cd0-b399-4d34-a9c2-531bd33e9f29,DISK], DatanodeInfoWithStorage[127.0.0.1:36306,DS-c11d50d3-2036-49f1-b37c-00d93a61ac24,DISK], DatanodeInfoWithStorage[127.0.0.1:39028,DS-d6f31bc8-e85c-4822-b10c-d506fd71a2dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33821,DS-62d3782d-69e4-47a1-8dac-37f978fe2104,DISK], DatanodeInfoWithStorage[127.0.0.1:37084,DS-8b5d99fa-9423-4281-8c70-1f32ce8ce124,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1522779462-172.17.0.21-1596944339412:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45835,DS-4e58b995-bcd2-4a32-ab79-08406eb9ca7f,DISK], DatanodeInfoWithStorage[127.0.0.1:38351,DS-dba0e9a0-dcb3-4d85-b4a0-f0fac309110b,DISK], DatanodeInfoWithStorage[127.0.0.1:39829,DS-b9a70ff9-7b7b-45b7-b00e-bbd11d98dab5,DISK], DatanodeInfoWithStorage[127.0.0.1:37902,DS-17753cd0-b399-4d34-a9c2-531bd33e9f29,DISK], DatanodeInfoWithStorage[127.0.0.1:36306,DS-c11d50d3-2036-49f1-b37c-00d93a61ac24,DISK], DatanodeInfoWithStorage[127.0.0.1:39028,DS-d6f31bc8-e85c-4822-b10c-d506fd71a2dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33821,DS-62d3782d-69e4-47a1-8dac-37f978fe2104,DISK], DatanodeInfoWithStorage[127.0.0.1:37084,DS-8b5d99fa-9423-4281-8c70-1f32ce8ce124,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1184331264-172.17.0.21-1596944613039:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37008,DS-c0012c99-eb38-427c-b48d-caab6ffae4a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34355,DS-249b6437-44cb-41ac-942d-a27111eb5cd0,DISK], DatanodeInfoWithStorage[127.0.0.1:45841,DS-65f510aa-b893-47f4-8472-f157a7aec4df,DISK], DatanodeInfoWithStorage[127.0.0.1:38207,DS-ad79b645-0bda-4b8e-90cc-22c035e700dd,DISK], DatanodeInfoWithStorage[127.0.0.1:35807,DS-1339a4e2-ed69-422a-baf5-a82b99d14ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:38934,DS-0e1f1183-968e-4e6b-9df4-5cbe2411824c,DISK], DatanodeInfoWithStorage[127.0.0.1:39811,DS-6f276bd5-d31f-4a90-b974-1c7d7a8b9831,DISK], DatanodeInfoWithStorage[127.0.0.1:41920,DS-8a413670-d419-461c-aa2f-39e5e930c120,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1184331264-172.17.0.21-1596944613039:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37008,DS-c0012c99-eb38-427c-b48d-caab6ffae4a1,DISK], DatanodeInfoWithStorage[127.0.0.1:34355,DS-249b6437-44cb-41ac-942d-a27111eb5cd0,DISK], DatanodeInfoWithStorage[127.0.0.1:45841,DS-65f510aa-b893-47f4-8472-f157a7aec4df,DISK], DatanodeInfoWithStorage[127.0.0.1:38207,DS-ad79b645-0bda-4b8e-90cc-22c035e700dd,DISK], DatanodeInfoWithStorage[127.0.0.1:35807,DS-1339a4e2-ed69-422a-baf5-a82b99d14ea1,DISK], DatanodeInfoWithStorage[127.0.0.1:38934,DS-0e1f1183-968e-4e6b-9df4-5cbe2411824c,DISK], DatanodeInfoWithStorage[127.0.0.1:39811,DS-6f276bd5-d31f-4a90-b974-1c7d7a8b9831,DISK], DatanodeInfoWithStorage[127.0.0.1:41920,DS-8a413670-d419-461c-aa2f-39e5e930c120,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-130351849-172.17.0.21-1596944721451:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40024,DS-8ffb23aa-93e9-4f91-98ab-53b55e36a6cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33167,DS-dc4eeac0-70bb-41de-a1a5-60a09a2e6dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:41666,DS-87f7d58a-2254-48d1-a331-a205277cd84f,DISK], DatanodeInfoWithStorage[127.0.0.1:38747,DS-f43f75c4-d833-45cc-88c3-a8149eaa31c5,DISK], DatanodeInfoWithStorage[127.0.0.1:36954,DS-eb8e25be-1c3a-4c66-9277-3800f6a01879,DISK], DatanodeInfoWithStorage[127.0.0.1:34451,DS-4fa5d456-b46b-4dc1-90c6-dd310b39daec,DISK], DatanodeInfoWithStorage[127.0.0.1:42421,DS-955e4d3f-0eb5-4075-a375-e994127a74ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46180,DS-5db5d04b-d4df-4098-b925-f1501bb03faf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-130351849-172.17.0.21-1596944721451:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40024,DS-8ffb23aa-93e9-4f91-98ab-53b55e36a6cd,DISK], DatanodeInfoWithStorage[127.0.0.1:33167,DS-dc4eeac0-70bb-41de-a1a5-60a09a2e6dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:41666,DS-87f7d58a-2254-48d1-a331-a205277cd84f,DISK], DatanodeInfoWithStorage[127.0.0.1:38747,DS-f43f75c4-d833-45cc-88c3-a8149eaa31c5,DISK], DatanodeInfoWithStorage[127.0.0.1:36954,DS-eb8e25be-1c3a-4c66-9277-3800f6a01879,DISK], DatanodeInfoWithStorage[127.0.0.1:34451,DS-4fa5d456-b46b-4dc1-90c6-dd310b39daec,DISK], DatanodeInfoWithStorage[127.0.0.1:42421,DS-955e4d3f-0eb5-4075-a375-e994127a74ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46180,DS-5db5d04b-d4df-4098-b925-f1501bb03faf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-445899920-172.17.0.21-1596945126922:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35972,DS-8321faa1-12a9-4cb5-b5a9-78ae65579652,DISK], DatanodeInfoWithStorage[127.0.0.1:41375,DS-ba151586-48bf-4177-8822-c6c1d7ceb96f,DISK], DatanodeInfoWithStorage[127.0.0.1:44826,DS-d201261c-8d4f-418d-87a8-842b8ecc6061,DISK], DatanodeInfoWithStorage[127.0.0.1:35052,DS-e3cad823-877c-4f8c-a1b6-78cd084f1403,DISK], DatanodeInfoWithStorage[127.0.0.1:40310,DS-3e7197a0-54aa-4f0a-9b41-2a8330b72532,DISK], DatanodeInfoWithStorage[127.0.0.1:37287,DS-7841e942-46e3-4a86-86ac-ead7d6a5199f,DISK], DatanodeInfoWithStorage[127.0.0.1:46201,DS-f0650d2e-cab2-4580-9883-5ac7f606c88d,DISK], DatanodeInfoWithStorage[127.0.0.1:44372,DS-e5256325-dbf7-4d95-b1a7-173e35cbb6b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-445899920-172.17.0.21-1596945126922:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35972,DS-8321faa1-12a9-4cb5-b5a9-78ae65579652,DISK], DatanodeInfoWithStorage[127.0.0.1:41375,DS-ba151586-48bf-4177-8822-c6c1d7ceb96f,DISK], DatanodeInfoWithStorage[127.0.0.1:44826,DS-d201261c-8d4f-418d-87a8-842b8ecc6061,DISK], DatanodeInfoWithStorage[127.0.0.1:35052,DS-e3cad823-877c-4f8c-a1b6-78cd084f1403,DISK], DatanodeInfoWithStorage[127.0.0.1:40310,DS-3e7197a0-54aa-4f0a-9b41-2a8330b72532,DISK], DatanodeInfoWithStorage[127.0.0.1:37287,DS-7841e942-46e3-4a86-86ac-ead7d6a5199f,DISK], DatanodeInfoWithStorage[127.0.0.1:46201,DS-f0650d2e-cab2-4580-9883-5ac7f606c88d,DISK], DatanodeInfoWithStorage[127.0.0.1:44372,DS-e5256325-dbf7-4d95-b1a7-173e35cbb6b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1290226749-172.17.0.21-1596946428548:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40003,DS-77290949-2831-416d-8a20-b00b1ec17b36,DISK], DatanodeInfoWithStorage[127.0.0.1:33999,DS-a41fbe6e-bed8-40c1-9096-6fed6188a422,DISK], DatanodeInfoWithStorage[127.0.0.1:38640,DS-b9968b21-d2fa-4f12-b32d-c3c204bc98fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45141,DS-c2bce314-6867-4e4f-a311-788731d22a6f,DISK], DatanodeInfoWithStorage[127.0.0.1:37478,DS-4da6b194-1cb8-496b-a1dd-0a1789c4afa5,DISK], DatanodeInfoWithStorage[127.0.0.1:40943,DS-67124de5-44ea-4089-b991-ba969459ef63,DISK], DatanodeInfoWithStorage[127.0.0.1:42463,DS-a0f96c1d-65d0-4559-87d5-66f29cf06242,DISK], DatanodeInfoWithStorage[127.0.0.1:41670,DS-75a3e4cf-9265-4805-ab4e-df095888edb3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1290226749-172.17.0.21-1596946428548:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40003,DS-77290949-2831-416d-8a20-b00b1ec17b36,DISK], DatanodeInfoWithStorage[127.0.0.1:33999,DS-a41fbe6e-bed8-40c1-9096-6fed6188a422,DISK], DatanodeInfoWithStorage[127.0.0.1:38640,DS-b9968b21-d2fa-4f12-b32d-c3c204bc98fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45141,DS-c2bce314-6867-4e4f-a311-788731d22a6f,DISK], DatanodeInfoWithStorage[127.0.0.1:37478,DS-4da6b194-1cb8-496b-a1dd-0a1789c4afa5,DISK], DatanodeInfoWithStorage[127.0.0.1:40943,DS-67124de5-44ea-4089-b991-ba969459ef63,DISK], DatanodeInfoWithStorage[127.0.0.1:42463,DS-a0f96c1d-65d0-4559-87d5-66f29cf06242,DISK], DatanodeInfoWithStorage[127.0.0.1:41670,DS-75a3e4cf-9265-4805-ab4e-df095888edb3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-362695016-172.17.0.21-1596946622272:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33695,DS-f2552a6c-7648-40bc-819a-129fe6527cd9,DISK], DatanodeInfoWithStorage[127.0.0.1:40867,DS-220f0023-ee6b-413c-b689-9b0d5deb2b62,DISK], DatanodeInfoWithStorage[127.0.0.1:39292,DS-4042e626-05ea-4bda-90ca-9b3d20ba0e3b,DISK], DatanodeInfoWithStorage[127.0.0.1:42458,DS-c4917518-fd85-4721-9033-07c6301cd3e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37408,DS-00e5c124-59fe-4b35-a67d-95c4911e552a,DISK], DatanodeInfoWithStorage[127.0.0.1:45027,DS-b473e5f3-f606-478e-9786-634cf9336780,DISK], DatanodeInfoWithStorage[127.0.0.1:38537,DS-91af7bda-c4a9-45cc-b2c3-bb84bfba84a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39796,DS-760bfc3c-3f7f-436e-8321-59ae0fe6b168,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-362695016-172.17.0.21-1596946622272:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33695,DS-f2552a6c-7648-40bc-819a-129fe6527cd9,DISK], DatanodeInfoWithStorage[127.0.0.1:40867,DS-220f0023-ee6b-413c-b689-9b0d5deb2b62,DISK], DatanodeInfoWithStorage[127.0.0.1:39292,DS-4042e626-05ea-4bda-90ca-9b3d20ba0e3b,DISK], DatanodeInfoWithStorage[127.0.0.1:42458,DS-c4917518-fd85-4721-9033-07c6301cd3e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37408,DS-00e5c124-59fe-4b35-a67d-95c4911e552a,DISK], DatanodeInfoWithStorage[127.0.0.1:45027,DS-b473e5f3-f606-478e-9786-634cf9336780,DISK], DatanodeInfoWithStorage[127.0.0.1:38537,DS-91af7bda-c4a9-45cc-b2c3-bb84bfba84a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39796,DS-760bfc3c-3f7f-436e-8321-59ae0fe6b168,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-487265388-172.17.0.21-1596947123180:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37403,DS-e6371d37-7a04-47f0-b55d-8b559fb3ec94,DISK], DatanodeInfoWithStorage[127.0.0.1:40910,DS-717163bc-bde6-4105-b73e-bfa931a6a78c,DISK], DatanodeInfoWithStorage[127.0.0.1:42779,DS-af3d1684-8754-4389-9b55-6746e37d260e,DISK], DatanodeInfoWithStorage[127.0.0.1:46696,DS-b616457d-e0a3-4b00-b467-821d1bba17c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35016,DS-b4677287-f26e-4b80-9c47-1884004cb619,DISK], DatanodeInfoWithStorage[127.0.0.1:37814,DS-c489a68e-b81e-4f8f-b782-4ce9b90e13e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37665,DS-21266921-b06b-4220-98e8-57394c4643c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39124,DS-eacf9b29-2e72-4f9c-94ad-d08b591aabed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-487265388-172.17.0.21-1596947123180:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37403,DS-e6371d37-7a04-47f0-b55d-8b559fb3ec94,DISK], DatanodeInfoWithStorage[127.0.0.1:40910,DS-717163bc-bde6-4105-b73e-bfa931a6a78c,DISK], DatanodeInfoWithStorage[127.0.0.1:42779,DS-af3d1684-8754-4389-9b55-6746e37d260e,DISK], DatanodeInfoWithStorage[127.0.0.1:46696,DS-b616457d-e0a3-4b00-b467-821d1bba17c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35016,DS-b4677287-f26e-4b80-9c47-1884004cb619,DISK], DatanodeInfoWithStorage[127.0.0.1:37814,DS-c489a68e-b81e-4f8f-b782-4ce9b90e13e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37665,DS-21266921-b06b-4220-98e8-57394c4643c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39124,DS-eacf9b29-2e72-4f9c-94ad-d08b591aabed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-739417552-172.17.0.21-1596947211414:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34039,DS-29510ef8-e08f-4658-8a6c-2e4b44a95ebb,DISK], DatanodeInfoWithStorage[127.0.0.1:39050,DS-4981dd68-addf-4d1a-b65c-a64923b92c91,DISK], DatanodeInfoWithStorage[127.0.0.1:45559,DS-54623ea6-5da5-4fa5-95e3-c22a7744735d,DISK], DatanodeInfoWithStorage[127.0.0.1:38719,DS-ea23fcf6-a1d1-4069-b36b-7db57e92ccc1,DISK], DatanodeInfoWithStorage[127.0.0.1:35528,DS-d2f4b89d-e1fd-413e-a421-be7707ebb4fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36852,DS-7a075120-92e7-47cf-9e5d-df56432c346c,DISK], DatanodeInfoWithStorage[127.0.0.1:35876,DS-108fd953-9865-493a-9519-be32baec8d40,DISK], DatanodeInfoWithStorage[127.0.0.1:42445,DS-66ca42ce-01fc-412a-8663-41be4643d1c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-739417552-172.17.0.21-1596947211414:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34039,DS-29510ef8-e08f-4658-8a6c-2e4b44a95ebb,DISK], DatanodeInfoWithStorage[127.0.0.1:39050,DS-4981dd68-addf-4d1a-b65c-a64923b92c91,DISK], DatanodeInfoWithStorage[127.0.0.1:45559,DS-54623ea6-5da5-4fa5-95e3-c22a7744735d,DISK], DatanodeInfoWithStorage[127.0.0.1:38719,DS-ea23fcf6-a1d1-4069-b36b-7db57e92ccc1,DISK], DatanodeInfoWithStorage[127.0.0.1:35528,DS-d2f4b89d-e1fd-413e-a421-be7707ebb4fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36852,DS-7a075120-92e7-47cf-9e5d-df56432c346c,DISK], DatanodeInfoWithStorage[127.0.0.1:35876,DS-108fd953-9865-493a-9519-be32baec8d40,DISK], DatanodeInfoWithStorage[127.0.0.1:42445,DS-66ca42ce-01fc-412a-8663-41be4643d1c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1817924556-172.17.0.21-1596947523931:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34608,DS-093d70a0-56e7-4319-b90e-93a416219f53,DISK], DatanodeInfoWithStorage[127.0.0.1:46864,DS-76117bf4-f10d-450a-b9bb-230a4eaf07cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39147,DS-3ed31304-b9a6-4d46-b2c3-3733fa82d7fd,DISK], DatanodeInfoWithStorage[127.0.0.1:35053,DS-0f2b268a-3eaa-4c05-a9e5-07222a13ad0b,DISK], DatanodeInfoWithStorage[127.0.0.1:46194,DS-00efea13-aa76-42cb-801e-d5d14a631892,DISK], DatanodeInfoWithStorage[127.0.0.1:40289,DS-d895634d-e3ad-40da-b173-39a9f732789e,DISK], DatanodeInfoWithStorage[127.0.0.1:36016,DS-9316669c-51b8-4441-b741-2d7d85f838a4,DISK], DatanodeInfoWithStorage[127.0.0.1:38995,DS-1ad0f91e-86c1-4404-8949-a1e2157c67ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1817924556-172.17.0.21-1596947523931:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34608,DS-093d70a0-56e7-4319-b90e-93a416219f53,DISK], DatanodeInfoWithStorage[127.0.0.1:46864,DS-76117bf4-f10d-450a-b9bb-230a4eaf07cb,DISK], DatanodeInfoWithStorage[127.0.0.1:39147,DS-3ed31304-b9a6-4d46-b2c3-3733fa82d7fd,DISK], DatanodeInfoWithStorage[127.0.0.1:35053,DS-0f2b268a-3eaa-4c05-a9e5-07222a13ad0b,DISK], DatanodeInfoWithStorage[127.0.0.1:46194,DS-00efea13-aa76-42cb-801e-d5d14a631892,DISK], DatanodeInfoWithStorage[127.0.0.1:40289,DS-d895634d-e3ad-40da-b173-39a9f732789e,DISK], DatanodeInfoWithStorage[127.0.0.1:36016,DS-9316669c-51b8-4441-b741-2d7d85f838a4,DISK], DatanodeInfoWithStorage[127.0.0.1:38995,DS-1ad0f91e-86c1-4404-8949-a1e2157c67ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.audit.log.token.tracking.id
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1174001480-172.17.0.21-1596947749604:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41011,DS-196dfe13-f745-450a-b6e0-67040facc23a,DISK], DatanodeInfoWithStorage[127.0.0.1:36283,DS-ae0c1062-c97d-4e7b-9fb8-17585279fc64,DISK], DatanodeInfoWithStorage[127.0.0.1:33683,DS-b7330da5-b912-47a9-8beb-8e4d4f07229e,DISK], DatanodeInfoWithStorage[127.0.0.1:42491,DS-eb9993d1-4d9b-4c2e-8f92-7dadc7127ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:40612,DS-44dbc9d4-e41c-4e5b-b4b9-d7fd29782f81,DISK], DatanodeInfoWithStorage[127.0.0.1:34905,DS-815f2320-8d48-4864-9965-935968b26dea,DISK], DatanodeInfoWithStorage[127.0.0.1:37521,DS-686ddf43-b70b-44a6-badd-b1efe566b1c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42642,DS-6038c3ce-5806-4cc2-8497-24e0f0b166e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1174001480-172.17.0.21-1596947749604:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41011,DS-196dfe13-f745-450a-b6e0-67040facc23a,DISK], DatanodeInfoWithStorage[127.0.0.1:36283,DS-ae0c1062-c97d-4e7b-9fb8-17585279fc64,DISK], DatanodeInfoWithStorage[127.0.0.1:33683,DS-b7330da5-b912-47a9-8beb-8e4d4f07229e,DISK], DatanodeInfoWithStorage[127.0.0.1:42491,DS-eb9993d1-4d9b-4c2e-8f92-7dadc7127ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:40612,DS-44dbc9d4-e41c-4e5b-b4b9-d7fd29782f81,DISK], DatanodeInfoWithStorage[127.0.0.1:34905,DS-815f2320-8d48-4864-9965-935968b26dea,DISK], DatanodeInfoWithStorage[127.0.0.1:37521,DS-686ddf43-b70b-44a6-badd-b1efe566b1c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42642,DS-6038c3ce-5806-4cc2-8497-24e0f0b166e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5572
