reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-100644580-172.17.0.17-1595404510279:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34022,DS-53d2409f-fb90-4d7e-be42-f1b1df2f1419,DISK], DatanodeInfoWithStorage[127.0.0.1:33468,DS-9ca1e9eb-4b5d-4934-b762-8702fe0b6c84,DISK], DatanodeInfoWithStorage[127.0.0.1:33042,DS-674c8093-13fc-41c0-877b-c62d6800d39e,DISK], DatanodeInfoWithStorage[127.0.0.1:37809,DS-06bfabc6-d202-4bc1-9c96-229aee0b561c,DISK], DatanodeInfoWithStorage[127.0.0.1:32872,DS-6762ba18-3b65-4fe4-9f63-ad403095b9d4,DISK], DatanodeInfoWithStorage[127.0.0.1:32923,DS-7db3d5b8-b421-44b9-abe8-b078275156ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46858,DS-12c134ef-8baa-4093-a8e6-ab7ae0eb7402,DISK], DatanodeInfoWithStorage[127.0.0.1:38387,DS-5806aa06-9e5d-4311-9574-14ef3be45149,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-100644580-172.17.0.17-1595404510279:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34022,DS-53d2409f-fb90-4d7e-be42-f1b1df2f1419,DISK], DatanodeInfoWithStorage[127.0.0.1:33468,DS-9ca1e9eb-4b5d-4934-b762-8702fe0b6c84,DISK], DatanodeInfoWithStorage[127.0.0.1:33042,DS-674c8093-13fc-41c0-877b-c62d6800d39e,DISK], DatanodeInfoWithStorage[127.0.0.1:37809,DS-06bfabc6-d202-4bc1-9c96-229aee0b561c,DISK], DatanodeInfoWithStorage[127.0.0.1:32872,DS-6762ba18-3b65-4fe4-9f63-ad403095b9d4,DISK], DatanodeInfoWithStorage[127.0.0.1:32923,DS-7db3d5b8-b421-44b9-abe8-b078275156ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46858,DS-12c134ef-8baa-4093-a8e6-ab7ae0eb7402,DISK], DatanodeInfoWithStorage[127.0.0.1:38387,DS-5806aa06-9e5d-4311-9574-14ef3be45149,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1156619532-172.17.0.17-1595405120143:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45361,DS-61feffc7-f524-4bb1-996d-bf2f1c4943bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43381,DS-c8fe1dd8-4849-4441-9a95-46a36cc5293e,DISK], DatanodeInfoWithStorage[127.0.0.1:39075,DS-cb652db7-b936-40e6-8ecd-0ac1b307003e,DISK], DatanodeInfoWithStorage[127.0.0.1:43117,DS-1cf224c5-79c5-4787-b566-88f64befd353,DISK], DatanodeInfoWithStorage[127.0.0.1:36872,DS-1b2312a7-0708-465e-8baa-b4104a029534,DISK], DatanodeInfoWithStorage[127.0.0.1:44420,DS-75ac04d0-5239-4b88-9431-2ead22f9d069,DISK], DatanodeInfoWithStorage[127.0.0.1:35050,DS-7b70bac5-a86e-42b8-a531-02f484c0ba0f,DISK], DatanodeInfoWithStorage[127.0.0.1:40278,DS-d2a1bb92-042b-41cd-8ed2-126d5ba21b2f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1156619532-172.17.0.17-1595405120143:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45361,DS-61feffc7-f524-4bb1-996d-bf2f1c4943bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43381,DS-c8fe1dd8-4849-4441-9a95-46a36cc5293e,DISK], DatanodeInfoWithStorage[127.0.0.1:39075,DS-cb652db7-b936-40e6-8ecd-0ac1b307003e,DISK], DatanodeInfoWithStorage[127.0.0.1:43117,DS-1cf224c5-79c5-4787-b566-88f64befd353,DISK], DatanodeInfoWithStorage[127.0.0.1:36872,DS-1b2312a7-0708-465e-8baa-b4104a029534,DISK], DatanodeInfoWithStorage[127.0.0.1:44420,DS-75ac04d0-5239-4b88-9431-2ead22f9d069,DISK], DatanodeInfoWithStorage[127.0.0.1:35050,DS-7b70bac5-a86e-42b8-a531-02f484c0ba0f,DISK], DatanodeInfoWithStorage[127.0.0.1:40278,DS-d2a1bb92-042b-41cd-8ed2-126d5ba21b2f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1189061712-172.17.0.17-1595405265151:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41684,DS-daa285cd-84dc-4b98-8586-fca676d97d6e,DISK], DatanodeInfoWithStorage[127.0.0.1:40999,DS-b0a57b70-22e7-41ee-b4cb-d42e3a799ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:40586,DS-bef17da4-1d3d-462b-90a8-eba62144d8cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38555,DS-d7eea8b6-2bd7-494c-a24b-abe0b0283d25,DISK], DatanodeInfoWithStorage[127.0.0.1:38579,DS-e10d49f5-18e8-407f-b435-1f7c4b25b958,DISK], DatanodeInfoWithStorage[127.0.0.1:32769,DS-ce37d434-451e-44cc-98b1-588d3e68a35c,DISK], DatanodeInfoWithStorage[127.0.0.1:37555,DS-a77b72dc-7d8d-486b-8765-382f50d2c9eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37442,DS-16f5b00c-8e8d-4ec0-8d1b-4dd106466764,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1189061712-172.17.0.17-1595405265151:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41684,DS-daa285cd-84dc-4b98-8586-fca676d97d6e,DISK], DatanodeInfoWithStorage[127.0.0.1:40999,DS-b0a57b70-22e7-41ee-b4cb-d42e3a799ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:40586,DS-bef17da4-1d3d-462b-90a8-eba62144d8cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38555,DS-d7eea8b6-2bd7-494c-a24b-abe0b0283d25,DISK], DatanodeInfoWithStorage[127.0.0.1:38579,DS-e10d49f5-18e8-407f-b435-1f7c4b25b958,DISK], DatanodeInfoWithStorage[127.0.0.1:32769,DS-ce37d434-451e-44cc-98b1-588d3e68a35c,DISK], DatanodeInfoWithStorage[127.0.0.1:37555,DS-a77b72dc-7d8d-486b-8765-382f50d2c9eb,DISK], DatanodeInfoWithStorage[127.0.0.1:37442,DS-16f5b00c-8e8d-4ec0-8d1b-4dd106466764,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1483752424-172.17.0.17-1595405636048:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36386,DS-3e4839c1-c102-4971-a396-068866d8b300,DISK], DatanodeInfoWithStorage[127.0.0.1:32798,DS-46e74dbc-cb11-42a6-a486-4bb2194f745a,DISK], DatanodeInfoWithStorage[127.0.0.1:38521,DS-be325a49-6e83-4bb9-92a5-9b62e31b1dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:45606,DS-391fa1fa-2f0e-4eb8-89cf-8fa4753a261e,DISK], DatanodeInfoWithStorage[127.0.0.1:39369,DS-24411d54-7fce-462d-886b-2effcf919572,DISK], DatanodeInfoWithStorage[127.0.0.1:37325,DS-6a6da0aa-346c-4874-8215-78e1e313f211,DISK], DatanodeInfoWithStorage[127.0.0.1:45255,DS-856c22e1-61a1-4234-a19e-654b20013832,DISK], DatanodeInfoWithStorage[127.0.0.1:40553,DS-012b6dd0-dea0-439b-afa6-52017fc21faa,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1483752424-172.17.0.17-1595405636048:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36386,DS-3e4839c1-c102-4971-a396-068866d8b300,DISK], DatanodeInfoWithStorage[127.0.0.1:32798,DS-46e74dbc-cb11-42a6-a486-4bb2194f745a,DISK], DatanodeInfoWithStorage[127.0.0.1:38521,DS-be325a49-6e83-4bb9-92a5-9b62e31b1dc7,DISK], DatanodeInfoWithStorage[127.0.0.1:45606,DS-391fa1fa-2f0e-4eb8-89cf-8fa4753a261e,DISK], DatanodeInfoWithStorage[127.0.0.1:39369,DS-24411d54-7fce-462d-886b-2effcf919572,DISK], DatanodeInfoWithStorage[127.0.0.1:37325,DS-6a6da0aa-346c-4874-8215-78e1e313f211,DISK], DatanodeInfoWithStorage[127.0.0.1:45255,DS-856c22e1-61a1-4234-a19e-654b20013832,DISK], DatanodeInfoWithStorage[127.0.0.1:40553,DS-012b6dd0-dea0-439b-afa6-52017fc21faa,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2076219650-172.17.0.17-1595405752331:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46493,DS-a5705eb6-56e3-42ac-8f38-d69ebe3242a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38503,DS-2ef1989e-f058-4cb7-833e-8d524e91ca45,DISK], DatanodeInfoWithStorage[127.0.0.1:43266,DS-3391f7f5-1dd5-4b99-82b2-aac784dd829f,DISK], DatanodeInfoWithStorage[127.0.0.1:37883,DS-d5bf2253-69e7-4a54-81f1-9e26384b85bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38123,DS-7d14cef3-666a-4810-b54a-bcffd753e881,DISK], DatanodeInfoWithStorage[127.0.0.1:46402,DS-bf4f8037-d14f-49fe-ad63-8c9091f8cefc,DISK], DatanodeInfoWithStorage[127.0.0.1:38508,DS-1db386ab-8798-4030-8c9c-7d1e124ab345,DISK], DatanodeInfoWithStorage[127.0.0.1:41722,DS-c8552958-7881-485e-aee5-95f1236cab04,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2076219650-172.17.0.17-1595405752331:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46493,DS-a5705eb6-56e3-42ac-8f38-d69ebe3242a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38503,DS-2ef1989e-f058-4cb7-833e-8d524e91ca45,DISK], DatanodeInfoWithStorage[127.0.0.1:43266,DS-3391f7f5-1dd5-4b99-82b2-aac784dd829f,DISK], DatanodeInfoWithStorage[127.0.0.1:37883,DS-d5bf2253-69e7-4a54-81f1-9e26384b85bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38123,DS-7d14cef3-666a-4810-b54a-bcffd753e881,DISK], DatanodeInfoWithStorage[127.0.0.1:46402,DS-bf4f8037-d14f-49fe-ad63-8c9091f8cefc,DISK], DatanodeInfoWithStorage[127.0.0.1:38508,DS-1db386ab-8798-4030-8c9c-7d1e124ab345,DISK], DatanodeInfoWithStorage[127.0.0.1:41722,DS-c8552958-7881-485e-aee5-95f1236cab04,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1925229991-172.17.0.17-1595405791862:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38220,DS-0ac9e7ea-141d-4d4e-bb14-c83f2ab27140,DISK], DatanodeInfoWithStorage[127.0.0.1:38921,DS-c8ee432d-af91-49b0-bb7f-44ba2db59a8c,DISK], DatanodeInfoWithStorage[127.0.0.1:41787,DS-ec4f9717-521f-4544-a363-ec622aa5fa05,DISK], DatanodeInfoWithStorage[127.0.0.1:37565,DS-b7fa9955-20bf-4c1a-870f-c3b0379bb6c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33656,DS-ab3c6d75-70a6-446c-8379-b05039117ef0,DISK], DatanodeInfoWithStorage[127.0.0.1:44273,DS-fed54e1b-df0e-4772-8880-b3d314ada641,DISK], DatanodeInfoWithStorage[127.0.0.1:42340,DS-a51da1ac-5b9e-4f6a-9560-3c408cbe86dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41015,DS-48e58664-d58f-4c9c-9f2a-c37ced51106a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1925229991-172.17.0.17-1595405791862:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38220,DS-0ac9e7ea-141d-4d4e-bb14-c83f2ab27140,DISK], DatanodeInfoWithStorage[127.0.0.1:38921,DS-c8ee432d-af91-49b0-bb7f-44ba2db59a8c,DISK], DatanodeInfoWithStorage[127.0.0.1:41787,DS-ec4f9717-521f-4544-a363-ec622aa5fa05,DISK], DatanodeInfoWithStorage[127.0.0.1:37565,DS-b7fa9955-20bf-4c1a-870f-c3b0379bb6c7,DISK], DatanodeInfoWithStorage[127.0.0.1:33656,DS-ab3c6d75-70a6-446c-8379-b05039117ef0,DISK], DatanodeInfoWithStorage[127.0.0.1:44273,DS-fed54e1b-df0e-4772-8880-b3d314ada641,DISK], DatanodeInfoWithStorage[127.0.0.1:42340,DS-a51da1ac-5b9e-4f6a-9560-3c408cbe86dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41015,DS-48e58664-d58f-4c9c-9f2a-c37ced51106a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1500717075-172.17.0.17-1595405904652:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36396,DS-4939f1e4-98c6-4cc5-ae96-add1ba5927f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46254,DS-9b806bdb-da67-40b4-a704-0a369e7ae78b,DISK], DatanodeInfoWithStorage[127.0.0.1:44006,DS-f995cca9-b523-469e-90b0-24b589ce52cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34763,DS-6238f530-9c10-4543-be7b-859b3ac83bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:44128,DS-4c576d67-a487-4634-8d98-155a5298e4b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45438,DS-c564f531-c34d-4646-b3b7-5f307a050ec6,DISK], DatanodeInfoWithStorage[127.0.0.1:33105,DS-a01a83a8-3f28-42eb-9282-cb7b3ff5122e,DISK], DatanodeInfoWithStorage[127.0.0.1:36753,DS-bc329503-cd87-477e-89b2-269911eb2816,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1500717075-172.17.0.17-1595405904652:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36396,DS-4939f1e4-98c6-4cc5-ae96-add1ba5927f0,DISK], DatanodeInfoWithStorage[127.0.0.1:46254,DS-9b806bdb-da67-40b4-a704-0a369e7ae78b,DISK], DatanodeInfoWithStorage[127.0.0.1:44006,DS-f995cca9-b523-469e-90b0-24b589ce52cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34763,DS-6238f530-9c10-4543-be7b-859b3ac83bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:44128,DS-4c576d67-a487-4634-8d98-155a5298e4b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45438,DS-c564f531-c34d-4646-b3b7-5f307a050ec6,DISK], DatanodeInfoWithStorage[127.0.0.1:33105,DS-a01a83a8-3f28-42eb-9282-cb7b3ff5122e,DISK], DatanodeInfoWithStorage[127.0.0.1:36753,DS-bc329503-cd87-477e-89b2-269911eb2816,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1619758799-172.17.0.17-1595406567222:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39069,DS-efc473fc-7aaf-4a49-82de-1ded25a708ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37775,DS-d81be8b7-ed26-4de2-a747-38185bb8b4cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35993,DS-5e9c25e2-4510-4b77-a943-a3431e607c61,DISK], DatanodeInfoWithStorage[127.0.0.1:42061,DS-3a32edc4-6296-435d-a99d-c3c668b96b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:45093,DS-2391cc83-482f-432e-8138-dfaeddf08338,DISK], DatanodeInfoWithStorage[127.0.0.1:39830,DS-b2533b69-6824-442e-a207-0445d44816e3,DISK], DatanodeInfoWithStorage[127.0.0.1:33004,DS-be151af8-892e-4f0b-ae07-f582c6abc03f,DISK], DatanodeInfoWithStorage[127.0.0.1:44311,DS-08d03c8c-5be4-41f2-a417-d3f8508650ea,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1619758799-172.17.0.17-1595406567222:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39069,DS-efc473fc-7aaf-4a49-82de-1ded25a708ef,DISK], DatanodeInfoWithStorage[127.0.0.1:37775,DS-d81be8b7-ed26-4de2-a747-38185bb8b4cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35993,DS-5e9c25e2-4510-4b77-a943-a3431e607c61,DISK], DatanodeInfoWithStorage[127.0.0.1:42061,DS-3a32edc4-6296-435d-a99d-c3c668b96b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:45093,DS-2391cc83-482f-432e-8138-dfaeddf08338,DISK], DatanodeInfoWithStorage[127.0.0.1:39830,DS-b2533b69-6824-442e-a207-0445d44816e3,DISK], DatanodeInfoWithStorage[127.0.0.1:33004,DS-be151af8-892e-4f0b-ae07-f582c6abc03f,DISK], DatanodeInfoWithStorage[127.0.0.1:44311,DS-08d03c8c-5be4-41f2-a417-d3f8508650ea,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1863369311-172.17.0.17-1595406607194:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44268,DS-49b52cc0-a133-45c6-97e0-e2d05179e982,DISK], DatanodeInfoWithStorage[127.0.0.1:34921,DS-b7bd3e31-5d03-4ef1-918c-0427208b9f48,DISK], DatanodeInfoWithStorage[127.0.0.1:42309,DS-00cc69cf-a921-4f43-9f69-96aefa82c7f1,DISK], DatanodeInfoWithStorage[127.0.0.1:46558,DS-3d60dbcf-fa1b-4e22-bb0a-93d8a52f5aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:39429,DS-9345b500-9f2c-431f-b1f8-c9f48f872c0a,DISK], DatanodeInfoWithStorage[127.0.0.1:37081,DS-4a9e249d-8fc6-4ed2-828d-b7b643a9e1b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33009,DS-93cc2288-dc7a-4c9c-8675-801f8f29ba2b,DISK], DatanodeInfoWithStorage[127.0.0.1:42624,DS-923cc798-37b9-4232-bfbd-6943647ff499,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1863369311-172.17.0.17-1595406607194:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44268,DS-49b52cc0-a133-45c6-97e0-e2d05179e982,DISK], DatanodeInfoWithStorage[127.0.0.1:34921,DS-b7bd3e31-5d03-4ef1-918c-0427208b9f48,DISK], DatanodeInfoWithStorage[127.0.0.1:42309,DS-00cc69cf-a921-4f43-9f69-96aefa82c7f1,DISK], DatanodeInfoWithStorage[127.0.0.1:46558,DS-3d60dbcf-fa1b-4e22-bb0a-93d8a52f5aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:39429,DS-9345b500-9f2c-431f-b1f8-c9f48f872c0a,DISK], DatanodeInfoWithStorage[127.0.0.1:37081,DS-4a9e249d-8fc6-4ed2-828d-b7b643a9e1b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33009,DS-93cc2288-dc7a-4c9c-8675-801f8f29ba2b,DISK], DatanodeInfoWithStorage[127.0.0.1:42624,DS-923cc798-37b9-4232-bfbd-6943647ff499,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1109839957-172.17.0.17-1595406648947:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37736,DS-adf032bd-feb2-4a7a-add8-fe24594aad4a,DISK], DatanodeInfoWithStorage[127.0.0.1:44888,DS-f74b47eb-7d3a-4d9e-9aa1-3b6a9aa2bfd3,DISK], DatanodeInfoWithStorage[127.0.0.1:34193,DS-d8bebc59-fa58-4d61-a346-9c0c61f81a7b,DISK], DatanodeInfoWithStorage[127.0.0.1:39355,DS-4b09949c-4346-4000-a648-e2a4e3e74b85,DISK], DatanodeInfoWithStorage[127.0.0.1:43153,DS-c2e11deb-83dd-47fa-a7b9-f1e7df671c27,DISK], DatanodeInfoWithStorage[127.0.0.1:36760,DS-8b20aa8e-fae8-4c89-abb0-1fdb43a0f490,DISK], DatanodeInfoWithStorage[127.0.0.1:38971,DS-8616ac48-fb37-4093-8b0b-c606688ddbb2,DISK], DatanodeInfoWithStorage[127.0.0.1:38199,DS-50cd0183-2ec8-4064-ae40-586faf291dc1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1109839957-172.17.0.17-1595406648947:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37736,DS-adf032bd-feb2-4a7a-add8-fe24594aad4a,DISK], DatanodeInfoWithStorage[127.0.0.1:44888,DS-f74b47eb-7d3a-4d9e-9aa1-3b6a9aa2bfd3,DISK], DatanodeInfoWithStorage[127.0.0.1:34193,DS-d8bebc59-fa58-4d61-a346-9c0c61f81a7b,DISK], DatanodeInfoWithStorage[127.0.0.1:39355,DS-4b09949c-4346-4000-a648-e2a4e3e74b85,DISK], DatanodeInfoWithStorage[127.0.0.1:43153,DS-c2e11deb-83dd-47fa-a7b9-f1e7df671c27,DISK], DatanodeInfoWithStorage[127.0.0.1:36760,DS-8b20aa8e-fae8-4c89-abb0-1fdb43a0f490,DISK], DatanodeInfoWithStorage[127.0.0.1:38971,DS-8616ac48-fb37-4093-8b0b-c606688ddbb2,DISK], DatanodeInfoWithStorage[127.0.0.1:38199,DS-50cd0183-2ec8-4064-ae40-586faf291dc1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-698666681-172.17.0.17-1595406785732:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46083,DS-67ca034c-a0f8-409d-a43e-b3bc41dbeb69,DISK], DatanodeInfoWithStorage[127.0.0.1:38663,DS-dd5d6976-e799-4cab-9602-9a53c8cc43fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45355,DS-f4dce0bb-7ba3-4c86-a1bc-b2d01874e350,DISK], DatanodeInfoWithStorage[127.0.0.1:36919,DS-95298ace-54a5-4d5a-aaed-17f7e2e958d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44497,DS-48e52760-6d35-494f-bf60-4148d6845cc8,DISK], DatanodeInfoWithStorage[127.0.0.1:35376,DS-c6171765-740f-4adb-829d-8bd125a73244,DISK], DatanodeInfoWithStorage[127.0.0.1:37622,DS-20cc8e66-2a80-432b-b0a6-c4bd447c0856,DISK], DatanodeInfoWithStorage[127.0.0.1:41871,DS-f018c586-26ee-4825-ab50-c82884e4b078,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-698666681-172.17.0.17-1595406785732:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46083,DS-67ca034c-a0f8-409d-a43e-b3bc41dbeb69,DISK], DatanodeInfoWithStorage[127.0.0.1:38663,DS-dd5d6976-e799-4cab-9602-9a53c8cc43fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45355,DS-f4dce0bb-7ba3-4c86-a1bc-b2d01874e350,DISK], DatanodeInfoWithStorage[127.0.0.1:36919,DS-95298ace-54a5-4d5a-aaed-17f7e2e958d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44497,DS-48e52760-6d35-494f-bf60-4148d6845cc8,DISK], DatanodeInfoWithStorage[127.0.0.1:35376,DS-c6171765-740f-4adb-829d-8bd125a73244,DISK], DatanodeInfoWithStorage[127.0.0.1:37622,DS-20cc8e66-2a80-432b-b0a6-c4bd447c0856,DISK], DatanodeInfoWithStorage[127.0.0.1:41871,DS-f018c586-26ee-4825-ab50-c82884e4b078,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1065289826-172.17.0.17-1595406823533:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43378,DS-ea6f2125-d5a2-4aef-9b71-daf0484ab08a,DISK], DatanodeInfoWithStorage[127.0.0.1:33055,DS-9cfd5131-9240-41f4-ace6-b584c04147ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35147,DS-d0b4b37e-c3db-4c44-80e0-a4431a13ab7c,DISK], DatanodeInfoWithStorage[127.0.0.1:33885,DS-88e5cb59-fc35-428c-99c9-0765f2e2a259,DISK], DatanodeInfoWithStorage[127.0.0.1:45035,DS-30c22cfc-9b5b-469d-bb97-9fbdcb6a07a3,DISK], DatanodeInfoWithStorage[127.0.0.1:38186,DS-39ee55cd-d80e-4905-8619-02b1129c770b,DISK], DatanodeInfoWithStorage[127.0.0.1:43525,DS-8abaafc0-6c12-4432-9870-dcbe9d2e60ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35687,DS-38bf49bc-ba43-4a6e-8c4a-6a1e21463b9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1065289826-172.17.0.17-1595406823533:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43378,DS-ea6f2125-d5a2-4aef-9b71-daf0484ab08a,DISK], DatanodeInfoWithStorage[127.0.0.1:33055,DS-9cfd5131-9240-41f4-ace6-b584c04147ba,DISK], DatanodeInfoWithStorage[127.0.0.1:35147,DS-d0b4b37e-c3db-4c44-80e0-a4431a13ab7c,DISK], DatanodeInfoWithStorage[127.0.0.1:33885,DS-88e5cb59-fc35-428c-99c9-0765f2e2a259,DISK], DatanodeInfoWithStorage[127.0.0.1:45035,DS-30c22cfc-9b5b-469d-bb97-9fbdcb6a07a3,DISK], DatanodeInfoWithStorage[127.0.0.1:38186,DS-39ee55cd-d80e-4905-8619-02b1129c770b,DISK], DatanodeInfoWithStorage[127.0.0.1:43525,DS-8abaafc0-6c12-4432-9870-dcbe9d2e60ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35687,DS-38bf49bc-ba43-4a6e-8c4a-6a1e21463b9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-619876872-172.17.0.17-1595406951739:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39668,DS-56e6b998-e568-413a-a445-9ed1034ef250,DISK], DatanodeInfoWithStorage[127.0.0.1:44999,DS-a06c752e-21c7-43ae-ba74-a9f69004a0d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36998,DS-e7ff9278-4274-4f1e-8b1e-b8d620f41ef3,DISK], DatanodeInfoWithStorage[127.0.0.1:43227,DS-fdfd2878-61ba-4398-baa8-81adde9c320a,DISK], DatanodeInfoWithStorage[127.0.0.1:36688,DS-13f697b1-3a86-485e-b645-530583d8e361,DISK], DatanodeInfoWithStorage[127.0.0.1:42990,DS-862968d8-1693-4b3e-be7f-dbf9be5b9511,DISK], DatanodeInfoWithStorage[127.0.0.1:46501,DS-fd9a301b-1b66-440c-8eda-b99540420e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:35976,DS-8083d201-8a9a-422f-b7ac-9605d920bca6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-619876872-172.17.0.17-1595406951739:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39668,DS-56e6b998-e568-413a-a445-9ed1034ef250,DISK], DatanodeInfoWithStorage[127.0.0.1:44999,DS-a06c752e-21c7-43ae-ba74-a9f69004a0d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36998,DS-e7ff9278-4274-4f1e-8b1e-b8d620f41ef3,DISK], DatanodeInfoWithStorage[127.0.0.1:43227,DS-fdfd2878-61ba-4398-baa8-81adde9c320a,DISK], DatanodeInfoWithStorage[127.0.0.1:36688,DS-13f697b1-3a86-485e-b645-530583d8e361,DISK], DatanodeInfoWithStorage[127.0.0.1:42990,DS-862968d8-1693-4b3e-be7f-dbf9be5b9511,DISK], DatanodeInfoWithStorage[127.0.0.1:46501,DS-fd9a301b-1b66-440c-8eda-b99540420e3c,DISK], DatanodeInfoWithStorage[127.0.0.1:35976,DS-8083d201-8a9a-422f-b7ac-9605d920bca6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1618853354-172.17.0.17-1595407237010:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35035,DS-dd02bd26-b401-48e2-8fb1-c3ec15e1639b,DISK], DatanodeInfoWithStorage[127.0.0.1:38464,DS-24560f9e-dde7-41a4-8cf1-e48e595e6d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:43721,DS-b61e91cc-4250-4fa9-9317-4a7d9d27014c,DISK], DatanodeInfoWithStorage[127.0.0.1:36936,DS-6468fbbd-3996-44aa-8eba-dc4f488625e9,DISK], DatanodeInfoWithStorage[127.0.0.1:39585,DS-9b8c82aa-afac-43e0-a569-66e3508ae99c,DISK], DatanodeInfoWithStorage[127.0.0.1:42966,DS-c0ef46ed-d710-4731-b332-27fd396bf77f,DISK], DatanodeInfoWithStorage[127.0.0.1:41804,DS-f8546594-5d3c-4bd6-9b22-4cd7f395747b,DISK], DatanodeInfoWithStorage[127.0.0.1:44634,DS-f2611b41-1a31-4c21-8216-9ee42c4e419b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1618853354-172.17.0.17-1595407237010:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35035,DS-dd02bd26-b401-48e2-8fb1-c3ec15e1639b,DISK], DatanodeInfoWithStorage[127.0.0.1:38464,DS-24560f9e-dde7-41a4-8cf1-e48e595e6d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:43721,DS-b61e91cc-4250-4fa9-9317-4a7d9d27014c,DISK], DatanodeInfoWithStorage[127.0.0.1:36936,DS-6468fbbd-3996-44aa-8eba-dc4f488625e9,DISK], DatanodeInfoWithStorage[127.0.0.1:39585,DS-9b8c82aa-afac-43e0-a569-66e3508ae99c,DISK], DatanodeInfoWithStorage[127.0.0.1:42966,DS-c0ef46ed-d710-4731-b332-27fd396bf77f,DISK], DatanodeInfoWithStorage[127.0.0.1:41804,DS-f8546594-5d3c-4bd6-9b22-4cd7f395747b,DISK], DatanodeInfoWithStorage[127.0.0.1:44634,DS-f2611b41-1a31-4c21-8216-9ee42c4e419b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1982136539-172.17.0.17-1595407275770:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38152,DS-164e6d55-8fcc-4f6b-ab47-e651110b3936,DISK], DatanodeInfoWithStorage[127.0.0.1:40789,DS-e8210d38-f44b-40e5-9207-c633eef569b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44179,DS-d2dfa88e-e2f7-4a03-9f62-ebd4a7831e37,DISK], DatanodeInfoWithStorage[127.0.0.1:35257,DS-0f11b837-b0d3-4c8b-b89d-55717a603748,DISK], DatanodeInfoWithStorage[127.0.0.1:40386,DS-3c2cfd1e-d850-4bcd-97f5-deafb89578e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36820,DS-cdd05434-c3b4-4047-b946-1857c8bb9e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:42576,DS-239ad102-2157-4982-9791-2d1a534828e1,DISK], DatanodeInfoWithStorage[127.0.0.1:44010,DS-c7c1d29e-12da-470d-ae6f-32aafc3d868b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1982136539-172.17.0.17-1595407275770:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38152,DS-164e6d55-8fcc-4f6b-ab47-e651110b3936,DISK], DatanodeInfoWithStorage[127.0.0.1:40789,DS-e8210d38-f44b-40e5-9207-c633eef569b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44179,DS-d2dfa88e-e2f7-4a03-9f62-ebd4a7831e37,DISK], DatanodeInfoWithStorage[127.0.0.1:35257,DS-0f11b837-b0d3-4c8b-b89d-55717a603748,DISK], DatanodeInfoWithStorage[127.0.0.1:40386,DS-3c2cfd1e-d850-4bcd-97f5-deafb89578e5,DISK], DatanodeInfoWithStorage[127.0.0.1:36820,DS-cdd05434-c3b4-4047-b946-1857c8bb9e8c,DISK], DatanodeInfoWithStorage[127.0.0.1:42576,DS-239ad102-2157-4982-9791-2d1a534828e1,DISK], DatanodeInfoWithStorage[127.0.0.1:44010,DS-c7c1d29e-12da-470d-ae6f-32aafc3d868b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-899100941-172.17.0.17-1595407383186:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37354,DS-380b7944-664c-4712-9bef-175e9017c270,DISK], DatanodeInfoWithStorage[127.0.0.1:39560,DS-56af6ba6-49aa-4c2b-a13f-f82e6b81cc5a,DISK], DatanodeInfoWithStorage[127.0.0.1:42125,DS-ec85443e-24c8-4ce4-bf69-62588f2a5c45,DISK], DatanodeInfoWithStorage[127.0.0.1:34850,DS-f15f80f8-5d8f-442e-9d5b-ff70016c17c3,DISK], DatanodeInfoWithStorage[127.0.0.1:36662,DS-c2af0c89-fd54-4ac2-a54c-a54db5bdc6c3,DISK], DatanodeInfoWithStorage[127.0.0.1:46052,DS-b0bbfee3-3292-4a09-b8e6-57e8d12e54a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44812,DS-a8c6c0fd-234e-414a-b62c-669054b002fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45217,DS-17ab5876-1487-463a-a1ac-82cf77506bc8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-899100941-172.17.0.17-1595407383186:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37354,DS-380b7944-664c-4712-9bef-175e9017c270,DISK], DatanodeInfoWithStorage[127.0.0.1:39560,DS-56af6ba6-49aa-4c2b-a13f-f82e6b81cc5a,DISK], DatanodeInfoWithStorage[127.0.0.1:42125,DS-ec85443e-24c8-4ce4-bf69-62588f2a5c45,DISK], DatanodeInfoWithStorage[127.0.0.1:34850,DS-f15f80f8-5d8f-442e-9d5b-ff70016c17c3,DISK], DatanodeInfoWithStorage[127.0.0.1:36662,DS-c2af0c89-fd54-4ac2-a54c-a54db5bdc6c3,DISK], DatanodeInfoWithStorage[127.0.0.1:46052,DS-b0bbfee3-3292-4a09-b8e6-57e8d12e54a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44812,DS-a8c6c0fd-234e-414a-b62c-669054b002fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45217,DS-17ab5876-1487-463a-a1ac-82cf77506bc8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1429266671-172.17.0.17-1595407696680:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34721,DS-4e6869cb-1dd3-4f9d-8c82-4fd5b9aabb5f,DISK], DatanodeInfoWithStorage[127.0.0.1:44742,DS-312dee38-0932-40a4-9d42-33e39888fd81,DISK], DatanodeInfoWithStorage[127.0.0.1:43574,DS-df44ef98-6f5e-4e3b-a178-a4f91a557a88,DISK], DatanodeInfoWithStorage[127.0.0.1:36595,DS-f1ae22f7-6217-43df-8d87-f015fd7f776d,DISK], DatanodeInfoWithStorage[127.0.0.1:34146,DS-d74c3e01-21a6-469d-9ccc-10e8a5d4c20d,DISK], DatanodeInfoWithStorage[127.0.0.1:43607,DS-f9d2c380-1ee3-44b5-888c-27153517c50a,DISK], DatanodeInfoWithStorage[127.0.0.1:44683,DS-aec6e471-407e-4074-9ff1-8a113dc33c52,DISK], DatanodeInfoWithStorage[127.0.0.1:35033,DS-9b94722d-4da0-4dec-8db3-d0b3ad5cab2f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1429266671-172.17.0.17-1595407696680:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34721,DS-4e6869cb-1dd3-4f9d-8c82-4fd5b9aabb5f,DISK], DatanodeInfoWithStorage[127.0.0.1:44742,DS-312dee38-0932-40a4-9d42-33e39888fd81,DISK], DatanodeInfoWithStorage[127.0.0.1:43574,DS-df44ef98-6f5e-4e3b-a178-a4f91a557a88,DISK], DatanodeInfoWithStorage[127.0.0.1:36595,DS-f1ae22f7-6217-43df-8d87-f015fd7f776d,DISK], DatanodeInfoWithStorage[127.0.0.1:34146,DS-d74c3e01-21a6-469d-9ccc-10e8a5d4c20d,DISK], DatanodeInfoWithStorage[127.0.0.1:43607,DS-f9d2c380-1ee3-44b5-888c-27153517c50a,DISK], DatanodeInfoWithStorage[127.0.0.1:44683,DS-aec6e471-407e-4074-9ff1-8a113dc33c52,DISK], DatanodeInfoWithStorage[127.0.0.1:35033,DS-9b94722d-4da0-4dec-8db3-d0b3ad5cab2f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1090960519-172.17.0.17-1595407767527:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33902,DS-ad160901-19e6-4956-ac51-7c211e086f06,DISK], DatanodeInfoWithStorage[127.0.0.1:46596,DS-48791839-785a-402c-89b9-e1deb395c9bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37890,DS-bd206a37-989e-4802-9eb7-c6e57c8cb6dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41678,DS-572fa8e6-39d9-4d0d-a242-eecfadfbf267,DISK], DatanodeInfoWithStorage[127.0.0.1:36579,DS-850dd49f-2cf9-451c-9a0e-8a507da1807f,DISK], DatanodeInfoWithStorage[127.0.0.1:44450,DS-c1f113c0-8d39-4aa2-84fe-1364d58123c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35400,DS-7614be2b-258d-462a-855b-88ac69630395,DISK], DatanodeInfoWithStorage[127.0.0.1:34820,DS-f6fb48e6-f47c-41c9-bedc-f8c0c7806548,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1090960519-172.17.0.17-1595407767527:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33902,DS-ad160901-19e6-4956-ac51-7c211e086f06,DISK], DatanodeInfoWithStorage[127.0.0.1:46596,DS-48791839-785a-402c-89b9-e1deb395c9bd,DISK], DatanodeInfoWithStorage[127.0.0.1:37890,DS-bd206a37-989e-4802-9eb7-c6e57c8cb6dc,DISK], DatanodeInfoWithStorage[127.0.0.1:41678,DS-572fa8e6-39d9-4d0d-a242-eecfadfbf267,DISK], DatanodeInfoWithStorage[127.0.0.1:36579,DS-850dd49f-2cf9-451c-9a0e-8a507da1807f,DISK], DatanodeInfoWithStorage[127.0.0.1:44450,DS-c1f113c0-8d39-4aa2-84fe-1364d58123c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35400,DS-7614be2b-258d-462a-855b-88ac69630395,DISK], DatanodeInfoWithStorage[127.0.0.1:34820,DS-f6fb48e6-f47c-41c9-bedc-f8c0c7806548,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-248277335-172.17.0.17-1595407799788:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38695,DS-b43cbc50-7295-4941-b352-18ea51109334,DISK], DatanodeInfoWithStorage[127.0.0.1:43324,DS-04b6dfe4-ddd1-45c8-82ce-3605c47f2277,DISK], DatanodeInfoWithStorage[127.0.0.1:36528,DS-59d9f48f-bd7b-4f91-9754-fe0213a650c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45009,DS-5a24f146-749f-4b3a-bc10-3c7d15a5ecd9,DISK], DatanodeInfoWithStorage[127.0.0.1:42573,DS-bc27589b-43d2-44a4-a9fd-1b0cf1a679af,DISK], DatanodeInfoWithStorage[127.0.0.1:33287,DS-9e19c223-5818-458f-9816-c5879fcd553c,DISK], DatanodeInfoWithStorage[127.0.0.1:38279,DS-ee754abb-1fbf-4c38-b726-4339f45f44fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42656,DS-13bd03da-311f-47fc-a10d-375d03472ee2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-248277335-172.17.0.17-1595407799788:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38695,DS-b43cbc50-7295-4941-b352-18ea51109334,DISK], DatanodeInfoWithStorage[127.0.0.1:43324,DS-04b6dfe4-ddd1-45c8-82ce-3605c47f2277,DISK], DatanodeInfoWithStorage[127.0.0.1:36528,DS-59d9f48f-bd7b-4f91-9754-fe0213a650c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45009,DS-5a24f146-749f-4b3a-bc10-3c7d15a5ecd9,DISK], DatanodeInfoWithStorage[127.0.0.1:42573,DS-bc27589b-43d2-44a4-a9fd-1b0cf1a679af,DISK], DatanodeInfoWithStorage[127.0.0.1:33287,DS-9e19c223-5818-458f-9816-c5879fcd553c,DISK], DatanodeInfoWithStorage[127.0.0.1:38279,DS-ee754abb-1fbf-4c38-b726-4339f45f44fb,DISK], DatanodeInfoWithStorage[127.0.0.1:42656,DS-13bd03da-311f-47fc-a10d-375d03472ee2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-577796602-172.17.0.17-1595408021239:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45097,DS-70cbaa19-91ae-47fa-a5d9-21ba7e5b74a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46007,DS-ba02718e-1e69-4165-9fed-71ee4a29c493,DISK], DatanodeInfoWithStorage[127.0.0.1:32921,DS-c97250f7-8f0a-4db0-a173-887089822817,DISK], DatanodeInfoWithStorage[127.0.0.1:38314,DS-9f88bb05-0bc3-4fac-aa01-31f00c2f0439,DISK], DatanodeInfoWithStorage[127.0.0.1:36908,DS-cc0728db-e8e6-46ec-8731-0c86e2372374,DISK], DatanodeInfoWithStorage[127.0.0.1:35010,DS-0bb3914c-de95-4b8e-9678-477eab9c5ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:44353,DS-d6e48027-f61e-4287-a735-d2fcf38356d3,DISK], DatanodeInfoWithStorage[127.0.0.1:43448,DS-edab8aba-3dd1-4d7f-b13f-fa5d8d35099d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-577796602-172.17.0.17-1595408021239:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45097,DS-70cbaa19-91ae-47fa-a5d9-21ba7e5b74a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46007,DS-ba02718e-1e69-4165-9fed-71ee4a29c493,DISK], DatanodeInfoWithStorage[127.0.0.1:32921,DS-c97250f7-8f0a-4db0-a173-887089822817,DISK], DatanodeInfoWithStorage[127.0.0.1:38314,DS-9f88bb05-0bc3-4fac-aa01-31f00c2f0439,DISK], DatanodeInfoWithStorage[127.0.0.1:36908,DS-cc0728db-e8e6-46ec-8731-0c86e2372374,DISK], DatanodeInfoWithStorage[127.0.0.1:35010,DS-0bb3914c-de95-4b8e-9678-477eab9c5ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:44353,DS-d6e48027-f61e-4287-a735-d2fcf38356d3,DISK], DatanodeInfoWithStorage[127.0.0.1:43448,DS-edab8aba-3dd1-4d7f-b13f-fa5d8d35099d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-413751576-172.17.0.17-1595408090190:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39365,DS-df02c9f3-717d-4416-9fde-f3473574add3,DISK], DatanodeInfoWithStorage[127.0.0.1:44870,DS-b94d999a-24c6-4ba4-b58c-12b4e348fb2d,DISK], DatanodeInfoWithStorage[127.0.0.1:34954,DS-4e89e1b6-67d3-4103-a8db-6a69ed4e4032,DISK], DatanodeInfoWithStorage[127.0.0.1:46014,DS-92236646-c3e8-47f9-9749-8a748345a233,DISK], DatanodeInfoWithStorage[127.0.0.1:41132,DS-410ee527-dea2-4c8c-aaa9-d4f8d309b9a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44047,DS-c0196705-ad37-4335-9379-86f39122f5cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36858,DS-b4122ba1-abb4-44a0-b1e0-8122712fcba1,DISK], DatanodeInfoWithStorage[127.0.0.1:33286,DS-3211efc1-41d2-4e7b-b4b6-aecbbfc0ccb7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-413751576-172.17.0.17-1595408090190:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39365,DS-df02c9f3-717d-4416-9fde-f3473574add3,DISK], DatanodeInfoWithStorage[127.0.0.1:44870,DS-b94d999a-24c6-4ba4-b58c-12b4e348fb2d,DISK], DatanodeInfoWithStorage[127.0.0.1:34954,DS-4e89e1b6-67d3-4103-a8db-6a69ed4e4032,DISK], DatanodeInfoWithStorage[127.0.0.1:46014,DS-92236646-c3e8-47f9-9749-8a748345a233,DISK], DatanodeInfoWithStorage[127.0.0.1:41132,DS-410ee527-dea2-4c8c-aaa9-d4f8d309b9a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44047,DS-c0196705-ad37-4335-9379-86f39122f5cb,DISK], DatanodeInfoWithStorage[127.0.0.1:36858,DS-b4122ba1-abb4-44a0-b1e0-8122712fcba1,DISK], DatanodeInfoWithStorage[127.0.0.1:33286,DS-3211efc1-41d2-4e7b-b4b6-aecbbfc0ccb7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-435312143-172.17.0.17-1595408162454:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42473,DS-bf5033ad-ebc4-4d30-a3f0-bc6808ae61b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41752,DS-f58a94ed-ef6a-4728-8ed8-51ac48360537,DISK], DatanodeInfoWithStorage[127.0.0.1:44648,DS-d158b8f9-cce3-4a72-a380-071686656bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:43756,DS-e3f8d6cc-0ae4-467f-8c6a-ccae2d8e43af,DISK], DatanodeInfoWithStorage[127.0.0.1:34556,DS-b5a09154-6fe5-48d1-b010-55f31d4182ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37297,DS-d41fa017-f7c1-42eb-9bc0-cd8fc6164bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:42499,DS-04d90d3d-8828-4645-82df-f28873765944,DISK], DatanodeInfoWithStorage[127.0.0.1:45625,DS-4a7ab146-6149-4a7d-b1f1-eae35e4929f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-435312143-172.17.0.17-1595408162454:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42473,DS-bf5033ad-ebc4-4d30-a3f0-bc6808ae61b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41752,DS-f58a94ed-ef6a-4728-8ed8-51ac48360537,DISK], DatanodeInfoWithStorage[127.0.0.1:44648,DS-d158b8f9-cce3-4a72-a380-071686656bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:43756,DS-e3f8d6cc-0ae4-467f-8c6a-ccae2d8e43af,DISK], DatanodeInfoWithStorage[127.0.0.1:34556,DS-b5a09154-6fe5-48d1-b010-55f31d4182ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37297,DS-d41fa017-f7c1-42eb-9bc0-cd8fc6164bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:42499,DS-04d90d3d-8828-4645-82df-f28873765944,DISK], DatanodeInfoWithStorage[127.0.0.1:45625,DS-4a7ab146-6149-4a7d-b1f1-eae35e4929f8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-499322004-172.17.0.17-1595408203396:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42536,DS-1714708a-2222-431c-97d3-aad7eaba3dc4,DISK], DatanodeInfoWithStorage[127.0.0.1:38783,DS-b9f61b47-d4e0-4c15-81c8-4531bc8821a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39206,DS-cb63e9ce-cb92-490d-bf10-c829ba4e4c57,DISK], DatanodeInfoWithStorage[127.0.0.1:33911,DS-109f6dd1-0077-41c7-868b-c812e43d9e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:46379,DS-f635265d-a6e4-408c-9364-d1e70eb8f040,DISK], DatanodeInfoWithStorage[127.0.0.1:34340,DS-58bb7145-54cd-4e25-b9e4-e7d537bbc6c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34371,DS-d4e0ff2e-c041-4b07-9199-cb8db1abaa5f,DISK], DatanodeInfoWithStorage[127.0.0.1:38667,DS-d56a2405-1109-46b5-b61e-f2838d6971c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-499322004-172.17.0.17-1595408203396:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42536,DS-1714708a-2222-431c-97d3-aad7eaba3dc4,DISK], DatanodeInfoWithStorage[127.0.0.1:38783,DS-b9f61b47-d4e0-4c15-81c8-4531bc8821a6,DISK], DatanodeInfoWithStorage[127.0.0.1:39206,DS-cb63e9ce-cb92-490d-bf10-c829ba4e4c57,DISK], DatanodeInfoWithStorage[127.0.0.1:33911,DS-109f6dd1-0077-41c7-868b-c812e43d9e0c,DISK], DatanodeInfoWithStorage[127.0.0.1:46379,DS-f635265d-a6e4-408c-9364-d1e70eb8f040,DISK], DatanodeInfoWithStorage[127.0.0.1:34340,DS-58bb7145-54cd-4e25-b9e4-e7d537bbc6c1,DISK], DatanodeInfoWithStorage[127.0.0.1:34371,DS-d4e0ff2e-c041-4b07-9199-cb8db1abaa5f,DISK], DatanodeInfoWithStorage[127.0.0.1:38667,DS-d56a2405-1109-46b5-b61e-f2838d6971c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1161538317-172.17.0.17-1595408272374:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43380,DS-d5f5358e-62c6-4cc4-bbef-4fb26d931154,DISK], DatanodeInfoWithStorage[127.0.0.1:43391,DS-cd826ced-8101-48cb-bc37-14d2e7d353da,DISK], DatanodeInfoWithStorage[127.0.0.1:34576,DS-e143c241-ccbf-4abf-a1c5-e43662784200,DISK], DatanodeInfoWithStorage[127.0.0.1:41309,DS-fd193a6e-d309-48f1-8434-1c965f0082da,DISK], DatanodeInfoWithStorage[127.0.0.1:34677,DS-f4c50b62-3cd1-4a06-9059-4b429d21a426,DISK], DatanodeInfoWithStorage[127.0.0.1:36095,DS-c2dd0258-de53-4ca7-871d-0dcd6bc44717,DISK], DatanodeInfoWithStorage[127.0.0.1:36126,DS-cee9e304-8a6c-49f3-8ccb-5c2263150f5e,DISK], DatanodeInfoWithStorage[127.0.0.1:38031,DS-da5526be-bf5b-45de-a737-0bc1c15df7fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1161538317-172.17.0.17-1595408272374:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43380,DS-d5f5358e-62c6-4cc4-bbef-4fb26d931154,DISK], DatanodeInfoWithStorage[127.0.0.1:43391,DS-cd826ced-8101-48cb-bc37-14d2e7d353da,DISK], DatanodeInfoWithStorage[127.0.0.1:34576,DS-e143c241-ccbf-4abf-a1c5-e43662784200,DISK], DatanodeInfoWithStorage[127.0.0.1:41309,DS-fd193a6e-d309-48f1-8434-1c965f0082da,DISK], DatanodeInfoWithStorage[127.0.0.1:34677,DS-f4c50b62-3cd1-4a06-9059-4b429d21a426,DISK], DatanodeInfoWithStorage[127.0.0.1:36095,DS-c2dd0258-de53-4ca7-871d-0dcd6bc44717,DISK], DatanodeInfoWithStorage[127.0.0.1:36126,DS-cee9e304-8a6c-49f3-8ccb-5c2263150f5e,DISK], DatanodeInfoWithStorage[127.0.0.1:38031,DS-da5526be-bf5b-45de-a737-0bc1c15df7fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1270932547-172.17.0.17-1595408308545:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46218,DS-8c6ccabd-2e97-4a3f-9130-caa55f25b21a,DISK], DatanodeInfoWithStorage[127.0.0.1:39691,DS-565b0553-a75e-4339-bae6-0d50c3aed575,DISK], DatanodeInfoWithStorage[127.0.0.1:43978,DS-f2600b82-f654-4dc1-909d-1e05c2ff173e,DISK], DatanodeInfoWithStorage[127.0.0.1:44691,DS-853589ba-a99f-4d55-a086-9663ca6c8139,DISK], DatanodeInfoWithStorage[127.0.0.1:36110,DS-91a090bf-a876-48c9-b7c9-c924b959bb15,DISK], DatanodeInfoWithStorage[127.0.0.1:33790,DS-04b2159b-84c8-4cfe-a557-32fa8a04d36c,DISK], DatanodeInfoWithStorage[127.0.0.1:37319,DS-55603763-0de0-4303-9b6b-fe5ab6a0ba9d,DISK], DatanodeInfoWithStorage[127.0.0.1:43463,DS-071c0fd1-65a5-49fe-89c9-a350559818f7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1270932547-172.17.0.17-1595408308545:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46218,DS-8c6ccabd-2e97-4a3f-9130-caa55f25b21a,DISK], DatanodeInfoWithStorage[127.0.0.1:39691,DS-565b0553-a75e-4339-bae6-0d50c3aed575,DISK], DatanodeInfoWithStorage[127.0.0.1:43978,DS-f2600b82-f654-4dc1-909d-1e05c2ff173e,DISK], DatanodeInfoWithStorage[127.0.0.1:44691,DS-853589ba-a99f-4d55-a086-9663ca6c8139,DISK], DatanodeInfoWithStorage[127.0.0.1:36110,DS-91a090bf-a876-48c9-b7c9-c924b959bb15,DISK], DatanodeInfoWithStorage[127.0.0.1:33790,DS-04b2159b-84c8-4cfe-a557-32fa8a04d36c,DISK], DatanodeInfoWithStorage[127.0.0.1:37319,DS-55603763-0de0-4303-9b6b-fe5ab6a0ba9d,DISK], DatanodeInfoWithStorage[127.0.0.1:43463,DS-071c0fd1-65a5-49fe-89c9-a350559818f7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1973702934-172.17.0.17-1595408414457:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33829,DS-02ff6701-2c68-4857-ba8d-76f21be21e70,DISK], DatanodeInfoWithStorage[127.0.0.1:33217,DS-f11e66ba-93ce-4e56-ab8d-a27646ccdb58,DISK], DatanodeInfoWithStorage[127.0.0.1:35398,DS-ce7ab564-aece-45b7-8f94-1aca42051242,DISK], DatanodeInfoWithStorage[127.0.0.1:37133,DS-cc7db6e3-a3d4-49d4-bc19-e034f78e80ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42997,DS-241f2aa2-9cfa-494e-856a-546e4f023a1b,DISK], DatanodeInfoWithStorage[127.0.0.1:38754,DS-27f9443d-86d1-4886-834a-6a3a8ce952df,DISK], DatanodeInfoWithStorage[127.0.0.1:43296,DS-033da0ec-8eeb-42ac-b8ee-3da44938e4b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36703,DS-b67adcd4-2cf3-400f-9d82-e662a1218374,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1973702934-172.17.0.17-1595408414457:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33829,DS-02ff6701-2c68-4857-ba8d-76f21be21e70,DISK], DatanodeInfoWithStorage[127.0.0.1:33217,DS-f11e66ba-93ce-4e56-ab8d-a27646ccdb58,DISK], DatanodeInfoWithStorage[127.0.0.1:35398,DS-ce7ab564-aece-45b7-8f94-1aca42051242,DISK], DatanodeInfoWithStorage[127.0.0.1:37133,DS-cc7db6e3-a3d4-49d4-bc19-e034f78e80ce,DISK], DatanodeInfoWithStorage[127.0.0.1:42997,DS-241f2aa2-9cfa-494e-856a-546e4f023a1b,DISK], DatanodeInfoWithStorage[127.0.0.1:38754,DS-27f9443d-86d1-4886-834a-6a3a8ce952df,DISK], DatanodeInfoWithStorage[127.0.0.1:43296,DS-033da0ec-8eeb-42ac-b8ee-3da44938e4b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36703,DS-b67adcd4-2cf3-400f-9d82-e662a1218374,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1412441636-172.17.0.17-1595408818386:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45137,DS-85e71768-5055-45e4-ac30-7afc7ff36483,DISK], DatanodeInfoWithStorage[127.0.0.1:38660,DS-ce2e1aae-3830-4177-8b48-0fd5a13a180c,DISK], DatanodeInfoWithStorage[127.0.0.1:38041,DS-48a7a971-dd18-4354-be3e-1ea2aae047f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44477,DS-5f5ae815-dcb9-4eb6-b937-e645b8126085,DISK], DatanodeInfoWithStorage[127.0.0.1:40097,DS-30a09c45-5650-434f-a32f-57708d04c6b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45738,DS-ec1aed0a-9ffd-48d0-8afa-3104a2be61d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42592,DS-f28d0af1-f581-4de1-96e0-39ea03ac740c,DISK], DatanodeInfoWithStorage[127.0.0.1:34864,DS-1e725a07-6ac1-456c-9509-dc49622b5301,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1412441636-172.17.0.17-1595408818386:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45137,DS-85e71768-5055-45e4-ac30-7afc7ff36483,DISK], DatanodeInfoWithStorage[127.0.0.1:38660,DS-ce2e1aae-3830-4177-8b48-0fd5a13a180c,DISK], DatanodeInfoWithStorage[127.0.0.1:38041,DS-48a7a971-dd18-4354-be3e-1ea2aae047f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44477,DS-5f5ae815-dcb9-4eb6-b937-e645b8126085,DISK], DatanodeInfoWithStorage[127.0.0.1:40097,DS-30a09c45-5650-434f-a32f-57708d04c6b3,DISK], DatanodeInfoWithStorage[127.0.0.1:45738,DS-ec1aed0a-9ffd-48d0-8afa-3104a2be61d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42592,DS-f28d0af1-f581-4de1-96e0-39ea03ac740c,DISK], DatanodeInfoWithStorage[127.0.0.1:34864,DS-1e725a07-6ac1-456c-9509-dc49622b5301,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-331656000-172.17.0.17-1595408858733:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36885,DS-0388a2ad-9899-4158-9332-a1fbb2a798c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43026,DS-c81d3422-a7be-4ee5-8814-a0389123de8b,DISK], DatanodeInfoWithStorage[127.0.0.1:44183,DS-8ce05d00-fb61-42cf-ab93-8a7184165657,DISK], DatanodeInfoWithStorage[127.0.0.1:34596,DS-db6b6ed8-4681-4219-b0f6-fd7868dbb1cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46165,DS-8beab3e5-8fdc-4d4e-85fd-9141ab52b9aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38876,DS-41a4d20f-0ee2-4f9e-8701-6302a3dc2645,DISK], DatanodeInfoWithStorage[127.0.0.1:43282,DS-0d3c2ec8-2af4-47c0-8294-9dea489b6a22,DISK], DatanodeInfoWithStorage[127.0.0.1:42952,DS-451febd8-5fe9-49bc-b43a-2b544d50dcc2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-331656000-172.17.0.17-1595408858733:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36885,DS-0388a2ad-9899-4158-9332-a1fbb2a798c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43026,DS-c81d3422-a7be-4ee5-8814-a0389123de8b,DISK], DatanodeInfoWithStorage[127.0.0.1:44183,DS-8ce05d00-fb61-42cf-ab93-8a7184165657,DISK], DatanodeInfoWithStorage[127.0.0.1:34596,DS-db6b6ed8-4681-4219-b0f6-fd7868dbb1cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46165,DS-8beab3e5-8fdc-4d4e-85fd-9141ab52b9aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38876,DS-41a4d20f-0ee2-4f9e-8701-6302a3dc2645,DISK], DatanodeInfoWithStorage[127.0.0.1:43282,DS-0d3c2ec8-2af4-47c0-8294-9dea489b6a22,DISK], DatanodeInfoWithStorage[127.0.0.1:42952,DS-451febd8-5fe9-49bc-b43a-2b544d50dcc2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1732666697-172.17.0.17-1595408934264:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41457,DS-12046c99-8653-47a4-9695-ceaa26be2bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:38176,DS-ad7816b6-f831-40c6-ab0c-a7cf8a31278e,DISK], DatanodeInfoWithStorage[127.0.0.1:43991,DS-f6f60f39-68ae-467a-9a89-97f6d26178d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46118,DS-9b4d3485-eb7f-442a-9426-5a74cb89b44c,DISK], DatanodeInfoWithStorage[127.0.0.1:33073,DS-86d32352-2425-4f4b-96e9-4e0aa6f3f146,DISK], DatanodeInfoWithStorage[127.0.0.1:35472,DS-a8cebf7f-c37a-4dea-8291-ec485b7ed3bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45322,DS-ae82c5d7-b903-493a-84fd-5bef7bef69f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42934,DS-d8c367f4-807e-4843-8ad5-97d555953ee1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1732666697-172.17.0.17-1595408934264:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41457,DS-12046c99-8653-47a4-9695-ceaa26be2bd3,DISK], DatanodeInfoWithStorage[127.0.0.1:38176,DS-ad7816b6-f831-40c6-ab0c-a7cf8a31278e,DISK], DatanodeInfoWithStorage[127.0.0.1:43991,DS-f6f60f39-68ae-467a-9a89-97f6d26178d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46118,DS-9b4d3485-eb7f-442a-9426-5a74cb89b44c,DISK], DatanodeInfoWithStorage[127.0.0.1:33073,DS-86d32352-2425-4f4b-96e9-4e0aa6f3f146,DISK], DatanodeInfoWithStorage[127.0.0.1:35472,DS-a8cebf7f-c37a-4dea-8291-ec485b7ed3bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45322,DS-ae82c5d7-b903-493a-84fd-5bef7bef69f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42934,DS-d8c367f4-807e-4843-8ad5-97d555953ee1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1141288975-172.17.0.17-1595409188224:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41996,DS-b3e24224-5bb6-480e-8942-88b5b963be0c,DISK], DatanodeInfoWithStorage[127.0.0.1:41736,DS-8c1e469e-40dd-4d4b-8b26-af74a41c246b,DISK], DatanodeInfoWithStorage[127.0.0.1:38961,DS-11057dc0-114d-460f-855b-6dd38031c2e7,DISK], DatanodeInfoWithStorage[127.0.0.1:39390,DS-ba96ab5a-a4b9-4e6b-b9d8-1be70b456eea,DISK], DatanodeInfoWithStorage[127.0.0.1:44284,DS-50d72d55-e56d-49bd-9b06-e71e3fac0f4a,DISK], DatanodeInfoWithStorage[127.0.0.1:44859,DS-54546b42-4bda-4690-9de8-133bf8a818c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45144,DS-75646b7a-d174-4b83-b646-cb459d5add01,DISK], DatanodeInfoWithStorage[127.0.0.1:41761,DS-b82528ca-0dcc-479a-8280-a94b8d478894,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1141288975-172.17.0.17-1595409188224:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41996,DS-b3e24224-5bb6-480e-8942-88b5b963be0c,DISK], DatanodeInfoWithStorage[127.0.0.1:41736,DS-8c1e469e-40dd-4d4b-8b26-af74a41c246b,DISK], DatanodeInfoWithStorage[127.0.0.1:38961,DS-11057dc0-114d-460f-855b-6dd38031c2e7,DISK], DatanodeInfoWithStorage[127.0.0.1:39390,DS-ba96ab5a-a4b9-4e6b-b9d8-1be70b456eea,DISK], DatanodeInfoWithStorage[127.0.0.1:44284,DS-50d72d55-e56d-49bd-9b06-e71e3fac0f4a,DISK], DatanodeInfoWithStorage[127.0.0.1:44859,DS-54546b42-4bda-4690-9de8-133bf8a818c8,DISK], DatanodeInfoWithStorage[127.0.0.1:45144,DS-75646b7a-d174-4b83-b646-cb459d5add01,DISK], DatanodeInfoWithStorage[127.0.0.1:41761,DS-b82528ca-0dcc-479a-8280-a94b8d478894,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-363854759-172.17.0.17-1595409235100:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45602,DS-d3b33aa8-f0e4-422f-9387-0e276adb25f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40161,DS-03815c63-cac5-4d1b-8e88-671e39265cd7,DISK], DatanodeInfoWithStorage[127.0.0.1:44610,DS-07797aa3-228b-462e-bb86-01acda2a0bef,DISK], DatanodeInfoWithStorage[127.0.0.1:46330,DS-c748a552-7539-4c40-8c73-9f6d6491fb3e,DISK], DatanodeInfoWithStorage[127.0.0.1:39064,DS-5879fa40-6360-4052-808d-c5c48e9bc1e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45937,DS-b4d82d44-98b1-4011-bef1-79be8a4dc185,DISK], DatanodeInfoWithStorage[127.0.0.1:37363,DS-e01356d2-4f4d-4fcd-8d1b-d933850b30a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41883,DS-1d5041b0-19fd-490f-ade3-9869ce87d7f5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-363854759-172.17.0.17-1595409235100:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45602,DS-d3b33aa8-f0e4-422f-9387-0e276adb25f3,DISK], DatanodeInfoWithStorage[127.0.0.1:40161,DS-03815c63-cac5-4d1b-8e88-671e39265cd7,DISK], DatanodeInfoWithStorage[127.0.0.1:44610,DS-07797aa3-228b-462e-bb86-01acda2a0bef,DISK], DatanodeInfoWithStorage[127.0.0.1:46330,DS-c748a552-7539-4c40-8c73-9f6d6491fb3e,DISK], DatanodeInfoWithStorage[127.0.0.1:39064,DS-5879fa40-6360-4052-808d-c5c48e9bc1e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45937,DS-b4d82d44-98b1-4011-bef1-79be8a4dc185,DISK], DatanodeInfoWithStorage[127.0.0.1:37363,DS-e01356d2-4f4d-4fcd-8d1b-d933850b30a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41883,DS-1d5041b0-19fd-490f-ade3-9869ce87d7f5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1537013937-172.17.0.17-1595409269320:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43625,DS-3f1af3de-74c1-40d0-bf0d-a9063ad8d16b,DISK], DatanodeInfoWithStorage[127.0.0.1:35271,DS-749d9907-bb39-46f5-9b1f-67cf8fc077d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35912,DS-f2bfe1bc-c5c9-4ed9-950e-205d3b78d551,DISK], DatanodeInfoWithStorage[127.0.0.1:46104,DS-453f7efc-90ad-4307-ac4b-7229a6656c56,DISK], DatanodeInfoWithStorage[127.0.0.1:38463,DS-058c495d-60fd-44be-854d-c8b95b32d8ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45184,DS-d0cc2f7f-e93e-4fb7-bba2-c196500efa50,DISK], DatanodeInfoWithStorage[127.0.0.1:35114,DS-58468358-8503-4dcb-a529-ca9f5096cacf,DISK], DatanodeInfoWithStorage[127.0.0.1:36177,DS-805a40c1-eb73-4698-9dd3-badd5e1e51cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1537013937-172.17.0.17-1595409269320:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43625,DS-3f1af3de-74c1-40d0-bf0d-a9063ad8d16b,DISK], DatanodeInfoWithStorage[127.0.0.1:35271,DS-749d9907-bb39-46f5-9b1f-67cf8fc077d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35912,DS-f2bfe1bc-c5c9-4ed9-950e-205d3b78d551,DISK], DatanodeInfoWithStorage[127.0.0.1:46104,DS-453f7efc-90ad-4307-ac4b-7229a6656c56,DISK], DatanodeInfoWithStorage[127.0.0.1:38463,DS-058c495d-60fd-44be-854d-c8b95b32d8ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45184,DS-d0cc2f7f-e93e-4fb7-bba2-c196500efa50,DISK], DatanodeInfoWithStorage[127.0.0.1:35114,DS-58468358-8503-4dcb-a529-ca9f5096cacf,DISK], DatanodeInfoWithStorage[127.0.0.1:36177,DS-805a40c1-eb73-4698-9dd3-badd5e1e51cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1806825145-172.17.0.17-1595409726682:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40127,DS-1394aee2-4413-4008-9b25-5490cc269cda,DISK], DatanodeInfoWithStorage[127.0.0.1:37055,DS-8bf4f387-93a2-44e6-ae3d-f8dba4ae7ef2,DISK], DatanodeInfoWithStorage[127.0.0.1:40799,DS-fe4af67a-ab4e-4da2-976f-e763564cb98e,DISK], DatanodeInfoWithStorage[127.0.0.1:45525,DS-464d2c38-5255-4471-8eed-6c5e8bce05be,DISK], DatanodeInfoWithStorage[127.0.0.1:38127,DS-a5bd9cbf-977c-4e63-993e-82a0c5b4b004,DISK], DatanodeInfoWithStorage[127.0.0.1:35576,DS-61bbe104-3b26-4b33-ac4c-475b4d0a9663,DISK], DatanodeInfoWithStorage[127.0.0.1:42294,DS-d3871bd7-4e29-496b-94b2-e8d7dbad1046,DISK], DatanodeInfoWithStorage[127.0.0.1:45522,DS-5f17147f-226c-4255-8a92-ae0c0e8f0d40,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1806825145-172.17.0.17-1595409726682:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40127,DS-1394aee2-4413-4008-9b25-5490cc269cda,DISK], DatanodeInfoWithStorage[127.0.0.1:37055,DS-8bf4f387-93a2-44e6-ae3d-f8dba4ae7ef2,DISK], DatanodeInfoWithStorage[127.0.0.1:40799,DS-fe4af67a-ab4e-4da2-976f-e763564cb98e,DISK], DatanodeInfoWithStorage[127.0.0.1:45525,DS-464d2c38-5255-4471-8eed-6c5e8bce05be,DISK], DatanodeInfoWithStorage[127.0.0.1:38127,DS-a5bd9cbf-977c-4e63-993e-82a0c5b4b004,DISK], DatanodeInfoWithStorage[127.0.0.1:35576,DS-61bbe104-3b26-4b33-ac4c-475b4d0a9663,DISK], DatanodeInfoWithStorage[127.0.0.1:42294,DS-d3871bd7-4e29-496b-94b2-e8d7dbad1046,DISK], DatanodeInfoWithStorage[127.0.0.1:45522,DS-5f17147f-226c-4255-8a92-ae0c0e8f0d40,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 20 out of 50
result: false positive !!!
Total execution time in seconds : 5434
