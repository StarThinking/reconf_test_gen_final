reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-601008917-172.17.0.21-1595352308375:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40512,DS-7518bdf5-8004-42c2-a5c4-f14e40af0e8d,DISK], DatanodeInfoWithStorage[127.0.0.1:38052,DS-f83e15af-ee4d-49ce-a7d2-a3bbb9568d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:35252,DS-788a1041-8d03-44c7-9666-c4b6722713b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40116,DS-f209ee45-73d4-4444-b353-6fd89684d50e,DISK], DatanodeInfoWithStorage[127.0.0.1:44977,DS-5bfaa149-69db-4f6b-8be8-804492236f12,DISK], DatanodeInfoWithStorage[127.0.0.1:44358,DS-e94f8538-dfea-4079-aa0d-4b4f59d4b81a,DISK], DatanodeInfoWithStorage[127.0.0.1:40018,DS-b58043e3-aa94-4980-a38b-0d1eaad01da8,DISK], DatanodeInfoWithStorage[127.0.0.1:40678,DS-8927ebf1-745a-4c41-8fb1-59f5fa0685fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-601008917-172.17.0.21-1595352308375:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40512,DS-7518bdf5-8004-42c2-a5c4-f14e40af0e8d,DISK], DatanodeInfoWithStorage[127.0.0.1:38052,DS-f83e15af-ee4d-49ce-a7d2-a3bbb9568d4a,DISK], DatanodeInfoWithStorage[127.0.0.1:35252,DS-788a1041-8d03-44c7-9666-c4b6722713b5,DISK], DatanodeInfoWithStorage[127.0.0.1:40116,DS-f209ee45-73d4-4444-b353-6fd89684d50e,DISK], DatanodeInfoWithStorage[127.0.0.1:44977,DS-5bfaa149-69db-4f6b-8be8-804492236f12,DISK], DatanodeInfoWithStorage[127.0.0.1:44358,DS-e94f8538-dfea-4079-aa0d-4b4f59d4b81a,DISK], DatanodeInfoWithStorage[127.0.0.1:40018,DS-b58043e3-aa94-4980-a38b-0d1eaad01da8,DISK], DatanodeInfoWithStorage[127.0.0.1:40678,DS-8927ebf1-745a-4c41-8fb1-59f5fa0685fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-789844680-172.17.0.21-1595352613732:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36877,DS-71bab720-69de-4306-bead-2bbcb605e226,DISK], DatanodeInfoWithStorage[127.0.0.1:40182,DS-c1611dcb-744d-46b6-8071-8f818d80de86,DISK], DatanodeInfoWithStorage[127.0.0.1:46841,DS-2a7c0067-3dc6-4d85-8d08-3c0ea48620d5,DISK], DatanodeInfoWithStorage[127.0.0.1:42566,DS-d26f4065-6731-457e-9146-b9ca79911ee1,DISK], DatanodeInfoWithStorage[127.0.0.1:44335,DS-a3593e63-315d-4308-ba31-72aa00a9dfdd,DISK], DatanodeInfoWithStorage[127.0.0.1:42299,DS-5946e2bc-ebeb-48c9-8a2b-8514c338d26e,DISK], DatanodeInfoWithStorage[127.0.0.1:37548,DS-dd1093b0-dcb5-4040-b946-7509a629f1c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37113,DS-a4c9be7a-352c-46b9-91d0-51af23a7bcf5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-789844680-172.17.0.21-1595352613732:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36877,DS-71bab720-69de-4306-bead-2bbcb605e226,DISK], DatanodeInfoWithStorage[127.0.0.1:40182,DS-c1611dcb-744d-46b6-8071-8f818d80de86,DISK], DatanodeInfoWithStorage[127.0.0.1:46841,DS-2a7c0067-3dc6-4d85-8d08-3c0ea48620d5,DISK], DatanodeInfoWithStorage[127.0.0.1:42566,DS-d26f4065-6731-457e-9146-b9ca79911ee1,DISK], DatanodeInfoWithStorage[127.0.0.1:44335,DS-a3593e63-315d-4308-ba31-72aa00a9dfdd,DISK], DatanodeInfoWithStorage[127.0.0.1:42299,DS-5946e2bc-ebeb-48c9-8a2b-8514c338d26e,DISK], DatanodeInfoWithStorage[127.0.0.1:37548,DS-dd1093b0-dcb5-4040-b946-7509a629f1c1,DISK], DatanodeInfoWithStorage[127.0.0.1:37113,DS-a4c9be7a-352c-46b9-91d0-51af23a7bcf5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1238562941-172.17.0.21-1595352681605:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46316,DS-6e01ece3-cfbc-420f-81af-4af7e4a1a863,DISK], DatanodeInfoWithStorage[127.0.0.1:37629,DS-19401f7b-06f2-43b9-a261-4eaee2ce6eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:39775,DS-df987135-8557-4909-b445-0fd9f172d38f,DISK], DatanodeInfoWithStorage[127.0.0.1:37279,DS-2ad148af-959f-420c-9e9b-99846b17a4e2,DISK], DatanodeInfoWithStorage[127.0.0.1:33984,DS-166cf3f0-9105-408e-b8ee-d70b481ba8b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41998,DS-38cf4804-3fc9-4539-ba44-6eb77f66d83a,DISK], DatanodeInfoWithStorage[127.0.0.1:42067,DS-e929c138-9262-434e-84e9-e57d217d6444,DISK], DatanodeInfoWithStorage[127.0.0.1:44030,DS-6112d247-c810-4855-8d67-891b90b02396,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1238562941-172.17.0.21-1595352681605:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46316,DS-6e01ece3-cfbc-420f-81af-4af7e4a1a863,DISK], DatanodeInfoWithStorage[127.0.0.1:37629,DS-19401f7b-06f2-43b9-a261-4eaee2ce6eb8,DISK], DatanodeInfoWithStorage[127.0.0.1:39775,DS-df987135-8557-4909-b445-0fd9f172d38f,DISK], DatanodeInfoWithStorage[127.0.0.1:37279,DS-2ad148af-959f-420c-9e9b-99846b17a4e2,DISK], DatanodeInfoWithStorage[127.0.0.1:33984,DS-166cf3f0-9105-408e-b8ee-d70b481ba8b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41998,DS-38cf4804-3fc9-4539-ba44-6eb77f66d83a,DISK], DatanodeInfoWithStorage[127.0.0.1:42067,DS-e929c138-9262-434e-84e9-e57d217d6444,DISK], DatanodeInfoWithStorage[127.0.0.1:44030,DS-6112d247-c810-4855-8d67-891b90b02396,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-985078194-172.17.0.21-1595353264830:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37797,DS-4832750b-9fd6-4dbc-a0da-c52138d99dc1,DISK], DatanodeInfoWithStorage[127.0.0.1:41715,DS-cd574e5f-ddbb-41d0-807e-0b50595d2991,DISK], DatanodeInfoWithStorage[127.0.0.1:43527,DS-5114e7ff-b762-4bc2-b9df-ebb835faa885,DISK], DatanodeInfoWithStorage[127.0.0.1:34425,DS-96f99276-6820-4ba2-8528-35ba951d2f45,DISK], DatanodeInfoWithStorage[127.0.0.1:36161,DS-10866b4b-3688-4e5b-8273-998e5636181f,DISK], DatanodeInfoWithStorage[127.0.0.1:44985,DS-60f112fa-f059-4e9a-adf6-6a7848f45e36,DISK], DatanodeInfoWithStorage[127.0.0.1:45709,DS-f672fff2-2202-4721-b3e1-a80731456c69,DISK], DatanodeInfoWithStorage[127.0.0.1:37161,DS-d5f57af5-bf0d-4542-a98f-3773648439c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-985078194-172.17.0.21-1595353264830:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37797,DS-4832750b-9fd6-4dbc-a0da-c52138d99dc1,DISK], DatanodeInfoWithStorage[127.0.0.1:41715,DS-cd574e5f-ddbb-41d0-807e-0b50595d2991,DISK], DatanodeInfoWithStorage[127.0.0.1:43527,DS-5114e7ff-b762-4bc2-b9df-ebb835faa885,DISK], DatanodeInfoWithStorage[127.0.0.1:34425,DS-96f99276-6820-4ba2-8528-35ba951d2f45,DISK], DatanodeInfoWithStorage[127.0.0.1:36161,DS-10866b4b-3688-4e5b-8273-998e5636181f,DISK], DatanodeInfoWithStorage[127.0.0.1:44985,DS-60f112fa-f059-4e9a-adf6-6a7848f45e36,DISK], DatanodeInfoWithStorage[127.0.0.1:45709,DS-f672fff2-2202-4721-b3e1-a80731456c69,DISK], DatanodeInfoWithStorage[127.0.0.1:37161,DS-d5f57af5-bf0d-4542-a98f-3773648439c5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1783179463-172.17.0.21-1595353300465:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36438,DS-4c9514a9-1dfd-4737-96ca-58662e18b650,DISK], DatanodeInfoWithStorage[127.0.0.1:41446,DS-2bbfa03a-453e-462c-b8b0-23bb5f1ab2d9,DISK], DatanodeInfoWithStorage[127.0.0.1:46184,DS-3f81eb63-c539-4bfd-8e68-0651dca3d540,DISK], DatanodeInfoWithStorage[127.0.0.1:37408,DS-8fb509d9-e236-470e-8904-8699654b625d,DISK], DatanodeInfoWithStorage[127.0.0.1:36599,DS-f6c91073-dbf3-4e8d-95b7-75150e165ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:32918,DS-2bc41aea-956b-42d6-96d7-fedba7cffb57,DISK], DatanodeInfoWithStorage[127.0.0.1:42386,DS-5a294272-a3a1-48c0-9a71-dc42b8f5ccd2,DISK], DatanodeInfoWithStorage[127.0.0.1:39627,DS-8b2d1423-b942-4231-82a4-588d2f5a902c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1783179463-172.17.0.21-1595353300465:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36438,DS-4c9514a9-1dfd-4737-96ca-58662e18b650,DISK], DatanodeInfoWithStorage[127.0.0.1:41446,DS-2bbfa03a-453e-462c-b8b0-23bb5f1ab2d9,DISK], DatanodeInfoWithStorage[127.0.0.1:46184,DS-3f81eb63-c539-4bfd-8e68-0651dca3d540,DISK], DatanodeInfoWithStorage[127.0.0.1:37408,DS-8fb509d9-e236-470e-8904-8699654b625d,DISK], DatanodeInfoWithStorage[127.0.0.1:36599,DS-f6c91073-dbf3-4e8d-95b7-75150e165ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:32918,DS-2bc41aea-956b-42d6-96d7-fedba7cffb57,DISK], DatanodeInfoWithStorage[127.0.0.1:42386,DS-5a294272-a3a1-48c0-9a71-dc42b8f5ccd2,DISK], DatanodeInfoWithStorage[127.0.0.1:39627,DS-8b2d1423-b942-4231-82a4-588d2f5a902c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-470463070-172.17.0.21-1595353472310:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39623,DS-c0ac3f93-bc6d-434c-b1b7-57230d84547f,DISK], DatanodeInfoWithStorage[127.0.0.1:33785,DS-6b006991-5b1c-4eeb-8a2d-431884bdb230,DISK], DatanodeInfoWithStorage[127.0.0.1:38526,DS-bfcc15ce-74ca-4e33-8dd3-a4844e88dda5,DISK], DatanodeInfoWithStorage[127.0.0.1:44090,DS-e2250b42-5d6a-414a-8926-d1d0e9cc41dd,DISK], DatanodeInfoWithStorage[127.0.0.1:46269,DS-6615c7ec-b2ba-4c83-9316-df5a49361493,DISK], DatanodeInfoWithStorage[127.0.0.1:42981,DS-d4bf8888-e8f3-48f9-b5d2-d137ff90c438,DISK], DatanodeInfoWithStorage[127.0.0.1:40648,DS-8f934b3e-92c6-465a-aa48-560faffdf1d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38882,DS-1e26da3d-4aa4-466f-8735-c480901a829f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-470463070-172.17.0.21-1595353472310:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39623,DS-c0ac3f93-bc6d-434c-b1b7-57230d84547f,DISK], DatanodeInfoWithStorage[127.0.0.1:33785,DS-6b006991-5b1c-4eeb-8a2d-431884bdb230,DISK], DatanodeInfoWithStorage[127.0.0.1:38526,DS-bfcc15ce-74ca-4e33-8dd3-a4844e88dda5,DISK], DatanodeInfoWithStorage[127.0.0.1:44090,DS-e2250b42-5d6a-414a-8926-d1d0e9cc41dd,DISK], DatanodeInfoWithStorage[127.0.0.1:46269,DS-6615c7ec-b2ba-4c83-9316-df5a49361493,DISK], DatanodeInfoWithStorage[127.0.0.1:42981,DS-d4bf8888-e8f3-48f9-b5d2-d137ff90c438,DISK], DatanodeInfoWithStorage[127.0.0.1:40648,DS-8f934b3e-92c6-465a-aa48-560faffdf1d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38882,DS-1e26da3d-4aa4-466f-8735-c480901a829f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-850553364-172.17.0.21-1595353506382:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44890,DS-0c644636-76d3-4d90-904c-0ecc41715dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:41294,DS-0bed218a-6b77-4b6f-acce-8a3f58a0cf32,DISK], DatanodeInfoWithStorage[127.0.0.1:45487,DS-8b4c7afa-73dd-4b96-a75b-c210367cfeca,DISK], DatanodeInfoWithStorage[127.0.0.1:43222,DS-adc49b34-b8c8-49b1-b7bc-67b756115052,DISK], DatanodeInfoWithStorage[127.0.0.1:45520,DS-4a1d3ffc-e8ce-4f2a-96a4-f4a10f71a117,DISK], DatanodeInfoWithStorage[127.0.0.1:37267,DS-2dd58257-a7ae-4083-942d-ab6553b3fbc0,DISK], DatanodeInfoWithStorage[127.0.0.1:36129,DS-0c2a2b2c-b3c5-4152-b9dd-4300005ef288,DISK], DatanodeInfoWithStorage[127.0.0.1:42905,DS-8425bda9-cc70-4a18-bfa9-e846ec61a590,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-850553364-172.17.0.21-1595353506382:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44890,DS-0c644636-76d3-4d90-904c-0ecc41715dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:41294,DS-0bed218a-6b77-4b6f-acce-8a3f58a0cf32,DISK], DatanodeInfoWithStorage[127.0.0.1:45487,DS-8b4c7afa-73dd-4b96-a75b-c210367cfeca,DISK], DatanodeInfoWithStorage[127.0.0.1:43222,DS-adc49b34-b8c8-49b1-b7bc-67b756115052,DISK], DatanodeInfoWithStorage[127.0.0.1:45520,DS-4a1d3ffc-e8ce-4f2a-96a4-f4a10f71a117,DISK], DatanodeInfoWithStorage[127.0.0.1:37267,DS-2dd58257-a7ae-4083-942d-ab6553b3fbc0,DISK], DatanodeInfoWithStorage[127.0.0.1:36129,DS-0c2a2b2c-b3c5-4152-b9dd-4300005ef288,DISK], DatanodeInfoWithStorage[127.0.0.1:42905,DS-8425bda9-cc70-4a18-bfa9-e846ec61a590,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2001381028-172.17.0.21-1595353686778:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42721,DS-b98e8b9f-cae9-4e6a-b84d-9d25d077e32c,DISK], DatanodeInfoWithStorage[127.0.0.1:43757,DS-6666e16c-211e-4a76-9c62-e556709f1f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:35811,DS-e894c6f4-dd49-443e-b77a-0ad2b5a9655c,DISK], DatanodeInfoWithStorage[127.0.0.1:33489,DS-4240d299-9bbd-4f0b-8740-2cb544bc9142,DISK], DatanodeInfoWithStorage[127.0.0.1:43336,DS-85b896fd-e387-4fdd-83ce-bdec2432c345,DISK], DatanodeInfoWithStorage[127.0.0.1:43116,DS-9260d0ce-de79-447e-832a-b82c793a3408,DISK], DatanodeInfoWithStorage[127.0.0.1:44730,DS-1531ad55-69c1-4c5e-8a2c-734a7b9eed6b,DISK], DatanodeInfoWithStorage[127.0.0.1:40128,DS-5c977ba7-d015-499f-9d0c-4054b9a7ef21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2001381028-172.17.0.21-1595353686778:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42721,DS-b98e8b9f-cae9-4e6a-b84d-9d25d077e32c,DISK], DatanodeInfoWithStorage[127.0.0.1:43757,DS-6666e16c-211e-4a76-9c62-e556709f1f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:35811,DS-e894c6f4-dd49-443e-b77a-0ad2b5a9655c,DISK], DatanodeInfoWithStorage[127.0.0.1:33489,DS-4240d299-9bbd-4f0b-8740-2cb544bc9142,DISK], DatanodeInfoWithStorage[127.0.0.1:43336,DS-85b896fd-e387-4fdd-83ce-bdec2432c345,DISK], DatanodeInfoWithStorage[127.0.0.1:43116,DS-9260d0ce-de79-447e-832a-b82c793a3408,DISK], DatanodeInfoWithStorage[127.0.0.1:44730,DS-1531ad55-69c1-4c5e-8a2c-734a7b9eed6b,DISK], DatanodeInfoWithStorage[127.0.0.1:40128,DS-5c977ba7-d015-499f-9d0c-4054b9a7ef21,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-402819523-172.17.0.21-1595353871395:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42825,DS-4a31a304-4e6a-4d93-a1cb-1f233aa55bcd,DISK], DatanodeInfoWithStorage[127.0.0.1:35900,DS-49ac8474-c319-48fa-a418-3995ffe808a7,DISK], DatanodeInfoWithStorage[127.0.0.1:44619,DS-e8c972e9-63f0-468a-87b7-a5009a8acd89,DISK], DatanodeInfoWithStorage[127.0.0.1:38321,DS-f5ab3477-4cc9-455c-bd8f-e952b8065d49,DISK], DatanodeInfoWithStorage[127.0.0.1:34977,DS-e03cd4aa-a4a0-4aee-b7c5-331f5ab8f24b,DISK], DatanodeInfoWithStorage[127.0.0.1:42775,DS-76d0a0b1-dc3b-4a4f-8c5b-edfc155f057f,DISK], DatanodeInfoWithStorage[127.0.0.1:45006,DS-e080e96f-065f-4c54-be86-9619eb869c7a,DISK], DatanodeInfoWithStorage[127.0.0.1:33464,DS-55cfccbd-9906-4a30-abd0-bea95bbb994e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-402819523-172.17.0.21-1595353871395:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42825,DS-4a31a304-4e6a-4d93-a1cb-1f233aa55bcd,DISK], DatanodeInfoWithStorage[127.0.0.1:35900,DS-49ac8474-c319-48fa-a418-3995ffe808a7,DISK], DatanodeInfoWithStorage[127.0.0.1:44619,DS-e8c972e9-63f0-468a-87b7-a5009a8acd89,DISK], DatanodeInfoWithStorage[127.0.0.1:38321,DS-f5ab3477-4cc9-455c-bd8f-e952b8065d49,DISK], DatanodeInfoWithStorage[127.0.0.1:34977,DS-e03cd4aa-a4a0-4aee-b7c5-331f5ab8f24b,DISK], DatanodeInfoWithStorage[127.0.0.1:42775,DS-76d0a0b1-dc3b-4a4f-8c5b-edfc155f057f,DISK], DatanodeInfoWithStorage[127.0.0.1:45006,DS-e080e96f-065f-4c54-be86-9619eb869c7a,DISK], DatanodeInfoWithStorage[127.0.0.1:33464,DS-55cfccbd-9906-4a30-abd0-bea95bbb994e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-562220470-172.17.0.21-1595354201276:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37249,DS-d4afab06-8552-4e8a-8d0f-f0b8de6e943c,DISK], DatanodeInfoWithStorage[127.0.0.1:34136,DS-0e388c26-129e-4f9e-b445-e02d0d2c4218,DISK], DatanodeInfoWithStorage[127.0.0.1:33563,DS-a1379a74-3c76-4f63-9a6d-afe902d60f50,DISK], DatanodeInfoWithStorage[127.0.0.1:40147,DS-9925a50d-f4f4-49e4-a6cf-627b5af60a35,DISK], DatanodeInfoWithStorage[127.0.0.1:35173,DS-a403d714-29ff-4185-aaa5-27c39f562a03,DISK], DatanodeInfoWithStorage[127.0.0.1:39546,DS-aaa0c7c0-aa63-4ee8-82f7-365a9eec6740,DISK], DatanodeInfoWithStorage[127.0.0.1:36863,DS-c8b97c51-6d53-41f4-818e-26c2968f6ed3,DISK], DatanodeInfoWithStorage[127.0.0.1:40564,DS-b95c883a-9916-4ec0-964a-f9dd68a215d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-562220470-172.17.0.21-1595354201276:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37249,DS-d4afab06-8552-4e8a-8d0f-f0b8de6e943c,DISK], DatanodeInfoWithStorage[127.0.0.1:34136,DS-0e388c26-129e-4f9e-b445-e02d0d2c4218,DISK], DatanodeInfoWithStorage[127.0.0.1:33563,DS-a1379a74-3c76-4f63-9a6d-afe902d60f50,DISK], DatanodeInfoWithStorage[127.0.0.1:40147,DS-9925a50d-f4f4-49e4-a6cf-627b5af60a35,DISK], DatanodeInfoWithStorage[127.0.0.1:35173,DS-a403d714-29ff-4185-aaa5-27c39f562a03,DISK], DatanodeInfoWithStorage[127.0.0.1:39546,DS-aaa0c7c0-aa63-4ee8-82f7-365a9eec6740,DISK], DatanodeInfoWithStorage[127.0.0.1:36863,DS-c8b97c51-6d53-41f4-818e-26c2968f6ed3,DISK], DatanodeInfoWithStorage[127.0.0.1:40564,DS-b95c883a-9916-4ec0-964a-f9dd68a215d0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-14795820-172.17.0.21-1595354606324:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37477,DS-120d2d34-f81c-4519-9795-d5fb35d7a4a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41423,DS-39e9700b-9fd6-40bc-a302-2b393d4d04d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41768,DS-7254ddbf-6410-42ef-b896-9eef03d2da70,DISK], DatanodeInfoWithStorage[127.0.0.1:36472,DS-86338aad-adfe-424b-b753-c192ef0578a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33798,DS-bc649735-800a-40e6-9b64-9685c54b7585,DISK], DatanodeInfoWithStorage[127.0.0.1:35635,DS-9e384946-445b-46a8-b47e-21123793cafb,DISK], DatanodeInfoWithStorage[127.0.0.1:43779,DS-9c6d0abb-a0c8-4b68-9259-44dfb32caaee,DISK], DatanodeInfoWithStorage[127.0.0.1:46620,DS-478c2ca7-71af-44bf-8a2d-96704fea66b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-14795820-172.17.0.21-1595354606324:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37477,DS-120d2d34-f81c-4519-9795-d5fb35d7a4a9,DISK], DatanodeInfoWithStorage[127.0.0.1:41423,DS-39e9700b-9fd6-40bc-a302-2b393d4d04d7,DISK], DatanodeInfoWithStorage[127.0.0.1:41768,DS-7254ddbf-6410-42ef-b896-9eef03d2da70,DISK], DatanodeInfoWithStorage[127.0.0.1:36472,DS-86338aad-adfe-424b-b753-c192ef0578a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33798,DS-bc649735-800a-40e6-9b64-9685c54b7585,DISK], DatanodeInfoWithStorage[127.0.0.1:35635,DS-9e384946-445b-46a8-b47e-21123793cafb,DISK], DatanodeInfoWithStorage[127.0.0.1:43779,DS-9c6d0abb-a0c8-4b68-9259-44dfb32caaee,DISK], DatanodeInfoWithStorage[127.0.0.1:46620,DS-478c2ca7-71af-44bf-8a2d-96704fea66b5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1956783558-172.17.0.21-1595355795768:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39768,DS-86c46162-a7b7-47be-840e-3669dbffd3c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34710,DS-51112f57-d6df-4633-b4bf-2eecffa2e673,DISK], DatanodeInfoWithStorage[127.0.0.1:41052,DS-93477b68-f2ea-4642-8954-2369aca36978,DISK], DatanodeInfoWithStorage[127.0.0.1:44712,DS-06e5f023-4ed3-4835-8159-ac96d7fdd309,DISK], DatanodeInfoWithStorage[127.0.0.1:40157,DS-fc7dc23d-471f-4b13-b4fe-9bcdf00f6e00,DISK], DatanodeInfoWithStorage[127.0.0.1:42521,DS-a0ca0cdb-2b0e-4cd3-a46c-5b7076f41287,DISK], DatanodeInfoWithStorage[127.0.0.1:36786,DS-40d2c4d7-5721-4d1e-9e18-2c6c34967706,DISK], DatanodeInfoWithStorage[127.0.0.1:38394,DS-27074515-3c1c-41eb-830c-33949bf907cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1956783558-172.17.0.21-1595355795768:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39768,DS-86c46162-a7b7-47be-840e-3669dbffd3c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34710,DS-51112f57-d6df-4633-b4bf-2eecffa2e673,DISK], DatanodeInfoWithStorage[127.0.0.1:41052,DS-93477b68-f2ea-4642-8954-2369aca36978,DISK], DatanodeInfoWithStorage[127.0.0.1:44712,DS-06e5f023-4ed3-4835-8159-ac96d7fdd309,DISK], DatanodeInfoWithStorage[127.0.0.1:40157,DS-fc7dc23d-471f-4b13-b4fe-9bcdf00f6e00,DISK], DatanodeInfoWithStorage[127.0.0.1:42521,DS-a0ca0cdb-2b0e-4cd3-a46c-5b7076f41287,DISK], DatanodeInfoWithStorage[127.0.0.1:36786,DS-40d2c4d7-5721-4d1e-9e18-2c6c34967706,DISK], DatanodeInfoWithStorage[127.0.0.1:38394,DS-27074515-3c1c-41eb-830c-33949bf907cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-433318608-172.17.0.21-1595356402700:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36187,DS-73ca23d7-988e-4090-ae37-b275aea682bc,DISK], DatanodeInfoWithStorage[127.0.0.1:40548,DS-8d3bc20a-f356-41d7-848b-ae2b34bd5ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:46718,DS-4c4b9309-5646-4d61-ab0f-ddfbf5ccaffd,DISK], DatanodeInfoWithStorage[127.0.0.1:35899,DS-f078967d-203b-406f-a3a7-abe2b4986ec2,DISK], DatanodeInfoWithStorage[127.0.0.1:33112,DS-617d4d25-7793-4a74-80b9-8fb6cf16dfc2,DISK], DatanodeInfoWithStorage[127.0.0.1:33101,DS-03aa12cf-e0aa-41a8-bb55-f463ed0a770d,DISK], DatanodeInfoWithStorage[127.0.0.1:38351,DS-ddb0fccb-0913-4e02-b0f2-586313245780,DISK], DatanodeInfoWithStorage[127.0.0.1:45683,DS-98d575d6-3459-481f-acc2-ea5caf680380,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-433318608-172.17.0.21-1595356402700:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36187,DS-73ca23d7-988e-4090-ae37-b275aea682bc,DISK], DatanodeInfoWithStorage[127.0.0.1:40548,DS-8d3bc20a-f356-41d7-848b-ae2b34bd5ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:46718,DS-4c4b9309-5646-4d61-ab0f-ddfbf5ccaffd,DISK], DatanodeInfoWithStorage[127.0.0.1:35899,DS-f078967d-203b-406f-a3a7-abe2b4986ec2,DISK], DatanodeInfoWithStorage[127.0.0.1:33112,DS-617d4d25-7793-4a74-80b9-8fb6cf16dfc2,DISK], DatanodeInfoWithStorage[127.0.0.1:33101,DS-03aa12cf-e0aa-41a8-bb55-f463ed0a770d,DISK], DatanodeInfoWithStorage[127.0.0.1:38351,DS-ddb0fccb-0913-4e02-b0f2-586313245780,DISK], DatanodeInfoWithStorage[127.0.0.1:45683,DS-98d575d6-3459-481f-acc2-ea5caf680380,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1556367623-172.17.0.21-1595356935032:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37035,DS-80a21d0d-66c0-497f-89e3-8bf0987f0ae4,DISK], DatanodeInfoWithStorage[127.0.0.1:41940,DS-47b997e6-877a-4fc8-984e-0ca2555e8e6d,DISK], DatanodeInfoWithStorage[127.0.0.1:33237,DS-13042551-a134-46e1-88f8-c26d08f1e327,DISK], DatanodeInfoWithStorage[127.0.0.1:45946,DS-a4e20aa9-2e07-4a0b-90dc-d56e8c40361b,DISK], DatanodeInfoWithStorage[127.0.0.1:35417,DS-ff09599d-3285-4dc0-bca2-b6b452be0bd5,DISK], DatanodeInfoWithStorage[127.0.0.1:33204,DS-8b1824c3-8442-418a-b29c-08daa4d4afaa,DISK], DatanodeInfoWithStorage[127.0.0.1:42825,DS-a3471aa3-0db1-4f67-89bb-660233a7d977,DISK], DatanodeInfoWithStorage[127.0.0.1:32957,DS-0b955939-09bb-454a-bd51-55c3eee1dde8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1556367623-172.17.0.21-1595356935032:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37035,DS-80a21d0d-66c0-497f-89e3-8bf0987f0ae4,DISK], DatanodeInfoWithStorage[127.0.0.1:41940,DS-47b997e6-877a-4fc8-984e-0ca2555e8e6d,DISK], DatanodeInfoWithStorage[127.0.0.1:33237,DS-13042551-a134-46e1-88f8-c26d08f1e327,DISK], DatanodeInfoWithStorage[127.0.0.1:45946,DS-a4e20aa9-2e07-4a0b-90dc-d56e8c40361b,DISK], DatanodeInfoWithStorage[127.0.0.1:35417,DS-ff09599d-3285-4dc0-bca2-b6b452be0bd5,DISK], DatanodeInfoWithStorage[127.0.0.1:33204,DS-8b1824c3-8442-418a-b29c-08daa4d4afaa,DISK], DatanodeInfoWithStorage[127.0.0.1:42825,DS-a3471aa3-0db1-4f67-89bb-660233a7d977,DISK], DatanodeInfoWithStorage[127.0.0.1:32957,DS-0b955939-09bb-454a-bd51-55c3eee1dde8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-702261318-172.17.0.21-1595357028698:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36799,DS-bcf79270-b052-434d-b0a5-a95bdb3e8de6,DISK], DatanodeInfoWithStorage[127.0.0.1:37891,DS-a8be11c8-5b93-4ee9-873c-af666138b377,DISK], DatanodeInfoWithStorage[127.0.0.1:45669,DS-3313cd59-c162-43c1-8d96-79696fc684ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45593,DS-18f45239-144f-4bbb-a8c2-2f85986f23ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43822,DS-f485bfc9-6f84-487d-ac5d-de09c9667f08,DISK], DatanodeInfoWithStorage[127.0.0.1:35031,DS-0e406bb5-5093-487f-a1c0-ae31a69df7e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39668,DS-dfdd3b07-40d5-4e91-bce3-c96f68802e79,DISK], DatanodeInfoWithStorage[127.0.0.1:46401,DS-141030e7-74d2-42dd-b64d-eb315a62acc5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-702261318-172.17.0.21-1595357028698:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36799,DS-bcf79270-b052-434d-b0a5-a95bdb3e8de6,DISK], DatanodeInfoWithStorage[127.0.0.1:37891,DS-a8be11c8-5b93-4ee9-873c-af666138b377,DISK], DatanodeInfoWithStorage[127.0.0.1:45669,DS-3313cd59-c162-43c1-8d96-79696fc684ad,DISK], DatanodeInfoWithStorage[127.0.0.1:45593,DS-18f45239-144f-4bbb-a8c2-2f85986f23ff,DISK], DatanodeInfoWithStorage[127.0.0.1:43822,DS-f485bfc9-6f84-487d-ac5d-de09c9667f08,DISK], DatanodeInfoWithStorage[127.0.0.1:35031,DS-0e406bb5-5093-487f-a1c0-ae31a69df7e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39668,DS-dfdd3b07-40d5-4e91-bce3-c96f68802e79,DISK], DatanodeInfoWithStorage[127.0.0.1:46401,DS-141030e7-74d2-42dd-b64d-eb315a62acc5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.snapshot.skip.capture.accesstime-only-change
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-11218252-172.17.0.21-1595357260748:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45097,DS-ca73b581-a3c9-47aa-852d-e70889cb2d85,DISK], DatanodeInfoWithStorage[127.0.0.1:46119,DS-2ba8af11-3c58-4b01-a485-b10fba025128,DISK], DatanodeInfoWithStorage[127.0.0.1:45120,DS-6c1826b2-459f-4304-a953-57ce3476ffb6,DISK], DatanodeInfoWithStorage[127.0.0.1:44321,DS-36e9bcf2-8376-4c53-8cb5-37f195fc8fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:37905,DS-67f705f6-e742-4a5a-8c8c-195d7a354c05,DISK], DatanodeInfoWithStorage[127.0.0.1:33456,DS-55cd43aa-3fcb-4056-9536-be685a7fb2ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44235,DS-c95e54f1-a503-45a2-96d5-a683b69157e6,DISK], DatanodeInfoWithStorage[127.0.0.1:43713,DS-30e6c15b-73d5-4ffa-8dbb-e6e73fdb5abd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-11218252-172.17.0.21-1595357260748:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45097,DS-ca73b581-a3c9-47aa-852d-e70889cb2d85,DISK], DatanodeInfoWithStorage[127.0.0.1:46119,DS-2ba8af11-3c58-4b01-a485-b10fba025128,DISK], DatanodeInfoWithStorage[127.0.0.1:45120,DS-6c1826b2-459f-4304-a953-57ce3476ffb6,DISK], DatanodeInfoWithStorage[127.0.0.1:44321,DS-36e9bcf2-8376-4c53-8cb5-37f195fc8fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:37905,DS-67f705f6-e742-4a5a-8c8c-195d7a354c05,DISK], DatanodeInfoWithStorage[127.0.0.1:33456,DS-55cd43aa-3fcb-4056-9536-be685a7fb2ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44235,DS-c95e54f1-a503-45a2-96d5-a683b69157e6,DISK], DatanodeInfoWithStorage[127.0.0.1:43713,DS-30e6c15b-73d5-4ffa-8dbb-e6e73fdb5abd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5193
