reconf_parameter: dfs.client.write.byte-array-manager.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.byte-array-manager.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-936426690-172.17.0.16-1596944594406:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37861,DS-e8a00e49-685e-4e95-a766-1d0786205902,DISK], DatanodeInfoWithStorage[127.0.0.1:45605,DS-8831a967-e2d8-458e-b2d1-f2ca9c545bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:46315,DS-b09da186-9708-40ea-9935-34e8f79173b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45375,DS-762c7c67-0808-47ff-929a-263ceb02eb60,DISK], DatanodeInfoWithStorage[127.0.0.1:38648,DS-d9eb5f51-de66-4396-ac7a-2fbd0e3dd2b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45406,DS-b70072bf-bef4-4bfc-9dba-f67ad56edf0b,DISK], DatanodeInfoWithStorage[127.0.0.1:32932,DS-ab2a4d90-6325-419b-bb7d-2206e942dbe4,DISK], DatanodeInfoWithStorage[127.0.0.1:46681,DS-0496fd85-54ca-47e3-a5d1-fa3b8ac99df7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-936426690-172.17.0.16-1596944594406:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37861,DS-e8a00e49-685e-4e95-a766-1d0786205902,DISK], DatanodeInfoWithStorage[127.0.0.1:45605,DS-8831a967-e2d8-458e-b2d1-f2ca9c545bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:46315,DS-b09da186-9708-40ea-9935-34e8f79173b8,DISK], DatanodeInfoWithStorage[127.0.0.1:45375,DS-762c7c67-0808-47ff-929a-263ceb02eb60,DISK], DatanodeInfoWithStorage[127.0.0.1:38648,DS-d9eb5f51-de66-4396-ac7a-2fbd0e3dd2b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45406,DS-b70072bf-bef4-4bfc-9dba-f67ad56edf0b,DISK], DatanodeInfoWithStorage[127.0.0.1:32932,DS-ab2a4d90-6325-419b-bb7d-2206e942dbe4,DISK], DatanodeInfoWithStorage[127.0.0.1:46681,DS-0496fd85-54ca-47e3-a5d1-fa3b8ac99df7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.byte-array-manager.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1740938307-172.17.0.16-1596945159369:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34005,DS-f1d27862-e495-424f-b2d8-83e69a91b39a,DISK], DatanodeInfoWithStorage[127.0.0.1:40576,DS-0d705757-c019-48cb-b371-ff38eb484530,DISK], DatanodeInfoWithStorage[127.0.0.1:40002,DS-af68fa52-c603-4fdc-afa3-a3976312acc1,DISK], DatanodeInfoWithStorage[127.0.0.1:35791,DS-024cc80f-2463-4d63-85b7-66988f9a04da,DISK], DatanodeInfoWithStorage[127.0.0.1:42668,DS-987d83ae-75a8-464c-8277-ba10a56903c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36990,DS-8d48ee42-c3c1-476b-9c0f-3488b094205e,DISK], DatanodeInfoWithStorage[127.0.0.1:36357,DS-5c36afdb-9b5f-484e-b9a0-bc823082d538,DISK], DatanodeInfoWithStorage[127.0.0.1:38479,DS-b793c8e4-f198-4fdf-941d-2e1407198db3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1740938307-172.17.0.16-1596945159369:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34005,DS-f1d27862-e495-424f-b2d8-83e69a91b39a,DISK], DatanodeInfoWithStorage[127.0.0.1:40576,DS-0d705757-c019-48cb-b371-ff38eb484530,DISK], DatanodeInfoWithStorage[127.0.0.1:40002,DS-af68fa52-c603-4fdc-afa3-a3976312acc1,DISK], DatanodeInfoWithStorage[127.0.0.1:35791,DS-024cc80f-2463-4d63-85b7-66988f9a04da,DISK], DatanodeInfoWithStorage[127.0.0.1:42668,DS-987d83ae-75a8-464c-8277-ba10a56903c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36990,DS-8d48ee42-c3c1-476b-9c0f-3488b094205e,DISK], DatanodeInfoWithStorage[127.0.0.1:36357,DS-5c36afdb-9b5f-484e-b9a0-bc823082d538,DISK], DatanodeInfoWithStorage[127.0.0.1:38479,DS-b793c8e4-f198-4fdf-941d-2e1407198db3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.byte-array-manager.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-57693408-172.17.0.16-1596945393698:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33483,DS-0d75948a-9a98-44ce-a928-f3ea56846d24,DISK], DatanodeInfoWithStorage[127.0.0.1:33830,DS-6e92e0da-ad7c-42d4-85b4-d253a100e9c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43291,DS-d1e55837-9bb5-4481-97b7-c7860957026e,DISK], DatanodeInfoWithStorage[127.0.0.1:45997,DS-a3ce84fc-461b-4471-9337-c093ae4f9050,DISK], DatanodeInfoWithStorage[127.0.0.1:40237,DS-c3b6d894-56d0-4cdd-a992-8fa3329cda76,DISK], DatanodeInfoWithStorage[127.0.0.1:43049,DS-1f56c8ee-2d40-4d51-bfe0-2859233dbb08,DISK], DatanodeInfoWithStorage[127.0.0.1:37008,DS-fd88b54b-00cc-4db2-a3f5-ee72b10d44d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42839,DS-3fbb75ed-1e5b-47b4-8d61-9605caadb329,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-57693408-172.17.0.16-1596945393698:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33483,DS-0d75948a-9a98-44ce-a928-f3ea56846d24,DISK], DatanodeInfoWithStorage[127.0.0.1:33830,DS-6e92e0da-ad7c-42d4-85b4-d253a100e9c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43291,DS-d1e55837-9bb5-4481-97b7-c7860957026e,DISK], DatanodeInfoWithStorage[127.0.0.1:45997,DS-a3ce84fc-461b-4471-9337-c093ae4f9050,DISK], DatanodeInfoWithStorage[127.0.0.1:40237,DS-c3b6d894-56d0-4cdd-a992-8fa3329cda76,DISK], DatanodeInfoWithStorage[127.0.0.1:43049,DS-1f56c8ee-2d40-4d51-bfe0-2859233dbb08,DISK], DatanodeInfoWithStorage[127.0.0.1:37008,DS-fd88b54b-00cc-4db2-a3f5-ee72b10d44d2,DISK], DatanodeInfoWithStorage[127.0.0.1:42839,DS-3fbb75ed-1e5b-47b4-8d61-9605caadb329,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.byte-array-manager.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1864065120-172.17.0.16-1596946056011:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45423,DS-8f6b74d7-eda1-47f9-8aaf-930dd715f854,DISK], DatanodeInfoWithStorage[127.0.0.1:37274,DS-2fe814af-2656-48e9-b2ff-25057090e5e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46691,DS-89ef0041-c92d-4e36-87c7-e42a483b2513,DISK], DatanodeInfoWithStorage[127.0.0.1:40083,DS-cee454e0-619b-4e77-8caf-30157e11769c,DISK], DatanodeInfoWithStorage[127.0.0.1:32885,DS-09dfa3b7-b7f8-42b0-81c5-58b40fff7891,DISK], DatanodeInfoWithStorage[127.0.0.1:43167,DS-56448d87-d951-4d7f-bf50-c6c2046c04ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37147,DS-85566098-6047-49a5-8d14-fb5d103a6d98,DISK], DatanodeInfoWithStorage[127.0.0.1:37055,DS-e3868beb-5401-4947-ab77-6810f459046e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1864065120-172.17.0.16-1596946056011:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45423,DS-8f6b74d7-eda1-47f9-8aaf-930dd715f854,DISK], DatanodeInfoWithStorage[127.0.0.1:37274,DS-2fe814af-2656-48e9-b2ff-25057090e5e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46691,DS-89ef0041-c92d-4e36-87c7-e42a483b2513,DISK], DatanodeInfoWithStorage[127.0.0.1:40083,DS-cee454e0-619b-4e77-8caf-30157e11769c,DISK], DatanodeInfoWithStorage[127.0.0.1:32885,DS-09dfa3b7-b7f8-42b0-81c5-58b40fff7891,DISK], DatanodeInfoWithStorage[127.0.0.1:43167,DS-56448d87-d951-4d7f-bf50-c6c2046c04ed,DISK], DatanodeInfoWithStorage[127.0.0.1:37147,DS-85566098-6047-49a5-8d14-fb5d103a6d98,DISK], DatanodeInfoWithStorage[127.0.0.1:37055,DS-e3868beb-5401-4947-ab77-6810f459046e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.byte-array-manager.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-95102555-172.17.0.16-1596946122476:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37965,DS-39d6685e-6dff-4d4e-9156-09a152e2b479,DISK], DatanodeInfoWithStorage[127.0.0.1:36735,DS-fa002408-e1fb-426e-bd21-6b0a0385501c,DISK], DatanodeInfoWithStorage[127.0.0.1:46485,DS-2ecd641f-5825-41bb-b1a5-edde02b1b3e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34039,DS-034740a6-5b24-450d-a5fc-2d3bf3619f3a,DISK], DatanodeInfoWithStorage[127.0.0.1:39501,DS-846f6f02-488c-4e2c-9770-0023481c8940,DISK], DatanodeInfoWithStorage[127.0.0.1:35884,DS-8e4cdc17-72ca-41a0-8625-93a7326fa186,DISK], DatanodeInfoWithStorage[127.0.0.1:41733,DS-f5155dac-310c-4ed7-a749-20354ee6c41a,DISK], DatanodeInfoWithStorage[127.0.0.1:44770,DS-2097a3dc-6d75-47dd-9802-e346a452eef5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-95102555-172.17.0.16-1596946122476:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37965,DS-39d6685e-6dff-4d4e-9156-09a152e2b479,DISK], DatanodeInfoWithStorage[127.0.0.1:36735,DS-fa002408-e1fb-426e-bd21-6b0a0385501c,DISK], DatanodeInfoWithStorage[127.0.0.1:46485,DS-2ecd641f-5825-41bb-b1a5-edde02b1b3e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34039,DS-034740a6-5b24-450d-a5fc-2d3bf3619f3a,DISK], DatanodeInfoWithStorage[127.0.0.1:39501,DS-846f6f02-488c-4e2c-9770-0023481c8940,DISK], DatanodeInfoWithStorage[127.0.0.1:35884,DS-8e4cdc17-72ca-41a0-8625-93a7326fa186,DISK], DatanodeInfoWithStorage[127.0.0.1:41733,DS-f5155dac-310c-4ed7-a749-20354ee6c41a,DISK], DatanodeInfoWithStorage[127.0.0.1:44770,DS-2097a3dc-6d75-47dd-9802-e346a452eef5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.byte-array-manager.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1420115545-172.17.0.16-1596946766043:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43131,DS-5439173c-d8a5-40e2-9dd8-1c53862b402b,DISK], DatanodeInfoWithStorage[127.0.0.1:33453,DS-ed31a232-0bcc-4c52-8804-8c6ee2a4d59d,DISK], DatanodeInfoWithStorage[127.0.0.1:38853,DS-4960c12f-6072-4c1d-b519-33b0cc0e9cd9,DISK], DatanodeInfoWithStorage[127.0.0.1:43469,DS-f7c985b0-3c8a-4fcf-b96f-d3139147edec,DISK], DatanodeInfoWithStorage[127.0.0.1:40881,DS-28c8bc58-7abb-424e-811a-83ebbe15c177,DISK], DatanodeInfoWithStorage[127.0.0.1:46056,DS-4367b975-160a-4166-b466-df7c458713b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46611,DS-a1957431-036d-4b1b-8037-e26ff408220f,DISK], DatanodeInfoWithStorage[127.0.0.1:33251,DS-9ec2cfda-816e-420d-8c75-637054209a8f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1420115545-172.17.0.16-1596946766043:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43131,DS-5439173c-d8a5-40e2-9dd8-1c53862b402b,DISK], DatanodeInfoWithStorage[127.0.0.1:33453,DS-ed31a232-0bcc-4c52-8804-8c6ee2a4d59d,DISK], DatanodeInfoWithStorage[127.0.0.1:38853,DS-4960c12f-6072-4c1d-b519-33b0cc0e9cd9,DISK], DatanodeInfoWithStorage[127.0.0.1:43469,DS-f7c985b0-3c8a-4fcf-b96f-d3139147edec,DISK], DatanodeInfoWithStorage[127.0.0.1:40881,DS-28c8bc58-7abb-424e-811a-83ebbe15c177,DISK], DatanodeInfoWithStorage[127.0.0.1:46056,DS-4367b975-160a-4166-b466-df7c458713b1,DISK], DatanodeInfoWithStorage[127.0.0.1:46611,DS-a1957431-036d-4b1b-8037-e26ff408220f,DISK], DatanodeInfoWithStorage[127.0.0.1:33251,DS-9ec2cfda-816e-420d-8c75-637054209a8f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.byte-array-manager.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1417027163-172.17.0.16-1596947265321:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42045,DS-0e139cb1-5654-4927-a7ec-9de76e00e39d,DISK], DatanodeInfoWithStorage[127.0.0.1:37145,DS-69319723-8137-4f32-a0c3-2a006689c1f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41844,DS-7a488a1c-1100-4cc7-9f9a-f0eb23da3b3a,DISK], DatanodeInfoWithStorage[127.0.0.1:40635,DS-4b9ab6a5-4d58-4d41-8f94-134319f873a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42042,DS-9397eef6-be8b-4955-bfab-905260fd7d10,DISK], DatanodeInfoWithStorage[127.0.0.1:39815,DS-3adad0a8-1c9a-40ba-a862-8f43aa112818,DISK], DatanodeInfoWithStorage[127.0.0.1:34386,DS-a114a600-e431-4f85-9bab-06ef594f3860,DISK], DatanodeInfoWithStorage[127.0.0.1:38300,DS-cf76779a-a9c8-453b-a3fe-d1d15981334b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1417027163-172.17.0.16-1596947265321:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42045,DS-0e139cb1-5654-4927-a7ec-9de76e00e39d,DISK], DatanodeInfoWithStorage[127.0.0.1:37145,DS-69319723-8137-4f32-a0c3-2a006689c1f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41844,DS-7a488a1c-1100-4cc7-9f9a-f0eb23da3b3a,DISK], DatanodeInfoWithStorage[127.0.0.1:40635,DS-4b9ab6a5-4d58-4d41-8f94-134319f873a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42042,DS-9397eef6-be8b-4955-bfab-905260fd7d10,DISK], DatanodeInfoWithStorage[127.0.0.1:39815,DS-3adad0a8-1c9a-40ba-a862-8f43aa112818,DISK], DatanodeInfoWithStorage[127.0.0.1:34386,DS-a114a600-e431-4f85-9bab-06ef594f3860,DISK], DatanodeInfoWithStorage[127.0.0.1:38300,DS-cf76779a-a9c8-453b-a3fe-d1d15981334b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.write.byte-array-manager.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1477035911-172.17.0.16-1596947479984:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43605,DS-6aedd8cc-8ba5-43ec-a63c-22199c5c559b,DISK], DatanodeInfoWithStorage[127.0.0.1:33491,DS-98658620-bc4f-4b11-8f76-6241292464d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45870,DS-815dd159-a2e7-4597-a999-a22db6d400d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37831,DS-661d4a56-6740-43af-88f9-6100a88465a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33411,DS-f41c8785-751b-4e0e-92e4-622b1e93fdbc,DISK], DatanodeInfoWithStorage[127.0.0.1:34122,DS-1eb2e18f-73c6-4102-b6ea-4327a22b9210,DISK], DatanodeInfoWithStorage[127.0.0.1:46450,DS-2bf58404-fc44-4559-b8e1-b1b2e1c682c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41539,DS-2fe77ec6-ff93-4c19-a078-b1cdb14797c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1477035911-172.17.0.16-1596947479984:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43605,DS-6aedd8cc-8ba5-43ec-a63c-22199c5c559b,DISK], DatanodeInfoWithStorage[127.0.0.1:33491,DS-98658620-bc4f-4b11-8f76-6241292464d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45870,DS-815dd159-a2e7-4597-a999-a22db6d400d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37831,DS-661d4a56-6740-43af-88f9-6100a88465a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33411,DS-f41c8785-751b-4e0e-92e4-622b1e93fdbc,DISK], DatanodeInfoWithStorage[127.0.0.1:34122,DS-1eb2e18f-73c6-4102-b6ea-4327a22b9210,DISK], DatanodeInfoWithStorage[127.0.0.1:46450,DS-2bf58404-fc44-4559-b8e1-b1b2e1c682c4,DISK], DatanodeInfoWithStorage[127.0.0.1:41539,DS-2fe77ec6-ff93-4c19-a078-b1cdb14797c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.byte-array-manager.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-509968504-172.17.0.16-1596947548707:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36133,DS-f235ab35-6387-4600-bd6a-33d4fe1e2627,DISK], DatanodeInfoWithStorage[127.0.0.1:41724,DS-6f6c7747-14c0-44f3-a518-c6e81a023c57,DISK], DatanodeInfoWithStorage[127.0.0.1:36276,DS-25755bd8-f4bb-4235-bde9-30d67462c91f,DISK], DatanodeInfoWithStorage[127.0.0.1:36413,DS-dac29c06-43b9-4179-94ea-01d82ebe9c05,DISK], DatanodeInfoWithStorage[127.0.0.1:44458,DS-11ba80ca-ed39-44e4-b30f-7b57ce8994a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35507,DS-8e031fd0-a8a4-4fc6-9cdc-7b4c4db84632,DISK], DatanodeInfoWithStorage[127.0.0.1:37554,DS-fb4b2bbb-a4d2-4436-855f-354a37d0a67f,DISK], DatanodeInfoWithStorage[127.0.0.1:42078,DS-5ea7ebe9-d237-4868-ad3c-b78b2e1d7658,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-509968504-172.17.0.16-1596947548707:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36133,DS-f235ab35-6387-4600-bd6a-33d4fe1e2627,DISK], DatanodeInfoWithStorage[127.0.0.1:41724,DS-6f6c7747-14c0-44f3-a518-c6e81a023c57,DISK], DatanodeInfoWithStorage[127.0.0.1:36276,DS-25755bd8-f4bb-4235-bde9-30d67462c91f,DISK], DatanodeInfoWithStorage[127.0.0.1:36413,DS-dac29c06-43b9-4179-94ea-01d82ebe9c05,DISK], DatanodeInfoWithStorage[127.0.0.1:44458,DS-11ba80ca-ed39-44e4-b30f-7b57ce8994a9,DISK], DatanodeInfoWithStorage[127.0.0.1:35507,DS-8e031fd0-a8a4-4fc6-9cdc-7b4c4db84632,DISK], DatanodeInfoWithStorage[127.0.0.1:37554,DS-fb4b2bbb-a4d2-4436-855f-354a37d0a67f,DISK], DatanodeInfoWithStorage[127.0.0.1:42078,DS-5ea7ebe9-d237-4868-ad3c-b78b2e1d7658,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.write.byte-array-manager.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2138895983-172.17.0.16-1596947578702:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46850,DS-9eb398cc-3b7c-4a88-9d03-dd7efb6bcfe4,DISK], DatanodeInfoWithStorage[127.0.0.1:33584,DS-3e9456c4-5f18-4252-97ed-3f3c39beaa88,DISK], DatanodeInfoWithStorage[127.0.0.1:41042,DS-80684cc3-eac0-4254-b082-8c84ba1a5c2d,DISK], DatanodeInfoWithStorage[127.0.0.1:35955,DS-34e8df0d-cd33-4049-8596-2d2babba6fab,DISK], DatanodeInfoWithStorage[127.0.0.1:40692,DS-817de881-d237-499f-b433-0de0b1f412c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40482,DS-b2b41b00-4f01-4309-933c-2b198f8c7ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:40845,DS-7426eee1-2304-49ba-abc8-6e5b97fde73e,DISK], DatanodeInfoWithStorage[127.0.0.1:45564,DS-7dca08f3-474d-46b8-9866-64e9b9611369,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2138895983-172.17.0.16-1596947578702:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46850,DS-9eb398cc-3b7c-4a88-9d03-dd7efb6bcfe4,DISK], DatanodeInfoWithStorage[127.0.0.1:33584,DS-3e9456c4-5f18-4252-97ed-3f3c39beaa88,DISK], DatanodeInfoWithStorage[127.0.0.1:41042,DS-80684cc3-eac0-4254-b082-8c84ba1a5c2d,DISK], DatanodeInfoWithStorage[127.0.0.1:35955,DS-34e8df0d-cd33-4049-8596-2d2babba6fab,DISK], DatanodeInfoWithStorage[127.0.0.1:40692,DS-817de881-d237-499f-b433-0de0b1f412c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40482,DS-b2b41b00-4f01-4309-933c-2b198f8c7ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:40845,DS-7426eee1-2304-49ba-abc8-6e5b97fde73e,DISK], DatanodeInfoWithStorage[127.0.0.1:45564,DS-7dca08f3-474d-46b8-9866-64e9b9611369,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.write.byte-array-manager.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1518652071-172.17.0.16-1596947684154:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39717,DS-614c65ca-dd6c-48b9-b17b-969622eef186,DISK], DatanodeInfoWithStorage[127.0.0.1:37221,DS-cfae60c9-fc5c-4880-9810-eda5a40a13c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33346,DS-9f930a7b-a3dc-4616-8556-4046e0c03a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:45409,DS-50a11670-3ad3-477c-8696-4c7cc4dec38f,DISK], DatanodeInfoWithStorage[127.0.0.1:39095,DS-4ec9e236-e3ba-476f-88a6-532f26c43792,DISK], DatanodeInfoWithStorage[127.0.0.1:45622,DS-f7878c1a-3858-4b8c-9218-24183f69919e,DISK], DatanodeInfoWithStorage[127.0.0.1:36409,DS-eef1683f-697a-4a8a-8843-4f7272a6a23a,DISK], DatanodeInfoWithStorage[127.0.0.1:43852,DS-f805bb16-4839-4aec-841c-9c41eeeae05d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1518652071-172.17.0.16-1596947684154:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39717,DS-614c65ca-dd6c-48b9-b17b-969622eef186,DISK], DatanodeInfoWithStorage[127.0.0.1:37221,DS-cfae60c9-fc5c-4880-9810-eda5a40a13c9,DISK], DatanodeInfoWithStorage[127.0.0.1:33346,DS-9f930a7b-a3dc-4616-8556-4046e0c03a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:45409,DS-50a11670-3ad3-477c-8696-4c7cc4dec38f,DISK], DatanodeInfoWithStorage[127.0.0.1:39095,DS-4ec9e236-e3ba-476f-88a6-532f26c43792,DISK], DatanodeInfoWithStorage[127.0.0.1:45622,DS-f7878c1a-3858-4b8c-9218-24183f69919e,DISK], DatanodeInfoWithStorage[127.0.0.1:36409,DS-eef1683f-697a-4a8a-8843-4f7272a6a23a,DISK], DatanodeInfoWithStorage[127.0.0.1:43852,DS-f805bb16-4839-4aec-841c-9c41eeeae05d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.write.byte-array-manager.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-622231542-172.17.0.16-1596948284253:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42619,DS-c07e1a62-21fe-472e-80e3-ea1b97613d59,DISK], DatanodeInfoWithStorage[127.0.0.1:39921,DS-a8c7592b-6a4a-499a-831e-5bcdf1db8192,DISK], DatanodeInfoWithStorage[127.0.0.1:40977,DS-fc7031a8-1b18-480b-b774-7e8e94cc52e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42206,DS-51dc3282-d06b-44f9-b5e2-a92bcb7636fc,DISK], DatanodeInfoWithStorage[127.0.0.1:37099,DS-c680fb5e-e82f-4c90-8068-da5a3966df66,DISK], DatanodeInfoWithStorage[127.0.0.1:42910,DS-75ce1f8c-fa36-4be9-acd1-f5a0d6f3ea92,DISK], DatanodeInfoWithStorage[127.0.0.1:43052,DS-3000309d-7efd-4027-9c87-c4c7fbb8f244,DISK], DatanodeInfoWithStorage[127.0.0.1:41103,DS-1b31baa7-1cd2-4ba4-a030-07ae7eab2e92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-622231542-172.17.0.16-1596948284253:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42619,DS-c07e1a62-21fe-472e-80e3-ea1b97613d59,DISK], DatanodeInfoWithStorage[127.0.0.1:39921,DS-a8c7592b-6a4a-499a-831e-5bcdf1db8192,DISK], DatanodeInfoWithStorage[127.0.0.1:40977,DS-fc7031a8-1b18-480b-b774-7e8e94cc52e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42206,DS-51dc3282-d06b-44f9-b5e2-a92bcb7636fc,DISK], DatanodeInfoWithStorage[127.0.0.1:37099,DS-c680fb5e-e82f-4c90-8068-da5a3966df66,DISK], DatanodeInfoWithStorage[127.0.0.1:42910,DS-75ce1f8c-fa36-4be9-acd1-f5a0d6f3ea92,DISK], DatanodeInfoWithStorage[127.0.0.1:43052,DS-3000309d-7efd-4027-9c87-c4c7fbb8f244,DISK], DatanodeInfoWithStorage[127.0.0.1:41103,DS-1b31baa7-1cd2-4ba4-a030-07ae7eab2e92,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.byte-array-manager.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-130241212-172.17.0.16-1596948762840:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36542,DS-2df5780b-f570-4cd0-8e7e-49c5f332d85a,DISK], DatanodeInfoWithStorage[127.0.0.1:33570,DS-67eb6a21-4df4-4adf-afed-d97855bf8d84,DISK], DatanodeInfoWithStorage[127.0.0.1:34753,DS-b38c9a72-fcaa-4c30-9289-a3f20173630a,DISK], DatanodeInfoWithStorage[127.0.0.1:36477,DS-964e4f10-8868-49be-b0a2-b9d613ee13a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38811,DS-7746a361-4f87-41e9-8b82-4f98c834765f,DISK], DatanodeInfoWithStorage[127.0.0.1:36046,DS-962c1664-ca45-4416-af1a-0b35f261bfb0,DISK], DatanodeInfoWithStorage[127.0.0.1:33536,DS-456f2529-6433-42d2-881d-6a77c2aea1a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33247,DS-1f614fce-1d6b-4ec3-9dec-e5eec28a893a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-130241212-172.17.0.16-1596948762840:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36542,DS-2df5780b-f570-4cd0-8e7e-49c5f332d85a,DISK], DatanodeInfoWithStorage[127.0.0.1:33570,DS-67eb6a21-4df4-4adf-afed-d97855bf8d84,DISK], DatanodeInfoWithStorage[127.0.0.1:34753,DS-b38c9a72-fcaa-4c30-9289-a3f20173630a,DISK], DatanodeInfoWithStorage[127.0.0.1:36477,DS-964e4f10-8868-49be-b0a2-b9d613ee13a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38811,DS-7746a361-4f87-41e9-8b82-4f98c834765f,DISK], DatanodeInfoWithStorage[127.0.0.1:36046,DS-962c1664-ca45-4416-af1a-0b35f261bfb0,DISK], DatanodeInfoWithStorage[127.0.0.1:33536,DS-456f2529-6433-42d2-881d-6a77c2aea1a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33247,DS-1f614fce-1d6b-4ec3-9dec-e5eec28a893a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.write.byte-array-manager.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1465611387-172.17.0.16-1596948793548:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37105,DS-0a41de17-49dd-4afd-a63b-e62a3bb3f52f,DISK], DatanodeInfoWithStorage[127.0.0.1:36385,DS-6954569e-b8a9-4364-9862-9648dc57590c,DISK], DatanodeInfoWithStorage[127.0.0.1:46390,DS-bc7f4f57-8100-4671-9c9f-70a6d73e5a22,DISK], DatanodeInfoWithStorage[127.0.0.1:37904,DS-ca93c634-d623-44ae-93bb-708e196a1033,DISK], DatanodeInfoWithStorage[127.0.0.1:39076,DS-a107e3e6-92ec-48ab-b56e-1744102934ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41673,DS-0cb3ef68-74e4-4773-a097-1607d207aa99,DISK], DatanodeInfoWithStorage[127.0.0.1:45724,DS-103287d8-68f6-4285-bdc4-77dcaed70ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:43395,DS-e0282f31-44a3-4551-b346-4eac5602604e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1465611387-172.17.0.16-1596948793548:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37105,DS-0a41de17-49dd-4afd-a63b-e62a3bb3f52f,DISK], DatanodeInfoWithStorage[127.0.0.1:36385,DS-6954569e-b8a9-4364-9862-9648dc57590c,DISK], DatanodeInfoWithStorage[127.0.0.1:46390,DS-bc7f4f57-8100-4671-9c9f-70a6d73e5a22,DISK], DatanodeInfoWithStorage[127.0.0.1:37904,DS-ca93c634-d623-44ae-93bb-708e196a1033,DISK], DatanodeInfoWithStorage[127.0.0.1:39076,DS-a107e3e6-92ec-48ab-b56e-1744102934ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41673,DS-0cb3ef68-74e4-4773-a097-1607d207aa99,DISK], DatanodeInfoWithStorage[127.0.0.1:45724,DS-103287d8-68f6-4285-bdc4-77dcaed70ba2,DISK], DatanodeInfoWithStorage[127.0.0.1:43395,DS-e0282f31-44a3-4551-b346-4eac5602604e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.byte-array-manager.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-924987450-172.17.0.16-1596948852331:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41897,DS-c8ac14f1-c519-411b-b8df-6aaa1bc8bb1b,DISK], DatanodeInfoWithStorage[127.0.0.1:41619,DS-abd3c44e-5135-440f-8ff1-217b62060583,DISK], DatanodeInfoWithStorage[127.0.0.1:36933,DS-5a3b9c77-e22c-4610-b1fd-5163a133dc12,DISK], DatanodeInfoWithStorage[127.0.0.1:34474,DS-8ac9125d-65d0-4e57-aaf0-d616fbc8a5f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41145,DS-b04158b4-3f10-4cc1-a216-e1cc9751044e,DISK], DatanodeInfoWithStorage[127.0.0.1:35621,DS-4837edd4-ba07-415d-9887-b507d0dd4877,DISK], DatanodeInfoWithStorage[127.0.0.1:38177,DS-5574f849-fe60-43a3-a402-d4e30ce4a423,DISK], DatanodeInfoWithStorage[127.0.0.1:34340,DS-51a43132-c1e6-48b5-b6c7-44be811ba51b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-924987450-172.17.0.16-1596948852331:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41897,DS-c8ac14f1-c519-411b-b8df-6aaa1bc8bb1b,DISK], DatanodeInfoWithStorage[127.0.0.1:41619,DS-abd3c44e-5135-440f-8ff1-217b62060583,DISK], DatanodeInfoWithStorage[127.0.0.1:36933,DS-5a3b9c77-e22c-4610-b1fd-5163a133dc12,DISK], DatanodeInfoWithStorage[127.0.0.1:34474,DS-8ac9125d-65d0-4e57-aaf0-d616fbc8a5f6,DISK], DatanodeInfoWithStorage[127.0.0.1:41145,DS-b04158b4-3f10-4cc1-a216-e1cc9751044e,DISK], DatanodeInfoWithStorage[127.0.0.1:35621,DS-4837edd4-ba07-415d-9887-b507d0dd4877,DISK], DatanodeInfoWithStorage[127.0.0.1:38177,DS-5574f849-fe60-43a3-a402-d4e30ce4a423,DISK], DatanodeInfoWithStorage[127.0.0.1:34340,DS-51a43132-c1e6-48b5-b6c7-44be811ba51b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 4559
