reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-251459969-172.17.0.16-1596883761297:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41202,DS-1bf94cb3-5e5c-4c16-9786-856b406249b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41138,DS-803ebf5b-9909-415f-a405-aaab83798fcd,DISK], DatanodeInfoWithStorage[127.0.0.1:43325,DS-5f659a5e-003a-4f7d-81f1-15a762f91f05,DISK], DatanodeInfoWithStorage[127.0.0.1:45642,DS-f9e8340d-2d48-413a-9f34-51c9ae83b4f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43492,DS-252a3159-9adb-4311-8692-8a05e77e8a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:33314,DS-df7f122d-d837-4c76-9592-18337d261eaf,DISK], DatanodeInfoWithStorage[127.0.0.1:36800,DS-b3815f0f-43de-4ae7-987d-2ecf3d24c625,DISK], DatanodeInfoWithStorage[127.0.0.1:33557,DS-f11f3c3d-740e-41a4-94c3-e241deca2989,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-251459969-172.17.0.16-1596883761297:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41202,DS-1bf94cb3-5e5c-4c16-9786-856b406249b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41138,DS-803ebf5b-9909-415f-a405-aaab83798fcd,DISK], DatanodeInfoWithStorage[127.0.0.1:43325,DS-5f659a5e-003a-4f7d-81f1-15a762f91f05,DISK], DatanodeInfoWithStorage[127.0.0.1:45642,DS-f9e8340d-2d48-413a-9f34-51c9ae83b4f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43492,DS-252a3159-9adb-4311-8692-8a05e77e8a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:33314,DS-df7f122d-d837-4c76-9592-18337d261eaf,DISK], DatanodeInfoWithStorage[127.0.0.1:36800,DS-b3815f0f-43de-4ae7-987d-2ecf3d24c625,DISK], DatanodeInfoWithStorage[127.0.0.1:33557,DS-f11f3c3d-740e-41a4-94c3-e241deca2989,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-763288259-172.17.0.16-1596883847724:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46239,DS-62b394fe-791f-44e1-9f03-e9a476f0bf19,DISK], DatanodeInfoWithStorage[127.0.0.1:45010,DS-a3b7e4a2-ed04-4268-b81f-5f183ddce480,DISK], DatanodeInfoWithStorage[127.0.0.1:40399,DS-c9c24552-784b-488e-89a0-6b9b23dd1256,DISK], DatanodeInfoWithStorage[127.0.0.1:37431,DS-c3e6c909-06d9-40a5-86a4-b23430fe0b52,DISK], DatanodeInfoWithStorage[127.0.0.1:42105,DS-4cbc39ce-deb4-4068-8626-fbae38a36b71,DISK], DatanodeInfoWithStorage[127.0.0.1:45482,DS-dcc9621e-da4f-4ec6-8366-89c503af7a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:36822,DS-e0b49a8c-73c9-454a-a388-215e1d713a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:46498,DS-54d7ab30-fa4e-43c9-b67d-06e8d8e79087,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-763288259-172.17.0.16-1596883847724:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46239,DS-62b394fe-791f-44e1-9f03-e9a476f0bf19,DISK], DatanodeInfoWithStorage[127.0.0.1:45010,DS-a3b7e4a2-ed04-4268-b81f-5f183ddce480,DISK], DatanodeInfoWithStorage[127.0.0.1:40399,DS-c9c24552-784b-488e-89a0-6b9b23dd1256,DISK], DatanodeInfoWithStorage[127.0.0.1:37431,DS-c3e6c909-06d9-40a5-86a4-b23430fe0b52,DISK], DatanodeInfoWithStorage[127.0.0.1:42105,DS-4cbc39ce-deb4-4068-8626-fbae38a36b71,DISK], DatanodeInfoWithStorage[127.0.0.1:45482,DS-dcc9621e-da4f-4ec6-8366-89c503af7a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:36822,DS-e0b49a8c-73c9-454a-a388-215e1d713a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:46498,DS-54d7ab30-fa4e-43c9-b67d-06e8d8e79087,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-419372185-172.17.0.16-1596884002672:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34920,DS-43d26a38-c2af-4ebb-b636-1c974028ecf9,DISK], DatanodeInfoWithStorage[127.0.0.1:43212,DS-f7c530b7-fb81-41cf-940d-b2c8e710068d,DISK], DatanodeInfoWithStorage[127.0.0.1:41843,DS-e271a11e-a4a4-4a2d-b7c9-dc36f03c44d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37962,DS-c28b3ce5-35af-4ed1-97d0-1f7ec1bd85f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38076,DS-e0710581-349d-4701-af8b-2cc27dc90850,DISK], DatanodeInfoWithStorage[127.0.0.1:44466,DS-9287c22f-bd46-4867-a6de-15c105bd594a,DISK], DatanodeInfoWithStorage[127.0.0.1:44832,DS-88ff4099-c06b-433b-bec7-7a57a70bed43,DISK], DatanodeInfoWithStorage[127.0.0.1:44121,DS-2c944de5-9861-42d9-97f2-6eda4fc0ee72,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-419372185-172.17.0.16-1596884002672:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34920,DS-43d26a38-c2af-4ebb-b636-1c974028ecf9,DISK], DatanodeInfoWithStorage[127.0.0.1:43212,DS-f7c530b7-fb81-41cf-940d-b2c8e710068d,DISK], DatanodeInfoWithStorage[127.0.0.1:41843,DS-e271a11e-a4a4-4a2d-b7c9-dc36f03c44d7,DISK], DatanodeInfoWithStorage[127.0.0.1:37962,DS-c28b3ce5-35af-4ed1-97d0-1f7ec1bd85f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38076,DS-e0710581-349d-4701-af8b-2cc27dc90850,DISK], DatanodeInfoWithStorage[127.0.0.1:44466,DS-9287c22f-bd46-4867-a6de-15c105bd594a,DISK], DatanodeInfoWithStorage[127.0.0.1:44832,DS-88ff4099-c06b-433b-bec7-7a57a70bed43,DISK], DatanodeInfoWithStorage[127.0.0.1:44121,DS-2c944de5-9861-42d9-97f2-6eda4fc0ee72,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-487983106-172.17.0.16-1596884644143:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36035,DS-08dafb48-a0db-4fb1-9d68-37033eddf5b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36849,DS-63fe128c-3053-4f14-99f4-b3766efcfafb,DISK], DatanodeInfoWithStorage[127.0.0.1:35713,DS-0eac3c04-5f08-4355-93e1-091ad8aa156d,DISK], DatanodeInfoWithStorage[127.0.0.1:39650,DS-12262496-a0f4-4ac8-bb6c-4cc6d9e502ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36307,DS-1491d97e-947e-4e45-a5ab-ff5eb005b45c,DISK], DatanodeInfoWithStorage[127.0.0.1:39086,DS-65cfdecd-f9f2-4434-b73e-ae4c108dd464,DISK], DatanodeInfoWithStorage[127.0.0.1:36263,DS-8750519c-5528-461b-8a3d-60d288008ee6,DISK], DatanodeInfoWithStorage[127.0.0.1:43693,DS-ddac6bba-f328-4ffe-8477-05c6b9fcab05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-487983106-172.17.0.16-1596884644143:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36035,DS-08dafb48-a0db-4fb1-9d68-37033eddf5b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36849,DS-63fe128c-3053-4f14-99f4-b3766efcfafb,DISK], DatanodeInfoWithStorage[127.0.0.1:35713,DS-0eac3c04-5f08-4355-93e1-091ad8aa156d,DISK], DatanodeInfoWithStorage[127.0.0.1:39650,DS-12262496-a0f4-4ac8-bb6c-4cc6d9e502ea,DISK], DatanodeInfoWithStorage[127.0.0.1:36307,DS-1491d97e-947e-4e45-a5ab-ff5eb005b45c,DISK], DatanodeInfoWithStorage[127.0.0.1:39086,DS-65cfdecd-f9f2-4434-b73e-ae4c108dd464,DISK], DatanodeInfoWithStorage[127.0.0.1:36263,DS-8750519c-5528-461b-8a3d-60d288008ee6,DISK], DatanodeInfoWithStorage[127.0.0.1:43693,DS-ddac6bba-f328-4ffe-8477-05c6b9fcab05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-800512129-172.17.0.16-1596885654175:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36785,DS-e7b2891b-241d-45b0-a0ab-a38884c3196e,DISK], DatanodeInfoWithStorage[127.0.0.1:39180,DS-f901f75f-5ef1-4c4e-99a5-1c3b6f34cb14,DISK], DatanodeInfoWithStorage[127.0.0.1:39052,DS-1aa5f3cb-599c-409c-8f2c-eee8fe716cb3,DISK], DatanodeInfoWithStorage[127.0.0.1:46391,DS-c48c85ee-745c-48a8-b933-e01be556693b,DISK], DatanodeInfoWithStorage[127.0.0.1:41060,DS-ebe90d05-96af-482f-8538-bb3a3ebba410,DISK], DatanodeInfoWithStorage[127.0.0.1:37143,DS-ac328885-66f0-404f-9c45-114c7f54932c,DISK], DatanodeInfoWithStorage[127.0.0.1:42945,DS-80565829-2857-48e2-9971-803e618f5717,DISK], DatanodeInfoWithStorage[127.0.0.1:36610,DS-403af8b6-4049-4dfb-9d27-8692f9af2cde,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-800512129-172.17.0.16-1596885654175:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36785,DS-e7b2891b-241d-45b0-a0ab-a38884c3196e,DISK], DatanodeInfoWithStorage[127.0.0.1:39180,DS-f901f75f-5ef1-4c4e-99a5-1c3b6f34cb14,DISK], DatanodeInfoWithStorage[127.0.0.1:39052,DS-1aa5f3cb-599c-409c-8f2c-eee8fe716cb3,DISK], DatanodeInfoWithStorage[127.0.0.1:46391,DS-c48c85ee-745c-48a8-b933-e01be556693b,DISK], DatanodeInfoWithStorage[127.0.0.1:41060,DS-ebe90d05-96af-482f-8538-bb3a3ebba410,DISK], DatanodeInfoWithStorage[127.0.0.1:37143,DS-ac328885-66f0-404f-9c45-114c7f54932c,DISK], DatanodeInfoWithStorage[127.0.0.1:42945,DS-80565829-2857-48e2-9971-803e618f5717,DISK], DatanodeInfoWithStorage[127.0.0.1:36610,DS-403af8b6-4049-4dfb-9d27-8692f9af2cde,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1384457670-172.17.0.16-1596885721776:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42683,DS-981fe0b8-98ca-49a3-b698-2f3bde5b9817,DISK], DatanodeInfoWithStorage[127.0.0.1:42445,DS-1a459c99-461f-4ac3-bf4e-7177d5dfd8de,DISK], DatanodeInfoWithStorage[127.0.0.1:36198,DS-073c3f47-4095-411e-914d-b580a48f5f2d,DISK], DatanodeInfoWithStorage[127.0.0.1:37615,DS-a7cfac12-46ab-4b8c-a040-40c224639812,DISK], DatanodeInfoWithStorage[127.0.0.1:44347,DS-8c670131-1bf7-4f2a-b1df-c5d21ecbc6ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45733,DS-9a6d91ee-e406-4802-9fef-d791892124f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40687,DS-b343458c-5aab-4024-9af8-92407f84a622,DISK], DatanodeInfoWithStorage[127.0.0.1:46250,DS-2687c395-bdce-43a8-8218-149660d2a3f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1384457670-172.17.0.16-1596885721776:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42683,DS-981fe0b8-98ca-49a3-b698-2f3bde5b9817,DISK], DatanodeInfoWithStorage[127.0.0.1:42445,DS-1a459c99-461f-4ac3-bf4e-7177d5dfd8de,DISK], DatanodeInfoWithStorage[127.0.0.1:36198,DS-073c3f47-4095-411e-914d-b580a48f5f2d,DISK], DatanodeInfoWithStorage[127.0.0.1:37615,DS-a7cfac12-46ab-4b8c-a040-40c224639812,DISK], DatanodeInfoWithStorage[127.0.0.1:44347,DS-8c670131-1bf7-4f2a-b1df-c5d21ecbc6ab,DISK], DatanodeInfoWithStorage[127.0.0.1:45733,DS-9a6d91ee-e406-4802-9fef-d791892124f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40687,DS-b343458c-5aab-4024-9af8-92407f84a622,DISK], DatanodeInfoWithStorage[127.0.0.1:46250,DS-2687c395-bdce-43a8-8218-149660d2a3f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1011793297-172.17.0.16-1596885754146:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35958,DS-770a9c2d-089d-4f0e-b70b-d634744a770b,DISK], DatanodeInfoWithStorage[127.0.0.1:33919,DS-b9e5354f-e251-41be-9e9a-2afaaa9c1918,DISK], DatanodeInfoWithStorage[127.0.0.1:39496,DS-0ec5f3c8-faf1-4093-8554-650cd8342517,DISK], DatanodeInfoWithStorage[127.0.0.1:35694,DS-106d6fff-50ca-484a-aaf9-fe14b0d57a37,DISK], DatanodeInfoWithStorage[127.0.0.1:46428,DS-b71007a9-3b12-490b-bb15-2b93ef723402,DISK], DatanodeInfoWithStorage[127.0.0.1:45123,DS-45374467-45e1-4233-a5cf-be8fd5703be8,DISK], DatanodeInfoWithStorage[127.0.0.1:38250,DS-771d08f2-b94f-4119-9cda-287a1a717281,DISK], DatanodeInfoWithStorage[127.0.0.1:34828,DS-77ae701b-8989-47e1-b657-d362937b5530,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1011793297-172.17.0.16-1596885754146:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35958,DS-770a9c2d-089d-4f0e-b70b-d634744a770b,DISK], DatanodeInfoWithStorage[127.0.0.1:33919,DS-b9e5354f-e251-41be-9e9a-2afaaa9c1918,DISK], DatanodeInfoWithStorage[127.0.0.1:39496,DS-0ec5f3c8-faf1-4093-8554-650cd8342517,DISK], DatanodeInfoWithStorage[127.0.0.1:35694,DS-106d6fff-50ca-484a-aaf9-fe14b0d57a37,DISK], DatanodeInfoWithStorage[127.0.0.1:46428,DS-b71007a9-3b12-490b-bb15-2b93ef723402,DISK], DatanodeInfoWithStorage[127.0.0.1:45123,DS-45374467-45e1-4233-a5cf-be8fd5703be8,DISK], DatanodeInfoWithStorage[127.0.0.1:38250,DS-771d08f2-b94f-4119-9cda-287a1a717281,DISK], DatanodeInfoWithStorage[127.0.0.1:34828,DS-77ae701b-8989-47e1-b657-d362937b5530,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-875829539-172.17.0.16-1596885940497:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46386,DS-588b3f3b-fd21-466b-81ca-e6acd66fb304,DISK], DatanodeInfoWithStorage[127.0.0.1:42728,DS-2be33bff-c5cd-48f6-902f-34f7a9a657f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36617,DS-4db4162b-a57c-4b63-8827-d350edb17153,DISK], DatanodeInfoWithStorage[127.0.0.1:32933,DS-6824a200-ed9d-47f5-8cca-afee4978cee9,DISK], DatanodeInfoWithStorage[127.0.0.1:38616,DS-d0af6ba1-96b0-4fbe-a498-dd33385e3355,DISK], DatanodeInfoWithStorage[127.0.0.1:40228,DS-21ffbc37-0ad8-4aa9-b4fb-55aeb8801945,DISK], DatanodeInfoWithStorage[127.0.0.1:46564,DS-773200d1-00ff-45a1-82d2-780e744bc0a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37800,DS-508927ce-bd4c-44c3-9f91-d94b96c3e7ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-875829539-172.17.0.16-1596885940497:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46386,DS-588b3f3b-fd21-466b-81ca-e6acd66fb304,DISK], DatanodeInfoWithStorage[127.0.0.1:42728,DS-2be33bff-c5cd-48f6-902f-34f7a9a657f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36617,DS-4db4162b-a57c-4b63-8827-d350edb17153,DISK], DatanodeInfoWithStorage[127.0.0.1:32933,DS-6824a200-ed9d-47f5-8cca-afee4978cee9,DISK], DatanodeInfoWithStorage[127.0.0.1:38616,DS-d0af6ba1-96b0-4fbe-a498-dd33385e3355,DISK], DatanodeInfoWithStorage[127.0.0.1:40228,DS-21ffbc37-0ad8-4aa9-b4fb-55aeb8801945,DISK], DatanodeInfoWithStorage[127.0.0.1:46564,DS-773200d1-00ff-45a1-82d2-780e744bc0a2,DISK], DatanodeInfoWithStorage[127.0.0.1:37800,DS-508927ce-bd4c-44c3-9f91-d94b96c3e7ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1735590758-172.17.0.16-1596886488466:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40710,DS-a36c23ed-b6ce-4862-8669-da54d05b780d,DISK], DatanodeInfoWithStorage[127.0.0.1:40874,DS-6864cea9-bb35-4ce7-ace2-52ebc37fd8a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43531,DS-cebd504b-9239-4e28-87c8-f37ce07cdc86,DISK], DatanodeInfoWithStorage[127.0.0.1:35010,DS-7d5078d1-a0b4-4a43-8760-e7b9b4b0803c,DISK], DatanodeInfoWithStorage[127.0.0.1:37184,DS-f5008e9d-2d19-43f5-9a86-74990611aa39,DISK], DatanodeInfoWithStorage[127.0.0.1:34375,DS-db8f8c53-4652-4a94-a631-a3b3a8c6fd08,DISK], DatanodeInfoWithStorage[127.0.0.1:33396,DS-ba4bbe92-1146-4a34-8486-4f3e3af7b757,DISK], DatanodeInfoWithStorage[127.0.0.1:40727,DS-404f2878-88e4-48b0-b5c6-9a9c5a0b3ec7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1735590758-172.17.0.16-1596886488466:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40710,DS-a36c23ed-b6ce-4862-8669-da54d05b780d,DISK], DatanodeInfoWithStorage[127.0.0.1:40874,DS-6864cea9-bb35-4ce7-ace2-52ebc37fd8a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43531,DS-cebd504b-9239-4e28-87c8-f37ce07cdc86,DISK], DatanodeInfoWithStorage[127.0.0.1:35010,DS-7d5078d1-a0b4-4a43-8760-e7b9b4b0803c,DISK], DatanodeInfoWithStorage[127.0.0.1:37184,DS-f5008e9d-2d19-43f5-9a86-74990611aa39,DISK], DatanodeInfoWithStorage[127.0.0.1:34375,DS-db8f8c53-4652-4a94-a631-a3b3a8c6fd08,DISK], DatanodeInfoWithStorage[127.0.0.1:33396,DS-ba4bbe92-1146-4a34-8486-4f3e3af7b757,DISK], DatanodeInfoWithStorage[127.0.0.1:40727,DS-404f2878-88e4-48b0-b5c6-9a9c5a0b3ec7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-722331952-172.17.0.16-1596888155070:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41749,DS-2d4eb408-0412-45e7-bc36-8dbb1060d4ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42830,DS-bb312b77-2f5b-45ff-86cf-809e4f19cea8,DISK], DatanodeInfoWithStorage[127.0.0.1:42129,DS-65e22559-6968-499f-8bab-c48bf6899c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:45210,DS-aa50ac6c-2314-4d71-8252-e1db837eb00b,DISK], DatanodeInfoWithStorage[127.0.0.1:38069,DS-a36afd4e-7e37-427f-8ff5-93974898bf4e,DISK], DatanodeInfoWithStorage[127.0.0.1:34150,DS-18867845-9376-4cbc-86b8-4e94d3b15a0a,DISK], DatanodeInfoWithStorage[127.0.0.1:37784,DS-34ff831a-0262-43c3-a58a-d58896f1cdf7,DISK], DatanodeInfoWithStorage[127.0.0.1:44110,DS-8455d4ea-7d05-4e79-8ca4-2184a3e25d34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-722331952-172.17.0.16-1596888155070:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41749,DS-2d4eb408-0412-45e7-bc36-8dbb1060d4ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42830,DS-bb312b77-2f5b-45ff-86cf-809e4f19cea8,DISK], DatanodeInfoWithStorage[127.0.0.1:42129,DS-65e22559-6968-499f-8bab-c48bf6899c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:45210,DS-aa50ac6c-2314-4d71-8252-e1db837eb00b,DISK], DatanodeInfoWithStorage[127.0.0.1:38069,DS-a36afd4e-7e37-427f-8ff5-93974898bf4e,DISK], DatanodeInfoWithStorage[127.0.0.1:34150,DS-18867845-9376-4cbc-86b8-4e94d3b15a0a,DISK], DatanodeInfoWithStorage[127.0.0.1:37784,DS-34ff831a-0262-43c3-a58a-d58896f1cdf7,DISK], DatanodeInfoWithStorage[127.0.0.1:44110,DS-8455d4ea-7d05-4e79-8ca4-2184a3e25d34,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 5 out of 50
result: false positive !!!
Total execution time in seconds : 5374
