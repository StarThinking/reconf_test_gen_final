reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-422958199-172.17.0.6-1595403851510:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39851,DS-bb1af139-5866-47a0-b4f2-839c6c049c0e,DISK], DatanodeInfoWithStorage[127.0.0.1:44676,DS-70f4b297-ad1a-4ad7-b225-f9f8aa91f56d,DISK], DatanodeInfoWithStorage[127.0.0.1:39147,DS-f93f4e6d-c628-471c-9e71-e282980e78a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35490,DS-6f38f1fe-d82b-44b9-8fa7-bc38aaf076a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46167,DS-1f626094-7b36-4903-8f82-6dad930ad4dd,DISK], DatanodeInfoWithStorage[127.0.0.1:32984,DS-1deb1781-ba15-4ad6-afb0-78803a4325f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42895,DS-3251e68a-4adf-49e7-8a88-5d23af8d4d3e,DISK], DatanodeInfoWithStorage[127.0.0.1:35925,DS-38e604cc-50ec-44d6-a8df-9307fb0e3cc4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-422958199-172.17.0.6-1595403851510:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39851,DS-bb1af139-5866-47a0-b4f2-839c6c049c0e,DISK], DatanodeInfoWithStorage[127.0.0.1:44676,DS-70f4b297-ad1a-4ad7-b225-f9f8aa91f56d,DISK], DatanodeInfoWithStorage[127.0.0.1:39147,DS-f93f4e6d-c628-471c-9e71-e282980e78a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35490,DS-6f38f1fe-d82b-44b9-8fa7-bc38aaf076a8,DISK], DatanodeInfoWithStorage[127.0.0.1:46167,DS-1f626094-7b36-4903-8f82-6dad930ad4dd,DISK], DatanodeInfoWithStorage[127.0.0.1:32984,DS-1deb1781-ba15-4ad6-afb0-78803a4325f2,DISK], DatanodeInfoWithStorage[127.0.0.1:42895,DS-3251e68a-4adf-49e7-8a88-5d23af8d4d3e,DISK], DatanodeInfoWithStorage[127.0.0.1:35925,DS-38e604cc-50ec-44d6-a8df-9307fb0e3cc4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-7121075-172.17.0.6-1595403982295:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39450,DS-6ce844c5-bff5-4f0d-a3f9-882ff36fc18d,DISK], DatanodeInfoWithStorage[127.0.0.1:36741,DS-f081c131-435d-4206-ad55-5c95af8b5a8f,DISK], DatanodeInfoWithStorage[127.0.0.1:38238,DS-2757162b-6504-4920-82a1-5d75f35d2b97,DISK], DatanodeInfoWithStorage[127.0.0.1:40978,DS-30e43111-8257-4759-9f59-4e24ed455eab,DISK], DatanodeInfoWithStorage[127.0.0.1:39129,DS-9fb4617f-3239-44cb-8cfd-b0eec4f03504,DISK], DatanodeInfoWithStorage[127.0.0.1:33921,DS-f6bdb005-0000-4c0a-8ea7-28d7511582b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39096,DS-375f9a01-7d4b-4daa-a703-bc77444fb166,DISK], DatanodeInfoWithStorage[127.0.0.1:33336,DS-9b76d7ad-a059-4b4a-b71e-fb75756b76b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-7121075-172.17.0.6-1595403982295:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39450,DS-6ce844c5-bff5-4f0d-a3f9-882ff36fc18d,DISK], DatanodeInfoWithStorage[127.0.0.1:36741,DS-f081c131-435d-4206-ad55-5c95af8b5a8f,DISK], DatanodeInfoWithStorage[127.0.0.1:38238,DS-2757162b-6504-4920-82a1-5d75f35d2b97,DISK], DatanodeInfoWithStorage[127.0.0.1:40978,DS-30e43111-8257-4759-9f59-4e24ed455eab,DISK], DatanodeInfoWithStorage[127.0.0.1:39129,DS-9fb4617f-3239-44cb-8cfd-b0eec4f03504,DISK], DatanodeInfoWithStorage[127.0.0.1:33921,DS-f6bdb005-0000-4c0a-8ea7-28d7511582b0,DISK], DatanodeInfoWithStorage[127.0.0.1:39096,DS-375f9a01-7d4b-4daa-a703-bc77444fb166,DISK], DatanodeInfoWithStorage[127.0.0.1:33336,DS-9b76d7ad-a059-4b4a-b71e-fb75756b76b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1840046244-172.17.0.6-1595404221363:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35175,DS-e6517f7c-4df3-43a2-b4d6-a7bd378a10c1,DISK], DatanodeInfoWithStorage[127.0.0.1:35985,DS-464db293-1756-4de1-bb7a-82211baf8fed,DISK], DatanodeInfoWithStorage[127.0.0.1:38939,DS-d2a37e06-4c92-48b1-a17d-e4a83d0a11db,DISK], DatanodeInfoWithStorage[127.0.0.1:39797,DS-33964e12-7f01-4040-b2af-625c79de8b88,DISK], DatanodeInfoWithStorage[127.0.0.1:40558,DS-a4090532-57e0-4997-8ba2-b96ed4e3db4f,DISK], DatanodeInfoWithStorage[127.0.0.1:37535,DS-3d9708e4-7d04-487b-9fa4-8c6623c95931,DISK], DatanodeInfoWithStorage[127.0.0.1:42564,DS-e689095c-84a1-4124-acc4-7a3fe056890b,DISK], DatanodeInfoWithStorage[127.0.0.1:46211,DS-e93c2411-4026-4af9-8f83-08cafeab6042,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1840046244-172.17.0.6-1595404221363:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35175,DS-e6517f7c-4df3-43a2-b4d6-a7bd378a10c1,DISK], DatanodeInfoWithStorage[127.0.0.1:35985,DS-464db293-1756-4de1-bb7a-82211baf8fed,DISK], DatanodeInfoWithStorage[127.0.0.1:38939,DS-d2a37e06-4c92-48b1-a17d-e4a83d0a11db,DISK], DatanodeInfoWithStorage[127.0.0.1:39797,DS-33964e12-7f01-4040-b2af-625c79de8b88,DISK], DatanodeInfoWithStorage[127.0.0.1:40558,DS-a4090532-57e0-4997-8ba2-b96ed4e3db4f,DISK], DatanodeInfoWithStorage[127.0.0.1:37535,DS-3d9708e4-7d04-487b-9fa4-8c6623c95931,DISK], DatanodeInfoWithStorage[127.0.0.1:42564,DS-e689095c-84a1-4124-acc4-7a3fe056890b,DISK], DatanodeInfoWithStorage[127.0.0.1:46211,DS-e93c2411-4026-4af9-8f83-08cafeab6042,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-942824616-172.17.0.6-1595404616778:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46018,DS-5b07556c-618a-4ead-8626-3de808f74fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:36960,DS-41bd1e6d-18c6-4df7-9d2b-dfc156bc2e49,DISK], DatanodeInfoWithStorage[127.0.0.1:33986,DS-ce4277ea-f98e-4928-bd56-d172f67ac0d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35926,DS-e7b312bd-48a0-4a82-89b6-e690cbe1d489,DISK], DatanodeInfoWithStorage[127.0.0.1:36766,DS-98f7dbff-537d-4cd6-ad4e-eb222be439a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40298,DS-34509d67-573b-416f-bd42-1a9f76e94ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:43897,DS-321b6206-b0da-4d54-a750-d217c2b6a556,DISK], DatanodeInfoWithStorage[127.0.0.1:39681,DS-e822039c-22da-4b78-8d12-04fc2c2762df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-942824616-172.17.0.6-1595404616778:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46018,DS-5b07556c-618a-4ead-8626-3de808f74fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:36960,DS-41bd1e6d-18c6-4df7-9d2b-dfc156bc2e49,DISK], DatanodeInfoWithStorage[127.0.0.1:33986,DS-ce4277ea-f98e-4928-bd56-d172f67ac0d3,DISK], DatanodeInfoWithStorage[127.0.0.1:35926,DS-e7b312bd-48a0-4a82-89b6-e690cbe1d489,DISK], DatanodeInfoWithStorage[127.0.0.1:36766,DS-98f7dbff-537d-4cd6-ad4e-eb222be439a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40298,DS-34509d67-573b-416f-bd42-1a9f76e94ab2,DISK], DatanodeInfoWithStorage[127.0.0.1:43897,DS-321b6206-b0da-4d54-a750-d217c2b6a556,DISK], DatanodeInfoWithStorage[127.0.0.1:39681,DS-e822039c-22da-4b78-8d12-04fc2c2762df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1183752566-172.17.0.6-1595404716137:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35419,DS-9fbfa140-9412-4680-95f1-76e757663ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:34690,DS-fea7d08d-4f9e-41f5-a8be-7bdfc7b84dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:46154,DS-f2bc556d-e8f1-452b-868a-ff75fc0cdc8b,DISK], DatanodeInfoWithStorage[127.0.0.1:45508,DS-a1fadcbb-1146-4c87-93ce-eeed6240279f,DISK], DatanodeInfoWithStorage[127.0.0.1:43539,DS-26ecfa00-e7cd-411d-838a-60587211375f,DISK], DatanodeInfoWithStorage[127.0.0.1:39569,DS-fcf0b58c-6e43-44cc-82d3-63d0a9158166,DISK], DatanodeInfoWithStorage[127.0.0.1:36234,DS-899d3e7f-944a-4f67-beda-92acb8398617,DISK], DatanodeInfoWithStorage[127.0.0.1:36348,DS-d9946878-08f8-4a59-8317-2c347725266f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1183752566-172.17.0.6-1595404716137:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35419,DS-9fbfa140-9412-4680-95f1-76e757663ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:34690,DS-fea7d08d-4f9e-41f5-a8be-7bdfc7b84dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:46154,DS-f2bc556d-e8f1-452b-868a-ff75fc0cdc8b,DISK], DatanodeInfoWithStorage[127.0.0.1:45508,DS-a1fadcbb-1146-4c87-93ce-eeed6240279f,DISK], DatanodeInfoWithStorage[127.0.0.1:43539,DS-26ecfa00-e7cd-411d-838a-60587211375f,DISK], DatanodeInfoWithStorage[127.0.0.1:39569,DS-fcf0b58c-6e43-44cc-82d3-63d0a9158166,DISK], DatanodeInfoWithStorage[127.0.0.1:36234,DS-899d3e7f-944a-4f67-beda-92acb8398617,DISK], DatanodeInfoWithStorage[127.0.0.1:36348,DS-d9946878-08f8-4a59-8317-2c347725266f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-423543896-172.17.0.6-1595404826930:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39324,DS-1aefac29-11b4-4a77-b0bb-28dd03a39d61,DISK], DatanodeInfoWithStorage[127.0.0.1:34599,DS-731a99a6-1d7a-43ab-9813-cf9148ed3051,DISK], DatanodeInfoWithStorage[127.0.0.1:34614,DS-6d7459bc-93bd-4675-b3a7-fdcfbe3d26ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37414,DS-99cecafa-cdfb-4ff6-b1fa-6c8ab84cfe82,DISK], DatanodeInfoWithStorage[127.0.0.1:36266,DS-feb4b7af-73fa-47ba-87e0-c83b14c25344,DISK], DatanodeInfoWithStorage[127.0.0.1:44828,DS-766ac8e0-6002-440a-afe4-324a6db75d55,DISK], DatanodeInfoWithStorage[127.0.0.1:42969,DS-a27108fc-c8b0-48be-9128-7c9d4253b0db,DISK], DatanodeInfoWithStorage[127.0.0.1:36329,DS-4ad52c1b-f650-47d3-95de-296b9bb4b76f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-423543896-172.17.0.6-1595404826930:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39324,DS-1aefac29-11b4-4a77-b0bb-28dd03a39d61,DISK], DatanodeInfoWithStorage[127.0.0.1:34599,DS-731a99a6-1d7a-43ab-9813-cf9148ed3051,DISK], DatanodeInfoWithStorage[127.0.0.1:34614,DS-6d7459bc-93bd-4675-b3a7-fdcfbe3d26ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37414,DS-99cecafa-cdfb-4ff6-b1fa-6c8ab84cfe82,DISK], DatanodeInfoWithStorage[127.0.0.1:36266,DS-feb4b7af-73fa-47ba-87e0-c83b14c25344,DISK], DatanodeInfoWithStorage[127.0.0.1:44828,DS-766ac8e0-6002-440a-afe4-324a6db75d55,DISK], DatanodeInfoWithStorage[127.0.0.1:42969,DS-a27108fc-c8b0-48be-9128-7c9d4253b0db,DISK], DatanodeInfoWithStorage[127.0.0.1:36329,DS-4ad52c1b-f650-47d3-95de-296b9bb4b76f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1369913528-172.17.0.6-1595405014350:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36392,DS-27682578-51f1-40d8-8109-3da3d6d049c0,DISK], DatanodeInfoWithStorage[127.0.0.1:38980,DS-1f257e3d-db63-4a64-ae2e-080d5d15c23a,DISK], DatanodeInfoWithStorage[127.0.0.1:37233,DS-70243fbe-bb87-4412-a189-7ad131bd70ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38938,DS-692c26fc-f252-461f-97ad-6a83f9d8ca6d,DISK], DatanodeInfoWithStorage[127.0.0.1:34825,DS-8dce60b2-54c3-4be5-aff0-d234402f46fb,DISK], DatanodeInfoWithStorage[127.0.0.1:33805,DS-4db624aa-2150-4b77-9199-751d39ac37e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43993,DS-a91487d5-403a-45d4-9e58-fc1b30644ef7,DISK], DatanodeInfoWithStorage[127.0.0.1:34831,DS-67b6e860-540a-4331-95d0-8da9a88d42fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1369913528-172.17.0.6-1595405014350:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36392,DS-27682578-51f1-40d8-8109-3da3d6d049c0,DISK], DatanodeInfoWithStorage[127.0.0.1:38980,DS-1f257e3d-db63-4a64-ae2e-080d5d15c23a,DISK], DatanodeInfoWithStorage[127.0.0.1:37233,DS-70243fbe-bb87-4412-a189-7ad131bd70ce,DISK], DatanodeInfoWithStorage[127.0.0.1:38938,DS-692c26fc-f252-461f-97ad-6a83f9d8ca6d,DISK], DatanodeInfoWithStorage[127.0.0.1:34825,DS-8dce60b2-54c3-4be5-aff0-d234402f46fb,DISK], DatanodeInfoWithStorage[127.0.0.1:33805,DS-4db624aa-2150-4b77-9199-751d39ac37e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43993,DS-a91487d5-403a-45d4-9e58-fc1b30644ef7,DISK], DatanodeInfoWithStorage[127.0.0.1:34831,DS-67b6e860-540a-4331-95d0-8da9a88d42fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-427394208-172.17.0.6-1595405481686:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39539,DS-cb54b55a-3fd4-4291-b613-a8f7fe36f21c,DISK], DatanodeInfoWithStorage[127.0.0.1:46039,DS-00720fc6-9f6e-47e9-a52b-63f1935e8ad5,DISK], DatanodeInfoWithStorage[127.0.0.1:35495,DS-341a80eb-f9c6-4a5d-a74d-338febc6baa3,DISK], DatanodeInfoWithStorage[127.0.0.1:38347,DS-6e9d2f8c-5b48-44dc-8849-6b594bf2c334,DISK], DatanodeInfoWithStorage[127.0.0.1:45545,DS-450766f2-5df4-4eb9-a20c-e5d89a39c27d,DISK], DatanodeInfoWithStorage[127.0.0.1:35246,DS-f468d159-cf0b-4727-b956-907f48d0aa02,DISK], DatanodeInfoWithStorage[127.0.0.1:43104,DS-c105a76a-1401-4d15-a1fe-6b5704cd98e7,DISK], DatanodeInfoWithStorage[127.0.0.1:46234,DS-e3fc3a2f-e770-4650-9d85-4add0cab1e89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-427394208-172.17.0.6-1595405481686:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39539,DS-cb54b55a-3fd4-4291-b613-a8f7fe36f21c,DISK], DatanodeInfoWithStorage[127.0.0.1:46039,DS-00720fc6-9f6e-47e9-a52b-63f1935e8ad5,DISK], DatanodeInfoWithStorage[127.0.0.1:35495,DS-341a80eb-f9c6-4a5d-a74d-338febc6baa3,DISK], DatanodeInfoWithStorage[127.0.0.1:38347,DS-6e9d2f8c-5b48-44dc-8849-6b594bf2c334,DISK], DatanodeInfoWithStorage[127.0.0.1:45545,DS-450766f2-5df4-4eb9-a20c-e5d89a39c27d,DISK], DatanodeInfoWithStorage[127.0.0.1:35246,DS-f468d159-cf0b-4727-b956-907f48d0aa02,DISK], DatanodeInfoWithStorage[127.0.0.1:43104,DS-c105a76a-1401-4d15-a1fe-6b5704cd98e7,DISK], DatanodeInfoWithStorage[127.0.0.1:46234,DS-e3fc3a2f-e770-4650-9d85-4add0cab1e89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-555331182-172.17.0.6-1595405625898:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37843,DS-ffe3198a-7b36-4e10-848b-90a7e0e70807,DISK], DatanodeInfoWithStorage[127.0.0.1:34212,DS-e4d69b58-ed55-4d37-a73c-e4c68b35ae42,DISK], DatanodeInfoWithStorage[127.0.0.1:35897,DS-f5645c5e-0fd8-4794-9364-d32c94c3a5c2,DISK], DatanodeInfoWithStorage[127.0.0.1:36176,DS-8dc91497-d284-41e1-b0c2-0060b92867ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42513,DS-2b5d3d4c-02f3-4258-b9fc-ba715bd2415f,DISK], DatanodeInfoWithStorage[127.0.0.1:39646,DS-271ab035-9489-49ad-a4ad-a8cea652211a,DISK], DatanodeInfoWithStorage[127.0.0.1:44158,DS-eeb58390-1c8a-488a-9d7c-7c507d774ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:38689,DS-641703cc-e1ce-4674-970f-95cc1905b40d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-555331182-172.17.0.6-1595405625898:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37843,DS-ffe3198a-7b36-4e10-848b-90a7e0e70807,DISK], DatanodeInfoWithStorage[127.0.0.1:34212,DS-e4d69b58-ed55-4d37-a73c-e4c68b35ae42,DISK], DatanodeInfoWithStorage[127.0.0.1:35897,DS-f5645c5e-0fd8-4794-9364-d32c94c3a5c2,DISK], DatanodeInfoWithStorage[127.0.0.1:36176,DS-8dc91497-d284-41e1-b0c2-0060b92867ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42513,DS-2b5d3d4c-02f3-4258-b9fc-ba715bd2415f,DISK], DatanodeInfoWithStorage[127.0.0.1:39646,DS-271ab035-9489-49ad-a4ad-a8cea652211a,DISK], DatanodeInfoWithStorage[127.0.0.1:44158,DS-eeb58390-1c8a-488a-9d7c-7c507d774ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:38689,DS-641703cc-e1ce-4674-970f-95cc1905b40d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1879155432-172.17.0.6-1595405774615:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42055,DS-27728eba-d85b-4004-9b0b-09502c78d852,DISK], DatanodeInfoWithStorage[127.0.0.1:37692,DS-1e1fddaa-ab2f-4f6e-b8b9-78f90a52a0f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39593,DS-f8fec054-d5e3-4fa5-82f2-711902a0de91,DISK], DatanodeInfoWithStorage[127.0.0.1:45612,DS-d0ac67d3-8dbb-4d67-9b83-fddd9c794fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:35185,DS-c5109299-d248-462b-b0a2-9f6b7410f349,DISK], DatanodeInfoWithStorage[127.0.0.1:45185,DS-6b21c82b-c9b7-4f3c-a232-cb2b0172b3d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39800,DS-70aa4c8b-b862-42d2-9f9c-1854e2a70e7a,DISK], DatanodeInfoWithStorage[127.0.0.1:42650,DS-09410228-4fb2-47f5-9996-0467fdacfd46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1879155432-172.17.0.6-1595405774615:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42055,DS-27728eba-d85b-4004-9b0b-09502c78d852,DISK], DatanodeInfoWithStorage[127.0.0.1:37692,DS-1e1fddaa-ab2f-4f6e-b8b9-78f90a52a0f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39593,DS-f8fec054-d5e3-4fa5-82f2-711902a0de91,DISK], DatanodeInfoWithStorage[127.0.0.1:45612,DS-d0ac67d3-8dbb-4d67-9b83-fddd9c794fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:35185,DS-c5109299-d248-462b-b0a2-9f6b7410f349,DISK], DatanodeInfoWithStorage[127.0.0.1:45185,DS-6b21c82b-c9b7-4f3c-a232-cb2b0172b3d3,DISK], DatanodeInfoWithStorage[127.0.0.1:39800,DS-70aa4c8b-b862-42d2-9f9c-1854e2a70e7a,DISK], DatanodeInfoWithStorage[127.0.0.1:42650,DS-09410228-4fb2-47f5-9996-0467fdacfd46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1625985253-172.17.0.6-1595405979114:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35742,DS-c6803cf4-977a-4d69-8000-7b97e76cf14c,DISK], DatanodeInfoWithStorage[127.0.0.1:38825,DS-e843a8f7-9fae-4bae-a41b-ff85fa5a92e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36458,DS-a03fb3b5-a9c7-4742-a15f-a21d25f3259e,DISK], DatanodeInfoWithStorage[127.0.0.1:46487,DS-38b9ad00-dd08-4aec-a11a-60a0f1fade48,DISK], DatanodeInfoWithStorage[127.0.0.1:40492,DS-dbecc3e4-2d30-42cb-afef-b4372b7adaa9,DISK], DatanodeInfoWithStorage[127.0.0.1:36276,DS-4ebbfc8a-3dc3-40ff-bc06-c775f78e671a,DISK], DatanodeInfoWithStorage[127.0.0.1:45158,DS-220a3f51-252b-4ddb-a640-c6584ef02bca,DISK], DatanodeInfoWithStorage[127.0.0.1:38006,DS-8a964c41-d3b4-4d59-87ec-76071d0e4584,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1625985253-172.17.0.6-1595405979114:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35742,DS-c6803cf4-977a-4d69-8000-7b97e76cf14c,DISK], DatanodeInfoWithStorage[127.0.0.1:38825,DS-e843a8f7-9fae-4bae-a41b-ff85fa5a92e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36458,DS-a03fb3b5-a9c7-4742-a15f-a21d25f3259e,DISK], DatanodeInfoWithStorage[127.0.0.1:46487,DS-38b9ad00-dd08-4aec-a11a-60a0f1fade48,DISK], DatanodeInfoWithStorage[127.0.0.1:40492,DS-dbecc3e4-2d30-42cb-afef-b4372b7adaa9,DISK], DatanodeInfoWithStorage[127.0.0.1:36276,DS-4ebbfc8a-3dc3-40ff-bc06-c775f78e671a,DISK], DatanodeInfoWithStorage[127.0.0.1:45158,DS-220a3f51-252b-4ddb-a640-c6584ef02bca,DISK], DatanodeInfoWithStorage[127.0.0.1:38006,DS-8a964c41-d3b4-4d59-87ec-76071d0e4584,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1720937161-172.17.0.6-1595406696113:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37280,DS-41ada54f-538d-4c0d-a553-4a0230e49e9b,DISK], DatanodeInfoWithStorage[127.0.0.1:45687,DS-d824a60f-408d-4d09-a53b-820896c5f0f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35629,DS-2076a16b-e6a5-447b-ac85-be3f74179be8,DISK], DatanodeInfoWithStorage[127.0.0.1:36866,DS-e8e671d3-53de-4dca-92e5-d61fc337706d,DISK], DatanodeInfoWithStorage[127.0.0.1:36089,DS-f97f9ae6-59bf-4e41-8d5c-411319cac053,DISK], DatanodeInfoWithStorage[127.0.0.1:41049,DS-afc87948-500c-4bd3-b7e3-688963cbefe7,DISK], DatanodeInfoWithStorage[127.0.0.1:32845,DS-0c3e25f8-f6c0-4c06-a193-53d07e442c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:38895,DS-6d6809e7-d366-4082-a6eb-1faf855f3cc2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1720937161-172.17.0.6-1595406696113:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37280,DS-41ada54f-538d-4c0d-a553-4a0230e49e9b,DISK], DatanodeInfoWithStorage[127.0.0.1:45687,DS-d824a60f-408d-4d09-a53b-820896c5f0f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35629,DS-2076a16b-e6a5-447b-ac85-be3f74179be8,DISK], DatanodeInfoWithStorage[127.0.0.1:36866,DS-e8e671d3-53de-4dca-92e5-d61fc337706d,DISK], DatanodeInfoWithStorage[127.0.0.1:36089,DS-f97f9ae6-59bf-4e41-8d5c-411319cac053,DISK], DatanodeInfoWithStorage[127.0.0.1:41049,DS-afc87948-500c-4bd3-b7e3-688963cbefe7,DISK], DatanodeInfoWithStorage[127.0.0.1:32845,DS-0c3e25f8-f6c0-4c06-a193-53d07e442c0d,DISK], DatanodeInfoWithStorage[127.0.0.1:38895,DS-6d6809e7-d366-4082-a6eb-1faf855f3cc2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-148868812-172.17.0.6-1595406869613:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40868,DS-48e45032-2e1e-43c9-bb4c-d5379a20c2d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35771,DS-27b5faac-a078-423f-a8a6-6ba29a8c6464,DISK], DatanodeInfoWithStorage[127.0.0.1:36583,DS-cc18b18d-b45a-4a4b-9741-0a625479846e,DISK], DatanodeInfoWithStorage[127.0.0.1:46617,DS-af4cf449-9692-401f-9076-d6358b48765e,DISK], DatanodeInfoWithStorage[127.0.0.1:33941,DS-2d21a5bb-85a2-4cf7-b70b-5fff934dfe42,DISK], DatanodeInfoWithStorage[127.0.0.1:33524,DS-d9f221de-4aae-4b14-bfff-012b8a7920d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41802,DS-762fc16f-8b96-48ab-ba56-af8d493eb76c,DISK], DatanodeInfoWithStorage[127.0.0.1:36964,DS-6896f4cb-1d96-4501-833a-5bef8f597a03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-148868812-172.17.0.6-1595406869613:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40868,DS-48e45032-2e1e-43c9-bb4c-d5379a20c2d5,DISK], DatanodeInfoWithStorage[127.0.0.1:35771,DS-27b5faac-a078-423f-a8a6-6ba29a8c6464,DISK], DatanodeInfoWithStorage[127.0.0.1:36583,DS-cc18b18d-b45a-4a4b-9741-0a625479846e,DISK], DatanodeInfoWithStorage[127.0.0.1:46617,DS-af4cf449-9692-401f-9076-d6358b48765e,DISK], DatanodeInfoWithStorage[127.0.0.1:33941,DS-2d21a5bb-85a2-4cf7-b70b-5fff934dfe42,DISK], DatanodeInfoWithStorage[127.0.0.1:33524,DS-d9f221de-4aae-4b14-bfff-012b8a7920d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41802,DS-762fc16f-8b96-48ab-ba56-af8d493eb76c,DISK], DatanodeInfoWithStorage[127.0.0.1:36964,DS-6896f4cb-1d96-4501-833a-5bef8f597a03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-105787252-172.17.0.6-1595407039379:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46141,DS-10f3ce8a-38d3-4d18-be8c-970da260952e,DISK], DatanodeInfoWithStorage[127.0.0.1:44559,DS-d78b6c0c-5d0b-4e57-b860-ef4ba7c2e2e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42288,DS-96c7abca-7fd6-461a-84a1-293bf4e4cbfe,DISK], DatanodeInfoWithStorage[127.0.0.1:46482,DS-6c88971e-811d-4733-a442-80d0761369c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34987,DS-a48a919e-9e21-4a94-b99a-7a4223c4af79,DISK], DatanodeInfoWithStorage[127.0.0.1:43224,DS-faf4930a-91a8-45ad-a403-38feda308ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:35012,DS-86d51d67-8947-49f3-a485-f10fec02ade2,DISK], DatanodeInfoWithStorage[127.0.0.1:43609,DS-1f57ef46-0125-48bb-b975-f4c81a861cd2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-105787252-172.17.0.6-1595407039379:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46141,DS-10f3ce8a-38d3-4d18-be8c-970da260952e,DISK], DatanodeInfoWithStorage[127.0.0.1:44559,DS-d78b6c0c-5d0b-4e57-b860-ef4ba7c2e2e5,DISK], DatanodeInfoWithStorage[127.0.0.1:42288,DS-96c7abca-7fd6-461a-84a1-293bf4e4cbfe,DISK], DatanodeInfoWithStorage[127.0.0.1:46482,DS-6c88971e-811d-4733-a442-80d0761369c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34987,DS-a48a919e-9e21-4a94-b99a-7a4223c4af79,DISK], DatanodeInfoWithStorage[127.0.0.1:43224,DS-faf4930a-91a8-45ad-a403-38feda308ad9,DISK], DatanodeInfoWithStorage[127.0.0.1:35012,DS-86d51d67-8947-49f3-a485-f10fec02ade2,DISK], DatanodeInfoWithStorage[127.0.0.1:43609,DS-1f57ef46-0125-48bb-b975-f4c81a861cd2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1234233413-172.17.0.6-1595407271851:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40261,DS-2e27a3ba-1017-4d57-aeb0-12e94344c086,DISK], DatanodeInfoWithStorage[127.0.0.1:34540,DS-bef79fc0-3457-4760-91e9-8daca684629a,DISK], DatanodeInfoWithStorage[127.0.0.1:45995,DS-309b829f-8e18-4c89-bfab-8272e9352dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:37502,DS-db68616d-c8ce-4152-847f-2c6df4fb7b65,DISK], DatanodeInfoWithStorage[127.0.0.1:41640,DS-fb9262df-7ed5-45d6-8266-2ff3117f29a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33180,DS-50c1789b-52f4-4387-861c-df01ad4c3bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:41064,DS-d96ff278-6d50-4d3b-acea-ea73f15f10ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37770,DS-800f78c7-badb-4f8d-8934-581496aee06c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1234233413-172.17.0.6-1595407271851:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40261,DS-2e27a3ba-1017-4d57-aeb0-12e94344c086,DISK], DatanodeInfoWithStorage[127.0.0.1:34540,DS-bef79fc0-3457-4760-91e9-8daca684629a,DISK], DatanodeInfoWithStorage[127.0.0.1:45995,DS-309b829f-8e18-4c89-bfab-8272e9352dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:37502,DS-db68616d-c8ce-4152-847f-2c6df4fb7b65,DISK], DatanodeInfoWithStorage[127.0.0.1:41640,DS-fb9262df-7ed5-45d6-8266-2ff3117f29a6,DISK], DatanodeInfoWithStorage[127.0.0.1:33180,DS-50c1789b-52f4-4387-861c-df01ad4c3bd1,DISK], DatanodeInfoWithStorage[127.0.0.1:41064,DS-d96ff278-6d50-4d3b-acea-ea73f15f10ff,DISK], DatanodeInfoWithStorage[127.0.0.1:37770,DS-800f78c7-badb-4f8d-8934-581496aee06c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1326401123-172.17.0.6-1595407665017:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37030,DS-ab03c635-2697-4550-a73e-05f39773901c,DISK], DatanodeInfoWithStorage[127.0.0.1:44041,DS-fcae5d4d-bdbf-4b1b-b7de-429a394228d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45988,DS-60b4611d-71ec-40d0-b84b-fbddd4dc1d8c,DISK], DatanodeInfoWithStorage[127.0.0.1:41441,DS-de31d7ee-2f14-4c79-93c8-556c59543d66,DISK], DatanodeInfoWithStorage[127.0.0.1:44032,DS-63f4721d-6247-48b4-aca3-3d6b82169256,DISK], DatanodeInfoWithStorage[127.0.0.1:43111,DS-abc1ca60-e127-4cbd-b3e2-64d543d1033e,DISK], DatanodeInfoWithStorage[127.0.0.1:45504,DS-e4b72985-0242-4881-a2e1-f48efe7bd3f8,DISK], DatanodeInfoWithStorage[127.0.0.1:45839,DS-2c750620-90d7-4e51-a487-dc1e4c62ca05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1326401123-172.17.0.6-1595407665017:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37030,DS-ab03c635-2697-4550-a73e-05f39773901c,DISK], DatanodeInfoWithStorage[127.0.0.1:44041,DS-fcae5d4d-bdbf-4b1b-b7de-429a394228d2,DISK], DatanodeInfoWithStorage[127.0.0.1:45988,DS-60b4611d-71ec-40d0-b84b-fbddd4dc1d8c,DISK], DatanodeInfoWithStorage[127.0.0.1:41441,DS-de31d7ee-2f14-4c79-93c8-556c59543d66,DISK], DatanodeInfoWithStorage[127.0.0.1:44032,DS-63f4721d-6247-48b4-aca3-3d6b82169256,DISK], DatanodeInfoWithStorage[127.0.0.1:43111,DS-abc1ca60-e127-4cbd-b3e2-64d543d1033e,DISK], DatanodeInfoWithStorage[127.0.0.1:45504,DS-e4b72985-0242-4881-a2e1-f48efe7bd3f8,DISK], DatanodeInfoWithStorage[127.0.0.1:45839,DS-2c750620-90d7-4e51-a487-dc1e4c62ca05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2055875504-172.17.0.6-1595408586978:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43116,DS-cdc9bc5b-c445-41fa-9f32-a8f7117d2034,DISK], DatanodeInfoWithStorage[127.0.0.1:32769,DS-4ee41c3f-761f-4e47-a5a3-6cc87874081d,DISK], DatanodeInfoWithStorage[127.0.0.1:45220,DS-d6265bf4-866c-48b4-9731-baae0f206ae5,DISK], DatanodeInfoWithStorage[127.0.0.1:36809,DS-da128007-d20e-40fd-9573-ba474a874453,DISK], DatanodeInfoWithStorage[127.0.0.1:42432,DS-881f9c90-8c71-4d90-9625-bb41375d3317,DISK], DatanodeInfoWithStorage[127.0.0.1:43695,DS-78f3ac9e-3385-4544-b5b7-9d7d222882e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38443,DS-b8e7355a-3b21-4388-bf16-3925764cfdec,DISK], DatanodeInfoWithStorage[127.0.0.1:42110,DS-34b42b05-4069-4a21-94d4-c492ea8cf169,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2055875504-172.17.0.6-1595408586978:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43116,DS-cdc9bc5b-c445-41fa-9f32-a8f7117d2034,DISK], DatanodeInfoWithStorage[127.0.0.1:32769,DS-4ee41c3f-761f-4e47-a5a3-6cc87874081d,DISK], DatanodeInfoWithStorage[127.0.0.1:45220,DS-d6265bf4-866c-48b4-9731-baae0f206ae5,DISK], DatanodeInfoWithStorage[127.0.0.1:36809,DS-da128007-d20e-40fd-9573-ba474a874453,DISK], DatanodeInfoWithStorage[127.0.0.1:42432,DS-881f9c90-8c71-4d90-9625-bb41375d3317,DISK], DatanodeInfoWithStorage[127.0.0.1:43695,DS-78f3ac9e-3385-4544-b5b7-9d7d222882e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38443,DS-b8e7355a-3b21-4388-bf16-3925764cfdec,DISK], DatanodeInfoWithStorage[127.0.0.1:42110,DS-34b42b05-4069-4a21-94d4-c492ea8cf169,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5225
