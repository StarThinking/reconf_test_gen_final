reconf_parameter: dfs.namenode.send.qop.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.send.qop.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-39081665-172.17.0.21-1595321764972:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45248,DS-d18f300a-a2e7-4ec1-b338-0ca01364d0ce,DISK], DatanodeInfoWithStorage[127.0.0.1:39771,DS-f750adad-0766-432c-9434-5ac8569bd568,DISK], DatanodeInfoWithStorage[127.0.0.1:37992,DS-053be997-fd4c-4277-b7df-2b411190b705,DISK], DatanodeInfoWithStorage[127.0.0.1:38362,DS-0d8ebdf6-e5ac-4e72-a6ff-761cd04575ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34363,DS-3b2bc0ed-4140-4ce7-b23d-5bf04cb06263,DISK], DatanodeInfoWithStorage[127.0.0.1:45704,DS-53286af6-0b65-4839-a3f0-b0dd32b95e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:45084,DS-1a261b7d-032b-42ff-99ff-7be115e180ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45843,DS-8a59cc5d-0c09-4a67-b477-41865e9e837f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-39081665-172.17.0.21-1595321764972:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45248,DS-d18f300a-a2e7-4ec1-b338-0ca01364d0ce,DISK], DatanodeInfoWithStorage[127.0.0.1:39771,DS-f750adad-0766-432c-9434-5ac8569bd568,DISK], DatanodeInfoWithStorage[127.0.0.1:37992,DS-053be997-fd4c-4277-b7df-2b411190b705,DISK], DatanodeInfoWithStorage[127.0.0.1:38362,DS-0d8ebdf6-e5ac-4e72-a6ff-761cd04575ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34363,DS-3b2bc0ed-4140-4ce7-b23d-5bf04cb06263,DISK], DatanodeInfoWithStorage[127.0.0.1:45704,DS-53286af6-0b65-4839-a3f0-b0dd32b95e9a,DISK], DatanodeInfoWithStorage[127.0.0.1:45084,DS-1a261b7d-032b-42ff-99ff-7be115e180ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45843,DS-8a59cc5d-0c09-4a67-b477-41865e9e837f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.send.qop.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-968462616-172.17.0.21-1595321859127:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40225,DS-bd4fb6eb-5cef-48b0-b3e4-4338b5176143,DISK], DatanodeInfoWithStorage[127.0.0.1:46797,DS-120addc7-7e35-4c82-ab7e-556ab5531a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:37873,DS-22b0f459-5f05-4f4c-a398-b06bf06ed0b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38123,DS-8f9fc248-31c2-496e-ba24-b63a3c6c0caf,DISK], DatanodeInfoWithStorage[127.0.0.1:41739,DS-d26f682c-5bbb-4449-8eb2-c4eb730c5005,DISK], DatanodeInfoWithStorage[127.0.0.1:36158,DS-a57e053a-b1f8-47f9-a8c9-dfc4b7433b36,DISK], DatanodeInfoWithStorage[127.0.0.1:41218,DS-5dd2e60b-1c65-411d-9ec3-bafcf7415667,DISK], DatanodeInfoWithStorage[127.0.0.1:41281,DS-68a370c5-f34f-41a4-9975-554ea7abec4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-968462616-172.17.0.21-1595321859127:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40225,DS-bd4fb6eb-5cef-48b0-b3e4-4338b5176143,DISK], DatanodeInfoWithStorage[127.0.0.1:46797,DS-120addc7-7e35-4c82-ab7e-556ab5531a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:37873,DS-22b0f459-5f05-4f4c-a398-b06bf06ed0b7,DISK], DatanodeInfoWithStorage[127.0.0.1:38123,DS-8f9fc248-31c2-496e-ba24-b63a3c6c0caf,DISK], DatanodeInfoWithStorage[127.0.0.1:41739,DS-d26f682c-5bbb-4449-8eb2-c4eb730c5005,DISK], DatanodeInfoWithStorage[127.0.0.1:36158,DS-a57e053a-b1f8-47f9-a8c9-dfc4b7433b36,DISK], DatanodeInfoWithStorage[127.0.0.1:41218,DS-5dd2e60b-1c65-411d-9ec3-bafcf7415667,DISK], DatanodeInfoWithStorage[127.0.0.1:41281,DS-68a370c5-f34f-41a4-9975-554ea7abec4c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.send.qop.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1864875312-172.17.0.21-1595322175718:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35601,DS-45361f7d-ec00-490a-a6c2-caf33e3e1a75,DISK], DatanodeInfoWithStorage[127.0.0.1:41295,DS-85ed4076-1210-44e3-92ee-c21d56be8211,DISK], DatanodeInfoWithStorage[127.0.0.1:33801,DS-b570a28f-0604-4b89-8438-5264f7169596,DISK], DatanodeInfoWithStorage[127.0.0.1:41441,DS-8c1dcb7f-199b-47f4-999b-f2b5242ba98d,DISK], DatanodeInfoWithStorage[127.0.0.1:33654,DS-83df664b-d9d9-4312-a116-795ff8255725,DISK], DatanodeInfoWithStorage[127.0.0.1:34267,DS-37887b0c-93cc-4a77-94fb-e75e6d1b6639,DISK], DatanodeInfoWithStorage[127.0.0.1:35651,DS-7e21f9f6-b3f2-4744-b6a3-46a6d0da86ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33479,DS-bc961a9b-024d-4add-99bd-27c3c0b4486e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1864875312-172.17.0.21-1595322175718:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35601,DS-45361f7d-ec00-490a-a6c2-caf33e3e1a75,DISK], DatanodeInfoWithStorage[127.0.0.1:41295,DS-85ed4076-1210-44e3-92ee-c21d56be8211,DISK], DatanodeInfoWithStorage[127.0.0.1:33801,DS-b570a28f-0604-4b89-8438-5264f7169596,DISK], DatanodeInfoWithStorage[127.0.0.1:41441,DS-8c1dcb7f-199b-47f4-999b-f2b5242ba98d,DISK], DatanodeInfoWithStorage[127.0.0.1:33654,DS-83df664b-d9d9-4312-a116-795ff8255725,DISK], DatanodeInfoWithStorage[127.0.0.1:34267,DS-37887b0c-93cc-4a77-94fb-e75e6d1b6639,DISK], DatanodeInfoWithStorage[127.0.0.1:35651,DS-7e21f9f6-b3f2-4744-b6a3-46a6d0da86ec,DISK], DatanodeInfoWithStorage[127.0.0.1:33479,DS-bc961a9b-024d-4add-99bd-27c3c0b4486e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.send.qop.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1036094173-172.17.0.21-1595322534419:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39162,DS-f80f3480-d3a8-4bfc-8c60-afa4a684e4ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45090,DS-21eea407-160f-45d5-9320-07e2eed57682,DISK], DatanodeInfoWithStorage[127.0.0.1:43341,DS-46b1bd68-e703-4220-b25d-aadbd698ff9c,DISK], DatanodeInfoWithStorage[127.0.0.1:33962,DS-98a50941-b84c-4688-9fb9-472dde2f0ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:33442,DS-5d75526e-234a-42d0-9c8c-3fdd33dfcbd7,DISK], DatanodeInfoWithStorage[127.0.0.1:39193,DS-d4e5e853-f545-47ad-832c-7227735ea297,DISK], DatanodeInfoWithStorage[127.0.0.1:33258,DS-dd8bf082-2015-4e3c-9e4a-1a73b471b51f,DISK], DatanodeInfoWithStorage[127.0.0.1:36879,DS-902f84d2-6bba-4879-9161-6375a58dc915,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1036094173-172.17.0.21-1595322534419:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39162,DS-f80f3480-d3a8-4bfc-8c60-afa4a684e4ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45090,DS-21eea407-160f-45d5-9320-07e2eed57682,DISK], DatanodeInfoWithStorage[127.0.0.1:43341,DS-46b1bd68-e703-4220-b25d-aadbd698ff9c,DISK], DatanodeInfoWithStorage[127.0.0.1:33962,DS-98a50941-b84c-4688-9fb9-472dde2f0ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:33442,DS-5d75526e-234a-42d0-9c8c-3fdd33dfcbd7,DISK], DatanodeInfoWithStorage[127.0.0.1:39193,DS-d4e5e853-f545-47ad-832c-7227735ea297,DISK], DatanodeInfoWithStorage[127.0.0.1:33258,DS-dd8bf082-2015-4e3c-9e4a-1a73b471b51f,DISK], DatanodeInfoWithStorage[127.0.0.1:36879,DS-902f84d2-6bba-4879-9161-6375a58dc915,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.send.qop.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-932735192-172.17.0.21-1595322601157:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36190,DS-f5eaa5d4-0345-4ec3-a324-63e7c18f395e,DISK], DatanodeInfoWithStorage[127.0.0.1:41617,DS-4a392e08-e73c-4948-b1e0-d21b3c46ca4e,DISK], DatanodeInfoWithStorage[127.0.0.1:45962,DS-d3696c3e-02ef-4752-9da6-890f2406a465,DISK], DatanodeInfoWithStorage[127.0.0.1:33144,DS-ef978d4e-c186-4ed0-9ca5-303057fcf196,DISK], DatanodeInfoWithStorage[127.0.0.1:45694,DS-1b8c6291-3ac4-4912-b516-f6f3366dc99f,DISK], DatanodeInfoWithStorage[127.0.0.1:45558,DS-d3f72b29-c36b-4c9e-bd34-01f1ebf772f9,DISK], DatanodeInfoWithStorage[127.0.0.1:40546,DS-5204f325-5e2e-45ea-a8a0-e54a3d8d09fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45337,DS-f788952f-cd88-49cf-a0e4-8cc2e5be8628,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-932735192-172.17.0.21-1595322601157:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36190,DS-f5eaa5d4-0345-4ec3-a324-63e7c18f395e,DISK], DatanodeInfoWithStorage[127.0.0.1:41617,DS-4a392e08-e73c-4948-b1e0-d21b3c46ca4e,DISK], DatanodeInfoWithStorage[127.0.0.1:45962,DS-d3696c3e-02ef-4752-9da6-890f2406a465,DISK], DatanodeInfoWithStorage[127.0.0.1:33144,DS-ef978d4e-c186-4ed0-9ca5-303057fcf196,DISK], DatanodeInfoWithStorage[127.0.0.1:45694,DS-1b8c6291-3ac4-4912-b516-f6f3366dc99f,DISK], DatanodeInfoWithStorage[127.0.0.1:45558,DS-d3f72b29-c36b-4c9e-bd34-01f1ebf772f9,DISK], DatanodeInfoWithStorage[127.0.0.1:40546,DS-5204f325-5e2e-45ea-a8a0-e54a3d8d09fc,DISK], DatanodeInfoWithStorage[127.0.0.1:45337,DS-f788952f-cd88-49cf-a0e4-8cc2e5be8628,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.send.qop.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-909608956-172.17.0.21-1595322665652:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37690,DS-bc5407c8-7ee3-47e0-a719-8eadd4a2faeb,DISK], DatanodeInfoWithStorage[127.0.0.1:35790,DS-30a4e5f8-2ed1-45e7-a313-7600a9549405,DISK], DatanodeInfoWithStorage[127.0.0.1:41406,DS-9eb09a4e-124a-4611-b81f-ee3f3642ba5b,DISK], DatanodeInfoWithStorage[127.0.0.1:44812,DS-253d942f-3e59-4341-8a7b-3960723e30b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35070,DS-15f148f5-2970-4cfc-930b-a391126d15c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38815,DS-0c514c2d-2b84-459a-a16d-e73d26aefe90,DISK], DatanodeInfoWithStorage[127.0.0.1:36471,DS-cf595148-8afa-4ea9-b817-c7e43304e889,DISK], DatanodeInfoWithStorage[127.0.0.1:46796,DS-19ba0872-3cf1-444f-a003-3a1654726eb6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-909608956-172.17.0.21-1595322665652:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37690,DS-bc5407c8-7ee3-47e0-a719-8eadd4a2faeb,DISK], DatanodeInfoWithStorage[127.0.0.1:35790,DS-30a4e5f8-2ed1-45e7-a313-7600a9549405,DISK], DatanodeInfoWithStorage[127.0.0.1:41406,DS-9eb09a4e-124a-4611-b81f-ee3f3642ba5b,DISK], DatanodeInfoWithStorage[127.0.0.1:44812,DS-253d942f-3e59-4341-8a7b-3960723e30b0,DISK], DatanodeInfoWithStorage[127.0.0.1:35070,DS-15f148f5-2970-4cfc-930b-a391126d15c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38815,DS-0c514c2d-2b84-459a-a16d-e73d26aefe90,DISK], DatanodeInfoWithStorage[127.0.0.1:36471,DS-cf595148-8afa-4ea9-b817-c7e43304e889,DISK], DatanodeInfoWithStorage[127.0.0.1:46796,DS-19ba0872-3cf1-444f-a003-3a1654726eb6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.send.qop.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1270314112-172.17.0.21-1595323158501:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39163,DS-cff05448-5c60-4acf-bed4-f2f63953e957,DISK], DatanodeInfoWithStorage[127.0.0.1:45811,DS-bb645df4-c2db-4e55-b27f-97e525c84673,DISK], DatanodeInfoWithStorage[127.0.0.1:33234,DS-55816b9f-a871-40ae-8e5b-c0dc5d924ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:41746,DS-bf8ef672-371f-4da8-8507-7239fc074eef,DISK], DatanodeInfoWithStorage[127.0.0.1:46056,DS-631bb833-df0a-4b88-91b9-032788926b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:44887,DS-fb951956-4363-4b74-b31b-272874b00310,DISK], DatanodeInfoWithStorage[127.0.0.1:35934,DS-6329570b-a7a7-4180-bd9a-4c36b2fad545,DISK], DatanodeInfoWithStorage[127.0.0.1:41164,DS-b10954d0-7a1b-4255-b2a9-50ffac1cfee6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1270314112-172.17.0.21-1595323158501:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39163,DS-cff05448-5c60-4acf-bed4-f2f63953e957,DISK], DatanodeInfoWithStorage[127.0.0.1:45811,DS-bb645df4-c2db-4e55-b27f-97e525c84673,DISK], DatanodeInfoWithStorage[127.0.0.1:33234,DS-55816b9f-a871-40ae-8e5b-c0dc5d924ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:41746,DS-bf8ef672-371f-4da8-8507-7239fc074eef,DISK], DatanodeInfoWithStorage[127.0.0.1:46056,DS-631bb833-df0a-4b88-91b9-032788926b8e,DISK], DatanodeInfoWithStorage[127.0.0.1:44887,DS-fb951956-4363-4b74-b31b-272874b00310,DISK], DatanodeInfoWithStorage[127.0.0.1:35934,DS-6329570b-a7a7-4180-bd9a-4c36b2fad545,DISK], DatanodeInfoWithStorage[127.0.0.1:41164,DS-b10954d0-7a1b-4255-b2a9-50ffac1cfee6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.send.qop.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-606683134-172.17.0.21-1595323253705:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38356,DS-3360d259-7d4a-4d39-9c49-ff4df62ff88e,DISK], DatanodeInfoWithStorage[127.0.0.1:37998,DS-dc9d4e2c-8cb8-4941-a5eb-3592bb325840,DISK], DatanodeInfoWithStorage[127.0.0.1:35178,DS-98922c95-d05d-4149-a505-572615533af3,DISK], DatanodeInfoWithStorage[127.0.0.1:42967,DS-9f51df56-c39e-4eb7-94d1-07f83acbf025,DISK], DatanodeInfoWithStorage[127.0.0.1:35277,DS-a83cf893-b52b-4d7f-85ee-2fc74924446b,DISK], DatanodeInfoWithStorage[127.0.0.1:43594,DS-ba896647-2d41-40fa-a3d6-2fad6cb6ffc2,DISK], DatanodeInfoWithStorage[127.0.0.1:41148,DS-92f3bb96-6fd2-40de-ae91-36251e853c16,DISK], DatanodeInfoWithStorage[127.0.0.1:42387,DS-690fa377-e578-448a-a9c3-1d090e78ac57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-606683134-172.17.0.21-1595323253705:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38356,DS-3360d259-7d4a-4d39-9c49-ff4df62ff88e,DISK], DatanodeInfoWithStorage[127.0.0.1:37998,DS-dc9d4e2c-8cb8-4941-a5eb-3592bb325840,DISK], DatanodeInfoWithStorage[127.0.0.1:35178,DS-98922c95-d05d-4149-a505-572615533af3,DISK], DatanodeInfoWithStorage[127.0.0.1:42967,DS-9f51df56-c39e-4eb7-94d1-07f83acbf025,DISK], DatanodeInfoWithStorage[127.0.0.1:35277,DS-a83cf893-b52b-4d7f-85ee-2fc74924446b,DISK], DatanodeInfoWithStorage[127.0.0.1:43594,DS-ba896647-2d41-40fa-a3d6-2fad6cb6ffc2,DISK], DatanodeInfoWithStorage[127.0.0.1:41148,DS-92f3bb96-6fd2-40de-ae91-36251e853c16,DISK], DatanodeInfoWithStorage[127.0.0.1:42387,DS-690fa377-e578-448a-a9c3-1d090e78ac57,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.send.qop.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-109053314-172.17.0.21-1595323759234:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34836,DS-8956538a-a6b4-433c-b6ff-be8100ea4815,DISK], DatanodeInfoWithStorage[127.0.0.1:46685,DS-fb8ecdf2-12eb-4084-980c-51cee883a280,DISK], DatanodeInfoWithStorage[127.0.0.1:36417,DS-708b7378-e247-475d-b75a-56660267f3c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45741,DS-bd400073-2d3c-4a87-9b16-bb78a52d06a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40476,DS-0ce460dd-b82e-47b6-84e5-82841f3c05ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39231,DS-2ecfbb04-0156-4b11-b48b-bf5c3656d018,DISK], DatanodeInfoWithStorage[127.0.0.1:45539,DS-10a6bc39-b0fe-4fde-b9c8-faee231a3b13,DISK], DatanodeInfoWithStorage[127.0.0.1:37673,DS-2fcf31c7-077c-4636-9653-b507c764d5b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-109053314-172.17.0.21-1595323759234:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34836,DS-8956538a-a6b4-433c-b6ff-be8100ea4815,DISK], DatanodeInfoWithStorage[127.0.0.1:46685,DS-fb8ecdf2-12eb-4084-980c-51cee883a280,DISK], DatanodeInfoWithStorage[127.0.0.1:36417,DS-708b7378-e247-475d-b75a-56660267f3c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45741,DS-bd400073-2d3c-4a87-9b16-bb78a52d06a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40476,DS-0ce460dd-b82e-47b6-84e5-82841f3c05ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39231,DS-2ecfbb04-0156-4b11-b48b-bf5c3656d018,DISK], DatanodeInfoWithStorage[127.0.0.1:45539,DS-10a6bc39-b0fe-4fde-b9c8-faee231a3b13,DISK], DatanodeInfoWithStorage[127.0.0.1:37673,DS-2fcf31c7-077c-4636-9653-b507c764d5b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.send.qop.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2029795985-172.17.0.21-1595323853934:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44447,DS-1e83da3b-3ac2-44b6-9737-b1e28033a1f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43818,DS-d5d2fc75-fd61-4ef3-92d8-dc304001e949,DISK], DatanodeInfoWithStorage[127.0.0.1:44937,DS-091e1920-8195-410a-b517-d986e0f5b1e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34679,DS-dcb4ca08-2475-4f31-9669-497291cd4a99,DISK], DatanodeInfoWithStorage[127.0.0.1:44262,DS-8ba6358f-060c-4eb5-bd85-1aa141a80968,DISK], DatanodeInfoWithStorage[127.0.0.1:36146,DS-6163e575-d6ef-479e-a8d0-bcb56d0e3cc3,DISK], DatanodeInfoWithStorage[127.0.0.1:33939,DS-942a1a21-0651-4c50-9051-56de221802bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44639,DS-21d62df9-8098-4b17-9ab3-31ed53a6624b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2029795985-172.17.0.21-1595323853934:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44447,DS-1e83da3b-3ac2-44b6-9737-b1e28033a1f1,DISK], DatanodeInfoWithStorage[127.0.0.1:43818,DS-d5d2fc75-fd61-4ef3-92d8-dc304001e949,DISK], DatanodeInfoWithStorage[127.0.0.1:44937,DS-091e1920-8195-410a-b517-d986e0f5b1e7,DISK], DatanodeInfoWithStorage[127.0.0.1:34679,DS-dcb4ca08-2475-4f31-9669-497291cd4a99,DISK], DatanodeInfoWithStorage[127.0.0.1:44262,DS-8ba6358f-060c-4eb5-bd85-1aa141a80968,DISK], DatanodeInfoWithStorage[127.0.0.1:36146,DS-6163e575-d6ef-479e-a8d0-bcb56d0e3cc3,DISK], DatanodeInfoWithStorage[127.0.0.1:33939,DS-942a1a21-0651-4c50-9051-56de221802bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44639,DS-21d62df9-8098-4b17-9ab3-31ed53a6624b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.send.qop.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1469694238-172.17.0.21-1595324176826:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46222,DS-cff3934e-483d-4319-b69b-ff6ac9881cc3,DISK], DatanodeInfoWithStorage[127.0.0.1:38745,DS-808d4646-ff78-4ff0-ad12-88e79d7b2864,DISK], DatanodeInfoWithStorage[127.0.0.1:32912,DS-c0a15e07-7b80-4423-9a10-263febb54b32,DISK], DatanodeInfoWithStorage[127.0.0.1:36305,DS-e87a9260-38ed-4819-83ef-972ed713272c,DISK], DatanodeInfoWithStorage[127.0.0.1:37543,DS-1df28ee9-f7c9-4f24-a92b-1f207ea3ae3e,DISK], DatanodeInfoWithStorage[127.0.0.1:35586,DS-31d0beab-a516-4a73-a093-5b05f7facd00,DISK], DatanodeInfoWithStorage[127.0.0.1:43247,DS-972e532b-61d5-421b-86a8-c11a2d57b5ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37417,DS-aaf15e2c-9224-4464-bc77-1a198231c03f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1469694238-172.17.0.21-1595324176826:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46222,DS-cff3934e-483d-4319-b69b-ff6ac9881cc3,DISK], DatanodeInfoWithStorage[127.0.0.1:38745,DS-808d4646-ff78-4ff0-ad12-88e79d7b2864,DISK], DatanodeInfoWithStorage[127.0.0.1:32912,DS-c0a15e07-7b80-4423-9a10-263febb54b32,DISK], DatanodeInfoWithStorage[127.0.0.1:36305,DS-e87a9260-38ed-4819-83ef-972ed713272c,DISK], DatanodeInfoWithStorage[127.0.0.1:37543,DS-1df28ee9-f7c9-4f24-a92b-1f207ea3ae3e,DISK], DatanodeInfoWithStorage[127.0.0.1:35586,DS-31d0beab-a516-4a73-a093-5b05f7facd00,DISK], DatanodeInfoWithStorage[127.0.0.1:43247,DS-972e532b-61d5-421b-86a8-c11a2d57b5ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37417,DS-aaf15e2c-9224-4464-bc77-1a198231c03f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.send.qop.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-424117880-172.17.0.21-1595324365057:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32774,DS-303596fa-5748-4c5d-83ae-1d44b0e3b666,DISK], DatanodeInfoWithStorage[127.0.0.1:46402,DS-b67aeade-e136-4adb-a15d-af6ac8d0609b,DISK], DatanodeInfoWithStorage[127.0.0.1:45138,DS-11c33ce5-d778-42a2-ac90-059978eceb93,DISK], DatanodeInfoWithStorage[127.0.0.1:46717,DS-c2905bd1-55fc-49fe-b0da-0f21b79de73c,DISK], DatanodeInfoWithStorage[127.0.0.1:40161,DS-59b18c74-83cd-4b0d-8bb9-8f2b9d0a16ed,DISK], DatanodeInfoWithStorage[127.0.0.1:32813,DS-06e699f3-a707-4adc-afd4-0417d5b92974,DISK], DatanodeInfoWithStorage[127.0.0.1:46830,DS-8b9db1ce-53f3-463c-b2ff-9bd5849bf44e,DISK], DatanodeInfoWithStorage[127.0.0.1:34812,DS-7b58ef58-b442-4b87-868c-2820318e7190,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-424117880-172.17.0.21-1595324365057:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32774,DS-303596fa-5748-4c5d-83ae-1d44b0e3b666,DISK], DatanodeInfoWithStorage[127.0.0.1:46402,DS-b67aeade-e136-4adb-a15d-af6ac8d0609b,DISK], DatanodeInfoWithStorage[127.0.0.1:45138,DS-11c33ce5-d778-42a2-ac90-059978eceb93,DISK], DatanodeInfoWithStorage[127.0.0.1:46717,DS-c2905bd1-55fc-49fe-b0da-0f21b79de73c,DISK], DatanodeInfoWithStorage[127.0.0.1:40161,DS-59b18c74-83cd-4b0d-8bb9-8f2b9d0a16ed,DISK], DatanodeInfoWithStorage[127.0.0.1:32813,DS-06e699f3-a707-4adc-afd4-0417d5b92974,DISK], DatanodeInfoWithStorage[127.0.0.1:46830,DS-8b9db1ce-53f3-463c-b2ff-9bd5849bf44e,DISK], DatanodeInfoWithStorage[127.0.0.1:34812,DS-7b58ef58-b442-4b87-868c-2820318e7190,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.send.qop.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1403736123-172.17.0.21-1595324653407:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43939,DS-a963c75a-dd25-4b8c-93e0-3f11d73a39f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33914,DS-8989a0ce-72a8-4415-85d7-465b2a5f37b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42520,DS-d5257787-6337-4bff-b7c1-4858223d96de,DISK], DatanodeInfoWithStorage[127.0.0.1:36549,DS-14c3a9a8-2bbf-4dbd-bc75-c432485fe3cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37516,DS-6a130c18-d125-4139-80a2-615d923b584b,DISK], DatanodeInfoWithStorage[127.0.0.1:38717,DS-93dbb875-fec8-43bd-b5aa-20fc0cc774a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46079,DS-f642d511-dab0-409a-b54d-2f72a06911ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41701,DS-fbcd0a28-7b47-4991-8d10-08162ebf808d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1403736123-172.17.0.21-1595324653407:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43939,DS-a963c75a-dd25-4b8c-93e0-3f11d73a39f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33914,DS-8989a0ce-72a8-4415-85d7-465b2a5f37b3,DISK], DatanodeInfoWithStorage[127.0.0.1:42520,DS-d5257787-6337-4bff-b7c1-4858223d96de,DISK], DatanodeInfoWithStorage[127.0.0.1:36549,DS-14c3a9a8-2bbf-4dbd-bc75-c432485fe3cf,DISK], DatanodeInfoWithStorage[127.0.0.1:37516,DS-6a130c18-d125-4139-80a2-615d923b584b,DISK], DatanodeInfoWithStorage[127.0.0.1:38717,DS-93dbb875-fec8-43bd-b5aa-20fc0cc774a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46079,DS-f642d511-dab0-409a-b54d-2f72a06911ed,DISK], DatanodeInfoWithStorage[127.0.0.1:41701,DS-fbcd0a28-7b47-4991-8d10-08162ebf808d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.send.qop.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1899037762-172.17.0.21-1595324979590:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42876,DS-a5719eaa-dcd3-48d1-9ad2-5657dd0ffe9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45540,DS-9dbed954-d193-4449-a252-ba187c973d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:35322,DS-60650e69-7fe8-47b4-859a-f5d0979387b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42496,DS-143c83d9-f231-44e4-bb12-3c1765aff0e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37674,DS-c12b5cdb-ec84-4aab-9ce8-cb7f0edac26c,DISK], DatanodeInfoWithStorage[127.0.0.1:42657,DS-90fca482-1fb9-4a36-b254-357b451dd9ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40354,DS-f2bdd986-e22b-49b9-a192-41e15ec63437,DISK], DatanodeInfoWithStorage[127.0.0.1:33530,DS-552359fe-3d84-405c-83d1-d1cf44193020,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1899037762-172.17.0.21-1595324979590:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42876,DS-a5719eaa-dcd3-48d1-9ad2-5657dd0ffe9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45540,DS-9dbed954-d193-4449-a252-ba187c973d6d,DISK], DatanodeInfoWithStorage[127.0.0.1:35322,DS-60650e69-7fe8-47b4-859a-f5d0979387b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42496,DS-143c83d9-f231-44e4-bb12-3c1765aff0e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37674,DS-c12b5cdb-ec84-4aab-9ce8-cb7f0edac26c,DISK], DatanodeInfoWithStorage[127.0.0.1:42657,DS-90fca482-1fb9-4a36-b254-357b451dd9ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40354,DS-f2bdd986-e22b-49b9-a192-41e15ec63437,DISK], DatanodeInfoWithStorage[127.0.0.1:33530,DS-552359fe-3d84-405c-83d1-d1cf44193020,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.send.qop.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1458952045-172.17.0.21-1595325126263:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35906,DS-19a8ceef-515e-4ad1-97cf-befee97db19e,DISK], DatanodeInfoWithStorage[127.0.0.1:33619,DS-e16ab026-b874-43e9-b938-f25961a83f27,DISK], DatanodeInfoWithStorage[127.0.0.1:35696,DS-4ee60efd-afb5-4611-b331-7946ca922758,DISK], DatanodeInfoWithStorage[127.0.0.1:43203,DS-bb5157f4-afa8-4a53-8ac1-9771d95d3160,DISK], DatanodeInfoWithStorage[127.0.0.1:45744,DS-c4da3033-c157-4ce6-9acf-2b0fde4f3d3a,DISK], DatanodeInfoWithStorage[127.0.0.1:41409,DS-1664923a-6002-492d-887b-f5b7c5d4d9d5,DISK], DatanodeInfoWithStorage[127.0.0.1:37596,DS-bb71e664-acd1-4f01-959a-467b6c381f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:40316,DS-f9c16bb6-53ab-4482-b8ad-30e0a8637eb7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1458952045-172.17.0.21-1595325126263:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35906,DS-19a8ceef-515e-4ad1-97cf-befee97db19e,DISK], DatanodeInfoWithStorage[127.0.0.1:33619,DS-e16ab026-b874-43e9-b938-f25961a83f27,DISK], DatanodeInfoWithStorage[127.0.0.1:35696,DS-4ee60efd-afb5-4611-b331-7946ca922758,DISK], DatanodeInfoWithStorage[127.0.0.1:43203,DS-bb5157f4-afa8-4a53-8ac1-9771d95d3160,DISK], DatanodeInfoWithStorage[127.0.0.1:45744,DS-c4da3033-c157-4ce6-9acf-2b0fde4f3d3a,DISK], DatanodeInfoWithStorage[127.0.0.1:41409,DS-1664923a-6002-492d-887b-f5b7c5d4d9d5,DISK], DatanodeInfoWithStorage[127.0.0.1:37596,DS-bb71e664-acd1-4f01-959a-467b6c381f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:40316,DS-f9c16bb6-53ab-4482-b8ad-30e0a8637eb7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.send.qop.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1518326415-172.17.0.21-1595325473742:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34624,DS-dacdfe8e-2472-4e68-aa10-6168a33a38e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46505,DS-e8ec191b-3cc1-4854-a892-c218851b61c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43591,DS-eaee6a26-9f38-4842-a478-7e3f68a3a4e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41613,DS-54ab1deb-eb56-492b-a10c-cd8736688e21,DISK], DatanodeInfoWithStorage[127.0.0.1:42485,DS-8de6caee-ad16-4c53-a344-e4f177c6a4d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36151,DS-9733a072-ecb9-48f8-8f8e-f4c54ca25508,DISK], DatanodeInfoWithStorage[127.0.0.1:43526,DS-a341756e-acaf-41f3-8bda-6794c893c7cd,DISK], DatanodeInfoWithStorage[127.0.0.1:35183,DS-4cf4c91c-bcea-4330-a1b9-e970fabfa675,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1518326415-172.17.0.21-1595325473742:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34624,DS-dacdfe8e-2472-4e68-aa10-6168a33a38e2,DISK], DatanodeInfoWithStorage[127.0.0.1:46505,DS-e8ec191b-3cc1-4854-a892-c218851b61c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43591,DS-eaee6a26-9f38-4842-a478-7e3f68a3a4e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41613,DS-54ab1deb-eb56-492b-a10c-cd8736688e21,DISK], DatanodeInfoWithStorage[127.0.0.1:42485,DS-8de6caee-ad16-4c53-a344-e4f177c6a4d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36151,DS-9733a072-ecb9-48f8-8f8e-f4c54ca25508,DISK], DatanodeInfoWithStorage[127.0.0.1:43526,DS-a341756e-acaf-41f3-8bda-6794c893c7cd,DISK], DatanodeInfoWithStorage[127.0.0.1:35183,DS-4cf4c91c-bcea-4330-a1b9-e970fabfa675,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.send.qop.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1699900803-172.17.0.21-1595325877403:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39027,DS-2618fff1-0c44-45d7-9d42-9dbb57f8952a,DISK], DatanodeInfoWithStorage[127.0.0.1:38729,DS-1731ab2c-86f3-4e29-a089-e916efdc0b91,DISK], DatanodeInfoWithStorage[127.0.0.1:35916,DS-4fab8cd0-2451-45c1-8f39-9fd94efc09bd,DISK], DatanodeInfoWithStorage[127.0.0.1:46212,DS-537ae2b3-6ef3-4fcd-b810-cc3250fe29a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45074,DS-2b4e48ee-8a8a-47d6-8c8e-ea380f24149f,DISK], DatanodeInfoWithStorage[127.0.0.1:37800,DS-e8bebc16-15c3-4525-be65-668aac60cc50,DISK], DatanodeInfoWithStorage[127.0.0.1:46698,DS-01d17f1b-c231-4159-bbc5-c59590c40fa0,DISK], DatanodeInfoWithStorage[127.0.0.1:34468,DS-649cb35d-3322-401b-b288-e1c0d3f70687,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1699900803-172.17.0.21-1595325877403:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39027,DS-2618fff1-0c44-45d7-9d42-9dbb57f8952a,DISK], DatanodeInfoWithStorage[127.0.0.1:38729,DS-1731ab2c-86f3-4e29-a089-e916efdc0b91,DISK], DatanodeInfoWithStorage[127.0.0.1:35916,DS-4fab8cd0-2451-45c1-8f39-9fd94efc09bd,DISK], DatanodeInfoWithStorage[127.0.0.1:46212,DS-537ae2b3-6ef3-4fcd-b810-cc3250fe29a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45074,DS-2b4e48ee-8a8a-47d6-8c8e-ea380f24149f,DISK], DatanodeInfoWithStorage[127.0.0.1:37800,DS-e8bebc16-15c3-4525-be65-668aac60cc50,DISK], DatanodeInfoWithStorage[127.0.0.1:46698,DS-01d17f1b-c231-4159-bbc5-c59590c40fa0,DISK], DatanodeInfoWithStorage[127.0.0.1:34468,DS-649cb35d-3322-401b-b288-e1c0d3f70687,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.send.qop.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-776292632-172.17.0.21-1595326464600:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33827,DS-ad1446ad-4b23-407a-a6bc-26bb18005e20,DISK], DatanodeInfoWithStorage[127.0.0.1:37848,DS-35fb61ca-23be-4766-a3f5-c210a170c8f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43424,DS-9430a91e-9723-45f5-897f-14539aca1ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:37918,DS-33f2902a-8ce0-4d90-bd6d-a0b862a8efdc,DISK], DatanodeInfoWithStorage[127.0.0.1:36187,DS-e75477d7-95d5-4f9f-bed9-6bbfb6463fda,DISK], DatanodeInfoWithStorage[127.0.0.1:37573,DS-5c40a232-fe28-43ee-a8e6-25728444f259,DISK], DatanodeInfoWithStorage[127.0.0.1:43740,DS-1c82f313-eb20-483a-b133-68665f722367,DISK], DatanodeInfoWithStorage[127.0.0.1:39272,DS-284ba0c1-6209-488b-9ab5-35830e63ff96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-776292632-172.17.0.21-1595326464600:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33827,DS-ad1446ad-4b23-407a-a6bc-26bb18005e20,DISK], DatanodeInfoWithStorage[127.0.0.1:37848,DS-35fb61ca-23be-4766-a3f5-c210a170c8f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43424,DS-9430a91e-9723-45f5-897f-14539aca1ee0,DISK], DatanodeInfoWithStorage[127.0.0.1:37918,DS-33f2902a-8ce0-4d90-bd6d-a0b862a8efdc,DISK], DatanodeInfoWithStorage[127.0.0.1:36187,DS-e75477d7-95d5-4f9f-bed9-6bbfb6463fda,DISK], DatanodeInfoWithStorage[127.0.0.1:37573,DS-5c40a232-fe28-43ee-a8e6-25728444f259,DISK], DatanodeInfoWithStorage[127.0.0.1:43740,DS-1c82f313-eb20-483a-b133-68665f722367,DISK], DatanodeInfoWithStorage[127.0.0.1:39272,DS-284ba0c1-6209-488b-9ab5-35830e63ff96,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.send.qop.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1606338552-172.17.0.21-1595326613078:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43518,DS-09d88a6c-5c60-4144-b156-cf290d35b8ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34327,DS-e83f06d9-4ce6-487a-b73c-e10b9f0293a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36330,DS-916b6c2b-a197-4cd7-8f9e-f8a9ef869d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:42771,DS-cf3eff23-c93e-44bc-b398-8fb19d3fb7c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45600,DS-3760320f-a19e-43a5-b39c-a3ed109b8381,DISK], DatanodeInfoWithStorage[127.0.0.1:42443,DS-79d89425-a50e-4807-aa02-abcadfb2a14c,DISK], DatanodeInfoWithStorage[127.0.0.1:37894,DS-83486898-4c1b-40c3-b844-90ec21fd1c43,DISK], DatanodeInfoWithStorage[127.0.0.1:44105,DS-36f71b08-efcf-464f-9d74-06e07f21e4d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1606338552-172.17.0.21-1595326613078:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43518,DS-09d88a6c-5c60-4144-b156-cf290d35b8ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34327,DS-e83f06d9-4ce6-487a-b73c-e10b9f0293a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36330,DS-916b6c2b-a197-4cd7-8f9e-f8a9ef869d0c,DISK], DatanodeInfoWithStorage[127.0.0.1:42771,DS-cf3eff23-c93e-44bc-b398-8fb19d3fb7c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45600,DS-3760320f-a19e-43a5-b39c-a3ed109b8381,DISK], DatanodeInfoWithStorage[127.0.0.1:42443,DS-79d89425-a50e-4807-aa02-abcadfb2a14c,DISK], DatanodeInfoWithStorage[127.0.0.1:37894,DS-83486898-4c1b-40c3-b844-90ec21fd1c43,DISK], DatanodeInfoWithStorage[127.0.0.1:44105,DS-36f71b08-efcf-464f-9d74-06e07f21e4d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5305
