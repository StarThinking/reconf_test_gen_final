reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-403344407-172.17.0.20-1596899429766:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40754,DS-ad5107bc-77f0-410b-8950-d82e297c00ad,DISK], DatanodeInfoWithStorage[127.0.0.1:32852,DS-34edd0d2-1178-4ab4-8d31-fee3e924f44c,DISK], DatanodeInfoWithStorage[127.0.0.1:37654,DS-b98e353b-63c0-4bae-801f-05796b5e84c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39996,DS-3297c298-8b66-4b44-829e-3b35fc3f27d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44619,DS-d497a269-d727-4b28-8924-5c8f022584d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43955,DS-6364c08a-e0b7-4955-b660-4e9e9516b3bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41043,DS-98f89b08-7bbf-4f76-abc7-2470b932aff8,DISK], DatanodeInfoWithStorage[127.0.0.1:34940,DS-61b17fe5-b64e-4daf-996a-97c3ece4206c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-403344407-172.17.0.20-1596899429766:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40754,DS-ad5107bc-77f0-410b-8950-d82e297c00ad,DISK], DatanodeInfoWithStorage[127.0.0.1:32852,DS-34edd0d2-1178-4ab4-8d31-fee3e924f44c,DISK], DatanodeInfoWithStorage[127.0.0.1:37654,DS-b98e353b-63c0-4bae-801f-05796b5e84c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39996,DS-3297c298-8b66-4b44-829e-3b35fc3f27d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44619,DS-d497a269-d727-4b28-8924-5c8f022584d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43955,DS-6364c08a-e0b7-4955-b660-4e9e9516b3bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41043,DS-98f89b08-7bbf-4f76-abc7-2470b932aff8,DISK], DatanodeInfoWithStorage[127.0.0.1:34940,DS-61b17fe5-b64e-4daf-996a-97c3ece4206c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1288667551-172.17.0.20-1596900382114:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42213,DS-fbbd8951-c0cb-4147-9e2b-40649d41c3b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45449,DS-014e431b-795c-441e-b592-50900a41ae2a,DISK], DatanodeInfoWithStorage[127.0.0.1:33216,DS-0f176672-0446-4938-8548-37fb19027a26,DISK], DatanodeInfoWithStorage[127.0.0.1:32913,DS-10e51f30-e3a5-495e-a5fe-304e779c3b6e,DISK], DatanodeInfoWithStorage[127.0.0.1:42081,DS-896f9cc5-54fd-4c0e-9686-f9048b6a5f24,DISK], DatanodeInfoWithStorage[127.0.0.1:36891,DS-f0856e78-3efe-44a5-972d-76edf7e6ad56,DISK], DatanodeInfoWithStorage[127.0.0.1:43429,DS-db00fe6b-a983-449f-867b-209490939cba,DISK], DatanodeInfoWithStorage[127.0.0.1:43635,DS-7df02aa0-fa5f-4d29-a245-dc0218254879,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1288667551-172.17.0.20-1596900382114:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42213,DS-fbbd8951-c0cb-4147-9e2b-40649d41c3b5,DISK], DatanodeInfoWithStorage[127.0.0.1:45449,DS-014e431b-795c-441e-b592-50900a41ae2a,DISK], DatanodeInfoWithStorage[127.0.0.1:33216,DS-0f176672-0446-4938-8548-37fb19027a26,DISK], DatanodeInfoWithStorage[127.0.0.1:32913,DS-10e51f30-e3a5-495e-a5fe-304e779c3b6e,DISK], DatanodeInfoWithStorage[127.0.0.1:42081,DS-896f9cc5-54fd-4c0e-9686-f9048b6a5f24,DISK], DatanodeInfoWithStorage[127.0.0.1:36891,DS-f0856e78-3efe-44a5-972d-76edf7e6ad56,DISK], DatanodeInfoWithStorage[127.0.0.1:43429,DS-db00fe6b-a983-449f-867b-209490939cba,DISK], DatanodeInfoWithStorage[127.0.0.1:43635,DS-7df02aa0-fa5f-4d29-a245-dc0218254879,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1035137327-172.17.0.20-1596900843600:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46296,DS-d831f107-efb4-49eb-aa58-ce1821f3b794,DISK], DatanodeInfoWithStorage[127.0.0.1:36856,DS-6b325447-2e79-446f-a767-ed2a80435572,DISK], DatanodeInfoWithStorage[127.0.0.1:46611,DS-6d22ace0-32c8-4250-8815-36a93755d0c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39748,DS-d79c2edf-db04-4bb3-9d0d-b49d13bafcb1,DISK], DatanodeInfoWithStorage[127.0.0.1:38079,DS-ee79882b-27ea-4072-af14-2fc133688b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:35796,DS-43794b99-7d00-4388-86b1-0ca52458584d,DISK], DatanodeInfoWithStorage[127.0.0.1:41982,DS-b30890da-af46-4698-998a-29ed59cfa41d,DISK], DatanodeInfoWithStorage[127.0.0.1:44235,DS-b856142f-50bb-4052-bbb1-364d06c9f2e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1035137327-172.17.0.20-1596900843600:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46296,DS-d831f107-efb4-49eb-aa58-ce1821f3b794,DISK], DatanodeInfoWithStorage[127.0.0.1:36856,DS-6b325447-2e79-446f-a767-ed2a80435572,DISK], DatanodeInfoWithStorage[127.0.0.1:46611,DS-6d22ace0-32c8-4250-8815-36a93755d0c7,DISK], DatanodeInfoWithStorage[127.0.0.1:39748,DS-d79c2edf-db04-4bb3-9d0d-b49d13bafcb1,DISK], DatanodeInfoWithStorage[127.0.0.1:38079,DS-ee79882b-27ea-4072-af14-2fc133688b0c,DISK], DatanodeInfoWithStorage[127.0.0.1:35796,DS-43794b99-7d00-4388-86b1-0ca52458584d,DISK], DatanodeInfoWithStorage[127.0.0.1:41982,DS-b30890da-af46-4698-998a-29ed59cfa41d,DISK], DatanodeInfoWithStorage[127.0.0.1:44235,DS-b856142f-50bb-4052-bbb1-364d06c9f2e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1523621453-172.17.0.20-1596901213795:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46349,DS-0a807b0e-c5d8-4e86-a28d-4ef9e8d91ace,DISK], DatanodeInfoWithStorage[127.0.0.1:42907,DS-dcf500fc-255a-4011-8507-f23575f12f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:33381,DS-4b1483a5-6aa5-446f-a299-7ac9aa2f364c,DISK], DatanodeInfoWithStorage[127.0.0.1:37620,DS-ed3804e1-2595-4094-b9b1-0f96d4788d78,DISK], DatanodeInfoWithStorage[127.0.0.1:33430,DS-3431c40c-81e7-4641-8bdf-63724a72a246,DISK], DatanodeInfoWithStorage[127.0.0.1:45454,DS-a5abcd50-5b9e-4ce9-93b6-28e4addf0bf5,DISK], DatanodeInfoWithStorage[127.0.0.1:35547,DS-c613308b-0889-4ac0-ad87-56b38ebf98c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42825,DS-cbebd787-2ef9-4fc6-b8a0-0b3f0db2c9c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1523621453-172.17.0.20-1596901213795:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46349,DS-0a807b0e-c5d8-4e86-a28d-4ef9e8d91ace,DISK], DatanodeInfoWithStorage[127.0.0.1:42907,DS-dcf500fc-255a-4011-8507-f23575f12f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:33381,DS-4b1483a5-6aa5-446f-a299-7ac9aa2f364c,DISK], DatanodeInfoWithStorage[127.0.0.1:37620,DS-ed3804e1-2595-4094-b9b1-0f96d4788d78,DISK], DatanodeInfoWithStorage[127.0.0.1:33430,DS-3431c40c-81e7-4641-8bdf-63724a72a246,DISK], DatanodeInfoWithStorage[127.0.0.1:45454,DS-a5abcd50-5b9e-4ce9-93b6-28e4addf0bf5,DISK], DatanodeInfoWithStorage[127.0.0.1:35547,DS-c613308b-0889-4ac0-ad87-56b38ebf98c6,DISK], DatanodeInfoWithStorage[127.0.0.1:42825,DS-cbebd787-2ef9-4fc6-b8a0-0b3f0db2c9c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-987713547-172.17.0.20-1596901291926:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37244,DS-df030c07-1e6e-4223-a0e1-cd1a1d896d89,DISK], DatanodeInfoWithStorage[127.0.0.1:37782,DS-6e2051c3-9ea3-42a4-b2af-406c6635f609,DISK], DatanodeInfoWithStorage[127.0.0.1:45625,DS-4302460a-baf1-4aa2-9e0b-caf73f207186,DISK], DatanodeInfoWithStorage[127.0.0.1:36147,DS-918dea9e-d840-4e2b-9476-0c92d5fdc88b,DISK], DatanodeInfoWithStorage[127.0.0.1:36329,DS-a66650a8-24de-40aa-ad2b-dcc67a76bcb0,DISK], DatanodeInfoWithStorage[127.0.0.1:41341,DS-5c6b1fc3-5002-43cc-9443-9a1b56434f27,DISK], DatanodeInfoWithStorage[127.0.0.1:41800,DS-11ec52ad-f1cb-498a-b147-bc206a0e50a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44786,DS-4cd85af3-ff81-4b5f-9381-25e3e0badb4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-987713547-172.17.0.20-1596901291926:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37244,DS-df030c07-1e6e-4223-a0e1-cd1a1d896d89,DISK], DatanodeInfoWithStorage[127.0.0.1:37782,DS-6e2051c3-9ea3-42a4-b2af-406c6635f609,DISK], DatanodeInfoWithStorage[127.0.0.1:45625,DS-4302460a-baf1-4aa2-9e0b-caf73f207186,DISK], DatanodeInfoWithStorage[127.0.0.1:36147,DS-918dea9e-d840-4e2b-9476-0c92d5fdc88b,DISK], DatanodeInfoWithStorage[127.0.0.1:36329,DS-a66650a8-24de-40aa-ad2b-dcc67a76bcb0,DISK], DatanodeInfoWithStorage[127.0.0.1:41341,DS-5c6b1fc3-5002-43cc-9443-9a1b56434f27,DISK], DatanodeInfoWithStorage[127.0.0.1:41800,DS-11ec52ad-f1cb-498a-b147-bc206a0e50a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44786,DS-4cd85af3-ff81-4b5f-9381-25e3e0badb4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-392603028-172.17.0.20-1596901474167:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41880,DS-2500c99a-77ee-4b90-983f-01cc5e205145,DISK], DatanodeInfoWithStorage[127.0.0.1:36499,DS-a7274e72-65d4-48bb-9f21-9cf6c098a6ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34301,DS-2b14ad75-029c-44f9-93df-c3a3beab09dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37574,DS-4e2a9572-9017-42fa-b04b-5d6e9763ab1d,DISK], DatanodeInfoWithStorage[127.0.0.1:40755,DS-cee9e9f6-f8f9-4122-8b25-b9963b4d0a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:40945,DS-7e333be4-e551-4ca8-9558-cf4721decff3,DISK], DatanodeInfoWithStorage[127.0.0.1:35636,DS-4af1af9c-325a-4427-a6c4-ed2bfa49fc5b,DISK], DatanodeInfoWithStorage[127.0.0.1:43107,DS-9ce547b7-d87c-41e7-88f1-d49bfb55b548,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-392603028-172.17.0.20-1596901474167:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41880,DS-2500c99a-77ee-4b90-983f-01cc5e205145,DISK], DatanodeInfoWithStorage[127.0.0.1:36499,DS-a7274e72-65d4-48bb-9f21-9cf6c098a6ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34301,DS-2b14ad75-029c-44f9-93df-c3a3beab09dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37574,DS-4e2a9572-9017-42fa-b04b-5d6e9763ab1d,DISK], DatanodeInfoWithStorage[127.0.0.1:40755,DS-cee9e9f6-f8f9-4122-8b25-b9963b4d0a2f,DISK], DatanodeInfoWithStorage[127.0.0.1:40945,DS-7e333be4-e551-4ca8-9558-cf4721decff3,DISK], DatanodeInfoWithStorage[127.0.0.1:35636,DS-4af1af9c-325a-4427-a6c4-ed2bfa49fc5b,DISK], DatanodeInfoWithStorage[127.0.0.1:43107,DS-9ce547b7-d87c-41e7-88f1-d49bfb55b548,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1486369744-172.17.0.20-1596901509869:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40943,DS-d0ac402b-55a6-41cb-8b65-e493593589ad,DISK], DatanodeInfoWithStorage[127.0.0.1:39515,DS-ff593518-4451-4f4a-a98e-082853e41ebe,DISK], DatanodeInfoWithStorage[127.0.0.1:39534,DS-5971c07f-499f-4a42-a902-4b59ee695e49,DISK], DatanodeInfoWithStorage[127.0.0.1:45586,DS-a410ccd2-11f5-4c79-96da-165c03728a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:33354,DS-7288ac3f-41d1-473d-b888-3e029d3a4dec,DISK], DatanodeInfoWithStorage[127.0.0.1:40494,DS-6cf9de58-225e-4340-a8f2-346eceb5798f,DISK], DatanodeInfoWithStorage[127.0.0.1:46754,DS-76f542d6-e530-4172-9f20-bd11b9453111,DISK], DatanodeInfoWithStorage[127.0.0.1:33184,DS-df3ecaec-fc38-442d-853d-245493af4742,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1486369744-172.17.0.20-1596901509869:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40943,DS-d0ac402b-55a6-41cb-8b65-e493593589ad,DISK], DatanodeInfoWithStorage[127.0.0.1:39515,DS-ff593518-4451-4f4a-a98e-082853e41ebe,DISK], DatanodeInfoWithStorage[127.0.0.1:39534,DS-5971c07f-499f-4a42-a902-4b59ee695e49,DISK], DatanodeInfoWithStorage[127.0.0.1:45586,DS-a410ccd2-11f5-4c79-96da-165c03728a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:33354,DS-7288ac3f-41d1-473d-b888-3e029d3a4dec,DISK], DatanodeInfoWithStorage[127.0.0.1:40494,DS-6cf9de58-225e-4340-a8f2-346eceb5798f,DISK], DatanodeInfoWithStorage[127.0.0.1:46754,DS-76f542d6-e530-4172-9f20-bd11b9453111,DISK], DatanodeInfoWithStorage[127.0.0.1:33184,DS-df3ecaec-fc38-442d-853d-245493af4742,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1834486481-172.17.0.20-1596901540619:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44391,DS-8b4e0804-c968-4041-8ea1-810bfd857ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:36116,DS-7d39bc1a-97a0-4e0b-9bfb-c9ac4baf2a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:39262,DS-0db1138d-24a4-4bf3-82b9-0c1c293ac785,DISK], DatanodeInfoWithStorage[127.0.0.1:36330,DS-dbf9c45a-615e-4122-af55-2e119a2a07d0,DISK], DatanodeInfoWithStorage[127.0.0.1:37871,DS-fe149848-cd8c-41ce-beed-4c672ff658e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43660,DS-31f2469e-e1ba-45c2-ba12-923e4674118e,DISK], DatanodeInfoWithStorage[127.0.0.1:46110,DS-48cfb240-7b1e-4fc9-b031-ebba87f47c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:43030,DS-f7ae23c1-bd82-4df0-bab6-759531d6b25a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1834486481-172.17.0.20-1596901540619:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44391,DS-8b4e0804-c968-4041-8ea1-810bfd857ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:36116,DS-7d39bc1a-97a0-4e0b-9bfb-c9ac4baf2a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:39262,DS-0db1138d-24a4-4bf3-82b9-0c1c293ac785,DISK], DatanodeInfoWithStorage[127.0.0.1:36330,DS-dbf9c45a-615e-4122-af55-2e119a2a07d0,DISK], DatanodeInfoWithStorage[127.0.0.1:37871,DS-fe149848-cd8c-41ce-beed-4c672ff658e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43660,DS-31f2469e-e1ba-45c2-ba12-923e4674118e,DISK], DatanodeInfoWithStorage[127.0.0.1:46110,DS-48cfb240-7b1e-4fc9-b031-ebba87f47c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:43030,DS-f7ae23c1-bd82-4df0-bab6-759531d6b25a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-110647717-172.17.0.20-1596901758383:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34510,DS-e58d9fc1-4274-4b18-a35b-6fcf291b1f27,DISK], DatanodeInfoWithStorage[127.0.0.1:37046,DS-18d3cff4-5026-45d2-9d1c-9d5c7930b29b,DISK], DatanodeInfoWithStorage[127.0.0.1:37893,DS-63f5bcd5-7f49-403d-bb40-000361806880,DISK], DatanodeInfoWithStorage[127.0.0.1:46786,DS-96af6def-4410-4e41-ada6-d5edca231e56,DISK], DatanodeInfoWithStorage[127.0.0.1:43186,DS-6b56fb65-2416-49cb-96ec-26144c013d36,DISK], DatanodeInfoWithStorage[127.0.0.1:42840,DS-c4249614-3d06-432f-bd51-3aa158e0aea4,DISK], DatanodeInfoWithStorage[127.0.0.1:41743,DS-d1fbcfc3-31b4-40bc-95e9-45054b8249b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34483,DS-32d0f369-a723-4e9b-b75d-b81832c8d8ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-110647717-172.17.0.20-1596901758383:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34510,DS-e58d9fc1-4274-4b18-a35b-6fcf291b1f27,DISK], DatanodeInfoWithStorage[127.0.0.1:37046,DS-18d3cff4-5026-45d2-9d1c-9d5c7930b29b,DISK], DatanodeInfoWithStorage[127.0.0.1:37893,DS-63f5bcd5-7f49-403d-bb40-000361806880,DISK], DatanodeInfoWithStorage[127.0.0.1:46786,DS-96af6def-4410-4e41-ada6-d5edca231e56,DISK], DatanodeInfoWithStorage[127.0.0.1:43186,DS-6b56fb65-2416-49cb-96ec-26144c013d36,DISK], DatanodeInfoWithStorage[127.0.0.1:42840,DS-c4249614-3d06-432f-bd51-3aa158e0aea4,DISK], DatanodeInfoWithStorage[127.0.0.1:41743,DS-d1fbcfc3-31b4-40bc-95e9-45054b8249b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34483,DS-32d0f369-a723-4e9b-b75d-b81832c8d8ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-328820621-172.17.0.20-1596901791062:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46580,DS-afa1c71b-ed2a-4e9b-bb54-8e495d916710,DISK], DatanodeInfoWithStorage[127.0.0.1:40900,DS-d8759c97-043e-4a0f-b7a1-4c4c1297b17a,DISK], DatanodeInfoWithStorage[127.0.0.1:37474,DS-62a4f456-b699-4d4b-9e25-be83130aaf8e,DISK], DatanodeInfoWithStorage[127.0.0.1:37662,DS-2e2f748a-bd32-4e24-8b97-8333d7e47a77,DISK], DatanodeInfoWithStorage[127.0.0.1:45330,DS-32ae2c7c-0913-49c8-b82b-4f83f426c16e,DISK], DatanodeInfoWithStorage[127.0.0.1:36803,DS-95c3fd37-3d87-4a8d-a609-ee61bf52711d,DISK], DatanodeInfoWithStorage[127.0.0.1:43160,DS-a96b4b93-9284-4c60-a83a-704d58843b85,DISK], DatanodeInfoWithStorage[127.0.0.1:41146,DS-c7ea6b81-8781-47e0-987c-9d6cf429064a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-328820621-172.17.0.20-1596901791062:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46580,DS-afa1c71b-ed2a-4e9b-bb54-8e495d916710,DISK], DatanodeInfoWithStorage[127.0.0.1:40900,DS-d8759c97-043e-4a0f-b7a1-4c4c1297b17a,DISK], DatanodeInfoWithStorage[127.0.0.1:37474,DS-62a4f456-b699-4d4b-9e25-be83130aaf8e,DISK], DatanodeInfoWithStorage[127.0.0.1:37662,DS-2e2f748a-bd32-4e24-8b97-8333d7e47a77,DISK], DatanodeInfoWithStorage[127.0.0.1:45330,DS-32ae2c7c-0913-49c8-b82b-4f83f426c16e,DISK], DatanodeInfoWithStorage[127.0.0.1:36803,DS-95c3fd37-3d87-4a8d-a609-ee61bf52711d,DISK], DatanodeInfoWithStorage[127.0.0.1:43160,DS-a96b4b93-9284-4c60-a83a-704d58843b85,DISK], DatanodeInfoWithStorage[127.0.0.1:41146,DS-c7ea6b81-8781-47e0-987c-9d6cf429064a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1220975786-172.17.0.20-1596902146633:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36453,DS-8f391029-17df-4866-963b-f90f399c1ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:46327,DS-114ab511-a9c4-43a3-a4e3-4a84703cf8a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35347,DS-9bd62913-f60e-47e8-b368-8ee1f8dad07f,DISK], DatanodeInfoWithStorage[127.0.0.1:38545,DS-21e65b81-e46d-4d7f-9b8d-1a71df6c6e72,DISK], DatanodeInfoWithStorage[127.0.0.1:36847,DS-3d8aea1a-8799-4228-a147-6d4e1a29ed45,DISK], DatanodeInfoWithStorage[127.0.0.1:42810,DS-48205cd3-9d0e-4ad1-8172-fbe3e20761b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37143,DS-42c664be-4746-4fac-a7bf-6e17c70277da,DISK], DatanodeInfoWithStorage[127.0.0.1:35741,DS-7ec9238f-33df-4fff-9973-b0d8baebff91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1220975786-172.17.0.20-1596902146633:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36453,DS-8f391029-17df-4866-963b-f90f399c1ae8,DISK], DatanodeInfoWithStorage[127.0.0.1:46327,DS-114ab511-a9c4-43a3-a4e3-4a84703cf8a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35347,DS-9bd62913-f60e-47e8-b368-8ee1f8dad07f,DISK], DatanodeInfoWithStorage[127.0.0.1:38545,DS-21e65b81-e46d-4d7f-9b8d-1a71df6c6e72,DISK], DatanodeInfoWithStorage[127.0.0.1:36847,DS-3d8aea1a-8799-4228-a147-6d4e1a29ed45,DISK], DatanodeInfoWithStorage[127.0.0.1:42810,DS-48205cd3-9d0e-4ad1-8172-fbe3e20761b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37143,DS-42c664be-4746-4fac-a7bf-6e17c70277da,DISK], DatanodeInfoWithStorage[127.0.0.1:35741,DS-7ec9238f-33df-4fff-9973-b0d8baebff91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1033401937-172.17.0.20-1596902288798:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39475,DS-f1094bfa-67d8-4dd6-a943-46fea50c5235,DISK], DatanodeInfoWithStorage[127.0.0.1:34739,DS-1c97bfb6-e0fe-4006-8903-d78f09630e2c,DISK], DatanodeInfoWithStorage[127.0.0.1:39324,DS-f839412f-ec3c-44e8-a175-933d8fc046ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45691,DS-d60d9739-4c93-4231-8bb1-7dad5182d39a,DISK], DatanodeInfoWithStorage[127.0.0.1:43510,DS-09c1b794-a48c-41af-a6a1-01b5abe10e54,DISK], DatanodeInfoWithStorage[127.0.0.1:34615,DS-5b42d6bf-fce9-4199-a550-6c70eefb6ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:44287,DS-da9f8efe-bb26-45fd-9d88-ee53fac1a62d,DISK], DatanodeInfoWithStorage[127.0.0.1:44857,DS-22e36051-4534-4713-9cd5-5183a24d05ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1033401937-172.17.0.20-1596902288798:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39475,DS-f1094bfa-67d8-4dd6-a943-46fea50c5235,DISK], DatanodeInfoWithStorage[127.0.0.1:34739,DS-1c97bfb6-e0fe-4006-8903-d78f09630e2c,DISK], DatanodeInfoWithStorage[127.0.0.1:39324,DS-f839412f-ec3c-44e8-a175-933d8fc046ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45691,DS-d60d9739-4c93-4231-8bb1-7dad5182d39a,DISK], DatanodeInfoWithStorage[127.0.0.1:43510,DS-09c1b794-a48c-41af-a6a1-01b5abe10e54,DISK], DatanodeInfoWithStorage[127.0.0.1:34615,DS-5b42d6bf-fce9-4199-a550-6c70eefb6ab4,DISK], DatanodeInfoWithStorage[127.0.0.1:44287,DS-da9f8efe-bb26-45fd-9d88-ee53fac1a62d,DISK], DatanodeInfoWithStorage[127.0.0.1:44857,DS-22e36051-4534-4713-9cd5-5183a24d05ea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1052343926-172.17.0.20-1596903848026:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42979,DS-0a2f729f-3f8d-495f-ab67-134c02bbcb6d,DISK], DatanodeInfoWithStorage[127.0.0.1:46839,DS-646a526f-cd58-4980-8484-c4863afa0c76,DISK], DatanodeInfoWithStorage[127.0.0.1:42300,DS-11e73f46-fabc-4cef-bdeb-ca0dee4385a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38953,DS-9cfe4b9c-8c92-498d-a17b-5037b7cc3eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:41906,DS-f1c6c03b-20f9-4bcc-8626-21b726d0b4fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41432,DS-9526b792-e8cc-4725-aefa-97c4e9dbcd09,DISK], DatanodeInfoWithStorage[127.0.0.1:34352,DS-bd8baf0d-57b6-4293-9185-c1f591f1984f,DISK], DatanodeInfoWithStorage[127.0.0.1:39051,DS-4c7c7455-02d5-4ad6-a12c-cf2f497b3a07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1052343926-172.17.0.20-1596903848026:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42979,DS-0a2f729f-3f8d-495f-ab67-134c02bbcb6d,DISK], DatanodeInfoWithStorage[127.0.0.1:46839,DS-646a526f-cd58-4980-8484-c4863afa0c76,DISK], DatanodeInfoWithStorage[127.0.0.1:42300,DS-11e73f46-fabc-4cef-bdeb-ca0dee4385a6,DISK], DatanodeInfoWithStorage[127.0.0.1:38953,DS-9cfe4b9c-8c92-498d-a17b-5037b7cc3eb4,DISK], DatanodeInfoWithStorage[127.0.0.1:41906,DS-f1c6c03b-20f9-4bcc-8626-21b726d0b4fe,DISK], DatanodeInfoWithStorage[127.0.0.1:41432,DS-9526b792-e8cc-4725-aefa-97c4e9dbcd09,DISK], DatanodeInfoWithStorage[127.0.0.1:34352,DS-bd8baf0d-57b6-4293-9185-c1f591f1984f,DISK], DatanodeInfoWithStorage[127.0.0.1:39051,DS-4c7c7455-02d5-4ad6-a12c-cf2f497b3a07,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5438
