reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1508243676-172.17.0.18-1596986011428:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43233,DS-dbbe86d3-a90a-46f9-b607-12e9ae2784ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42232,DS-4e0dbe19-7d81-41bb-b1a6-771e1112aca1,DISK], DatanodeInfoWithStorage[127.0.0.1:40290,DS-e0317294-0b00-4672-bb88-5999fef4e14f,DISK], DatanodeInfoWithStorage[127.0.0.1:38976,DS-bd12ca46-68fb-42b5-a64d-bb46a94db08f,DISK], DatanodeInfoWithStorage[127.0.0.1:39328,DS-fbd8663b-7932-4c8e-a492-b17b5b60b568,DISK], DatanodeInfoWithStorage[127.0.0.1:43856,DS-af62c58a-30cf-498e-acf1-a6bd5f40185a,DISK], DatanodeInfoWithStorage[127.0.0.1:44612,DS-822047c6-bf5a-402a-aad8-86e0d31bd7b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34537,DS-edfd1e52-4ecb-457b-9e14-8c852579df22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1508243676-172.17.0.18-1596986011428:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43233,DS-dbbe86d3-a90a-46f9-b607-12e9ae2784ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42232,DS-4e0dbe19-7d81-41bb-b1a6-771e1112aca1,DISK], DatanodeInfoWithStorage[127.0.0.1:40290,DS-e0317294-0b00-4672-bb88-5999fef4e14f,DISK], DatanodeInfoWithStorage[127.0.0.1:38976,DS-bd12ca46-68fb-42b5-a64d-bb46a94db08f,DISK], DatanodeInfoWithStorage[127.0.0.1:39328,DS-fbd8663b-7932-4c8e-a492-b17b5b60b568,DISK], DatanodeInfoWithStorage[127.0.0.1:43856,DS-af62c58a-30cf-498e-acf1-a6bd5f40185a,DISK], DatanodeInfoWithStorage[127.0.0.1:44612,DS-822047c6-bf5a-402a-aad8-86e0d31bd7b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34537,DS-edfd1e52-4ecb-457b-9e14-8c852579df22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1351518310-172.17.0.18-1596986082963:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36630,DS-01c00489-2f97-449b-ba48-919940904456,DISK], DatanodeInfoWithStorage[127.0.0.1:45836,DS-1a8ab426-3861-46d5-a10d-70ee25dedde2,DISK], DatanodeInfoWithStorage[127.0.0.1:41399,DS-32f75572-9d47-4a45-9ea5-3b2742109b45,DISK], DatanodeInfoWithStorage[127.0.0.1:44301,DS-b9726d71-131c-446e-b266-d3b151d7e678,DISK], DatanodeInfoWithStorage[127.0.0.1:43116,DS-de592bcc-d760-427a-87db-88168b03d9a4,DISK], DatanodeInfoWithStorage[127.0.0.1:38554,DS-2b0bf35b-19ab-4577-9de9-2012f165fc3f,DISK], DatanodeInfoWithStorage[127.0.0.1:40280,DS-e7898767-d987-4577-ad77-d01a3fe0569d,DISK], DatanodeInfoWithStorage[127.0.0.1:44881,DS-2b98239f-8064-41b1-ab0f-6818579c3021,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1351518310-172.17.0.18-1596986082963:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36630,DS-01c00489-2f97-449b-ba48-919940904456,DISK], DatanodeInfoWithStorage[127.0.0.1:45836,DS-1a8ab426-3861-46d5-a10d-70ee25dedde2,DISK], DatanodeInfoWithStorage[127.0.0.1:41399,DS-32f75572-9d47-4a45-9ea5-3b2742109b45,DISK], DatanodeInfoWithStorage[127.0.0.1:44301,DS-b9726d71-131c-446e-b266-d3b151d7e678,DISK], DatanodeInfoWithStorage[127.0.0.1:43116,DS-de592bcc-d760-427a-87db-88168b03d9a4,DISK], DatanodeInfoWithStorage[127.0.0.1:38554,DS-2b0bf35b-19ab-4577-9de9-2012f165fc3f,DISK], DatanodeInfoWithStorage[127.0.0.1:40280,DS-e7898767-d987-4577-ad77-d01a3fe0569d,DISK], DatanodeInfoWithStorage[127.0.0.1:44881,DS-2b98239f-8064-41b1-ab0f-6818579c3021,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-228264825-172.17.0.18-1596986180879:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42102,DS-2b4be038-e9da-4267-a231-d7b953d4c1ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44738,DS-2f92f898-48f2-45e1-8e77-20a9f777e048,DISK], DatanodeInfoWithStorage[127.0.0.1:33209,DS-18ccb5e9-4ebf-4ab5-8077-940c08141be7,DISK], DatanodeInfoWithStorage[127.0.0.1:38593,DS-524b3ca6-e353-443f-a544-090a34712556,DISK], DatanodeInfoWithStorage[127.0.0.1:39535,DS-213e3c07-5a93-4e4c-a8bd-53c1a723f8f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33377,DS-f58f1527-ea0f-45ef-bba1-e1fc9069db12,DISK], DatanodeInfoWithStorage[127.0.0.1:40063,DS-cb062fcc-ec61-4395-986b-faa937fa70a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42391,DS-1aefdd28-a522-4098-9f71-567e7a4731bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-228264825-172.17.0.18-1596986180879:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42102,DS-2b4be038-e9da-4267-a231-d7b953d4c1ed,DISK], DatanodeInfoWithStorage[127.0.0.1:44738,DS-2f92f898-48f2-45e1-8e77-20a9f777e048,DISK], DatanodeInfoWithStorage[127.0.0.1:33209,DS-18ccb5e9-4ebf-4ab5-8077-940c08141be7,DISK], DatanodeInfoWithStorage[127.0.0.1:38593,DS-524b3ca6-e353-443f-a544-090a34712556,DISK], DatanodeInfoWithStorage[127.0.0.1:39535,DS-213e3c07-5a93-4e4c-a8bd-53c1a723f8f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33377,DS-f58f1527-ea0f-45ef-bba1-e1fc9069db12,DISK], DatanodeInfoWithStorage[127.0.0.1:40063,DS-cb062fcc-ec61-4395-986b-faa937fa70a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42391,DS-1aefdd28-a522-4098-9f71-567e7a4731bb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-45698738-172.17.0.18-1596986392269:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44458,DS-e7bd70b4-59e4-461d-aa63-34c7a4cdeb14,DISK], DatanodeInfoWithStorage[127.0.0.1:40353,DS-1108eed6-c3a3-40fb-9e78-114a0cddd7d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39250,DS-d8ddd9f5-d758-424c-b61d-1a191ff57ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:42021,DS-c9306e55-f06c-4835-b8fc-9a9efe6c1d73,DISK], DatanodeInfoWithStorage[127.0.0.1:34829,DS-6e5eafde-c32d-49ca-a889-dc63cd604435,DISK], DatanodeInfoWithStorage[127.0.0.1:44440,DS-60ef60cd-26d2-4102-916e-3a5120922c86,DISK], DatanodeInfoWithStorage[127.0.0.1:42847,DS-619d1d86-84cc-41cc-bf8f-26f625089514,DISK], DatanodeInfoWithStorage[127.0.0.1:46785,DS-1cb5ee4e-1695-4641-8b24-4cee41edb9cc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-45698738-172.17.0.18-1596986392269:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44458,DS-e7bd70b4-59e4-461d-aa63-34c7a4cdeb14,DISK], DatanodeInfoWithStorage[127.0.0.1:40353,DS-1108eed6-c3a3-40fb-9e78-114a0cddd7d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39250,DS-d8ddd9f5-d758-424c-b61d-1a191ff57ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:42021,DS-c9306e55-f06c-4835-b8fc-9a9efe6c1d73,DISK], DatanodeInfoWithStorage[127.0.0.1:34829,DS-6e5eafde-c32d-49ca-a889-dc63cd604435,DISK], DatanodeInfoWithStorage[127.0.0.1:44440,DS-60ef60cd-26d2-4102-916e-3a5120922c86,DISK], DatanodeInfoWithStorage[127.0.0.1:42847,DS-619d1d86-84cc-41cc-bf8f-26f625089514,DISK], DatanodeInfoWithStorage[127.0.0.1:46785,DS-1cb5ee4e-1695-4641-8b24-4cee41edb9cc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1341941500-172.17.0.18-1596986452754:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45297,DS-389c2f16-4f3d-4acb-955e-1e59bf0b4306,DISK], DatanodeInfoWithStorage[127.0.0.1:43793,DS-0899df07-b332-4691-93a8-dda51fa30cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:42561,DS-4b100534-2387-4e43-acd6-900117cb2eba,DISK], DatanodeInfoWithStorage[127.0.0.1:40347,DS-52ca4fdc-fa71-4069-930f-458314db1d9b,DISK], DatanodeInfoWithStorage[127.0.0.1:33400,DS-dc126199-e201-4339-8ec4-0970f9831302,DISK], DatanodeInfoWithStorage[127.0.0.1:39226,DS-f3e18faf-5e09-4164-9507-791731104211,DISK], DatanodeInfoWithStorage[127.0.0.1:39830,DS-c927e500-deab-4ff2-a3ae-d2c5d8842748,DISK], DatanodeInfoWithStorage[127.0.0.1:33770,DS-e773b975-6cdc-4ebe-8dfd-8616936fecae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1341941500-172.17.0.18-1596986452754:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45297,DS-389c2f16-4f3d-4acb-955e-1e59bf0b4306,DISK], DatanodeInfoWithStorage[127.0.0.1:43793,DS-0899df07-b332-4691-93a8-dda51fa30cf8,DISK], DatanodeInfoWithStorage[127.0.0.1:42561,DS-4b100534-2387-4e43-acd6-900117cb2eba,DISK], DatanodeInfoWithStorage[127.0.0.1:40347,DS-52ca4fdc-fa71-4069-930f-458314db1d9b,DISK], DatanodeInfoWithStorage[127.0.0.1:33400,DS-dc126199-e201-4339-8ec4-0970f9831302,DISK], DatanodeInfoWithStorage[127.0.0.1:39226,DS-f3e18faf-5e09-4164-9507-791731104211,DISK], DatanodeInfoWithStorage[127.0.0.1:39830,DS-c927e500-deab-4ff2-a3ae-d2c5d8842748,DISK], DatanodeInfoWithStorage[127.0.0.1:33770,DS-e773b975-6cdc-4ebe-8dfd-8616936fecae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1618973625-172.17.0.18-1596986485962:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43287,DS-ef33b11e-9bd0-4e90-be6f-bcf77a9d232d,DISK], DatanodeInfoWithStorage[127.0.0.1:41823,DS-637fb3d7-262b-42f6-952b-07a12c852aa3,DISK], DatanodeInfoWithStorage[127.0.0.1:38254,DS-324c18e8-a024-4149-8a30-695d6e2dcce3,DISK], DatanodeInfoWithStorage[127.0.0.1:37435,DS-ecfa72d6-5034-4309-842d-237838bea122,DISK], DatanodeInfoWithStorage[127.0.0.1:39369,DS-98afd145-ba72-4f22-931f-8ec8e15e1042,DISK], DatanodeInfoWithStorage[127.0.0.1:42884,DS-30ac7859-3714-4549-9f69-ae0ff33dfc77,DISK], DatanodeInfoWithStorage[127.0.0.1:43982,DS-9b32f2da-cff0-4e7d-a435-fd4744268751,DISK], DatanodeInfoWithStorage[127.0.0.1:39926,DS-fc56e10b-6dd6-488e-9d58-aacb8ebe97a4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1618973625-172.17.0.18-1596986485962:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43287,DS-ef33b11e-9bd0-4e90-be6f-bcf77a9d232d,DISK], DatanodeInfoWithStorage[127.0.0.1:41823,DS-637fb3d7-262b-42f6-952b-07a12c852aa3,DISK], DatanodeInfoWithStorage[127.0.0.1:38254,DS-324c18e8-a024-4149-8a30-695d6e2dcce3,DISK], DatanodeInfoWithStorage[127.0.0.1:37435,DS-ecfa72d6-5034-4309-842d-237838bea122,DISK], DatanodeInfoWithStorage[127.0.0.1:39369,DS-98afd145-ba72-4f22-931f-8ec8e15e1042,DISK], DatanodeInfoWithStorage[127.0.0.1:42884,DS-30ac7859-3714-4549-9f69-ae0ff33dfc77,DISK], DatanodeInfoWithStorage[127.0.0.1:43982,DS-9b32f2da-cff0-4e7d-a435-fd4744268751,DISK], DatanodeInfoWithStorage[127.0.0.1:39926,DS-fc56e10b-6dd6-488e-9d58-aacb8ebe97a4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1298689613-172.17.0.18-1596986589220:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38786,DS-901f4198-d12b-4cfe-960a-4eec2d5d0f38,DISK], DatanodeInfoWithStorage[127.0.0.1:38944,DS-ce34a669-ec9c-4883-a546-7710aab0905d,DISK], DatanodeInfoWithStorage[127.0.0.1:42884,DS-b442ad9f-d0b3-420d-af11-70d3345c6633,DISK], DatanodeInfoWithStorage[127.0.0.1:42005,DS-a9472d89-9933-4487-a91c-c3cc5dd3ad72,DISK], DatanodeInfoWithStorage[127.0.0.1:36125,DS-3e5ba458-4f29-40c1-b612-06645ddf4beb,DISK], DatanodeInfoWithStorage[127.0.0.1:33679,DS-b7ef1813-ee03-438f-b680-6ebc24e50cb1,DISK], DatanodeInfoWithStorage[127.0.0.1:35293,DS-5c2e6dbd-8c1d-479c-b31f-1053f6e4490d,DISK], DatanodeInfoWithStorage[127.0.0.1:43133,DS-6d44c481-bc29-419c-b572-0757a4e2547b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1298689613-172.17.0.18-1596986589220:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38786,DS-901f4198-d12b-4cfe-960a-4eec2d5d0f38,DISK], DatanodeInfoWithStorage[127.0.0.1:38944,DS-ce34a669-ec9c-4883-a546-7710aab0905d,DISK], DatanodeInfoWithStorage[127.0.0.1:42884,DS-b442ad9f-d0b3-420d-af11-70d3345c6633,DISK], DatanodeInfoWithStorage[127.0.0.1:42005,DS-a9472d89-9933-4487-a91c-c3cc5dd3ad72,DISK], DatanodeInfoWithStorage[127.0.0.1:36125,DS-3e5ba458-4f29-40c1-b612-06645ddf4beb,DISK], DatanodeInfoWithStorage[127.0.0.1:33679,DS-b7ef1813-ee03-438f-b680-6ebc24e50cb1,DISK], DatanodeInfoWithStorage[127.0.0.1:35293,DS-5c2e6dbd-8c1d-479c-b31f-1053f6e4490d,DISK], DatanodeInfoWithStorage[127.0.0.1:43133,DS-6d44c481-bc29-419c-b572-0757a4e2547b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-17403451-172.17.0.18-1596986771602:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35175,DS-74dec1b4-be42-4145-bb1b-4e2d3582a759,DISK], DatanodeInfoWithStorage[127.0.0.1:41130,DS-233fddd1-24f5-49e5-b4ad-7e43f1e19fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:36306,DS-98fc1015-e209-4165-a6fc-7b76e87a6eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:42476,DS-5b5d0ce1-2851-46eb-ae1c-ca53d1a57b94,DISK], DatanodeInfoWithStorage[127.0.0.1:46183,DS-c973cbc3-3f1e-4121-8bec-a718494c9e4d,DISK], DatanodeInfoWithStorage[127.0.0.1:36257,DS-bfd3a32f-837a-48ab-9ef4-1796ef0068f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39708,DS-e1353ae3-e8c2-4f39-a667-b5ce07668f7d,DISK], DatanodeInfoWithStorage[127.0.0.1:34825,DS-c65e9329-d198-4873-a299-a4e51f1cc81f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-17403451-172.17.0.18-1596986771602:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35175,DS-74dec1b4-be42-4145-bb1b-4e2d3582a759,DISK], DatanodeInfoWithStorage[127.0.0.1:41130,DS-233fddd1-24f5-49e5-b4ad-7e43f1e19fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:36306,DS-98fc1015-e209-4165-a6fc-7b76e87a6eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:42476,DS-5b5d0ce1-2851-46eb-ae1c-ca53d1a57b94,DISK], DatanodeInfoWithStorage[127.0.0.1:46183,DS-c973cbc3-3f1e-4121-8bec-a718494c9e4d,DISK], DatanodeInfoWithStorage[127.0.0.1:36257,DS-bfd3a32f-837a-48ab-9ef4-1796ef0068f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39708,DS-e1353ae3-e8c2-4f39-a667-b5ce07668f7d,DISK], DatanodeInfoWithStorage[127.0.0.1:34825,DS-c65e9329-d198-4873-a299-a4e51f1cc81f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2016527441-172.17.0.18-1596986844893:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35055,DS-407934e2-be02-4eb5-8fa8-00891572338e,DISK], DatanodeInfoWithStorage[127.0.0.1:45477,DS-815ff3f0-006d-4a07-9411-ec2a69cc73ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45464,DS-76ea1803-c11a-4126-9df6-f7effb2242db,DISK], DatanodeInfoWithStorage[127.0.0.1:40030,DS-ea8642af-cc1c-4981-9787-310cf0bbf25e,DISK], DatanodeInfoWithStorage[127.0.0.1:34735,DS-df045339-d09e-4d6a-986b-dd45127e154a,DISK], DatanodeInfoWithStorage[127.0.0.1:39063,DS-a180e510-098f-4c95-9c90-6ca0810adc38,DISK], DatanodeInfoWithStorage[127.0.0.1:46184,DS-8c9a34ea-e515-4dc3-b78f-acca2940b9e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37925,DS-57d01dce-f51b-4053-8398-d91967c0d30c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2016527441-172.17.0.18-1596986844893:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35055,DS-407934e2-be02-4eb5-8fa8-00891572338e,DISK], DatanodeInfoWithStorage[127.0.0.1:45477,DS-815ff3f0-006d-4a07-9411-ec2a69cc73ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45464,DS-76ea1803-c11a-4126-9df6-f7effb2242db,DISK], DatanodeInfoWithStorage[127.0.0.1:40030,DS-ea8642af-cc1c-4981-9787-310cf0bbf25e,DISK], DatanodeInfoWithStorage[127.0.0.1:34735,DS-df045339-d09e-4d6a-986b-dd45127e154a,DISK], DatanodeInfoWithStorage[127.0.0.1:39063,DS-a180e510-098f-4c95-9c90-6ca0810adc38,DISK], DatanodeInfoWithStorage[127.0.0.1:46184,DS-8c9a34ea-e515-4dc3-b78f-acca2940b9e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37925,DS-57d01dce-f51b-4053-8398-d91967c0d30c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-916518275-172.17.0.18-1596986975204:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41179,DS-7f32ca9e-fc5f-4d54-a0e6-4c9ba4eb5f6f,DISK], DatanodeInfoWithStorage[127.0.0.1:40310,DS-bf036f21-447d-4083-902d-1450d8629c37,DISK], DatanodeInfoWithStorage[127.0.0.1:42593,DS-7e4fb838-f939-4945-91a3-20f52691ab84,DISK], DatanodeInfoWithStorage[127.0.0.1:44103,DS-a9d9af42-27de-4920-a959-7a709bf39fcf,DISK], DatanodeInfoWithStorage[127.0.0.1:33804,DS-50489003-577b-42ce-a9b9-42634cbabd33,DISK], DatanodeInfoWithStorage[127.0.0.1:46847,DS-d57475b5-3729-4ae4-bd27-62b12859620a,DISK], DatanodeInfoWithStorage[127.0.0.1:45806,DS-34821648-6df9-4a9a-967e-649a81dd2a35,DISK], DatanodeInfoWithStorage[127.0.0.1:41520,DS-c3442510-33d9-4053-ba76-c27eaf32c2ea,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-916518275-172.17.0.18-1596986975204:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41179,DS-7f32ca9e-fc5f-4d54-a0e6-4c9ba4eb5f6f,DISK], DatanodeInfoWithStorage[127.0.0.1:40310,DS-bf036f21-447d-4083-902d-1450d8629c37,DISK], DatanodeInfoWithStorage[127.0.0.1:42593,DS-7e4fb838-f939-4945-91a3-20f52691ab84,DISK], DatanodeInfoWithStorage[127.0.0.1:44103,DS-a9d9af42-27de-4920-a959-7a709bf39fcf,DISK], DatanodeInfoWithStorage[127.0.0.1:33804,DS-50489003-577b-42ce-a9b9-42634cbabd33,DISK], DatanodeInfoWithStorage[127.0.0.1:46847,DS-d57475b5-3729-4ae4-bd27-62b12859620a,DISK], DatanodeInfoWithStorage[127.0.0.1:45806,DS-34821648-6df9-4a9a-967e-649a81dd2a35,DISK], DatanodeInfoWithStorage[127.0.0.1:41520,DS-c3442510-33d9-4053-ba76-c27eaf32c2ea,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1409220585-172.17.0.18-1596987273504:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44583,DS-2c61a9ca-0df6-48c7-9135-366cff1f1283,DISK], DatanodeInfoWithStorage[127.0.0.1:46005,DS-5e5bc5c1-c2b4-4804-a561-609baa8a6ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:39146,DS-c9fd7bb7-07aa-4ad0-a0ad-b59bae675c0f,DISK], DatanodeInfoWithStorage[127.0.0.1:35248,DS-df5c85b2-e38b-439b-8394-c67d9823915d,DISK], DatanodeInfoWithStorage[127.0.0.1:46701,DS-b25bec1e-faf9-4dc8-8adc-b866f70a207d,DISK], DatanodeInfoWithStorage[127.0.0.1:40285,DS-1fb46960-b0cc-42ad-a957-5a4d59214129,DISK], DatanodeInfoWithStorage[127.0.0.1:33480,DS-237f0308-9db6-4445-afd3-3a48f71b5b18,DISK], DatanodeInfoWithStorage[127.0.0.1:34774,DS-19f94d06-1ca1-4122-b641-bff606c1cfc2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1409220585-172.17.0.18-1596987273504:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44583,DS-2c61a9ca-0df6-48c7-9135-366cff1f1283,DISK], DatanodeInfoWithStorage[127.0.0.1:46005,DS-5e5bc5c1-c2b4-4804-a561-609baa8a6ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:39146,DS-c9fd7bb7-07aa-4ad0-a0ad-b59bae675c0f,DISK], DatanodeInfoWithStorage[127.0.0.1:35248,DS-df5c85b2-e38b-439b-8394-c67d9823915d,DISK], DatanodeInfoWithStorage[127.0.0.1:46701,DS-b25bec1e-faf9-4dc8-8adc-b866f70a207d,DISK], DatanodeInfoWithStorage[127.0.0.1:40285,DS-1fb46960-b0cc-42ad-a957-5a4d59214129,DISK], DatanodeInfoWithStorage[127.0.0.1:33480,DS-237f0308-9db6-4445-afd3-3a48f71b5b18,DISK], DatanodeInfoWithStorage[127.0.0.1:34774,DS-19f94d06-1ca1-4122-b641-bff606c1cfc2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-394634391-172.17.0.18-1596987368149:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32870,DS-ca6cbd23-1407-4255-923d-55c690147370,DISK], DatanodeInfoWithStorage[127.0.0.1:40672,DS-1c2998b1-ac64-4ff4-be14-edec15269cd9,DISK], DatanodeInfoWithStorage[127.0.0.1:42278,DS-15db4e16-f06f-4c24-bcba-e57d02ac4a14,DISK], DatanodeInfoWithStorage[127.0.0.1:36695,DS-6e62a8a1-d176-4aba-84ab-c5db6b1d4982,DISK], DatanodeInfoWithStorage[127.0.0.1:38688,DS-c0e0bb04-32b7-4dbc-9b7a-3b4d42610683,DISK], DatanodeInfoWithStorage[127.0.0.1:43465,DS-4a698f61-277e-4fb7-a8a6-6d93e224fb5e,DISK], DatanodeInfoWithStorage[127.0.0.1:41138,DS-e32fdc77-363c-4fcb-b0ea-481290e76b97,DISK], DatanodeInfoWithStorage[127.0.0.1:45811,DS-f0af9f62-38f4-45d5-949d-cb3903e180f9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-394634391-172.17.0.18-1596987368149:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32870,DS-ca6cbd23-1407-4255-923d-55c690147370,DISK], DatanodeInfoWithStorage[127.0.0.1:40672,DS-1c2998b1-ac64-4ff4-be14-edec15269cd9,DISK], DatanodeInfoWithStorage[127.0.0.1:42278,DS-15db4e16-f06f-4c24-bcba-e57d02ac4a14,DISK], DatanodeInfoWithStorage[127.0.0.1:36695,DS-6e62a8a1-d176-4aba-84ab-c5db6b1d4982,DISK], DatanodeInfoWithStorage[127.0.0.1:38688,DS-c0e0bb04-32b7-4dbc-9b7a-3b4d42610683,DISK], DatanodeInfoWithStorage[127.0.0.1:43465,DS-4a698f61-277e-4fb7-a8a6-6d93e224fb5e,DISK], DatanodeInfoWithStorage[127.0.0.1:41138,DS-e32fdc77-363c-4fcb-b0ea-481290e76b97,DISK], DatanodeInfoWithStorage[127.0.0.1:45811,DS-f0af9f62-38f4-45d5-949d-cb3903e180f9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-413663271-172.17.0.18-1596987698358:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35335,DS-d3dcecf0-3856-4aa6-8449-80276a633311,DISK], DatanodeInfoWithStorage[127.0.0.1:39329,DS-c974430b-ad78-4d29-859d-6fc6b8a47626,DISK], DatanodeInfoWithStorage[127.0.0.1:39966,DS-fd22eeca-0a7c-499b-8c20-d4a7b61c0b70,DISK], DatanodeInfoWithStorage[127.0.0.1:39328,DS-fbc58e98-b261-4dfa-b408-824b8c6023bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41831,DS-e6a27857-3c6d-470d-b0a2-e853ad46afd5,DISK], DatanodeInfoWithStorage[127.0.0.1:46208,DS-3d45615c-aefe-4228-94f9-878b317a11f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45990,DS-3441d0c8-3b85-4e41-aaec-d51def8ff57a,DISK], DatanodeInfoWithStorage[127.0.0.1:39322,DS-004d2f46-49cc-41cf-93d3-63ad9239313b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-413663271-172.17.0.18-1596987698358:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35335,DS-d3dcecf0-3856-4aa6-8449-80276a633311,DISK], DatanodeInfoWithStorage[127.0.0.1:39329,DS-c974430b-ad78-4d29-859d-6fc6b8a47626,DISK], DatanodeInfoWithStorage[127.0.0.1:39966,DS-fd22eeca-0a7c-499b-8c20-d4a7b61c0b70,DISK], DatanodeInfoWithStorage[127.0.0.1:39328,DS-fbc58e98-b261-4dfa-b408-824b8c6023bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41831,DS-e6a27857-3c6d-470d-b0a2-e853ad46afd5,DISK], DatanodeInfoWithStorage[127.0.0.1:46208,DS-3d45615c-aefe-4228-94f9-878b317a11f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45990,DS-3441d0c8-3b85-4e41-aaec-d51def8ff57a,DISK], DatanodeInfoWithStorage[127.0.0.1:39322,DS-004d2f46-49cc-41cf-93d3-63ad9239313b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-637170717-172.17.0.18-1596987749809:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40614,DS-9c1c8a4e-3ffd-444a-bb10-819194a7e8ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39769,DS-bafc375b-0705-4836-a638-1fb19891481f,DISK], DatanodeInfoWithStorage[127.0.0.1:40563,DS-a8fdfbc8-3bde-45a6-b32c-f0841372cddd,DISK], DatanodeInfoWithStorage[127.0.0.1:41467,DS-3e745c49-99d4-468c-a022-216f08f42c94,DISK], DatanodeInfoWithStorage[127.0.0.1:36563,DS-4df15fc1-37e4-4fb1-a1aa-47c6c3e86770,DISK], DatanodeInfoWithStorage[127.0.0.1:45771,DS-dd3e057d-3b15-4284-9ba7-1d1828522458,DISK], DatanodeInfoWithStorage[127.0.0.1:42052,DS-d14ae3cb-09b0-40e0-b4a5-9af6a5ee2f90,DISK], DatanodeInfoWithStorage[127.0.0.1:41547,DS-5a6fbffc-13a4-4c37-aac0-0df32dabb868,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-637170717-172.17.0.18-1596987749809:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40614,DS-9c1c8a4e-3ffd-444a-bb10-819194a7e8ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39769,DS-bafc375b-0705-4836-a638-1fb19891481f,DISK], DatanodeInfoWithStorage[127.0.0.1:40563,DS-a8fdfbc8-3bde-45a6-b32c-f0841372cddd,DISK], DatanodeInfoWithStorage[127.0.0.1:41467,DS-3e745c49-99d4-468c-a022-216f08f42c94,DISK], DatanodeInfoWithStorage[127.0.0.1:36563,DS-4df15fc1-37e4-4fb1-a1aa-47c6c3e86770,DISK], DatanodeInfoWithStorage[127.0.0.1:45771,DS-dd3e057d-3b15-4284-9ba7-1d1828522458,DISK], DatanodeInfoWithStorage[127.0.0.1:42052,DS-d14ae3cb-09b0-40e0-b4a5-9af6a5ee2f90,DISK], DatanodeInfoWithStorage[127.0.0.1:41547,DS-5a6fbffc-13a4-4c37-aac0-0df32dabb868,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2060732640-172.17.0.18-1596987798470:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35599,DS-fc83c12c-27bb-48e1-9475-76642bdb338b,DISK], DatanodeInfoWithStorage[127.0.0.1:38211,DS-badf7500-e5c8-4eac-bbee-bb77c53dff59,DISK], DatanodeInfoWithStorage[127.0.0.1:36036,DS-4f366ee8-d5c9-459c-b9be-2d8cd5e82aa6,DISK], DatanodeInfoWithStorage[127.0.0.1:45993,DS-a97358f7-fa70-4b95-962a-452248615342,DISK], DatanodeInfoWithStorage[127.0.0.1:36849,DS-b3dd7c23-1b75-40fb-b2f0-a5bb32908f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:39622,DS-18944141-5229-4b8d-844c-06c113d61a98,DISK], DatanodeInfoWithStorage[127.0.0.1:45364,DS-f7073501-c2af-4902-9d4f-874f98fc0713,DISK], DatanodeInfoWithStorage[127.0.0.1:44366,DS-03a15b90-b53e-424c-b2f9-ac9b28a4187c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2060732640-172.17.0.18-1596987798470:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35599,DS-fc83c12c-27bb-48e1-9475-76642bdb338b,DISK], DatanodeInfoWithStorage[127.0.0.1:38211,DS-badf7500-e5c8-4eac-bbee-bb77c53dff59,DISK], DatanodeInfoWithStorage[127.0.0.1:36036,DS-4f366ee8-d5c9-459c-b9be-2d8cd5e82aa6,DISK], DatanodeInfoWithStorage[127.0.0.1:45993,DS-a97358f7-fa70-4b95-962a-452248615342,DISK], DatanodeInfoWithStorage[127.0.0.1:36849,DS-b3dd7c23-1b75-40fb-b2f0-a5bb32908f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:39622,DS-18944141-5229-4b8d-844c-06c113d61a98,DISK], DatanodeInfoWithStorage[127.0.0.1:45364,DS-f7073501-c2af-4902-9d4f-874f98fc0713,DISK], DatanodeInfoWithStorage[127.0.0.1:44366,DS-03a15b90-b53e-424c-b2f9-ac9b28a4187c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-659971406-172.17.0.18-1596987848428:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45775,DS-033a8460-44d0-4951-b022-b663ff5096a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42720,DS-9595c5de-64bd-41fd-bb0c-81f1b5d93f82,DISK], DatanodeInfoWithStorage[127.0.0.1:37260,DS-b1991253-8ad8-44b0-a5c9-46c92a88ae74,DISK], DatanodeInfoWithStorage[127.0.0.1:34588,DS-2fca9320-fc80-4fd4-9429-30bd74176ac1,DISK], DatanodeInfoWithStorage[127.0.0.1:33102,DS-30f4cb08-ed08-4e1d-836c-b3796fd82e9b,DISK], DatanodeInfoWithStorage[127.0.0.1:33369,DS-d39d5c3d-c70f-4b60-ad1d-e7e8a0c59e43,DISK], DatanodeInfoWithStorage[127.0.0.1:44433,DS-d9312d13-cb7d-4e07-b7de-40514cb452b8,DISK], DatanodeInfoWithStorage[127.0.0.1:32874,DS-e7c07d47-68df-4ba9-b4dc-bea018cc3226,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-659971406-172.17.0.18-1596987848428:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45775,DS-033a8460-44d0-4951-b022-b663ff5096a6,DISK], DatanodeInfoWithStorage[127.0.0.1:42720,DS-9595c5de-64bd-41fd-bb0c-81f1b5d93f82,DISK], DatanodeInfoWithStorage[127.0.0.1:37260,DS-b1991253-8ad8-44b0-a5c9-46c92a88ae74,DISK], DatanodeInfoWithStorage[127.0.0.1:34588,DS-2fca9320-fc80-4fd4-9429-30bd74176ac1,DISK], DatanodeInfoWithStorage[127.0.0.1:33102,DS-30f4cb08-ed08-4e1d-836c-b3796fd82e9b,DISK], DatanodeInfoWithStorage[127.0.0.1:33369,DS-d39d5c3d-c70f-4b60-ad1d-e7e8a0c59e43,DISK], DatanodeInfoWithStorage[127.0.0.1:44433,DS-d9312d13-cb7d-4e07-b7de-40514cb452b8,DISK], DatanodeInfoWithStorage[127.0.0.1:32874,DS-e7c07d47-68df-4ba9-b4dc-bea018cc3226,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1687721738-172.17.0.18-1596987948564:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33211,DS-2b8ad9a8-abeb-4934-9a86-3ebc7f5a0527,DISK], DatanodeInfoWithStorage[127.0.0.1:43825,DS-d9b2a353-5225-4c67-8fe3-999fe782c1e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35906,DS-13c905ed-0ef0-44ee-a87f-4f2cbfe78f51,DISK], DatanodeInfoWithStorage[127.0.0.1:34947,DS-c5bfafb2-b3fa-4412-b1ad-fdd6f937b9a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35095,DS-ce5f2a95-3054-4f68-99bf-3048ac96eb11,DISK], DatanodeInfoWithStorage[127.0.0.1:45160,DS-b5ac16cd-d9cd-405e-932c-c0b45558b73c,DISK], DatanodeInfoWithStorage[127.0.0.1:40724,DS-6cd5e4d5-8967-49a1-be77-0529ba6720e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45922,DS-da71d49e-c6cf-477c-9e59-e9de819cad77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1687721738-172.17.0.18-1596987948564:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33211,DS-2b8ad9a8-abeb-4934-9a86-3ebc7f5a0527,DISK], DatanodeInfoWithStorage[127.0.0.1:43825,DS-d9b2a353-5225-4c67-8fe3-999fe782c1e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35906,DS-13c905ed-0ef0-44ee-a87f-4f2cbfe78f51,DISK], DatanodeInfoWithStorage[127.0.0.1:34947,DS-c5bfafb2-b3fa-4412-b1ad-fdd6f937b9a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35095,DS-ce5f2a95-3054-4f68-99bf-3048ac96eb11,DISK], DatanodeInfoWithStorage[127.0.0.1:45160,DS-b5ac16cd-d9cd-405e-932c-c0b45558b73c,DISK], DatanodeInfoWithStorage[127.0.0.1:40724,DS-6cd5e4d5-8967-49a1-be77-0529ba6720e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45922,DS-da71d49e-c6cf-477c-9e59-e9de819cad77,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-474174918-172.17.0.18-1596987982263:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34753,DS-fb013bec-45c6-4970-9861-25be3f66ae46,DISK], DatanodeInfoWithStorage[127.0.0.1:46776,DS-a2799074-c526-4e58-996f-b629812b50c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33355,DS-fdf9b858-3915-42cf-a99b-8410e3d9e5d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34843,DS-6362a84b-463f-476d-9137-690eddb1a55e,DISK], DatanodeInfoWithStorage[127.0.0.1:36895,DS-70de3297-6c17-4d65-a6c2-b7a8dc8d374a,DISK], DatanodeInfoWithStorage[127.0.0.1:37759,DS-eeaca488-7c20-4a3d-81f6-f619eb148cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:41643,DS-a17ef568-8e6c-46b8-8636-24789e3c0dd8,DISK], DatanodeInfoWithStorage[127.0.0.1:44192,DS-d77970e8-814b-4b69-9d0b-d7b346f4ac6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-474174918-172.17.0.18-1596987982263:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34753,DS-fb013bec-45c6-4970-9861-25be3f66ae46,DISK], DatanodeInfoWithStorage[127.0.0.1:46776,DS-a2799074-c526-4e58-996f-b629812b50c5,DISK], DatanodeInfoWithStorage[127.0.0.1:33355,DS-fdf9b858-3915-42cf-a99b-8410e3d9e5d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34843,DS-6362a84b-463f-476d-9137-690eddb1a55e,DISK], DatanodeInfoWithStorage[127.0.0.1:36895,DS-70de3297-6c17-4d65-a6c2-b7a8dc8d374a,DISK], DatanodeInfoWithStorage[127.0.0.1:37759,DS-eeaca488-7c20-4a3d-81f6-f619eb148cc2,DISK], DatanodeInfoWithStorage[127.0.0.1:41643,DS-a17ef568-8e6c-46b8-8636-24789e3c0dd8,DISK], DatanodeInfoWithStorage[127.0.0.1:44192,DS-d77970e8-814b-4b69-9d0b-d7b346f4ac6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-747055534-172.17.0.18-1596988128899:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38419,DS-1bc68ccb-0c5f-4e55-8550-46d5e94d917a,DISK], DatanodeInfoWithStorage[127.0.0.1:39738,DS-bb2c2cb6-e535-4430-8adc-d6e2c29413b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41017,DS-963f5894-cd30-4417-a051-70c49bf0d29c,DISK], DatanodeInfoWithStorage[127.0.0.1:38605,DS-992e3f97-c850-468c-a299-842bbfa213b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37313,DS-abc6fdc9-c3fd-491f-a87e-2f3fa215c53b,DISK], DatanodeInfoWithStorage[127.0.0.1:32785,DS-d7aab221-48f5-4f5e-bc9a-aa2111272397,DISK], DatanodeInfoWithStorage[127.0.0.1:34003,DS-9e331e2d-391e-4907-9be1-8f97affdc3e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36963,DS-53ba3d4c-d822-4340-b196-24012cf51792,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-747055534-172.17.0.18-1596988128899:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38419,DS-1bc68ccb-0c5f-4e55-8550-46d5e94d917a,DISK], DatanodeInfoWithStorage[127.0.0.1:39738,DS-bb2c2cb6-e535-4430-8adc-d6e2c29413b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41017,DS-963f5894-cd30-4417-a051-70c49bf0d29c,DISK], DatanodeInfoWithStorage[127.0.0.1:38605,DS-992e3f97-c850-468c-a299-842bbfa213b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37313,DS-abc6fdc9-c3fd-491f-a87e-2f3fa215c53b,DISK], DatanodeInfoWithStorage[127.0.0.1:32785,DS-d7aab221-48f5-4f5e-bc9a-aa2111272397,DISK], DatanodeInfoWithStorage[127.0.0.1:34003,DS-9e331e2d-391e-4907-9be1-8f97affdc3e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36963,DS-53ba3d4c-d822-4340-b196-24012cf51792,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-446430062-172.17.0.18-1596988226650:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37244,DS-5c3a5b54-7aae-432e-8439-adf521bba370,DISK], DatanodeInfoWithStorage[127.0.0.1:46622,DS-6bbe9f4b-0666-44d5-8cc9-0da0892e23ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42096,DS-c17623a6-6911-48dc-8a17-a7661c2242d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42087,DS-7513680f-5fd5-4a3a-83b0-9a132d1f61ae,DISK], DatanodeInfoWithStorage[127.0.0.1:36949,DS-62c1079a-877c-40ca-b6b1-ccac809b1b47,DISK], DatanodeInfoWithStorage[127.0.0.1:39728,DS-83b7e03b-4661-432a-9bfa-9624c3dc5e99,DISK], DatanodeInfoWithStorage[127.0.0.1:43815,DS-7c2b42cd-b916-418c-b427-0c44a034bfd6,DISK], DatanodeInfoWithStorage[127.0.0.1:44761,DS-38628c85-ffca-4255-8ed9-0b762be7de8f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-446430062-172.17.0.18-1596988226650:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37244,DS-5c3a5b54-7aae-432e-8439-adf521bba370,DISK], DatanodeInfoWithStorage[127.0.0.1:46622,DS-6bbe9f4b-0666-44d5-8cc9-0da0892e23ab,DISK], DatanodeInfoWithStorage[127.0.0.1:42096,DS-c17623a6-6911-48dc-8a17-a7661c2242d1,DISK], DatanodeInfoWithStorage[127.0.0.1:42087,DS-7513680f-5fd5-4a3a-83b0-9a132d1f61ae,DISK], DatanodeInfoWithStorage[127.0.0.1:36949,DS-62c1079a-877c-40ca-b6b1-ccac809b1b47,DISK], DatanodeInfoWithStorage[127.0.0.1:39728,DS-83b7e03b-4661-432a-9bfa-9624c3dc5e99,DISK], DatanodeInfoWithStorage[127.0.0.1:43815,DS-7c2b42cd-b916-418c-b427-0c44a034bfd6,DISK], DatanodeInfoWithStorage[127.0.0.1:44761,DS-38628c85-ffca-4255-8ed9-0b762be7de8f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1404074699-172.17.0.18-1596988243559:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40834,DS-a9765927-1463-4f11-ab3b-d85bdda7b38b,DISK], DatanodeInfoWithStorage[127.0.0.1:41126,DS-fc8d2b5b-4be4-444c-a633-df8c7ffbf1fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46552,DS-739c6c5d-ebf4-4599-bb9b-7e75e3f8b71e,DISK], DatanodeInfoWithStorage[127.0.0.1:33001,DS-07949864-3f7b-45d3-a28b-fc0809dc8c57,DISK], DatanodeInfoWithStorage[127.0.0.1:41791,DS-95b3a051-ec96-4e04-b459-aeab1d30ad3a,DISK], DatanodeInfoWithStorage[127.0.0.1:36186,DS-08d26202-4ad4-4e19-b921-f2914bbfabff,DISK], DatanodeInfoWithStorage[127.0.0.1:43179,DS-e956e997-764c-4c74-857c-04f34d160dcb,DISK], DatanodeInfoWithStorage[127.0.0.1:44038,DS-75adac23-826e-4c2e-a40f-05064e9f638c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1404074699-172.17.0.18-1596988243559:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40834,DS-a9765927-1463-4f11-ab3b-d85bdda7b38b,DISK], DatanodeInfoWithStorage[127.0.0.1:41126,DS-fc8d2b5b-4be4-444c-a633-df8c7ffbf1fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46552,DS-739c6c5d-ebf4-4599-bb9b-7e75e3f8b71e,DISK], DatanodeInfoWithStorage[127.0.0.1:33001,DS-07949864-3f7b-45d3-a28b-fc0809dc8c57,DISK], DatanodeInfoWithStorage[127.0.0.1:41791,DS-95b3a051-ec96-4e04-b459-aeab1d30ad3a,DISK], DatanodeInfoWithStorage[127.0.0.1:36186,DS-08d26202-4ad4-4e19-b921-f2914bbfabff,DISK], DatanodeInfoWithStorage[127.0.0.1:43179,DS-e956e997-764c-4c74-857c-04f34d160dcb,DISK], DatanodeInfoWithStorage[127.0.0.1:44038,DS-75adac23-826e-4c2e-a40f-05064e9f638c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-285760608-172.17.0.18-1596988260185:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42419,DS-73ad9370-a6e1-4d68-8950-0fe491e5ca28,DISK], DatanodeInfoWithStorage[127.0.0.1:34760,DS-d3bb24e8-e30d-406d-8643-6955b584b58e,DISK], DatanodeInfoWithStorage[127.0.0.1:33904,DS-919c8961-2765-4309-976b-a23097e05db5,DISK], DatanodeInfoWithStorage[127.0.0.1:39885,DS-effb537c-bf99-4f84-bd4b-2b9b0573bf93,DISK], DatanodeInfoWithStorage[127.0.0.1:37509,DS-5b7906e5-0244-4089-865b-1d057cf6a091,DISK], DatanodeInfoWithStorage[127.0.0.1:41078,DS-92e8513f-62ed-4686-97f3-81762949417a,DISK], DatanodeInfoWithStorage[127.0.0.1:33967,DS-363f8747-c437-4c8b-86ba-f0a50824a54e,DISK], DatanodeInfoWithStorage[127.0.0.1:33687,DS-c7409f52-5603-407a-9b8c-efd6e2d863f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-285760608-172.17.0.18-1596988260185:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42419,DS-73ad9370-a6e1-4d68-8950-0fe491e5ca28,DISK], DatanodeInfoWithStorage[127.0.0.1:34760,DS-d3bb24e8-e30d-406d-8643-6955b584b58e,DISK], DatanodeInfoWithStorage[127.0.0.1:33904,DS-919c8961-2765-4309-976b-a23097e05db5,DISK], DatanodeInfoWithStorage[127.0.0.1:39885,DS-effb537c-bf99-4f84-bd4b-2b9b0573bf93,DISK], DatanodeInfoWithStorage[127.0.0.1:37509,DS-5b7906e5-0244-4089-865b-1d057cf6a091,DISK], DatanodeInfoWithStorage[127.0.0.1:41078,DS-92e8513f-62ed-4686-97f3-81762949417a,DISK], DatanodeInfoWithStorage[127.0.0.1:33967,DS-363f8747-c437-4c8b-86ba-f0a50824a54e,DISK], DatanodeInfoWithStorage[127.0.0.1:33687,DS-c7409f52-5603-407a-9b8c-efd6e2d863f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1852597819-172.17.0.18-1596988276872:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37951,DS-460ba522-1d59-48d7-a73e-9e799e84f0b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36292,DS-3f560867-7431-4ab1-9088-8d5188f7084d,DISK], DatanodeInfoWithStorage[127.0.0.1:41355,DS-a58951cb-1dbb-4130-a6d3-df59387c111a,DISK], DatanodeInfoWithStorage[127.0.0.1:37492,DS-ff6d29a2-ca67-4221-b49e-c1bfdbd861fe,DISK], DatanodeInfoWithStorage[127.0.0.1:44989,DS-207e2ad2-16c8-4a01-915f-201f631494c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35769,DS-00739b09-4bae-4d7b-be57-67bc760ad468,DISK], DatanodeInfoWithStorage[127.0.0.1:44039,DS-079abdf2-1882-49f3-935b-355834d93706,DISK], DatanodeInfoWithStorage[127.0.0.1:36327,DS-272ef402-4fb8-42c3-bc91-97d7e1a89cbb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1852597819-172.17.0.18-1596988276872:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37951,DS-460ba522-1d59-48d7-a73e-9e799e84f0b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36292,DS-3f560867-7431-4ab1-9088-8d5188f7084d,DISK], DatanodeInfoWithStorage[127.0.0.1:41355,DS-a58951cb-1dbb-4130-a6d3-df59387c111a,DISK], DatanodeInfoWithStorage[127.0.0.1:37492,DS-ff6d29a2-ca67-4221-b49e-c1bfdbd861fe,DISK], DatanodeInfoWithStorage[127.0.0.1:44989,DS-207e2ad2-16c8-4a01-915f-201f631494c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35769,DS-00739b09-4bae-4d7b-be57-67bc760ad468,DISK], DatanodeInfoWithStorage[127.0.0.1:44039,DS-079abdf2-1882-49f3-935b-355834d93706,DISK], DatanodeInfoWithStorage[127.0.0.1:36327,DS-272ef402-4fb8-42c3-bc91-97d7e1a89cbb,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1716729797-172.17.0.18-1596988326614:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38787,DS-e8de17ed-5d22-4ebb-afff-52a0f589685b,DISK], DatanodeInfoWithStorage[127.0.0.1:42763,DS-d8003018-b008-42ae-b984-491ed284b712,DISK], DatanodeInfoWithStorage[127.0.0.1:44316,DS-ece5e9f0-041a-4314-a272-fd5d6743da65,DISK], DatanodeInfoWithStorage[127.0.0.1:36102,DS-4686c150-965d-4c9e-9336-d6cbce2e17cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45447,DS-b2458ee9-9fa3-4701-b1ef-0027b8ae54ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36344,DS-bb9993a1-d404-42ed-be87-32a6c4813913,DISK], DatanodeInfoWithStorage[127.0.0.1:40175,DS-769257d8-4ec3-4810-8555-a4bbf10b1452,DISK], DatanodeInfoWithStorage[127.0.0.1:46465,DS-5d18caaa-5863-4082-b789-e8407abcc261,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1716729797-172.17.0.18-1596988326614:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38787,DS-e8de17ed-5d22-4ebb-afff-52a0f589685b,DISK], DatanodeInfoWithStorage[127.0.0.1:42763,DS-d8003018-b008-42ae-b984-491ed284b712,DISK], DatanodeInfoWithStorage[127.0.0.1:44316,DS-ece5e9f0-041a-4314-a272-fd5d6743da65,DISK], DatanodeInfoWithStorage[127.0.0.1:36102,DS-4686c150-965d-4c9e-9336-d6cbce2e17cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45447,DS-b2458ee9-9fa3-4701-b1ef-0027b8ae54ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36344,DS-bb9993a1-d404-42ed-be87-32a6c4813913,DISK], DatanodeInfoWithStorage[127.0.0.1:40175,DS-769257d8-4ec3-4810-8555-a4bbf10b1452,DISK], DatanodeInfoWithStorage[127.0.0.1:46465,DS-5d18caaa-5863-4082-b789-e8407abcc261,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1388748477-172.17.0.18-1596988343259:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37881,DS-056dbbb9-69f6-4c21-a34b-20d930105125,DISK], DatanodeInfoWithStorage[127.0.0.1:38557,DS-72cc8c4f-d08b-4073-bb20-f4d778617f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:43426,DS-af17ad03-9ce9-4d6b-a679-73e637cb29ec,DISK], DatanodeInfoWithStorage[127.0.0.1:32966,DS-d02b03e3-ff88-4fda-ba74-40cd9304ce06,DISK], DatanodeInfoWithStorage[127.0.0.1:37400,DS-4b6b7e27-853d-47c9-86a7-82033fe0fa76,DISK], DatanodeInfoWithStorage[127.0.0.1:37169,DS-f2542023-c438-4570-88e9-054a2c58f521,DISK], DatanodeInfoWithStorage[127.0.0.1:34754,DS-e92f6149-7a45-493b-ab31-c98d09c53a7e,DISK], DatanodeInfoWithStorage[127.0.0.1:43522,DS-6c903ebf-eb1c-49e0-8abe-f9c6b777c815,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1388748477-172.17.0.18-1596988343259:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37881,DS-056dbbb9-69f6-4c21-a34b-20d930105125,DISK], DatanodeInfoWithStorage[127.0.0.1:38557,DS-72cc8c4f-d08b-4073-bb20-f4d778617f4b,DISK], DatanodeInfoWithStorage[127.0.0.1:43426,DS-af17ad03-9ce9-4d6b-a679-73e637cb29ec,DISK], DatanodeInfoWithStorage[127.0.0.1:32966,DS-d02b03e3-ff88-4fda-ba74-40cd9304ce06,DISK], DatanodeInfoWithStorage[127.0.0.1:37400,DS-4b6b7e27-853d-47c9-86a7-82033fe0fa76,DISK], DatanodeInfoWithStorage[127.0.0.1:37169,DS-f2542023-c438-4570-88e9-054a2c58f521,DISK], DatanodeInfoWithStorage[127.0.0.1:34754,DS-e92f6149-7a45-493b-ab31-c98d09c53a7e,DISK], DatanodeInfoWithStorage[127.0.0.1:43522,DS-6c903ebf-eb1c-49e0-8abe-f9c6b777c815,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-94006132-172.17.0.18-1596988375722:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32770,DS-cbae0d96-0f3f-41dc-bfbd-f8899d3ad681,DISK], DatanodeInfoWithStorage[127.0.0.1:40669,DS-d24b63f3-b41f-4826-acbe-628c59fdd13e,DISK], DatanodeInfoWithStorage[127.0.0.1:35221,DS-3c7b6008-1181-47b3-8f12-ee424dbc2365,DISK], DatanodeInfoWithStorage[127.0.0.1:43374,DS-0b791dc1-c8b5-48d0-88df-4778f9f90bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:46787,DS-b2e036a8-c549-4687-85c4-f30afe67653e,DISK], DatanodeInfoWithStorage[127.0.0.1:37521,DS-c0d32b1b-f1ef-4b58-82f6-d5dfe0aeac2b,DISK], DatanodeInfoWithStorage[127.0.0.1:36269,DS-107eda5d-b743-4800-af91-0a79999e3227,DISK], DatanodeInfoWithStorage[127.0.0.1:33976,DS-ce4a2e4b-5642-4939-b5c4-fc6bb49d65ea,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-94006132-172.17.0.18-1596988375722:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32770,DS-cbae0d96-0f3f-41dc-bfbd-f8899d3ad681,DISK], DatanodeInfoWithStorage[127.0.0.1:40669,DS-d24b63f3-b41f-4826-acbe-628c59fdd13e,DISK], DatanodeInfoWithStorage[127.0.0.1:35221,DS-3c7b6008-1181-47b3-8f12-ee424dbc2365,DISK], DatanodeInfoWithStorage[127.0.0.1:43374,DS-0b791dc1-c8b5-48d0-88df-4778f9f90bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:46787,DS-b2e036a8-c549-4687-85c4-f30afe67653e,DISK], DatanodeInfoWithStorage[127.0.0.1:37521,DS-c0d32b1b-f1ef-4b58-82f6-d5dfe0aeac2b,DISK], DatanodeInfoWithStorage[127.0.0.1:36269,DS-107eda5d-b743-4800-af91-0a79999e3227,DISK], DatanodeInfoWithStorage[127.0.0.1:33976,DS-ce4a2e4b-5642-4939-b5c4-fc6bb49d65ea,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1545969012-172.17.0.18-1596988408292:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41683,DS-a10f0b65-c3d2-4841-8b5a-0ca74b692a3b,DISK], DatanodeInfoWithStorage[127.0.0.1:34293,DS-8cbf6497-8033-49a7-a060-d08426d37f37,DISK], DatanodeInfoWithStorage[127.0.0.1:38266,DS-4a8c9ae4-c046-4cd0-8066-86f43433f571,DISK], DatanodeInfoWithStorage[127.0.0.1:34379,DS-31c1c49e-65d9-4b29-9725-69d55e49d2f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40366,DS-d2d130f8-9263-4e21-97ed-26551530ce92,DISK], DatanodeInfoWithStorage[127.0.0.1:36746,DS-3eb6cae7-9f25-40ca-bc2e-0ec793bf03a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39844,DS-1ebaf7b1-cb0c-4aae-8081-d711c10c2da7,DISK], DatanodeInfoWithStorage[127.0.0.1:35602,DS-70329f1a-657e-461b-820e-92fbfc2e3127,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1545969012-172.17.0.18-1596988408292:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41683,DS-a10f0b65-c3d2-4841-8b5a-0ca74b692a3b,DISK], DatanodeInfoWithStorage[127.0.0.1:34293,DS-8cbf6497-8033-49a7-a060-d08426d37f37,DISK], DatanodeInfoWithStorage[127.0.0.1:38266,DS-4a8c9ae4-c046-4cd0-8066-86f43433f571,DISK], DatanodeInfoWithStorage[127.0.0.1:34379,DS-31c1c49e-65d9-4b29-9725-69d55e49d2f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40366,DS-d2d130f8-9263-4e21-97ed-26551530ce92,DISK], DatanodeInfoWithStorage[127.0.0.1:36746,DS-3eb6cae7-9f25-40ca-bc2e-0ec793bf03a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39844,DS-1ebaf7b1-cb0c-4aae-8081-d711c10c2da7,DISK], DatanodeInfoWithStorage[127.0.0.1:35602,DS-70329f1a-657e-461b-820e-92fbfc2e3127,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1620387154-172.17.0.18-1596988424921:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33658,DS-d5502d70-4a10-458f-b117-3807e64df15b,DISK], DatanodeInfoWithStorage[127.0.0.1:44402,DS-65f6e552-0833-48b0-b82d-9f8fd8adb6e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34355,DS-fe60bbeb-319c-438f-87e4-1441130d04cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45177,DS-8bee1e06-d8e3-4fe8-ba72-59a340ec17ed,DISK], DatanodeInfoWithStorage[127.0.0.1:35259,DS-d54b08d6-b257-47ba-a762-062a25cec444,DISK], DatanodeInfoWithStorage[127.0.0.1:41381,DS-c471d43e-1c8a-4109-8615-f022bb68b112,DISK], DatanodeInfoWithStorage[127.0.0.1:46456,DS-920d21fa-dd42-440d-b515-2bc4f95efcc6,DISK], DatanodeInfoWithStorage[127.0.0.1:33330,DS-90baea11-1cb2-4d2b-aef8-abef095c9dff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1620387154-172.17.0.18-1596988424921:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33658,DS-d5502d70-4a10-458f-b117-3807e64df15b,DISK], DatanodeInfoWithStorage[127.0.0.1:44402,DS-65f6e552-0833-48b0-b82d-9f8fd8adb6e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34355,DS-fe60bbeb-319c-438f-87e4-1441130d04cf,DISK], DatanodeInfoWithStorage[127.0.0.1:45177,DS-8bee1e06-d8e3-4fe8-ba72-59a340ec17ed,DISK], DatanodeInfoWithStorage[127.0.0.1:35259,DS-d54b08d6-b257-47ba-a762-062a25cec444,DISK], DatanodeInfoWithStorage[127.0.0.1:41381,DS-c471d43e-1c8a-4109-8615-f022bb68b112,DISK], DatanodeInfoWithStorage[127.0.0.1:46456,DS-920d21fa-dd42-440d-b515-2bc4f95efcc6,DISK], DatanodeInfoWithStorage[127.0.0.1:33330,DS-90baea11-1cb2-4d2b-aef8-abef095c9dff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1182580611-172.17.0.18-1596988472301:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39734,DS-39075f70-eb39-4079-991d-153f82535ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:42852,DS-b666b6cf-fc91-46e5-a28a-1fcca2a90e83,DISK], DatanodeInfoWithStorage[127.0.0.1:42733,DS-535337c6-9bf6-45b3-bbcb-436bacfb99cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38689,DS-5d1d2172-6315-4362-9105-28a193e1ac40,DISK], DatanodeInfoWithStorage[127.0.0.1:35589,DS-710934e0-877c-4571-8523-e32def9f9c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:39783,DS-31280d8c-026b-4bdf-b80a-f4ef2ffc8b21,DISK], DatanodeInfoWithStorage[127.0.0.1:36747,DS-19981493-15e6-4a88-90c6-a6b2a240427f,DISK], DatanodeInfoWithStorage[127.0.0.1:42218,DS-a100f1a5-4896-4ddb-bb4f-b54dd7d444d1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1182580611-172.17.0.18-1596988472301:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39734,DS-39075f70-eb39-4079-991d-153f82535ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:42852,DS-b666b6cf-fc91-46e5-a28a-1fcca2a90e83,DISK], DatanodeInfoWithStorage[127.0.0.1:42733,DS-535337c6-9bf6-45b3-bbcb-436bacfb99cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38689,DS-5d1d2172-6315-4362-9105-28a193e1ac40,DISK], DatanodeInfoWithStorage[127.0.0.1:35589,DS-710934e0-877c-4571-8523-e32def9f9c5e,DISK], DatanodeInfoWithStorage[127.0.0.1:39783,DS-31280d8c-026b-4bdf-b80a-f4ef2ffc8b21,DISK], DatanodeInfoWithStorage[127.0.0.1:36747,DS-19981493-15e6-4a88-90c6-a6b2a240427f,DISK], DatanodeInfoWithStorage[127.0.0.1:42218,DS-a100f1a5-4896-4ddb-bb4f-b54dd7d444d1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1571115260-172.17.0.18-1596988602436:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33804,DS-8c5bf5f7-c6cc-4797-a0f1-9a0a70dfafb5,DISK], DatanodeInfoWithStorage[127.0.0.1:40055,DS-3be94631-9f73-4ce1-a4b3-c89423708d8e,DISK], DatanodeInfoWithStorage[127.0.0.1:37937,DS-f0b3d390-9f12-49d5-87cc-588f0da3fe2d,DISK], DatanodeInfoWithStorage[127.0.0.1:46818,DS-b9e61da8-745a-4bdc-ae22-25a869298324,DISK], DatanodeInfoWithStorage[127.0.0.1:46081,DS-50172b6e-5e20-4177-a9f3-23fe9e6222e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39704,DS-c894ce59-d280-4478-8f35-90b777ace0a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39143,DS-7bd5eece-7aaf-431a-afe4-2d62aa9b3ce5,DISK], DatanodeInfoWithStorage[127.0.0.1:45422,DS-1023a8d6-01eb-4b5f-a48e-06f0a18cb853,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1571115260-172.17.0.18-1596988602436:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33804,DS-8c5bf5f7-c6cc-4797-a0f1-9a0a70dfafb5,DISK], DatanodeInfoWithStorage[127.0.0.1:40055,DS-3be94631-9f73-4ce1-a4b3-c89423708d8e,DISK], DatanodeInfoWithStorage[127.0.0.1:37937,DS-f0b3d390-9f12-49d5-87cc-588f0da3fe2d,DISK], DatanodeInfoWithStorage[127.0.0.1:46818,DS-b9e61da8-745a-4bdc-ae22-25a869298324,DISK], DatanodeInfoWithStorage[127.0.0.1:46081,DS-50172b6e-5e20-4177-a9f3-23fe9e6222e4,DISK], DatanodeInfoWithStorage[127.0.0.1:39704,DS-c894ce59-d280-4478-8f35-90b777ace0a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39143,DS-7bd5eece-7aaf-431a-afe4-2d62aa9b3ce5,DISK], DatanodeInfoWithStorage[127.0.0.1:45422,DS-1023a8d6-01eb-4b5f-a48e-06f0a18cb853,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2080145694-172.17.0.18-1596988667758:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33071,DS-27177867-5471-4e4f-b5f7-e13e31334040,DISK], DatanodeInfoWithStorage[127.0.0.1:34484,DS-fa04526e-d5f8-4e7c-b4a5-a257db4e563d,DISK], DatanodeInfoWithStorage[127.0.0.1:40656,DS-d82588b5-7274-4506-90b3-1a941fb181f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45002,DS-53bd005d-90ee-4773-baee-1deb063cafa6,DISK], DatanodeInfoWithStorage[127.0.0.1:39151,DS-cc849d29-81dc-4e8f-9626-763fbe26cc18,DISK], DatanodeInfoWithStorage[127.0.0.1:45545,DS-fd3083ac-29ca-454c-8c77-7725b39f17a3,DISK], DatanodeInfoWithStorage[127.0.0.1:46607,DS-1028ef25-6fb4-404b-8535-4d6fc7c68bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:36849,DS-3387191c-783a-4d1c-ae20-ff36095b1d3e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2080145694-172.17.0.18-1596988667758:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33071,DS-27177867-5471-4e4f-b5f7-e13e31334040,DISK], DatanodeInfoWithStorage[127.0.0.1:34484,DS-fa04526e-d5f8-4e7c-b4a5-a257db4e563d,DISK], DatanodeInfoWithStorage[127.0.0.1:40656,DS-d82588b5-7274-4506-90b3-1a941fb181f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45002,DS-53bd005d-90ee-4773-baee-1deb063cafa6,DISK], DatanodeInfoWithStorage[127.0.0.1:39151,DS-cc849d29-81dc-4e8f-9626-763fbe26cc18,DISK], DatanodeInfoWithStorage[127.0.0.1:45545,DS-fd3083ac-29ca-454c-8c77-7725b39f17a3,DISK], DatanodeInfoWithStorage[127.0.0.1:46607,DS-1028ef25-6fb4-404b-8535-4d6fc7c68bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:36849,DS-3387191c-783a-4d1c-ae20-ff36095b1d3e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1668044278-172.17.0.18-1596988766187:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42547,DS-3d7f8d12-c899-4a2a-93dc-2b480775abf9,DISK], DatanodeInfoWithStorage[127.0.0.1:36436,DS-5b593e7f-c53f-4549-b4e6-78432ce9a6b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35603,DS-316df8bd-aedc-4b7f-bb5d-b5a2b6045bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:33413,DS-824c52c7-dcb9-4ba6-a15a-1e06e8f21d8b,DISK], DatanodeInfoWithStorage[127.0.0.1:37321,DS-f6e976d6-b360-421d-b681-21b46773e7c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44705,DS-b9e7df12-aadb-4463-b7d7-3ed6e4e2d575,DISK], DatanodeInfoWithStorage[127.0.0.1:33416,DS-558a41c6-7f86-47ef-a82b-a449c9f9bcc8,DISK], DatanodeInfoWithStorage[127.0.0.1:44833,DS-bffe277e-512a-4ba5-a2f5-ea539fdab686,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1668044278-172.17.0.18-1596988766187:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42547,DS-3d7f8d12-c899-4a2a-93dc-2b480775abf9,DISK], DatanodeInfoWithStorage[127.0.0.1:36436,DS-5b593e7f-c53f-4549-b4e6-78432ce9a6b5,DISK], DatanodeInfoWithStorage[127.0.0.1:35603,DS-316df8bd-aedc-4b7f-bb5d-b5a2b6045bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:33413,DS-824c52c7-dcb9-4ba6-a15a-1e06e8f21d8b,DISK], DatanodeInfoWithStorage[127.0.0.1:37321,DS-f6e976d6-b360-421d-b681-21b46773e7c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44705,DS-b9e7df12-aadb-4463-b7d7-3ed6e4e2d575,DISK], DatanodeInfoWithStorage[127.0.0.1:33416,DS-558a41c6-7f86-47ef-a82b-a449c9f9bcc8,DISK], DatanodeInfoWithStorage[127.0.0.1:44833,DS-bffe277e-512a-4ba5-a2f5-ea539fdab686,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1216193490-172.17.0.18-1596988782127:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36277,DS-5811a4c6-90b2-423a-8f12-c2cdbec8a97b,DISK], DatanodeInfoWithStorage[127.0.0.1:43634,DS-a6ed0ead-0ab0-4820-8c7f-c8abf577fb4b,DISK], DatanodeInfoWithStorage[127.0.0.1:46186,DS-50cf822b-568b-419d-b658-b0e712c5547d,DISK], DatanodeInfoWithStorage[127.0.0.1:41721,DS-14c86c9f-7ea2-4d9c-b69f-8a64a0faa0f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41499,DS-98cbf5b2-85c5-4a57-ada9-62d426afade0,DISK], DatanodeInfoWithStorage[127.0.0.1:41607,DS-39cc4029-f330-4a28-99bd-9ca688c2601a,DISK], DatanodeInfoWithStorage[127.0.0.1:43913,DS-f4eb7014-33bc-405c-b574-6d6e7d502be0,DISK], DatanodeInfoWithStorage[127.0.0.1:46416,DS-c827d67b-513c-4c92-81bc-27e5990a337d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1216193490-172.17.0.18-1596988782127:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36277,DS-5811a4c6-90b2-423a-8f12-c2cdbec8a97b,DISK], DatanodeInfoWithStorage[127.0.0.1:43634,DS-a6ed0ead-0ab0-4820-8c7f-c8abf577fb4b,DISK], DatanodeInfoWithStorage[127.0.0.1:46186,DS-50cf822b-568b-419d-b658-b0e712c5547d,DISK], DatanodeInfoWithStorage[127.0.0.1:41721,DS-14c86c9f-7ea2-4d9c-b69f-8a64a0faa0f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41499,DS-98cbf5b2-85c5-4a57-ada9-62d426afade0,DISK], DatanodeInfoWithStorage[127.0.0.1:41607,DS-39cc4029-f330-4a28-99bd-9ca688c2601a,DISK], DatanodeInfoWithStorage[127.0.0.1:43913,DS-f4eb7014-33bc-405c-b574-6d6e7d502be0,DISK], DatanodeInfoWithStorage[127.0.0.1:46416,DS-c827d67b-513c-4c92-81bc-27e5990a337d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1712502145-172.17.0.18-1596988814262:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38995,DS-93be4a02-d4a8-4885-82ca-13f65a760426,DISK], DatanodeInfoWithStorage[127.0.0.1:35201,DS-3f40fe52-c0df-4ad7-b7e0-0dcac9801ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:38595,DS-eaca41ac-fc36-4214-a640-b8255101f8be,DISK], DatanodeInfoWithStorage[127.0.0.1:46669,DS-ba83ed48-142e-4fea-9a04-009d63c8c2c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36492,DS-1e6ae51f-ab2e-49c7-8fb9-0a93012be0a4,DISK], DatanodeInfoWithStorage[127.0.0.1:32784,DS-02296c3d-bb33-4849-b58e-6154a84da44e,DISK], DatanodeInfoWithStorage[127.0.0.1:41243,DS-f72867e9-84f8-4b63-ba06-1dc13384ffe3,DISK], DatanodeInfoWithStorage[127.0.0.1:35057,DS-17f6bc60-ffdb-4b5a-9f21-40b7ba0d794c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1712502145-172.17.0.18-1596988814262:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38995,DS-93be4a02-d4a8-4885-82ca-13f65a760426,DISK], DatanodeInfoWithStorage[127.0.0.1:35201,DS-3f40fe52-c0df-4ad7-b7e0-0dcac9801ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:38595,DS-eaca41ac-fc36-4214-a640-b8255101f8be,DISK], DatanodeInfoWithStorage[127.0.0.1:46669,DS-ba83ed48-142e-4fea-9a04-009d63c8c2c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36492,DS-1e6ae51f-ab2e-49c7-8fb9-0a93012be0a4,DISK], DatanodeInfoWithStorage[127.0.0.1:32784,DS-02296c3d-bb33-4849-b58e-6154a84da44e,DISK], DatanodeInfoWithStorage[127.0.0.1:41243,DS-f72867e9-84f8-4b63-ba06-1dc13384ffe3,DISK], DatanodeInfoWithStorage[127.0.0.1:35057,DS-17f6bc60-ffdb-4b5a-9f21-40b7ba0d794c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-997509705-172.17.0.18-1596988879862:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44187,DS-cfedc7c7-7226-401a-9b33-eada62d36a93,DISK], DatanodeInfoWithStorage[127.0.0.1:41087,DS-c24a368b-22bb-4e3d-907f-3fb324198f3d,DISK], DatanodeInfoWithStorage[127.0.0.1:34063,DS-9a629d8c-e000-4641-b7cc-7c6912bbed96,DISK], DatanodeInfoWithStorage[127.0.0.1:42876,DS-93d7abb3-e145-4bcf-b8b0-e90df6345a47,DISK], DatanodeInfoWithStorage[127.0.0.1:37092,DS-c07d885a-acce-42e8-9d87-4a58898c3f40,DISK], DatanodeInfoWithStorage[127.0.0.1:37409,DS-d562777a-d38e-4f65-aa8f-e66caf04224e,DISK], DatanodeInfoWithStorage[127.0.0.1:34962,DS-36914b89-068d-4746-ae54-710ed6b9e9e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44604,DS-ed42e938-cd9e-4f74-b8bb-d4b4d9186e4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-997509705-172.17.0.18-1596988879862:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44187,DS-cfedc7c7-7226-401a-9b33-eada62d36a93,DISK], DatanodeInfoWithStorage[127.0.0.1:41087,DS-c24a368b-22bb-4e3d-907f-3fb324198f3d,DISK], DatanodeInfoWithStorage[127.0.0.1:34063,DS-9a629d8c-e000-4641-b7cc-7c6912bbed96,DISK], DatanodeInfoWithStorage[127.0.0.1:42876,DS-93d7abb3-e145-4bcf-b8b0-e90df6345a47,DISK], DatanodeInfoWithStorage[127.0.0.1:37092,DS-c07d885a-acce-42e8-9d87-4a58898c3f40,DISK], DatanodeInfoWithStorage[127.0.0.1:37409,DS-d562777a-d38e-4f65-aa8f-e66caf04224e,DISK], DatanodeInfoWithStorage[127.0.0.1:34962,DS-36914b89-068d-4746-ae54-710ed6b9e9e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44604,DS-ed42e938-cd9e-4f74-b8bb-d4b4d9186e4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1283400632-172.17.0.18-1596988945988:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46189,DS-bca99a18-a3f2-4c37-b7ec-54ed879fbd93,DISK], DatanodeInfoWithStorage[127.0.0.1:36147,DS-40a84c04-bb9a-4d24-bbf0-83b32e5827f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36046,DS-ec1931c0-4ffe-4c06-ad38-eefedb8ce264,DISK], DatanodeInfoWithStorage[127.0.0.1:41008,DS-5a98e480-0e12-4698-bb7c-2c1dec0a73b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36225,DS-6f1cdef1-f547-4eff-b4dc-d60564d93ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:46211,DS-d78ac66a-2c6c-4005-a72a-6b35215e8300,DISK], DatanodeInfoWithStorage[127.0.0.1:41573,DS-2cf15371-d370-4f86-835b-15b6feecf6cd,DISK], DatanodeInfoWithStorage[127.0.0.1:36259,DS-54f1c1eb-1082-4bb3-89bf-d6ead8b89ff9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1283400632-172.17.0.18-1596988945988:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46189,DS-bca99a18-a3f2-4c37-b7ec-54ed879fbd93,DISK], DatanodeInfoWithStorage[127.0.0.1:36147,DS-40a84c04-bb9a-4d24-bbf0-83b32e5827f7,DISK], DatanodeInfoWithStorage[127.0.0.1:36046,DS-ec1931c0-4ffe-4c06-ad38-eefedb8ce264,DISK], DatanodeInfoWithStorage[127.0.0.1:41008,DS-5a98e480-0e12-4698-bb7c-2c1dec0a73b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36225,DS-6f1cdef1-f547-4eff-b4dc-d60564d93ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:46211,DS-d78ac66a-2c6c-4005-a72a-6b35215e8300,DISK], DatanodeInfoWithStorage[127.0.0.1:41573,DS-2cf15371-d370-4f86-835b-15b6feecf6cd,DISK], DatanodeInfoWithStorage[127.0.0.1:36259,DS-54f1c1eb-1082-4bb3-89bf-d6ead8b89ff9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-270793990-172.17.0.18-1596989012536:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42938,DS-67b9b69d-5fda-4dfa-90d4-1d7d2c2cafd2,DISK], DatanodeInfoWithStorage[127.0.0.1:42620,DS-9eca3fad-8062-4c3a-a4ce-8e9ef2592688,DISK], DatanodeInfoWithStorage[127.0.0.1:39932,DS-3e39985e-42e5-439b-a91f-c98f923f049d,DISK], DatanodeInfoWithStorage[127.0.0.1:39031,DS-79617b2c-1214-4829-9ced-9c97936457a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43014,DS-5357d4ca-7199-4e7f-a983-f2c2d608ebce,DISK], DatanodeInfoWithStorage[127.0.0.1:44863,DS-cfa08677-28e0-46f2-bb8d-a107bb91a987,DISK], DatanodeInfoWithStorage[127.0.0.1:41756,DS-2bc4101b-8764-42d4-bad1-8ba45341aebb,DISK], DatanodeInfoWithStorage[127.0.0.1:34225,DS-4e206a86-be82-4424-a2a8-b5100931d64a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-270793990-172.17.0.18-1596989012536:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42938,DS-67b9b69d-5fda-4dfa-90d4-1d7d2c2cafd2,DISK], DatanodeInfoWithStorage[127.0.0.1:42620,DS-9eca3fad-8062-4c3a-a4ce-8e9ef2592688,DISK], DatanodeInfoWithStorage[127.0.0.1:39932,DS-3e39985e-42e5-439b-a91f-c98f923f049d,DISK], DatanodeInfoWithStorage[127.0.0.1:39031,DS-79617b2c-1214-4829-9ced-9c97936457a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43014,DS-5357d4ca-7199-4e7f-a983-f2c2d608ebce,DISK], DatanodeInfoWithStorage[127.0.0.1:44863,DS-cfa08677-28e0-46f2-bb8d-a107bb91a987,DISK], DatanodeInfoWithStorage[127.0.0.1:41756,DS-2bc4101b-8764-42d4-bad1-8ba45341aebb,DISK], DatanodeInfoWithStorage[127.0.0.1:34225,DS-4e206a86-be82-4424-a2a8-b5100931d64a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-399067832-172.17.0.18-1596989045470:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34766,DS-5f83c718-12c9-40e7-a59e-6b477dc3a4cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46377,DS-6383ed11-eb4f-4b14-b0aa-96b9cd7b1a47,DISK], DatanodeInfoWithStorage[127.0.0.1:45816,DS-59d79cc4-0441-4fb3-a9f5-624c13b829de,DISK], DatanodeInfoWithStorage[127.0.0.1:33915,DS-e4e26f6b-9177-44e9-bb59-4bb8875f590e,DISK], DatanodeInfoWithStorage[127.0.0.1:43948,DS-bdf62a44-bb20-4419-b3c6-2eb003e71ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:35869,DS-c7e16490-45d4-4c0c-9232-5bd03814f6ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45914,DS-73493543-c426-4f7c-a217-140bcf24399e,DISK], DatanodeInfoWithStorage[127.0.0.1:39092,DS-d3b7e6d0-3138-4be9-ad25-25c79a3f9902,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-399067832-172.17.0.18-1596989045470:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34766,DS-5f83c718-12c9-40e7-a59e-6b477dc3a4cd,DISK], DatanodeInfoWithStorage[127.0.0.1:46377,DS-6383ed11-eb4f-4b14-b0aa-96b9cd7b1a47,DISK], DatanodeInfoWithStorage[127.0.0.1:45816,DS-59d79cc4-0441-4fb3-a9f5-624c13b829de,DISK], DatanodeInfoWithStorage[127.0.0.1:33915,DS-e4e26f6b-9177-44e9-bb59-4bb8875f590e,DISK], DatanodeInfoWithStorage[127.0.0.1:43948,DS-bdf62a44-bb20-4419-b3c6-2eb003e71ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:35869,DS-c7e16490-45d4-4c0c-9232-5bd03814f6ae,DISK], DatanodeInfoWithStorage[127.0.0.1:45914,DS-73493543-c426-4f7c-a217-140bcf24399e,DISK], DatanodeInfoWithStorage[127.0.0.1:39092,DS-d3b7e6d0-3138-4be9-ad25-25c79a3f9902,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1412056771-172.17.0.18-1596989078164:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41785,DS-8ccf10e7-1cdf-47bd-9677-12d0be53111e,DISK], DatanodeInfoWithStorage[127.0.0.1:32841,DS-6dec3ce9-9d20-4611-ad9b-2a66a219b16a,DISK], DatanodeInfoWithStorage[127.0.0.1:38209,DS-94fb36f7-d572-4fb3-9dcd-2bfb9f17bb44,DISK], DatanodeInfoWithStorage[127.0.0.1:38685,DS-75e94a37-73a6-4918-bba7-87bab7f17885,DISK], DatanodeInfoWithStorage[127.0.0.1:37742,DS-66cf15fb-5050-4e57-837f-9a5d2812ecb3,DISK], DatanodeInfoWithStorage[127.0.0.1:38844,DS-90f53ad0-a4c6-492f-aa18-ba97eb98bd50,DISK], DatanodeInfoWithStorage[127.0.0.1:41867,DS-51c4e809-2bec-48e2-af27-4d0388d0fcb5,DISK], DatanodeInfoWithStorage[127.0.0.1:43571,DS-8d705425-bbc4-46c3-ab38-2e88d842a5ff,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1412056771-172.17.0.18-1596989078164:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41785,DS-8ccf10e7-1cdf-47bd-9677-12d0be53111e,DISK], DatanodeInfoWithStorage[127.0.0.1:32841,DS-6dec3ce9-9d20-4611-ad9b-2a66a219b16a,DISK], DatanodeInfoWithStorage[127.0.0.1:38209,DS-94fb36f7-d572-4fb3-9dcd-2bfb9f17bb44,DISK], DatanodeInfoWithStorage[127.0.0.1:38685,DS-75e94a37-73a6-4918-bba7-87bab7f17885,DISK], DatanodeInfoWithStorage[127.0.0.1:37742,DS-66cf15fb-5050-4e57-837f-9a5d2812ecb3,DISK], DatanodeInfoWithStorage[127.0.0.1:38844,DS-90f53ad0-a4c6-492f-aa18-ba97eb98bd50,DISK], DatanodeInfoWithStorage[127.0.0.1:41867,DS-51c4e809-2bec-48e2-af27-4d0388d0fcb5,DISK], DatanodeInfoWithStorage[127.0.0.1:43571,DS-8d705425-bbc4-46c3-ab38-2e88d842a5ff,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 29 out of 50
result: false positive !!!
Total execution time in seconds : 3334
