reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-985552397-172.17.0.4-1596899048592:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36453,DS-18e77dc6-94e2-4773-89c9-10c2e369de77,DISK], DatanodeInfoWithStorage[127.0.0.1:39903,DS-9af95d62-ba1e-480e-b664-a04ab69f8258,DISK], DatanodeInfoWithStorage[127.0.0.1:34066,DS-364b5336-0efc-4557-8c12-3bb5323cb913,DISK], DatanodeInfoWithStorage[127.0.0.1:39642,DS-fb61885b-8176-48eb-9965-a351f9beec49,DISK], DatanodeInfoWithStorage[127.0.0.1:43410,DS-f4efd0d7-25bd-4db6-94a8-4812b5f6fc80,DISK], DatanodeInfoWithStorage[127.0.0.1:36138,DS-47eb1dbd-608f-48ea-9d0f-6364beb32f92,DISK], DatanodeInfoWithStorage[127.0.0.1:36065,DS-18689b0e-d6af-4b18-a4f6-8d8b3d7e59ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44752,DS-1e16bbe6-af09-4c9e-9b5e-f235c9935ea4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-985552397-172.17.0.4-1596899048592:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36453,DS-18e77dc6-94e2-4773-89c9-10c2e369de77,DISK], DatanodeInfoWithStorage[127.0.0.1:39903,DS-9af95d62-ba1e-480e-b664-a04ab69f8258,DISK], DatanodeInfoWithStorage[127.0.0.1:34066,DS-364b5336-0efc-4557-8c12-3bb5323cb913,DISK], DatanodeInfoWithStorage[127.0.0.1:39642,DS-fb61885b-8176-48eb-9965-a351f9beec49,DISK], DatanodeInfoWithStorage[127.0.0.1:43410,DS-f4efd0d7-25bd-4db6-94a8-4812b5f6fc80,DISK], DatanodeInfoWithStorage[127.0.0.1:36138,DS-47eb1dbd-608f-48ea-9d0f-6364beb32f92,DISK], DatanodeInfoWithStorage[127.0.0.1:36065,DS-18689b0e-d6af-4b18-a4f6-8d8b3d7e59ea,DISK], DatanodeInfoWithStorage[127.0.0.1:44752,DS-1e16bbe6-af09-4c9e-9b5e-f235c9935ea4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-541643714-172.17.0.4-1596899284694:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39962,DS-797c3837-25e8-4ad7-a061-98d3ef7b012f,DISK], DatanodeInfoWithStorage[127.0.0.1:38683,DS-0a02a59a-27c0-4e49-b606-8063acb74eac,DISK], DatanodeInfoWithStorage[127.0.0.1:45824,DS-b55dd7a3-6c71-4c71-8ff8-8d3c96e21e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:34542,DS-7fe74975-de59-41bf-91b0-2b12c5b5350d,DISK], DatanodeInfoWithStorage[127.0.0.1:34547,DS-caf4c119-813d-47a1-b4b9-3974db849480,DISK], DatanodeInfoWithStorage[127.0.0.1:37706,DS-91dfd113-c643-4eab-a17d-62661d320506,DISK], DatanodeInfoWithStorage[127.0.0.1:46753,DS-e0b8b2f7-b75d-492d-a42d-e15dcc6a6562,DISK], DatanodeInfoWithStorage[127.0.0.1:34546,DS-5342f632-0e96-4b70-9ba9-d997090b2b40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-541643714-172.17.0.4-1596899284694:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39962,DS-797c3837-25e8-4ad7-a061-98d3ef7b012f,DISK], DatanodeInfoWithStorage[127.0.0.1:38683,DS-0a02a59a-27c0-4e49-b606-8063acb74eac,DISK], DatanodeInfoWithStorage[127.0.0.1:45824,DS-b55dd7a3-6c71-4c71-8ff8-8d3c96e21e1a,DISK], DatanodeInfoWithStorage[127.0.0.1:34542,DS-7fe74975-de59-41bf-91b0-2b12c5b5350d,DISK], DatanodeInfoWithStorage[127.0.0.1:34547,DS-caf4c119-813d-47a1-b4b9-3974db849480,DISK], DatanodeInfoWithStorage[127.0.0.1:37706,DS-91dfd113-c643-4eab-a17d-62661d320506,DISK], DatanodeInfoWithStorage[127.0.0.1:46753,DS-e0b8b2f7-b75d-492d-a42d-e15dcc6a6562,DISK], DatanodeInfoWithStorage[127.0.0.1:34546,DS-5342f632-0e96-4b70-9ba9-d997090b2b40,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-316030747-172.17.0.4-1596899720325:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46638,DS-5c7ad9b0-248b-454e-8376-93b0c6f6dfed,DISK], DatanodeInfoWithStorage[127.0.0.1:41325,DS-df9b22fd-1099-474f-828a-06f59f18a59e,DISK], DatanodeInfoWithStorage[127.0.0.1:42401,DS-8f78a1c3-5bb8-4222-a58a-3d3add59451f,DISK], DatanodeInfoWithStorage[127.0.0.1:45249,DS-94a8e8b5-ba96-473c-bd19-7fdcee531b35,DISK], DatanodeInfoWithStorage[127.0.0.1:46782,DS-55fee58b-0e13-4eb6-8574-eaa8181ab1ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33174,DS-bceb54c4-f7c3-4d4e-a4c7-0f6134db7c83,DISK], DatanodeInfoWithStorage[127.0.0.1:40272,DS-52fefc49-7daa-4483-a832-1a74ff68b58c,DISK], DatanodeInfoWithStorage[127.0.0.1:39528,DS-bfb3391c-0610-4bf9-ab7d-dec8c81c11ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-316030747-172.17.0.4-1596899720325:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46638,DS-5c7ad9b0-248b-454e-8376-93b0c6f6dfed,DISK], DatanodeInfoWithStorage[127.0.0.1:41325,DS-df9b22fd-1099-474f-828a-06f59f18a59e,DISK], DatanodeInfoWithStorage[127.0.0.1:42401,DS-8f78a1c3-5bb8-4222-a58a-3d3add59451f,DISK], DatanodeInfoWithStorage[127.0.0.1:45249,DS-94a8e8b5-ba96-473c-bd19-7fdcee531b35,DISK], DatanodeInfoWithStorage[127.0.0.1:46782,DS-55fee58b-0e13-4eb6-8574-eaa8181ab1ce,DISK], DatanodeInfoWithStorage[127.0.0.1:33174,DS-bceb54c4-f7c3-4d4e-a4c7-0f6134db7c83,DISK], DatanodeInfoWithStorage[127.0.0.1:40272,DS-52fefc49-7daa-4483-a832-1a74ff68b58c,DISK], DatanodeInfoWithStorage[127.0.0.1:39528,DS-bfb3391c-0610-4bf9-ab7d-dec8c81c11ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-983646604-172.17.0.4-1596900043717:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43729,DS-0414d751-b374-4de0-9f89-ce5106ba0b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:42643,DS-8f6291d1-77d2-42ba-8e17-97db8bb95f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:35193,DS-b7e5d16b-bbbf-4126-8944-ef3a5c9275ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34764,DS-6c0a6b2c-c643-40c3-8d01-d0d21e48b497,DISK], DatanodeInfoWithStorage[127.0.0.1:43391,DS-f6fd2460-91eb-467f-ba01-02b2a622f1dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33807,DS-546648d4-af52-4d72-b5f8-6f58fb482fc4,DISK], DatanodeInfoWithStorage[127.0.0.1:36126,DS-8b207d8d-ce80-4735-bd13-8e0b31917ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:35927,DS-f5cc021a-ab63-4611-ab95-06ddb796b820,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-983646604-172.17.0.4-1596900043717:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43729,DS-0414d751-b374-4de0-9f89-ce5106ba0b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:42643,DS-8f6291d1-77d2-42ba-8e17-97db8bb95f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:35193,DS-b7e5d16b-bbbf-4126-8944-ef3a5c9275ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34764,DS-6c0a6b2c-c643-40c3-8d01-d0d21e48b497,DISK], DatanodeInfoWithStorage[127.0.0.1:43391,DS-f6fd2460-91eb-467f-ba01-02b2a622f1dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33807,DS-546648d4-af52-4d72-b5f8-6f58fb482fc4,DISK], DatanodeInfoWithStorage[127.0.0.1:36126,DS-8b207d8d-ce80-4735-bd13-8e0b31917ecc,DISK], DatanodeInfoWithStorage[127.0.0.1:35927,DS-f5cc021a-ab63-4611-ab95-06ddb796b820,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1533301198-172.17.0.4-1596900941795:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33037,DS-8c9e7b23-98c0-4e2b-97d3-e1f617e43b6c,DISK], DatanodeInfoWithStorage[127.0.0.1:46660,DS-641c2950-f151-46b2-b8a9-bfa4d2501e01,DISK], DatanodeInfoWithStorage[127.0.0.1:35467,DS-0d70dcfa-460a-4d26-baf0-a5129e7b9aee,DISK], DatanodeInfoWithStorage[127.0.0.1:40942,DS-633cd228-25b5-4ad4-a001-97a34b9688b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37441,DS-15f5952c-db24-4e80-81a4-08bdded48bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:35946,DS-69a05b1d-50db-4960-b1e7-942869225de3,DISK], DatanodeInfoWithStorage[127.0.0.1:43019,DS-9cfcc62b-7a62-4249-abfc-6b7404300f32,DISK], DatanodeInfoWithStorage[127.0.0.1:43384,DS-05012c56-e51a-4706-afbe-a0282cb91028,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1533301198-172.17.0.4-1596900941795:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33037,DS-8c9e7b23-98c0-4e2b-97d3-e1f617e43b6c,DISK], DatanodeInfoWithStorage[127.0.0.1:46660,DS-641c2950-f151-46b2-b8a9-bfa4d2501e01,DISK], DatanodeInfoWithStorage[127.0.0.1:35467,DS-0d70dcfa-460a-4d26-baf0-a5129e7b9aee,DISK], DatanodeInfoWithStorage[127.0.0.1:40942,DS-633cd228-25b5-4ad4-a001-97a34b9688b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37441,DS-15f5952c-db24-4e80-81a4-08bdded48bb5,DISK], DatanodeInfoWithStorage[127.0.0.1:35946,DS-69a05b1d-50db-4960-b1e7-942869225de3,DISK], DatanodeInfoWithStorage[127.0.0.1:43019,DS-9cfcc62b-7a62-4249-abfc-6b7404300f32,DISK], DatanodeInfoWithStorage[127.0.0.1:43384,DS-05012c56-e51a-4706-afbe-a0282cb91028,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1278264726-172.17.0.4-1596901127373:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32917,DS-5e9d0250-fd40-43bd-9850-6435f7d9dd4a,DISK], DatanodeInfoWithStorage[127.0.0.1:46092,DS-f2337910-92f4-4ab2-804b-40822ed12a05,DISK], DatanodeInfoWithStorage[127.0.0.1:36627,DS-d63f6bc0-5fd5-409f-8dc0-6b2dfd41120d,DISK], DatanodeInfoWithStorage[127.0.0.1:33625,DS-30323c1b-e9f8-4c04-8fe6-7648c1725a6b,DISK], DatanodeInfoWithStorage[127.0.0.1:39094,DS-de6d5b1c-a31a-481a-b85e-6c2e3e7a2579,DISK], DatanodeInfoWithStorage[127.0.0.1:45539,DS-9b20baeb-35e1-4b26-bece-07d446aeaccc,DISK], DatanodeInfoWithStorage[127.0.0.1:36640,DS-73bd863a-7f59-46a5-b622-2dad8b261b8c,DISK], DatanodeInfoWithStorage[127.0.0.1:38469,DS-5737cab2-5dba-420e-a24e-a638c4d76b31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1278264726-172.17.0.4-1596901127373:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32917,DS-5e9d0250-fd40-43bd-9850-6435f7d9dd4a,DISK], DatanodeInfoWithStorage[127.0.0.1:46092,DS-f2337910-92f4-4ab2-804b-40822ed12a05,DISK], DatanodeInfoWithStorage[127.0.0.1:36627,DS-d63f6bc0-5fd5-409f-8dc0-6b2dfd41120d,DISK], DatanodeInfoWithStorage[127.0.0.1:33625,DS-30323c1b-e9f8-4c04-8fe6-7648c1725a6b,DISK], DatanodeInfoWithStorage[127.0.0.1:39094,DS-de6d5b1c-a31a-481a-b85e-6c2e3e7a2579,DISK], DatanodeInfoWithStorage[127.0.0.1:45539,DS-9b20baeb-35e1-4b26-bece-07d446aeaccc,DISK], DatanodeInfoWithStorage[127.0.0.1:36640,DS-73bd863a-7f59-46a5-b622-2dad8b261b8c,DISK], DatanodeInfoWithStorage[127.0.0.1:38469,DS-5737cab2-5dba-420e-a24e-a638c4d76b31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-141427390-172.17.0.4-1596901485734:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38401,DS-4668eba7-c5a6-4c8a-a988-9dd8ff6a1d9b,DISK], DatanodeInfoWithStorage[127.0.0.1:36790,DS-dc15b17e-fbab-4f8a-bd89-54fc432c7ba3,DISK], DatanodeInfoWithStorage[127.0.0.1:45245,DS-543b8566-b699-4aa8-940c-e502a370368a,DISK], DatanodeInfoWithStorage[127.0.0.1:38100,DS-6ea551f7-7af5-48ea-883a-c9a024160841,DISK], DatanodeInfoWithStorage[127.0.0.1:33673,DS-3a0f3efd-5958-4717-b4b3-3cb237cc92db,DISK], DatanodeInfoWithStorage[127.0.0.1:45095,DS-37af7a40-e77c-47ca-b897-67f023ef160c,DISK], DatanodeInfoWithStorage[127.0.0.1:33936,DS-68cc79c2-4bc5-4a28-9136-cf59e0f15d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:36956,DS-7a62b93b-ba53-4702-8b3d-3db9017ad499,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-141427390-172.17.0.4-1596901485734:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38401,DS-4668eba7-c5a6-4c8a-a988-9dd8ff6a1d9b,DISK], DatanodeInfoWithStorage[127.0.0.1:36790,DS-dc15b17e-fbab-4f8a-bd89-54fc432c7ba3,DISK], DatanodeInfoWithStorage[127.0.0.1:45245,DS-543b8566-b699-4aa8-940c-e502a370368a,DISK], DatanodeInfoWithStorage[127.0.0.1:38100,DS-6ea551f7-7af5-48ea-883a-c9a024160841,DISK], DatanodeInfoWithStorage[127.0.0.1:33673,DS-3a0f3efd-5958-4717-b4b3-3cb237cc92db,DISK], DatanodeInfoWithStorage[127.0.0.1:45095,DS-37af7a40-e77c-47ca-b897-67f023ef160c,DISK], DatanodeInfoWithStorage[127.0.0.1:33936,DS-68cc79c2-4bc5-4a28-9136-cf59e0f15d6c,DISK], DatanodeInfoWithStorage[127.0.0.1:36956,DS-7a62b93b-ba53-4702-8b3d-3db9017ad499,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-154267586-172.17.0.4-1596901592912:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38248,DS-79843794-22ec-431d-8767-e390f51511d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45220,DS-826535c3-9b72-4d2c-b337-ae32f06641f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37088,DS-8b7093d0-784d-40a4-b600-2224fa7d5575,DISK], DatanodeInfoWithStorage[127.0.0.1:42786,DS-27f2ff34-b2fd-4f81-a5c2-0f6a313996c8,DISK], DatanodeInfoWithStorage[127.0.0.1:37246,DS-ce13e894-8f6b-4587-bde5-fe76b9cd31a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34191,DS-6865a77b-6dc7-4fb3-97ce-41c75f2598cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41493,DS-631ab16a-04ce-4b7a-9ab7-3c33d99512b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41587,DS-89950b8a-d9ab-451c-bfa7-fbb8fa7b83e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-154267586-172.17.0.4-1596901592912:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38248,DS-79843794-22ec-431d-8767-e390f51511d7,DISK], DatanodeInfoWithStorage[127.0.0.1:45220,DS-826535c3-9b72-4d2c-b337-ae32f06641f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37088,DS-8b7093d0-784d-40a4-b600-2224fa7d5575,DISK], DatanodeInfoWithStorage[127.0.0.1:42786,DS-27f2ff34-b2fd-4f81-a5c2-0f6a313996c8,DISK], DatanodeInfoWithStorage[127.0.0.1:37246,DS-ce13e894-8f6b-4587-bde5-fe76b9cd31a7,DISK], DatanodeInfoWithStorage[127.0.0.1:34191,DS-6865a77b-6dc7-4fb3-97ce-41c75f2598cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41493,DS-631ab16a-04ce-4b7a-9ab7-3c33d99512b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41587,DS-89950b8a-d9ab-451c-bfa7-fbb8fa7b83e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2069566273-172.17.0.4-1596901619325:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42395,DS-cb9ff8a1-d59e-48c5-b6b6-1c792baf3738,DISK], DatanodeInfoWithStorage[127.0.0.1:41016,DS-b27d31af-57b0-4eb5-b42d-a9e95bad7f98,DISK], DatanodeInfoWithStorage[127.0.0.1:45570,DS-d73f9d27-f165-4efd-bb26-f7378e1c13e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43413,DS-01e3c70d-344b-4858-ae8c-328af3e33177,DISK], DatanodeInfoWithStorage[127.0.0.1:40658,DS-3aca71e7-403c-4fac-9ef6-44a76d2a5531,DISK], DatanodeInfoWithStorage[127.0.0.1:44799,DS-4bacba19-4701-4002-9d04-a890c4169a31,DISK], DatanodeInfoWithStorage[127.0.0.1:36120,DS-e93b78d9-45c9-403b-a99d-2037d942aa3c,DISK], DatanodeInfoWithStorage[127.0.0.1:35210,DS-c9070366-5489-49d4-966c-489901082496,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2069566273-172.17.0.4-1596901619325:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42395,DS-cb9ff8a1-d59e-48c5-b6b6-1c792baf3738,DISK], DatanodeInfoWithStorage[127.0.0.1:41016,DS-b27d31af-57b0-4eb5-b42d-a9e95bad7f98,DISK], DatanodeInfoWithStorage[127.0.0.1:45570,DS-d73f9d27-f165-4efd-bb26-f7378e1c13e3,DISK], DatanodeInfoWithStorage[127.0.0.1:43413,DS-01e3c70d-344b-4858-ae8c-328af3e33177,DISK], DatanodeInfoWithStorage[127.0.0.1:40658,DS-3aca71e7-403c-4fac-9ef6-44a76d2a5531,DISK], DatanodeInfoWithStorage[127.0.0.1:44799,DS-4bacba19-4701-4002-9d04-a890c4169a31,DISK], DatanodeInfoWithStorage[127.0.0.1:36120,DS-e93b78d9-45c9-403b-a99d-2037d942aa3c,DISK], DatanodeInfoWithStorage[127.0.0.1:35210,DS-c9070366-5489-49d4-966c-489901082496,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1382905474-172.17.0.4-1596901722180:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32797,DS-ea365818-e48d-419b-ae16-b857bc494dd0,DISK], DatanodeInfoWithStorage[127.0.0.1:34317,DS-aa3e88b8-d21b-43d7-bd38-3c74c3db0375,DISK], DatanodeInfoWithStorage[127.0.0.1:43108,DS-eaa6f586-1103-4b66-8e90-246a057b27b1,DISK], DatanodeInfoWithStorage[127.0.0.1:38291,DS-d446a94a-b8d1-4757-a3fd-b43b4e74f62f,DISK], DatanodeInfoWithStorage[127.0.0.1:34360,DS-1a65e32a-db87-4990-b231-a22bdfdceee6,DISK], DatanodeInfoWithStorage[127.0.0.1:45341,DS-3e9c5bb4-840c-4aef-ae1d-94b9172ebdda,DISK], DatanodeInfoWithStorage[127.0.0.1:36094,DS-5458f0b6-890b-4815-9506-a62176e30e7e,DISK], DatanodeInfoWithStorage[127.0.0.1:45093,DS-b203bf6f-ae13-4f11-bb1e-9dd5a9f9f757,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1382905474-172.17.0.4-1596901722180:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32797,DS-ea365818-e48d-419b-ae16-b857bc494dd0,DISK], DatanodeInfoWithStorage[127.0.0.1:34317,DS-aa3e88b8-d21b-43d7-bd38-3c74c3db0375,DISK], DatanodeInfoWithStorage[127.0.0.1:43108,DS-eaa6f586-1103-4b66-8e90-246a057b27b1,DISK], DatanodeInfoWithStorage[127.0.0.1:38291,DS-d446a94a-b8d1-4757-a3fd-b43b4e74f62f,DISK], DatanodeInfoWithStorage[127.0.0.1:34360,DS-1a65e32a-db87-4990-b231-a22bdfdceee6,DISK], DatanodeInfoWithStorage[127.0.0.1:45341,DS-3e9c5bb4-840c-4aef-ae1d-94b9172ebdda,DISK], DatanodeInfoWithStorage[127.0.0.1:36094,DS-5458f0b6-890b-4815-9506-a62176e30e7e,DISK], DatanodeInfoWithStorage[127.0.0.1:45093,DS-b203bf6f-ae13-4f11-bb1e-9dd5a9f9f757,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1710449361-172.17.0.4-1596902046255:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35294,DS-fb126597-f492-467f-886c-e94067cfcda7,DISK], DatanodeInfoWithStorage[127.0.0.1:39219,DS-2eca6ab3-7da8-48ef-80d3-2e348393e6df,DISK], DatanodeInfoWithStorage[127.0.0.1:41171,DS-bdd00572-6e3c-4405-a8a3-7c149e695bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:33349,DS-58e24558-3404-40e8-86d0-4adfaa67e24f,DISK], DatanodeInfoWithStorage[127.0.0.1:43627,DS-4a154c42-ccba-4802-abcd-94d33a98f8d8,DISK], DatanodeInfoWithStorage[127.0.0.1:40379,DS-f2520738-5e49-4511-bca6-d2d2179b246a,DISK], DatanodeInfoWithStorage[127.0.0.1:38304,DS-f3a215d1-fd09-4ee2-a787-5eb501fd469b,DISK], DatanodeInfoWithStorage[127.0.0.1:37723,DS-504db1cc-45fd-4ca8-b021-0dd4ebd2e2f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1710449361-172.17.0.4-1596902046255:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35294,DS-fb126597-f492-467f-886c-e94067cfcda7,DISK], DatanodeInfoWithStorage[127.0.0.1:39219,DS-2eca6ab3-7da8-48ef-80d3-2e348393e6df,DISK], DatanodeInfoWithStorage[127.0.0.1:41171,DS-bdd00572-6e3c-4405-a8a3-7c149e695bc1,DISK], DatanodeInfoWithStorage[127.0.0.1:33349,DS-58e24558-3404-40e8-86d0-4adfaa67e24f,DISK], DatanodeInfoWithStorage[127.0.0.1:43627,DS-4a154c42-ccba-4802-abcd-94d33a98f8d8,DISK], DatanodeInfoWithStorage[127.0.0.1:40379,DS-f2520738-5e49-4511-bca6-d2d2179b246a,DISK], DatanodeInfoWithStorage[127.0.0.1:38304,DS-f3a215d1-fd09-4ee2-a787-5eb501fd469b,DISK], DatanodeInfoWithStorage[127.0.0.1:37723,DS-504db1cc-45fd-4ca8-b021-0dd4ebd2e2f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1382554693-172.17.0.4-1596902591306:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38551,DS-e9de98f0-270f-441d-b38f-ec1ab70f1e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:43610,DS-41d31118-3d43-44f9-987d-1be0f2e0f800,DISK], DatanodeInfoWithStorage[127.0.0.1:45376,DS-726e2500-9a6c-49f4-8395-5fd9574712a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36019,DS-4beb0d5c-8c39-459d-be4a-91d25bdcb803,DISK], DatanodeInfoWithStorage[127.0.0.1:43016,DS-d2c5734a-6eb8-40ab-9844-cfe737c0a9a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39983,DS-31726392-1776-4de1-8135-da5464ebc62b,DISK], DatanodeInfoWithStorage[127.0.0.1:41269,DS-343c94be-9f4d-4e32-803a-96f033389566,DISK], DatanodeInfoWithStorage[127.0.0.1:44474,DS-6d853f82-c800-4dc5-b8af-8cd404a8098b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1382554693-172.17.0.4-1596902591306:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38551,DS-e9de98f0-270f-441d-b38f-ec1ab70f1e6c,DISK], DatanodeInfoWithStorage[127.0.0.1:43610,DS-41d31118-3d43-44f9-987d-1be0f2e0f800,DISK], DatanodeInfoWithStorage[127.0.0.1:45376,DS-726e2500-9a6c-49f4-8395-5fd9574712a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36019,DS-4beb0d5c-8c39-459d-be4a-91d25bdcb803,DISK], DatanodeInfoWithStorage[127.0.0.1:43016,DS-d2c5734a-6eb8-40ab-9844-cfe737c0a9a9,DISK], DatanodeInfoWithStorage[127.0.0.1:39983,DS-31726392-1776-4de1-8135-da5464ebc62b,DISK], DatanodeInfoWithStorage[127.0.0.1:41269,DS-343c94be-9f4d-4e32-803a-96f033389566,DISK], DatanodeInfoWithStorage[127.0.0.1:44474,DS-6d853f82-c800-4dc5-b8af-8cd404a8098b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-763647570-172.17.0.4-1596902805782:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43204,DS-8152aa96-3bd9-4262-8fcb-492735805f34,DISK], DatanodeInfoWithStorage[127.0.0.1:34763,DS-d0c22569-fc9f-4f35-9b1a-dfe6004b2300,DISK], DatanodeInfoWithStorage[127.0.0.1:44829,DS-3a0107f5-2418-44da-9915-8de8cefa30ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45696,DS-b34815b8-3b27-49ac-b654-fc217486727f,DISK], DatanodeInfoWithStorage[127.0.0.1:40364,DS-bbc75607-b129-4f38-89c5-b06c59a7f356,DISK], DatanodeInfoWithStorage[127.0.0.1:44698,DS-dbca3c4b-d2bc-4e2e-a18b-6765c7e28cce,DISK], DatanodeInfoWithStorage[127.0.0.1:45684,DS-bfc4ef54-6396-4ee5-8ec8-43b1c82db573,DISK], DatanodeInfoWithStorage[127.0.0.1:33273,DS-68a58c7b-e01d-43a9-83dd-c52264cc3e32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-763647570-172.17.0.4-1596902805782:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43204,DS-8152aa96-3bd9-4262-8fcb-492735805f34,DISK], DatanodeInfoWithStorage[127.0.0.1:34763,DS-d0c22569-fc9f-4f35-9b1a-dfe6004b2300,DISK], DatanodeInfoWithStorage[127.0.0.1:44829,DS-3a0107f5-2418-44da-9915-8de8cefa30ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45696,DS-b34815b8-3b27-49ac-b654-fc217486727f,DISK], DatanodeInfoWithStorage[127.0.0.1:40364,DS-bbc75607-b129-4f38-89c5-b06c59a7f356,DISK], DatanodeInfoWithStorage[127.0.0.1:44698,DS-dbca3c4b-d2bc-4e2e-a18b-6765c7e28cce,DISK], DatanodeInfoWithStorage[127.0.0.1:45684,DS-bfc4ef54-6396-4ee5-8ec8-43b1c82db573,DISK], DatanodeInfoWithStorage[127.0.0.1:33273,DS-68a58c7b-e01d-43a9-83dd-c52264cc3e32,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.redundancy.considerLoad
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1205527920-172.17.0.4-1596903175602:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41032,DS-9b3e16fb-a2cf-421c-91fe-905e5eb2c13a,DISK], DatanodeInfoWithStorage[127.0.0.1:36257,DS-f40515e4-c492-4765-8b3a-131491b698ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33876,DS-21638a33-d337-4021-a286-5c2c0f46c838,DISK], DatanodeInfoWithStorage[127.0.0.1:38349,DS-1999ea28-68bf-44d5-b697-0c3b42c1e01b,DISK], DatanodeInfoWithStorage[127.0.0.1:37880,DS-ae046854-15ff-42bc-b2ab-ea23ffdbbaf3,DISK], DatanodeInfoWithStorage[127.0.0.1:40096,DS-ae51d7d7-23ee-444d-b132-b0522001d55b,DISK], DatanodeInfoWithStorage[127.0.0.1:43297,DS-bd3abbed-bc64-4afa-9453-2c690abe03a7,DISK], DatanodeInfoWithStorage[127.0.0.1:44732,DS-fec280f1-48c3-4392-94d6-ff05ef578b79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1205527920-172.17.0.4-1596903175602:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41032,DS-9b3e16fb-a2cf-421c-91fe-905e5eb2c13a,DISK], DatanodeInfoWithStorage[127.0.0.1:36257,DS-f40515e4-c492-4765-8b3a-131491b698ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33876,DS-21638a33-d337-4021-a286-5c2c0f46c838,DISK], DatanodeInfoWithStorage[127.0.0.1:38349,DS-1999ea28-68bf-44d5-b697-0c3b42c1e01b,DISK], DatanodeInfoWithStorage[127.0.0.1:37880,DS-ae046854-15ff-42bc-b2ab-ea23ffdbbaf3,DISK], DatanodeInfoWithStorage[127.0.0.1:40096,DS-ae51d7d7-23ee-444d-b132-b0522001d55b,DISK], DatanodeInfoWithStorage[127.0.0.1:43297,DS-bd3abbed-bc64-4afa-9453-2c690abe03a7,DISK], DatanodeInfoWithStorage[127.0.0.1:44732,DS-fec280f1-48c3-4392-94d6-ff05ef578b79,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: might be true error
Total execution time in seconds : 4937
