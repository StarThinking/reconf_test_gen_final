reconf_parameter: dfs.client.write.byte-array-manager.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.byte-array-manager.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1067321277-172.17.0.4-1595310030125:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42004,DS-b28a97ff-9273-413e-81b0-12191ae0a666,DISK], DatanodeInfoWithStorage[127.0.0.1:42063,DS-1643a7d3-3365-4f8c-9b3a-3792972637aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34167,DS-ae498824-6393-4061-8359-1834035622f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43275,DS-5070ccb9-22dd-44ec-af33-80e1be26d0c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40335,DS-f2905cc2-2b5d-4208-b0d6-a7da2587ca98,DISK], DatanodeInfoWithStorage[127.0.0.1:32773,DS-229c8ce6-d834-40fa-85fd-740cf0e17b08,DISK], DatanodeInfoWithStorage[127.0.0.1:33634,DS-89378d56-7746-4ac2-96c7-48b2ddfa19a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41062,DS-5d4e1d14-0cb6-4450-a561-32cf49e75989,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1067321277-172.17.0.4-1595310030125:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42004,DS-b28a97ff-9273-413e-81b0-12191ae0a666,DISK], DatanodeInfoWithStorage[127.0.0.1:42063,DS-1643a7d3-3365-4f8c-9b3a-3792972637aa,DISK], DatanodeInfoWithStorage[127.0.0.1:34167,DS-ae498824-6393-4061-8359-1834035622f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43275,DS-5070ccb9-22dd-44ec-af33-80e1be26d0c6,DISK], DatanodeInfoWithStorage[127.0.0.1:40335,DS-f2905cc2-2b5d-4208-b0d6-a7da2587ca98,DISK], DatanodeInfoWithStorage[127.0.0.1:32773,DS-229c8ce6-d834-40fa-85fd-740cf0e17b08,DISK], DatanodeInfoWithStorage[127.0.0.1:33634,DS-89378d56-7746-4ac2-96c7-48b2ddfa19a5,DISK], DatanodeInfoWithStorage[127.0.0.1:41062,DS-5d4e1d14-0cb6-4450-a561-32cf49e75989,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.byte-array-manager.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2017597947-172.17.0.4-1595310129892:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36294,DS-1bdddbda-c1b2-4491-8a22-1d70a7a9ecb5,DISK], DatanodeInfoWithStorage[127.0.0.1:46217,DS-2d5ee333-f54a-4f15-84e1-22e7281dfee8,DISK], DatanodeInfoWithStorage[127.0.0.1:44593,DS-a8236138-6514-4006-8c03-890709d77b53,DISK], DatanodeInfoWithStorage[127.0.0.1:36726,DS-33527698-6c72-43de-97b2-9470f29f854a,DISK], DatanodeInfoWithStorage[127.0.0.1:34000,DS-697cfd48-2c2f-4ea6-88df-50511f3db618,DISK], DatanodeInfoWithStorage[127.0.0.1:38125,DS-8c2b2a95-ca4e-4c19-b3fe-04ab75460488,DISK], DatanodeInfoWithStorage[127.0.0.1:33298,DS-8c461c0b-3611-446a-9758-b45c1fabe270,DISK], DatanodeInfoWithStorage[127.0.0.1:40118,DS-1234892b-534f-468c-8076-674a23c076fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2017597947-172.17.0.4-1595310129892:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36294,DS-1bdddbda-c1b2-4491-8a22-1d70a7a9ecb5,DISK], DatanodeInfoWithStorage[127.0.0.1:46217,DS-2d5ee333-f54a-4f15-84e1-22e7281dfee8,DISK], DatanodeInfoWithStorage[127.0.0.1:44593,DS-a8236138-6514-4006-8c03-890709d77b53,DISK], DatanodeInfoWithStorage[127.0.0.1:36726,DS-33527698-6c72-43de-97b2-9470f29f854a,DISK], DatanodeInfoWithStorage[127.0.0.1:34000,DS-697cfd48-2c2f-4ea6-88df-50511f3db618,DISK], DatanodeInfoWithStorage[127.0.0.1:38125,DS-8c2b2a95-ca4e-4c19-b3fe-04ab75460488,DISK], DatanodeInfoWithStorage[127.0.0.1:33298,DS-8c461c0b-3611-446a-9758-b45c1fabe270,DISK], DatanodeInfoWithStorage[127.0.0.1:40118,DS-1234892b-534f-468c-8076-674a23c076fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.byte-array-manager.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2066594999-172.17.0.4-1595310225631:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40079,DS-569679ad-03dc-430e-8bce-d95b7d3a0ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:39097,DS-a622dc21-3288-4516-ab18-8f754f437a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:40641,DS-15bcf9ca-7588-4949-9041-0a7b4b402b29,DISK], DatanodeInfoWithStorage[127.0.0.1:37005,DS-96fdff3d-146c-4142-ac9d-7b90726b2b27,DISK], DatanodeInfoWithStorage[127.0.0.1:39648,DS-b5b3f6b1-65c2-498c-b042-355138b2a5a4,DISK], DatanodeInfoWithStorage[127.0.0.1:45320,DS-301106d2-00d0-4b74-b5e8-4af321f97b77,DISK], DatanodeInfoWithStorage[127.0.0.1:41986,DS-581b4653-636b-4472-bf9e-b4f49ede6808,DISK], DatanodeInfoWithStorage[127.0.0.1:38028,DS-4e762377-f625-4d33-87e1-a504248dd822,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2066594999-172.17.0.4-1595310225631:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40079,DS-569679ad-03dc-430e-8bce-d95b7d3a0ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:39097,DS-a622dc21-3288-4516-ab18-8f754f437a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:40641,DS-15bcf9ca-7588-4949-9041-0a7b4b402b29,DISK], DatanodeInfoWithStorage[127.0.0.1:37005,DS-96fdff3d-146c-4142-ac9d-7b90726b2b27,DISK], DatanodeInfoWithStorage[127.0.0.1:39648,DS-b5b3f6b1-65c2-498c-b042-355138b2a5a4,DISK], DatanodeInfoWithStorage[127.0.0.1:45320,DS-301106d2-00d0-4b74-b5e8-4af321f97b77,DISK], DatanodeInfoWithStorage[127.0.0.1:41986,DS-581b4653-636b-4472-bf9e-b4f49ede6808,DISK], DatanodeInfoWithStorage[127.0.0.1:38028,DS-4e762377-f625-4d33-87e1-a504248dd822,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.write.byte-array-manager.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-432467817-172.17.0.4-1595310379471:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41937,DS-1828bff6-9223-480f-9b41-5c99be117423,DISK], DatanodeInfoWithStorage[127.0.0.1:34771,DS-5db810d0-7f24-4ffc-870f-d6bd08e4bc94,DISK], DatanodeInfoWithStorage[127.0.0.1:38881,DS-68ff87b3-ba00-473d-9185-d114a254fa28,DISK], DatanodeInfoWithStorage[127.0.0.1:41633,DS-a030e1b0-fe4c-4fed-8aad-310b03d2df24,DISK], DatanodeInfoWithStorage[127.0.0.1:39015,DS-ce7dc5c7-5522-46db-b98a-2c1e0c2ec0d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40861,DS-e288a9b0-184a-429a-98f8-729173e22e04,DISK], DatanodeInfoWithStorage[127.0.0.1:37984,DS-0daa0a87-723f-470b-af28-9f3392e256ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45818,DS-8de396f6-74a5-465c-9a67-defe38e81fae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-432467817-172.17.0.4-1595310379471:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41937,DS-1828bff6-9223-480f-9b41-5c99be117423,DISK], DatanodeInfoWithStorage[127.0.0.1:34771,DS-5db810d0-7f24-4ffc-870f-d6bd08e4bc94,DISK], DatanodeInfoWithStorage[127.0.0.1:38881,DS-68ff87b3-ba00-473d-9185-d114a254fa28,DISK], DatanodeInfoWithStorage[127.0.0.1:41633,DS-a030e1b0-fe4c-4fed-8aad-310b03d2df24,DISK], DatanodeInfoWithStorage[127.0.0.1:39015,DS-ce7dc5c7-5522-46db-b98a-2c1e0c2ec0d9,DISK], DatanodeInfoWithStorage[127.0.0.1:40861,DS-e288a9b0-184a-429a-98f8-729173e22e04,DISK], DatanodeInfoWithStorage[127.0.0.1:37984,DS-0daa0a87-723f-470b-af28-9f3392e256ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45818,DS-8de396f6-74a5-465c-9a67-defe38e81fae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.write.byte-array-manager.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1458352960-172.17.0.4-1595310669824:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44969,DS-df0b9a86-bcd9-4c4e-a5d5-b55155217509,DISK], DatanodeInfoWithStorage[127.0.0.1:45226,DS-bad415b1-2565-4552-80d1-fefa3d93db90,DISK], DatanodeInfoWithStorage[127.0.0.1:37486,DS-c23eee89-7aec-422b-8437-e11cd28cb396,DISK], DatanodeInfoWithStorage[127.0.0.1:33181,DS-13df3f4c-c5ec-42de-b5e9-1beb09d509e9,DISK], DatanodeInfoWithStorage[127.0.0.1:46368,DS-6e6affb2-1fe4-430e-aaf9-a4dca8f54cc9,DISK], DatanodeInfoWithStorage[127.0.0.1:45264,DS-d1ba8eda-ccef-4197-8eb8-afa4725a8127,DISK], DatanodeInfoWithStorage[127.0.0.1:42476,DS-c3a54273-c161-4dcc-a452-e8a529fee437,DISK], DatanodeInfoWithStorage[127.0.0.1:42431,DS-3119ab9a-6812-4e3f-bb7e-e04960512e47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1458352960-172.17.0.4-1595310669824:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44969,DS-df0b9a86-bcd9-4c4e-a5d5-b55155217509,DISK], DatanodeInfoWithStorage[127.0.0.1:45226,DS-bad415b1-2565-4552-80d1-fefa3d93db90,DISK], DatanodeInfoWithStorage[127.0.0.1:37486,DS-c23eee89-7aec-422b-8437-e11cd28cb396,DISK], DatanodeInfoWithStorage[127.0.0.1:33181,DS-13df3f4c-c5ec-42de-b5e9-1beb09d509e9,DISK], DatanodeInfoWithStorage[127.0.0.1:46368,DS-6e6affb2-1fe4-430e-aaf9-a4dca8f54cc9,DISK], DatanodeInfoWithStorage[127.0.0.1:45264,DS-d1ba8eda-ccef-4197-8eb8-afa4725a8127,DISK], DatanodeInfoWithStorage[127.0.0.1:42476,DS-c3a54273-c161-4dcc-a452-e8a529fee437,DISK], DatanodeInfoWithStorage[127.0.0.1:42431,DS-3119ab9a-6812-4e3f-bb7e-e04960512e47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.write.byte-array-manager.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1089112206-172.17.0.4-1595311066816:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41401,DS-f53878a7-645b-4031-9e9e-44d55d5af086,DISK], DatanodeInfoWithStorage[127.0.0.1:43548,DS-93cfddf9-5a1e-4e14-b0e8-ed7f00c3feeb,DISK], DatanodeInfoWithStorage[127.0.0.1:43865,DS-3b450e27-60c8-4917-a14c-32e331943ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:35400,DS-ffa9fca3-f1a0-4b64-8937-eb79024d257f,DISK], DatanodeInfoWithStorage[127.0.0.1:43089,DS-98af23f0-102b-4e4f-9f34-a67af88f5a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:43972,DS-06cbf121-bf4a-4e1b-84eb-549931bda8a3,DISK], DatanodeInfoWithStorage[127.0.0.1:45958,DS-c802b73e-f9dc-4641-8a86-1d70e75ccd69,DISK], DatanodeInfoWithStorage[127.0.0.1:42788,DS-13463ffa-44a4-4f13-bc0b-5ee09b506688,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1089112206-172.17.0.4-1595311066816:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41401,DS-f53878a7-645b-4031-9e9e-44d55d5af086,DISK], DatanodeInfoWithStorage[127.0.0.1:43548,DS-93cfddf9-5a1e-4e14-b0e8-ed7f00c3feeb,DISK], DatanodeInfoWithStorage[127.0.0.1:43865,DS-3b450e27-60c8-4917-a14c-32e331943ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:35400,DS-ffa9fca3-f1a0-4b64-8937-eb79024d257f,DISK], DatanodeInfoWithStorage[127.0.0.1:43089,DS-98af23f0-102b-4e4f-9f34-a67af88f5a6c,DISK], DatanodeInfoWithStorage[127.0.0.1:43972,DS-06cbf121-bf4a-4e1b-84eb-549931bda8a3,DISK], DatanodeInfoWithStorage[127.0.0.1:45958,DS-c802b73e-f9dc-4641-8a86-1d70e75ccd69,DISK], DatanodeInfoWithStorage[127.0.0.1:42788,DS-13463ffa-44a4-4f13-bc0b-5ee09b506688,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.byte-array-manager.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1291046399-172.17.0.4-1595311139528:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38685,DS-95df14af-24c9-44f2-a3e3-2c8e5c26e6fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42129,DS-86d0845f-8b39-4378-9dfa-b6839bb1bc84,DISK], DatanodeInfoWithStorage[127.0.0.1:43670,DS-a02a9099-3078-4ba8-b379-fc9f573e42d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35277,DS-f16fa496-e11e-4fc4-861d-b54c3cf66512,DISK], DatanodeInfoWithStorage[127.0.0.1:34267,DS-acdd75e2-6780-4110-b5ce-620f23e2f1fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44569,DS-4fc6ffeb-c191-4384-b6a4-4d8f5fcfd2ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41969,DS-b61a0a88-ee62-48e1-8c6c-46ad859029ed,DISK], DatanodeInfoWithStorage[127.0.0.1:45677,DS-4e48efca-c0ab-4661-997c-82084870becc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1291046399-172.17.0.4-1595311139528:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38685,DS-95df14af-24c9-44f2-a3e3-2c8e5c26e6fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42129,DS-86d0845f-8b39-4378-9dfa-b6839bb1bc84,DISK], DatanodeInfoWithStorage[127.0.0.1:43670,DS-a02a9099-3078-4ba8-b379-fc9f573e42d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35277,DS-f16fa496-e11e-4fc4-861d-b54c3cf66512,DISK], DatanodeInfoWithStorage[127.0.0.1:34267,DS-acdd75e2-6780-4110-b5ce-620f23e2f1fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44569,DS-4fc6ffeb-c191-4384-b6a4-4d8f5fcfd2ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41969,DS-b61a0a88-ee62-48e1-8c6c-46ad859029ed,DISK], DatanodeInfoWithStorage[127.0.0.1:45677,DS-4e48efca-c0ab-4661-997c-82084870becc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.byte-array-manager.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1264840698-172.17.0.4-1595311236307:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33336,DS-9914af38-96a5-4189-9f18-f043ec8b6c96,DISK], DatanodeInfoWithStorage[127.0.0.1:40095,DS-61d3bab0-9cc6-4763-bda1-097c20c320ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33122,DS-327ad786-5a97-480b-90c8-6f55999375da,DISK], DatanodeInfoWithStorage[127.0.0.1:37616,DS-9161ebfd-7f2b-45a2-9e11-2dfee6ba0ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:44856,DS-0d0e687c-7572-419d-9d4e-c4ed80547110,DISK], DatanodeInfoWithStorage[127.0.0.1:36066,DS-0ae8568c-6e82-4a80-ba82-6816bddae505,DISK], DatanodeInfoWithStorage[127.0.0.1:43165,DS-331adc9c-1cc4-4e98-b500-3fbef1916b2a,DISK], DatanodeInfoWithStorage[127.0.0.1:36355,DS-71549aa1-b9a0-400c-a06e-d81308c06c16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1264840698-172.17.0.4-1595311236307:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33336,DS-9914af38-96a5-4189-9f18-f043ec8b6c96,DISK], DatanodeInfoWithStorage[127.0.0.1:40095,DS-61d3bab0-9cc6-4763-bda1-097c20c320ba,DISK], DatanodeInfoWithStorage[127.0.0.1:33122,DS-327ad786-5a97-480b-90c8-6f55999375da,DISK], DatanodeInfoWithStorage[127.0.0.1:37616,DS-9161ebfd-7f2b-45a2-9e11-2dfee6ba0ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:44856,DS-0d0e687c-7572-419d-9d4e-c4ed80547110,DISK], DatanodeInfoWithStorage[127.0.0.1:36066,DS-0ae8568c-6e82-4a80-ba82-6816bddae505,DISK], DatanodeInfoWithStorage[127.0.0.1:43165,DS-331adc9c-1cc4-4e98-b500-3fbef1916b2a,DISK], DatanodeInfoWithStorage[127.0.0.1:36355,DS-71549aa1-b9a0-400c-a06e-d81308c06c16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.byte-array-manager.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-680994044-172.17.0.4-1595311393570:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44596,DS-3dfc3727-0d9e-4017-b553-256c9ee98277,DISK], DatanodeInfoWithStorage[127.0.0.1:39060,DS-2da6f94a-22e0-4d63-9217-31e676a60ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:42735,DS-3782b4bb-4ae0-456b-8a67-267e5b2f524a,DISK], DatanodeInfoWithStorage[127.0.0.1:44836,DS-c7162afd-cd7b-4ff1-8695-fd45eb9e98ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39830,DS-f0562b74-589d-4e67-9d36-1342ef405e14,DISK], DatanodeInfoWithStorage[127.0.0.1:41391,DS-e254773d-f3a2-4973-bb6f-6b690965ea21,DISK], DatanodeInfoWithStorage[127.0.0.1:33323,DS-2f04bafb-2bbd-4713-8a3f-d9461e43ec16,DISK], DatanodeInfoWithStorage[127.0.0.1:45122,DS-f8b297c4-e852-42a7-b80b-105e6c30c49c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-680994044-172.17.0.4-1595311393570:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44596,DS-3dfc3727-0d9e-4017-b553-256c9ee98277,DISK], DatanodeInfoWithStorage[127.0.0.1:39060,DS-2da6f94a-22e0-4d63-9217-31e676a60ef5,DISK], DatanodeInfoWithStorage[127.0.0.1:42735,DS-3782b4bb-4ae0-456b-8a67-267e5b2f524a,DISK], DatanodeInfoWithStorage[127.0.0.1:44836,DS-c7162afd-cd7b-4ff1-8695-fd45eb9e98ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39830,DS-f0562b74-589d-4e67-9d36-1342ef405e14,DISK], DatanodeInfoWithStorage[127.0.0.1:41391,DS-e254773d-f3a2-4973-bb6f-6b690965ea21,DISK], DatanodeInfoWithStorage[127.0.0.1:33323,DS-2f04bafb-2bbd-4713-8a3f-d9461e43ec16,DISK], DatanodeInfoWithStorage[127.0.0.1:45122,DS-f8b297c4-e852-42a7-b80b-105e6c30c49c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.write.byte-array-manager.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-115849356-172.17.0.4-1595311431873:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40458,DS-3f857353-ae39-4eb5-803c-1929b56e4dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:38918,DS-d95120bb-21ff-4ac2-ba4f-7eeea646fe1a,DISK], DatanodeInfoWithStorage[127.0.0.1:37148,DS-eb477980-c264-4034-a4d8-ca3978b47310,DISK], DatanodeInfoWithStorage[127.0.0.1:44115,DS-5973e98f-bf39-4c7b-a772-7556434c1fb4,DISK], DatanodeInfoWithStorage[127.0.0.1:43532,DS-122419fd-9d44-4cbd-b5db-bc85f6ff917b,DISK], DatanodeInfoWithStorage[127.0.0.1:43125,DS-2e8d59f8-e831-4612-b4ff-a63429b57a76,DISK], DatanodeInfoWithStorage[127.0.0.1:33725,DS-dc58924d-e27f-40d2-b8f8-0c14a040502b,DISK], DatanodeInfoWithStorage[127.0.0.1:38542,DS-12ff683b-c31c-432d-a107-7ec3304ec5ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-115849356-172.17.0.4-1595311431873:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40458,DS-3f857353-ae39-4eb5-803c-1929b56e4dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:38918,DS-d95120bb-21ff-4ac2-ba4f-7eeea646fe1a,DISK], DatanodeInfoWithStorage[127.0.0.1:37148,DS-eb477980-c264-4034-a4d8-ca3978b47310,DISK], DatanodeInfoWithStorage[127.0.0.1:44115,DS-5973e98f-bf39-4c7b-a772-7556434c1fb4,DISK], DatanodeInfoWithStorage[127.0.0.1:43532,DS-122419fd-9d44-4cbd-b5db-bc85f6ff917b,DISK], DatanodeInfoWithStorage[127.0.0.1:43125,DS-2e8d59f8-e831-4612-b4ff-a63429b57a76,DISK], DatanodeInfoWithStorage[127.0.0.1:33725,DS-dc58924d-e27f-40d2-b8f8-0c14a040502b,DISK], DatanodeInfoWithStorage[127.0.0.1:38542,DS-12ff683b-c31c-432d-a107-7ec3304ec5ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.write.byte-array-manager.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1990800634-172.17.0.4-1595311750562:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43966,DS-da33f7f9-d6c3-4b8d-a844-9f31f61d1040,DISK], DatanodeInfoWithStorage[127.0.0.1:42736,DS-acf327fa-a1ce-4663-878f-1c334b50d485,DISK], DatanodeInfoWithStorage[127.0.0.1:44747,DS-9253e857-e48c-4700-a7bd-aeb1cf53d285,DISK], DatanodeInfoWithStorage[127.0.0.1:38038,DS-16e6ad56-6f59-4fab-923e-cdb15d983511,DISK], DatanodeInfoWithStorage[127.0.0.1:45320,DS-4983c575-70c9-4d11-aecb-4aa5abf6389a,DISK], DatanodeInfoWithStorage[127.0.0.1:46235,DS-6d52c0c9-094e-4837-b890-79d4deae6da7,DISK], DatanodeInfoWithStorage[127.0.0.1:43727,DS-9d09382e-b7a9-4333-976f-e4a693b694d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43476,DS-f9b632ef-ed72-440d-9a7d-89fbf1ab9e98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1990800634-172.17.0.4-1595311750562:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43966,DS-da33f7f9-d6c3-4b8d-a844-9f31f61d1040,DISK], DatanodeInfoWithStorage[127.0.0.1:42736,DS-acf327fa-a1ce-4663-878f-1c334b50d485,DISK], DatanodeInfoWithStorage[127.0.0.1:44747,DS-9253e857-e48c-4700-a7bd-aeb1cf53d285,DISK], DatanodeInfoWithStorage[127.0.0.1:38038,DS-16e6ad56-6f59-4fab-923e-cdb15d983511,DISK], DatanodeInfoWithStorage[127.0.0.1:45320,DS-4983c575-70c9-4d11-aecb-4aa5abf6389a,DISK], DatanodeInfoWithStorage[127.0.0.1:46235,DS-6d52c0c9-094e-4837-b890-79d4deae6da7,DISK], DatanodeInfoWithStorage[127.0.0.1:43727,DS-9d09382e-b7a9-4333-976f-e4a693b694d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43476,DS-f9b632ef-ed72-440d-9a7d-89fbf1ab9e98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.write.byte-array-manager.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1048892951-172.17.0.4-1595312723367:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33236,DS-0426b1ba-7efc-4dc4-9991-935e256a1a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:35910,DS-b46d348a-c748-455b-a114-b4e037698be5,DISK], DatanodeInfoWithStorage[127.0.0.1:40123,DS-85308c35-9a54-42a6-ae38-b0a1c6df40d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43806,DS-484bd33f-908a-4532-94cb-8cc2f8695480,DISK], DatanodeInfoWithStorage[127.0.0.1:35537,DS-23c2124d-11fa-481e-97ab-5b81ca37c6bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33353,DS-2339a8ac-cb0c-4cf8-89b1-6968a5fd44ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46649,DS-31ca370e-4022-4041-b6ec-c6d2f473e1fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42284,DS-bcce413f-89af-439f-bf93-89003a49c8ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1048892951-172.17.0.4-1595312723367:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33236,DS-0426b1ba-7efc-4dc4-9991-935e256a1a5b,DISK], DatanodeInfoWithStorage[127.0.0.1:35910,DS-b46d348a-c748-455b-a114-b4e037698be5,DISK], DatanodeInfoWithStorage[127.0.0.1:40123,DS-85308c35-9a54-42a6-ae38-b0a1c6df40d6,DISK], DatanodeInfoWithStorage[127.0.0.1:43806,DS-484bd33f-908a-4532-94cb-8cc2f8695480,DISK], DatanodeInfoWithStorage[127.0.0.1:35537,DS-23c2124d-11fa-481e-97ab-5b81ca37c6bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33353,DS-2339a8ac-cb0c-4cf8-89b1-6968a5fd44ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46649,DS-31ca370e-4022-4041-b6ec-c6d2f473e1fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42284,DS-bcce413f-89af-439f-bf93-89003a49c8ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.write.byte-array-manager.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-267754991-172.17.0.4-1595313352714:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45943,DS-01fa423d-75e8-425e-8643-72e6dc3ecbee,DISK], DatanodeInfoWithStorage[127.0.0.1:33769,DS-cbf09350-9b95-4657-8c57-5769fde79783,DISK], DatanodeInfoWithStorage[127.0.0.1:35082,DS-9ec09d48-c8a1-467b-be70-06638d314eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:39961,DS-a48b3080-0e33-44c7-be4e-841c80620364,DISK], DatanodeInfoWithStorage[127.0.0.1:45482,DS-9c70a7b4-d1e5-4d4e-9d7f-624b29261268,DISK], DatanodeInfoWithStorage[127.0.0.1:41156,DS-751cd0c7-0c25-46bc-b819-89c48565089d,DISK], DatanodeInfoWithStorage[127.0.0.1:40479,DS-b0994ae5-af9c-4b46-8c71-48bcb744d2c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34615,DS-7609bc43-1010-496b-b7b3-5d38e6790124,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-267754991-172.17.0.4-1595313352714:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45943,DS-01fa423d-75e8-425e-8643-72e6dc3ecbee,DISK], DatanodeInfoWithStorage[127.0.0.1:33769,DS-cbf09350-9b95-4657-8c57-5769fde79783,DISK], DatanodeInfoWithStorage[127.0.0.1:35082,DS-9ec09d48-c8a1-467b-be70-06638d314eb7,DISK], DatanodeInfoWithStorage[127.0.0.1:39961,DS-a48b3080-0e33-44c7-be4e-841c80620364,DISK], DatanodeInfoWithStorage[127.0.0.1:45482,DS-9c70a7b4-d1e5-4d4e-9d7f-624b29261268,DISK], DatanodeInfoWithStorage[127.0.0.1:41156,DS-751cd0c7-0c25-46bc-b819-89c48565089d,DISK], DatanodeInfoWithStorage[127.0.0.1:40479,DS-b0994ae5-af9c-4b46-8c71-48bcb744d2c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34615,DS-7609bc43-1010-496b-b7b3-5d38e6790124,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.byte-array-manager.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-297328846-172.17.0.4-1595313389965:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45886,DS-6025f454-68ce-4ab9-af48-4ffc37c15b15,DISK], DatanodeInfoWithStorage[127.0.0.1:40217,DS-166eaa7f-5ba8-42dc-a696-1c0b9f6d4aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:43191,DS-9b03b0f1-ca1c-4dd0-8091-75d79e9d24a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38024,DS-265055a6-f9c5-41be-aafd-f95faf71d6e2,DISK], DatanodeInfoWithStorage[127.0.0.1:35210,DS-01f23b06-7b62-4b9a-a832-e365aa4ed46b,DISK], DatanodeInfoWithStorage[127.0.0.1:35607,DS-b4bf3bdd-040a-49c0-96f5-7544dc9265c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36671,DS-794fe436-206c-456a-b724-d65c86b9b10d,DISK], DatanodeInfoWithStorage[127.0.0.1:33187,DS-e33b4012-b4ec-47fe-8d58-c89228d7d16e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-297328846-172.17.0.4-1595313389965:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45886,DS-6025f454-68ce-4ab9-af48-4ffc37c15b15,DISK], DatanodeInfoWithStorage[127.0.0.1:40217,DS-166eaa7f-5ba8-42dc-a696-1c0b9f6d4aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:43191,DS-9b03b0f1-ca1c-4dd0-8091-75d79e9d24a2,DISK], DatanodeInfoWithStorage[127.0.0.1:38024,DS-265055a6-f9c5-41be-aafd-f95faf71d6e2,DISK], DatanodeInfoWithStorage[127.0.0.1:35210,DS-01f23b06-7b62-4b9a-a832-e365aa4ed46b,DISK], DatanodeInfoWithStorage[127.0.0.1:35607,DS-b4bf3bdd-040a-49c0-96f5-7544dc9265c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36671,DS-794fe436-206c-456a-b724-d65c86b9b10d,DISK], DatanodeInfoWithStorage[127.0.0.1:33187,DS-e33b4012-b4ec-47fe-8d58-c89228d7d16e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.write.byte-array-manager.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-593931740-172.17.0.4-1595313664194:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37908,DS-bb8ab11f-181f-42ec-a431-5741088147a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35557,DS-66ed7af6-47fe-4a08-a2e6-b8ce0cfcafeb,DISK], DatanodeInfoWithStorage[127.0.0.1:40675,DS-69760401-0876-4653-a041-a3275625540a,DISK], DatanodeInfoWithStorage[127.0.0.1:38836,DS-1bbb410c-3836-4a6d-9674-55506886d614,DISK], DatanodeInfoWithStorage[127.0.0.1:34899,DS-f8dc9001-ec25-4592-8fbe-d0e9932a505b,DISK], DatanodeInfoWithStorage[127.0.0.1:46435,DS-9523e2b4-d419-4e9e-ae95-f354b5e478fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43408,DS-e870a778-fc90-4d04-874b-3d30520845c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37319,DS-7f05e73f-112d-4473-addc-2c018af2848c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-593931740-172.17.0.4-1595313664194:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37908,DS-bb8ab11f-181f-42ec-a431-5741088147a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35557,DS-66ed7af6-47fe-4a08-a2e6-b8ce0cfcafeb,DISK], DatanodeInfoWithStorage[127.0.0.1:40675,DS-69760401-0876-4653-a041-a3275625540a,DISK], DatanodeInfoWithStorage[127.0.0.1:38836,DS-1bbb410c-3836-4a6d-9674-55506886d614,DISK], DatanodeInfoWithStorage[127.0.0.1:34899,DS-f8dc9001-ec25-4592-8fbe-d0e9932a505b,DISK], DatanodeInfoWithStorage[127.0.0.1:46435,DS-9523e2b4-d419-4e9e-ae95-f354b5e478fe,DISK], DatanodeInfoWithStorage[127.0.0.1:43408,DS-e870a778-fc90-4d04-874b-3d30520845c5,DISK], DatanodeInfoWithStorage[127.0.0.1:37319,DS-7f05e73f-112d-4473-addc-2c018af2848c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.byte-array-manager.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1915910981-172.17.0.4-1595313696994:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37904,DS-3967ab75-49af-47ed-84de-f950334bfe75,DISK], DatanodeInfoWithStorage[127.0.0.1:39227,DS-133d0f51-6bad-4341-be87-e171435c2041,DISK], DatanodeInfoWithStorage[127.0.0.1:33226,DS-5673a5ac-321c-4443-a696-b056ef342af4,DISK], DatanodeInfoWithStorage[127.0.0.1:33045,DS-eda76e6f-fe4c-4b50-ac70-a26503a7576a,DISK], DatanodeInfoWithStorage[127.0.0.1:38527,DS-8b2aa230-a299-4560-837b-7848a09fc9bc,DISK], DatanodeInfoWithStorage[127.0.0.1:36612,DS-a0894691-d689-47b4-9123-3e4eade5ea33,DISK], DatanodeInfoWithStorage[127.0.0.1:36857,DS-b6ea9c70-bb02-4fe8-8758-cf6fe343c7e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43710,DS-6c3ee256-c796-4bcc-bf00-b9b5a760ff9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1915910981-172.17.0.4-1595313696994:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37904,DS-3967ab75-49af-47ed-84de-f950334bfe75,DISK], DatanodeInfoWithStorage[127.0.0.1:39227,DS-133d0f51-6bad-4341-be87-e171435c2041,DISK], DatanodeInfoWithStorage[127.0.0.1:33226,DS-5673a5ac-321c-4443-a696-b056ef342af4,DISK], DatanodeInfoWithStorage[127.0.0.1:33045,DS-eda76e6f-fe4c-4b50-ac70-a26503a7576a,DISK], DatanodeInfoWithStorage[127.0.0.1:38527,DS-8b2aa230-a299-4560-837b-7848a09fc9bc,DISK], DatanodeInfoWithStorage[127.0.0.1:36612,DS-a0894691-d689-47b4-9123-3e4eade5ea33,DISK], DatanodeInfoWithStorage[127.0.0.1:36857,DS-b6ea9c70-bb02-4fe8-8758-cf6fe343c7e1,DISK], DatanodeInfoWithStorage[127.0.0.1:43710,DS-6c3ee256-c796-4bcc-bf00-b9b5a760ff9f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.write.byte-array-manager.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-693591166-172.17.0.4-1595313943345:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36736,DS-c939ba83-ae4c-43ca-9fd7-cdde0a36af77,DISK], DatanodeInfoWithStorage[127.0.0.1:40453,DS-a555ad2d-72c7-494f-b33b-927d142c675d,DISK], DatanodeInfoWithStorage[127.0.0.1:41355,DS-407f5d1e-dafb-4745-ac66-8a6c528ae96e,DISK], DatanodeInfoWithStorage[127.0.0.1:43848,DS-cd5596cd-2be0-4f38-a3dd-fe7c48cc089a,DISK], DatanodeInfoWithStorage[127.0.0.1:32874,DS-9408a1ad-c456-4124-82db-6fce3c40d179,DISK], DatanodeInfoWithStorage[127.0.0.1:43506,DS-9411cbc8-366e-4a6d-9930-17b2535d939e,DISK], DatanodeInfoWithStorage[127.0.0.1:37486,DS-912400fa-e984-46f2-a460-3e5f75ee84ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45729,DS-22bec61f-6d56-4af9-b73d-9419e98a7d99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-693591166-172.17.0.4-1595313943345:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36736,DS-c939ba83-ae4c-43ca-9fd7-cdde0a36af77,DISK], DatanodeInfoWithStorage[127.0.0.1:40453,DS-a555ad2d-72c7-494f-b33b-927d142c675d,DISK], DatanodeInfoWithStorage[127.0.0.1:41355,DS-407f5d1e-dafb-4745-ac66-8a6c528ae96e,DISK], DatanodeInfoWithStorage[127.0.0.1:43848,DS-cd5596cd-2be0-4f38-a3dd-fe7c48cc089a,DISK], DatanodeInfoWithStorage[127.0.0.1:32874,DS-9408a1ad-c456-4124-82db-6fce3c40d179,DISK], DatanodeInfoWithStorage[127.0.0.1:43506,DS-9411cbc8-366e-4a6d-9930-17b2535d939e,DISK], DatanodeInfoWithStorage[127.0.0.1:37486,DS-912400fa-e984-46f2-a460-3e5f75ee84ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45729,DS-22bec61f-6d56-4af9-b73d-9419e98a7d99,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.write.byte-array-manager.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-303966334-172.17.0.4-1595314084356:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36575,DS-e38721d4-026f-43a8-a9da-1e63d51c9483,DISK], DatanodeInfoWithStorage[127.0.0.1:43166,DS-2773c63b-6f6d-42b3-88e2-6632a8cbd71e,DISK], DatanodeInfoWithStorage[127.0.0.1:40805,DS-c3b3c474-1e66-4d51-821b-bc18099fb2a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44315,DS-ee1dbd87-6f71-47c7-ad68-5e11f6fa6677,DISK], DatanodeInfoWithStorage[127.0.0.1:39131,DS-640efa77-f932-4653-b95e-88989870b05f,DISK], DatanodeInfoWithStorage[127.0.0.1:39022,DS-018fc6e2-3ccd-4b0d-aa17-607ae8eca101,DISK], DatanodeInfoWithStorage[127.0.0.1:42600,DS-964456ac-f159-4b81-9978-b0b5184215d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36763,DS-68c5273f-013a-403e-b82e-04b520efc620,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-303966334-172.17.0.4-1595314084356:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36575,DS-e38721d4-026f-43a8-a9da-1e63d51c9483,DISK], DatanodeInfoWithStorage[127.0.0.1:43166,DS-2773c63b-6f6d-42b3-88e2-6632a8cbd71e,DISK], DatanodeInfoWithStorage[127.0.0.1:40805,DS-c3b3c474-1e66-4d51-821b-bc18099fb2a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44315,DS-ee1dbd87-6f71-47c7-ad68-5e11f6fa6677,DISK], DatanodeInfoWithStorage[127.0.0.1:39131,DS-640efa77-f932-4653-b95e-88989870b05f,DISK], DatanodeInfoWithStorage[127.0.0.1:39022,DS-018fc6e2-3ccd-4b0d-aa17-607ae8eca101,DISK], DatanodeInfoWithStorage[127.0.0.1:42600,DS-964456ac-f159-4b81-9978-b0b5184215d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36763,DS-68c5273f-013a-403e-b82e-04b520efc620,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.write.byte-array-manager.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery17
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-46192382-172.17.0.4-1595314292914:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36718,DS-fc23c0ae-94d1-4a59-b8cb-b93bb26501bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45478,DS-ea4e78a7-ba21-491a-87a9-f2d89116d4ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33131,DS-453e1ffd-f5b2-49d1-8dc3-f15dc00af0f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34267,DS-db6b9067-7007-4162-81f7-11232a1abba2,DISK], DatanodeInfoWithStorage[127.0.0.1:41650,DS-1dd6da55-6bce-492c-b8bb-0b1dbd26d692,DISK], DatanodeInfoWithStorage[127.0.0.1:41368,DS-d2a5831d-d0e8-4837-82f4-3f49af216378,DISK], DatanodeInfoWithStorage[127.0.0.1:41929,DS-91640b91-2725-425f-b1a7-af854853b80a,DISK], DatanodeInfoWithStorage[127.0.0.1:34247,DS-89f231df-484f-4941-a302-0fd0bed15458,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-46192382-172.17.0.4-1595314292914:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36718,DS-fc23c0ae-94d1-4a59-b8cb-b93bb26501bd,DISK], DatanodeInfoWithStorage[127.0.0.1:45478,DS-ea4e78a7-ba21-491a-87a9-f2d89116d4ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33131,DS-453e1ffd-f5b2-49d1-8dc3-f15dc00af0f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34267,DS-db6b9067-7007-4162-81f7-11232a1abba2,DISK], DatanodeInfoWithStorage[127.0.0.1:41650,DS-1dd6da55-6bce-492c-b8bb-0b1dbd26d692,DISK], DatanodeInfoWithStorage[127.0.0.1:41368,DS-d2a5831d-d0e8-4837-82f4-3f49af216378,DISK], DatanodeInfoWithStorage[127.0.0.1:41929,DS-91640b91-2725-425f-b1a7-af854853b80a,DISK], DatanodeInfoWithStorage[127.0.0.1:34247,DS-89f231df-484f-4941-a302-0fd0bed15458,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery17(TestFileChecksum.java:493)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5040
