reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-763531181-172.17.0.19-1595349826117:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41963,DS-21003c39-f98e-458e-b1b4-802708651510,DISK], DatanodeInfoWithStorage[127.0.0.1:38875,DS-c15eb095-1989-424e-8bac-057616934711,DISK], DatanodeInfoWithStorage[127.0.0.1:34020,DS-6a320a2a-116a-40fc-abb9-6bacd81bd543,DISK], DatanodeInfoWithStorage[127.0.0.1:38304,DS-3909d512-f207-4173-ae07-bddcad597f08,DISK], DatanodeInfoWithStorage[127.0.0.1:40680,DS-8e56dda0-4a8c-428b-948c-5292cf3e0816,DISK], DatanodeInfoWithStorage[127.0.0.1:38158,DS-8466aa9c-015d-44ee-a441-387105cbb808,DISK], DatanodeInfoWithStorage[127.0.0.1:35566,DS-1f523610-9ce3-417c-800d-a2d3351a945d,DISK], DatanodeInfoWithStorage[127.0.0.1:37002,DS-f42c57d3-3480-4e0f-b206-8a2d3a937919,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-763531181-172.17.0.19-1595349826117:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41963,DS-21003c39-f98e-458e-b1b4-802708651510,DISK], DatanodeInfoWithStorage[127.0.0.1:38875,DS-c15eb095-1989-424e-8bac-057616934711,DISK], DatanodeInfoWithStorage[127.0.0.1:34020,DS-6a320a2a-116a-40fc-abb9-6bacd81bd543,DISK], DatanodeInfoWithStorage[127.0.0.1:38304,DS-3909d512-f207-4173-ae07-bddcad597f08,DISK], DatanodeInfoWithStorage[127.0.0.1:40680,DS-8e56dda0-4a8c-428b-948c-5292cf3e0816,DISK], DatanodeInfoWithStorage[127.0.0.1:38158,DS-8466aa9c-015d-44ee-a441-387105cbb808,DISK], DatanodeInfoWithStorage[127.0.0.1:35566,DS-1f523610-9ce3-417c-800d-a2d3351a945d,DISK], DatanodeInfoWithStorage[127.0.0.1:37002,DS-f42c57d3-3480-4e0f-b206-8a2d3a937919,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-557738923-172.17.0.19-1595350031841:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46868,DS-fc940bdf-37d9-4929-a62f-41801c05a6db,DISK], DatanodeInfoWithStorage[127.0.0.1:43740,DS-241e7054-1d0b-478e-b0be-0627f3b48101,DISK], DatanodeInfoWithStorage[127.0.0.1:42235,DS-2029c9b4-309f-4b97-bd47-d0cad16116a4,DISK], DatanodeInfoWithStorage[127.0.0.1:45263,DS-ccf12f7d-9855-4811-8ad0-c3ba04c367fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45868,DS-6dcfdec3-27e3-4afd-9d4e-42b818834e96,DISK], DatanodeInfoWithStorage[127.0.0.1:43460,DS-b93f3576-f0ae-4f82-9f42-66de4d9de0d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39350,DS-d0f3f9ba-bb83-4a11-b41b-fe322a72c43c,DISK], DatanodeInfoWithStorage[127.0.0.1:37548,DS-d6943a3e-ca2b-41fe-aff2-9bb4b6085bac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-557738923-172.17.0.19-1595350031841:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46868,DS-fc940bdf-37d9-4929-a62f-41801c05a6db,DISK], DatanodeInfoWithStorage[127.0.0.1:43740,DS-241e7054-1d0b-478e-b0be-0627f3b48101,DISK], DatanodeInfoWithStorage[127.0.0.1:42235,DS-2029c9b4-309f-4b97-bd47-d0cad16116a4,DISK], DatanodeInfoWithStorage[127.0.0.1:45263,DS-ccf12f7d-9855-4811-8ad0-c3ba04c367fb,DISK], DatanodeInfoWithStorage[127.0.0.1:45868,DS-6dcfdec3-27e3-4afd-9d4e-42b818834e96,DISK], DatanodeInfoWithStorage[127.0.0.1:43460,DS-b93f3576-f0ae-4f82-9f42-66de4d9de0d6,DISK], DatanodeInfoWithStorage[127.0.0.1:39350,DS-d0f3f9ba-bb83-4a11-b41b-fe322a72c43c,DISK], DatanodeInfoWithStorage[127.0.0.1:37548,DS-d6943a3e-ca2b-41fe-aff2-9bb4b6085bac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-704278789-172.17.0.19-1595350416608:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35939,DS-3a5302d8-45c5-450a-a9dc-b3f5a3ad4580,DISK], DatanodeInfoWithStorage[127.0.0.1:37124,DS-2dcb8084-88f1-4d32-895b-1d6a326ed883,DISK], DatanodeInfoWithStorage[127.0.0.1:42900,DS-a9857608-7cad-49cb-85b8-d10f5b725558,DISK], DatanodeInfoWithStorage[127.0.0.1:43142,DS-f7f5279b-3274-41bc-b513-1a3f26ad6c2c,DISK], DatanodeInfoWithStorage[127.0.0.1:41754,DS-cb051076-6071-4b4f-a4f7-4d7304791945,DISK], DatanodeInfoWithStorage[127.0.0.1:40747,DS-7b1c34c0-e7af-46ac-8756-06931213f175,DISK], DatanodeInfoWithStorage[127.0.0.1:38448,DS-84f034ca-029f-4230-861a-e502f53ce529,DISK], DatanodeInfoWithStorage[127.0.0.1:45407,DS-114dc34e-e594-4636-89c7-66a826b411c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-704278789-172.17.0.19-1595350416608:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35939,DS-3a5302d8-45c5-450a-a9dc-b3f5a3ad4580,DISK], DatanodeInfoWithStorage[127.0.0.1:37124,DS-2dcb8084-88f1-4d32-895b-1d6a326ed883,DISK], DatanodeInfoWithStorage[127.0.0.1:42900,DS-a9857608-7cad-49cb-85b8-d10f5b725558,DISK], DatanodeInfoWithStorage[127.0.0.1:43142,DS-f7f5279b-3274-41bc-b513-1a3f26ad6c2c,DISK], DatanodeInfoWithStorage[127.0.0.1:41754,DS-cb051076-6071-4b4f-a4f7-4d7304791945,DISK], DatanodeInfoWithStorage[127.0.0.1:40747,DS-7b1c34c0-e7af-46ac-8756-06931213f175,DISK], DatanodeInfoWithStorage[127.0.0.1:38448,DS-84f034ca-029f-4230-861a-e502f53ce529,DISK], DatanodeInfoWithStorage[127.0.0.1:45407,DS-114dc34e-e594-4636-89c7-66a826b411c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1509995431-172.17.0.19-1595350443085:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44941,DS-b3bd6a5a-6a8a-4796-98bc-f56d18e35087,DISK], DatanodeInfoWithStorage[127.0.0.1:35801,DS-f2335994-9cbf-45ec-818b-d7ee99bcf807,DISK], DatanodeInfoWithStorage[127.0.0.1:46180,DS-0d2d7c6e-b5bc-487a-91a7-896abc18c24e,DISK], DatanodeInfoWithStorage[127.0.0.1:42615,DS-f7ebebeb-791b-4f5b-b04e-c7ead2666a51,DISK], DatanodeInfoWithStorage[127.0.0.1:38345,DS-2e0c92ef-d6e5-4bc6-9fcd-975f3b26c961,DISK], DatanodeInfoWithStorage[127.0.0.1:46178,DS-585caebd-6302-4f22-a813-3718d16a75c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36570,DS-cdcf02b5-8be6-4955-92ec-c849c1497104,DISK], DatanodeInfoWithStorage[127.0.0.1:38283,DS-96157508-1c11-4344-a9f7-9123cd71073d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1509995431-172.17.0.19-1595350443085:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44941,DS-b3bd6a5a-6a8a-4796-98bc-f56d18e35087,DISK], DatanodeInfoWithStorage[127.0.0.1:35801,DS-f2335994-9cbf-45ec-818b-d7ee99bcf807,DISK], DatanodeInfoWithStorage[127.0.0.1:46180,DS-0d2d7c6e-b5bc-487a-91a7-896abc18c24e,DISK], DatanodeInfoWithStorage[127.0.0.1:42615,DS-f7ebebeb-791b-4f5b-b04e-c7ead2666a51,DISK], DatanodeInfoWithStorage[127.0.0.1:38345,DS-2e0c92ef-d6e5-4bc6-9fcd-975f3b26c961,DISK], DatanodeInfoWithStorage[127.0.0.1:46178,DS-585caebd-6302-4f22-a813-3718d16a75c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36570,DS-cdcf02b5-8be6-4955-92ec-c849c1497104,DISK], DatanodeInfoWithStorage[127.0.0.1:38283,DS-96157508-1c11-4344-a9f7-9123cd71073d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1995448722-172.17.0.19-1595350753952:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45009,DS-f6367119-6428-45ca-8179-4a301fe99655,DISK], DatanodeInfoWithStorage[127.0.0.1:43293,DS-0e73ee72-022a-489d-912c-d54cd93d641d,DISK], DatanodeInfoWithStorage[127.0.0.1:42471,DS-55968971-4e10-46d3-84a3-73f2345921fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46338,DS-670faf9d-27f1-47e1-82dd-ce4153374e0b,DISK], DatanodeInfoWithStorage[127.0.0.1:45775,DS-6b96677c-24bd-449a-a426-7c3bb6ead773,DISK], DatanodeInfoWithStorage[127.0.0.1:33859,DS-68fdee93-a21d-418f-80bf-5abfaa132777,DISK], DatanodeInfoWithStorage[127.0.0.1:43002,DS-5ba40115-71a3-4007-b5b4-fcc53d1949f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34387,DS-ccad9a49-eba5-40f2-8fd5-27fd3c0d0e8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1995448722-172.17.0.19-1595350753952:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45009,DS-f6367119-6428-45ca-8179-4a301fe99655,DISK], DatanodeInfoWithStorage[127.0.0.1:43293,DS-0e73ee72-022a-489d-912c-d54cd93d641d,DISK], DatanodeInfoWithStorage[127.0.0.1:42471,DS-55968971-4e10-46d3-84a3-73f2345921fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46338,DS-670faf9d-27f1-47e1-82dd-ce4153374e0b,DISK], DatanodeInfoWithStorage[127.0.0.1:45775,DS-6b96677c-24bd-449a-a426-7c3bb6ead773,DISK], DatanodeInfoWithStorage[127.0.0.1:33859,DS-68fdee93-a21d-418f-80bf-5abfaa132777,DISK], DatanodeInfoWithStorage[127.0.0.1:43002,DS-5ba40115-71a3-4007-b5b4-fcc53d1949f3,DISK], DatanodeInfoWithStorage[127.0.0.1:34387,DS-ccad9a49-eba5-40f2-8fd5-27fd3c0d0e8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1610503960-172.17.0.19-1595351691647:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45737,DS-3765046c-04be-49ea-ad47-78e839f449d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33268,DS-b27347fb-1d03-42d2-a5b9-d19440338183,DISK], DatanodeInfoWithStorage[127.0.0.1:33462,DS-229bbe4a-82e2-4d7c-b057-1963589565dc,DISK], DatanodeInfoWithStorage[127.0.0.1:34259,DS-29b2c9ad-25ee-4bc2-9c36-784b138f55fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44206,DS-ea27854a-2063-44a5-9df5-e6b924594a66,DISK], DatanodeInfoWithStorage[127.0.0.1:39743,DS-659f96dd-8582-4a1d-ad43-4fb52c114c58,DISK], DatanodeInfoWithStorage[127.0.0.1:38472,DS-7dd69e58-d725-420c-9ce9-2e9540fb35fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46393,DS-a558d695-764d-452b-9b69-383272d07aa9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1610503960-172.17.0.19-1595351691647:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45737,DS-3765046c-04be-49ea-ad47-78e839f449d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33268,DS-b27347fb-1d03-42d2-a5b9-d19440338183,DISK], DatanodeInfoWithStorage[127.0.0.1:33462,DS-229bbe4a-82e2-4d7c-b057-1963589565dc,DISK], DatanodeInfoWithStorage[127.0.0.1:34259,DS-29b2c9ad-25ee-4bc2-9c36-784b138f55fc,DISK], DatanodeInfoWithStorage[127.0.0.1:44206,DS-ea27854a-2063-44a5-9df5-e6b924594a66,DISK], DatanodeInfoWithStorage[127.0.0.1:39743,DS-659f96dd-8582-4a1d-ad43-4fb52c114c58,DISK], DatanodeInfoWithStorage[127.0.0.1:38472,DS-7dd69e58-d725-420c-9ce9-2e9540fb35fe,DISK], DatanodeInfoWithStorage[127.0.0.1:46393,DS-a558d695-764d-452b-9b69-383272d07aa9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-840714234-172.17.0.19-1595351720132:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43937,DS-3bd159b4-fe45-4b01-a1be-512653522c55,DISK], DatanodeInfoWithStorage[127.0.0.1:36067,DS-0d593a7e-2156-4f8a-a931-cb1f0e650c5b,DISK], DatanodeInfoWithStorage[127.0.0.1:46766,DS-9a4eae15-a86b-4ad2-83f5-3f68af48ab01,DISK], DatanodeInfoWithStorage[127.0.0.1:36356,DS-72fa881b-cec1-4ebf-b874-2aa0eb840dcd,DISK], DatanodeInfoWithStorage[127.0.0.1:41571,DS-ab7408ee-989e-4e22-92e0-0662b22cfd8a,DISK], DatanodeInfoWithStorage[127.0.0.1:37083,DS-8c24307a-5318-4a98-8c70-057dd605f7a3,DISK], DatanodeInfoWithStorage[127.0.0.1:38410,DS-54f78adc-9fa9-4925-89ea-7770e56d3fa3,DISK], DatanodeInfoWithStorage[127.0.0.1:42928,DS-f443b1ad-c90a-4a28-aea1-90a0f8ee483b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-840714234-172.17.0.19-1595351720132:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43937,DS-3bd159b4-fe45-4b01-a1be-512653522c55,DISK], DatanodeInfoWithStorage[127.0.0.1:36067,DS-0d593a7e-2156-4f8a-a931-cb1f0e650c5b,DISK], DatanodeInfoWithStorage[127.0.0.1:46766,DS-9a4eae15-a86b-4ad2-83f5-3f68af48ab01,DISK], DatanodeInfoWithStorage[127.0.0.1:36356,DS-72fa881b-cec1-4ebf-b874-2aa0eb840dcd,DISK], DatanodeInfoWithStorage[127.0.0.1:41571,DS-ab7408ee-989e-4e22-92e0-0662b22cfd8a,DISK], DatanodeInfoWithStorage[127.0.0.1:37083,DS-8c24307a-5318-4a98-8c70-057dd605f7a3,DISK], DatanodeInfoWithStorage[127.0.0.1:38410,DS-54f78adc-9fa9-4925-89ea-7770e56d3fa3,DISK], DatanodeInfoWithStorage[127.0.0.1:42928,DS-f443b1ad-c90a-4a28-aea1-90a0f8ee483b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1259059210-172.17.0.19-1595351784500:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43998,DS-50913173-d724-47ce-ac27-fa4a6cfd41d5,DISK], DatanodeInfoWithStorage[127.0.0.1:42726,DS-ba42b735-f549-4594-ae16-e1f5cbd8c877,DISK], DatanodeInfoWithStorage[127.0.0.1:40050,DS-60943d7e-e273-4c26-bbde-786bda3b366f,DISK], DatanodeInfoWithStorage[127.0.0.1:37980,DS-badddbab-70aa-4e80-8ff5-c96b978ad9c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40493,DS-99879b0d-e796-485d-bb5f-18b6052210cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45020,DS-711a1fd7-17d5-45cb-8b02-8633ba93e8a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35051,DS-2249baef-2a53-4dd9-9b2e-5b9d0887fec1,DISK], DatanodeInfoWithStorage[127.0.0.1:46340,DS-1f434578-56a0-4949-ba6c-ae99107a99c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1259059210-172.17.0.19-1595351784500:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43998,DS-50913173-d724-47ce-ac27-fa4a6cfd41d5,DISK], DatanodeInfoWithStorage[127.0.0.1:42726,DS-ba42b735-f549-4594-ae16-e1f5cbd8c877,DISK], DatanodeInfoWithStorage[127.0.0.1:40050,DS-60943d7e-e273-4c26-bbde-786bda3b366f,DISK], DatanodeInfoWithStorage[127.0.0.1:37980,DS-badddbab-70aa-4e80-8ff5-c96b978ad9c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40493,DS-99879b0d-e796-485d-bb5f-18b6052210cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45020,DS-711a1fd7-17d5-45cb-8b02-8633ba93e8a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35051,DS-2249baef-2a53-4dd9-9b2e-5b9d0887fec1,DISK], DatanodeInfoWithStorage[127.0.0.1:46340,DS-1f434578-56a0-4949-ba6c-ae99107a99c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-199955017-172.17.0.19-1595351813094:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37857,DS-2dcbf586-309c-490f-bc5c-7d31a0aa29d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42482,DS-d349f8c1-598c-455f-89bf-23499896c1b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36171,DS-47cf618a-c79f-49d9-a0a5-9d9a0d32ea5f,DISK], DatanodeInfoWithStorage[127.0.0.1:36213,DS-d4d2e633-1ba0-49b8-be09-6ec4c6481db8,DISK], DatanodeInfoWithStorage[127.0.0.1:44635,DS-62f17e7d-3b6a-43e5-8ae7-562c7419dd22,DISK], DatanodeInfoWithStorage[127.0.0.1:39241,DS-a1c2f572-8ca0-47d2-9b8d-e8a8edb383b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38667,DS-75af4beb-315b-4ed5-9ee4-b2d9eed5e88e,DISK], DatanodeInfoWithStorage[127.0.0.1:38238,DS-3907810c-a5b2-4ed5-a900-558cea79e6cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-199955017-172.17.0.19-1595351813094:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37857,DS-2dcbf586-309c-490f-bc5c-7d31a0aa29d0,DISK], DatanodeInfoWithStorage[127.0.0.1:42482,DS-d349f8c1-598c-455f-89bf-23499896c1b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36171,DS-47cf618a-c79f-49d9-a0a5-9d9a0d32ea5f,DISK], DatanodeInfoWithStorage[127.0.0.1:36213,DS-d4d2e633-1ba0-49b8-be09-6ec4c6481db8,DISK], DatanodeInfoWithStorage[127.0.0.1:44635,DS-62f17e7d-3b6a-43e5-8ae7-562c7419dd22,DISK], DatanodeInfoWithStorage[127.0.0.1:39241,DS-a1c2f572-8ca0-47d2-9b8d-e8a8edb383b5,DISK], DatanodeInfoWithStorage[127.0.0.1:38667,DS-75af4beb-315b-4ed5-9ee4-b2d9eed5e88e,DISK], DatanodeInfoWithStorage[127.0.0.1:38238,DS-3907810c-a5b2-4ed5-a900-558cea79e6cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-870693548-172.17.0.19-1595352174681:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41915,DS-9a707130-6a1e-4aa5-817b-78da2e1fbadb,DISK], DatanodeInfoWithStorage[127.0.0.1:41645,DS-25e7f13e-cd7d-4dff-82eb-24f8a485dd00,DISK], DatanodeInfoWithStorage[127.0.0.1:37751,DS-cac22879-4847-4bef-8f45-e3472d1fb236,DISK], DatanodeInfoWithStorage[127.0.0.1:40467,DS-d895718b-adcc-4185-89c6-ccf801111eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:33646,DS-9a4fbe16-a74d-4acc-9c25-b1f2d1af92b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34950,DS-b93edaaf-ebb5-4166-b8af-9c8a6cf74634,DISK], DatanodeInfoWithStorage[127.0.0.1:44414,DS-36aefbdf-5255-4878-8b0c-c1ce4c3d53a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34974,DS-4db18865-4320-478d-a1ae-5514ab96f0a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-870693548-172.17.0.19-1595352174681:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41915,DS-9a707130-6a1e-4aa5-817b-78da2e1fbadb,DISK], DatanodeInfoWithStorage[127.0.0.1:41645,DS-25e7f13e-cd7d-4dff-82eb-24f8a485dd00,DISK], DatanodeInfoWithStorage[127.0.0.1:37751,DS-cac22879-4847-4bef-8f45-e3472d1fb236,DISK], DatanodeInfoWithStorage[127.0.0.1:40467,DS-d895718b-adcc-4185-89c6-ccf801111eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:33646,DS-9a4fbe16-a74d-4acc-9c25-b1f2d1af92b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34950,DS-b93edaaf-ebb5-4166-b8af-9c8a6cf74634,DISK], DatanodeInfoWithStorage[127.0.0.1:44414,DS-36aefbdf-5255-4878-8b0c-c1ce4c3d53a5,DISK], DatanodeInfoWithStorage[127.0.0.1:34974,DS-4db18865-4320-478d-a1ae-5514ab96f0a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1194247766-172.17.0.19-1595352384581:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33042,DS-0feafa8a-5a5b-490a-8d94-490dc8b343bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41407,DS-63d14d7f-605d-4ca5-bef7-186a0b1fa998,DISK], DatanodeInfoWithStorage[127.0.0.1:37266,DS-3edc3115-103a-447f-a88e-86cdae4bee97,DISK], DatanodeInfoWithStorage[127.0.0.1:43061,DS-dd1085c7-c4dd-41da-89d5-55e3748dfcb2,DISK], DatanodeInfoWithStorage[127.0.0.1:45191,DS-0aa53532-9560-476a-882a-1b2875b53281,DISK], DatanodeInfoWithStorage[127.0.0.1:36665,DS-85077567-1312-4750-a3df-64d7cc576b18,DISK], DatanodeInfoWithStorage[127.0.0.1:33104,DS-5b8a8ff0-866a-43bd-b871-b2957d06ea62,DISK], DatanodeInfoWithStorage[127.0.0.1:42833,DS-562c7f39-6f57-44da-b05f-cb1253b71fc8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1194247766-172.17.0.19-1595352384581:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33042,DS-0feafa8a-5a5b-490a-8d94-490dc8b343bc,DISK], DatanodeInfoWithStorage[127.0.0.1:41407,DS-63d14d7f-605d-4ca5-bef7-186a0b1fa998,DISK], DatanodeInfoWithStorage[127.0.0.1:37266,DS-3edc3115-103a-447f-a88e-86cdae4bee97,DISK], DatanodeInfoWithStorage[127.0.0.1:43061,DS-dd1085c7-c4dd-41da-89d5-55e3748dfcb2,DISK], DatanodeInfoWithStorage[127.0.0.1:45191,DS-0aa53532-9560-476a-882a-1b2875b53281,DISK], DatanodeInfoWithStorage[127.0.0.1:36665,DS-85077567-1312-4750-a3df-64d7cc576b18,DISK], DatanodeInfoWithStorage[127.0.0.1:33104,DS-5b8a8ff0-866a-43bd-b871-b2957d06ea62,DISK], DatanodeInfoWithStorage[127.0.0.1:42833,DS-562c7f39-6f57-44da-b05f-cb1253b71fc8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-427627702-172.17.0.19-1595352980319:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36789,DS-7668473a-8944-4738-87fc-65e779baa4d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45409,DS-e1bcf780-3c93-4775-80a0-ccf05ca52ee8,DISK], DatanodeInfoWithStorage[127.0.0.1:34937,DS-ce7ffc55-5378-4893-95d0-ea5a7360165a,DISK], DatanodeInfoWithStorage[127.0.0.1:39108,DS-95c83cbd-4001-4ecc-96d0-3f253916abb7,DISK], DatanodeInfoWithStorage[127.0.0.1:43809,DS-1c18fdf4-be5c-4816-81a3-f9a9012d6d8e,DISK], DatanodeInfoWithStorage[127.0.0.1:37586,DS-748624ca-7cbf-4b9d-ab0e-f3bc21fe6e04,DISK], DatanodeInfoWithStorage[127.0.0.1:46573,DS-fdb80261-3b61-49d4-8766-b37ff8db2a15,DISK], DatanodeInfoWithStorage[127.0.0.1:35758,DS-e7d4761b-e9d1-4df8-be42-2ea20c9e0b85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-427627702-172.17.0.19-1595352980319:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36789,DS-7668473a-8944-4738-87fc-65e779baa4d3,DISK], DatanodeInfoWithStorage[127.0.0.1:45409,DS-e1bcf780-3c93-4775-80a0-ccf05ca52ee8,DISK], DatanodeInfoWithStorage[127.0.0.1:34937,DS-ce7ffc55-5378-4893-95d0-ea5a7360165a,DISK], DatanodeInfoWithStorage[127.0.0.1:39108,DS-95c83cbd-4001-4ecc-96d0-3f253916abb7,DISK], DatanodeInfoWithStorage[127.0.0.1:43809,DS-1c18fdf4-be5c-4816-81a3-f9a9012d6d8e,DISK], DatanodeInfoWithStorage[127.0.0.1:37586,DS-748624ca-7cbf-4b9d-ab0e-f3bc21fe6e04,DISK], DatanodeInfoWithStorage[127.0.0.1:46573,DS-fdb80261-3b61-49d4-8766-b37ff8db2a15,DISK], DatanodeInfoWithStorage[127.0.0.1:35758,DS-e7d4761b-e9d1-4df8-be42-2ea20c9e0b85,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1554614870-172.17.0.19-1595353911690:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35856,DS-ca284851-148b-4f57-92c6-47602138b176,DISK], DatanodeInfoWithStorage[127.0.0.1:40747,DS-3d74d99f-f53a-49a7-9204-3b06f54012e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36463,DS-52d2599a-f7c3-4e57-b679-c96101e5a7b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46772,DS-e8c1c5ee-5935-476c-97b0-c67adc73d6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46561,DS-a2938255-3066-44f4-8c2a-086a8e7aa279,DISK], DatanodeInfoWithStorage[127.0.0.1:37551,DS-31be83af-5ad2-42b5-b029-160c4a519b43,DISK], DatanodeInfoWithStorage[127.0.0.1:37231,DS-4b2a15bb-5fe4-40e1-aa32-5eeee16a18d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34209,DS-eb3e0184-0a30-4c53-9551-836b28da879b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1554614870-172.17.0.19-1595353911690:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35856,DS-ca284851-148b-4f57-92c6-47602138b176,DISK], DatanodeInfoWithStorage[127.0.0.1:40747,DS-3d74d99f-f53a-49a7-9204-3b06f54012e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36463,DS-52d2599a-f7c3-4e57-b679-c96101e5a7b8,DISK], DatanodeInfoWithStorage[127.0.0.1:46772,DS-e8c1c5ee-5935-476c-97b0-c67adc73d6c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46561,DS-a2938255-3066-44f4-8c2a-086a8e7aa279,DISK], DatanodeInfoWithStorage[127.0.0.1:37551,DS-31be83af-5ad2-42b5-b029-160c4a519b43,DISK], DatanodeInfoWithStorage[127.0.0.1:37231,DS-4b2a15bb-5fe4-40e1-aa32-5eeee16a18d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34209,DS-eb3e0184-0a30-4c53-9551-836b28da879b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-674684259-172.17.0.19-1595354040771:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35470,DS-c7b34912-8242-404c-96e6-21d47f465564,DISK], DatanodeInfoWithStorage[127.0.0.1:35614,DS-d5eb61d3-1acc-4d80-9836-3b2ac94e0a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:46788,DS-f457aaef-2262-4ed9-818d-ca3d1a81ed34,DISK], DatanodeInfoWithStorage[127.0.0.1:42597,DS-70cd3fc3-a880-48d3-bc4f-cd10867bb566,DISK], DatanodeInfoWithStorage[127.0.0.1:33966,DS-93e493f5-2287-4920-be24-96d6e528e4e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46139,DS-50f305a2-069a-401c-81f4-b96812944f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:33342,DS-37ff8eaf-d372-4486-9404-47edeaa46a66,DISK], DatanodeInfoWithStorage[127.0.0.1:42837,DS-4e942d82-5cad-4f6f-9dd7-204f178f5599,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-674684259-172.17.0.19-1595354040771:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35470,DS-c7b34912-8242-404c-96e6-21d47f465564,DISK], DatanodeInfoWithStorage[127.0.0.1:35614,DS-d5eb61d3-1acc-4d80-9836-3b2ac94e0a6e,DISK], DatanodeInfoWithStorage[127.0.0.1:46788,DS-f457aaef-2262-4ed9-818d-ca3d1a81ed34,DISK], DatanodeInfoWithStorage[127.0.0.1:42597,DS-70cd3fc3-a880-48d3-bc4f-cd10867bb566,DISK], DatanodeInfoWithStorage[127.0.0.1:33966,DS-93e493f5-2287-4920-be24-96d6e528e4e6,DISK], DatanodeInfoWithStorage[127.0.0.1:46139,DS-50f305a2-069a-401c-81f4-b96812944f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:33342,DS-37ff8eaf-d372-4486-9404-47edeaa46a66,DISK], DatanodeInfoWithStorage[127.0.0.1:42837,DS-4e942d82-5cad-4f6f-9dd7-204f178f5599,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.data.transfer.server.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1452426104-172.17.0.19-1595354340117:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35618,DS-5c2c121b-4015-4a3b-9c6b-2215ab980c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:42555,DS-009c84a3-823a-4d13-a045-cd17b5e00921,DISK], DatanodeInfoWithStorage[127.0.0.1:38877,DS-ded53c71-673c-43cf-a43f-682868af870e,DISK], DatanodeInfoWithStorage[127.0.0.1:40663,DS-953fe8bb-7477-4d26-afe1-ad8d21a5160c,DISK], DatanodeInfoWithStorage[127.0.0.1:38793,DS-e1ce9e62-2759-40c2-9e59-46b21e65a12c,DISK], DatanodeInfoWithStorage[127.0.0.1:39794,DS-2787540a-138c-423e-9190-04f7a59d5ad4,DISK], DatanodeInfoWithStorage[127.0.0.1:46857,DS-b33f027b-7819-4eff-8b11-d1d64fb795a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34600,DS-4ce9467f-fd11-42ae-8c2a-b8a3c31dfbb7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1452426104-172.17.0.19-1595354340117:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35618,DS-5c2c121b-4015-4a3b-9c6b-2215ab980c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:42555,DS-009c84a3-823a-4d13-a045-cd17b5e00921,DISK], DatanodeInfoWithStorage[127.0.0.1:38877,DS-ded53c71-673c-43cf-a43f-682868af870e,DISK], DatanodeInfoWithStorage[127.0.0.1:40663,DS-953fe8bb-7477-4d26-afe1-ad8d21a5160c,DISK], DatanodeInfoWithStorage[127.0.0.1:38793,DS-e1ce9e62-2759-40c2-9e59-46b21e65a12c,DISK], DatanodeInfoWithStorage[127.0.0.1:39794,DS-2787540a-138c-423e-9190-04f7a59d5ad4,DISK], DatanodeInfoWithStorage[127.0.0.1:46857,DS-b33f027b-7819-4eff-8b11-d1d64fb795a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34600,DS-4ce9467f-fd11-42ae-8c2a-b8a3c31dfbb7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5051
