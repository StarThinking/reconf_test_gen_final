reconf_parameter: dfs.client.cache.drop.behind.reads
component: hdfs:NameNode
v1: null
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.reads
component: hdfs:NameNode
v1: null
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1596718957-172.17.0.8-1596871850932:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42538,DS-c99afb39-e88c-44ed-aa32-47d0ff257e71,DISK], DatanodeInfoWithStorage[127.0.0.1:41639,DS-a9380e89-a0f0-4993-8b58-993265e483b6,DISK], DatanodeInfoWithStorage[127.0.0.1:37520,DS-59c1566a-1441-43a6-9b87-bad006df3065,DISK], DatanodeInfoWithStorage[127.0.0.1:35557,DS-617b31c1-654d-4bcf-b825-827025c48b8b,DISK], DatanodeInfoWithStorage[127.0.0.1:34382,DS-78af9348-002b-42dc-979f-52337cca54eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44907,DS-f60f64a6-e9eb-47a1-aa10-61365e5afa01,DISK], DatanodeInfoWithStorage[127.0.0.1:46791,DS-f381a20d-52ee-4c35-be47-84021be0cb8c,DISK], DatanodeInfoWithStorage[127.0.0.1:38274,DS-212425aa-cf01-4481-964a-0c101b0f9f28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1596718957-172.17.0.8-1596871850932:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42538,DS-c99afb39-e88c-44ed-aa32-47d0ff257e71,DISK], DatanodeInfoWithStorage[127.0.0.1:41639,DS-a9380e89-a0f0-4993-8b58-993265e483b6,DISK], DatanodeInfoWithStorage[127.0.0.1:37520,DS-59c1566a-1441-43a6-9b87-bad006df3065,DISK], DatanodeInfoWithStorage[127.0.0.1:35557,DS-617b31c1-654d-4bcf-b825-827025c48b8b,DISK], DatanodeInfoWithStorage[127.0.0.1:34382,DS-78af9348-002b-42dc-979f-52337cca54eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44907,DS-f60f64a6-e9eb-47a1-aa10-61365e5afa01,DISK], DatanodeInfoWithStorage[127.0.0.1:46791,DS-f381a20d-52ee-4c35-be47-84021be0cb8c,DISK], DatanodeInfoWithStorage[127.0.0.1:38274,DS-212425aa-cf01-4481-964a-0c101b0f9f28,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.reads
component: hdfs:NameNode
v1: null
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1172627426-172.17.0.8-1596872075306:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39417,DS-3d42b40c-7bb0-4a59-8843-a87cbc1eb406,DISK], DatanodeInfoWithStorage[127.0.0.1:43114,DS-031411d1-7534-4c12-87a9-fd7cebc00618,DISK], DatanodeInfoWithStorage[127.0.0.1:36711,DS-1efd06c3-cf3b-419a-bd3b-8da39b3c4453,DISK], DatanodeInfoWithStorage[127.0.0.1:35933,DS-5ff25f00-f3c8-4494-9df2-272124f83b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:42592,DS-314b9701-f8b2-43db-bbfc-92bc156ea7a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35008,DS-e028119e-7766-418b-b1e5-c38ddd0193af,DISK], DatanodeInfoWithStorage[127.0.0.1:44658,DS-df3434d1-c187-4b00-845c-a4a6dc01cf62,DISK], DatanodeInfoWithStorage[127.0.0.1:33226,DS-ca4dcc50-9a00-4457-bf7c-0e683b3876cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1172627426-172.17.0.8-1596872075306:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39417,DS-3d42b40c-7bb0-4a59-8843-a87cbc1eb406,DISK], DatanodeInfoWithStorage[127.0.0.1:43114,DS-031411d1-7534-4c12-87a9-fd7cebc00618,DISK], DatanodeInfoWithStorage[127.0.0.1:36711,DS-1efd06c3-cf3b-419a-bd3b-8da39b3c4453,DISK], DatanodeInfoWithStorage[127.0.0.1:35933,DS-5ff25f00-f3c8-4494-9df2-272124f83b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:42592,DS-314b9701-f8b2-43db-bbfc-92bc156ea7a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35008,DS-e028119e-7766-418b-b1e5-c38ddd0193af,DISK], DatanodeInfoWithStorage[127.0.0.1:44658,DS-df3434d1-c187-4b00-845c-a4a6dc01cf62,DISK], DatanodeInfoWithStorage[127.0.0.1:33226,DS-ca4dcc50-9a00-4457-bf7c-0e683b3876cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.reads
component: hdfs:NameNode
v1: null
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-989681778-172.17.0.8-1596872109464:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39798,DS-025addd3-f06b-45e5-b948-e92e8c827654,DISK], DatanodeInfoWithStorage[127.0.0.1:42011,DS-66d75274-03b4-4a19-aaf2-5dec5ab1862a,DISK], DatanodeInfoWithStorage[127.0.0.1:46122,DS-080cd711-7e4c-47d6-be60-bacaeb463074,DISK], DatanodeInfoWithStorage[127.0.0.1:37440,DS-109f1ea0-2595-4573-9382-fddaa77e6923,DISK], DatanodeInfoWithStorage[127.0.0.1:34362,DS-5f24265c-d686-4ba2-a3bb-c052b1576ae6,DISK], DatanodeInfoWithStorage[127.0.0.1:37557,DS-8bc2a53c-85ff-4211-9b54-e2d61e5c341b,DISK], DatanodeInfoWithStorage[127.0.0.1:33671,DS-4081ef75-928c-49e4-87a5-1ea5cc0f2bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:36987,DS-a9ab7752-922f-4ba4-9b70-523a148a6cd5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-989681778-172.17.0.8-1596872109464:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39798,DS-025addd3-f06b-45e5-b948-e92e8c827654,DISK], DatanodeInfoWithStorage[127.0.0.1:42011,DS-66d75274-03b4-4a19-aaf2-5dec5ab1862a,DISK], DatanodeInfoWithStorage[127.0.0.1:46122,DS-080cd711-7e4c-47d6-be60-bacaeb463074,DISK], DatanodeInfoWithStorage[127.0.0.1:37440,DS-109f1ea0-2595-4573-9382-fddaa77e6923,DISK], DatanodeInfoWithStorage[127.0.0.1:34362,DS-5f24265c-d686-4ba2-a3bb-c052b1576ae6,DISK], DatanodeInfoWithStorage[127.0.0.1:37557,DS-8bc2a53c-85ff-4211-9b54-e2d61e5c341b,DISK], DatanodeInfoWithStorage[127.0.0.1:33671,DS-4081ef75-928c-49e4-87a5-1ea5cc0f2bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:36987,DS-a9ab7752-922f-4ba4-9b70-523a148a6cd5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.reads
component: hdfs:NameNode
v1: null
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-24315803-172.17.0.8-1596872431505:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35082,DS-26332646-0768-42de-b6b2-fe9efecab2aa,DISK], DatanodeInfoWithStorage[127.0.0.1:46611,DS-05eb8fd5-ac77-43bd-b899-24e3227b9794,DISK], DatanodeInfoWithStorage[127.0.0.1:38191,DS-b425243b-8e17-46da-9e97-cc2dfabfe173,DISK], DatanodeInfoWithStorage[127.0.0.1:43792,DS-818d793c-093a-43a9-bf37-91cd41b115ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34808,DS-9fcb89bc-3c1c-4bd7-ad9f-8a63c81757c2,DISK], DatanodeInfoWithStorage[127.0.0.1:46040,DS-5e43bfda-c285-4e3f-b714-7394feac61ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37976,DS-c478dcb8-6d1d-4bbd-b5e2-2d9d411fd0b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44222,DS-475a3e58-526a-4c96-8bb2-e83afb01a28a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-24315803-172.17.0.8-1596872431505:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35082,DS-26332646-0768-42de-b6b2-fe9efecab2aa,DISK], DatanodeInfoWithStorage[127.0.0.1:46611,DS-05eb8fd5-ac77-43bd-b899-24e3227b9794,DISK], DatanodeInfoWithStorage[127.0.0.1:38191,DS-b425243b-8e17-46da-9e97-cc2dfabfe173,DISK], DatanodeInfoWithStorage[127.0.0.1:43792,DS-818d793c-093a-43a9-bf37-91cd41b115ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34808,DS-9fcb89bc-3c1c-4bd7-ad9f-8a63c81757c2,DISK], DatanodeInfoWithStorage[127.0.0.1:46040,DS-5e43bfda-c285-4e3f-b714-7394feac61ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37976,DS-c478dcb8-6d1d-4bbd-b5e2-2d9d411fd0b0,DISK], DatanodeInfoWithStorage[127.0.0.1:44222,DS-475a3e58-526a-4c96-8bb2-e83afb01a28a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.reads
component: hdfs:NameNode
v1: null
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-737880442-172.17.0.8-1596872795818:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41305,DS-062fd1c1-ad5f-4574-bf66-2a1efccc11c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33257,DS-172bece8-20c5-4501-8bad-0385268c3df5,DISK], DatanodeInfoWithStorage[127.0.0.1:39845,DS-859ca24f-c06a-4837-9aaa-d7581fc91eec,DISK], DatanodeInfoWithStorage[127.0.0.1:43449,DS-4dcb8fb0-3caa-4434-9862-ab246220ae8e,DISK], DatanodeInfoWithStorage[127.0.0.1:34229,DS-cf246c6d-e322-42f6-8ff1-24ef2294df1a,DISK], DatanodeInfoWithStorage[127.0.0.1:32879,DS-17847231-69a6-4e1c-bd66-aa19121ec61c,DISK], DatanodeInfoWithStorage[127.0.0.1:33511,DS-087a73bf-1c8a-4bed-b37c-db7ece154fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:44883,DS-4df3218d-f619-4bba-98a5-cdf5a54ab276,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-737880442-172.17.0.8-1596872795818:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41305,DS-062fd1c1-ad5f-4574-bf66-2a1efccc11c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33257,DS-172bece8-20c5-4501-8bad-0385268c3df5,DISK], DatanodeInfoWithStorage[127.0.0.1:39845,DS-859ca24f-c06a-4837-9aaa-d7581fc91eec,DISK], DatanodeInfoWithStorage[127.0.0.1:43449,DS-4dcb8fb0-3caa-4434-9862-ab246220ae8e,DISK], DatanodeInfoWithStorage[127.0.0.1:34229,DS-cf246c6d-e322-42f6-8ff1-24ef2294df1a,DISK], DatanodeInfoWithStorage[127.0.0.1:32879,DS-17847231-69a6-4e1c-bd66-aa19121ec61c,DISK], DatanodeInfoWithStorage[127.0.0.1:33511,DS-087a73bf-1c8a-4bed-b37c-db7ece154fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:44883,DS-4df3218d-f619-4bba-98a5-cdf5a54ab276,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.reads
component: hdfs:NameNode
v1: null
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-477365780-172.17.0.8-1596873015417:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34524,DS-9be578ee-7879-4aab-8db4-2ef601d1b413,DISK], DatanodeInfoWithStorage[127.0.0.1:43909,DS-2c653033-7f49-41e1-b2da-e6850d905253,DISK], DatanodeInfoWithStorage[127.0.0.1:37775,DS-e9d9a80d-1384-4051-8a30-f1df83f68257,DISK], DatanodeInfoWithStorage[127.0.0.1:36251,DS-f7f4db0b-ff22-4b2b-8096-3ea57bb6cc92,DISK], DatanodeInfoWithStorage[127.0.0.1:40060,DS-3bc992db-b329-43bd-810d-1a76b20cd154,DISK], DatanodeInfoWithStorage[127.0.0.1:39596,DS-52d33dc2-edef-4a97-b2e3-39b2c1f5dbd5,DISK], DatanodeInfoWithStorage[127.0.0.1:33506,DS-8583be00-3821-4fb9-958a-e249224eef2e,DISK], DatanodeInfoWithStorage[127.0.0.1:40556,DS-db3784d8-8e39-4b72-ac83-0c16239d6f12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-477365780-172.17.0.8-1596873015417:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34524,DS-9be578ee-7879-4aab-8db4-2ef601d1b413,DISK], DatanodeInfoWithStorage[127.0.0.1:43909,DS-2c653033-7f49-41e1-b2da-e6850d905253,DISK], DatanodeInfoWithStorage[127.0.0.1:37775,DS-e9d9a80d-1384-4051-8a30-f1df83f68257,DISK], DatanodeInfoWithStorage[127.0.0.1:36251,DS-f7f4db0b-ff22-4b2b-8096-3ea57bb6cc92,DISK], DatanodeInfoWithStorage[127.0.0.1:40060,DS-3bc992db-b329-43bd-810d-1a76b20cd154,DISK], DatanodeInfoWithStorage[127.0.0.1:39596,DS-52d33dc2-edef-4a97-b2e3-39b2c1f5dbd5,DISK], DatanodeInfoWithStorage[127.0.0.1:33506,DS-8583be00-3821-4fb9-958a-e249224eef2e,DISK], DatanodeInfoWithStorage[127.0.0.1:40556,DS-db3784d8-8e39-4b72-ac83-0c16239d6f12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.reads
component: hdfs:NameNode
v1: null
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1924121587-172.17.0.8-1596873055069:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44518,DS-2a8930bb-56ac-4c4d-aa52-c15d72e0eb63,DISK], DatanodeInfoWithStorage[127.0.0.1:46012,DS-abc33aae-3764-45ea-a590-6cd7b9c7e82a,DISK], DatanodeInfoWithStorage[127.0.0.1:45024,DS-0e05186f-7ba1-48c6-9033-cf3a09dd7e85,DISK], DatanodeInfoWithStorage[127.0.0.1:33838,DS-ff6873da-0813-4e2b-86d7-64b76859862d,DISK], DatanodeInfoWithStorage[127.0.0.1:43997,DS-75ecf1a8-0f83-4bab-9823-6f7e43534dd9,DISK], DatanodeInfoWithStorage[127.0.0.1:42720,DS-945614fa-e640-46ef-8977-9970d42acaca,DISK], DatanodeInfoWithStorage[127.0.0.1:39673,DS-fbe50ad4-7d84-4786-8d01-1895dab61bba,DISK], DatanodeInfoWithStorage[127.0.0.1:34117,DS-44daaadf-f87a-43bf-b48b-c41bdc17b14d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1924121587-172.17.0.8-1596873055069:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44518,DS-2a8930bb-56ac-4c4d-aa52-c15d72e0eb63,DISK], DatanodeInfoWithStorage[127.0.0.1:46012,DS-abc33aae-3764-45ea-a590-6cd7b9c7e82a,DISK], DatanodeInfoWithStorage[127.0.0.1:45024,DS-0e05186f-7ba1-48c6-9033-cf3a09dd7e85,DISK], DatanodeInfoWithStorage[127.0.0.1:33838,DS-ff6873da-0813-4e2b-86d7-64b76859862d,DISK], DatanodeInfoWithStorage[127.0.0.1:43997,DS-75ecf1a8-0f83-4bab-9823-6f7e43534dd9,DISK], DatanodeInfoWithStorage[127.0.0.1:42720,DS-945614fa-e640-46ef-8977-9970d42acaca,DISK], DatanodeInfoWithStorage[127.0.0.1:39673,DS-fbe50ad4-7d84-4786-8d01-1895dab61bba,DISK], DatanodeInfoWithStorage[127.0.0.1:34117,DS-44daaadf-f87a-43bf-b48b-c41bdc17b14d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.reads
component: hdfs:NameNode
v1: null
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-177766584-172.17.0.8-1596873126298:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40781,DS-0577f132-a97a-4342-8c7c-5a55c079efa9,DISK], DatanodeInfoWithStorage[127.0.0.1:45989,DS-10bfd907-9c72-4984-abe9-4bb1e721e488,DISK], DatanodeInfoWithStorage[127.0.0.1:46280,DS-ba4eaf18-6a0f-430d-9fab-b35817d72aed,DISK], DatanodeInfoWithStorage[127.0.0.1:33107,DS-4ffd34d6-041a-4d85-a052-6efb469841d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43921,DS-3483349e-90be-4884-840c-771b17bc49a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39539,DS-68e5342d-c82f-4311-a965-17610c768e08,DISK], DatanodeInfoWithStorage[127.0.0.1:41626,DS-93d19115-0be3-4405-ab56-8fed4977c1d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40947,DS-f93c158f-33fd-4f09-9df9-c4efc2678cd4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-177766584-172.17.0.8-1596873126298:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40781,DS-0577f132-a97a-4342-8c7c-5a55c079efa9,DISK], DatanodeInfoWithStorage[127.0.0.1:45989,DS-10bfd907-9c72-4984-abe9-4bb1e721e488,DISK], DatanodeInfoWithStorage[127.0.0.1:46280,DS-ba4eaf18-6a0f-430d-9fab-b35817d72aed,DISK], DatanodeInfoWithStorage[127.0.0.1:33107,DS-4ffd34d6-041a-4d85-a052-6efb469841d2,DISK], DatanodeInfoWithStorage[127.0.0.1:43921,DS-3483349e-90be-4884-840c-771b17bc49a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39539,DS-68e5342d-c82f-4311-a965-17610c768e08,DISK], DatanodeInfoWithStorage[127.0.0.1:41626,DS-93d19115-0be3-4405-ab56-8fed4977c1d4,DISK], DatanodeInfoWithStorage[127.0.0.1:40947,DS-f93c158f-33fd-4f09-9df9-c4efc2678cd4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.reads
component: hdfs:NameNode
v1: null
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-780214705-172.17.0.8-1596874138395:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39374,DS-20924c66-0a61-4f52-8d4f-c8492a434204,DISK], DatanodeInfoWithStorage[127.0.0.1:35975,DS-89112cc3-ffbd-4b02-8aaf-d15c43bfae3e,DISK], DatanodeInfoWithStorage[127.0.0.1:41339,DS-1322ab8e-480a-4240-b46e-ec12a38dceac,DISK], DatanodeInfoWithStorage[127.0.0.1:43228,DS-173e41cf-5ee4-4ecf-bd2b-7c799a7e0ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:32918,DS-e9ecbcae-24fb-4be2-bb3e-9f33e9653ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:46490,DS-0c5f74f7-d8e0-4e88-9f60-0f66415feea9,DISK], DatanodeInfoWithStorage[127.0.0.1:37830,DS-42f4eafd-7cb2-4af5-8f3a-e850e62f8107,DISK], DatanodeInfoWithStorage[127.0.0.1:38012,DS-1caac073-22d7-42c6-a134-cfd977da2f9d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-780214705-172.17.0.8-1596874138395:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39374,DS-20924c66-0a61-4f52-8d4f-c8492a434204,DISK], DatanodeInfoWithStorage[127.0.0.1:35975,DS-89112cc3-ffbd-4b02-8aaf-d15c43bfae3e,DISK], DatanodeInfoWithStorage[127.0.0.1:41339,DS-1322ab8e-480a-4240-b46e-ec12a38dceac,DISK], DatanodeInfoWithStorage[127.0.0.1:43228,DS-173e41cf-5ee4-4ecf-bd2b-7c799a7e0ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:32918,DS-e9ecbcae-24fb-4be2-bb3e-9f33e9653ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:46490,DS-0c5f74f7-d8e0-4e88-9f60-0f66415feea9,DISK], DatanodeInfoWithStorage[127.0.0.1:37830,DS-42f4eafd-7cb2-4af5-8f3a-e850e62f8107,DISK], DatanodeInfoWithStorage[127.0.0.1:38012,DS-1caac073-22d7-42c6-a134-cfd977da2f9d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.reads
component: hdfs:NameNode
v1: null
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1634251328-172.17.0.8-1596874415264:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35517,DS-1f3abfcc-e31f-493e-a14b-22ef3a55b648,DISK], DatanodeInfoWithStorage[127.0.0.1:36765,DS-0919b5fb-2113-45d6-b2b3-9a9a8c61dbdd,DISK], DatanodeInfoWithStorage[127.0.0.1:40367,DS-013ee043-efe7-4df2-9c4c-9e0c060ac919,DISK], DatanodeInfoWithStorage[127.0.0.1:33604,DS-36894b91-1dd7-4c6e-8f85-808e36d2d2c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46088,DS-dd22cf65-4a39-4dfe-a09d-d30e2b774809,DISK], DatanodeInfoWithStorage[127.0.0.1:43403,DS-327d4a01-a84c-4f70-9c72-00d0cc58fd35,DISK], DatanodeInfoWithStorage[127.0.0.1:33325,DS-613d1f09-2629-4807-badb-8f0cc3e70ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:35807,DS-21c72b61-bc2b-400e-958a-2126656e410c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1634251328-172.17.0.8-1596874415264:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35517,DS-1f3abfcc-e31f-493e-a14b-22ef3a55b648,DISK], DatanodeInfoWithStorage[127.0.0.1:36765,DS-0919b5fb-2113-45d6-b2b3-9a9a8c61dbdd,DISK], DatanodeInfoWithStorage[127.0.0.1:40367,DS-013ee043-efe7-4df2-9c4c-9e0c060ac919,DISK], DatanodeInfoWithStorage[127.0.0.1:33604,DS-36894b91-1dd7-4c6e-8f85-808e36d2d2c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46088,DS-dd22cf65-4a39-4dfe-a09d-d30e2b774809,DISK], DatanodeInfoWithStorage[127.0.0.1:43403,DS-327d4a01-a84c-4f70-9c72-00d0cc58fd35,DISK], DatanodeInfoWithStorage[127.0.0.1:33325,DS-613d1f09-2629-4807-badb-8f0cc3e70ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:35807,DS-21c72b61-bc2b-400e-958a-2126656e410c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.cache.drop.behind.reads
component: hdfs:NameNode
v1: null
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1299831857-172.17.0.8-1596874448829:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44538,DS-1feaddda-2fe3-452e-9090-cdb5254d402e,DISK], DatanodeInfoWithStorage[127.0.0.1:35372,DS-3519b76f-fded-4bbc-97ef-5048648e9c19,DISK], DatanodeInfoWithStorage[127.0.0.1:42277,DS-dbbc5452-d2d9-40f0-adc3-3742d919c3dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43868,DS-ff993a83-4e45-4c45-bf14-a0c5583e5058,DISK], DatanodeInfoWithStorage[127.0.0.1:44792,DS-cd45ff08-4e99-4eca-abd8-28259efd35f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41759,DS-12c2c5ad-bfa1-4c7e-89ec-6569aedc32c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33265,DS-a1bffbd7-05cb-4a04-8518-658627d44cce,DISK], DatanodeInfoWithStorage[127.0.0.1:36942,DS-4d07197c-78c0-4f70-b01d-8119b9f47de7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1299831857-172.17.0.8-1596874448829:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44538,DS-1feaddda-2fe3-452e-9090-cdb5254d402e,DISK], DatanodeInfoWithStorage[127.0.0.1:35372,DS-3519b76f-fded-4bbc-97ef-5048648e9c19,DISK], DatanodeInfoWithStorage[127.0.0.1:42277,DS-dbbc5452-d2d9-40f0-adc3-3742d919c3dc,DISK], DatanodeInfoWithStorage[127.0.0.1:43868,DS-ff993a83-4e45-4c45-bf14-a0c5583e5058,DISK], DatanodeInfoWithStorage[127.0.0.1:44792,DS-cd45ff08-4e99-4eca-abd8-28259efd35f5,DISK], DatanodeInfoWithStorage[127.0.0.1:41759,DS-12c2c5ad-bfa1-4c7e-89ec-6569aedc32c4,DISK], DatanodeInfoWithStorage[127.0.0.1:33265,DS-a1bffbd7-05cb-4a04-8518-658627d44cce,DISK], DatanodeInfoWithStorage[127.0.0.1:36942,DS-4d07197c-78c0-4f70-b01d-8119b9f47de7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.reads
component: hdfs:NameNode
v1: null
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2017840545-172.17.0.8-1596874668249:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33270,DS-a673aabd-19d5-482e-85b4-e814eaa593ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44194,DS-ce6e2cd4-e2a3-4de3-84c4-276fe56975b1,DISK], DatanodeInfoWithStorage[127.0.0.1:39265,DS-600eb26d-1d4b-4310-b332-00919648f6b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33709,DS-8e060cb1-772a-446b-bc50-787ecb3ec0a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44543,DS-5c896f32-76b6-41f3-be9c-ebe217e6decc,DISK], DatanodeInfoWithStorage[127.0.0.1:33059,DS-b6744cb7-4e05-4699-a9c2-811e6cb7c9d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40802,DS-d14d8708-fd9d-48e6-988b-7b6eab265f63,DISK], DatanodeInfoWithStorage[127.0.0.1:35241,DS-745c4564-5624-4aac-b57e-b136952c62ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2017840545-172.17.0.8-1596874668249:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33270,DS-a673aabd-19d5-482e-85b4-e814eaa593ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44194,DS-ce6e2cd4-e2a3-4de3-84c4-276fe56975b1,DISK], DatanodeInfoWithStorage[127.0.0.1:39265,DS-600eb26d-1d4b-4310-b332-00919648f6b6,DISK], DatanodeInfoWithStorage[127.0.0.1:33709,DS-8e060cb1-772a-446b-bc50-787ecb3ec0a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44543,DS-5c896f32-76b6-41f3-be9c-ebe217e6decc,DISK], DatanodeInfoWithStorage[127.0.0.1:33059,DS-b6744cb7-4e05-4699-a9c2-811e6cb7c9d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40802,DS-d14d8708-fd9d-48e6-988b-7b6eab265f63,DISK], DatanodeInfoWithStorage[127.0.0.1:35241,DS-745c4564-5624-4aac-b57e-b136952c62ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.reads
component: hdfs:NameNode
v1: null
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-398769895-172.17.0.8-1596874703487:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32957,DS-e63469d2-4f88-414d-8e40-6c2d405e5cdb,DISK], DatanodeInfoWithStorage[127.0.0.1:44595,DS-51e11490-5389-47b0-bce0-989aefa88532,DISK], DatanodeInfoWithStorage[127.0.0.1:43393,DS-f31b19d3-51f3-46f0-9d4c-eeeb7b728ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:34619,DS-47701004-8c8c-4dd9-b745-76e806e95c1a,DISK], DatanodeInfoWithStorage[127.0.0.1:40520,DS-dba82376-43b8-433b-bcb1-587dee68d95e,DISK], DatanodeInfoWithStorage[127.0.0.1:38839,DS-56af7ee1-8eda-4601-a300-2b65ab31c405,DISK], DatanodeInfoWithStorage[127.0.0.1:39638,DS-13ba3536-0587-4b5c-9754-3315b794576a,DISK], DatanodeInfoWithStorage[127.0.0.1:40080,DS-86d2fe94-0511-4767-8ce2-cafff34d4c75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-398769895-172.17.0.8-1596874703487:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32957,DS-e63469d2-4f88-414d-8e40-6c2d405e5cdb,DISK], DatanodeInfoWithStorage[127.0.0.1:44595,DS-51e11490-5389-47b0-bce0-989aefa88532,DISK], DatanodeInfoWithStorage[127.0.0.1:43393,DS-f31b19d3-51f3-46f0-9d4c-eeeb7b728ff7,DISK], DatanodeInfoWithStorage[127.0.0.1:34619,DS-47701004-8c8c-4dd9-b745-76e806e95c1a,DISK], DatanodeInfoWithStorage[127.0.0.1:40520,DS-dba82376-43b8-433b-bcb1-587dee68d95e,DISK], DatanodeInfoWithStorage[127.0.0.1:38839,DS-56af7ee1-8eda-4601-a300-2b65ab31c405,DISK], DatanodeInfoWithStorage[127.0.0.1:39638,DS-13ba3536-0587-4b5c-9754-3315b794576a,DISK], DatanodeInfoWithStorage[127.0.0.1:40080,DS-86d2fe94-0511-4767-8ce2-cafff34d4c75,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.reads
component: hdfs:NameNode
v1: null
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1856305634-172.17.0.8-1596875086098:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34444,DS-ee4ed6eb-b2b7-453b-a697-4045aece4496,DISK], DatanodeInfoWithStorage[127.0.0.1:43372,DS-002b062a-c510-4d53-bba7-ecf841cb1ec2,DISK], DatanodeInfoWithStorage[127.0.0.1:43346,DS-f1903b9b-b66e-4ba4-ba0e-9c2e68f93489,DISK], DatanodeInfoWithStorage[127.0.0.1:36371,DS-cf0d7de7-9de6-43ec-b7a0-6b503c1c87e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37732,DS-9f2f928a-0d52-4de6-bbce-bb60f7dd7165,DISK], DatanodeInfoWithStorage[127.0.0.1:36146,DS-1e6a5198-64bf-4512-a49c-910e05c04a27,DISK], DatanodeInfoWithStorage[127.0.0.1:37812,DS-01047101-b081-4927-aaf3-3694d1075de5,DISK], DatanodeInfoWithStorage[127.0.0.1:34604,DS-61fead06-778d-41bf-b579-392504f7c40c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1856305634-172.17.0.8-1596875086098:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34444,DS-ee4ed6eb-b2b7-453b-a697-4045aece4496,DISK], DatanodeInfoWithStorage[127.0.0.1:43372,DS-002b062a-c510-4d53-bba7-ecf841cb1ec2,DISK], DatanodeInfoWithStorage[127.0.0.1:43346,DS-f1903b9b-b66e-4ba4-ba0e-9c2e68f93489,DISK], DatanodeInfoWithStorage[127.0.0.1:36371,DS-cf0d7de7-9de6-43ec-b7a0-6b503c1c87e9,DISK], DatanodeInfoWithStorage[127.0.0.1:37732,DS-9f2f928a-0d52-4de6-bbce-bb60f7dd7165,DISK], DatanodeInfoWithStorage[127.0.0.1:36146,DS-1e6a5198-64bf-4512-a49c-910e05c04a27,DISK], DatanodeInfoWithStorage[127.0.0.1:37812,DS-01047101-b081-4927-aaf3-3694d1075de5,DISK], DatanodeInfoWithStorage[127.0.0.1:34604,DS-61fead06-778d-41bf-b579-392504f7c40c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.reads
component: hdfs:NameNode
v1: null
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1079496958-172.17.0.8-1596875245882:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45295,DS-7e9f7971-84ba-4cb0-9197-ab5d233ea893,DISK], DatanodeInfoWithStorage[127.0.0.1:35875,DS-96b02d48-25fb-4312-9286-aab85f324bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:33408,DS-bbc73bf5-ba4e-4154-a701-f47c5f80bdfc,DISK], DatanodeInfoWithStorage[127.0.0.1:42417,DS-3d2faa0f-0434-4c9e-aa16-29f18fb82f19,DISK], DatanodeInfoWithStorage[127.0.0.1:38620,DS-740096ad-a154-4b94-8378-3f1d57bd2fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:38372,DS-2007afe3-a6ae-44f4-8ff5-91ea4c00450f,DISK], DatanodeInfoWithStorage[127.0.0.1:44393,DS-c7bc8af4-b678-41ab-8bf7-98b47e460f34,DISK], DatanodeInfoWithStorage[127.0.0.1:38381,DS-fc441935-97a8-4725-ac82-5205b0439a06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1079496958-172.17.0.8-1596875245882:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45295,DS-7e9f7971-84ba-4cb0-9197-ab5d233ea893,DISK], DatanodeInfoWithStorage[127.0.0.1:35875,DS-96b02d48-25fb-4312-9286-aab85f324bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:33408,DS-bbc73bf5-ba4e-4154-a701-f47c5f80bdfc,DISK], DatanodeInfoWithStorage[127.0.0.1:42417,DS-3d2faa0f-0434-4c9e-aa16-29f18fb82f19,DISK], DatanodeInfoWithStorage[127.0.0.1:38620,DS-740096ad-a154-4b94-8378-3f1d57bd2fd1,DISK], DatanodeInfoWithStorage[127.0.0.1:38372,DS-2007afe3-a6ae-44f4-8ff5-91ea4c00450f,DISK], DatanodeInfoWithStorage[127.0.0.1:44393,DS-c7bc8af4-b678-41ab-8bf7-98b47e460f34,DISK], DatanodeInfoWithStorage[127.0.0.1:38381,DS-fc441935-97a8-4725-ac82-5205b0439a06,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.reads
component: hdfs:NameNode
v1: null
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-857151391-172.17.0.8-1596875313379:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39702,DS-c06b9de1-a13e-4ad7-99c0-96b4b68ab9df,DISK], DatanodeInfoWithStorage[127.0.0.1:33505,DS-6aac6d76-2343-4505-8761-fec75997b9c4,DISK], DatanodeInfoWithStorage[127.0.0.1:44284,DS-6c33e215-5a35-4b43-a89c-c2b37cf5517c,DISK], DatanodeInfoWithStorage[127.0.0.1:39401,DS-5efee22d-45d3-4aee-97d9-52f80bd6433b,DISK], DatanodeInfoWithStorage[127.0.0.1:45597,DS-4f9a6113-1b5b-45c3-a940-ad3f3267422e,DISK], DatanodeInfoWithStorage[127.0.0.1:46854,DS-534e0f82-152a-4b45-b305-925652cf1e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:35997,DS-491ec12b-61c4-4041-b0e2-0290dc56dd9a,DISK], DatanodeInfoWithStorage[127.0.0.1:40762,DS-921fc591-e341-42c9-878b-5d06863db3ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-857151391-172.17.0.8-1596875313379:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39702,DS-c06b9de1-a13e-4ad7-99c0-96b4b68ab9df,DISK], DatanodeInfoWithStorage[127.0.0.1:33505,DS-6aac6d76-2343-4505-8761-fec75997b9c4,DISK], DatanodeInfoWithStorage[127.0.0.1:44284,DS-6c33e215-5a35-4b43-a89c-c2b37cf5517c,DISK], DatanodeInfoWithStorage[127.0.0.1:39401,DS-5efee22d-45d3-4aee-97d9-52f80bd6433b,DISK], DatanodeInfoWithStorage[127.0.0.1:45597,DS-4f9a6113-1b5b-45c3-a940-ad3f3267422e,DISK], DatanodeInfoWithStorage[127.0.0.1:46854,DS-534e0f82-152a-4b45-b305-925652cf1e5e,DISK], DatanodeInfoWithStorage[127.0.0.1:35997,DS-491ec12b-61c4-4041-b0e2-0290dc56dd9a,DISK], DatanodeInfoWithStorage[127.0.0.1:40762,DS-921fc591-e341-42c9-878b-5d06863db3ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.reads
component: hdfs:NameNode
v1: null
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1041968036-172.17.0.8-1596875886411:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35385,DS-b83186fa-cc1e-4a11-bb73-23d2c1ac7e72,DISK], DatanodeInfoWithStorage[127.0.0.1:39710,DS-43ff6baf-cf3a-4910-888f-1068f592916a,DISK], DatanodeInfoWithStorage[127.0.0.1:35720,DS-b37ce7c1-0e50-474a-b292-b674aba64644,DISK], DatanodeInfoWithStorage[127.0.0.1:46230,DS-37ed7d0e-a412-486a-b405-7a2b4f3bf1fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37674,DS-e8eeed52-338d-4a0d-a32e-adf1e5be85a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45467,DS-97972741-edc1-428b-9c41-d71fa4ab4b7b,DISK], DatanodeInfoWithStorage[127.0.0.1:45983,DS-4df212d0-3533-4f39-8537-17559810947b,DISK], DatanodeInfoWithStorage[127.0.0.1:36053,DS-cffca8a0-126b-4619-840e-8db6a5f07cea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1041968036-172.17.0.8-1596875886411:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35385,DS-b83186fa-cc1e-4a11-bb73-23d2c1ac7e72,DISK], DatanodeInfoWithStorage[127.0.0.1:39710,DS-43ff6baf-cf3a-4910-888f-1068f592916a,DISK], DatanodeInfoWithStorage[127.0.0.1:35720,DS-b37ce7c1-0e50-474a-b292-b674aba64644,DISK], DatanodeInfoWithStorage[127.0.0.1:46230,DS-37ed7d0e-a412-486a-b405-7a2b4f3bf1fa,DISK], DatanodeInfoWithStorage[127.0.0.1:37674,DS-e8eeed52-338d-4a0d-a32e-adf1e5be85a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45467,DS-97972741-edc1-428b-9c41-d71fa4ab4b7b,DISK], DatanodeInfoWithStorage[127.0.0.1:45983,DS-4df212d0-3533-4f39-8537-17559810947b,DISK], DatanodeInfoWithStorage[127.0.0.1:36053,DS-cffca8a0-126b-4619-840e-8db6a5f07cea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.reads
component: hdfs:NameNode
v1: null
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1352210946-172.17.0.8-1596876002716:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45126,DS-c898a008-1ce7-4e91-a8c2-488f7109b927,DISK], DatanodeInfoWithStorage[127.0.0.1:41169,DS-0fa955c6-7866-431e-9c3c-563ba780c715,DISK], DatanodeInfoWithStorage[127.0.0.1:35820,DS-8717c4f0-4f12-46da-baa7-8f42b1434c47,DISK], DatanodeInfoWithStorage[127.0.0.1:41375,DS-aff420a7-7735-4686-bdaf-6d65bbe761cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39971,DS-8e8bafb6-4eec-498d-8575-d1fe11cbb97a,DISK], DatanodeInfoWithStorage[127.0.0.1:33532,DS-309bf7c4-f0db-4eb3-8c33-dc4b98d68d8a,DISK], DatanodeInfoWithStorage[127.0.0.1:43485,DS-f542df5d-caca-4695-aee8-dd55fadb3be6,DISK], DatanodeInfoWithStorage[127.0.0.1:44213,DS-a4c0b853-ff42-4efc-ac5d-8ade738a1b6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1352210946-172.17.0.8-1596876002716:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45126,DS-c898a008-1ce7-4e91-a8c2-488f7109b927,DISK], DatanodeInfoWithStorage[127.0.0.1:41169,DS-0fa955c6-7866-431e-9c3c-563ba780c715,DISK], DatanodeInfoWithStorage[127.0.0.1:35820,DS-8717c4f0-4f12-46da-baa7-8f42b1434c47,DISK], DatanodeInfoWithStorage[127.0.0.1:41375,DS-aff420a7-7735-4686-bdaf-6d65bbe761cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39971,DS-8e8bafb6-4eec-498d-8575-d1fe11cbb97a,DISK], DatanodeInfoWithStorage[127.0.0.1:33532,DS-309bf7c4-f0db-4eb3-8c33-dc4b98d68d8a,DISK], DatanodeInfoWithStorage[127.0.0.1:43485,DS-f542df5d-caca-4695-aee8-dd55fadb3be6,DISK], DatanodeInfoWithStorage[127.0.0.1:44213,DS-a4c0b853-ff42-4efc-ac5d-8ade738a1b6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.reads
component: hdfs:NameNode
v1: null
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1502496017-172.17.0.8-1596876460941:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46839,DS-61e2647b-972e-4268-b1ee-378a7b73fabe,DISK], DatanodeInfoWithStorage[127.0.0.1:38866,DS-c7a83397-9c65-4125-98d9-90d0e4ac021b,DISK], DatanodeInfoWithStorage[127.0.0.1:41315,DS-15a3a37a-e876-4fbd-abba-c9c9eef9d529,DISK], DatanodeInfoWithStorage[127.0.0.1:34371,DS-80eb3b83-e781-4c94-9399-a47369c45d29,DISK], DatanodeInfoWithStorage[127.0.0.1:37015,DS-7036069a-64f8-4339-8487-f9059515d18c,DISK], DatanodeInfoWithStorage[127.0.0.1:44174,DS-fd667f4b-063c-4cb8-a9fc-fc2a10355cf7,DISK], DatanodeInfoWithStorage[127.0.0.1:32899,DS-9fa33e79-d256-43d0-91cc-85f0a3439f0d,DISK], DatanodeInfoWithStorage[127.0.0.1:44359,DS-ed93774b-b678-4656-9431-a4d4b01eeed7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1502496017-172.17.0.8-1596876460941:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46839,DS-61e2647b-972e-4268-b1ee-378a7b73fabe,DISK], DatanodeInfoWithStorage[127.0.0.1:38866,DS-c7a83397-9c65-4125-98d9-90d0e4ac021b,DISK], DatanodeInfoWithStorage[127.0.0.1:41315,DS-15a3a37a-e876-4fbd-abba-c9c9eef9d529,DISK], DatanodeInfoWithStorage[127.0.0.1:34371,DS-80eb3b83-e781-4c94-9399-a47369c45d29,DISK], DatanodeInfoWithStorage[127.0.0.1:37015,DS-7036069a-64f8-4339-8487-f9059515d18c,DISK], DatanodeInfoWithStorage[127.0.0.1:44174,DS-fd667f4b-063c-4cb8-a9fc-fc2a10355cf7,DISK], DatanodeInfoWithStorage[127.0.0.1:32899,DS-9fa33e79-d256-43d0-91cc-85f0a3439f0d,DISK], DatanodeInfoWithStorage[127.0.0.1:44359,DS-ed93774b-b678-4656-9431-a4d4b01eeed7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.reads
component: hdfs:NameNode
v1: null
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-776963850-172.17.0.8-1596876891048:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38716,DS-9f4785ff-4a49-408d-a181-bfdd35ccaef4,DISK], DatanodeInfoWithStorage[127.0.0.1:40462,DS-7c44f84f-0c97-4540-a65a-f340b4ae69bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42626,DS-ca2b7183-20ea-4dae-a0df-67fb79dbf80d,DISK], DatanodeInfoWithStorage[127.0.0.1:41841,DS-91813b7a-6920-4f9f-8568-9586587e6d54,DISK], DatanodeInfoWithStorage[127.0.0.1:45588,DS-6cc4a46e-5dc6-4a24-be1f-71d1882069a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33675,DS-f6f2c029-29e6-4bf5-8366-b30c0279c139,DISK], DatanodeInfoWithStorage[127.0.0.1:45187,DS-7164ac55-b3f6-47fa-a354-7cacd20c99b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35439,DS-c2113cab-aaed-4157-ab36-149e24648e35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-776963850-172.17.0.8-1596876891048:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38716,DS-9f4785ff-4a49-408d-a181-bfdd35ccaef4,DISK], DatanodeInfoWithStorage[127.0.0.1:40462,DS-7c44f84f-0c97-4540-a65a-f340b4ae69bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42626,DS-ca2b7183-20ea-4dae-a0df-67fb79dbf80d,DISK], DatanodeInfoWithStorage[127.0.0.1:41841,DS-91813b7a-6920-4f9f-8568-9586587e6d54,DISK], DatanodeInfoWithStorage[127.0.0.1:45588,DS-6cc4a46e-5dc6-4a24-be1f-71d1882069a5,DISK], DatanodeInfoWithStorage[127.0.0.1:33675,DS-f6f2c029-29e6-4bf5-8366-b30c0279c139,DISK], DatanodeInfoWithStorage[127.0.0.1:45187,DS-7164ac55-b3f6-47fa-a354-7cacd20c99b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35439,DS-c2113cab-aaed-4157-ab36-149e24648e35,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.reads
component: hdfs:NameNode
v1: null
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1712534680-172.17.0.8-1596876967670:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43048,DS-a8d1397d-dade-468c-a2c3-6212b1874a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:36276,DS-0ea65af3-b931-497a-a7ac-5ffce42431f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34901,DS-52ecd186-ee2b-451d-a113-48a09f616acd,DISK], DatanodeInfoWithStorage[127.0.0.1:41200,DS-48ebf4e3-8efc-421b-9b35-2b797c7423e5,DISK], DatanodeInfoWithStorage[127.0.0.1:33025,DS-b1fffb5f-33de-456a-9c32-e04cbcd028c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37898,DS-68977a17-ead3-4e78-8b23-f6c8847e2647,DISK], DatanodeInfoWithStorage[127.0.0.1:32872,DS-5d819345-acbb-4a15-8f17-9ecfeca012ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34545,DS-f76ffa6f-add4-4394-bcd0-25e0fc308333,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1712534680-172.17.0.8-1596876967670:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43048,DS-a8d1397d-dade-468c-a2c3-6212b1874a9a,DISK], DatanodeInfoWithStorage[127.0.0.1:36276,DS-0ea65af3-b931-497a-a7ac-5ffce42431f8,DISK], DatanodeInfoWithStorage[127.0.0.1:34901,DS-52ecd186-ee2b-451d-a113-48a09f616acd,DISK], DatanodeInfoWithStorage[127.0.0.1:41200,DS-48ebf4e3-8efc-421b-9b35-2b797c7423e5,DISK], DatanodeInfoWithStorage[127.0.0.1:33025,DS-b1fffb5f-33de-456a-9c32-e04cbcd028c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37898,DS-68977a17-ead3-4e78-8b23-f6c8847e2647,DISK], DatanodeInfoWithStorage[127.0.0.1:32872,DS-5d819345-acbb-4a15-8f17-9ecfeca012ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34545,DS-f76ffa6f-add4-4394-bcd0-25e0fc308333,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.reads
component: hdfs:NameNode
v1: null
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1658623577-172.17.0.8-1596877284611:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39599,DS-3a477ff2-2fe0-4ec3-82ef-56b8c721bb5d,DISK], DatanodeInfoWithStorage[127.0.0.1:35851,DS-eafcd522-783a-43cf-ac49-3c1fb15a3af7,DISK], DatanodeInfoWithStorage[127.0.0.1:36307,DS-131e111e-4da5-467c-a0ee-b9508cfc2b57,DISK], DatanodeInfoWithStorage[127.0.0.1:33204,DS-fd8dddf3-b4da-43b2-af3b-787022a05bce,DISK], DatanodeInfoWithStorage[127.0.0.1:40148,DS-cfa3d58e-74ed-4545-ae47-63ef1cba9d61,DISK], DatanodeInfoWithStorage[127.0.0.1:43365,DS-bee7a937-fdbe-4ab3-8b0b-6807ed069cea,DISK], DatanodeInfoWithStorage[127.0.0.1:36049,DS-71cea608-6ab3-4fac-aa87-d9ae655fcddf,DISK], DatanodeInfoWithStorage[127.0.0.1:43316,DS-0525d0e3-0417-4199-9a19-3da5c24d2693,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1658623577-172.17.0.8-1596877284611:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39599,DS-3a477ff2-2fe0-4ec3-82ef-56b8c721bb5d,DISK], DatanodeInfoWithStorage[127.0.0.1:35851,DS-eafcd522-783a-43cf-ac49-3c1fb15a3af7,DISK], DatanodeInfoWithStorage[127.0.0.1:36307,DS-131e111e-4da5-467c-a0ee-b9508cfc2b57,DISK], DatanodeInfoWithStorage[127.0.0.1:33204,DS-fd8dddf3-b4da-43b2-af3b-787022a05bce,DISK], DatanodeInfoWithStorage[127.0.0.1:40148,DS-cfa3d58e-74ed-4545-ae47-63ef1cba9d61,DISK], DatanodeInfoWithStorage[127.0.0.1:43365,DS-bee7a937-fdbe-4ab3-8b0b-6807ed069cea,DISK], DatanodeInfoWithStorage[127.0.0.1:36049,DS-71cea608-6ab3-4fac-aa87-d9ae655fcddf,DISK], DatanodeInfoWithStorage[127.0.0.1:43316,DS-0525d0e3-0417-4199-9a19-3da5c24d2693,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 16 out of 50
result: false positive !!!
Total execution time in seconds : 5591
