reconf_parameter: dfs.client.read.shortcircuit
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-32444102-172.17.0.14-1595289263459:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33582,DS-f43e3add-dc20-4677-b991-94c0a2e71591,DISK], DatanodeInfoWithStorage[127.0.0.1:43677,DS-0243418e-8d38-4505-953c-84dfc7664056,DISK], DatanodeInfoWithStorage[127.0.0.1:45866,DS-1386f68d-a2ea-4f5f-b6a4-10aae1362062,DISK], DatanodeInfoWithStorage[127.0.0.1:41373,DS-1a35e064-2554-4f95-8f63-601708e05fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:42072,DS-8becb836-843e-4155-bf57-65431ca7622a,DISK], DatanodeInfoWithStorage[127.0.0.1:33281,DS-40f898a1-ae45-4abd-aa44-f25968c9c205,DISK], DatanodeInfoWithStorage[127.0.0.1:45574,DS-87c337ba-a6cf-4e94-858c-a677dce81b73,DISK], DatanodeInfoWithStorage[127.0.0.1:34292,DS-ea1df265-6e56-4a18-84b2-ec71d5dc83a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-32444102-172.17.0.14-1595289263459:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33582,DS-f43e3add-dc20-4677-b991-94c0a2e71591,DISK], DatanodeInfoWithStorage[127.0.0.1:43677,DS-0243418e-8d38-4505-953c-84dfc7664056,DISK], DatanodeInfoWithStorage[127.0.0.1:45866,DS-1386f68d-a2ea-4f5f-b6a4-10aae1362062,DISK], DatanodeInfoWithStorage[127.0.0.1:41373,DS-1a35e064-2554-4f95-8f63-601708e05fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:42072,DS-8becb836-843e-4155-bf57-65431ca7622a,DISK], DatanodeInfoWithStorage[127.0.0.1:33281,DS-40f898a1-ae45-4abd-aa44-f25968c9c205,DISK], DatanodeInfoWithStorage[127.0.0.1:45574,DS-87c337ba-a6cf-4e94-858c-a677dce81b73,DISK], DatanodeInfoWithStorage[127.0.0.1:34292,DS-ea1df265-6e56-4a18-84b2-ec71d5dc83a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1487204649-172.17.0.14-1595289664262:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44128,DS-e70c2c59-ee06-4297-a257-61683b6dbfa3,DISK], DatanodeInfoWithStorage[127.0.0.1:43095,DS-13a39d99-2b19-4332-9616-44b1038a5e51,DISK], DatanodeInfoWithStorage[127.0.0.1:37285,DS-0a3b28f4-a32c-4763-96bb-2c533d05f476,DISK], DatanodeInfoWithStorage[127.0.0.1:42193,DS-553836c0-f376-49d4-9562-2dbd6784007e,DISK], DatanodeInfoWithStorage[127.0.0.1:35151,DS-240752b5-4fcd-4542-8b90-63742a73ad05,DISK], DatanodeInfoWithStorage[127.0.0.1:36190,DS-919fe5cf-243f-472c-a99e-c1cb7eef4ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:44516,DS-fd88d80e-2ec1-44be-b233-9c9219171afd,DISK], DatanodeInfoWithStorage[127.0.0.1:36979,DS-02a661f1-7572-4ff1-85b0-3474e030688b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1487204649-172.17.0.14-1595289664262:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44128,DS-e70c2c59-ee06-4297-a257-61683b6dbfa3,DISK], DatanodeInfoWithStorage[127.0.0.1:43095,DS-13a39d99-2b19-4332-9616-44b1038a5e51,DISK], DatanodeInfoWithStorage[127.0.0.1:37285,DS-0a3b28f4-a32c-4763-96bb-2c533d05f476,DISK], DatanodeInfoWithStorage[127.0.0.1:42193,DS-553836c0-f376-49d4-9562-2dbd6784007e,DISK], DatanodeInfoWithStorage[127.0.0.1:35151,DS-240752b5-4fcd-4542-8b90-63742a73ad05,DISK], DatanodeInfoWithStorage[127.0.0.1:36190,DS-919fe5cf-243f-472c-a99e-c1cb7eef4ed1,DISK], DatanodeInfoWithStorage[127.0.0.1:44516,DS-fd88d80e-2ec1-44be-b233-9c9219171afd,DISK], DatanodeInfoWithStorage[127.0.0.1:36979,DS-02a661f1-7572-4ff1-85b0-3474e030688b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1951491389-172.17.0.14-1595289812969:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34718,DS-5e67dbc7-7d0b-4c05-bf98-d3e8b8b4c1cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40532,DS-8e72751d-142c-45e2-a56a-02f9104a97e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42579,DS-7a41c3f9-4b98-48aa-87f1-97810946704e,DISK], DatanodeInfoWithStorage[127.0.0.1:36354,DS-f7d47fe4-51f8-4549-b950-1e9045bb4035,DISK], DatanodeInfoWithStorage[127.0.0.1:34101,DS-3cac4032-7e72-45d9-882a-c78a0bba375f,DISK], DatanodeInfoWithStorage[127.0.0.1:33124,DS-8f831afa-3911-434c-b30b-761caf891edf,DISK], DatanodeInfoWithStorage[127.0.0.1:41338,DS-8082d976-9c7e-4e72-8d68-f81fe914d5e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35539,DS-d248d094-6875-4e1b-b5ee-9fea293a4c6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1951491389-172.17.0.14-1595289812969:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34718,DS-5e67dbc7-7d0b-4c05-bf98-d3e8b8b4c1cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40532,DS-8e72751d-142c-45e2-a56a-02f9104a97e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42579,DS-7a41c3f9-4b98-48aa-87f1-97810946704e,DISK], DatanodeInfoWithStorage[127.0.0.1:36354,DS-f7d47fe4-51f8-4549-b950-1e9045bb4035,DISK], DatanodeInfoWithStorage[127.0.0.1:34101,DS-3cac4032-7e72-45d9-882a-c78a0bba375f,DISK], DatanodeInfoWithStorage[127.0.0.1:33124,DS-8f831afa-3911-434c-b30b-761caf891edf,DISK], DatanodeInfoWithStorage[127.0.0.1:41338,DS-8082d976-9c7e-4e72-8d68-f81fe914d5e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35539,DS-d248d094-6875-4e1b-b5ee-9fea293a4c6c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1701988004-172.17.0.14-1595290324465:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43398,DS-9f9ab8d2-10c2-4ff5-84ad-9833cb5b8cec,DISK], DatanodeInfoWithStorage[127.0.0.1:43728,DS-8413681e-1e39-4507-b0fb-2536a514b682,DISK], DatanodeInfoWithStorage[127.0.0.1:42996,DS-d905764b-66ee-4820-bf8d-91c19f04b64f,DISK], DatanodeInfoWithStorage[127.0.0.1:36541,DS-e3d99062-f42e-42f2-aedf-fecdccc174f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39676,DS-49101d64-f2bd-4ac1-b2c0-01287254c12f,DISK], DatanodeInfoWithStorage[127.0.0.1:40558,DS-9ac10c2e-098a-4be7-9a4d-222a07d2eb84,DISK], DatanodeInfoWithStorage[127.0.0.1:38120,DS-2c1569f5-aca3-45bc-b2a9-11744132410c,DISK], DatanodeInfoWithStorage[127.0.0.1:39460,DS-4ce641f3-00ba-4509-8848-9e74d4ddb99a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1701988004-172.17.0.14-1595290324465:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43398,DS-9f9ab8d2-10c2-4ff5-84ad-9833cb5b8cec,DISK], DatanodeInfoWithStorage[127.0.0.1:43728,DS-8413681e-1e39-4507-b0fb-2536a514b682,DISK], DatanodeInfoWithStorage[127.0.0.1:42996,DS-d905764b-66ee-4820-bf8d-91c19f04b64f,DISK], DatanodeInfoWithStorage[127.0.0.1:36541,DS-e3d99062-f42e-42f2-aedf-fecdccc174f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39676,DS-49101d64-f2bd-4ac1-b2c0-01287254c12f,DISK], DatanodeInfoWithStorage[127.0.0.1:40558,DS-9ac10c2e-098a-4be7-9a4d-222a07d2eb84,DISK], DatanodeInfoWithStorage[127.0.0.1:38120,DS-2c1569f5-aca3-45bc-b2a9-11744132410c,DISK], DatanodeInfoWithStorage[127.0.0.1:39460,DS-4ce641f3-00ba-4509-8848-9e74d4ddb99a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-577369159-172.17.0.14-1595290397946:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45402,DS-fda4f4fd-ac5c-40d8-b9d6-9d18ef1ffe60,DISK], DatanodeInfoWithStorage[127.0.0.1:34399,DS-1a375af5-c2f9-4974-aab9-eb5c994096fc,DISK], DatanodeInfoWithStorage[127.0.0.1:41021,DS-a27b70ac-5450-4234-a409-26d6a36a024c,DISK], DatanodeInfoWithStorage[127.0.0.1:35251,DS-92e22115-eda8-440d-8b58-070e990acd1b,DISK], DatanodeInfoWithStorage[127.0.0.1:43270,DS-42700f86-f99a-4d2d-8e43-b50b1c253b12,DISK], DatanodeInfoWithStorage[127.0.0.1:42875,DS-aa8be9e6-eba0-45e8-a885-e040ed6a2dc1,DISK], DatanodeInfoWithStorage[127.0.0.1:37759,DS-40f18797-da51-45f9-b556-820e95e2d390,DISK], DatanodeInfoWithStorage[127.0.0.1:36926,DS-dd07373d-4cb9-4bea-90f6-8c2d902685f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-577369159-172.17.0.14-1595290397946:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45402,DS-fda4f4fd-ac5c-40d8-b9d6-9d18ef1ffe60,DISK], DatanodeInfoWithStorage[127.0.0.1:34399,DS-1a375af5-c2f9-4974-aab9-eb5c994096fc,DISK], DatanodeInfoWithStorage[127.0.0.1:41021,DS-a27b70ac-5450-4234-a409-26d6a36a024c,DISK], DatanodeInfoWithStorage[127.0.0.1:35251,DS-92e22115-eda8-440d-8b58-070e990acd1b,DISK], DatanodeInfoWithStorage[127.0.0.1:43270,DS-42700f86-f99a-4d2d-8e43-b50b1c253b12,DISK], DatanodeInfoWithStorage[127.0.0.1:42875,DS-aa8be9e6-eba0-45e8-a885-e040ed6a2dc1,DISK], DatanodeInfoWithStorage[127.0.0.1:37759,DS-40f18797-da51-45f9-b556-820e95e2d390,DISK], DatanodeInfoWithStorage[127.0.0.1:36926,DS-dd07373d-4cb9-4bea-90f6-8c2d902685f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-876192279-172.17.0.14-1595290726567:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44213,DS-a88eb1fb-0783-477a-9d80-a30c6a3bcd0f,DISK], DatanodeInfoWithStorage[127.0.0.1:33440,DS-7be5608c-cae8-40f6-a54a-ac4269eff5ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37607,DS-cafa0f02-c689-4bdb-a6ec-800ea2562c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:41531,DS-fd8dcf9b-3165-4408-b8e6-98e354e2caeb,DISK], DatanodeInfoWithStorage[127.0.0.1:34801,DS-7a703515-1410-47f9-aa8b-0da214882f2f,DISK], DatanodeInfoWithStorage[127.0.0.1:42342,DS-fcb2b497-b0b0-406c-b110-ef431db2b0f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37161,DS-73ad0899-0618-4e41-ac51-b6fcef978abc,DISK], DatanodeInfoWithStorage[127.0.0.1:45288,DS-0bae61bc-a025-493b-96bb-53256eb116bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-876192279-172.17.0.14-1595290726567:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44213,DS-a88eb1fb-0783-477a-9d80-a30c6a3bcd0f,DISK], DatanodeInfoWithStorage[127.0.0.1:33440,DS-7be5608c-cae8-40f6-a54a-ac4269eff5ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37607,DS-cafa0f02-c689-4bdb-a6ec-800ea2562c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:41531,DS-fd8dcf9b-3165-4408-b8e6-98e354e2caeb,DISK], DatanodeInfoWithStorage[127.0.0.1:34801,DS-7a703515-1410-47f9-aa8b-0da214882f2f,DISK], DatanodeInfoWithStorage[127.0.0.1:42342,DS-fcb2b497-b0b0-406c-b110-ef431db2b0f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37161,DS-73ad0899-0618-4e41-ac51-b6fcef978abc,DISK], DatanodeInfoWithStorage[127.0.0.1:45288,DS-0bae61bc-a025-493b-96bb-53256eb116bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2090651373-172.17.0.14-1595291056780:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44071,DS-d7980252-4921-4120-ba5d-30c46787e321,DISK], DatanodeInfoWithStorage[127.0.0.1:46662,DS-ff2fc11f-00b2-4ed8-8fa5-9739d4b579c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40853,DS-699443d2-d4a3-43ff-a473-d86d45c6bbe4,DISK], DatanodeInfoWithStorage[127.0.0.1:33726,DS-df8c3eea-38ab-4098-a78b-15963d2c80d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38486,DS-c860b94d-aeda-438d-92a0-a95ccc985d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:36104,DS-006df296-96e5-4030-b592-09dd5e02cb61,DISK], DatanodeInfoWithStorage[127.0.0.1:35649,DS-4e97be2d-30e3-4712-9711-71881f62178e,DISK], DatanodeInfoWithStorage[127.0.0.1:34169,DS-0b2d0cc3-8810-4cba-910c-ee407aa951be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2090651373-172.17.0.14-1595291056780:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44071,DS-d7980252-4921-4120-ba5d-30c46787e321,DISK], DatanodeInfoWithStorage[127.0.0.1:46662,DS-ff2fc11f-00b2-4ed8-8fa5-9739d4b579c8,DISK], DatanodeInfoWithStorage[127.0.0.1:40853,DS-699443d2-d4a3-43ff-a473-d86d45c6bbe4,DISK], DatanodeInfoWithStorage[127.0.0.1:33726,DS-df8c3eea-38ab-4098-a78b-15963d2c80d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38486,DS-c860b94d-aeda-438d-92a0-a95ccc985d5f,DISK], DatanodeInfoWithStorage[127.0.0.1:36104,DS-006df296-96e5-4030-b592-09dd5e02cb61,DISK], DatanodeInfoWithStorage[127.0.0.1:35649,DS-4e97be2d-30e3-4712-9711-71881f62178e,DISK], DatanodeInfoWithStorage[127.0.0.1:34169,DS-0b2d0cc3-8810-4cba-910c-ee407aa951be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1765043701-172.17.0.14-1595291613677:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38992,DS-30b1149b-11b6-4351-b4e9-8e7a1e1e2193,DISK], DatanodeInfoWithStorage[127.0.0.1:38789,DS-7861002a-de75-440c-b71d-2cfd15850a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:43570,DS-d18d7c4d-f106-49da-8462-0d7909fa2735,DISK], DatanodeInfoWithStorage[127.0.0.1:36130,DS-c61a16b4-3486-41c2-bbad-766632fdbe12,DISK], DatanodeInfoWithStorage[127.0.0.1:34348,DS-0db3fb8d-512c-40e2-a3a3-97dd8350b138,DISK], DatanodeInfoWithStorage[127.0.0.1:40813,DS-02434c65-8c82-449b-82b4-ef361d2543a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41303,DS-5513108c-3f5c-4175-ab93-28c4ed2cb2c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43144,DS-ce46789f-4d75-49ae-8dee-254bc70818df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1765043701-172.17.0.14-1595291613677:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38992,DS-30b1149b-11b6-4351-b4e9-8e7a1e1e2193,DISK], DatanodeInfoWithStorage[127.0.0.1:38789,DS-7861002a-de75-440c-b71d-2cfd15850a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:43570,DS-d18d7c4d-f106-49da-8462-0d7909fa2735,DISK], DatanodeInfoWithStorage[127.0.0.1:36130,DS-c61a16b4-3486-41c2-bbad-766632fdbe12,DISK], DatanodeInfoWithStorage[127.0.0.1:34348,DS-0db3fb8d-512c-40e2-a3a3-97dd8350b138,DISK], DatanodeInfoWithStorage[127.0.0.1:40813,DS-02434c65-8c82-449b-82b4-ef361d2543a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41303,DS-5513108c-3f5c-4175-ab93-28c4ed2cb2c9,DISK], DatanodeInfoWithStorage[127.0.0.1:43144,DS-ce46789f-4d75-49ae-8dee-254bc70818df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-766527755-172.17.0.14-1595291756104:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42303,DS-975aa29f-ceed-4ba2-8402-2f6007d2d768,DISK], DatanodeInfoWithStorage[127.0.0.1:43286,DS-eca84750-43f3-4aa4-9d86-3c217add1d08,DISK], DatanodeInfoWithStorage[127.0.0.1:39608,DS-acb8df65-7507-40b6-ba08-b9417cbac95e,DISK], DatanodeInfoWithStorage[127.0.0.1:38972,DS-6df84542-ef92-4fec-841a-1273cbca649d,DISK], DatanodeInfoWithStorage[127.0.0.1:33243,DS-fce69642-9bed-435c-b211-a66cf81e3ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:46631,DS-9cf4d361-2245-4312-929d-26b26a9b6261,DISK], DatanodeInfoWithStorage[127.0.0.1:34751,DS-c6f41c1b-097b-4863-a7b8-a5e394e34d79,DISK], DatanodeInfoWithStorage[127.0.0.1:34947,DS-672f1d0f-b1df-41e6-a021-7f1ddbdd70c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-766527755-172.17.0.14-1595291756104:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42303,DS-975aa29f-ceed-4ba2-8402-2f6007d2d768,DISK], DatanodeInfoWithStorage[127.0.0.1:43286,DS-eca84750-43f3-4aa4-9d86-3c217add1d08,DISK], DatanodeInfoWithStorage[127.0.0.1:39608,DS-acb8df65-7507-40b6-ba08-b9417cbac95e,DISK], DatanodeInfoWithStorage[127.0.0.1:38972,DS-6df84542-ef92-4fec-841a-1273cbca649d,DISK], DatanodeInfoWithStorage[127.0.0.1:33243,DS-fce69642-9bed-435c-b211-a66cf81e3ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:46631,DS-9cf4d361-2245-4312-929d-26b26a9b6261,DISK], DatanodeInfoWithStorage[127.0.0.1:34751,DS-c6f41c1b-097b-4863-a7b8-a5e394e34d79,DISK], DatanodeInfoWithStorage[127.0.0.1:34947,DS-672f1d0f-b1df-41e6-a021-7f1ddbdd70c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-746094174-172.17.0.14-1595292358310:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40562,DS-b441c23c-e182-4732-80dc-b4d331f7832c,DISK], DatanodeInfoWithStorage[127.0.0.1:39692,DS-db94fc06-06ee-4a6d-9308-90dc10f857ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41359,DS-fa71edf9-ecb6-4533-80a5-63ab0dab3b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:39417,DS-bd280a77-7ce4-4e62-b76c-677b2a59a50c,DISK], DatanodeInfoWithStorage[127.0.0.1:43373,DS-d675070c-bb2b-454e-8b06-c7621b927d59,DISK], DatanodeInfoWithStorage[127.0.0.1:39456,DS-a6824a32-024a-47d5-ab1c-6fe3ede59783,DISK], DatanodeInfoWithStorage[127.0.0.1:46842,DS-9c08f05e-be7f-4684-8273-55a4f3ee7b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:33982,DS-9707a2ed-0c47-4093-be16-ab742a153f54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-746094174-172.17.0.14-1595292358310:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40562,DS-b441c23c-e182-4732-80dc-b4d331f7832c,DISK], DatanodeInfoWithStorage[127.0.0.1:39692,DS-db94fc06-06ee-4a6d-9308-90dc10f857ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41359,DS-fa71edf9-ecb6-4533-80a5-63ab0dab3b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:39417,DS-bd280a77-7ce4-4e62-b76c-677b2a59a50c,DISK], DatanodeInfoWithStorage[127.0.0.1:43373,DS-d675070c-bb2b-454e-8b06-c7621b927d59,DISK], DatanodeInfoWithStorage[127.0.0.1:39456,DS-a6824a32-024a-47d5-ab1c-6fe3ede59783,DISK], DatanodeInfoWithStorage[127.0.0.1:46842,DS-9c08f05e-be7f-4684-8273-55a4f3ee7b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:33982,DS-9707a2ed-0c47-4093-be16-ab742a153f54,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-593083197-172.17.0.14-1595293184601:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38600,DS-f7e41a30-6526-4336-8ae1-1a38abdf4898,DISK], DatanodeInfoWithStorage[127.0.0.1:35076,DS-accdac25-d5ab-45ed-987e-2834f0f70657,DISK], DatanodeInfoWithStorage[127.0.0.1:38232,DS-f3f85f70-95ce-421d-bd24-2bdd613a3654,DISK], DatanodeInfoWithStorage[127.0.0.1:37319,DS-5aa3b47f-1214-4751-98ce-b46b1d07a98c,DISK], DatanodeInfoWithStorage[127.0.0.1:41950,DS-0891e405-f414-49d6-ae0f-0841c996011b,DISK], DatanodeInfoWithStorage[127.0.0.1:44650,DS-266e01c9-d306-4769-9d11-921044414f2a,DISK], DatanodeInfoWithStorage[127.0.0.1:43412,DS-706a962c-9fbd-435f-aac0-130081133954,DISK], DatanodeInfoWithStorage[127.0.0.1:41855,DS-2852cdf8-5276-4eb6-9d08-64254d0efcb6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-593083197-172.17.0.14-1595293184601:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38600,DS-f7e41a30-6526-4336-8ae1-1a38abdf4898,DISK], DatanodeInfoWithStorage[127.0.0.1:35076,DS-accdac25-d5ab-45ed-987e-2834f0f70657,DISK], DatanodeInfoWithStorage[127.0.0.1:38232,DS-f3f85f70-95ce-421d-bd24-2bdd613a3654,DISK], DatanodeInfoWithStorage[127.0.0.1:37319,DS-5aa3b47f-1214-4751-98ce-b46b1d07a98c,DISK], DatanodeInfoWithStorage[127.0.0.1:41950,DS-0891e405-f414-49d6-ae0f-0841c996011b,DISK], DatanodeInfoWithStorage[127.0.0.1:44650,DS-266e01c9-d306-4769-9d11-921044414f2a,DISK], DatanodeInfoWithStorage[127.0.0.1:43412,DS-706a962c-9fbd-435f-aac0-130081133954,DISK], DatanodeInfoWithStorage[127.0.0.1:41855,DS-2852cdf8-5276-4eb6-9d08-64254d0efcb6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1807589682-172.17.0.14-1595293288413:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36621,DS-6ebff108-ff8a-4922-a6f4-e25145a20a8c,DISK], DatanodeInfoWithStorage[127.0.0.1:39323,DS-55878fea-0074-4b87-8f00-7fcd398a3aa3,DISK], DatanodeInfoWithStorage[127.0.0.1:40213,DS-ebde7386-2bc5-43ee-9d5b-5070f5010e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:46112,DS-e2e4da4e-9f43-4646-99a8-e39bafd667cb,DISK], DatanodeInfoWithStorage[127.0.0.1:42869,DS-70df5ab5-3ab1-4635-8ee9-d583ceda821a,DISK], DatanodeInfoWithStorage[127.0.0.1:44250,DS-d9dd859f-0d4d-4edb-83c5-8e10c6ede01d,DISK], DatanodeInfoWithStorage[127.0.0.1:46592,DS-5584c7ce-1075-4912-8e6e-6e58907aaa74,DISK], DatanodeInfoWithStorage[127.0.0.1:35284,DS-261509c4-961d-4999-baf3-e3e89e3fcb22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1807589682-172.17.0.14-1595293288413:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36621,DS-6ebff108-ff8a-4922-a6f4-e25145a20a8c,DISK], DatanodeInfoWithStorage[127.0.0.1:39323,DS-55878fea-0074-4b87-8f00-7fcd398a3aa3,DISK], DatanodeInfoWithStorage[127.0.0.1:40213,DS-ebde7386-2bc5-43ee-9d5b-5070f5010e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:46112,DS-e2e4da4e-9f43-4646-99a8-e39bafd667cb,DISK], DatanodeInfoWithStorage[127.0.0.1:42869,DS-70df5ab5-3ab1-4635-8ee9-d583ceda821a,DISK], DatanodeInfoWithStorage[127.0.0.1:44250,DS-d9dd859f-0d4d-4edb-83c5-8e10c6ede01d,DISK], DatanodeInfoWithStorage[127.0.0.1:46592,DS-5584c7ce-1075-4912-8e6e-6e58907aaa74,DISK], DatanodeInfoWithStorage[127.0.0.1:35284,DS-261509c4-961d-4999-baf3-e3e89e3fcb22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: false positive !!!
Total execution time in seconds : 5280
