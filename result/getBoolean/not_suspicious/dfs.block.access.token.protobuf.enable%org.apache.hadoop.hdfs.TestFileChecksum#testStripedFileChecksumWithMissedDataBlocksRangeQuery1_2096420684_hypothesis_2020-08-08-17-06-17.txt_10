reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2013081438-172.17.0.12-1596907041541:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35348,DS-f43bb644-2d36-47b9-9ac5-b3a9e5856ea4,DISK], DatanodeInfoWithStorage[127.0.0.1:40765,DS-19c80c60-4715-4db1-b2d3-138a776197c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46692,DS-5436bf40-87a7-4c99-84e4-3bd935a7dcfa,DISK], DatanodeInfoWithStorage[127.0.0.1:40753,DS-63978b83-010d-4f60-bdfd-5a186bc628da,DISK], DatanodeInfoWithStorage[127.0.0.1:38788,DS-c5a0f7ae-4186-4d39-b971-8cd6d928d942,DISK], DatanodeInfoWithStorage[127.0.0.1:44457,DS-1a8fab7c-b398-4c5d-b678-195b1d06a349,DISK], DatanodeInfoWithStorage[127.0.0.1:33948,DS-5f86aff2-5409-4c19-8e36-e5159166030a,DISK], DatanodeInfoWithStorage[127.0.0.1:38856,DS-1bb6a8e7-c768-43fb-9b34-f40aceea88f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2013081438-172.17.0.12-1596907041541:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35348,DS-f43bb644-2d36-47b9-9ac5-b3a9e5856ea4,DISK], DatanodeInfoWithStorage[127.0.0.1:40765,DS-19c80c60-4715-4db1-b2d3-138a776197c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46692,DS-5436bf40-87a7-4c99-84e4-3bd935a7dcfa,DISK], DatanodeInfoWithStorage[127.0.0.1:40753,DS-63978b83-010d-4f60-bdfd-5a186bc628da,DISK], DatanodeInfoWithStorage[127.0.0.1:38788,DS-c5a0f7ae-4186-4d39-b971-8cd6d928d942,DISK], DatanodeInfoWithStorage[127.0.0.1:44457,DS-1a8fab7c-b398-4c5d-b678-195b1d06a349,DISK], DatanodeInfoWithStorage[127.0.0.1:33948,DS-5f86aff2-5409-4c19-8e36-e5159166030a,DISK], DatanodeInfoWithStorage[127.0.0.1:38856,DS-1bb6a8e7-c768-43fb-9b34-f40aceea88f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1227221598-172.17.0.12-1596907684254:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46555,DS-e66864a7-4643-4053-bd6b-1bcf2a92745c,DISK], DatanodeInfoWithStorage[127.0.0.1:33023,DS-5e19be03-15df-4fd3-b407-4a95371e3f24,DISK], DatanodeInfoWithStorage[127.0.0.1:42303,DS-e2cf3606-ac12-480e-9403-1b91df65d1ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37974,DS-d0fee28d-80a6-4532-8dad-ad49f0a10d09,DISK], DatanodeInfoWithStorage[127.0.0.1:40288,DS-3bab50fe-8344-46e4-b0e7-3d4f7db958a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42746,DS-2ebb1008-bc44-4f55-aff8-68eea2304007,DISK], DatanodeInfoWithStorage[127.0.0.1:33072,DS-fedaef0d-17ca-4c99-87fc-0808950da55e,DISK], DatanodeInfoWithStorage[127.0.0.1:42455,DS-151b6bf2-cc11-44be-9b7b-6fb527dd7bdd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1227221598-172.17.0.12-1596907684254:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46555,DS-e66864a7-4643-4053-bd6b-1bcf2a92745c,DISK], DatanodeInfoWithStorage[127.0.0.1:33023,DS-5e19be03-15df-4fd3-b407-4a95371e3f24,DISK], DatanodeInfoWithStorage[127.0.0.1:42303,DS-e2cf3606-ac12-480e-9403-1b91df65d1ee,DISK], DatanodeInfoWithStorage[127.0.0.1:37974,DS-d0fee28d-80a6-4532-8dad-ad49f0a10d09,DISK], DatanodeInfoWithStorage[127.0.0.1:40288,DS-3bab50fe-8344-46e4-b0e7-3d4f7db958a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42746,DS-2ebb1008-bc44-4f55-aff8-68eea2304007,DISK], DatanodeInfoWithStorage[127.0.0.1:33072,DS-fedaef0d-17ca-4c99-87fc-0808950da55e,DISK], DatanodeInfoWithStorage[127.0.0.1:42455,DS-151b6bf2-cc11-44be-9b7b-6fb527dd7bdd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1282304087-172.17.0.12-1596908170908:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34363,DS-c504dc5d-660b-48c4-8bb7-f08b462931ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39390,DS-d8f69791-1c4e-425b-9302-d6b01006a2cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42345,DS-641cf2e6-bf42-4fe5-b10a-998a45007be0,DISK], DatanodeInfoWithStorage[127.0.0.1:44980,DS-5ed0a505-0d43-4302-b528-d37c4b0d23d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40813,DS-74c31205-6ae4-4d5d-89b6-013e3ba6647a,DISK], DatanodeInfoWithStorage[127.0.0.1:42008,DS-dbeba90f-4069-4314-aae9-dae0f24dda3b,DISK], DatanodeInfoWithStorage[127.0.0.1:39361,DS-9c6ab942-d2d8-4798-a875-bc2160b449f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34662,DS-83162eaf-36e3-41a7-a36f-a55f53e0e22c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1282304087-172.17.0.12-1596908170908:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34363,DS-c504dc5d-660b-48c4-8bb7-f08b462931ed,DISK], DatanodeInfoWithStorage[127.0.0.1:39390,DS-d8f69791-1c4e-425b-9302-d6b01006a2cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42345,DS-641cf2e6-bf42-4fe5-b10a-998a45007be0,DISK], DatanodeInfoWithStorage[127.0.0.1:44980,DS-5ed0a505-0d43-4302-b528-d37c4b0d23d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40813,DS-74c31205-6ae4-4d5d-89b6-013e3ba6647a,DISK], DatanodeInfoWithStorage[127.0.0.1:42008,DS-dbeba90f-4069-4314-aae9-dae0f24dda3b,DISK], DatanodeInfoWithStorage[127.0.0.1:39361,DS-9c6ab942-d2d8-4798-a875-bc2160b449f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34662,DS-83162eaf-36e3-41a7-a36f-a55f53e0e22c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-952440006-172.17.0.12-1596908620278:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41777,DS-6ef92134-a33b-4772-bddf-d9eab749ee88,DISK], DatanodeInfoWithStorage[127.0.0.1:41346,DS-622cc72b-5c6f-4c26-9a92-9a8b563323f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46183,DS-4ffbdc04-e3ed-4445-8ea4-f3f9d1367a05,DISK], DatanodeInfoWithStorage[127.0.0.1:42979,DS-925c0397-25b8-4c52-a801-31e9363f4aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:33571,DS-61978c6d-e183-4eb2-a35d-c2e8f95d02f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34441,DS-befa7d18-dd23-4574-a0ed-99945c3604a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38149,DS-0e63438d-d720-477c-afcd-9ca460b18676,DISK], DatanodeInfoWithStorage[127.0.0.1:41998,DS-a5b5fb36-99a1-4bb5-a860-e1814ccb469d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-952440006-172.17.0.12-1596908620278:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41777,DS-6ef92134-a33b-4772-bddf-d9eab749ee88,DISK], DatanodeInfoWithStorage[127.0.0.1:41346,DS-622cc72b-5c6f-4c26-9a92-9a8b563323f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46183,DS-4ffbdc04-e3ed-4445-8ea4-f3f9d1367a05,DISK], DatanodeInfoWithStorage[127.0.0.1:42979,DS-925c0397-25b8-4c52-a801-31e9363f4aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:33571,DS-61978c6d-e183-4eb2-a35d-c2e8f95d02f7,DISK], DatanodeInfoWithStorage[127.0.0.1:34441,DS-befa7d18-dd23-4574-a0ed-99945c3604a9,DISK], DatanodeInfoWithStorage[127.0.0.1:38149,DS-0e63438d-d720-477c-afcd-9ca460b18676,DISK], DatanodeInfoWithStorage[127.0.0.1:41998,DS-a5b5fb36-99a1-4bb5-a860-e1814ccb469d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1086105189-172.17.0.12-1596908764529:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36602,DS-1d143d02-a4e8-44ad-bf17-37ea54982d87,DISK], DatanodeInfoWithStorage[127.0.0.1:37950,DS-12fe3fa2-4d17-45c0-9131-8d105c292e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:41086,DS-30274249-62d7-4d6f-abb3-d17b4eda196e,DISK], DatanodeInfoWithStorage[127.0.0.1:38947,DS-cddb3035-f21e-4117-839a-f7b180c12bc0,DISK], DatanodeInfoWithStorage[127.0.0.1:44085,DS-3ab818b3-8902-4e62-840c-370cc3e28918,DISK], DatanodeInfoWithStorage[127.0.0.1:37063,DS-fddf9e01-f492-493c-88cf-563d654e9794,DISK], DatanodeInfoWithStorage[127.0.0.1:46426,DS-425f344f-2e5a-48dd-b748-e78ee37cd4d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41637,DS-c671bef8-c2f0-42cb-acec-04e64d90af90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1086105189-172.17.0.12-1596908764529:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36602,DS-1d143d02-a4e8-44ad-bf17-37ea54982d87,DISK], DatanodeInfoWithStorage[127.0.0.1:37950,DS-12fe3fa2-4d17-45c0-9131-8d105c292e2a,DISK], DatanodeInfoWithStorage[127.0.0.1:41086,DS-30274249-62d7-4d6f-abb3-d17b4eda196e,DISK], DatanodeInfoWithStorage[127.0.0.1:38947,DS-cddb3035-f21e-4117-839a-f7b180c12bc0,DISK], DatanodeInfoWithStorage[127.0.0.1:44085,DS-3ab818b3-8902-4e62-840c-370cc3e28918,DISK], DatanodeInfoWithStorage[127.0.0.1:37063,DS-fddf9e01-f492-493c-88cf-563d654e9794,DISK], DatanodeInfoWithStorage[127.0.0.1:46426,DS-425f344f-2e5a-48dd-b748-e78ee37cd4d4,DISK], DatanodeInfoWithStorage[127.0.0.1:41637,DS-c671bef8-c2f0-42cb-acec-04e64d90af90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1431478553-172.17.0.12-1596909162328:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38528,DS-6a780b9f-1352-4e33-81cd-2143709a4f24,DISK], DatanodeInfoWithStorage[127.0.0.1:33511,DS-42f3cddd-c2b6-42d8-8399-43f35b466f25,DISK], DatanodeInfoWithStorage[127.0.0.1:41363,DS-b9b8393f-08c2-4889-b2cf-f831fdd6bd38,DISK], DatanodeInfoWithStorage[127.0.0.1:35242,DS-5bc53b49-6f85-4e76-afe4-d6f4f7445a18,DISK], DatanodeInfoWithStorage[127.0.0.1:46124,DS-eb6b51cc-03d7-4b0b-8048-73ebf5bd3a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:39913,DS-69069abe-37f7-4f6e-bf6d-5960b307d5af,DISK], DatanodeInfoWithStorage[127.0.0.1:40614,DS-c38c0586-f696-4a5c-afa6-7542f09a1b3b,DISK], DatanodeInfoWithStorage[127.0.0.1:38099,DS-c74ec589-0de1-447f-aa86-31ac9a08a058,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1431478553-172.17.0.12-1596909162328:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38528,DS-6a780b9f-1352-4e33-81cd-2143709a4f24,DISK], DatanodeInfoWithStorage[127.0.0.1:33511,DS-42f3cddd-c2b6-42d8-8399-43f35b466f25,DISK], DatanodeInfoWithStorage[127.0.0.1:41363,DS-b9b8393f-08c2-4889-b2cf-f831fdd6bd38,DISK], DatanodeInfoWithStorage[127.0.0.1:35242,DS-5bc53b49-6f85-4e76-afe4-d6f4f7445a18,DISK], DatanodeInfoWithStorage[127.0.0.1:46124,DS-eb6b51cc-03d7-4b0b-8048-73ebf5bd3a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:39913,DS-69069abe-37f7-4f6e-bf6d-5960b307d5af,DISK], DatanodeInfoWithStorage[127.0.0.1:40614,DS-c38c0586-f696-4a5c-afa6-7542f09a1b3b,DISK], DatanodeInfoWithStorage[127.0.0.1:38099,DS-c74ec589-0de1-447f-aa86-31ac9a08a058,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-582185837-172.17.0.12-1596909343541:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39211,DS-8fedf21d-3a82-4510-9964-fe87a095c2e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46033,DS-502c1637-aac1-4c42-b38f-91c28269bd60,DISK], DatanodeInfoWithStorage[127.0.0.1:33008,DS-1ad2d884-cd9d-4c91-b596-5ac01c655e21,DISK], DatanodeInfoWithStorage[127.0.0.1:34121,DS-f7af41eb-d73a-44ac-83af-bc00e132583e,DISK], DatanodeInfoWithStorage[127.0.0.1:33549,DS-fd82a6f4-d7ff-46ef-87c9-9936db48d410,DISK], DatanodeInfoWithStorage[127.0.0.1:37336,DS-d8aada0b-c5ad-4938-8490-817494fd9258,DISK], DatanodeInfoWithStorage[127.0.0.1:43270,DS-7019266e-1876-48ae-8bcf-a2bfece42332,DISK], DatanodeInfoWithStorage[127.0.0.1:32983,DS-2a42bff7-153a-4b0a-8097-0f8b5f819aaf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-582185837-172.17.0.12-1596909343541:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39211,DS-8fedf21d-3a82-4510-9964-fe87a095c2e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46033,DS-502c1637-aac1-4c42-b38f-91c28269bd60,DISK], DatanodeInfoWithStorage[127.0.0.1:33008,DS-1ad2d884-cd9d-4c91-b596-5ac01c655e21,DISK], DatanodeInfoWithStorage[127.0.0.1:34121,DS-f7af41eb-d73a-44ac-83af-bc00e132583e,DISK], DatanodeInfoWithStorage[127.0.0.1:33549,DS-fd82a6f4-d7ff-46ef-87c9-9936db48d410,DISK], DatanodeInfoWithStorage[127.0.0.1:37336,DS-d8aada0b-c5ad-4938-8490-817494fd9258,DISK], DatanodeInfoWithStorage[127.0.0.1:43270,DS-7019266e-1876-48ae-8bcf-a2bfece42332,DISK], DatanodeInfoWithStorage[127.0.0.1:32983,DS-2a42bff7-153a-4b0a-8097-0f8b5f819aaf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1811291505-172.17.0.12-1596910075623:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44715,DS-53dda0bc-56f6-4562-b623-aa1efdad79a5,DISK], DatanodeInfoWithStorage[127.0.0.1:37587,DS-99a9b6ac-841e-4dd5-b987-ad3de492bcec,DISK], DatanodeInfoWithStorage[127.0.0.1:45466,DS-aacc3ece-eff4-4a06-9767-0a6ef21af9a5,DISK], DatanodeInfoWithStorage[127.0.0.1:37018,DS-d9eb0405-8dc3-4ac7-bb5f-6c121315a5a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35734,DS-b9d04517-90a6-4163-b855-ed1f7c1b8201,DISK], DatanodeInfoWithStorage[127.0.0.1:37720,DS-605fede4-267a-4244-b7ab-dcaf46fb29ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34626,DS-a1e7f0c3-a326-4d6b-a061-fae0e8609efa,DISK], DatanodeInfoWithStorage[127.0.0.1:45485,DS-34768547-4ecb-475f-a1a7-acb71d2b676e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1811291505-172.17.0.12-1596910075623:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44715,DS-53dda0bc-56f6-4562-b623-aa1efdad79a5,DISK], DatanodeInfoWithStorage[127.0.0.1:37587,DS-99a9b6ac-841e-4dd5-b987-ad3de492bcec,DISK], DatanodeInfoWithStorage[127.0.0.1:45466,DS-aacc3ece-eff4-4a06-9767-0a6ef21af9a5,DISK], DatanodeInfoWithStorage[127.0.0.1:37018,DS-d9eb0405-8dc3-4ac7-bb5f-6c121315a5a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35734,DS-b9d04517-90a6-4163-b855-ed1f7c1b8201,DISK], DatanodeInfoWithStorage[127.0.0.1:37720,DS-605fede4-267a-4244-b7ab-dcaf46fb29ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34626,DS-a1e7f0c3-a326-4d6b-a061-fae0e8609efa,DISK], DatanodeInfoWithStorage[127.0.0.1:45485,DS-34768547-4ecb-475f-a1a7-acb71d2b676e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1174499093-172.17.0.12-1596910232555:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40368,DS-2e2967b4-f3f9-410e-ba4c-2bb7327767ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36474,DS-487958f5-1ddf-45f1-8135-ea5e7abce4dc,DISK], DatanodeInfoWithStorage[127.0.0.1:32816,DS-f39bfef5-0be4-48cb-b739-696aa47f93f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33448,DS-744cdcf1-c36f-44c8-b9f9-0a6af81b9b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:38726,DS-f229d54a-9808-4a31-8a2e-92a66455adf9,DISK], DatanodeInfoWithStorage[127.0.0.1:41530,DS-6f1535c1-25fa-40f4-8b5a-e24cffaf4664,DISK], DatanodeInfoWithStorage[127.0.0.1:43061,DS-aad058b7-dfac-4180-a6bf-9b666fa2d0c7,DISK], DatanodeInfoWithStorage[127.0.0.1:44609,DS-a4304a41-ab88-4cf6-bd63-57f684ed5721,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1174499093-172.17.0.12-1596910232555:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40368,DS-2e2967b4-f3f9-410e-ba4c-2bb7327767ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36474,DS-487958f5-1ddf-45f1-8135-ea5e7abce4dc,DISK], DatanodeInfoWithStorage[127.0.0.1:32816,DS-f39bfef5-0be4-48cb-b739-696aa47f93f5,DISK], DatanodeInfoWithStorage[127.0.0.1:33448,DS-744cdcf1-c36f-44c8-b9f9-0a6af81b9b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:38726,DS-f229d54a-9808-4a31-8a2e-92a66455adf9,DISK], DatanodeInfoWithStorage[127.0.0.1:41530,DS-6f1535c1-25fa-40f4-8b5a-e24cffaf4664,DISK], DatanodeInfoWithStorage[127.0.0.1:43061,DS-aad058b7-dfac-4180-a6bf-9b666fa2d0c7,DISK], DatanodeInfoWithStorage[127.0.0.1:44609,DS-a4304a41-ab88-4cf6-bd63-57f684ed5721,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1339063110-172.17.0.12-1596910732745:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40929,DS-43706155-0b9a-4320-91fb-03bb94c03583,DISK], DatanodeInfoWithStorage[127.0.0.1:38749,DS-539df7b0-cb87-42e7-9016-3fb3944692b2,DISK], DatanodeInfoWithStorage[127.0.0.1:39311,DS-1d8d9101-753e-4398-b199-8ca92e05c4ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41171,DS-a61935d4-dc63-4d9c-9515-1c6f177d6ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:37513,DS-b4d4cf17-9f04-424f-8b99-2dfa146a64f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33222,DS-ec557695-e317-4e23-b7df-57341eb27943,DISK], DatanodeInfoWithStorage[127.0.0.1:33205,DS-4a4d95ff-b286-40e9-a076-b2ee5c20086a,DISK], DatanodeInfoWithStorage[127.0.0.1:42992,DS-4f0598be-4712-441a-9d3f-e736862fd90f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1339063110-172.17.0.12-1596910732745:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40929,DS-43706155-0b9a-4320-91fb-03bb94c03583,DISK], DatanodeInfoWithStorage[127.0.0.1:38749,DS-539df7b0-cb87-42e7-9016-3fb3944692b2,DISK], DatanodeInfoWithStorage[127.0.0.1:39311,DS-1d8d9101-753e-4398-b199-8ca92e05c4ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41171,DS-a61935d4-dc63-4d9c-9515-1c6f177d6ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:37513,DS-b4d4cf17-9f04-424f-8b99-2dfa146a64f4,DISK], DatanodeInfoWithStorage[127.0.0.1:33222,DS-ec557695-e317-4e23-b7df-57341eb27943,DISK], DatanodeInfoWithStorage[127.0.0.1:33205,DS-4a4d95ff-b286-40e9-a076-b2ee5c20086a,DISK], DatanodeInfoWithStorage[127.0.0.1:42992,DS-4f0598be-4712-441a-9d3f-e736862fd90f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2050723692-172.17.0.12-1596911002503:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33332,DS-7473ea86-eca5-4502-8deb-5306de52e8d6,DISK], DatanodeInfoWithStorage[127.0.0.1:46348,DS-62312fe5-1adb-4cf7-a59c-c6398a87bbc7,DISK], DatanodeInfoWithStorage[127.0.0.1:35814,DS-55fef956-8346-460c-8df9-047c1bdad9f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40141,DS-cb4df6fa-6152-4c72-b1f9-61ebd87304db,DISK], DatanodeInfoWithStorage[127.0.0.1:46780,DS-d8fd235e-6a0a-401f-9c50-e1965a83579e,DISK], DatanodeInfoWithStorage[127.0.0.1:40861,DS-fe19e4a6-7ddb-4c01-a419-fd98054e593c,DISK], DatanodeInfoWithStorage[127.0.0.1:41030,DS-8b7d4c72-26b7-4890-93eb-1df8079fb5aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40102,DS-e0764a8f-a5ad-46b3-b0ce-2d281162e158,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2050723692-172.17.0.12-1596911002503:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33332,DS-7473ea86-eca5-4502-8deb-5306de52e8d6,DISK], DatanodeInfoWithStorage[127.0.0.1:46348,DS-62312fe5-1adb-4cf7-a59c-c6398a87bbc7,DISK], DatanodeInfoWithStorage[127.0.0.1:35814,DS-55fef956-8346-460c-8df9-047c1bdad9f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40141,DS-cb4df6fa-6152-4c72-b1f9-61ebd87304db,DISK], DatanodeInfoWithStorage[127.0.0.1:46780,DS-d8fd235e-6a0a-401f-9c50-e1965a83579e,DISK], DatanodeInfoWithStorage[127.0.0.1:40861,DS-fe19e4a6-7ddb-4c01-a419-fd98054e593c,DISK], DatanodeInfoWithStorage[127.0.0.1:41030,DS-8b7d4c72-26b7-4890-93eb-1df8079fb5aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40102,DS-e0764a8f-a5ad-46b3-b0ce-2d281162e158,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-525983671-172.17.0.12-1596911079504:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36125,DS-c72a5e06-c731-407f-a08e-f6adf973709a,DISK], DatanodeInfoWithStorage[127.0.0.1:36916,DS-28f9eeb9-27c7-47af-9384-d2e715139199,DISK], DatanodeInfoWithStorage[127.0.0.1:43012,DS-79cf96e0-fce6-4771-aea0-8b8d93931bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:44719,DS-d5595647-6ae5-4fd1-bf9e-1386d41a29bb,DISK], DatanodeInfoWithStorage[127.0.0.1:43839,DS-3e30ccd4-de34-4f27-a92d-09deb44ee04c,DISK], DatanodeInfoWithStorage[127.0.0.1:46145,DS-99edd823-9063-4c8b-88e0-c1e6c9a8bcdd,DISK], DatanodeInfoWithStorage[127.0.0.1:37244,DS-630f2938-7bc6-46e2-a634-49add9e248b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45426,DS-6ae43859-a779-494c-bd06-af9dc18ae3ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-525983671-172.17.0.12-1596911079504:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36125,DS-c72a5e06-c731-407f-a08e-f6adf973709a,DISK], DatanodeInfoWithStorage[127.0.0.1:36916,DS-28f9eeb9-27c7-47af-9384-d2e715139199,DISK], DatanodeInfoWithStorage[127.0.0.1:43012,DS-79cf96e0-fce6-4771-aea0-8b8d93931bfe,DISK], DatanodeInfoWithStorage[127.0.0.1:44719,DS-d5595647-6ae5-4fd1-bf9e-1386d41a29bb,DISK], DatanodeInfoWithStorage[127.0.0.1:43839,DS-3e30ccd4-de34-4f27-a92d-09deb44ee04c,DISK], DatanodeInfoWithStorage[127.0.0.1:46145,DS-99edd823-9063-4c8b-88e0-c1e6c9a8bcdd,DISK], DatanodeInfoWithStorage[127.0.0.1:37244,DS-630f2938-7bc6-46e2-a634-49add9e248b1,DISK], DatanodeInfoWithStorage[127.0.0.1:45426,DS-6ae43859-a779-494c-bd06-af9dc18ae3ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-923004512-172.17.0.12-1596911305038:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36950,DS-64ef13d1-2def-4ac5-a7f0-6c51903f992e,DISK], DatanodeInfoWithStorage[127.0.0.1:45944,DS-d0c39af3-f368-4df2-9eda-0df618aa3214,DISK], DatanodeInfoWithStorage[127.0.0.1:40203,DS-f8528fbf-b27e-45da-920a-792ede4db2b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39578,DS-39807b4b-dee0-4858-b811-b68fb2442b79,DISK], DatanodeInfoWithStorage[127.0.0.1:45339,DS-d1914d3c-c7ec-4d2b-aa63-aaf7728c28b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37911,DS-5df24b36-99e2-4158-b909-0d8ad344a356,DISK], DatanodeInfoWithStorage[127.0.0.1:42919,DS-c7338256-85a6-4429-8496-c966d4327b7b,DISK], DatanodeInfoWithStorage[127.0.0.1:41344,DS-e2dc4fae-d42d-4631-aa88-6ad696713101,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-923004512-172.17.0.12-1596911305038:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36950,DS-64ef13d1-2def-4ac5-a7f0-6c51903f992e,DISK], DatanodeInfoWithStorage[127.0.0.1:45944,DS-d0c39af3-f368-4df2-9eda-0df618aa3214,DISK], DatanodeInfoWithStorage[127.0.0.1:40203,DS-f8528fbf-b27e-45da-920a-792ede4db2b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39578,DS-39807b4b-dee0-4858-b811-b68fb2442b79,DISK], DatanodeInfoWithStorage[127.0.0.1:45339,DS-d1914d3c-c7ec-4d2b-aa63-aaf7728c28b9,DISK], DatanodeInfoWithStorage[127.0.0.1:37911,DS-5df24b36-99e2-4158-b909-0d8ad344a356,DISK], DatanodeInfoWithStorage[127.0.0.1:42919,DS-c7338256-85a6-4429-8496-c966d4327b7b,DISK], DatanodeInfoWithStorage[127.0.0.1:41344,DS-e2dc4fae-d42d-4631-aa88-6ad696713101,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-902090174-172.17.0.12-1596911374768:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43066,DS-3c862fd8-7f8b-436c-96d0-031efedea5ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40135,DS-20f5570d-67d8-4df4-8068-ae13a0abd6e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44589,DS-0442a174-5602-4a9c-bae7-55df0f78e5de,DISK], DatanodeInfoWithStorage[127.0.0.1:36794,DS-af72cae3-4cdb-4637-a893-2a65cae17561,DISK], DatanodeInfoWithStorage[127.0.0.1:45189,DS-0575e2fb-d745-4c09-81ac-a7b3bce31645,DISK], DatanodeInfoWithStorage[127.0.0.1:42156,DS-f282ce55-fac5-4b02-89e6-ffe93c2f5dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:36279,DS-d5641f7c-10d7-45b8-8c03-ac68f76e5d25,DISK], DatanodeInfoWithStorage[127.0.0.1:34711,DS-52b98907-6ea5-4b61-afcf-39d7ec722c52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-902090174-172.17.0.12-1596911374768:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43066,DS-3c862fd8-7f8b-436c-96d0-031efedea5ca,DISK], DatanodeInfoWithStorage[127.0.0.1:40135,DS-20f5570d-67d8-4df4-8068-ae13a0abd6e9,DISK], DatanodeInfoWithStorage[127.0.0.1:44589,DS-0442a174-5602-4a9c-bae7-55df0f78e5de,DISK], DatanodeInfoWithStorage[127.0.0.1:36794,DS-af72cae3-4cdb-4637-a893-2a65cae17561,DISK], DatanodeInfoWithStorage[127.0.0.1:45189,DS-0575e2fb-d745-4c09-81ac-a7b3bce31645,DISK], DatanodeInfoWithStorage[127.0.0.1:42156,DS-f282ce55-fac5-4b02-89e6-ffe93c2f5dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:36279,DS-d5641f7c-10d7-45b8-8c03-ac68f76e5d25,DISK], DatanodeInfoWithStorage[127.0.0.1:34711,DS-52b98907-6ea5-4b61-afcf-39d7ec722c52,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-92888630-172.17.0.12-1596911568442:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46241,DS-b8c953b8-6f75-47c5-a76a-60d50a79c21d,DISK], DatanodeInfoWithStorage[127.0.0.1:43459,DS-7a074995-0024-4ea1-a6f5-5029a89f6e52,DISK], DatanodeInfoWithStorage[127.0.0.1:36675,DS-363f10e1-436e-4005-887c-9d18feb7bbaa,DISK], DatanodeInfoWithStorage[127.0.0.1:34613,DS-77d08ae0-a391-4231-b773-6103f502970f,DISK], DatanodeInfoWithStorage[127.0.0.1:39070,DS-b1f14b74-2320-46c8-b950-f7d4bff99b75,DISK], DatanodeInfoWithStorage[127.0.0.1:35308,DS-05e09acc-fef1-4580-b1f0-95c92e067cad,DISK], DatanodeInfoWithStorage[127.0.0.1:41999,DS-160761b7-983a-43bd-ac5a-5653ec3a38b8,DISK], DatanodeInfoWithStorage[127.0.0.1:36349,DS-6e294457-fe38-466f-a713-c6ab681714c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-92888630-172.17.0.12-1596911568442:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46241,DS-b8c953b8-6f75-47c5-a76a-60d50a79c21d,DISK], DatanodeInfoWithStorage[127.0.0.1:43459,DS-7a074995-0024-4ea1-a6f5-5029a89f6e52,DISK], DatanodeInfoWithStorage[127.0.0.1:36675,DS-363f10e1-436e-4005-887c-9d18feb7bbaa,DISK], DatanodeInfoWithStorage[127.0.0.1:34613,DS-77d08ae0-a391-4231-b773-6103f502970f,DISK], DatanodeInfoWithStorage[127.0.0.1:39070,DS-b1f14b74-2320-46c8-b950-f7d4bff99b75,DISK], DatanodeInfoWithStorage[127.0.0.1:35308,DS-05e09acc-fef1-4580-b1f0-95c92e067cad,DISK], DatanodeInfoWithStorage[127.0.0.1:41999,DS-160761b7-983a-43bd-ac5a-5653ec3a38b8,DISK], DatanodeInfoWithStorage[127.0.0.1:36349,DS-6e294457-fe38-466f-a713-c6ab681714c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.access.token.protobuf.enable
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-866320337-172.17.0.12-1596911888028:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37142,DS-13dbb563-810b-4628-9924-0421ac0dcbae,DISK], DatanodeInfoWithStorage[127.0.0.1:42404,DS-3f91b9df-64dd-4789-9eb1-e4c9aee11ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:37451,DS-d6c42734-f584-4188-9e2c-af9d2ac0db5f,DISK], DatanodeInfoWithStorage[127.0.0.1:43261,DS-b1137e96-4790-4809-9fce-fef5e2fa6df5,DISK], DatanodeInfoWithStorage[127.0.0.1:37246,DS-8665fe2b-ed4e-47f0-a095-56a289635f3d,DISK], DatanodeInfoWithStorage[127.0.0.1:36131,DS-c2f595e1-51bc-434b-8ec6-72d871b8fed2,DISK], DatanodeInfoWithStorage[127.0.0.1:41640,DS-d51aa60b-e17b-4cf9-a7e8-57fef3cba044,DISK], DatanodeInfoWithStorage[127.0.0.1:44477,DS-7b7c8120-6b93-480a-9307-1cf1fa3560b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-866320337-172.17.0.12-1596911888028:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37142,DS-13dbb563-810b-4628-9924-0421ac0dcbae,DISK], DatanodeInfoWithStorage[127.0.0.1:42404,DS-3f91b9df-64dd-4789-9eb1-e4c9aee11ae2,DISK], DatanodeInfoWithStorage[127.0.0.1:37451,DS-d6c42734-f584-4188-9e2c-af9d2ac0db5f,DISK], DatanodeInfoWithStorage[127.0.0.1:43261,DS-b1137e96-4790-4809-9fce-fef5e2fa6df5,DISK], DatanodeInfoWithStorage[127.0.0.1:37246,DS-8665fe2b-ed4e-47f0-a095-56a289635f3d,DISK], DatanodeInfoWithStorage[127.0.0.1:36131,DS-c2f595e1-51bc-434b-8ec6-72d871b8fed2,DISK], DatanodeInfoWithStorage[127.0.0.1:41640,DS-d51aa60b-e17b-4cf9-a7e8-57fef3cba044,DISK], DatanodeInfoWithStorage[127.0.0.1:44477,DS-7b7c8120-6b93-480a-9307-1cf1fa3560b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5574
