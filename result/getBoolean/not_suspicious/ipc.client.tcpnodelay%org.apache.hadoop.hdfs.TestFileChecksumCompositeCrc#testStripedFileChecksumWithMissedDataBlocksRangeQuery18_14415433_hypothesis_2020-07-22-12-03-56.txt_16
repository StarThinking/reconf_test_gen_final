reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1576123982-172.17.0.10-1595419553171:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33156,DS-759107ca-2310-4a11-a001-f72b3d53aaff,DISK], DatanodeInfoWithStorage[127.0.0.1:38448,DS-6ca0bdaf-b1fb-4fde-b8be-0cbff5c876a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39645,DS-20f4f271-09e2-4ec2-a738-4b7cd7fa797e,DISK], DatanodeInfoWithStorage[127.0.0.1:35703,DS-2991bc7d-a535-462d-b5c1-608f9fa0e670,DISK], DatanodeInfoWithStorage[127.0.0.1:45078,DS-73554806-30f3-4fcc-a531-c14a026c2c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:33337,DS-937b2da7-ceaf-4894-af77-d671f7809a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:42485,DS-e7e3519e-af85-462c-a09e-cb662445be6f,DISK], DatanodeInfoWithStorage[127.0.0.1:38501,DS-96916bc3-38bb-4702-8e0e-163e1c3f0037,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1576123982-172.17.0.10-1595419553171:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33156,DS-759107ca-2310-4a11-a001-f72b3d53aaff,DISK], DatanodeInfoWithStorage[127.0.0.1:38448,DS-6ca0bdaf-b1fb-4fde-b8be-0cbff5c876a2,DISK], DatanodeInfoWithStorage[127.0.0.1:39645,DS-20f4f271-09e2-4ec2-a738-4b7cd7fa797e,DISK], DatanodeInfoWithStorage[127.0.0.1:35703,DS-2991bc7d-a535-462d-b5c1-608f9fa0e670,DISK], DatanodeInfoWithStorage[127.0.0.1:45078,DS-73554806-30f3-4fcc-a531-c14a026c2c9c,DISK], DatanodeInfoWithStorage[127.0.0.1:33337,DS-937b2da7-ceaf-4894-af77-d671f7809a8d,DISK], DatanodeInfoWithStorage[127.0.0.1:42485,DS-e7e3519e-af85-462c-a09e-cb662445be6f,DISK], DatanodeInfoWithStorage[127.0.0.1:38501,DS-96916bc3-38bb-4702-8e0e-163e1c3f0037,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1485417183-172.17.0.10-1595419639384:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36103,DS-24bb04f5-6bfb-45ec-815f-31b9354fe60f,DISK], DatanodeInfoWithStorage[127.0.0.1:44235,DS-f0e2bd0f-d461-4499-a620-f2201031af72,DISK], DatanodeInfoWithStorage[127.0.0.1:38471,DS-758d593b-dde4-482c-b2ec-5b6cdcc62002,DISK], DatanodeInfoWithStorage[127.0.0.1:39715,DS-852007d7-c9ff-4479-8c3d-e431bfe5b193,DISK], DatanodeInfoWithStorage[127.0.0.1:39207,DS-54ebf7d4-b941-438c-8d3a-9940fc5f10a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39229,DS-9734c9a7-0854-4042-8294-8b0a2304937f,DISK], DatanodeInfoWithStorage[127.0.0.1:38765,DS-711e5c0a-feb4-4de7-ad7b-e470690d3093,DISK], DatanodeInfoWithStorage[127.0.0.1:42761,DS-79ff19c7-daf2-4ab8-9293-0748afac14ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1485417183-172.17.0.10-1595419639384:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36103,DS-24bb04f5-6bfb-45ec-815f-31b9354fe60f,DISK], DatanodeInfoWithStorage[127.0.0.1:44235,DS-f0e2bd0f-d461-4499-a620-f2201031af72,DISK], DatanodeInfoWithStorage[127.0.0.1:38471,DS-758d593b-dde4-482c-b2ec-5b6cdcc62002,DISK], DatanodeInfoWithStorage[127.0.0.1:39715,DS-852007d7-c9ff-4479-8c3d-e431bfe5b193,DISK], DatanodeInfoWithStorage[127.0.0.1:39207,DS-54ebf7d4-b941-438c-8d3a-9940fc5f10a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39229,DS-9734c9a7-0854-4042-8294-8b0a2304937f,DISK], DatanodeInfoWithStorage[127.0.0.1:38765,DS-711e5c0a-feb4-4de7-ad7b-e470690d3093,DISK], DatanodeInfoWithStorage[127.0.0.1:42761,DS-79ff19c7-daf2-4ab8-9293-0748afac14ee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-584819194-172.17.0.10-1595420310263:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40147,DS-b5313c8c-9d46-4dfd-8eda-cfc6fff23209,DISK], DatanodeInfoWithStorage[127.0.0.1:34063,DS-4ea8e792-967d-4c80-a01e-405ae5f85690,DISK], DatanodeInfoWithStorage[127.0.0.1:44826,DS-70548ad7-4b4f-499c-9c29-dfea02be1b09,DISK], DatanodeInfoWithStorage[127.0.0.1:43909,DS-ea7705ed-f870-4a13-b3a8-481796e257be,DISK], DatanodeInfoWithStorage[127.0.0.1:45059,DS-674c236c-de04-47d2-87fd-0a2e7e635814,DISK], DatanodeInfoWithStorage[127.0.0.1:39384,DS-d8622ecf-edd4-4cce-b157-e7a9f17022c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42129,DS-84a94c5b-8898-4599-ba4a-43567a074b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:32791,DS-ff4edf7d-aab1-483e-a4d5-1e8dd50d1afc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-584819194-172.17.0.10-1595420310263:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40147,DS-b5313c8c-9d46-4dfd-8eda-cfc6fff23209,DISK], DatanodeInfoWithStorage[127.0.0.1:34063,DS-4ea8e792-967d-4c80-a01e-405ae5f85690,DISK], DatanodeInfoWithStorage[127.0.0.1:44826,DS-70548ad7-4b4f-499c-9c29-dfea02be1b09,DISK], DatanodeInfoWithStorage[127.0.0.1:43909,DS-ea7705ed-f870-4a13-b3a8-481796e257be,DISK], DatanodeInfoWithStorage[127.0.0.1:45059,DS-674c236c-de04-47d2-87fd-0a2e7e635814,DISK], DatanodeInfoWithStorage[127.0.0.1:39384,DS-d8622ecf-edd4-4cce-b157-e7a9f17022c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42129,DS-84a94c5b-8898-4599-ba4a-43567a074b7d,DISK], DatanodeInfoWithStorage[127.0.0.1:32791,DS-ff4edf7d-aab1-483e-a4d5-1e8dd50d1afc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-549734150-172.17.0.10-1595420495014:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37971,DS-d66f593a-4faf-46dc-8f0e-47c3ccab8642,DISK], DatanodeInfoWithStorage[127.0.0.1:38640,DS-14fd921b-be62-49df-9217-529749f4ee3e,DISK], DatanodeInfoWithStorage[127.0.0.1:39697,DS-cb3ca6bc-81cf-4e25-8272-9ed0b596f9ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34830,DS-85151edf-b01b-4273-8ddb-a98b56c02182,DISK], DatanodeInfoWithStorage[127.0.0.1:46453,DS-c2a88c1b-a529-405f-973c-076c72da506a,DISK], DatanodeInfoWithStorage[127.0.0.1:36223,DS-cdae10ff-2563-4931-aa77-f26a436f83d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40432,DS-790f98ca-df8c-460a-9516-f966a2f4fd76,DISK], DatanodeInfoWithStorage[127.0.0.1:45933,DS-90a4d7d0-5546-4310-9c6d-c4857c1f754e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-549734150-172.17.0.10-1595420495014:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37971,DS-d66f593a-4faf-46dc-8f0e-47c3ccab8642,DISK], DatanodeInfoWithStorage[127.0.0.1:38640,DS-14fd921b-be62-49df-9217-529749f4ee3e,DISK], DatanodeInfoWithStorage[127.0.0.1:39697,DS-cb3ca6bc-81cf-4e25-8272-9ed0b596f9ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34830,DS-85151edf-b01b-4273-8ddb-a98b56c02182,DISK], DatanodeInfoWithStorage[127.0.0.1:46453,DS-c2a88c1b-a529-405f-973c-076c72da506a,DISK], DatanodeInfoWithStorage[127.0.0.1:36223,DS-cdae10ff-2563-4931-aa77-f26a436f83d7,DISK], DatanodeInfoWithStorage[127.0.0.1:40432,DS-790f98ca-df8c-460a-9516-f966a2f4fd76,DISK], DatanodeInfoWithStorage[127.0.0.1:45933,DS-90a4d7d0-5546-4310-9c6d-c4857c1f754e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1044225560-172.17.0.10-1595420588855:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35082,DS-3d960be6-4239-467a-97b0-60e7610a55ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36928,DS-545be3ff-0082-4d82-a993-6d28cdbb9aa8,DISK], DatanodeInfoWithStorage[127.0.0.1:45338,DS-9cf62758-110d-4fd8-874a-a3d6a047fb97,DISK], DatanodeInfoWithStorage[127.0.0.1:45847,DS-72391839-8357-46ad-8c21-8bd2e8e6621d,DISK], DatanodeInfoWithStorage[127.0.0.1:38703,DS-ef4eefdf-a62a-420b-8879-5adb99c53c3c,DISK], DatanodeInfoWithStorage[127.0.0.1:43503,DS-da87a8bc-dad4-4519-b12e-f06147ed657b,DISK], DatanodeInfoWithStorage[127.0.0.1:46536,DS-db16fd18-f407-455e-bb49-851b0da335fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36336,DS-49e80c25-4e8d-4757-b4b6-d1f10f703dfc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1044225560-172.17.0.10-1595420588855:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35082,DS-3d960be6-4239-467a-97b0-60e7610a55ba,DISK], DatanodeInfoWithStorage[127.0.0.1:36928,DS-545be3ff-0082-4d82-a993-6d28cdbb9aa8,DISK], DatanodeInfoWithStorage[127.0.0.1:45338,DS-9cf62758-110d-4fd8-874a-a3d6a047fb97,DISK], DatanodeInfoWithStorage[127.0.0.1:45847,DS-72391839-8357-46ad-8c21-8bd2e8e6621d,DISK], DatanodeInfoWithStorage[127.0.0.1:38703,DS-ef4eefdf-a62a-420b-8879-5adb99c53c3c,DISK], DatanodeInfoWithStorage[127.0.0.1:43503,DS-da87a8bc-dad4-4519-b12e-f06147ed657b,DISK], DatanodeInfoWithStorage[127.0.0.1:46536,DS-db16fd18-f407-455e-bb49-851b0da335fa,DISK], DatanodeInfoWithStorage[127.0.0.1:36336,DS-49e80c25-4e8d-4757-b4b6-d1f10f703dfc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-388303372-172.17.0.10-1595421044348:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42430,DS-effbf0eb-9e4c-49bb-bc46-c218ac728236,DISK], DatanodeInfoWithStorage[127.0.0.1:45875,DS-e7359098-252f-4818-b6c1-8790b7161037,DISK], DatanodeInfoWithStorage[127.0.0.1:38505,DS-7ac0ffe7-49d3-4824-83aa-e1ba954c6eab,DISK], DatanodeInfoWithStorage[127.0.0.1:33792,DS-46bb195b-209b-487f-8ca2-92848517deee,DISK], DatanodeInfoWithStorage[127.0.0.1:43085,DS-7bdf79de-85c5-4fcb-829a-52d0067fa622,DISK], DatanodeInfoWithStorage[127.0.0.1:39209,DS-09206e05-e196-47b2-8736-8967b331d4b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42288,DS-d0fc2515-96d7-40e8-8ddb-77bffb10e7a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44290,DS-544c5c87-c758-4676-ab9a-085373019c6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-388303372-172.17.0.10-1595421044348:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42430,DS-effbf0eb-9e4c-49bb-bc46-c218ac728236,DISK], DatanodeInfoWithStorage[127.0.0.1:45875,DS-e7359098-252f-4818-b6c1-8790b7161037,DISK], DatanodeInfoWithStorage[127.0.0.1:38505,DS-7ac0ffe7-49d3-4824-83aa-e1ba954c6eab,DISK], DatanodeInfoWithStorage[127.0.0.1:33792,DS-46bb195b-209b-487f-8ca2-92848517deee,DISK], DatanodeInfoWithStorage[127.0.0.1:43085,DS-7bdf79de-85c5-4fcb-829a-52d0067fa622,DISK], DatanodeInfoWithStorage[127.0.0.1:39209,DS-09206e05-e196-47b2-8736-8967b331d4b2,DISK], DatanodeInfoWithStorage[127.0.0.1:42288,DS-d0fc2515-96d7-40e8-8ddb-77bffb10e7a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44290,DS-544c5c87-c758-4676-ab9a-085373019c6f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1426496946-172.17.0.10-1595421417700:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44046,DS-121bdb6e-b084-423d-8bbb-68f5630a6ec4,DISK], DatanodeInfoWithStorage[127.0.0.1:40067,DS-36a15e6e-6cbe-4009-ad6a-6fc56b647dab,DISK], DatanodeInfoWithStorage[127.0.0.1:39126,DS-8943becd-b7ef-412c-afec-6e1a5d2bd3b3,DISK], DatanodeInfoWithStorage[127.0.0.1:38841,DS-faa62269-1239-4aa2-943c-a69bb855435e,DISK], DatanodeInfoWithStorage[127.0.0.1:35221,DS-49657f0b-6d0a-4bcc-b77b-ca02e7e8422d,DISK], DatanodeInfoWithStorage[127.0.0.1:43399,DS-50eb9be8-c47a-46c8-8982-8bbb04a7aa0b,DISK], DatanodeInfoWithStorage[127.0.0.1:43443,DS-0fc1d0c0-bcda-477e-bfd0-8a63b777df92,DISK], DatanodeInfoWithStorage[127.0.0.1:42177,DS-bc391bdb-3795-4a6b-a0c2-77a6784124b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1426496946-172.17.0.10-1595421417700:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44046,DS-121bdb6e-b084-423d-8bbb-68f5630a6ec4,DISK], DatanodeInfoWithStorage[127.0.0.1:40067,DS-36a15e6e-6cbe-4009-ad6a-6fc56b647dab,DISK], DatanodeInfoWithStorage[127.0.0.1:39126,DS-8943becd-b7ef-412c-afec-6e1a5d2bd3b3,DISK], DatanodeInfoWithStorage[127.0.0.1:38841,DS-faa62269-1239-4aa2-943c-a69bb855435e,DISK], DatanodeInfoWithStorage[127.0.0.1:35221,DS-49657f0b-6d0a-4bcc-b77b-ca02e7e8422d,DISK], DatanodeInfoWithStorage[127.0.0.1:43399,DS-50eb9be8-c47a-46c8-8982-8bbb04a7aa0b,DISK], DatanodeInfoWithStorage[127.0.0.1:43443,DS-0fc1d0c0-bcda-477e-bfd0-8a63b777df92,DISK], DatanodeInfoWithStorage[127.0.0.1:42177,DS-bc391bdb-3795-4a6b-a0c2-77a6784124b2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1509848410-172.17.0.10-1595421604182:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42274,DS-32529402-ebbb-4096-9ea3-f5ce046afed2,DISK], DatanodeInfoWithStorage[127.0.0.1:37052,DS-e582f806-54d5-4c57-ad3f-3940ebde0401,DISK], DatanodeInfoWithStorage[127.0.0.1:46434,DS-9632999d-cbfe-44c9-ae92-cc5f8f868a4e,DISK], DatanodeInfoWithStorage[127.0.0.1:35906,DS-4bf95c94-7f3f-4475-b878-87ddbd4640e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37512,DS-c29d5159-3bb2-4b8c-bcdf-d5a0adf8b0bb,DISK], DatanodeInfoWithStorage[127.0.0.1:43157,DS-7f0c42d6-40b1-487d-b9c8-7c119e9ab93f,DISK], DatanodeInfoWithStorage[127.0.0.1:33827,DS-a6b69bb4-aece-49f3-81b2-7fb1671fe05a,DISK], DatanodeInfoWithStorage[127.0.0.1:46349,DS-4e628de1-d664-4179-af27-88e95473fffa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1509848410-172.17.0.10-1595421604182:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42274,DS-32529402-ebbb-4096-9ea3-f5ce046afed2,DISK], DatanodeInfoWithStorage[127.0.0.1:37052,DS-e582f806-54d5-4c57-ad3f-3940ebde0401,DISK], DatanodeInfoWithStorage[127.0.0.1:46434,DS-9632999d-cbfe-44c9-ae92-cc5f8f868a4e,DISK], DatanodeInfoWithStorage[127.0.0.1:35906,DS-4bf95c94-7f3f-4475-b878-87ddbd4640e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37512,DS-c29d5159-3bb2-4b8c-bcdf-d5a0adf8b0bb,DISK], DatanodeInfoWithStorage[127.0.0.1:43157,DS-7f0c42d6-40b1-487d-b9c8-7c119e9ab93f,DISK], DatanodeInfoWithStorage[127.0.0.1:33827,DS-a6b69bb4-aece-49f3-81b2-7fb1671fe05a,DISK], DatanodeInfoWithStorage[127.0.0.1:46349,DS-4e628de1-d664-4179-af27-88e95473fffa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-964032052-172.17.0.10-1595422789756:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43635,DS-1206448e-032c-4a82-aa59-ea5bd1e306e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43949,DS-3341a65b-95c3-4bad-b94c-87b095574f6a,DISK], DatanodeInfoWithStorage[127.0.0.1:44282,DS-ddf7d5a2-ec6b-498a-a76d-245748f8f1fd,DISK], DatanodeInfoWithStorage[127.0.0.1:43584,DS-1898bda5-873c-45f2-b370-2914eafa540c,DISK], DatanodeInfoWithStorage[127.0.0.1:45903,DS-cee2ae2b-a8a8-49de-8d2e-c00e9a990278,DISK], DatanodeInfoWithStorage[127.0.0.1:44633,DS-b92f1e14-205f-4486-9606-8edaaf77255a,DISK], DatanodeInfoWithStorage[127.0.0.1:44349,DS-29422347-8087-41bd-b853-16132c618f81,DISK], DatanodeInfoWithStorage[127.0.0.1:46666,DS-1e8d5d63-03e4-4459-bfa2-0be09a14f7d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-964032052-172.17.0.10-1595422789756:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43635,DS-1206448e-032c-4a82-aa59-ea5bd1e306e5,DISK], DatanodeInfoWithStorage[127.0.0.1:43949,DS-3341a65b-95c3-4bad-b94c-87b095574f6a,DISK], DatanodeInfoWithStorage[127.0.0.1:44282,DS-ddf7d5a2-ec6b-498a-a76d-245748f8f1fd,DISK], DatanodeInfoWithStorage[127.0.0.1:43584,DS-1898bda5-873c-45f2-b370-2914eafa540c,DISK], DatanodeInfoWithStorage[127.0.0.1:45903,DS-cee2ae2b-a8a8-49de-8d2e-c00e9a990278,DISK], DatanodeInfoWithStorage[127.0.0.1:44633,DS-b92f1e14-205f-4486-9606-8edaaf77255a,DISK], DatanodeInfoWithStorage[127.0.0.1:44349,DS-29422347-8087-41bd-b853-16132c618f81,DISK], DatanodeInfoWithStorage[127.0.0.1:46666,DS-1e8d5d63-03e4-4459-bfa2-0be09a14f7d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-4232607-172.17.0.10-1595422924917:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34324,DS-20a880df-9589-436e-b483-58701ada469d,DISK], DatanodeInfoWithStorage[127.0.0.1:34225,DS-370217dc-3fb5-4080-b000-a3945e07841f,DISK], DatanodeInfoWithStorage[127.0.0.1:42423,DS-3dbcc59b-602a-44e3-a50e-021f7ac28b35,DISK], DatanodeInfoWithStorage[127.0.0.1:40535,DS-74a6d468-22b3-4ab5-a9ca-a08f23eece4c,DISK], DatanodeInfoWithStorage[127.0.0.1:39275,DS-44bad843-610c-486d-ad77-5fb97f5a9d1a,DISK], DatanodeInfoWithStorage[127.0.0.1:33102,DS-e6dfc7a6-16e7-4e00-8f44-fefa89089e63,DISK], DatanodeInfoWithStorage[127.0.0.1:40261,DS-45f6772c-af3c-4d7e-aa65-113f40ffd425,DISK], DatanodeInfoWithStorage[127.0.0.1:33080,DS-15239c24-09d9-4ed0-bd2d-82e973ef4e5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-4232607-172.17.0.10-1595422924917:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34324,DS-20a880df-9589-436e-b483-58701ada469d,DISK], DatanodeInfoWithStorage[127.0.0.1:34225,DS-370217dc-3fb5-4080-b000-a3945e07841f,DISK], DatanodeInfoWithStorage[127.0.0.1:42423,DS-3dbcc59b-602a-44e3-a50e-021f7ac28b35,DISK], DatanodeInfoWithStorage[127.0.0.1:40535,DS-74a6d468-22b3-4ab5-a9ca-a08f23eece4c,DISK], DatanodeInfoWithStorage[127.0.0.1:39275,DS-44bad843-610c-486d-ad77-5fb97f5a9d1a,DISK], DatanodeInfoWithStorage[127.0.0.1:33102,DS-e6dfc7a6-16e7-4e00-8f44-fefa89089e63,DISK], DatanodeInfoWithStorage[127.0.0.1:40261,DS-45f6772c-af3c-4d7e-aa65-113f40ffd425,DISK], DatanodeInfoWithStorage[127.0.0.1:33080,DS-15239c24-09d9-4ed0-bd2d-82e973ef4e5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-938226173-172.17.0.10-1595423057051:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43996,DS-ae2a8ffb-2898-4411-a06d-dd016756789b,DISK], DatanodeInfoWithStorage[127.0.0.1:42765,DS-0099d18b-abc7-4083-9466-fd31d5008f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:46544,DS-f4f4e910-8aa5-4f6f-9412-65c7f34de7e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41649,DS-27b538c9-d5f4-4a70-8ecf-7cedb194a158,DISK], DatanodeInfoWithStorage[127.0.0.1:39852,DS-2588a7e9-e5b9-4e27-8a55-bcf4a480602a,DISK], DatanodeInfoWithStorage[127.0.0.1:42985,DS-605ec0b6-701a-4325-af13-49af2f5d59ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38909,DS-cf702690-7826-484d-b47c-9ec3a66fd87a,DISK], DatanodeInfoWithStorage[127.0.0.1:45502,DS-a9abbffc-5280-4c50-a54b-290217164693,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-938226173-172.17.0.10-1595423057051:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43996,DS-ae2a8ffb-2898-4411-a06d-dd016756789b,DISK], DatanodeInfoWithStorage[127.0.0.1:42765,DS-0099d18b-abc7-4083-9466-fd31d5008f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:46544,DS-f4f4e910-8aa5-4f6f-9412-65c7f34de7e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41649,DS-27b538c9-d5f4-4a70-8ecf-7cedb194a158,DISK], DatanodeInfoWithStorage[127.0.0.1:39852,DS-2588a7e9-e5b9-4e27-8a55-bcf4a480602a,DISK], DatanodeInfoWithStorage[127.0.0.1:42985,DS-605ec0b6-701a-4325-af13-49af2f5d59ed,DISK], DatanodeInfoWithStorage[127.0.0.1:38909,DS-cf702690-7826-484d-b47c-9ec3a66fd87a,DISK], DatanodeInfoWithStorage[127.0.0.1:45502,DS-a9abbffc-5280-4c50-a54b-290217164693,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-549156571-172.17.0.10-1595423294755:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35207,DS-6c703619-b6eb-4904-b7e5-2a024df8d7ea,DISK], DatanodeInfoWithStorage[127.0.0.1:46738,DS-2e8a15b5-2812-494f-86fd-01b8602c5d69,DISK], DatanodeInfoWithStorage[127.0.0.1:45960,DS-3b74726d-369c-44b3-858e-f8b6e4de72c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37479,DS-01e16521-3af8-4aa2-866b-2faf3a8f1c25,DISK], DatanodeInfoWithStorage[127.0.0.1:33841,DS-114b77e7-fca0-41ab-8f54-4d6e392528a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46663,DS-3643e959-b9a8-48c4-8da2-36ef7d058ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:37608,DS-68f16249-8f82-44df-a6ea-346736a6adbb,DISK], DatanodeInfoWithStorage[127.0.0.1:41926,DS-0d5ce38c-b121-4610-ad51-aee17538692c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-549156571-172.17.0.10-1595423294755:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35207,DS-6c703619-b6eb-4904-b7e5-2a024df8d7ea,DISK], DatanodeInfoWithStorage[127.0.0.1:46738,DS-2e8a15b5-2812-494f-86fd-01b8602c5d69,DISK], DatanodeInfoWithStorage[127.0.0.1:45960,DS-3b74726d-369c-44b3-858e-f8b6e4de72c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37479,DS-01e16521-3af8-4aa2-866b-2faf3a8f1c25,DISK], DatanodeInfoWithStorage[127.0.0.1:33841,DS-114b77e7-fca0-41ab-8f54-4d6e392528a0,DISK], DatanodeInfoWithStorage[127.0.0.1:46663,DS-3643e959-b9a8-48c4-8da2-36ef7d058ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:37608,DS-68f16249-8f82-44df-a6ea-346736a6adbb,DISK], DatanodeInfoWithStorage[127.0.0.1:41926,DS-0d5ce38c-b121-4610-ad51-aee17538692c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1995561177-172.17.0.10-1595425093207:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38111,DS-8d006a6e-0007-4ae6-bd7d-ce404e640f76,DISK], DatanodeInfoWithStorage[127.0.0.1:42636,DS-90703e4c-d339-4aa1-a6e3-3f61f7568d09,DISK], DatanodeInfoWithStorage[127.0.0.1:45255,DS-715c2a7f-c010-407e-97c3-d2aae5e088a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34383,DS-2ca58fa8-5d91-4927-b886-262ced879777,DISK], DatanodeInfoWithStorage[127.0.0.1:36972,DS-156851d1-f666-4f79-9b17-7258743f55d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39027,DS-1cf170d2-4efe-4ac0-940c-60aea2e2ccca,DISK], DatanodeInfoWithStorage[127.0.0.1:35738,DS-f8b6a9b5-3a5b-4512-b625-22cc2002f848,DISK], DatanodeInfoWithStorage[127.0.0.1:36750,DS-59a9790d-18bb-4c45-a62d-ae97d0a908b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1995561177-172.17.0.10-1595425093207:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38111,DS-8d006a6e-0007-4ae6-bd7d-ce404e640f76,DISK], DatanodeInfoWithStorage[127.0.0.1:42636,DS-90703e4c-d339-4aa1-a6e3-3f61f7568d09,DISK], DatanodeInfoWithStorage[127.0.0.1:45255,DS-715c2a7f-c010-407e-97c3-d2aae5e088a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34383,DS-2ca58fa8-5d91-4927-b886-262ced879777,DISK], DatanodeInfoWithStorage[127.0.0.1:36972,DS-156851d1-f666-4f79-9b17-7258743f55d4,DISK], DatanodeInfoWithStorage[127.0.0.1:39027,DS-1cf170d2-4efe-4ac0-940c-60aea2e2ccca,DISK], DatanodeInfoWithStorage[127.0.0.1:35738,DS-f8b6a9b5-3a5b-4512-b625-22cc2002f848,DISK], DatanodeInfoWithStorage[127.0.0.1:36750,DS-59a9790d-18bb-4c45-a62d-ae97d0a908b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.tcpnodelay
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1931782679-172.17.0.10-1595425471528:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43522,DS-3024ae05-e19c-4981-aee9-34951cb2c830,DISK], DatanodeInfoWithStorage[127.0.0.1:38277,DS-2abafc0c-8ff4-4aa6-ab9d-058fb3742d76,DISK], DatanodeInfoWithStorage[127.0.0.1:41662,DS-929942e0-8678-4375-a9a8-b65c7e6dd375,DISK], DatanodeInfoWithStorage[127.0.0.1:38243,DS-d4551241-09a8-4967-a5ea-fca99bd298fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46105,DS-e348db97-9a3c-4e56-81c0-445029524b29,DISK], DatanodeInfoWithStorage[127.0.0.1:32777,DS-7b82d4b1-33e2-4710-a7a6-5efe3b44a013,DISK], DatanodeInfoWithStorage[127.0.0.1:44739,DS-2ccbc259-85d2-4fc1-8e80-83676815279f,DISK], DatanodeInfoWithStorage[127.0.0.1:40213,DS-2bc9aa81-ee34-427c-83d4-5141c5ef5b68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1931782679-172.17.0.10-1595425471528:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43522,DS-3024ae05-e19c-4981-aee9-34951cb2c830,DISK], DatanodeInfoWithStorage[127.0.0.1:38277,DS-2abafc0c-8ff4-4aa6-ab9d-058fb3742d76,DISK], DatanodeInfoWithStorage[127.0.0.1:41662,DS-929942e0-8678-4375-a9a8-b65c7e6dd375,DISK], DatanodeInfoWithStorage[127.0.0.1:38243,DS-d4551241-09a8-4967-a5ea-fca99bd298fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46105,DS-e348db97-9a3c-4e56-81c0-445029524b29,DISK], DatanodeInfoWithStorage[127.0.0.1:32777,DS-7b82d4b1-33e2-4710-a7a6-5efe3b44a013,DISK], DatanodeInfoWithStorage[127.0.0.1:44739,DS-2ccbc259-85d2-4fc1-8e80-83676815279f,DISK], DatanodeInfoWithStorage[127.0.0.1:40213,DS-2bc9aa81-ee34-427c-83d4-5141c5ef5b68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 6959
