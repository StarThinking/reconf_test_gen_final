reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1053054366-172.17.0.18-1595410973652:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39331,DS-be7e2bcb-ebc6-44b0-9b10-78ef790793ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38189,DS-c800114e-ed20-4941-b93f-86c7f589c81f,DISK], DatanodeInfoWithStorage[127.0.0.1:36621,DS-82e9201c-415f-4805-93e8-f658b89618fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42938,DS-d83cc3a2-73f7-4ec0-ba47-67a4e0ab96e0,DISK], DatanodeInfoWithStorage[127.0.0.1:32967,DS-ac94c7e3-a0c0-4ceb-a234-129eccb34e57,DISK], DatanodeInfoWithStorage[127.0.0.1:33108,DS-2b475e92-8600-4762-9026-e78d179cac9b,DISK], DatanodeInfoWithStorage[127.0.0.1:44008,DS-a5753b29-de7c-4440-ae5d-141646ef09ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36957,DS-3c7ec31c-39d7-41cd-878a-0699ccc8119c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1053054366-172.17.0.18-1595410973652:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39331,DS-be7e2bcb-ebc6-44b0-9b10-78ef790793ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38189,DS-c800114e-ed20-4941-b93f-86c7f589c81f,DISK], DatanodeInfoWithStorage[127.0.0.1:36621,DS-82e9201c-415f-4805-93e8-f658b89618fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42938,DS-d83cc3a2-73f7-4ec0-ba47-67a4e0ab96e0,DISK], DatanodeInfoWithStorage[127.0.0.1:32967,DS-ac94c7e3-a0c0-4ceb-a234-129eccb34e57,DISK], DatanodeInfoWithStorage[127.0.0.1:33108,DS-2b475e92-8600-4762-9026-e78d179cac9b,DISK], DatanodeInfoWithStorage[127.0.0.1:44008,DS-a5753b29-de7c-4440-ae5d-141646ef09ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36957,DS-3c7ec31c-39d7-41cd-878a-0699ccc8119c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2021968822-172.17.0.18-1595411465000:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36065,DS-46fc9cae-d1ac-46c1-9697-f539e752bae7,DISK], DatanodeInfoWithStorage[127.0.0.1:43562,DS-1aa7b8c6-3c11-457b-b9b5-2e12275ef0b2,DISK], DatanodeInfoWithStorage[127.0.0.1:34241,DS-be5630d5-f52b-4470-8120-b6f42a2c8d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:41353,DS-d7a7b98a-16db-407b-ab88-e377f340f606,DISK], DatanodeInfoWithStorage[127.0.0.1:39519,DS-a3e32797-2360-4b4c-acc4-713de12a9170,DISK], DatanodeInfoWithStorage[127.0.0.1:38026,DS-a1534471-ca3c-42d6-ae4a-ebf500d22afa,DISK], DatanodeInfoWithStorage[127.0.0.1:36962,DS-4df378ea-a5a2-4ccb-bede-866cef89abea,DISK], DatanodeInfoWithStorage[127.0.0.1:38962,DS-612e7997-ae1c-4366-b77f-5441435de2c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2021968822-172.17.0.18-1595411465000:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36065,DS-46fc9cae-d1ac-46c1-9697-f539e752bae7,DISK], DatanodeInfoWithStorage[127.0.0.1:43562,DS-1aa7b8c6-3c11-457b-b9b5-2e12275ef0b2,DISK], DatanodeInfoWithStorage[127.0.0.1:34241,DS-be5630d5-f52b-4470-8120-b6f42a2c8d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:41353,DS-d7a7b98a-16db-407b-ab88-e377f340f606,DISK], DatanodeInfoWithStorage[127.0.0.1:39519,DS-a3e32797-2360-4b4c-acc4-713de12a9170,DISK], DatanodeInfoWithStorage[127.0.0.1:38026,DS-a1534471-ca3c-42d6-ae4a-ebf500d22afa,DISK], DatanodeInfoWithStorage[127.0.0.1:36962,DS-4df378ea-a5a2-4ccb-bede-866cef89abea,DISK], DatanodeInfoWithStorage[127.0.0.1:38962,DS-612e7997-ae1c-4366-b77f-5441435de2c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-367863215-172.17.0.18-1595411868796:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33281,DS-676a4423-80ba-4fee-b568-4745a45c28c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36892,DS-a7dc1a18-e39f-4a4b-b573-d951815d5cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:45109,DS-17251656-2914-4045-8d1d-170168724a78,DISK], DatanodeInfoWithStorage[127.0.0.1:34549,DS-78e05efd-1fce-4ea4-8778-15cab2cbc2de,DISK], DatanodeInfoWithStorage[127.0.0.1:44314,DS-c0b6878a-5b63-409b-abb9-a55fc5777d2a,DISK], DatanodeInfoWithStorage[127.0.0.1:46131,DS-978b24ef-cbe3-492f-ade5-51b62c138237,DISK], DatanodeInfoWithStorage[127.0.0.1:42095,DS-daec5d64-c4c2-4109-a59d-d778d2ba5121,DISK], DatanodeInfoWithStorage[127.0.0.1:36613,DS-cc5faef1-1c4c-4fa5-aeec-3abdcf782e12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-367863215-172.17.0.18-1595411868796:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33281,DS-676a4423-80ba-4fee-b568-4745a45c28c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36892,DS-a7dc1a18-e39f-4a4b-b573-d951815d5cf4,DISK], DatanodeInfoWithStorage[127.0.0.1:45109,DS-17251656-2914-4045-8d1d-170168724a78,DISK], DatanodeInfoWithStorage[127.0.0.1:34549,DS-78e05efd-1fce-4ea4-8778-15cab2cbc2de,DISK], DatanodeInfoWithStorage[127.0.0.1:44314,DS-c0b6878a-5b63-409b-abb9-a55fc5777d2a,DISK], DatanodeInfoWithStorage[127.0.0.1:46131,DS-978b24ef-cbe3-492f-ade5-51b62c138237,DISK], DatanodeInfoWithStorage[127.0.0.1:42095,DS-daec5d64-c4c2-4109-a59d-d778d2ba5121,DISK], DatanodeInfoWithStorage[127.0.0.1:36613,DS-cc5faef1-1c4c-4fa5-aeec-3abdcf782e12,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1586874156-172.17.0.18-1595412796217:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41721,DS-541525ad-74ab-46a8-b436-d680c58c3313,DISK], DatanodeInfoWithStorage[127.0.0.1:37447,DS-a59f8f8c-41ff-4489-911c-3eb77b8a9753,DISK], DatanodeInfoWithStorage[127.0.0.1:36778,DS-f8dae2a9-e69c-4c8c-9cfb-249b79f3d493,DISK], DatanodeInfoWithStorage[127.0.0.1:43343,DS-f46aa688-5c4a-4eb7-bc1d-74c146091ac8,DISK], DatanodeInfoWithStorage[127.0.0.1:44091,DS-45fc0138-bd27-4ede-a854-0c996dfaca4c,DISK], DatanodeInfoWithStorage[127.0.0.1:37386,DS-71e8df4c-0a25-4c0c-b93d-fe7c96fceb09,DISK], DatanodeInfoWithStorage[127.0.0.1:40904,DS-00d221f8-a3ad-4456-84ba-ff9196ee6d88,DISK], DatanodeInfoWithStorage[127.0.0.1:35373,DS-636bd7f9-b60a-4817-a9ca-927b6499d8c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1586874156-172.17.0.18-1595412796217:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41721,DS-541525ad-74ab-46a8-b436-d680c58c3313,DISK], DatanodeInfoWithStorage[127.0.0.1:37447,DS-a59f8f8c-41ff-4489-911c-3eb77b8a9753,DISK], DatanodeInfoWithStorage[127.0.0.1:36778,DS-f8dae2a9-e69c-4c8c-9cfb-249b79f3d493,DISK], DatanodeInfoWithStorage[127.0.0.1:43343,DS-f46aa688-5c4a-4eb7-bc1d-74c146091ac8,DISK], DatanodeInfoWithStorage[127.0.0.1:44091,DS-45fc0138-bd27-4ede-a854-0c996dfaca4c,DISK], DatanodeInfoWithStorage[127.0.0.1:37386,DS-71e8df4c-0a25-4c0c-b93d-fe7c96fceb09,DISK], DatanodeInfoWithStorage[127.0.0.1:40904,DS-00d221f8-a3ad-4456-84ba-ff9196ee6d88,DISK], DatanodeInfoWithStorage[127.0.0.1:35373,DS-636bd7f9-b60a-4817-a9ca-927b6499d8c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-728334037-172.17.0.18-1595413251161:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42300,DS-a647ae8f-6702-422d-888f-1b58a062fe89,DISK], DatanodeInfoWithStorage[127.0.0.1:39371,DS-8c8543d0-9216-4485-a53f-bbc4590d9da0,DISK], DatanodeInfoWithStorage[127.0.0.1:35172,DS-1f426c91-17ee-4986-ab0f-89f09e822118,DISK], DatanodeInfoWithStorage[127.0.0.1:39968,DS-0a804023-e89e-4eb2-87b3-2a61de24a92d,DISK], DatanodeInfoWithStorage[127.0.0.1:37292,DS-44671b14-f01a-45a6-8d74-6ed277a937c1,DISK], DatanodeInfoWithStorage[127.0.0.1:42372,DS-a101081c-00ed-451a-a7e9-716fa2a58aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:44741,DS-2f9bd1a7-4c5a-4eff-b82b-5bcb455f7974,DISK], DatanodeInfoWithStorage[127.0.0.1:42569,DS-913ff71d-b837-4ab0-9d1d-318f09add688,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-728334037-172.17.0.18-1595413251161:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42300,DS-a647ae8f-6702-422d-888f-1b58a062fe89,DISK], DatanodeInfoWithStorage[127.0.0.1:39371,DS-8c8543d0-9216-4485-a53f-bbc4590d9da0,DISK], DatanodeInfoWithStorage[127.0.0.1:35172,DS-1f426c91-17ee-4986-ab0f-89f09e822118,DISK], DatanodeInfoWithStorage[127.0.0.1:39968,DS-0a804023-e89e-4eb2-87b3-2a61de24a92d,DISK], DatanodeInfoWithStorage[127.0.0.1:37292,DS-44671b14-f01a-45a6-8d74-6ed277a937c1,DISK], DatanodeInfoWithStorage[127.0.0.1:42372,DS-a101081c-00ed-451a-a7e9-716fa2a58aa5,DISK], DatanodeInfoWithStorage[127.0.0.1:44741,DS-2f9bd1a7-4c5a-4eff-b82b-5bcb455f7974,DISK], DatanodeInfoWithStorage[127.0.0.1:42569,DS-913ff71d-b837-4ab0-9d1d-318f09add688,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1911296898-172.17.0.18-1595413796616:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42982,DS-d773d8d8-c5dd-4926-acb6-f294f6bec748,DISK], DatanodeInfoWithStorage[127.0.0.1:45248,DS-90577cc8-60a9-4086-91e8-ef7cbc6f7349,DISK], DatanodeInfoWithStorage[127.0.0.1:40620,DS-0e2c75d0-df39-45f3-b4c0-a65c766900e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45034,DS-2e680307-c1c3-442f-9a2a-733fef9b7791,DISK], DatanodeInfoWithStorage[127.0.0.1:34127,DS-718df19d-2d24-4405-8e71-16832187b21d,DISK], DatanodeInfoWithStorage[127.0.0.1:38048,DS-c7a7a4d3-5d65-47b4-90e7-1fd48fd63bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:34410,DS-587f4884-a86d-4343-bbe2-88c34cc9c92e,DISK], DatanodeInfoWithStorage[127.0.0.1:35046,DS-7f9ded0b-20fc-4e41-a4eb-16221f9a8f91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1911296898-172.17.0.18-1595413796616:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42982,DS-d773d8d8-c5dd-4926-acb6-f294f6bec748,DISK], DatanodeInfoWithStorage[127.0.0.1:45248,DS-90577cc8-60a9-4086-91e8-ef7cbc6f7349,DISK], DatanodeInfoWithStorage[127.0.0.1:40620,DS-0e2c75d0-df39-45f3-b4c0-a65c766900e1,DISK], DatanodeInfoWithStorage[127.0.0.1:45034,DS-2e680307-c1c3-442f-9a2a-733fef9b7791,DISK], DatanodeInfoWithStorage[127.0.0.1:34127,DS-718df19d-2d24-4405-8e71-16832187b21d,DISK], DatanodeInfoWithStorage[127.0.0.1:38048,DS-c7a7a4d3-5d65-47b4-90e7-1fd48fd63bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:34410,DS-587f4884-a86d-4343-bbe2-88c34cc9c92e,DISK], DatanodeInfoWithStorage[127.0.0.1:35046,DS-7f9ded0b-20fc-4e41-a4eb-16221f9a8f91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1783819929-172.17.0.18-1595414270460:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38490,DS-df56a4e8-69b3-43ae-88b3-1a5c3195b791,DISK], DatanodeInfoWithStorage[127.0.0.1:42315,DS-a574d817-1319-4997-89ce-b978fa9a5ae7,DISK], DatanodeInfoWithStorage[127.0.0.1:39467,DS-b8048b1e-5616-4e1e-85c3-a09d5707b47a,DISK], DatanodeInfoWithStorage[127.0.0.1:39879,DS-16ac446c-798b-468e-8771-b0282019ca51,DISK], DatanodeInfoWithStorage[127.0.0.1:42728,DS-791c610d-549c-46a1-8e10-8cac407a0068,DISK], DatanodeInfoWithStorage[127.0.0.1:44826,DS-02a388ca-ec5f-46b6-be6a-4522a84c8171,DISK], DatanodeInfoWithStorage[127.0.0.1:44477,DS-5458a122-ea40-4bfd-9ad9-032b23815610,DISK], DatanodeInfoWithStorage[127.0.0.1:39128,DS-bbddd234-e3a5-4591-953a-681e545b7b95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1783819929-172.17.0.18-1595414270460:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38490,DS-df56a4e8-69b3-43ae-88b3-1a5c3195b791,DISK], DatanodeInfoWithStorage[127.0.0.1:42315,DS-a574d817-1319-4997-89ce-b978fa9a5ae7,DISK], DatanodeInfoWithStorage[127.0.0.1:39467,DS-b8048b1e-5616-4e1e-85c3-a09d5707b47a,DISK], DatanodeInfoWithStorage[127.0.0.1:39879,DS-16ac446c-798b-468e-8771-b0282019ca51,DISK], DatanodeInfoWithStorage[127.0.0.1:42728,DS-791c610d-549c-46a1-8e10-8cac407a0068,DISK], DatanodeInfoWithStorage[127.0.0.1:44826,DS-02a388ca-ec5f-46b6-be6a-4522a84c8171,DISK], DatanodeInfoWithStorage[127.0.0.1:44477,DS-5458a122-ea40-4bfd-9ad9-032b23815610,DISK], DatanodeInfoWithStorage[127.0.0.1:39128,DS-bbddd234-e3a5-4591-953a-681e545b7b95,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1338505944-172.17.0.18-1595414455601:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42568,DS-79ef9c96-9468-4768-866e-bc6d3ab7728f,DISK], DatanodeInfoWithStorage[127.0.0.1:36453,DS-bc7002bd-21c6-4370-9797-a25797fd1948,DISK], DatanodeInfoWithStorage[127.0.0.1:33691,DS-8436929a-0582-4445-bde1-b840e8e3d8d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38618,DS-779f7873-a7cf-4177-978f-0b90b948aacf,DISK], DatanodeInfoWithStorage[127.0.0.1:39222,DS-6e252524-7904-4aa1-a37d-5e6d53c07a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:38001,DS-91f0c5b4-be3f-4c9d-8cce-663e5451e08d,DISK], DatanodeInfoWithStorage[127.0.0.1:39210,DS-789a35bb-6ce2-4fb3-82f7-0a0f886694e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37855,DS-3a4bd1c2-ff50-4932-aec7-43ebc8fa2f4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1338505944-172.17.0.18-1595414455601:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42568,DS-79ef9c96-9468-4768-866e-bc6d3ab7728f,DISK], DatanodeInfoWithStorage[127.0.0.1:36453,DS-bc7002bd-21c6-4370-9797-a25797fd1948,DISK], DatanodeInfoWithStorage[127.0.0.1:33691,DS-8436929a-0582-4445-bde1-b840e8e3d8d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38618,DS-779f7873-a7cf-4177-978f-0b90b948aacf,DISK], DatanodeInfoWithStorage[127.0.0.1:39222,DS-6e252524-7904-4aa1-a37d-5e6d53c07a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:38001,DS-91f0c5b4-be3f-4c9d-8cce-663e5451e08d,DISK], DatanodeInfoWithStorage[127.0.0.1:39210,DS-789a35bb-6ce2-4fb3-82f7-0a0f886694e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37855,DS-3a4bd1c2-ff50-4932-aec7-43ebc8fa2f4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-6995343-172.17.0.18-1595414486480:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39297,DS-cf996490-646b-42f4-9ac1-8d85c021f713,DISK], DatanodeInfoWithStorage[127.0.0.1:45920,DS-5f84857f-e25a-4747-9627-c797a29ecd3c,DISK], DatanodeInfoWithStorage[127.0.0.1:44845,DS-9fc15acb-db0e-4f58-b5a2-c339debc64b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36757,DS-8104ddb0-464a-4113-b9f6-18e775548c07,DISK], DatanodeInfoWithStorage[127.0.0.1:40010,DS-4fb48239-0190-4f1a-a894-ba01cfbe7ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:39118,DS-2058b8b0-ec7f-424f-9541-4d5c8db22c46,DISK], DatanodeInfoWithStorage[127.0.0.1:44408,DS-e1ee24e2-cacd-47c8-bf5f-3c25b91e8e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:40277,DS-ffbb8a21-5ffe-498d-8847-d15c89f9d11f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-6995343-172.17.0.18-1595414486480:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39297,DS-cf996490-646b-42f4-9ac1-8d85c021f713,DISK], DatanodeInfoWithStorage[127.0.0.1:45920,DS-5f84857f-e25a-4747-9627-c797a29ecd3c,DISK], DatanodeInfoWithStorage[127.0.0.1:44845,DS-9fc15acb-db0e-4f58-b5a2-c339debc64b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36757,DS-8104ddb0-464a-4113-b9f6-18e775548c07,DISK], DatanodeInfoWithStorage[127.0.0.1:40010,DS-4fb48239-0190-4f1a-a894-ba01cfbe7ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:39118,DS-2058b8b0-ec7f-424f-9541-4d5c8db22c46,DISK], DatanodeInfoWithStorage[127.0.0.1:44408,DS-e1ee24e2-cacd-47c8-bf5f-3c25b91e8e1c,DISK], DatanodeInfoWithStorage[127.0.0.1:40277,DS-ffbb8a21-5ffe-498d-8847-d15c89f9d11f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1933240265-172.17.0.18-1595414586999:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39993,DS-84d1a417-b52a-466b-bb02-1e04e26923b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43373,DS-82e7163a-98a8-4f09-8a8c-9130649b3211,DISK], DatanodeInfoWithStorage[127.0.0.1:34091,DS-930c9324-477e-42d9-b97b-937861b5abb3,DISK], DatanodeInfoWithStorage[127.0.0.1:44573,DS-1bc67293-d8db-421b-82db-7c8621886a2a,DISK], DatanodeInfoWithStorage[127.0.0.1:39967,DS-551a245d-30ae-4c84-a576-1fa8b02d62da,DISK], DatanodeInfoWithStorage[127.0.0.1:37417,DS-7cb4876e-2eaa-416d-83a0-ca33ff2f1d53,DISK], DatanodeInfoWithStorage[127.0.0.1:33300,DS-f032731a-9b69-42ae-95e7-f7ac6c6b5c32,DISK], DatanodeInfoWithStorage[127.0.0.1:33506,DS-abb2be42-023d-4753-87af-9df81f2fa2a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1933240265-172.17.0.18-1595414586999:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39993,DS-84d1a417-b52a-466b-bb02-1e04e26923b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43373,DS-82e7163a-98a8-4f09-8a8c-9130649b3211,DISK], DatanodeInfoWithStorage[127.0.0.1:34091,DS-930c9324-477e-42d9-b97b-937861b5abb3,DISK], DatanodeInfoWithStorage[127.0.0.1:44573,DS-1bc67293-d8db-421b-82db-7c8621886a2a,DISK], DatanodeInfoWithStorage[127.0.0.1:39967,DS-551a245d-30ae-4c84-a576-1fa8b02d62da,DISK], DatanodeInfoWithStorage[127.0.0.1:37417,DS-7cb4876e-2eaa-416d-83a0-ca33ff2f1d53,DISK], DatanodeInfoWithStorage[127.0.0.1:33300,DS-f032731a-9b69-42ae-95e7-f7ac6c6b5c32,DISK], DatanodeInfoWithStorage[127.0.0.1:33506,DS-abb2be42-023d-4753-87af-9df81f2fa2a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1894927047-172.17.0.18-1595414741432:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45056,DS-b45bb84a-9ee1-4be4-a881-b61aceb8fb01,DISK], DatanodeInfoWithStorage[127.0.0.1:40107,DS-0599a0a0-c816-49e6-863d-ea93fdd4b3ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33692,DS-80ccc8dd-b572-400a-905e-447778fdc742,DISK], DatanodeInfoWithStorage[127.0.0.1:46687,DS-bb446d75-7a04-4a9b-9c46-67cbb1ea599c,DISK], DatanodeInfoWithStorage[127.0.0.1:42655,DS-0fa6fc1b-bc89-4a6f-a28f-4f707544461f,DISK], DatanodeInfoWithStorage[127.0.0.1:42152,DS-32c386d6-7160-4f92-be5e-949af624825e,DISK], DatanodeInfoWithStorage[127.0.0.1:42794,DS-01bddf59-c694-4f8a-bf17-88e4d75d75a6,DISK], DatanodeInfoWithStorage[127.0.0.1:41797,DS-b50e3adb-8f06-4a62-86b6-719695c1f698,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1894927047-172.17.0.18-1595414741432:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45056,DS-b45bb84a-9ee1-4be4-a881-b61aceb8fb01,DISK], DatanodeInfoWithStorage[127.0.0.1:40107,DS-0599a0a0-c816-49e6-863d-ea93fdd4b3ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33692,DS-80ccc8dd-b572-400a-905e-447778fdc742,DISK], DatanodeInfoWithStorage[127.0.0.1:46687,DS-bb446d75-7a04-4a9b-9c46-67cbb1ea599c,DISK], DatanodeInfoWithStorage[127.0.0.1:42655,DS-0fa6fc1b-bc89-4a6f-a28f-4f707544461f,DISK], DatanodeInfoWithStorage[127.0.0.1:42152,DS-32c386d6-7160-4f92-be5e-949af624825e,DISK], DatanodeInfoWithStorage[127.0.0.1:42794,DS-01bddf59-c694-4f8a-bf17-88e4d75d75a6,DISK], DatanodeInfoWithStorage[127.0.0.1:41797,DS-b50e3adb-8f06-4a62-86b6-719695c1f698,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-989790260-172.17.0.18-1595414778496:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38524,DS-ef13f4a0-2a85-4ae0-9e1a-3f68ac96af8c,DISK], DatanodeInfoWithStorage[127.0.0.1:34058,DS-4130317c-0012-4636-b7a4-5719c846b2a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41001,DS-9b19c82a-ddd8-4a9a-b605-13bbda39abe3,DISK], DatanodeInfoWithStorage[127.0.0.1:33066,DS-a70303d0-3989-47d5-a428-22e74a761559,DISK], DatanodeInfoWithStorage[127.0.0.1:33473,DS-5b786920-33ff-41e0-b125-332dd2cf814f,DISK], DatanodeInfoWithStorage[127.0.0.1:41850,DS-8e47fa74-4d0a-4f62-9893-365b3c3cb486,DISK], DatanodeInfoWithStorage[127.0.0.1:38344,DS-fae95898-5745-4cf7-bde6-b70dc33d6f86,DISK], DatanodeInfoWithStorage[127.0.0.1:42120,DS-442a3432-258d-459e-8dc8-526d0c3ff432,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-989790260-172.17.0.18-1595414778496:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38524,DS-ef13f4a0-2a85-4ae0-9e1a-3f68ac96af8c,DISK], DatanodeInfoWithStorage[127.0.0.1:34058,DS-4130317c-0012-4636-b7a4-5719c846b2a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41001,DS-9b19c82a-ddd8-4a9a-b605-13bbda39abe3,DISK], DatanodeInfoWithStorage[127.0.0.1:33066,DS-a70303d0-3989-47d5-a428-22e74a761559,DISK], DatanodeInfoWithStorage[127.0.0.1:33473,DS-5b786920-33ff-41e0-b125-332dd2cf814f,DISK], DatanodeInfoWithStorage[127.0.0.1:41850,DS-8e47fa74-4d0a-4f62-9893-365b3c3cb486,DISK], DatanodeInfoWithStorage[127.0.0.1:38344,DS-fae95898-5745-4cf7-bde6-b70dc33d6f86,DISK], DatanodeInfoWithStorage[127.0.0.1:42120,DS-442a3432-258d-459e-8dc8-526d0c3ff432,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1733604846-172.17.0.18-1595414884955:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40793,DS-c53f8bac-3da2-4409-903d-06c409daffed,DISK], DatanodeInfoWithStorage[127.0.0.1:40049,DS-bcfbe49b-0eff-43cd-95fd-5abb35a8e8e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38435,DS-f791788d-b27d-41f0-ab08-343df596a3de,DISK], DatanodeInfoWithStorage[127.0.0.1:40627,DS-24ee4200-a4ed-4360-92fb-425df325592f,DISK], DatanodeInfoWithStorage[127.0.0.1:41721,DS-82ecb398-8fc2-49d3-8e78-c143a73a67fa,DISK], DatanodeInfoWithStorage[127.0.0.1:34601,DS-1a1d0b9d-efdd-4391-a738-572276934d52,DISK], DatanodeInfoWithStorage[127.0.0.1:46442,DS-27fba4a2-23c8-48b8-8277-1f05c3346636,DISK], DatanodeInfoWithStorage[127.0.0.1:44748,DS-c464fd70-6158-4ddb-bb3d-95f9da65a3d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1733604846-172.17.0.18-1595414884955:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40793,DS-c53f8bac-3da2-4409-903d-06c409daffed,DISK], DatanodeInfoWithStorage[127.0.0.1:40049,DS-bcfbe49b-0eff-43cd-95fd-5abb35a8e8e6,DISK], DatanodeInfoWithStorage[127.0.0.1:38435,DS-f791788d-b27d-41f0-ab08-343df596a3de,DISK], DatanodeInfoWithStorage[127.0.0.1:40627,DS-24ee4200-a4ed-4360-92fb-425df325592f,DISK], DatanodeInfoWithStorage[127.0.0.1:41721,DS-82ecb398-8fc2-49d3-8e78-c143a73a67fa,DISK], DatanodeInfoWithStorage[127.0.0.1:34601,DS-1a1d0b9d-efdd-4391-a738-572276934d52,DISK], DatanodeInfoWithStorage[127.0.0.1:46442,DS-27fba4a2-23c8-48b8-8277-1f05c3346636,DISK], DatanodeInfoWithStorage[127.0.0.1:44748,DS-c464fd70-6158-4ddb-bb3d-95f9da65a3d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1072919172-172.17.0.18-1595415224286:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32880,DS-ab2f821a-7d8e-4cad-b6d1-32a2b72d6735,DISK], DatanodeInfoWithStorage[127.0.0.1:46859,DS-a4277aeb-591d-421b-aa41-f0bd51077a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:40483,DS-b0be40ca-741e-488f-8ed9-e663d979cb38,DISK], DatanodeInfoWithStorage[127.0.0.1:36330,DS-0ce25eaa-32a3-4236-a489-3aef8627d70d,DISK], DatanodeInfoWithStorage[127.0.0.1:46157,DS-d3afe553-58b3-447d-a4b4-a8dd3670a68c,DISK], DatanodeInfoWithStorage[127.0.0.1:42371,DS-944ea0fd-1390-4271-94a9-0f14cddb4658,DISK], DatanodeInfoWithStorage[127.0.0.1:39927,DS-78fab5d2-016e-4889-9a72-5a662d9a5e3e,DISK], DatanodeInfoWithStorage[127.0.0.1:42823,DS-42c62a4d-7653-4891-a042-74d07778a28d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1072919172-172.17.0.18-1595415224286:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32880,DS-ab2f821a-7d8e-4cad-b6d1-32a2b72d6735,DISK], DatanodeInfoWithStorage[127.0.0.1:46859,DS-a4277aeb-591d-421b-aa41-f0bd51077a9f,DISK], DatanodeInfoWithStorage[127.0.0.1:40483,DS-b0be40ca-741e-488f-8ed9-e663d979cb38,DISK], DatanodeInfoWithStorage[127.0.0.1:36330,DS-0ce25eaa-32a3-4236-a489-3aef8627d70d,DISK], DatanodeInfoWithStorage[127.0.0.1:46157,DS-d3afe553-58b3-447d-a4b4-a8dd3670a68c,DISK], DatanodeInfoWithStorage[127.0.0.1:42371,DS-944ea0fd-1390-4271-94a9-0f14cddb4658,DISK], DatanodeInfoWithStorage[127.0.0.1:39927,DS-78fab5d2-016e-4889-9a72-5a662d9a5e3e,DISK], DatanodeInfoWithStorage[127.0.0.1:42823,DS-42c62a4d-7653-4891-a042-74d07778a28d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5066
