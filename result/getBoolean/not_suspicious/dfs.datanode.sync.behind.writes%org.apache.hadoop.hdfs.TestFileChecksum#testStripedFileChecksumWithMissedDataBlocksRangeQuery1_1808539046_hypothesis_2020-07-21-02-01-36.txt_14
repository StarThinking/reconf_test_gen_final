reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2008951300-172.17.0.12-1595297051823:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40364,DS-3b6e6c45-a6e0-4730-b5a8-d1dc82d329bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36167,DS-8876c710-aa33-404b-ae9b-4f3f40d69b47,DISK], DatanodeInfoWithStorage[127.0.0.1:46086,DS-61c3dd38-ae9d-468e-b3c5-c44f27883525,DISK], DatanodeInfoWithStorage[127.0.0.1:43369,DS-ca5e7221-ea94-41e5-b7a3-8973cee19179,DISK], DatanodeInfoWithStorage[127.0.0.1:38950,DS-f66ab523-44f1-4057-aa6c-afede4138e56,DISK], DatanodeInfoWithStorage[127.0.0.1:35010,DS-5edc229a-ca09-4544-943b-e7a2eb8edefa,DISK], DatanodeInfoWithStorage[127.0.0.1:34982,DS-fd49a9fc-ae5f-46ad-a874-5e566ebc3a78,DISK], DatanodeInfoWithStorage[127.0.0.1:36937,DS-9b77e489-2010-461b-ba4a-bb297e3c08cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2008951300-172.17.0.12-1595297051823:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40364,DS-3b6e6c45-a6e0-4730-b5a8-d1dc82d329bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36167,DS-8876c710-aa33-404b-ae9b-4f3f40d69b47,DISK], DatanodeInfoWithStorage[127.0.0.1:46086,DS-61c3dd38-ae9d-468e-b3c5-c44f27883525,DISK], DatanodeInfoWithStorage[127.0.0.1:43369,DS-ca5e7221-ea94-41e5-b7a3-8973cee19179,DISK], DatanodeInfoWithStorage[127.0.0.1:38950,DS-f66ab523-44f1-4057-aa6c-afede4138e56,DISK], DatanodeInfoWithStorage[127.0.0.1:35010,DS-5edc229a-ca09-4544-943b-e7a2eb8edefa,DISK], DatanodeInfoWithStorage[127.0.0.1:34982,DS-fd49a9fc-ae5f-46ad-a874-5e566ebc3a78,DISK], DatanodeInfoWithStorage[127.0.0.1:36937,DS-9b77e489-2010-461b-ba4a-bb297e3c08cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-93039729-172.17.0.12-1595297152313:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42302,DS-f32f9265-2a59-4630-89ab-4e3b451e8f44,DISK], DatanodeInfoWithStorage[127.0.0.1:38021,DS-2d41c39c-c7cb-45f6-9ce7-360bef3c32c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44854,DS-e786ed09-c416-4867-a4cd-a239d02985de,DISK], DatanodeInfoWithStorage[127.0.0.1:46454,DS-498c058e-4f1b-4ae3-8aa3-8bd3ff0393ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36309,DS-a19bfab7-fb61-492d-83f2-743882be56a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37822,DS-20d1bdcc-208d-4bba-a4a5-e293ee467c49,DISK], DatanodeInfoWithStorage[127.0.0.1:44435,DS-04d7ce71-718e-42f3-8ead-36e59b5458e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44359,DS-8ddd55b2-f0af-42de-bded-ca876e927b16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-93039729-172.17.0.12-1595297152313:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42302,DS-f32f9265-2a59-4630-89ab-4e3b451e8f44,DISK], DatanodeInfoWithStorage[127.0.0.1:38021,DS-2d41c39c-c7cb-45f6-9ce7-360bef3c32c2,DISK], DatanodeInfoWithStorage[127.0.0.1:44854,DS-e786ed09-c416-4867-a4cd-a239d02985de,DISK], DatanodeInfoWithStorage[127.0.0.1:46454,DS-498c058e-4f1b-4ae3-8aa3-8bd3ff0393ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36309,DS-a19bfab7-fb61-492d-83f2-743882be56a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37822,DS-20d1bdcc-208d-4bba-a4a5-e293ee467c49,DISK], DatanodeInfoWithStorage[127.0.0.1:44435,DS-04d7ce71-718e-42f3-8ead-36e59b5458e4,DISK], DatanodeInfoWithStorage[127.0.0.1:44359,DS-8ddd55b2-f0af-42de-bded-ca876e927b16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1708764676-172.17.0.12-1595297279305:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46496,DS-e18c0b16-4ad0-4fe7-bf05-df8e88afebaf,DISK], DatanodeInfoWithStorage[127.0.0.1:43309,DS-3ce0ea6b-c8e3-443f-b136-4fbaa153cff4,DISK], DatanodeInfoWithStorage[127.0.0.1:37281,DS-fe6dfc58-13c0-4a65-bd5e-944bd7540817,DISK], DatanodeInfoWithStorage[127.0.0.1:34878,DS-ee391071-4c14-4d1b-a05e-421280699864,DISK], DatanodeInfoWithStorage[127.0.0.1:32854,DS-112d3715-5528-42f7-8269-b66fe28c6dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:36402,DS-589ebdb8-d5de-4cef-bd5b-7485ab131839,DISK], DatanodeInfoWithStorage[127.0.0.1:41263,DS-f600a85c-a9fe-4ef7-be0c-dbd3de471e38,DISK], DatanodeInfoWithStorage[127.0.0.1:44483,DS-0081f41a-e39a-428a-a128-f1add3c63a80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1708764676-172.17.0.12-1595297279305:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46496,DS-e18c0b16-4ad0-4fe7-bf05-df8e88afebaf,DISK], DatanodeInfoWithStorage[127.0.0.1:43309,DS-3ce0ea6b-c8e3-443f-b136-4fbaa153cff4,DISK], DatanodeInfoWithStorage[127.0.0.1:37281,DS-fe6dfc58-13c0-4a65-bd5e-944bd7540817,DISK], DatanodeInfoWithStorage[127.0.0.1:34878,DS-ee391071-4c14-4d1b-a05e-421280699864,DISK], DatanodeInfoWithStorage[127.0.0.1:32854,DS-112d3715-5528-42f7-8269-b66fe28c6dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:36402,DS-589ebdb8-d5de-4cef-bd5b-7485ab131839,DISK], DatanodeInfoWithStorage[127.0.0.1:41263,DS-f600a85c-a9fe-4ef7-be0c-dbd3de471e38,DISK], DatanodeInfoWithStorage[127.0.0.1:44483,DS-0081f41a-e39a-428a-a128-f1add3c63a80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-726497054-172.17.0.12-1595297311247:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38122,DS-f14b1bfb-b5f1-4b7a-a982-e3f41dbaf89f,DISK], DatanodeInfoWithStorage[127.0.0.1:41591,DS-9bf13609-4640-4da4-a3be-31158122b0eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44495,DS-22e22825-31f5-4b8f-8b99-baec7e70fd23,DISK], DatanodeInfoWithStorage[127.0.0.1:38665,DS-51b14de3-1460-44f9-83dd-0e7ec13c5bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:36277,DS-aba14290-5640-40b9-9839-761839ed9fef,DISK], DatanodeInfoWithStorage[127.0.0.1:34370,DS-568db8d5-ded1-48b0-9772-eff31d9e4cc8,DISK], DatanodeInfoWithStorage[127.0.0.1:41535,DS-cfcaf9d3-8be2-4350-959a-04a03a286ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:33549,DS-8434dbc5-9574-4c44-9fe8-d640582b4b59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-726497054-172.17.0.12-1595297311247:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38122,DS-f14b1bfb-b5f1-4b7a-a982-e3f41dbaf89f,DISK], DatanodeInfoWithStorage[127.0.0.1:41591,DS-9bf13609-4640-4da4-a3be-31158122b0eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44495,DS-22e22825-31f5-4b8f-8b99-baec7e70fd23,DISK], DatanodeInfoWithStorage[127.0.0.1:38665,DS-51b14de3-1460-44f9-83dd-0e7ec13c5bb0,DISK], DatanodeInfoWithStorage[127.0.0.1:36277,DS-aba14290-5640-40b9-9839-761839ed9fef,DISK], DatanodeInfoWithStorage[127.0.0.1:34370,DS-568db8d5-ded1-48b0-9772-eff31d9e4cc8,DISK], DatanodeInfoWithStorage[127.0.0.1:41535,DS-cfcaf9d3-8be2-4350-959a-04a03a286ccb,DISK], DatanodeInfoWithStorage[127.0.0.1:33549,DS-8434dbc5-9574-4c44-9fe8-d640582b4b59,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1337594953-172.17.0.12-1595297417647:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35729,DS-44f9a958-2f1e-4661-b384-885bd8d2efcf,DISK], DatanodeInfoWithStorage[127.0.0.1:43025,DS-c1dd3c47-d48e-4422-87d1-77e1bd186017,DISK], DatanodeInfoWithStorage[127.0.0.1:45723,DS-3b7a58bb-a4ea-494e-8e80-6daa31e01a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:45881,DS-654487ab-6d1f-43fd-a349-878996b9dd5b,DISK], DatanodeInfoWithStorage[127.0.0.1:34952,DS-5a8d0f11-b700-4e4a-9b0d-34c7a9d2e15d,DISK], DatanodeInfoWithStorage[127.0.0.1:42781,DS-aa66fad7-79f6-42ec-bc36-95a74ffa1668,DISK], DatanodeInfoWithStorage[127.0.0.1:34085,DS-0da82865-5b27-4123-8271-63d2fe649ddc,DISK], DatanodeInfoWithStorage[127.0.0.1:41918,DS-94adf966-fccd-44a3-9b75-2395b9e8a298,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1337594953-172.17.0.12-1595297417647:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35729,DS-44f9a958-2f1e-4661-b384-885bd8d2efcf,DISK], DatanodeInfoWithStorage[127.0.0.1:43025,DS-c1dd3c47-d48e-4422-87d1-77e1bd186017,DISK], DatanodeInfoWithStorage[127.0.0.1:45723,DS-3b7a58bb-a4ea-494e-8e80-6daa31e01a1c,DISK], DatanodeInfoWithStorage[127.0.0.1:45881,DS-654487ab-6d1f-43fd-a349-878996b9dd5b,DISK], DatanodeInfoWithStorage[127.0.0.1:34952,DS-5a8d0f11-b700-4e4a-9b0d-34c7a9d2e15d,DISK], DatanodeInfoWithStorage[127.0.0.1:42781,DS-aa66fad7-79f6-42ec-bc36-95a74ffa1668,DISK], DatanodeInfoWithStorage[127.0.0.1:34085,DS-0da82865-5b27-4123-8271-63d2fe649ddc,DISK], DatanodeInfoWithStorage[127.0.0.1:41918,DS-94adf966-fccd-44a3-9b75-2395b9e8a298,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-457075529-172.17.0.12-1595297616501:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33911,DS-4980699c-9803-4490-8d4f-aa9511333a81,DISK], DatanodeInfoWithStorage[127.0.0.1:39891,DS-9c8a289c-4d8b-4d4f-91a3-1cd6aacf1903,DISK], DatanodeInfoWithStorage[127.0.0.1:33921,DS-9d6031db-2c13-4338-aebb-c73e907f4a32,DISK], DatanodeInfoWithStorage[127.0.0.1:44464,DS-b08c0a3c-ade6-48f0-8bd4-b070a3573c14,DISK], DatanodeInfoWithStorage[127.0.0.1:38400,DS-8f3e21b0-45b9-4678-94c3-15266bf320af,DISK], DatanodeInfoWithStorage[127.0.0.1:44215,DS-e73df345-9a9e-453e-947c-9f5b758732c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40249,DS-34e2ab4d-913c-45c4-8f95-08d16ec0f8c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38607,DS-da770ba6-8fc7-4c47-bcc3-4f7ae76a8c8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-457075529-172.17.0.12-1595297616501:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33911,DS-4980699c-9803-4490-8d4f-aa9511333a81,DISK], DatanodeInfoWithStorage[127.0.0.1:39891,DS-9c8a289c-4d8b-4d4f-91a3-1cd6aacf1903,DISK], DatanodeInfoWithStorage[127.0.0.1:33921,DS-9d6031db-2c13-4338-aebb-c73e907f4a32,DISK], DatanodeInfoWithStorage[127.0.0.1:44464,DS-b08c0a3c-ade6-48f0-8bd4-b070a3573c14,DISK], DatanodeInfoWithStorage[127.0.0.1:38400,DS-8f3e21b0-45b9-4678-94c3-15266bf320af,DISK], DatanodeInfoWithStorage[127.0.0.1:44215,DS-e73df345-9a9e-453e-947c-9f5b758732c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40249,DS-34e2ab4d-913c-45c4-8f95-08d16ec0f8c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38607,DS-da770ba6-8fc7-4c47-bcc3-4f7ae76a8c8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-825566068-172.17.0.12-1595297983785:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40370,DS-6d53b7c0-538f-4234-82bd-6d33737d6967,DISK], DatanodeInfoWithStorage[127.0.0.1:42540,DS-8297ce18-b100-412c-a0e2-1c2d21cc04c0,DISK], DatanodeInfoWithStorage[127.0.0.1:44329,DS-4940071c-9ef9-46a1-9124-4d9f9fbb0cd6,DISK], DatanodeInfoWithStorage[127.0.0.1:45833,DS-382a044c-db65-4105-b406-4819ed784f62,DISK], DatanodeInfoWithStorage[127.0.0.1:39352,DS-eedf294f-c2e0-48ba-96ec-b92554c82330,DISK], DatanodeInfoWithStorage[127.0.0.1:35927,DS-3bdc74f3-1225-4af6-b256-015dd5082176,DISK], DatanodeInfoWithStorage[127.0.0.1:33125,DS-58962f91-3f3b-4488-afc1-9670e9240425,DISK], DatanodeInfoWithStorage[127.0.0.1:34763,DS-4105cae0-41e9-43db-89bd-556fab5bc966,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-825566068-172.17.0.12-1595297983785:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40370,DS-6d53b7c0-538f-4234-82bd-6d33737d6967,DISK], DatanodeInfoWithStorage[127.0.0.1:42540,DS-8297ce18-b100-412c-a0e2-1c2d21cc04c0,DISK], DatanodeInfoWithStorage[127.0.0.1:44329,DS-4940071c-9ef9-46a1-9124-4d9f9fbb0cd6,DISK], DatanodeInfoWithStorage[127.0.0.1:45833,DS-382a044c-db65-4105-b406-4819ed784f62,DISK], DatanodeInfoWithStorage[127.0.0.1:39352,DS-eedf294f-c2e0-48ba-96ec-b92554c82330,DISK], DatanodeInfoWithStorage[127.0.0.1:35927,DS-3bdc74f3-1225-4af6-b256-015dd5082176,DISK], DatanodeInfoWithStorage[127.0.0.1:33125,DS-58962f91-3f3b-4488-afc1-9670e9240425,DISK], DatanodeInfoWithStorage[127.0.0.1:34763,DS-4105cae0-41e9-43db-89bd-556fab5bc966,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1150935843-172.17.0.12-1595298629584:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44973,DS-e2c2a39f-e119-4a8b-8601-eebb54eaeff9,DISK], DatanodeInfoWithStorage[127.0.0.1:37952,DS-a5ba462c-29bf-429c-a774-62587aba746b,DISK], DatanodeInfoWithStorage[127.0.0.1:33908,DS-a461c9c4-ec93-4f4b-9dff-875eee71c5f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42068,DS-5256a291-ceb6-4f3b-89af-f24bc2af974a,DISK], DatanodeInfoWithStorage[127.0.0.1:36994,DS-c4e36b81-7561-463c-b0b2-6619c87a0eaf,DISK], DatanodeInfoWithStorage[127.0.0.1:36284,DS-dc56e2bf-ac69-47e0-9be2-2b2e789a727f,DISK], DatanodeInfoWithStorage[127.0.0.1:33669,DS-923ed5c1-8876-408f-8216-1847c6eda1c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38244,DS-be8dac95-f12e-4073-af7b-134f43c78d80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1150935843-172.17.0.12-1595298629584:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44973,DS-e2c2a39f-e119-4a8b-8601-eebb54eaeff9,DISK], DatanodeInfoWithStorage[127.0.0.1:37952,DS-a5ba462c-29bf-429c-a774-62587aba746b,DISK], DatanodeInfoWithStorage[127.0.0.1:33908,DS-a461c9c4-ec93-4f4b-9dff-875eee71c5f1,DISK], DatanodeInfoWithStorage[127.0.0.1:42068,DS-5256a291-ceb6-4f3b-89af-f24bc2af974a,DISK], DatanodeInfoWithStorage[127.0.0.1:36994,DS-c4e36b81-7561-463c-b0b2-6619c87a0eaf,DISK], DatanodeInfoWithStorage[127.0.0.1:36284,DS-dc56e2bf-ac69-47e0-9be2-2b2e789a727f,DISK], DatanodeInfoWithStorage[127.0.0.1:33669,DS-923ed5c1-8876-408f-8216-1847c6eda1c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38244,DS-be8dac95-f12e-4073-af7b-134f43c78d80,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1890929207-172.17.0.12-1595298926665:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33918,DS-3073e991-f072-4af2-acfd-8dc9e3c1e9ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42587,DS-7c332e4d-57a5-4434-a753-40943142c72b,DISK], DatanodeInfoWithStorage[127.0.0.1:44615,DS-c9460456-13ba-4d68-a7f0-a09080ee5479,DISK], DatanodeInfoWithStorage[127.0.0.1:36119,DS-0a7d7bee-8771-4ab9-85b5-05db8bbcc33e,DISK], DatanodeInfoWithStorage[127.0.0.1:44127,DS-268d8a25-b073-4570-aa6d-46e81204baf9,DISK], DatanodeInfoWithStorage[127.0.0.1:44412,DS-b057e975-478a-4c2a-b38f-36c1f16acada,DISK], DatanodeInfoWithStorage[127.0.0.1:37333,DS-0dbba19a-10df-4f79-8bb3-7e01d7657b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:38189,DS-66b25275-9030-496c-b2f2-b1c314e803cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1890929207-172.17.0.12-1595298926665:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33918,DS-3073e991-f072-4af2-acfd-8dc9e3c1e9ed,DISK], DatanodeInfoWithStorage[127.0.0.1:42587,DS-7c332e4d-57a5-4434-a753-40943142c72b,DISK], DatanodeInfoWithStorage[127.0.0.1:44615,DS-c9460456-13ba-4d68-a7f0-a09080ee5479,DISK], DatanodeInfoWithStorage[127.0.0.1:36119,DS-0a7d7bee-8771-4ab9-85b5-05db8bbcc33e,DISK], DatanodeInfoWithStorage[127.0.0.1:44127,DS-268d8a25-b073-4570-aa6d-46e81204baf9,DISK], DatanodeInfoWithStorage[127.0.0.1:44412,DS-b057e975-478a-4c2a-b38f-36c1f16acada,DISK], DatanodeInfoWithStorage[127.0.0.1:37333,DS-0dbba19a-10df-4f79-8bb3-7e01d7657b5e,DISK], DatanodeInfoWithStorage[127.0.0.1:38189,DS-66b25275-9030-496c-b2f2-b1c314e803cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-387759898-172.17.0.12-1595299071167:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37798,DS-0c81443a-abe7-49b8-8e76-6102edb26874,DISK], DatanodeInfoWithStorage[127.0.0.1:40415,DS-41b8ff28-70f1-4050-8ed9-36efe2dd9493,DISK], DatanodeInfoWithStorage[127.0.0.1:36709,DS-08a27c5b-cb03-4727-865e-c0c5a008a727,DISK], DatanodeInfoWithStorage[127.0.0.1:41315,DS-1df35acb-dfcd-4836-b78d-60961a8243d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34048,DS-be7d75b6-a13e-4a60-b07f-f0234075247e,DISK], DatanodeInfoWithStorage[127.0.0.1:45881,DS-51bce7ad-499c-4436-bc56-9fe7e7ff336d,DISK], DatanodeInfoWithStorage[127.0.0.1:33758,DS-7c1cc8b2-dce0-4bc7-a237-31dcf22e999b,DISK], DatanodeInfoWithStorage[127.0.0.1:43459,DS-e7d9229e-dc13-4636-917e-cd35b782f525,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-387759898-172.17.0.12-1595299071167:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37798,DS-0c81443a-abe7-49b8-8e76-6102edb26874,DISK], DatanodeInfoWithStorage[127.0.0.1:40415,DS-41b8ff28-70f1-4050-8ed9-36efe2dd9493,DISK], DatanodeInfoWithStorage[127.0.0.1:36709,DS-08a27c5b-cb03-4727-865e-c0c5a008a727,DISK], DatanodeInfoWithStorage[127.0.0.1:41315,DS-1df35acb-dfcd-4836-b78d-60961a8243d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34048,DS-be7d75b6-a13e-4a60-b07f-f0234075247e,DISK], DatanodeInfoWithStorage[127.0.0.1:45881,DS-51bce7ad-499c-4436-bc56-9fe7e7ff336d,DISK], DatanodeInfoWithStorage[127.0.0.1:33758,DS-7c1cc8b2-dce0-4bc7-a237-31dcf22e999b,DISK], DatanodeInfoWithStorage[127.0.0.1:43459,DS-e7d9229e-dc13-4636-917e-cd35b782f525,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1821837522-172.17.0.12-1595299927891:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39205,DS-501c9ff8-5529-4a9c-a2d2-5a669371c064,DISK], DatanodeInfoWithStorage[127.0.0.1:45674,DS-dd61fc8b-7b96-4fb0-b107-c3041b8ddfa0,DISK], DatanodeInfoWithStorage[127.0.0.1:44291,DS-716b787b-6cc1-42d8-a98a-85c7b7f7929b,DISK], DatanodeInfoWithStorage[127.0.0.1:40512,DS-cc236f77-1e42-485a-a3a3-2cc7498185be,DISK], DatanodeInfoWithStorage[127.0.0.1:40531,DS-e24f3240-93c9-4f97-ab18-34fe526f0455,DISK], DatanodeInfoWithStorage[127.0.0.1:39785,DS-10ad8753-4cdd-485f-aec2-405b5bf29dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:36232,DS-4a3522ab-e294-4820-bdac-c758d7828ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:42855,DS-3b3fdc9e-3b67-4243-a3bf-51f2b43c266e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1821837522-172.17.0.12-1595299927891:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39205,DS-501c9ff8-5529-4a9c-a2d2-5a669371c064,DISK], DatanodeInfoWithStorage[127.0.0.1:45674,DS-dd61fc8b-7b96-4fb0-b107-c3041b8ddfa0,DISK], DatanodeInfoWithStorage[127.0.0.1:44291,DS-716b787b-6cc1-42d8-a98a-85c7b7f7929b,DISK], DatanodeInfoWithStorage[127.0.0.1:40512,DS-cc236f77-1e42-485a-a3a3-2cc7498185be,DISK], DatanodeInfoWithStorage[127.0.0.1:40531,DS-e24f3240-93c9-4f97-ab18-34fe526f0455,DISK], DatanodeInfoWithStorage[127.0.0.1:39785,DS-10ad8753-4cdd-485f-aec2-405b5bf29dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:36232,DS-4a3522ab-e294-4820-bdac-c758d7828ac9,DISK], DatanodeInfoWithStorage[127.0.0.1:42855,DS-3b3fdc9e-3b67-4243-a3bf-51f2b43c266e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-411586490-172.17.0.12-1595299959683:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41437,DS-75579685-caaf-4846-9143-e362498ccc33,DISK], DatanodeInfoWithStorage[127.0.0.1:43851,DS-649acae2-65a1-4e24-8084-856b0f21f5b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44973,DS-8bdc97ab-a62b-4ab9-9cba-dd7966bb9f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:44941,DS-2bc56087-c44c-4b5a-aa17-5b30562558e1,DISK], DatanodeInfoWithStorage[127.0.0.1:32878,DS-d8a12ad7-b8d7-442c-9aea-29f9d61f0ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:35170,DS-1463b00a-229a-4c28-b295-19e6a0297c71,DISK], DatanodeInfoWithStorage[127.0.0.1:42279,DS-d031c3cd-49c3-43c6-9fda-f3605024aeea,DISK], DatanodeInfoWithStorage[127.0.0.1:43256,DS-7c64bb8b-d84c-4e80-9729-e804dce7cc38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-411586490-172.17.0.12-1595299959683:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41437,DS-75579685-caaf-4846-9143-e362498ccc33,DISK], DatanodeInfoWithStorage[127.0.0.1:43851,DS-649acae2-65a1-4e24-8084-856b0f21f5b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44973,DS-8bdc97ab-a62b-4ab9-9cba-dd7966bb9f5f,DISK], DatanodeInfoWithStorage[127.0.0.1:44941,DS-2bc56087-c44c-4b5a-aa17-5b30562558e1,DISK], DatanodeInfoWithStorage[127.0.0.1:32878,DS-d8a12ad7-b8d7-442c-9aea-29f9d61f0ba4,DISK], DatanodeInfoWithStorage[127.0.0.1:35170,DS-1463b00a-229a-4c28-b295-19e6a0297c71,DISK], DatanodeInfoWithStorage[127.0.0.1:42279,DS-d031c3cd-49c3-43c6-9fda-f3605024aeea,DISK], DatanodeInfoWithStorage[127.0.0.1:43256,DS-7c64bb8b-d84c-4e80-9729-e804dce7cc38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1412355301-172.17.0.12-1595300177423:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37181,DS-acc9d34e-b19b-4d43-8a75-9982c065b366,DISK], DatanodeInfoWithStorage[127.0.0.1:37882,DS-c888b40d-d42b-4f61-a551-9f8651cf88dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40419,DS-99461b42-dd2e-4ca8-a0f9-8c585a7fc1f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36772,DS-1569a31e-0d80-4157-bf07-0000cc5dce14,DISK], DatanodeInfoWithStorage[127.0.0.1:43335,DS-6a3c7c03-38b1-4bd6-bd95-b77c4d5ec831,DISK], DatanodeInfoWithStorage[127.0.0.1:35218,DS-f6cc4416-f0d8-4306-9da8-8e7db7b698d4,DISK], DatanodeInfoWithStorage[127.0.0.1:32987,DS-7217afee-178a-45ef-b861-eec257044c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:44752,DS-b4fdfa14-5ad9-4226-a9bd-5569cec5216e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1412355301-172.17.0.12-1595300177423:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37181,DS-acc9d34e-b19b-4d43-8a75-9982c065b366,DISK], DatanodeInfoWithStorage[127.0.0.1:37882,DS-c888b40d-d42b-4f61-a551-9f8651cf88dd,DISK], DatanodeInfoWithStorage[127.0.0.1:40419,DS-99461b42-dd2e-4ca8-a0f9-8c585a7fc1f3,DISK], DatanodeInfoWithStorage[127.0.0.1:36772,DS-1569a31e-0d80-4157-bf07-0000cc5dce14,DISK], DatanodeInfoWithStorage[127.0.0.1:43335,DS-6a3c7c03-38b1-4bd6-bd95-b77c4d5ec831,DISK], DatanodeInfoWithStorage[127.0.0.1:35218,DS-f6cc4416-f0d8-4306-9da8-8e7db7b698d4,DISK], DatanodeInfoWithStorage[127.0.0.1:32987,DS-7217afee-178a-45ef-b861-eec257044c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:44752,DS-b4fdfa14-5ad9-4226-a9bd-5569cec5216e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-408795187-172.17.0.12-1595300278676:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40108,DS-6cce2fb3-c7ae-4feb-a25f-7bdda2f98097,DISK], DatanodeInfoWithStorage[127.0.0.1:41737,DS-e8f4dceb-1711-4f82-8876-3fff54fd9316,DISK], DatanodeInfoWithStorage[127.0.0.1:36624,DS-a6462768-2edd-40c9-8d26-07d80782133a,DISK], DatanodeInfoWithStorage[127.0.0.1:39782,DS-769a65a8-559d-4af5-baae-bb761be9b8d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41881,DS-8054c96b-a69e-4a73-914d-9fc7f86447d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42310,DS-ade76f61-cef1-4cc7-bd20-984667cd3dd8,DISK], DatanodeInfoWithStorage[127.0.0.1:43531,DS-a6866f13-f871-4e53-b6ff-7ea551b6109e,DISK], DatanodeInfoWithStorage[127.0.0.1:33504,DS-41ded35e-04f0-486a-ba30-b114e233a4d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-408795187-172.17.0.12-1595300278676:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40108,DS-6cce2fb3-c7ae-4feb-a25f-7bdda2f98097,DISK], DatanodeInfoWithStorage[127.0.0.1:41737,DS-e8f4dceb-1711-4f82-8876-3fff54fd9316,DISK], DatanodeInfoWithStorage[127.0.0.1:36624,DS-a6462768-2edd-40c9-8d26-07d80782133a,DISK], DatanodeInfoWithStorage[127.0.0.1:39782,DS-769a65a8-559d-4af5-baae-bb761be9b8d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41881,DS-8054c96b-a69e-4a73-914d-9fc7f86447d4,DISK], DatanodeInfoWithStorage[127.0.0.1:42310,DS-ade76f61-cef1-4cc7-bd20-984667cd3dd8,DISK], DatanodeInfoWithStorage[127.0.0.1:43531,DS-a6866f13-f871-4e53-b6ff-7ea551b6109e,DISK], DatanodeInfoWithStorage[127.0.0.1:33504,DS-41ded35e-04f0-486a-ba30-b114e233a4d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-135605079-172.17.0.12-1595300315209:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35285,DS-d0f843ea-e99e-41d4-8417-da18ba403716,DISK], DatanodeInfoWithStorage[127.0.0.1:42938,DS-b35bebd0-0b55-4c20-ae47-c25a3d79ae2d,DISK], DatanodeInfoWithStorage[127.0.0.1:36131,DS-33bf0957-4d44-45ea-b843-afdac704eff5,DISK], DatanodeInfoWithStorage[127.0.0.1:44317,DS-15034850-e67d-4d42-9d53-627adacec7ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39442,DS-d47e37ac-248b-44b4-a745-d2ed414fae7f,DISK], DatanodeInfoWithStorage[127.0.0.1:33300,DS-1be7b593-0b6f-4ac4-bfbf-50c7975ebbb0,DISK], DatanodeInfoWithStorage[127.0.0.1:35226,DS-60592109-fa86-4b7e-8968-155869252aed,DISK], DatanodeInfoWithStorage[127.0.0.1:43329,DS-bd834012-7fd3-4622-98ac-09385660cbb3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-135605079-172.17.0.12-1595300315209:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35285,DS-d0f843ea-e99e-41d4-8417-da18ba403716,DISK], DatanodeInfoWithStorage[127.0.0.1:42938,DS-b35bebd0-0b55-4c20-ae47-c25a3d79ae2d,DISK], DatanodeInfoWithStorage[127.0.0.1:36131,DS-33bf0957-4d44-45ea-b843-afdac704eff5,DISK], DatanodeInfoWithStorage[127.0.0.1:44317,DS-15034850-e67d-4d42-9d53-627adacec7ee,DISK], DatanodeInfoWithStorage[127.0.0.1:39442,DS-d47e37ac-248b-44b4-a745-d2ed414fae7f,DISK], DatanodeInfoWithStorage[127.0.0.1:33300,DS-1be7b593-0b6f-4ac4-bfbf-50c7975ebbb0,DISK], DatanodeInfoWithStorage[127.0.0.1:35226,DS-60592109-fa86-4b7e-8968-155869252aed,DISK], DatanodeInfoWithStorage[127.0.0.1:43329,DS-bd834012-7fd3-4622-98ac-09385660cbb3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1138207331-172.17.0.12-1595300801106:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42413,DS-b12884cd-91cc-4493-8f73-46bbe72c028a,DISK], DatanodeInfoWithStorage[127.0.0.1:33959,DS-e73d04b0-19c5-4796-a5e7-13c732693a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:35588,DS-f4157cd1-da2d-488f-9e9d-26ef94a3d3d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39306,DS-4c46de4e-7a2f-40d2-b72f-2fdce188b89d,DISK], DatanodeInfoWithStorage[127.0.0.1:38731,DS-f31cef4b-89e9-4360-8c17-6b2980beee8d,DISK], DatanodeInfoWithStorage[127.0.0.1:46259,DS-f58b7165-c7a7-477a-96d1-abe901ca859d,DISK], DatanodeInfoWithStorage[127.0.0.1:46184,DS-cd87fe97-ff3f-4a24-8a7b-9775012bd009,DISK], DatanodeInfoWithStorage[127.0.0.1:32842,DS-8f507613-a4b9-4fd2-b022-e07cb857636e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1138207331-172.17.0.12-1595300801106:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42413,DS-b12884cd-91cc-4493-8f73-46bbe72c028a,DISK], DatanodeInfoWithStorage[127.0.0.1:33959,DS-e73d04b0-19c5-4796-a5e7-13c732693a4d,DISK], DatanodeInfoWithStorage[127.0.0.1:35588,DS-f4157cd1-da2d-488f-9e9d-26ef94a3d3d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39306,DS-4c46de4e-7a2f-40d2-b72f-2fdce188b89d,DISK], DatanodeInfoWithStorage[127.0.0.1:38731,DS-f31cef4b-89e9-4360-8c17-6b2980beee8d,DISK], DatanodeInfoWithStorage[127.0.0.1:46259,DS-f58b7165-c7a7-477a-96d1-abe901ca859d,DISK], DatanodeInfoWithStorage[127.0.0.1:46184,DS-cd87fe97-ff3f-4a24-8a7b-9775012bd009,DISK], DatanodeInfoWithStorage[127.0.0.1:32842,DS-8f507613-a4b9-4fd2-b022-e07cb857636e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1042296173-172.17.0.12-1595300866928:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36809,DS-d9c23e0c-904a-42ca-82f5-bec5adb22c54,DISK], DatanodeInfoWithStorage[127.0.0.1:34556,DS-cdb99d27-9abb-4e78-af0d-d9d261f0d38a,DISK], DatanodeInfoWithStorage[127.0.0.1:36696,DS-fc0df3a5-f180-48d4-8ef8-6305a900d575,DISK], DatanodeInfoWithStorage[127.0.0.1:40168,DS-83bf47dc-fc46-476d-a1cf-525258a1b54e,DISK], DatanodeInfoWithStorage[127.0.0.1:36623,DS-8c54fd8c-c349-4e5d-a341-fa8c477c6067,DISK], DatanodeInfoWithStorage[127.0.0.1:38980,DS-9772dc34-ec2b-446c-9df2-420e394e225f,DISK], DatanodeInfoWithStorage[127.0.0.1:34806,DS-4b829721-b05a-4e34-a290-edc4d9ac1244,DISK], DatanodeInfoWithStorage[127.0.0.1:38471,DS-692c699b-e413-47ba-80dd-413c522aab0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1042296173-172.17.0.12-1595300866928:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36809,DS-d9c23e0c-904a-42ca-82f5-bec5adb22c54,DISK], DatanodeInfoWithStorage[127.0.0.1:34556,DS-cdb99d27-9abb-4e78-af0d-d9d261f0d38a,DISK], DatanodeInfoWithStorage[127.0.0.1:36696,DS-fc0df3a5-f180-48d4-8ef8-6305a900d575,DISK], DatanodeInfoWithStorage[127.0.0.1:40168,DS-83bf47dc-fc46-476d-a1cf-525258a1b54e,DISK], DatanodeInfoWithStorage[127.0.0.1:36623,DS-8c54fd8c-c349-4e5d-a341-fa8c477c6067,DISK], DatanodeInfoWithStorage[127.0.0.1:38980,DS-9772dc34-ec2b-446c-9df2-420e394e225f,DISK], DatanodeInfoWithStorage[127.0.0.1:34806,DS-4b829721-b05a-4e34-a290-edc4d9ac1244,DISK], DatanodeInfoWithStorage[127.0.0.1:38471,DS-692c699b-e413-47ba-80dd-413c522aab0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-818271279-172.17.0.12-1595301102356:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37802,DS-3db74954-7892-44c5-979b-9eeccb65a53e,DISK], DatanodeInfoWithStorage[127.0.0.1:38172,DS-0c95602d-49a7-4127-96fb-446e9e8d0f93,DISK], DatanodeInfoWithStorage[127.0.0.1:38540,DS-5cd321e7-57c8-44b6-ace8-f0700c756b64,DISK], DatanodeInfoWithStorage[127.0.0.1:42741,DS-faa0a25a-6c04-48fb-8ad0-8f18ff77938c,DISK], DatanodeInfoWithStorage[127.0.0.1:38184,DS-0cae99ee-acca-4d5e-857a-d8f1bb24eb55,DISK], DatanodeInfoWithStorage[127.0.0.1:34841,DS-75bb6da3-3cb3-4ac6-87d5-6c662c15fcdf,DISK], DatanodeInfoWithStorage[127.0.0.1:36279,DS-7a6ef847-83b8-4008-9ce5-24fb78b14231,DISK], DatanodeInfoWithStorage[127.0.0.1:37332,DS-a6042870-84a2-4fb0-9fa4-5506370db28b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-818271279-172.17.0.12-1595301102356:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37802,DS-3db74954-7892-44c5-979b-9eeccb65a53e,DISK], DatanodeInfoWithStorage[127.0.0.1:38172,DS-0c95602d-49a7-4127-96fb-446e9e8d0f93,DISK], DatanodeInfoWithStorage[127.0.0.1:38540,DS-5cd321e7-57c8-44b6-ace8-f0700c756b64,DISK], DatanodeInfoWithStorage[127.0.0.1:42741,DS-faa0a25a-6c04-48fb-8ad0-8f18ff77938c,DISK], DatanodeInfoWithStorage[127.0.0.1:38184,DS-0cae99ee-acca-4d5e-857a-d8f1bb24eb55,DISK], DatanodeInfoWithStorage[127.0.0.1:34841,DS-75bb6da3-3cb3-4ac6-87d5-6c662c15fcdf,DISK], DatanodeInfoWithStorage[127.0.0.1:36279,DS-7a6ef847-83b8-4008-9ce5-24fb78b14231,DISK], DatanodeInfoWithStorage[127.0.0.1:37332,DS-a6042870-84a2-4fb0-9fa4-5506370db28b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2096963182-172.17.0.12-1595301483076:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42038,DS-cfb6b5aa-30c8-40b4-9661-e0dc72d10524,DISK], DatanodeInfoWithStorage[127.0.0.1:45692,DS-34b40f2a-9847-463e-80ad-d7eea7ea21d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39213,DS-1752b13f-3943-485a-9805-9d57b3da8321,DISK], DatanodeInfoWithStorage[127.0.0.1:39275,DS-ca51c07a-6c61-4255-8d83-1357899d7a72,DISK], DatanodeInfoWithStorage[127.0.0.1:44202,DS-72b11beb-45aa-4cbe-94d5-b5f43a0ae827,DISK], DatanodeInfoWithStorage[127.0.0.1:44450,DS-0c24dfa9-a5f9-45bc-8fa1-2b3059bc1278,DISK], DatanodeInfoWithStorage[127.0.0.1:38264,DS-bb65b927-25b2-4fab-98e5-162645f04e62,DISK], DatanodeInfoWithStorage[127.0.0.1:34859,DS-a1aec738-51b3-4846-9767-78a2f9896685,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2096963182-172.17.0.12-1595301483076:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42038,DS-cfb6b5aa-30c8-40b4-9661-e0dc72d10524,DISK], DatanodeInfoWithStorage[127.0.0.1:45692,DS-34b40f2a-9847-463e-80ad-d7eea7ea21d9,DISK], DatanodeInfoWithStorage[127.0.0.1:39213,DS-1752b13f-3943-485a-9805-9d57b3da8321,DISK], DatanodeInfoWithStorage[127.0.0.1:39275,DS-ca51c07a-6c61-4255-8d83-1357899d7a72,DISK], DatanodeInfoWithStorage[127.0.0.1:44202,DS-72b11beb-45aa-4cbe-94d5-b5f43a0ae827,DISK], DatanodeInfoWithStorage[127.0.0.1:44450,DS-0c24dfa9-a5f9-45bc-8fa1-2b3059bc1278,DISK], DatanodeInfoWithStorage[127.0.0.1:38264,DS-bb65b927-25b2-4fab-98e5-162645f04e62,DISK], DatanodeInfoWithStorage[127.0.0.1:34859,DS-a1aec738-51b3-4846-9767-78a2f9896685,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-83587508-172.17.0.12-1595301722985:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33936,DS-98283f4f-68c9-4cb3-ab4a-c4203ad66750,DISK], DatanodeInfoWithStorage[127.0.0.1:39691,DS-14a8db33-511d-468f-ae45-a1a5a6ff785d,DISK], DatanodeInfoWithStorage[127.0.0.1:37158,DS-20492c6f-9a1d-45fa-b12a-ae0a66700055,DISK], DatanodeInfoWithStorage[127.0.0.1:46343,DS-037658a6-f281-4648-8529-2b0f077cda91,DISK], DatanodeInfoWithStorage[127.0.0.1:45632,DS-dc523cb1-3b57-40b0-b067-118a7806de04,DISK], DatanodeInfoWithStorage[127.0.0.1:45740,DS-553b22da-e130-45d4-a008-23d4d8e3c586,DISK], DatanodeInfoWithStorage[127.0.0.1:40476,DS-42f8d89e-a87f-44a3-bdea-49f4b270153c,DISK], DatanodeInfoWithStorage[127.0.0.1:42348,DS-fd8d110b-3ab5-4084-a714-c831415a77ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-83587508-172.17.0.12-1595301722985:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33936,DS-98283f4f-68c9-4cb3-ab4a-c4203ad66750,DISK], DatanodeInfoWithStorage[127.0.0.1:39691,DS-14a8db33-511d-468f-ae45-a1a5a6ff785d,DISK], DatanodeInfoWithStorage[127.0.0.1:37158,DS-20492c6f-9a1d-45fa-b12a-ae0a66700055,DISK], DatanodeInfoWithStorage[127.0.0.1:46343,DS-037658a6-f281-4648-8529-2b0f077cda91,DISK], DatanodeInfoWithStorage[127.0.0.1:45632,DS-dc523cb1-3b57-40b0-b067-118a7806de04,DISK], DatanodeInfoWithStorage[127.0.0.1:45740,DS-553b22da-e130-45d4-a008-23d4d8e3c586,DISK], DatanodeInfoWithStorage[127.0.0.1:40476,DS-42f8d89e-a87f-44a3-bdea-49f4b270153c,DISK], DatanodeInfoWithStorage[127.0.0.1:42348,DS-fd8d110b-3ab5-4084-a714-c831415a77ec,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-895070915-172.17.0.12-1595301927769:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39754,DS-e0b76bea-9dbf-40ce-a93c-05d4298e0790,DISK], DatanodeInfoWithStorage[127.0.0.1:37746,DS-40062c50-80b1-4a55-a920-9366d8527832,DISK], DatanodeInfoWithStorage[127.0.0.1:46310,DS-7d8d3ad9-f6ad-4197-a817-a36b787457b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33815,DS-a6b190a4-52e2-4c38-8186-ee15ec6e326e,DISK], DatanodeInfoWithStorage[127.0.0.1:37154,DS-050ae17f-0fcb-4d20-bd6f-c0cd8c89395e,DISK], DatanodeInfoWithStorage[127.0.0.1:41510,DS-3076a587-20bc-4ea0-865e-62f6ce0580a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40582,DS-f6afd49b-4d77-45dd-b748-5d85a968c834,DISK], DatanodeInfoWithStorage[127.0.0.1:43663,DS-b9dde61d-6abb-44e1-873d-282e7aa6ffb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-895070915-172.17.0.12-1595301927769:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39754,DS-e0b76bea-9dbf-40ce-a93c-05d4298e0790,DISK], DatanodeInfoWithStorage[127.0.0.1:37746,DS-40062c50-80b1-4a55-a920-9366d8527832,DISK], DatanodeInfoWithStorage[127.0.0.1:46310,DS-7d8d3ad9-f6ad-4197-a817-a36b787457b7,DISK], DatanodeInfoWithStorage[127.0.0.1:33815,DS-a6b190a4-52e2-4c38-8186-ee15ec6e326e,DISK], DatanodeInfoWithStorage[127.0.0.1:37154,DS-050ae17f-0fcb-4d20-bd6f-c0cd8c89395e,DISK], DatanodeInfoWithStorage[127.0.0.1:41510,DS-3076a587-20bc-4ea0-865e-62f6ce0580a8,DISK], DatanodeInfoWithStorage[127.0.0.1:40582,DS-f6afd49b-4d77-45dd-b748-5d85a968c834,DISK], DatanodeInfoWithStorage[127.0.0.1:43663,DS-b9dde61d-6abb-44e1-873d-282e7aa6ffb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5110
