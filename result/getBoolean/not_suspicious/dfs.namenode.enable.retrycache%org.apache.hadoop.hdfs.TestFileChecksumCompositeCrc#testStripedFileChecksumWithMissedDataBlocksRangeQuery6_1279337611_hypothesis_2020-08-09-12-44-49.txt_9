reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-919835222-172.17.0.10-1596977156568:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36599,DS-2f29388c-af00-4256-a7a0-de5c3628c0ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39402,DS-25993cda-8573-420e-899e-b2a142191e4d,DISK], DatanodeInfoWithStorage[127.0.0.1:37818,DS-f0e14274-2fdb-41cc-99dd-68cd64439e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:46327,DS-c9a62432-77db-4d8a-a32c-da4864d82be5,DISK], DatanodeInfoWithStorage[127.0.0.1:35422,DS-2a272586-7308-4beb-810b-3ef94605ca88,DISK], DatanodeInfoWithStorage[127.0.0.1:37059,DS-c8cad203-0d04-4453-a46a-b4e39db76689,DISK], DatanodeInfoWithStorage[127.0.0.1:36368,DS-6b93e29a-80f5-42de-8478-36ec68af0b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:36669,DS-e2cfb6a0-3d03-4939-b455-6452f19467d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-919835222-172.17.0.10-1596977156568:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36599,DS-2f29388c-af00-4256-a7a0-de5c3628c0ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39402,DS-25993cda-8573-420e-899e-b2a142191e4d,DISK], DatanodeInfoWithStorage[127.0.0.1:37818,DS-f0e14274-2fdb-41cc-99dd-68cd64439e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:46327,DS-c9a62432-77db-4d8a-a32c-da4864d82be5,DISK], DatanodeInfoWithStorage[127.0.0.1:35422,DS-2a272586-7308-4beb-810b-3ef94605ca88,DISK], DatanodeInfoWithStorage[127.0.0.1:37059,DS-c8cad203-0d04-4453-a46a-b4e39db76689,DISK], DatanodeInfoWithStorage[127.0.0.1:36368,DS-6b93e29a-80f5-42de-8478-36ec68af0b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:36669,DS-e2cfb6a0-3d03-4939-b455-6452f19467d6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-65835419-172.17.0.10-1596977731917:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36781,DS-96784d5c-576a-4d15-ab94-a92c00dcdac8,DISK], DatanodeInfoWithStorage[127.0.0.1:34482,DS-22d024ea-7a57-44d8-a13f-ae2aa535556e,DISK], DatanodeInfoWithStorage[127.0.0.1:45004,DS-0b63c403-da78-4a30-b366-13514dccc5c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38889,DS-2de82b26-03de-4b3a-9d99-971624638534,DISK], DatanodeInfoWithStorage[127.0.0.1:36515,DS-3d5f9d12-a5ca-4bd3-b11a-40f79e710f27,DISK], DatanodeInfoWithStorage[127.0.0.1:43642,DS-b96ae672-0150-48b6-90f6-1465a6f840bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37737,DS-669d7eee-5970-499e-b3fb-22dd47b4da93,DISK], DatanodeInfoWithStorage[127.0.0.1:32907,DS-0f7d6ff3-e266-4e3a-9088-d2c8188868b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-65835419-172.17.0.10-1596977731917:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36781,DS-96784d5c-576a-4d15-ab94-a92c00dcdac8,DISK], DatanodeInfoWithStorage[127.0.0.1:34482,DS-22d024ea-7a57-44d8-a13f-ae2aa535556e,DISK], DatanodeInfoWithStorage[127.0.0.1:45004,DS-0b63c403-da78-4a30-b366-13514dccc5c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38889,DS-2de82b26-03de-4b3a-9d99-971624638534,DISK], DatanodeInfoWithStorage[127.0.0.1:36515,DS-3d5f9d12-a5ca-4bd3-b11a-40f79e710f27,DISK], DatanodeInfoWithStorage[127.0.0.1:43642,DS-b96ae672-0150-48b6-90f6-1465a6f840bc,DISK], DatanodeInfoWithStorage[127.0.0.1:37737,DS-669d7eee-5970-499e-b3fb-22dd47b4da93,DISK], DatanodeInfoWithStorage[127.0.0.1:32907,DS-0f7d6ff3-e266-4e3a-9088-d2c8188868b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-706365253-172.17.0.10-1596977825838:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45417,DS-8dac2a71-9a9f-407a-a303-ad0dc43875b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44537,DS-a82de051-6808-4a61-a7a3-2e9ee208d781,DISK], DatanodeInfoWithStorage[127.0.0.1:45409,DS-038f2378-fa3a-4cdf-b03f-88289ee3b313,DISK], DatanodeInfoWithStorage[127.0.0.1:43747,DS-ba974d6a-b5b9-41dd-8057-9645ab80acee,DISK], DatanodeInfoWithStorage[127.0.0.1:36568,DS-06116f83-b888-4fe8-8848-df46687c56c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43254,DS-a1ad68ee-8bfa-48e4-85fd-a2a43c99060f,DISK], DatanodeInfoWithStorage[127.0.0.1:44353,DS-a9944afd-d13a-4514-b450-1dc7ec5994e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44265,DS-eeafeb38-514d-4084-852c-54e2cbf20ce6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-706365253-172.17.0.10-1596977825838:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45417,DS-8dac2a71-9a9f-407a-a303-ad0dc43875b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44537,DS-a82de051-6808-4a61-a7a3-2e9ee208d781,DISK], DatanodeInfoWithStorage[127.0.0.1:45409,DS-038f2378-fa3a-4cdf-b03f-88289ee3b313,DISK], DatanodeInfoWithStorage[127.0.0.1:43747,DS-ba974d6a-b5b9-41dd-8057-9645ab80acee,DISK], DatanodeInfoWithStorage[127.0.0.1:36568,DS-06116f83-b888-4fe8-8848-df46687c56c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43254,DS-a1ad68ee-8bfa-48e4-85fd-a2a43c99060f,DISK], DatanodeInfoWithStorage[127.0.0.1:44353,DS-a9944afd-d13a-4514-b450-1dc7ec5994e2,DISK], DatanodeInfoWithStorage[127.0.0.1:44265,DS-eeafeb38-514d-4084-852c-54e2cbf20ce6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1454987580-172.17.0.10-1596978259220:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43882,DS-0addeacb-5d45-4e19-89bb-407d306d8f26,DISK], DatanodeInfoWithStorage[127.0.0.1:33328,DS-42352379-d193-4695-9276-89615be90999,DISK], DatanodeInfoWithStorage[127.0.0.1:34537,DS-cd39834b-1212-4313-a0a1-8126800dd67f,DISK], DatanodeInfoWithStorage[127.0.0.1:38704,DS-e116b6c5-d233-4069-bd84-8c1f75347bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:36275,DS-95d7a6df-b601-4966-84c0-c899fd43a4be,DISK], DatanodeInfoWithStorage[127.0.0.1:46149,DS-d278cbe4-4e17-4b67-991e-5858ff33b0ce,DISK], DatanodeInfoWithStorage[127.0.0.1:36800,DS-9fd8566b-643a-4928-973b-21410dd0794c,DISK], DatanodeInfoWithStorage[127.0.0.1:42942,DS-b8273780-bd7c-44a3-a360-3f33a53e487d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1454987580-172.17.0.10-1596978259220:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43882,DS-0addeacb-5d45-4e19-89bb-407d306d8f26,DISK], DatanodeInfoWithStorage[127.0.0.1:33328,DS-42352379-d193-4695-9276-89615be90999,DISK], DatanodeInfoWithStorage[127.0.0.1:34537,DS-cd39834b-1212-4313-a0a1-8126800dd67f,DISK], DatanodeInfoWithStorage[127.0.0.1:38704,DS-e116b6c5-d233-4069-bd84-8c1f75347bb6,DISK], DatanodeInfoWithStorage[127.0.0.1:36275,DS-95d7a6df-b601-4966-84c0-c899fd43a4be,DISK], DatanodeInfoWithStorage[127.0.0.1:46149,DS-d278cbe4-4e17-4b67-991e-5858ff33b0ce,DISK], DatanodeInfoWithStorage[127.0.0.1:36800,DS-9fd8566b-643a-4928-973b-21410dd0794c,DISK], DatanodeInfoWithStorage[127.0.0.1:42942,DS-b8273780-bd7c-44a3-a360-3f33a53e487d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2089150582-172.17.0.10-1596978304300:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37823,DS-c8705899-3c8d-4b0d-aceb-af3d4eba4ea4,DISK], DatanodeInfoWithStorage[127.0.0.1:35291,DS-32a8a328-1241-4cce-be44-6f8eea393fbd,DISK], DatanodeInfoWithStorage[127.0.0.1:44215,DS-ee050b38-719b-482b-afde-2f8cf6cece05,DISK], DatanodeInfoWithStorage[127.0.0.1:35583,DS-bf919be0-4e80-4d27-a2c3-fb6cfd97a291,DISK], DatanodeInfoWithStorage[127.0.0.1:44379,DS-7601545f-80e2-43f1-b1a1-bb5a98917315,DISK], DatanodeInfoWithStorage[127.0.0.1:35138,DS-c4abbe5c-f16e-4cb4-915a-65c2f0547c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:37414,DS-17624d99-a3d0-4c59-8586-95c1c0450e61,DISK], DatanodeInfoWithStorage[127.0.0.1:33234,DS-b41e704f-c07d-47c6-9bb7-19f1be3e729c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2089150582-172.17.0.10-1596978304300:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37823,DS-c8705899-3c8d-4b0d-aceb-af3d4eba4ea4,DISK], DatanodeInfoWithStorage[127.0.0.1:35291,DS-32a8a328-1241-4cce-be44-6f8eea393fbd,DISK], DatanodeInfoWithStorage[127.0.0.1:44215,DS-ee050b38-719b-482b-afde-2f8cf6cece05,DISK], DatanodeInfoWithStorage[127.0.0.1:35583,DS-bf919be0-4e80-4d27-a2c3-fb6cfd97a291,DISK], DatanodeInfoWithStorage[127.0.0.1:44379,DS-7601545f-80e2-43f1-b1a1-bb5a98917315,DISK], DatanodeInfoWithStorage[127.0.0.1:35138,DS-c4abbe5c-f16e-4cb4-915a-65c2f0547c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:37414,DS-17624d99-a3d0-4c59-8586-95c1c0450e61,DISK], DatanodeInfoWithStorage[127.0.0.1:33234,DS-b41e704f-c07d-47c6-9bb7-19f1be3e729c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-384379136-172.17.0.10-1596978439619:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36722,DS-7a52bcfb-f488-4bcf-bcff-3fb4d17426b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44148,DS-65093081-e6cb-40b4-8446-08ce79e3184b,DISK], DatanodeInfoWithStorage[127.0.0.1:35161,DS-b62f741d-815f-4d69-b0a4-fba346af6627,DISK], DatanodeInfoWithStorage[127.0.0.1:40594,DS-af14ddb9-12f1-40dd-a5ab-9fc33da4ad09,DISK], DatanodeInfoWithStorage[127.0.0.1:46052,DS-5de8b9e8-56d1-4b6d-8c25-b58a730d20a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45636,DS-31b152b2-909f-4915-be29-79a9eb60ecf5,DISK], DatanodeInfoWithStorage[127.0.0.1:39614,DS-6253b9ac-128e-42cf-923e-19d9f578513b,DISK], DatanodeInfoWithStorage[127.0.0.1:39420,DS-11b67827-a683-4161-b215-2627fd239537,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-384379136-172.17.0.10-1596978439619:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36722,DS-7a52bcfb-f488-4bcf-bcff-3fb4d17426b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44148,DS-65093081-e6cb-40b4-8446-08ce79e3184b,DISK], DatanodeInfoWithStorage[127.0.0.1:35161,DS-b62f741d-815f-4d69-b0a4-fba346af6627,DISK], DatanodeInfoWithStorage[127.0.0.1:40594,DS-af14ddb9-12f1-40dd-a5ab-9fc33da4ad09,DISK], DatanodeInfoWithStorage[127.0.0.1:46052,DS-5de8b9e8-56d1-4b6d-8c25-b58a730d20a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45636,DS-31b152b2-909f-4915-be29-79a9eb60ecf5,DISK], DatanodeInfoWithStorage[127.0.0.1:39614,DS-6253b9ac-128e-42cf-923e-19d9f578513b,DISK], DatanodeInfoWithStorage[127.0.0.1:39420,DS-11b67827-a683-4161-b215-2627fd239537,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-51361414-172.17.0.10-1596978619709:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40342,DS-0626df34-f86c-4132-a12f-476b4ead8cee,DISK], DatanodeInfoWithStorage[127.0.0.1:46335,DS-9d37c8a8-e590-4a4e-ab16-87908101cb56,DISK], DatanodeInfoWithStorage[127.0.0.1:46665,DS-973edb3a-4357-458e-a721-126f93306404,DISK], DatanodeInfoWithStorage[127.0.0.1:34726,DS-bf22495e-1f8e-4caa-a4ca-f79521c8eaeb,DISK], DatanodeInfoWithStorage[127.0.0.1:40725,DS-851e48f6-89e0-4b7a-852c-f1fa8074efd5,DISK], DatanodeInfoWithStorage[127.0.0.1:46619,DS-3f234e06-6022-47a6-ab3f-2a6bdc0f9d05,DISK], DatanodeInfoWithStorage[127.0.0.1:44121,DS-2950be2c-c069-4bf6-968d-f3807122dfb2,DISK], DatanodeInfoWithStorage[127.0.0.1:46311,DS-b325c3bf-3755-4201-8694-9dd86b5af856,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-51361414-172.17.0.10-1596978619709:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40342,DS-0626df34-f86c-4132-a12f-476b4ead8cee,DISK], DatanodeInfoWithStorage[127.0.0.1:46335,DS-9d37c8a8-e590-4a4e-ab16-87908101cb56,DISK], DatanodeInfoWithStorage[127.0.0.1:46665,DS-973edb3a-4357-458e-a721-126f93306404,DISK], DatanodeInfoWithStorage[127.0.0.1:34726,DS-bf22495e-1f8e-4caa-a4ca-f79521c8eaeb,DISK], DatanodeInfoWithStorage[127.0.0.1:40725,DS-851e48f6-89e0-4b7a-852c-f1fa8074efd5,DISK], DatanodeInfoWithStorage[127.0.0.1:46619,DS-3f234e06-6022-47a6-ab3f-2a6bdc0f9d05,DISK], DatanodeInfoWithStorage[127.0.0.1:44121,DS-2950be2c-c069-4bf6-968d-f3807122dfb2,DISK], DatanodeInfoWithStorage[127.0.0.1:46311,DS-b325c3bf-3755-4201-8694-9dd86b5af856,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-182469087-172.17.0.10-1596978939397:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34110,DS-8cbaaeaa-4a0b-4a51-b240-b7ad19e49c03,DISK], DatanodeInfoWithStorage[127.0.0.1:44434,DS-3ba8f440-7999-4b53-8ed1-afe7bdb11595,DISK], DatanodeInfoWithStorage[127.0.0.1:41102,DS-24536a11-83a1-4b90-9f9d-dcf6b0a1c023,DISK], DatanodeInfoWithStorage[127.0.0.1:33952,DS-5ced8582-ddf5-45e6-9d7b-87a56f9f89d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44801,DS-3b4a5834-1054-47e1-8280-df0e36eaf68e,DISK], DatanodeInfoWithStorage[127.0.0.1:34936,DS-8fa46278-a430-44f3-8886-8e76192848b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40038,DS-0ccb601b-3a83-414c-a483-52937fe76cd3,DISK], DatanodeInfoWithStorage[127.0.0.1:33626,DS-f0f47a8d-8969-4f6a-8d92-6a9e4665eae7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-182469087-172.17.0.10-1596978939397:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34110,DS-8cbaaeaa-4a0b-4a51-b240-b7ad19e49c03,DISK], DatanodeInfoWithStorage[127.0.0.1:44434,DS-3ba8f440-7999-4b53-8ed1-afe7bdb11595,DISK], DatanodeInfoWithStorage[127.0.0.1:41102,DS-24536a11-83a1-4b90-9f9d-dcf6b0a1c023,DISK], DatanodeInfoWithStorage[127.0.0.1:33952,DS-5ced8582-ddf5-45e6-9d7b-87a56f9f89d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44801,DS-3b4a5834-1054-47e1-8280-df0e36eaf68e,DISK], DatanodeInfoWithStorage[127.0.0.1:34936,DS-8fa46278-a430-44f3-8886-8e76192848b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40038,DS-0ccb601b-3a83-414c-a483-52937fe76cd3,DISK], DatanodeInfoWithStorage[127.0.0.1:33626,DS-f0f47a8d-8969-4f6a-8d92-6a9e4665eae7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2130420840-172.17.0.10-1596979113627:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39396,DS-58bfa70e-7e08-4dbe-81a3-1daab5490052,DISK], DatanodeInfoWithStorage[127.0.0.1:39019,DS-20aaf3e8-3b61-4934-92d8-ebe602b0604c,DISK], DatanodeInfoWithStorage[127.0.0.1:39708,DS-c63181da-f346-494b-bd69-40a57846bbdc,DISK], DatanodeInfoWithStorage[127.0.0.1:39882,DS-a2afa1c2-058e-429f-805a-49b668f35ead,DISK], DatanodeInfoWithStorage[127.0.0.1:33832,DS-e962bc5a-0fd6-4cca-9465-9db91103d6d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36619,DS-bcbc58a5-2d09-4007-ad87-674fd9f403d2,DISK], DatanodeInfoWithStorage[127.0.0.1:37232,DS-1b5a9c7f-4697-4c61-a2d1-c7df06a6020d,DISK], DatanodeInfoWithStorage[127.0.0.1:37506,DS-7b2b70e7-7bbd-4d45-a3f5-7546d6c22310,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2130420840-172.17.0.10-1596979113627:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39396,DS-58bfa70e-7e08-4dbe-81a3-1daab5490052,DISK], DatanodeInfoWithStorage[127.0.0.1:39019,DS-20aaf3e8-3b61-4934-92d8-ebe602b0604c,DISK], DatanodeInfoWithStorage[127.0.0.1:39708,DS-c63181da-f346-494b-bd69-40a57846bbdc,DISK], DatanodeInfoWithStorage[127.0.0.1:39882,DS-a2afa1c2-058e-429f-805a-49b668f35ead,DISK], DatanodeInfoWithStorage[127.0.0.1:33832,DS-e962bc5a-0fd6-4cca-9465-9db91103d6d5,DISK], DatanodeInfoWithStorage[127.0.0.1:36619,DS-bcbc58a5-2d09-4007-ad87-674fd9f403d2,DISK], DatanodeInfoWithStorage[127.0.0.1:37232,DS-1b5a9c7f-4697-4c61-a2d1-c7df06a6020d,DISK], DatanodeInfoWithStorage[127.0.0.1:37506,DS-7b2b70e7-7bbd-4d45-a3f5-7546d6c22310,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1336932684-172.17.0.10-1596979241546:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35452,DS-14888044-d31e-4986-8d17-e22cb975e5fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44277,DS-f1d1bb70-37f1-479b-8c8b-ff6bdab55eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:39661,DS-860c4d9d-5c2c-4c9c-ba42-dc59b801f94a,DISK], DatanodeInfoWithStorage[127.0.0.1:44992,DS-6636edcd-7607-4c62-bf09-f5b9c0d2b21f,DISK], DatanodeInfoWithStorage[127.0.0.1:43138,DS-9b2667ae-d641-45dc-bc3d-135f4d8b7323,DISK], DatanodeInfoWithStorage[127.0.0.1:35837,DS-3b3cec55-376d-481f-8028-6224f3725a02,DISK], DatanodeInfoWithStorage[127.0.0.1:37220,DS-c7a60d66-e056-42d4-8c90-8892780975b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43857,DS-4a6dd2c4-b568-44d1-815b-38ce98cd654e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1336932684-172.17.0.10-1596979241546:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35452,DS-14888044-d31e-4986-8d17-e22cb975e5fb,DISK], DatanodeInfoWithStorage[127.0.0.1:44277,DS-f1d1bb70-37f1-479b-8c8b-ff6bdab55eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:39661,DS-860c4d9d-5c2c-4c9c-ba42-dc59b801f94a,DISK], DatanodeInfoWithStorage[127.0.0.1:44992,DS-6636edcd-7607-4c62-bf09-f5b9c0d2b21f,DISK], DatanodeInfoWithStorage[127.0.0.1:43138,DS-9b2667ae-d641-45dc-bc3d-135f4d8b7323,DISK], DatanodeInfoWithStorage[127.0.0.1:35837,DS-3b3cec55-376d-481f-8028-6224f3725a02,DISK], DatanodeInfoWithStorage[127.0.0.1:37220,DS-c7a60d66-e056-42d4-8c90-8892780975b5,DISK], DatanodeInfoWithStorage[127.0.0.1:43857,DS-4a6dd2c4-b568-44d1-815b-38ce98cd654e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-456050078-172.17.0.10-1596979322612:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38476,DS-eb5f03fc-a9c2-4a0a-8846-31d003315c12,DISK], DatanodeInfoWithStorage[127.0.0.1:41258,DS-83431894-f166-4ec6-938c-4ba355901ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:45449,DS-0acb8e99-50f1-411a-8138-4ff955615fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:45294,DS-f837b8ee-d111-4b39-8226-6d34d6fe750e,DISK], DatanodeInfoWithStorage[127.0.0.1:38400,DS-ee5b2ad7-e802-4201-b8f0-e6a02740f3f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41206,DS-cad55163-0331-4724-ba22-c8fc282a44e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37109,DS-e2c7e9ee-042b-4279-9a0e-c9d118853206,DISK], DatanodeInfoWithStorage[127.0.0.1:34339,DS-08fd43c8-2587-4ea5-a79d-bcf416358b0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-456050078-172.17.0.10-1596979322612:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38476,DS-eb5f03fc-a9c2-4a0a-8846-31d003315c12,DISK], DatanodeInfoWithStorage[127.0.0.1:41258,DS-83431894-f166-4ec6-938c-4ba355901ecb,DISK], DatanodeInfoWithStorage[127.0.0.1:45449,DS-0acb8e99-50f1-411a-8138-4ff955615fa8,DISK], DatanodeInfoWithStorage[127.0.0.1:45294,DS-f837b8ee-d111-4b39-8226-6d34d6fe750e,DISK], DatanodeInfoWithStorage[127.0.0.1:38400,DS-ee5b2ad7-e802-4201-b8f0-e6a02740f3f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41206,DS-cad55163-0331-4724-ba22-c8fc282a44e2,DISK], DatanodeInfoWithStorage[127.0.0.1:37109,DS-e2c7e9ee-042b-4279-9a0e-c9d118853206,DISK], DatanodeInfoWithStorage[127.0.0.1:34339,DS-08fd43c8-2587-4ea5-a79d-bcf416358b0a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1961307450-172.17.0.10-1596979362822:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39380,DS-c65fcaaf-c225-44cd-8006-fe423b6b9d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:44212,DS-c806ed77-cd25-449d-b09c-5eaa4420f199,DISK], DatanodeInfoWithStorage[127.0.0.1:39325,DS-ae3bbbf4-a4c0-41f0-bcd6-a71543080cae,DISK], DatanodeInfoWithStorage[127.0.0.1:33827,DS-852ecdcc-ddfb-4bec-b622-0c3129e0295e,DISK], DatanodeInfoWithStorage[127.0.0.1:37592,DS-60169fbc-06bd-470a-a5a0-2962007f8a7d,DISK], DatanodeInfoWithStorage[127.0.0.1:38184,DS-1e23c7a9-ade5-43de-ac21-c0636299e1a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42997,DS-323aa0a7-6b4f-47e4-b08b-523e87feb26b,DISK], DatanodeInfoWithStorage[127.0.0.1:44839,DS-4bce1135-c91f-4ae3-93d3-84c907c5f936,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1961307450-172.17.0.10-1596979362822:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39380,DS-c65fcaaf-c225-44cd-8006-fe423b6b9d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:44212,DS-c806ed77-cd25-449d-b09c-5eaa4420f199,DISK], DatanodeInfoWithStorage[127.0.0.1:39325,DS-ae3bbbf4-a4c0-41f0-bcd6-a71543080cae,DISK], DatanodeInfoWithStorage[127.0.0.1:33827,DS-852ecdcc-ddfb-4bec-b622-0c3129e0295e,DISK], DatanodeInfoWithStorage[127.0.0.1:37592,DS-60169fbc-06bd-470a-a5a0-2962007f8a7d,DISK], DatanodeInfoWithStorage[127.0.0.1:38184,DS-1e23c7a9-ade5-43de-ac21-c0636299e1a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42997,DS-323aa0a7-6b4f-47e4-b08b-523e87feb26b,DISK], DatanodeInfoWithStorage[127.0.0.1:44839,DS-4bce1135-c91f-4ae3-93d3-84c907c5f936,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1450202433-172.17.0.10-1596979564862:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40125,DS-428a4f24-49c1-4fc0-87c9-905899987264,DISK], DatanodeInfoWithStorage[127.0.0.1:33392,DS-9959a251-d494-437f-94bd-7136493dae6f,DISK], DatanodeInfoWithStorage[127.0.0.1:41640,DS-927eff89-2c18-41aa-b0fc-46619794a538,DISK], DatanodeInfoWithStorage[127.0.0.1:39573,DS-89b63986-d949-44ff-b55e-64ec4d51ea73,DISK], DatanodeInfoWithStorage[127.0.0.1:45918,DS-6194963b-e520-4232-95f4-4d4e767a38b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44037,DS-e04fa15c-f42e-4da7-a560-1131f9dec545,DISK], DatanodeInfoWithStorage[127.0.0.1:39332,DS-8062360d-c20c-40ea-be0a-08e8762dd439,DISK], DatanodeInfoWithStorage[127.0.0.1:36693,DS-1744d808-a0fb-4ed6-814a-e6af990f8a41,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1450202433-172.17.0.10-1596979564862:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40125,DS-428a4f24-49c1-4fc0-87c9-905899987264,DISK], DatanodeInfoWithStorage[127.0.0.1:33392,DS-9959a251-d494-437f-94bd-7136493dae6f,DISK], DatanodeInfoWithStorage[127.0.0.1:41640,DS-927eff89-2c18-41aa-b0fc-46619794a538,DISK], DatanodeInfoWithStorage[127.0.0.1:39573,DS-89b63986-d949-44ff-b55e-64ec4d51ea73,DISK], DatanodeInfoWithStorage[127.0.0.1:45918,DS-6194963b-e520-4232-95f4-4d4e767a38b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44037,DS-e04fa15c-f42e-4da7-a560-1131f9dec545,DISK], DatanodeInfoWithStorage[127.0.0.1:39332,DS-8062360d-c20c-40ea-be0a-08e8762dd439,DISK], DatanodeInfoWithStorage[127.0.0.1:36693,DS-1744d808-a0fb-4ed6-814a-e6af990f8a41,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1761464217-172.17.0.10-1596979884350:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36549,DS-7bec2bf0-89ca-4b44-9b60-edda32a1b258,DISK], DatanodeInfoWithStorage[127.0.0.1:37162,DS-df55fbfe-d3db-43f8-8b01-0dfb614d9d12,DISK], DatanodeInfoWithStorage[127.0.0.1:44375,DS-d99d7526-df42-4f66-b899-77d4c91704a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46011,DS-90b5c1c8-90ba-430f-bfc4-a3c696982021,DISK], DatanodeInfoWithStorage[127.0.0.1:46596,DS-08823561-c5bf-4d13-b2f8-24d769505e97,DISK], DatanodeInfoWithStorage[127.0.0.1:41423,DS-dd2c471e-26c3-42e0-ad7e-34e388e32edf,DISK], DatanodeInfoWithStorage[127.0.0.1:41400,DS-37b4973c-27cd-4439-bb5e-34152fce7de2,DISK], DatanodeInfoWithStorage[127.0.0.1:40298,DS-c362d783-f273-4e3b-bac2-b32fca452a5c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1761464217-172.17.0.10-1596979884350:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36549,DS-7bec2bf0-89ca-4b44-9b60-edda32a1b258,DISK], DatanodeInfoWithStorage[127.0.0.1:37162,DS-df55fbfe-d3db-43f8-8b01-0dfb614d9d12,DISK], DatanodeInfoWithStorage[127.0.0.1:44375,DS-d99d7526-df42-4f66-b899-77d4c91704a5,DISK], DatanodeInfoWithStorage[127.0.0.1:46011,DS-90b5c1c8-90ba-430f-bfc4-a3c696982021,DISK], DatanodeInfoWithStorage[127.0.0.1:46596,DS-08823561-c5bf-4d13-b2f8-24d769505e97,DISK], DatanodeInfoWithStorage[127.0.0.1:41423,DS-dd2c471e-26c3-42e0-ad7e-34e388e32edf,DISK], DatanodeInfoWithStorage[127.0.0.1:41400,DS-37b4973c-27cd-4439-bb5e-34152fce7de2,DISK], DatanodeInfoWithStorage[127.0.0.1:40298,DS-c362d783-f273-4e3b-bac2-b32fca452a5c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-546768476-172.17.0.10-1596980386881:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35090,DS-ae7013af-d0b2-44de-9b42-413c087fe13a,DISK], DatanodeInfoWithStorage[127.0.0.1:34334,DS-2014683e-4c67-48a8-adaa-acc1438786c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45851,DS-e8ade076-f367-47e6-ace1-02a18c5ba4ad,DISK], DatanodeInfoWithStorage[127.0.0.1:39766,DS-9f9b5a3f-0b03-4117-9f84-e54eb11c50d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45366,DS-737e3372-4ea5-4ede-8884-13c07f2e24bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35426,DS-74a7a371-4b34-484e-8465-6105105f8ed2,DISK], DatanodeInfoWithStorage[127.0.0.1:35439,DS-1c20ed50-f3a0-4fa1-968a-8a970f58d89f,DISK], DatanodeInfoWithStorage[127.0.0.1:36479,DS-bfe570cd-1546-4e8f-8d17-699592f68aa6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-546768476-172.17.0.10-1596980386881:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35090,DS-ae7013af-d0b2-44de-9b42-413c087fe13a,DISK], DatanodeInfoWithStorage[127.0.0.1:34334,DS-2014683e-4c67-48a8-adaa-acc1438786c9,DISK], DatanodeInfoWithStorage[127.0.0.1:45851,DS-e8ade076-f367-47e6-ace1-02a18c5ba4ad,DISK], DatanodeInfoWithStorage[127.0.0.1:39766,DS-9f9b5a3f-0b03-4117-9f84-e54eb11c50d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45366,DS-737e3372-4ea5-4ede-8884-13c07f2e24bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35426,DS-74a7a371-4b34-484e-8465-6105105f8ed2,DISK], DatanodeInfoWithStorage[127.0.0.1:35439,DS-1c20ed50-f3a0-4fa1-968a-8a970f58d89f,DISK], DatanodeInfoWithStorage[127.0.0.1:36479,DS-bfe570cd-1546-4e8f-8d17-699592f68aa6,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-395016272-172.17.0.10-1596980457898:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36451,DS-65112f26-b714-4da1-bfe2-be75f84a177a,DISK], DatanodeInfoWithStorage[127.0.0.1:44632,DS-ea7ed89e-72ad-4853-b2c6-228d3306eec5,DISK], DatanodeInfoWithStorage[127.0.0.1:39680,DS-39a0b28d-e822-46fc-a4cd-3335fc90c33a,DISK], DatanodeInfoWithStorage[127.0.0.1:44997,DS-8a60b80e-30d1-4ee0-a1a9-c9089e4fba9b,DISK], DatanodeInfoWithStorage[127.0.0.1:46677,DS-669bee15-18ca-4cd2-ad19-ef0b257244c0,DISK], DatanodeInfoWithStorage[127.0.0.1:39747,DS-50cade90-3606-4a52-929a-83a466124ab1,DISK], DatanodeInfoWithStorage[127.0.0.1:40508,DS-64bd45c7-85cd-4c21-a189-7ea019e26b9a,DISK], DatanodeInfoWithStorage[127.0.0.1:35708,DS-3c9eef59-85eb-4877-aee1-3259f5a375f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-395016272-172.17.0.10-1596980457898:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36451,DS-65112f26-b714-4da1-bfe2-be75f84a177a,DISK], DatanodeInfoWithStorage[127.0.0.1:44632,DS-ea7ed89e-72ad-4853-b2c6-228d3306eec5,DISK], DatanodeInfoWithStorage[127.0.0.1:39680,DS-39a0b28d-e822-46fc-a4cd-3335fc90c33a,DISK], DatanodeInfoWithStorage[127.0.0.1:44997,DS-8a60b80e-30d1-4ee0-a1a9-c9089e4fba9b,DISK], DatanodeInfoWithStorage[127.0.0.1:46677,DS-669bee15-18ca-4cd2-ad19-ef0b257244c0,DISK], DatanodeInfoWithStorage[127.0.0.1:39747,DS-50cade90-3606-4a52-929a-83a466124ab1,DISK], DatanodeInfoWithStorage[127.0.0.1:40508,DS-64bd45c7-85cd-4c21-a189-7ea019e26b9a,DISK], DatanodeInfoWithStorage[127.0.0.1:35708,DS-3c9eef59-85eb-4877-aee1-3259f5a375f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2126767218-172.17.0.10-1596980748184:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39712,DS-5dcaf8fe-58a1-4674-b222-76d04051ead8,DISK], DatanodeInfoWithStorage[127.0.0.1:45310,DS-e295f8c7-bf61-4b4c-a76a-752d709a52ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45197,DS-5874bcb1-14da-4b8b-9bb5-33b0c25c0642,DISK], DatanodeInfoWithStorage[127.0.0.1:37987,DS-6d0dea14-71b8-48f2-99c5-0a6f357677a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44778,DS-90a9025a-ee37-4187-bf9a-ce2fc94c9e10,DISK], DatanodeInfoWithStorage[127.0.0.1:37012,DS-7fc0845c-7666-47d4-8b3c-24aeca976ada,DISK], DatanodeInfoWithStorage[127.0.0.1:33678,DS-435cdd90-999c-40d1-8946-bf3f0cccfd1a,DISK], DatanodeInfoWithStorage[127.0.0.1:42726,DS-5364e023-f962-4cad-8e37-722ba8b11c15,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2126767218-172.17.0.10-1596980748184:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39712,DS-5dcaf8fe-58a1-4674-b222-76d04051ead8,DISK], DatanodeInfoWithStorage[127.0.0.1:45310,DS-e295f8c7-bf61-4b4c-a76a-752d709a52ca,DISK], DatanodeInfoWithStorage[127.0.0.1:45197,DS-5874bcb1-14da-4b8b-9bb5-33b0c25c0642,DISK], DatanodeInfoWithStorage[127.0.0.1:37987,DS-6d0dea14-71b8-48f2-99c5-0a6f357677a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44778,DS-90a9025a-ee37-4187-bf9a-ce2fc94c9e10,DISK], DatanodeInfoWithStorage[127.0.0.1:37012,DS-7fc0845c-7666-47d4-8b3c-24aeca976ada,DISK], DatanodeInfoWithStorage[127.0.0.1:33678,DS-435cdd90-999c-40d1-8946-bf3f0cccfd1a,DISK], DatanodeInfoWithStorage[127.0.0.1:42726,DS-5364e023-f962-4cad-8e37-722ba8b11c15,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-204735644-172.17.0.10-1596980832324:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42749,DS-7cfbfac6-78e4-485f-a246-e49ae847947c,DISK], DatanodeInfoWithStorage[127.0.0.1:40694,DS-adb041ac-ab5c-4518-9d9b-9a16539a1dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:35810,DS-0a7742ac-76cd-443f-b214-d4767fdeff18,DISK], DatanodeInfoWithStorage[127.0.0.1:39377,DS-a08c04b3-8e92-4548-b592-d8ea02714198,DISK], DatanodeInfoWithStorage[127.0.0.1:42495,DS-c9ae7528-f8f4-4e8a-ac1a-458b61a70c54,DISK], DatanodeInfoWithStorage[127.0.0.1:45323,DS-1ad0978f-0a9a-42c8-a108-79c825f979a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36584,DS-1cf7f2ea-7092-442f-b92a-5e2637a0ff20,DISK], DatanodeInfoWithStorage[127.0.0.1:37842,DS-3e601226-fc5f-4da1-bb45-b0b478d9c119,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-204735644-172.17.0.10-1596980832324:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42749,DS-7cfbfac6-78e4-485f-a246-e49ae847947c,DISK], DatanodeInfoWithStorage[127.0.0.1:40694,DS-adb041ac-ab5c-4518-9d9b-9a16539a1dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:35810,DS-0a7742ac-76cd-443f-b214-d4767fdeff18,DISK], DatanodeInfoWithStorage[127.0.0.1:39377,DS-a08c04b3-8e92-4548-b592-d8ea02714198,DISK], DatanodeInfoWithStorage[127.0.0.1:42495,DS-c9ae7528-f8f4-4e8a-ac1a-458b61a70c54,DISK], DatanodeInfoWithStorage[127.0.0.1:45323,DS-1ad0978f-0a9a-42c8-a108-79c825f979a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36584,DS-1cf7f2ea-7092-442f-b92a-5e2637a0ff20,DISK], DatanodeInfoWithStorage[127.0.0.1:37842,DS-3e601226-fc5f-4da1-bb45-b0b478d9c119,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1695247123-172.17.0.10-1596980877833:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42359,DS-b16892c6-2619-4aa7-b3b0-eb8e709b7a9d,DISK], DatanodeInfoWithStorage[127.0.0.1:38516,DS-56d89d5c-1c88-454d-bf5b-739dbecd1515,DISK], DatanodeInfoWithStorage[127.0.0.1:44262,DS-e85fa941-39bb-4c99-9c6c-a9439687bd2b,DISK], DatanodeInfoWithStorage[127.0.0.1:36582,DS-80d6c022-115d-47c4-b24c-04407838c06e,DISK], DatanodeInfoWithStorage[127.0.0.1:34052,DS-3fe06cc1-c811-4e94-9fda-40c6d5bf7ce3,DISK], DatanodeInfoWithStorage[127.0.0.1:46369,DS-5a671731-12b1-4975-a50b-43930914dabf,DISK], DatanodeInfoWithStorage[127.0.0.1:40621,DS-4fec9735-b688-447c-92dd-e65c0ddd276f,DISK], DatanodeInfoWithStorage[127.0.0.1:32927,DS-b27a92b1-a3a9-4a1d-aa24-0609e509ec47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1695247123-172.17.0.10-1596980877833:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42359,DS-b16892c6-2619-4aa7-b3b0-eb8e709b7a9d,DISK], DatanodeInfoWithStorage[127.0.0.1:38516,DS-56d89d5c-1c88-454d-bf5b-739dbecd1515,DISK], DatanodeInfoWithStorage[127.0.0.1:44262,DS-e85fa941-39bb-4c99-9c6c-a9439687bd2b,DISK], DatanodeInfoWithStorage[127.0.0.1:36582,DS-80d6c022-115d-47c4-b24c-04407838c06e,DISK], DatanodeInfoWithStorage[127.0.0.1:34052,DS-3fe06cc1-c811-4e94-9fda-40c6d5bf7ce3,DISK], DatanodeInfoWithStorage[127.0.0.1:46369,DS-5a671731-12b1-4975-a50b-43930914dabf,DISK], DatanodeInfoWithStorage[127.0.0.1:40621,DS-4fec9735-b688-447c-92dd-e65c0ddd276f,DISK], DatanodeInfoWithStorage[127.0.0.1:32927,DS-b27a92b1-a3a9-4a1d-aa24-0609e509ec47,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1158404174-172.17.0.10-1596980926199:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37593,DS-48dee919-6778-4a37-abf8-c7b91c4160bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40139,DS-9b8df3e3-2b45-43e9-9aa0-f2678eeb9c11,DISK], DatanodeInfoWithStorage[127.0.0.1:42510,DS-7758abb6-05aa-4812-9f8d-3c4df938cda1,DISK], DatanodeInfoWithStorage[127.0.0.1:44695,DS-e43d2ede-860e-43a4-a1c6-012379d66f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39660,DS-95ef78e5-7b2f-4c22-8400-091ae94369ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33132,DS-eea33bd2-325f-4cd5-808d-7dc812b56ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:39794,DS-fd50851c-d53a-4002-b9ff-ed56d7a58274,DISK], DatanodeInfoWithStorage[127.0.0.1:46771,DS-99ff208c-a043-4a39-bca0-1c6f71509e97,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1158404174-172.17.0.10-1596980926199:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37593,DS-48dee919-6778-4a37-abf8-c7b91c4160bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40139,DS-9b8df3e3-2b45-43e9-9aa0-f2678eeb9c11,DISK], DatanodeInfoWithStorage[127.0.0.1:42510,DS-7758abb6-05aa-4812-9f8d-3c4df938cda1,DISK], DatanodeInfoWithStorage[127.0.0.1:44695,DS-e43d2ede-860e-43a4-a1c6-012379d66f5c,DISK], DatanodeInfoWithStorage[127.0.0.1:39660,DS-95ef78e5-7b2f-4c22-8400-091ae94369ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33132,DS-eea33bd2-325f-4cd5-808d-7dc812b56ce7,DISK], DatanodeInfoWithStorage[127.0.0.1:39794,DS-fd50851c-d53a-4002-b9ff-ed56d7a58274,DISK], DatanodeInfoWithStorage[127.0.0.1:46771,DS-99ff208c-a043-4a39-bca0-1c6f71509e97,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1001888069-172.17.0.10-1596980967477:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32789,DS-ee63a0c6-a9d3-4c8d-a5df-63a203951839,DISK], DatanodeInfoWithStorage[127.0.0.1:38499,DS-6bc41257-ef8d-4cf8-b479-3f034a9b6321,DISK], DatanodeInfoWithStorage[127.0.0.1:37839,DS-f6755704-cc20-41b0-82dd-db3a7dd7ba02,DISK], DatanodeInfoWithStorage[127.0.0.1:41744,DS-c97a2aab-90d5-4aa3-86fd-646ddb99b8b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37753,DS-5c97d418-7475-45c3-bbcb-ec1cd1e4fbaf,DISK], DatanodeInfoWithStorage[127.0.0.1:40855,DS-319a66cc-c61b-4b2e-896d-9f5330bc60e1,DISK], DatanodeInfoWithStorage[127.0.0.1:44825,DS-d37f95ae-01c2-40b0-864e-c4f22a55a674,DISK], DatanodeInfoWithStorage[127.0.0.1:40182,DS-435df7d4-7fb6-49ac-a777-291696ce0c4f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1001888069-172.17.0.10-1596980967477:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32789,DS-ee63a0c6-a9d3-4c8d-a5df-63a203951839,DISK], DatanodeInfoWithStorage[127.0.0.1:38499,DS-6bc41257-ef8d-4cf8-b479-3f034a9b6321,DISK], DatanodeInfoWithStorage[127.0.0.1:37839,DS-f6755704-cc20-41b0-82dd-db3a7dd7ba02,DISK], DatanodeInfoWithStorage[127.0.0.1:41744,DS-c97a2aab-90d5-4aa3-86fd-646ddb99b8b0,DISK], DatanodeInfoWithStorage[127.0.0.1:37753,DS-5c97d418-7475-45c3-bbcb-ec1cd1e4fbaf,DISK], DatanodeInfoWithStorage[127.0.0.1:40855,DS-319a66cc-c61b-4b2e-896d-9f5330bc60e1,DISK], DatanodeInfoWithStorage[127.0.0.1:44825,DS-d37f95ae-01c2-40b0-864e-c4f22a55a674,DISK], DatanodeInfoWithStorage[127.0.0.1:40182,DS-435df7d4-7fb6-49ac-a777-291696ce0c4f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-628703701-172.17.0.10-1596981142603:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45295,DS-67380a40-908f-4186-9a64-4ab91632585a,DISK], DatanodeInfoWithStorage[127.0.0.1:33733,DS-76d86bac-b23b-493b-8d6d-f18a8e8faa08,DISK], DatanodeInfoWithStorage[127.0.0.1:45571,DS-291e8822-3535-4c72-9854-4c2730c9d8c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45940,DS-a2dcfd1d-73dc-4964-831c-c2f2ad3a1d96,DISK], DatanodeInfoWithStorage[127.0.0.1:32896,DS-4b55a3e1-1b0a-4980-9588-829327409d66,DISK], DatanodeInfoWithStorage[127.0.0.1:42891,DS-c8aea69b-2247-4d47-9e1a-68e7acd0071a,DISK], DatanodeInfoWithStorage[127.0.0.1:38535,DS-81bcd0c7-1b12-47b7-9ae8-0abce92b4e53,DISK], DatanodeInfoWithStorage[127.0.0.1:33297,DS-a12db370-c752-4465-a5e8-ab4d3d90e2be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-628703701-172.17.0.10-1596981142603:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45295,DS-67380a40-908f-4186-9a64-4ab91632585a,DISK], DatanodeInfoWithStorage[127.0.0.1:33733,DS-76d86bac-b23b-493b-8d6d-f18a8e8faa08,DISK], DatanodeInfoWithStorage[127.0.0.1:45571,DS-291e8822-3535-4c72-9854-4c2730c9d8c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45940,DS-a2dcfd1d-73dc-4964-831c-c2f2ad3a1d96,DISK], DatanodeInfoWithStorage[127.0.0.1:32896,DS-4b55a3e1-1b0a-4980-9588-829327409d66,DISK], DatanodeInfoWithStorage[127.0.0.1:42891,DS-c8aea69b-2247-4d47-9e1a-68e7acd0071a,DISK], DatanodeInfoWithStorage[127.0.0.1:38535,DS-81bcd0c7-1b12-47b7-9ae8-0abce92b4e53,DISK], DatanodeInfoWithStorage[127.0.0.1:33297,DS-a12db370-c752-4465-a5e8-ab4d3d90e2be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1337188828-172.17.0.10-1596981316438:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40472,DS-69024d37-559b-4cec-badf-1f7578fff26d,DISK], DatanodeInfoWithStorage[127.0.0.1:35461,DS-82091d9f-99f1-4b3e-89c5-a3d64bfb8ef8,DISK], DatanodeInfoWithStorage[127.0.0.1:42369,DS-afc70a1d-92dc-4336-8a3e-542defaf1fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:38490,DS-92cd8354-077b-4102-ad2f-7d7fef43e1e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45553,DS-ca0a3fc2-2f22-43a1-929b-dd8f310d0618,DISK], DatanodeInfoWithStorage[127.0.0.1:42787,DS-ace4b74d-2c89-40fc-b589-151f8f513bce,DISK], DatanodeInfoWithStorage[127.0.0.1:46648,DS-5de63883-e7ac-47aa-bacd-dcac451d17a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43158,DS-5e49d6dd-cb56-418b-9cbf-c95883ccbcb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1337188828-172.17.0.10-1596981316438:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40472,DS-69024d37-559b-4cec-badf-1f7578fff26d,DISK], DatanodeInfoWithStorage[127.0.0.1:35461,DS-82091d9f-99f1-4b3e-89c5-a3d64bfb8ef8,DISK], DatanodeInfoWithStorage[127.0.0.1:42369,DS-afc70a1d-92dc-4336-8a3e-542defaf1fdf,DISK], DatanodeInfoWithStorage[127.0.0.1:38490,DS-92cd8354-077b-4102-ad2f-7d7fef43e1e0,DISK], DatanodeInfoWithStorage[127.0.0.1:45553,DS-ca0a3fc2-2f22-43a1-929b-dd8f310d0618,DISK], DatanodeInfoWithStorage[127.0.0.1:42787,DS-ace4b74d-2c89-40fc-b589-151f8f513bce,DISK], DatanodeInfoWithStorage[127.0.0.1:46648,DS-5de63883-e7ac-47aa-bacd-dcac451d17a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43158,DS-5e49d6dd-cb56-418b-9cbf-c95883ccbcb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1159498795-172.17.0.10-1596981369690:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40562,DS-61f0919e-c94e-4c25-89a3-e0fab489296d,DISK], DatanodeInfoWithStorage[127.0.0.1:42782,DS-8c004273-d967-4e49-ae71-c5f5cd3db823,DISK], DatanodeInfoWithStorage[127.0.0.1:42344,DS-25e3c859-6dc4-4dcd-8e4c-1e766ab23713,DISK], DatanodeInfoWithStorage[127.0.0.1:34708,DS-d1b8b249-2832-4779-a1e2-6fd5534dfa6a,DISK], DatanodeInfoWithStorage[127.0.0.1:42304,DS-1e77e975-6e5b-4938-8c52-1bf778c12958,DISK], DatanodeInfoWithStorage[127.0.0.1:43580,DS-9b000411-e8ed-4fa7-b93b-3f180614e8a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37846,DS-7e0eb77a-6acb-4235-b583-0cb5a0a12f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:42552,DS-978cbbaf-37cf-41ee-8157-cffa3a1f57c7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1159498795-172.17.0.10-1596981369690:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40562,DS-61f0919e-c94e-4c25-89a3-e0fab489296d,DISK], DatanodeInfoWithStorage[127.0.0.1:42782,DS-8c004273-d967-4e49-ae71-c5f5cd3db823,DISK], DatanodeInfoWithStorage[127.0.0.1:42344,DS-25e3c859-6dc4-4dcd-8e4c-1e766ab23713,DISK], DatanodeInfoWithStorage[127.0.0.1:34708,DS-d1b8b249-2832-4779-a1e2-6fd5534dfa6a,DISK], DatanodeInfoWithStorage[127.0.0.1:42304,DS-1e77e975-6e5b-4938-8c52-1bf778c12958,DISK], DatanodeInfoWithStorage[127.0.0.1:43580,DS-9b000411-e8ed-4fa7-b93b-3f180614e8a7,DISK], DatanodeInfoWithStorage[127.0.0.1:37846,DS-7e0eb77a-6acb-4235-b583-0cb5a0a12f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:42552,DS-978cbbaf-37cf-41ee-8157-cffa3a1f57c7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1507184164-172.17.0.10-1596981784398:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43020,DS-ab6f6546-d185-41b1-bfa9-ae6f1d4d52d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38921,DS-8baf0238-e05d-4da8-bdf2-0eed8fea3c91,DISK], DatanodeInfoWithStorage[127.0.0.1:40656,DS-6bc1ec10-eb04-4b69-b4de-dbd79af50f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:43841,DS-bd8215fa-9fd9-470b-83c3-45105a08ca23,DISK], DatanodeInfoWithStorage[127.0.0.1:33049,DS-7b45bb29-3c54-4c74-b44a-7583816e1dc6,DISK], DatanodeInfoWithStorage[127.0.0.1:45620,DS-4a09e410-1672-4a51-8411-55b8446866a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41887,DS-037c9381-40cb-42b2-a63d-a33e0ff3f4c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43375,DS-0ed85713-213f-45e9-b539-1a258ac3b17f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1507184164-172.17.0.10-1596981784398:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43020,DS-ab6f6546-d185-41b1-bfa9-ae6f1d4d52d5,DISK], DatanodeInfoWithStorage[127.0.0.1:38921,DS-8baf0238-e05d-4da8-bdf2-0eed8fea3c91,DISK], DatanodeInfoWithStorage[127.0.0.1:40656,DS-6bc1ec10-eb04-4b69-b4de-dbd79af50f1c,DISK], DatanodeInfoWithStorage[127.0.0.1:43841,DS-bd8215fa-9fd9-470b-83c3-45105a08ca23,DISK], DatanodeInfoWithStorage[127.0.0.1:33049,DS-7b45bb29-3c54-4c74-b44a-7583816e1dc6,DISK], DatanodeInfoWithStorage[127.0.0.1:45620,DS-4a09e410-1672-4a51-8411-55b8446866a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41887,DS-037c9381-40cb-42b2-a63d-a33e0ff3f4c6,DISK], DatanodeInfoWithStorage[127.0.0.1:43375,DS-0ed85713-213f-45e9-b539-1a258ac3b17f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1435836752-172.17.0.10-1596981991062:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38541,DS-3ecf02e0-e13f-4ffe-816d-5cb4fda94f03,DISK], DatanodeInfoWithStorage[127.0.0.1:43325,DS-e528481a-09fd-4e11-90db-6fcd86768101,DISK], DatanodeInfoWithStorage[127.0.0.1:43888,DS-767bb8d1-c5a9-4016-a302-5178f0fdc918,DISK], DatanodeInfoWithStorage[127.0.0.1:39801,DS-a58cf40c-b149-47f2-8fc6-1d7598b506be,DISK], DatanodeInfoWithStorage[127.0.0.1:41372,DS-b5de782b-20d3-415b-a014-f1c3fb1897ca,DISK], DatanodeInfoWithStorage[127.0.0.1:38373,DS-fe86ac27-c74a-4d88-b834-4fe81b156bba,DISK], DatanodeInfoWithStorage[127.0.0.1:46487,DS-d48adda7-4a00-40e1-bc2f-9374de11c61e,DISK], DatanodeInfoWithStorage[127.0.0.1:44832,DS-c95688d8-e673-4186-8511-07bd9acaecb8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1435836752-172.17.0.10-1596981991062:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38541,DS-3ecf02e0-e13f-4ffe-816d-5cb4fda94f03,DISK], DatanodeInfoWithStorage[127.0.0.1:43325,DS-e528481a-09fd-4e11-90db-6fcd86768101,DISK], DatanodeInfoWithStorage[127.0.0.1:43888,DS-767bb8d1-c5a9-4016-a302-5178f0fdc918,DISK], DatanodeInfoWithStorage[127.0.0.1:39801,DS-a58cf40c-b149-47f2-8fc6-1d7598b506be,DISK], DatanodeInfoWithStorage[127.0.0.1:41372,DS-b5de782b-20d3-415b-a014-f1c3fb1897ca,DISK], DatanodeInfoWithStorage[127.0.0.1:38373,DS-fe86ac27-c74a-4d88-b834-4fe81b156bba,DISK], DatanodeInfoWithStorage[127.0.0.1:46487,DS-d48adda7-4a00-40e1-bc2f-9374de11c61e,DISK], DatanodeInfoWithStorage[127.0.0.1:44832,DS-c95688d8-e673-4186-8511-07bd9acaecb8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-117945860-172.17.0.10-1596982157129:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44517,DS-501d1e30-be28-4650-8410-1a7cea3240f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45352,DS-9b6d03cf-85e0-49d1-9930-fb186fa95835,DISK], DatanodeInfoWithStorage[127.0.0.1:37803,DS-371cca8c-f217-4efc-9825-94ba1d9fd23c,DISK], DatanodeInfoWithStorage[127.0.0.1:41242,DS-d78ece63-2e2a-471f-955b-23bd96f2e2cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34463,DS-2d78a2f0-52e7-4b25-9572-a33fa73f2e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:39024,DS-3dffc698-0ef3-4d7c-a6b0-e18c49ab2669,DISK], DatanodeInfoWithStorage[127.0.0.1:44960,DS-fa48c1e4-e355-4389-a75d-2abf4e088251,DISK], DatanodeInfoWithStorage[127.0.0.1:44905,DS-a4370605-e3cc-4f5c-8d01-e68845d23fbc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-117945860-172.17.0.10-1596982157129:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44517,DS-501d1e30-be28-4650-8410-1a7cea3240f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45352,DS-9b6d03cf-85e0-49d1-9930-fb186fa95835,DISK], DatanodeInfoWithStorage[127.0.0.1:37803,DS-371cca8c-f217-4efc-9825-94ba1d9fd23c,DISK], DatanodeInfoWithStorage[127.0.0.1:41242,DS-d78ece63-2e2a-471f-955b-23bd96f2e2cc,DISK], DatanodeInfoWithStorage[127.0.0.1:34463,DS-2d78a2f0-52e7-4b25-9572-a33fa73f2e1b,DISK], DatanodeInfoWithStorage[127.0.0.1:39024,DS-3dffc698-0ef3-4d7c-a6b0-e18c49ab2669,DISK], DatanodeInfoWithStorage[127.0.0.1:44960,DS-fa48c1e4-e355-4389-a75d-2abf4e088251,DISK], DatanodeInfoWithStorage[127.0.0.1:44905,DS-a4370605-e3cc-4f5c-8d01-e68845d23fbc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1686895658-172.17.0.10-1596982336078:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35909,DS-3d9f9bbb-05b0-4dd5-a999-dd14f62bbe8c,DISK], DatanodeInfoWithStorage[127.0.0.1:39158,DS-4827fb9f-74c9-4fe8-9f2e-d581becab0a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33818,DS-b587b003-ce76-4330-b9b8-47954af5781c,DISK], DatanodeInfoWithStorage[127.0.0.1:32877,DS-0abedf88-95d7-4017-b1fb-34339061f277,DISK], DatanodeInfoWithStorage[127.0.0.1:37548,DS-f3c3ee55-71f3-4229-9066-9ca345718b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:33798,DS-a305f725-0414-4a1a-8724-8ea98b266394,DISK], DatanodeInfoWithStorage[127.0.0.1:44930,DS-7b5d2aac-ac86-4874-abf6-7f274c25d590,DISK], DatanodeInfoWithStorage[127.0.0.1:39880,DS-625cc792-5080-469d-99b8-6e1a70612d18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1686895658-172.17.0.10-1596982336078:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35909,DS-3d9f9bbb-05b0-4dd5-a999-dd14f62bbe8c,DISK], DatanodeInfoWithStorage[127.0.0.1:39158,DS-4827fb9f-74c9-4fe8-9f2e-d581becab0a4,DISK], DatanodeInfoWithStorage[127.0.0.1:33818,DS-b587b003-ce76-4330-b9b8-47954af5781c,DISK], DatanodeInfoWithStorage[127.0.0.1:32877,DS-0abedf88-95d7-4017-b1fb-34339061f277,DISK], DatanodeInfoWithStorage[127.0.0.1:37548,DS-f3c3ee55-71f3-4229-9066-9ca345718b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:33798,DS-a305f725-0414-4a1a-8724-8ea98b266394,DISK], DatanodeInfoWithStorage[127.0.0.1:44930,DS-7b5d2aac-ac86-4874-abf6-7f274c25d590,DISK], DatanodeInfoWithStorage[127.0.0.1:39880,DS-625cc792-5080-469d-99b8-6e1a70612d18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-726641507-172.17.0.10-1596982416637:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38144,DS-b9c682a5-5b9b-4c6f-abb1-1214280bfea2,DISK], DatanodeInfoWithStorage[127.0.0.1:36481,DS-632202fa-cf8d-48c4-a04e-45f45c47b662,DISK], DatanodeInfoWithStorage[127.0.0.1:44162,DS-b25992a5-4b9c-43ad-a52b-a20b3fa2d756,DISK], DatanodeInfoWithStorage[127.0.0.1:33674,DS-b9fe34aa-b8ce-47e4-8c7d-888b374a4288,DISK], DatanodeInfoWithStorage[127.0.0.1:42247,DS-7248e09c-32b0-4ed3-816c-1482fb633575,DISK], DatanodeInfoWithStorage[127.0.0.1:39676,DS-7ea1aae5-77be-470a-9248-0994d38109af,DISK], DatanodeInfoWithStorage[127.0.0.1:41583,DS-760eb6ad-fa42-483e-abb5-26e61cf32950,DISK], DatanodeInfoWithStorage[127.0.0.1:37789,DS-4e6e7924-9baa-4db0-9849-29b790db1df5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-726641507-172.17.0.10-1596982416637:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38144,DS-b9c682a5-5b9b-4c6f-abb1-1214280bfea2,DISK], DatanodeInfoWithStorage[127.0.0.1:36481,DS-632202fa-cf8d-48c4-a04e-45f45c47b662,DISK], DatanodeInfoWithStorage[127.0.0.1:44162,DS-b25992a5-4b9c-43ad-a52b-a20b3fa2d756,DISK], DatanodeInfoWithStorage[127.0.0.1:33674,DS-b9fe34aa-b8ce-47e4-8c7d-888b374a4288,DISK], DatanodeInfoWithStorage[127.0.0.1:42247,DS-7248e09c-32b0-4ed3-816c-1482fb633575,DISK], DatanodeInfoWithStorage[127.0.0.1:39676,DS-7ea1aae5-77be-470a-9248-0994d38109af,DISK], DatanodeInfoWithStorage[127.0.0.1:41583,DS-760eb6ad-fa42-483e-abb5-26e61cf32950,DISK], DatanodeInfoWithStorage[127.0.0.1:37789,DS-4e6e7924-9baa-4db0-9849-29b790db1df5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-414695734-172.17.0.10-1596982502534:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45625,DS-abd62b88-d9e0-4da1-8d6d-84ebb3b23eb6,DISK], DatanodeInfoWithStorage[127.0.0.1:40319,DS-dbd6abfd-4612-46bb-a782-aecdd5e5cda3,DISK], DatanodeInfoWithStorage[127.0.0.1:38332,DS-92d29656-7994-46aa-bb9d-d6af1323a3ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43056,DS-e31b80d9-89d7-4296-9f9b-540dc20c9590,DISK], DatanodeInfoWithStorage[127.0.0.1:35613,DS-f81525a3-9568-4f7b-9ce6-dec0b9db3338,DISK], DatanodeInfoWithStorage[127.0.0.1:36169,DS-17bd7eee-4199-4702-9c1e-bce168cb8870,DISK], DatanodeInfoWithStorage[127.0.0.1:40951,DS-8391829a-1ea1-403c-87f6-107e28cab88e,DISK], DatanodeInfoWithStorage[127.0.0.1:35250,DS-943ea778-28cf-4ce2-a81b-0bb9a8e919f3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-414695734-172.17.0.10-1596982502534:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45625,DS-abd62b88-d9e0-4da1-8d6d-84ebb3b23eb6,DISK], DatanodeInfoWithStorage[127.0.0.1:40319,DS-dbd6abfd-4612-46bb-a782-aecdd5e5cda3,DISK], DatanodeInfoWithStorage[127.0.0.1:38332,DS-92d29656-7994-46aa-bb9d-d6af1323a3ef,DISK], DatanodeInfoWithStorage[127.0.0.1:43056,DS-e31b80d9-89d7-4296-9f9b-540dc20c9590,DISK], DatanodeInfoWithStorage[127.0.0.1:35613,DS-f81525a3-9568-4f7b-9ce6-dec0b9db3338,DISK], DatanodeInfoWithStorage[127.0.0.1:36169,DS-17bd7eee-4199-4702-9c1e-bce168cb8870,DISK], DatanodeInfoWithStorage[127.0.0.1:40951,DS-8391829a-1ea1-403c-87f6-107e28cab88e,DISK], DatanodeInfoWithStorage[127.0.0.1:35250,DS-943ea778-28cf-4ce2-a81b-0bb9a8e919f3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-84871533-172.17.0.10-1596982633770:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44757,DS-42f3b158-281c-49ee-871f-4f111e5f4124,DISK], DatanodeInfoWithStorage[127.0.0.1:38791,DS-456f2321-c18b-4690-8472-fc838347b3ed,DISK], DatanodeInfoWithStorage[127.0.0.1:46830,DS-473e3b53-9205-4212-93d3-f338445a3d35,DISK], DatanodeInfoWithStorage[127.0.0.1:38282,DS-4d34018a-3a73-448a-90b3-4499728f4c85,DISK], DatanodeInfoWithStorage[127.0.0.1:45599,DS-b43b788e-9424-4c61-98b8-24cd9c0a50ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40445,DS-cc9ab4e5-c854-45d1-a7bc-3f579fbcb592,DISK], DatanodeInfoWithStorage[127.0.0.1:37651,DS-5ea34a33-b0ee-46b6-8416-560d5532c094,DISK], DatanodeInfoWithStorage[127.0.0.1:43153,DS-9029802e-1fc2-474b-8f30-d918c47a8049,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-84871533-172.17.0.10-1596982633770:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44757,DS-42f3b158-281c-49ee-871f-4f111e5f4124,DISK], DatanodeInfoWithStorage[127.0.0.1:38791,DS-456f2321-c18b-4690-8472-fc838347b3ed,DISK], DatanodeInfoWithStorage[127.0.0.1:46830,DS-473e3b53-9205-4212-93d3-f338445a3d35,DISK], DatanodeInfoWithStorage[127.0.0.1:38282,DS-4d34018a-3a73-448a-90b3-4499728f4c85,DISK], DatanodeInfoWithStorage[127.0.0.1:45599,DS-b43b788e-9424-4c61-98b8-24cd9c0a50ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40445,DS-cc9ab4e5-c854-45d1-a7bc-3f579fbcb592,DISK], DatanodeInfoWithStorage[127.0.0.1:37651,DS-5ea34a33-b0ee-46b6-8416-560d5532c094,DISK], DatanodeInfoWithStorage[127.0.0.1:43153,DS-9029802e-1fc2-474b-8f30-d918c47a8049,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1207034930-172.17.0.10-1596982939491:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44834,DS-37aad7be-0377-4904-9014-c59a96e59e7b,DISK], DatanodeInfoWithStorage[127.0.0.1:39336,DS-6d3c7a02-dd9f-4257-ab72-72d1f6d63d92,DISK], DatanodeInfoWithStorage[127.0.0.1:42770,DS-2a6e7435-5b55-4fd1-97f8-877473ddbce7,DISK], DatanodeInfoWithStorage[127.0.0.1:35737,DS-ef8e2dff-fece-4aa6-b199-06360fe01da4,DISK], DatanodeInfoWithStorage[127.0.0.1:36493,DS-688fc3cf-2a49-47d5-ba05-b06ec686accd,DISK], DatanodeInfoWithStorage[127.0.0.1:34920,DS-8d11c7d3-d3ae-4577-9a50-39262f3d1127,DISK], DatanodeInfoWithStorage[127.0.0.1:38348,DS-149ac5ec-818f-4765-a23d-5df7f1072daf,DISK], DatanodeInfoWithStorage[127.0.0.1:40162,DS-f9677f83-6432-47bf-8bbf-ed0dec20b11b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1207034930-172.17.0.10-1596982939491:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44834,DS-37aad7be-0377-4904-9014-c59a96e59e7b,DISK], DatanodeInfoWithStorage[127.0.0.1:39336,DS-6d3c7a02-dd9f-4257-ab72-72d1f6d63d92,DISK], DatanodeInfoWithStorage[127.0.0.1:42770,DS-2a6e7435-5b55-4fd1-97f8-877473ddbce7,DISK], DatanodeInfoWithStorage[127.0.0.1:35737,DS-ef8e2dff-fece-4aa6-b199-06360fe01da4,DISK], DatanodeInfoWithStorage[127.0.0.1:36493,DS-688fc3cf-2a49-47d5-ba05-b06ec686accd,DISK], DatanodeInfoWithStorage[127.0.0.1:34920,DS-8d11c7d3-d3ae-4577-9a50-39262f3d1127,DISK], DatanodeInfoWithStorage[127.0.0.1:38348,DS-149ac5ec-818f-4765-a23d-5df7f1072daf,DISK], DatanodeInfoWithStorage[127.0.0.1:40162,DS-f9677f83-6432-47bf-8bbf-ed0dec20b11b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1393926418-172.17.0.10-1596982985809:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44178,DS-d9a63d58-41b6-4b7b-bf29-b1e48191277b,DISK], DatanodeInfoWithStorage[127.0.0.1:35954,DS-034ce7a8-dcc5-4a0b-975b-4e2386c9fec0,DISK], DatanodeInfoWithStorage[127.0.0.1:33201,DS-5dd09b75-f981-4489-bec8-86b49c2186c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41522,DS-15c789e3-9ca1-4127-8038-cbf96e119658,DISK], DatanodeInfoWithStorage[127.0.0.1:35945,DS-cd5229f6-807d-46c4-9864-17f0ebb8e850,DISK], DatanodeInfoWithStorage[127.0.0.1:44711,DS-d43745d7-9ade-4e0c-aeab-044cafb1560a,DISK], DatanodeInfoWithStorage[127.0.0.1:34862,DS-ee7e3cf1-328f-4bc3-b631-426a2417fdef,DISK], DatanodeInfoWithStorage[127.0.0.1:46548,DS-bae35f97-b6c6-4d95-9d6b-283d4742c764,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1393926418-172.17.0.10-1596982985809:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44178,DS-d9a63d58-41b6-4b7b-bf29-b1e48191277b,DISK], DatanodeInfoWithStorage[127.0.0.1:35954,DS-034ce7a8-dcc5-4a0b-975b-4e2386c9fec0,DISK], DatanodeInfoWithStorage[127.0.0.1:33201,DS-5dd09b75-f981-4489-bec8-86b49c2186c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41522,DS-15c789e3-9ca1-4127-8038-cbf96e119658,DISK], DatanodeInfoWithStorage[127.0.0.1:35945,DS-cd5229f6-807d-46c4-9864-17f0ebb8e850,DISK], DatanodeInfoWithStorage[127.0.0.1:44711,DS-d43745d7-9ade-4e0c-aeab-044cafb1560a,DISK], DatanodeInfoWithStorage[127.0.0.1:34862,DS-ee7e3cf1-328f-4bc3-b631-426a2417fdef,DISK], DatanodeInfoWithStorage[127.0.0.1:46548,DS-bae35f97-b6c6-4d95-9d6b-283d4742c764,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1977128321-172.17.0.10-1596983150094:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36978,DS-9c3173b0-456e-4645-bcc2-fabe57cfb64a,DISK], DatanodeInfoWithStorage[127.0.0.1:34322,DS-93c2d205-71ff-4116-bf62-b3f337c72071,DISK], DatanodeInfoWithStorage[127.0.0.1:37761,DS-31be36a9-8d52-4439-8910-84fa91e39ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:34499,DS-2e445de8-e084-4ffd-9be5-94405c676885,DISK], DatanodeInfoWithStorage[127.0.0.1:46083,DS-9b93a808-ecf9-47e3-ab8b-14f4c489231d,DISK], DatanodeInfoWithStorage[127.0.0.1:41216,DS-fffb5cb8-c660-4a27-83a9-0c008ec20b81,DISK], DatanodeInfoWithStorage[127.0.0.1:42825,DS-99f5d8d7-ebae-446c-a4a7-aea533c285a5,DISK], DatanodeInfoWithStorage[127.0.0.1:37110,DS-84f98502-ff5c-4b13-8ddc-fd53e43b0f8b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1977128321-172.17.0.10-1596983150094:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36978,DS-9c3173b0-456e-4645-bcc2-fabe57cfb64a,DISK], DatanodeInfoWithStorage[127.0.0.1:34322,DS-93c2d205-71ff-4116-bf62-b3f337c72071,DISK], DatanodeInfoWithStorage[127.0.0.1:37761,DS-31be36a9-8d52-4439-8910-84fa91e39ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:34499,DS-2e445de8-e084-4ffd-9be5-94405c676885,DISK], DatanodeInfoWithStorage[127.0.0.1:46083,DS-9b93a808-ecf9-47e3-ab8b-14f4c489231d,DISK], DatanodeInfoWithStorage[127.0.0.1:41216,DS-fffb5cb8-c660-4a27-83a9-0c008ec20b81,DISK], DatanodeInfoWithStorage[127.0.0.1:42825,DS-99f5d8d7-ebae-446c-a4a7-aea533c285a5,DISK], DatanodeInfoWithStorage[127.0.0.1:37110,DS-84f98502-ff5c-4b13-8ddc-fd53e43b0f8b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-443648121-172.17.0.10-1596983307897:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35886,DS-f05fef22-fb63-468c-9e12-a2a4dd48d300,DISK], DatanodeInfoWithStorage[127.0.0.1:35272,DS-f394da55-056c-4940-9f11-15ba603dd84f,DISK], DatanodeInfoWithStorage[127.0.0.1:36016,DS-61acbcc3-40fb-44d9-adc3-205a227f8c97,DISK], DatanodeInfoWithStorage[127.0.0.1:45173,DS-387a138f-a690-451e-a3bc-e207da52516c,DISK], DatanodeInfoWithStorage[127.0.0.1:38209,DS-9ef00be4-2915-4fe7-b7dd-d1588b307cf6,DISK], DatanodeInfoWithStorage[127.0.0.1:43997,DS-9c4395e3-da79-48f2-b965-00d618443560,DISK], DatanodeInfoWithStorage[127.0.0.1:43711,DS-ed0d4a6f-7e70-4965-ae69-e0d98dc69782,DISK], DatanodeInfoWithStorage[127.0.0.1:40678,DS-2f31eb7f-e391-4aa5-bbbc-f101d8d13219,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-443648121-172.17.0.10-1596983307897:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35886,DS-f05fef22-fb63-468c-9e12-a2a4dd48d300,DISK], DatanodeInfoWithStorage[127.0.0.1:35272,DS-f394da55-056c-4940-9f11-15ba603dd84f,DISK], DatanodeInfoWithStorage[127.0.0.1:36016,DS-61acbcc3-40fb-44d9-adc3-205a227f8c97,DISK], DatanodeInfoWithStorage[127.0.0.1:45173,DS-387a138f-a690-451e-a3bc-e207da52516c,DISK], DatanodeInfoWithStorage[127.0.0.1:38209,DS-9ef00be4-2915-4fe7-b7dd-d1588b307cf6,DISK], DatanodeInfoWithStorage[127.0.0.1:43997,DS-9c4395e3-da79-48f2-b965-00d618443560,DISK], DatanodeInfoWithStorage[127.0.0.1:43711,DS-ed0d4a6f-7e70-4965-ae69-e0d98dc69782,DISK], DatanodeInfoWithStorage[127.0.0.1:40678,DS-2f31eb7f-e391-4aa5-bbbc-f101d8d13219,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.enable.retrycache
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-14383584-172.17.0.10-1596983603862:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39986,DS-67ac4f3e-2ab6-4cae-aaad-34a3338d3ad3,DISK], DatanodeInfoWithStorage[127.0.0.1:41695,DS-9fdef25e-1cee-471e-af34-f55877538014,DISK], DatanodeInfoWithStorage[127.0.0.1:40463,DS-b93dbb0a-53d2-4f65-838e-3f356a132f46,DISK], DatanodeInfoWithStorage[127.0.0.1:44361,DS-fe366b2f-163e-4c88-871c-799090564212,DISK], DatanodeInfoWithStorage[127.0.0.1:34007,DS-cf6ead21-e3cf-4b90-8231-f8be853d34cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41822,DS-05b6e9ce-34ec-4dbc-b823-aceda9ae65fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37516,DS-a8b7fa43-7d63-42ee-bb03-6ade38f065e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39585,DS-89c1d482-0f24-4eb7-9577-dbf6332cecc5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-14383584-172.17.0.10-1596983603862:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39986,DS-67ac4f3e-2ab6-4cae-aaad-34a3338d3ad3,DISK], DatanodeInfoWithStorage[127.0.0.1:41695,DS-9fdef25e-1cee-471e-af34-f55877538014,DISK], DatanodeInfoWithStorage[127.0.0.1:40463,DS-b93dbb0a-53d2-4f65-838e-3f356a132f46,DISK], DatanodeInfoWithStorage[127.0.0.1:44361,DS-fe366b2f-163e-4c88-871c-799090564212,DISK], DatanodeInfoWithStorage[127.0.0.1:34007,DS-cf6ead21-e3cf-4b90-8231-f8be853d34cd,DISK], DatanodeInfoWithStorage[127.0.0.1:41822,DS-05b6e9ce-34ec-4dbc-b823-aceda9ae65fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37516,DS-a8b7fa43-7d63-42ee-bb03-6ade38f065e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39585,DS-89c1d482-0f24-4eb7-9577-dbf6332cecc5,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 14 out of 50
v1v1v2v2 failed with probability 19 out of 50
result: false positive !!!
Total execution time in seconds : 6539
