reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1480947897-172.17.0.21-1595297977866:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37687,DS-be44cd1d-fc3d-4289-8d98-b1d07321e4ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45557,DS-c1e5f762-0a1a-4cce-b66a-c9c8aab1294f,DISK], DatanodeInfoWithStorage[127.0.0.1:37990,DS-8fe37e89-4547-4afe-9666-4e256394d6aa,DISK], DatanodeInfoWithStorage[127.0.0.1:46167,DS-e4c9a05e-1bf8-465d-8c02-fa6effe2ff8c,DISK], DatanodeInfoWithStorage[127.0.0.1:37340,DS-49a7e4f1-2755-46be-a2cc-50a7b5da216f,DISK], DatanodeInfoWithStorage[127.0.0.1:44171,DS-b5a3d3d5-4a58-47e3-ba7b-f2cafed30d33,DISK], DatanodeInfoWithStorage[127.0.0.1:37375,DS-098f5ee8-5113-4f58-827c-6899b33e2d01,DISK], DatanodeInfoWithStorage[127.0.0.1:33847,DS-7a0c85d5-80d1-470d-bce5-d3bd9dc5afd4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1480947897-172.17.0.21-1595297977866:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37687,DS-be44cd1d-fc3d-4289-8d98-b1d07321e4ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45557,DS-c1e5f762-0a1a-4cce-b66a-c9c8aab1294f,DISK], DatanodeInfoWithStorage[127.0.0.1:37990,DS-8fe37e89-4547-4afe-9666-4e256394d6aa,DISK], DatanodeInfoWithStorage[127.0.0.1:46167,DS-e4c9a05e-1bf8-465d-8c02-fa6effe2ff8c,DISK], DatanodeInfoWithStorage[127.0.0.1:37340,DS-49a7e4f1-2755-46be-a2cc-50a7b5da216f,DISK], DatanodeInfoWithStorage[127.0.0.1:44171,DS-b5a3d3d5-4a58-47e3-ba7b-f2cafed30d33,DISK], DatanodeInfoWithStorage[127.0.0.1:37375,DS-098f5ee8-5113-4f58-827c-6899b33e2d01,DISK], DatanodeInfoWithStorage[127.0.0.1:33847,DS-7a0c85d5-80d1-470d-bce5-d3bd9dc5afd4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-160611624-172.17.0.21-1595298076799:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43296,DS-c626abcf-b377-42b6-8cec-58739e4afa2a,DISK], DatanodeInfoWithStorage[127.0.0.1:41613,DS-711e4f78-928f-40fc-95bb-aeae32041301,DISK], DatanodeInfoWithStorage[127.0.0.1:35652,DS-a5e62121-7150-4064-b6ff-a911e8ac7c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:45032,DS-3e1775bb-58c5-4d0b-b088-b89fd575383c,DISK], DatanodeInfoWithStorage[127.0.0.1:33995,DS-9c2370da-cd27-498a-b335-6380655c18c0,DISK], DatanodeInfoWithStorage[127.0.0.1:43197,DS-d2615087-2143-405a-acdb-15daed2684fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36061,DS-7c0a5ca9-d0c7-492a-9362-6f121ce92b62,DISK], DatanodeInfoWithStorage[127.0.0.1:33624,DS-813a4e80-ba5f-404c-970b-71e7c97aa396,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-160611624-172.17.0.21-1595298076799:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43296,DS-c626abcf-b377-42b6-8cec-58739e4afa2a,DISK], DatanodeInfoWithStorage[127.0.0.1:41613,DS-711e4f78-928f-40fc-95bb-aeae32041301,DISK], DatanodeInfoWithStorage[127.0.0.1:35652,DS-a5e62121-7150-4064-b6ff-a911e8ac7c9e,DISK], DatanodeInfoWithStorage[127.0.0.1:45032,DS-3e1775bb-58c5-4d0b-b088-b89fd575383c,DISK], DatanodeInfoWithStorage[127.0.0.1:33995,DS-9c2370da-cd27-498a-b335-6380655c18c0,DISK], DatanodeInfoWithStorage[127.0.0.1:43197,DS-d2615087-2143-405a-acdb-15daed2684fe,DISK], DatanodeInfoWithStorage[127.0.0.1:36061,DS-7c0a5ca9-d0c7-492a-9362-6f121ce92b62,DISK], DatanodeInfoWithStorage[127.0.0.1:33624,DS-813a4e80-ba5f-404c-970b-71e7c97aa396,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-639866613-172.17.0.21-1595298105056:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44290,DS-dc48fea2-453a-4e18-ae55-522ba727668f,DISK], DatanodeInfoWithStorage[127.0.0.1:36024,DS-1dfa69ba-44bf-4efb-b3c2-e4937a1a1015,DISK], DatanodeInfoWithStorage[127.0.0.1:34850,DS-c6cfe588-2b7c-4ae4-ae27-33265f4f03bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36970,DS-217bc6d4-d390-4d7b-a41a-a44d4111a7ec,DISK], DatanodeInfoWithStorage[127.0.0.1:43092,DS-d291c42a-9756-436d-9324-2092d15de622,DISK], DatanodeInfoWithStorage[127.0.0.1:38276,DS-7daf9ce7-c327-4608-85fa-d6444aacb441,DISK], DatanodeInfoWithStorage[127.0.0.1:46357,DS-b6f0634b-6e83-4f83-a27e-88e7129ecbed,DISK], DatanodeInfoWithStorage[127.0.0.1:44418,DS-bd5fd020-a80e-4b40-8157-1c774c4c8029,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-639866613-172.17.0.21-1595298105056:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44290,DS-dc48fea2-453a-4e18-ae55-522ba727668f,DISK], DatanodeInfoWithStorage[127.0.0.1:36024,DS-1dfa69ba-44bf-4efb-b3c2-e4937a1a1015,DISK], DatanodeInfoWithStorage[127.0.0.1:34850,DS-c6cfe588-2b7c-4ae4-ae27-33265f4f03bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36970,DS-217bc6d4-d390-4d7b-a41a-a44d4111a7ec,DISK], DatanodeInfoWithStorage[127.0.0.1:43092,DS-d291c42a-9756-436d-9324-2092d15de622,DISK], DatanodeInfoWithStorage[127.0.0.1:38276,DS-7daf9ce7-c327-4608-85fa-d6444aacb441,DISK], DatanodeInfoWithStorage[127.0.0.1:46357,DS-b6f0634b-6e83-4f83-a27e-88e7129ecbed,DISK], DatanodeInfoWithStorage[127.0.0.1:44418,DS-bd5fd020-a80e-4b40-8157-1c774c4c8029,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2107539899-172.17.0.21-1595298416383:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41361,DS-a468e666-e42e-4446-a46b-a3f758201e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:44357,DS-6a12ac94-c764-4185-8bbf-24b3e6b9ce29,DISK], DatanodeInfoWithStorage[127.0.0.1:35203,DS-86c61ee5-7ada-4bf5-b1b8-8b6bf7dfcfa5,DISK], DatanodeInfoWithStorage[127.0.0.1:44041,DS-78845e30-46c5-4335-a02b-a0676fea24ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44633,DS-8e7230b5-c5c0-4912-833d-c5ac0ebe2d9b,DISK], DatanodeInfoWithStorage[127.0.0.1:43200,DS-2bd7b051-c452-4cbc-970a-004f67de91ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35335,DS-de5df7b1-a4c2-4073-a03b-affe1bd7acde,DISK], DatanodeInfoWithStorage[127.0.0.1:34397,DS-35494428-6ad0-4c26-bf06-94a67854d5f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2107539899-172.17.0.21-1595298416383:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41361,DS-a468e666-e42e-4446-a46b-a3f758201e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:44357,DS-6a12ac94-c764-4185-8bbf-24b3e6b9ce29,DISK], DatanodeInfoWithStorage[127.0.0.1:35203,DS-86c61ee5-7ada-4bf5-b1b8-8b6bf7dfcfa5,DISK], DatanodeInfoWithStorage[127.0.0.1:44041,DS-78845e30-46c5-4335-a02b-a0676fea24ec,DISK], DatanodeInfoWithStorage[127.0.0.1:44633,DS-8e7230b5-c5c0-4912-833d-c5ac0ebe2d9b,DISK], DatanodeInfoWithStorage[127.0.0.1:43200,DS-2bd7b051-c452-4cbc-970a-004f67de91ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35335,DS-de5df7b1-a4c2-4073-a03b-affe1bd7acde,DISK], DatanodeInfoWithStorage[127.0.0.1:34397,DS-35494428-6ad0-4c26-bf06-94a67854d5f0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-286278761-172.17.0.21-1595298520691:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33162,DS-179c3f1e-6958-45e0-a8a9-769770d625b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37584,DS-aec23ea5-cda4-4006-b68a-7231f354797b,DISK], DatanodeInfoWithStorage[127.0.0.1:43031,DS-57a66665-85fb-42c1-b8c5-9972b1586f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:37814,DS-b5534989-6d3f-4033-b181-c8f238a56047,DISK], DatanodeInfoWithStorage[127.0.0.1:42917,DS-0960717e-eac1-4cfd-8ab5-5d121aa093f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35653,DS-2231d9cb-7643-4b50-81ab-808bdc80cad5,DISK], DatanodeInfoWithStorage[127.0.0.1:38425,DS-3e551ff5-de5a-44b4-a9b5-abd3f407c578,DISK], DatanodeInfoWithStorage[127.0.0.1:43721,DS-b9459d46-1424-497e-983f-5c1402b19059,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-286278761-172.17.0.21-1595298520691:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33162,DS-179c3f1e-6958-45e0-a8a9-769770d625b7,DISK], DatanodeInfoWithStorage[127.0.0.1:37584,DS-aec23ea5-cda4-4006-b68a-7231f354797b,DISK], DatanodeInfoWithStorage[127.0.0.1:43031,DS-57a66665-85fb-42c1-b8c5-9972b1586f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:37814,DS-b5534989-6d3f-4033-b181-c8f238a56047,DISK], DatanodeInfoWithStorage[127.0.0.1:42917,DS-0960717e-eac1-4cfd-8ab5-5d121aa093f7,DISK], DatanodeInfoWithStorage[127.0.0.1:35653,DS-2231d9cb-7643-4b50-81ab-808bdc80cad5,DISK], DatanodeInfoWithStorage[127.0.0.1:38425,DS-3e551ff5-de5a-44b4-a9b5-abd3f407c578,DISK], DatanodeInfoWithStorage[127.0.0.1:43721,DS-b9459d46-1424-497e-983f-5c1402b19059,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-761351240-172.17.0.21-1595298703614:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35670,DS-62c405a4-22e1-4c6d-83a1-078207b2e11f,DISK], DatanodeInfoWithStorage[127.0.0.1:46112,DS-fa6d5a19-18b0-482a-918a-b2f29ac02aac,DISK], DatanodeInfoWithStorage[127.0.0.1:43813,DS-c7950999-6897-4e13-985e-7956ea409b2d,DISK], DatanodeInfoWithStorage[127.0.0.1:36505,DS-5bdddbb2-fc32-4f3a-a7b5-bda1587afb45,DISK], DatanodeInfoWithStorage[127.0.0.1:44285,DS-86d250ca-d46b-42ae-adc9-3d5fb35fa5bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42741,DS-907ed45b-7633-481e-b3ec-49463099bab0,DISK], DatanodeInfoWithStorage[127.0.0.1:46771,DS-3b852109-3add-46a5-8d92-3ad118166dd5,DISK], DatanodeInfoWithStorage[127.0.0.1:45353,DS-7339b0d0-2364-4373-920a-9b4476a22e5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-761351240-172.17.0.21-1595298703614:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35670,DS-62c405a4-22e1-4c6d-83a1-078207b2e11f,DISK], DatanodeInfoWithStorage[127.0.0.1:46112,DS-fa6d5a19-18b0-482a-918a-b2f29ac02aac,DISK], DatanodeInfoWithStorage[127.0.0.1:43813,DS-c7950999-6897-4e13-985e-7956ea409b2d,DISK], DatanodeInfoWithStorage[127.0.0.1:36505,DS-5bdddbb2-fc32-4f3a-a7b5-bda1587afb45,DISK], DatanodeInfoWithStorage[127.0.0.1:44285,DS-86d250ca-d46b-42ae-adc9-3d5fb35fa5bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42741,DS-907ed45b-7633-481e-b3ec-49463099bab0,DISK], DatanodeInfoWithStorage[127.0.0.1:46771,DS-3b852109-3add-46a5-8d92-3ad118166dd5,DISK], DatanodeInfoWithStorage[127.0.0.1:45353,DS-7339b0d0-2364-4373-920a-9b4476a22e5d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2117046701-172.17.0.21-1595299205894:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36402,DS-07233a4b-c5dc-45bd-b323-eb8344dde15f,DISK], DatanodeInfoWithStorage[127.0.0.1:41375,DS-767b0a8e-b41c-4582-b86f-cfb098ba9e20,DISK], DatanodeInfoWithStorage[127.0.0.1:38490,DS-e3954840-22ee-4fe3-be71-1bf60027abea,DISK], DatanodeInfoWithStorage[127.0.0.1:36508,DS-18f7c6fa-ff8c-4787-b693-692b996873da,DISK], DatanodeInfoWithStorage[127.0.0.1:42142,DS-2fb6fc25-a1ca-47bc-9033-6ba21df8e242,DISK], DatanodeInfoWithStorage[127.0.0.1:39215,DS-edece0a5-764d-4b75-8efe-3643b76bd2af,DISK], DatanodeInfoWithStorage[127.0.0.1:33624,DS-4b7c8cb7-93a2-4a4d-bed4-95bf7df7bd09,DISK], DatanodeInfoWithStorage[127.0.0.1:33935,DS-f86df602-82f6-417c-a16d-9b796ab4b10d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2117046701-172.17.0.21-1595299205894:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36402,DS-07233a4b-c5dc-45bd-b323-eb8344dde15f,DISK], DatanodeInfoWithStorage[127.0.0.1:41375,DS-767b0a8e-b41c-4582-b86f-cfb098ba9e20,DISK], DatanodeInfoWithStorage[127.0.0.1:38490,DS-e3954840-22ee-4fe3-be71-1bf60027abea,DISK], DatanodeInfoWithStorage[127.0.0.1:36508,DS-18f7c6fa-ff8c-4787-b693-692b996873da,DISK], DatanodeInfoWithStorage[127.0.0.1:42142,DS-2fb6fc25-a1ca-47bc-9033-6ba21df8e242,DISK], DatanodeInfoWithStorage[127.0.0.1:39215,DS-edece0a5-764d-4b75-8efe-3643b76bd2af,DISK], DatanodeInfoWithStorage[127.0.0.1:33624,DS-4b7c8cb7-93a2-4a4d-bed4-95bf7df7bd09,DISK], DatanodeInfoWithStorage[127.0.0.1:33935,DS-f86df602-82f6-417c-a16d-9b796ab4b10d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-412764285-172.17.0.21-1595299329070:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40070,DS-bcebc7e6-72f8-47c8-96d3-522cc86b4273,DISK], DatanodeInfoWithStorage[127.0.0.1:43255,DS-84b07133-bb76-48bb-98c4-27978de1c2ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45436,DS-d44e0c19-1ed9-414a-805b-9a401e326086,DISK], DatanodeInfoWithStorage[127.0.0.1:42534,DS-0708d2c8-2370-4a0b-a2a1-f23afc69a2af,DISK], DatanodeInfoWithStorage[127.0.0.1:37913,DS-17a1b3b7-5831-4851-bac0-79ff0eab10e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38408,DS-474d9bbc-6639-4ecd-b362-d9b049b5daae,DISK], DatanodeInfoWithStorage[127.0.0.1:34252,DS-e29cda1c-6f0b-4b96-a7c1-1f15b63fe55d,DISK], DatanodeInfoWithStorage[127.0.0.1:43765,DS-79c677a9-1c16-401e-a158-04fa7ae486f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-412764285-172.17.0.21-1595299329070:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40070,DS-bcebc7e6-72f8-47c8-96d3-522cc86b4273,DISK], DatanodeInfoWithStorage[127.0.0.1:43255,DS-84b07133-bb76-48bb-98c4-27978de1c2ee,DISK], DatanodeInfoWithStorage[127.0.0.1:45436,DS-d44e0c19-1ed9-414a-805b-9a401e326086,DISK], DatanodeInfoWithStorage[127.0.0.1:42534,DS-0708d2c8-2370-4a0b-a2a1-f23afc69a2af,DISK], DatanodeInfoWithStorage[127.0.0.1:37913,DS-17a1b3b7-5831-4851-bac0-79ff0eab10e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38408,DS-474d9bbc-6639-4ecd-b362-d9b049b5daae,DISK], DatanodeInfoWithStorage[127.0.0.1:34252,DS-e29cda1c-6f0b-4b96-a7c1-1f15b63fe55d,DISK], DatanodeInfoWithStorage[127.0.0.1:43765,DS-79c677a9-1c16-401e-a158-04fa7ae486f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-159145022-172.17.0.21-1595299806985:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37187,DS-954dc5f7-f090-46e1-8829-132877d69866,DISK], DatanodeInfoWithStorage[127.0.0.1:43862,DS-b93d16dd-ba56-4194-9054-066f4c347980,DISK], DatanodeInfoWithStorage[127.0.0.1:44910,DS-01f58d08-ee6f-4e5b-8312-a8513b8c98ee,DISK], DatanodeInfoWithStorage[127.0.0.1:40138,DS-d95b3f54-c7bc-4659-b411-f2318b0cd309,DISK], DatanodeInfoWithStorage[127.0.0.1:37038,DS-33a82b18-8226-4ea3-a1a1-45dccb7e8bb4,DISK], DatanodeInfoWithStorage[127.0.0.1:37559,DS-f78c4e03-9ead-4d18-9d6c-2cd82b03fcd8,DISK], DatanodeInfoWithStorage[127.0.0.1:35922,DS-3bcf7180-c983-4b6c-94ea-d55f8aedc550,DISK], DatanodeInfoWithStorage[127.0.0.1:38057,DS-c36311fe-26db-47cc-9696-3aa8ebe018d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-159145022-172.17.0.21-1595299806985:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37187,DS-954dc5f7-f090-46e1-8829-132877d69866,DISK], DatanodeInfoWithStorage[127.0.0.1:43862,DS-b93d16dd-ba56-4194-9054-066f4c347980,DISK], DatanodeInfoWithStorage[127.0.0.1:44910,DS-01f58d08-ee6f-4e5b-8312-a8513b8c98ee,DISK], DatanodeInfoWithStorage[127.0.0.1:40138,DS-d95b3f54-c7bc-4659-b411-f2318b0cd309,DISK], DatanodeInfoWithStorage[127.0.0.1:37038,DS-33a82b18-8226-4ea3-a1a1-45dccb7e8bb4,DISK], DatanodeInfoWithStorage[127.0.0.1:37559,DS-f78c4e03-9ead-4d18-9d6c-2cd82b03fcd8,DISK], DatanodeInfoWithStorage[127.0.0.1:35922,DS-3bcf7180-c983-4b6c-94ea-d55f8aedc550,DISK], DatanodeInfoWithStorage[127.0.0.1:38057,DS-c36311fe-26db-47cc-9696-3aa8ebe018d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1700518446-172.17.0.21-1595300226679:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38214,DS-1cbf295f-3683-473c-99ac-769333241151,DISK], DatanodeInfoWithStorage[127.0.0.1:37216,DS-ee87b885-9747-4c8e-a5ac-8bdf8638b3c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35420,DS-2d6d8dba-6353-4252-b4e0-28c02306cba5,DISK], DatanodeInfoWithStorage[127.0.0.1:36430,DS-39094d31-1e0b-426c-b796-86b8e3878f53,DISK], DatanodeInfoWithStorage[127.0.0.1:34007,DS-36466de0-74eb-4a51-905d-f256fe20686d,DISK], DatanodeInfoWithStorage[127.0.0.1:34425,DS-5d3c1bda-9857-448f-b84e-4d1516fdeb1d,DISK], DatanodeInfoWithStorage[127.0.0.1:36032,DS-17563063-e0d5-4bd7-90ab-46f37835ff4f,DISK], DatanodeInfoWithStorage[127.0.0.1:33922,DS-1a539363-1e95-4f78-b700-5d5b7a755c05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1700518446-172.17.0.21-1595300226679:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38214,DS-1cbf295f-3683-473c-99ac-769333241151,DISK], DatanodeInfoWithStorage[127.0.0.1:37216,DS-ee87b885-9747-4c8e-a5ac-8bdf8638b3c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35420,DS-2d6d8dba-6353-4252-b4e0-28c02306cba5,DISK], DatanodeInfoWithStorage[127.0.0.1:36430,DS-39094d31-1e0b-426c-b796-86b8e3878f53,DISK], DatanodeInfoWithStorage[127.0.0.1:34007,DS-36466de0-74eb-4a51-905d-f256fe20686d,DISK], DatanodeInfoWithStorage[127.0.0.1:34425,DS-5d3c1bda-9857-448f-b84e-4d1516fdeb1d,DISK], DatanodeInfoWithStorage[127.0.0.1:36032,DS-17563063-e0d5-4bd7-90ab-46f37835ff4f,DISK], DatanodeInfoWithStorage[127.0.0.1:33922,DS-1a539363-1e95-4f78-b700-5d5b7a755c05,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-271337048-172.17.0.21-1595301077832:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34420,DS-a04ed2a4-4bf9-4e4c-949c-423674d666d3,DISK], DatanodeInfoWithStorage[127.0.0.1:41718,DS-3fe8ee51-da70-4543-8a47-46fc63e6ad10,DISK], DatanodeInfoWithStorage[127.0.0.1:39458,DS-2dd3e3b7-e12a-4483-bb10-44369a428a95,DISK], DatanodeInfoWithStorage[127.0.0.1:32806,DS-54a8f565-8b98-4c44-a65c-4af6577746aa,DISK], DatanodeInfoWithStorage[127.0.0.1:42832,DS-b5307890-b854-4dbd-870f-a157d336ed9a,DISK], DatanodeInfoWithStorage[127.0.0.1:45165,DS-57d51162-4db8-41a6-a3a4-f404ad46c230,DISK], DatanodeInfoWithStorage[127.0.0.1:46804,DS-e27d5a51-dab5-428e-a072-2c266b38bcb8,DISK], DatanodeInfoWithStorage[127.0.0.1:33887,DS-1cace702-e830-42af-8e52-9483d8341bc1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-271337048-172.17.0.21-1595301077832:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34420,DS-a04ed2a4-4bf9-4e4c-949c-423674d666d3,DISK], DatanodeInfoWithStorage[127.0.0.1:41718,DS-3fe8ee51-da70-4543-8a47-46fc63e6ad10,DISK], DatanodeInfoWithStorage[127.0.0.1:39458,DS-2dd3e3b7-e12a-4483-bb10-44369a428a95,DISK], DatanodeInfoWithStorage[127.0.0.1:32806,DS-54a8f565-8b98-4c44-a65c-4af6577746aa,DISK], DatanodeInfoWithStorage[127.0.0.1:42832,DS-b5307890-b854-4dbd-870f-a157d336ed9a,DISK], DatanodeInfoWithStorage[127.0.0.1:45165,DS-57d51162-4db8-41a6-a3a4-f404ad46c230,DISK], DatanodeInfoWithStorage[127.0.0.1:46804,DS-e27d5a51-dab5-428e-a072-2c266b38bcb8,DISK], DatanodeInfoWithStorage[127.0.0.1:33887,DS-1cace702-e830-42af-8e52-9483d8341bc1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2137359747-172.17.0.21-1595301427281:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33863,DS-10fb2bd7-d028-4f4f-9590-120f5e821f5b,DISK], DatanodeInfoWithStorage[127.0.0.1:45994,DS-62cd6ccb-0ccc-47b1-93f3-5a0acc96e1e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45312,DS-2f372634-fdb8-452f-aea9-a441b6f789cb,DISK], DatanodeInfoWithStorage[127.0.0.1:42938,DS-a6783e87-47f1-4e10-b6e3-aed699c9b790,DISK], DatanodeInfoWithStorage[127.0.0.1:36100,DS-355f803d-568f-490c-acca-af63cf628fd0,DISK], DatanodeInfoWithStorage[127.0.0.1:44566,DS-e93f4f27-6d8f-4f35-a6ea-26e3e04b5bca,DISK], DatanodeInfoWithStorage[127.0.0.1:39379,DS-39db9b5b-a255-4ab9-9f23-c76dfc49197d,DISK], DatanodeInfoWithStorage[127.0.0.1:44423,DS-e81fd472-113a-4dcf-8ef4-8e719a13dbb7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2137359747-172.17.0.21-1595301427281:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33863,DS-10fb2bd7-d028-4f4f-9590-120f5e821f5b,DISK], DatanodeInfoWithStorage[127.0.0.1:45994,DS-62cd6ccb-0ccc-47b1-93f3-5a0acc96e1e4,DISK], DatanodeInfoWithStorage[127.0.0.1:45312,DS-2f372634-fdb8-452f-aea9-a441b6f789cb,DISK], DatanodeInfoWithStorage[127.0.0.1:42938,DS-a6783e87-47f1-4e10-b6e3-aed699c9b790,DISK], DatanodeInfoWithStorage[127.0.0.1:36100,DS-355f803d-568f-490c-acca-af63cf628fd0,DISK], DatanodeInfoWithStorage[127.0.0.1:44566,DS-e93f4f27-6d8f-4f35-a6ea-26e3e04b5bca,DISK], DatanodeInfoWithStorage[127.0.0.1:39379,DS-39db9b5b-a255-4ab9-9f23-c76dfc49197d,DISK], DatanodeInfoWithStorage[127.0.0.1:44423,DS-e81fd472-113a-4dcf-8ef4-8e719a13dbb7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-705334448-172.17.0.21-1595302141076:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33702,DS-2991346f-6d25-4aa5-a2b7-0d61d5d8923c,DISK], DatanodeInfoWithStorage[127.0.0.1:41676,DS-8ebae43d-35a3-4911-9394-82be09ffddb3,DISK], DatanodeInfoWithStorage[127.0.0.1:46868,DS-f6ce4e2a-0f7f-4502-bd15-f1965d091794,DISK], DatanodeInfoWithStorage[127.0.0.1:45186,DS-5b3699f2-b1a2-4f21-9611-e842e0f2a5a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39236,DS-508eb0ba-a923-4053-b650-4b1665b7fcea,DISK], DatanodeInfoWithStorage[127.0.0.1:45107,DS-a54b889c-88b5-4ab9-9754-7833a9e14f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:41249,DS-74145649-e5bd-4950-a73b-4b7d4289fe15,DISK], DatanodeInfoWithStorage[127.0.0.1:45671,DS-f5db5944-61f0-4fd0-b75a-8210611ca80d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-705334448-172.17.0.21-1595302141076:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33702,DS-2991346f-6d25-4aa5-a2b7-0d61d5d8923c,DISK], DatanodeInfoWithStorage[127.0.0.1:41676,DS-8ebae43d-35a3-4911-9394-82be09ffddb3,DISK], DatanodeInfoWithStorage[127.0.0.1:46868,DS-f6ce4e2a-0f7f-4502-bd15-f1965d091794,DISK], DatanodeInfoWithStorage[127.0.0.1:45186,DS-5b3699f2-b1a2-4f21-9611-e842e0f2a5a1,DISK], DatanodeInfoWithStorage[127.0.0.1:39236,DS-508eb0ba-a923-4053-b650-4b1665b7fcea,DISK], DatanodeInfoWithStorage[127.0.0.1:45107,DS-a54b889c-88b5-4ab9-9754-7833a9e14f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:41249,DS-74145649-e5bd-4950-a73b-4b7d4289fe15,DISK], DatanodeInfoWithStorage[127.0.0.1:45671,DS-f5db5944-61f0-4fd0-b75a-8210611ca80d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-502685544-172.17.0.21-1595302504874:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43251,DS-97425bd2-a5da-45a1-817a-f63f14160143,DISK], DatanodeInfoWithStorage[127.0.0.1:34537,DS-0808d082-2a3b-409a-a445-49c909abc4be,DISK], DatanodeInfoWithStorage[127.0.0.1:35210,DS-340b36c7-7307-485f-8ee8-d9792fd538de,DISK], DatanodeInfoWithStorage[127.0.0.1:34030,DS-38d71042-695c-42ac-841f-37755ff360b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46780,DS-d3ed230f-31da-40ec-aa1a-dc96e1acc737,DISK], DatanodeInfoWithStorage[127.0.0.1:45737,DS-c34a8b37-2b6d-4bec-a29f-23457b37d641,DISK], DatanodeInfoWithStorage[127.0.0.1:42639,DS-6cf89450-036b-48cb-aa3a-97f18a56886e,DISK], DatanodeInfoWithStorage[127.0.0.1:41042,DS-cf922a57-8e0e-435b-867d-0c9b3ede0b5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-502685544-172.17.0.21-1595302504874:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43251,DS-97425bd2-a5da-45a1-817a-f63f14160143,DISK], DatanodeInfoWithStorage[127.0.0.1:34537,DS-0808d082-2a3b-409a-a445-49c909abc4be,DISK], DatanodeInfoWithStorage[127.0.0.1:35210,DS-340b36c7-7307-485f-8ee8-d9792fd538de,DISK], DatanodeInfoWithStorage[127.0.0.1:34030,DS-38d71042-695c-42ac-841f-37755ff360b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46780,DS-d3ed230f-31da-40ec-aa1a-dc96e1acc737,DISK], DatanodeInfoWithStorage[127.0.0.1:45737,DS-c34a8b37-2b6d-4bec-a29f-23457b37d641,DISK], DatanodeInfoWithStorage[127.0.0.1:42639,DS-6cf89450-036b-48cb-aa3a-97f18a56886e,DISK], DatanodeInfoWithStorage[127.0.0.1:41042,DS-cf922a57-8e0e-435b-867d-0c9b3ede0b5f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-954909702-172.17.0.21-1595302882690:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33060,DS-15ac5534-7140-4813-917b-faef4dddf16a,DISK], DatanodeInfoWithStorage[127.0.0.1:43997,DS-631851e1-8adb-4ff4-a2c9-a7b16dd76d6e,DISK], DatanodeInfoWithStorage[127.0.0.1:42442,DS-c8f329a3-6f0f-41eb-95ad-087185a5b980,DISK], DatanodeInfoWithStorage[127.0.0.1:39743,DS-318c1283-b823-4deb-be04-1669e33c35ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37446,DS-e519e73d-a13d-4c72-8f44-e1701e368b53,DISK], DatanodeInfoWithStorage[127.0.0.1:46811,DS-5069dee0-cbac-46da-82e2-68b9ddd121a4,DISK], DatanodeInfoWithStorage[127.0.0.1:38714,DS-c54d09fe-63df-4ba4-9d92-07c458b822c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41846,DS-fb1fd031-511c-4427-bdf5-3fbe0a05ed8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-954909702-172.17.0.21-1595302882690:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33060,DS-15ac5534-7140-4813-917b-faef4dddf16a,DISK], DatanodeInfoWithStorage[127.0.0.1:43997,DS-631851e1-8adb-4ff4-a2c9-a7b16dd76d6e,DISK], DatanodeInfoWithStorage[127.0.0.1:42442,DS-c8f329a3-6f0f-41eb-95ad-087185a5b980,DISK], DatanodeInfoWithStorage[127.0.0.1:39743,DS-318c1283-b823-4deb-be04-1669e33c35ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37446,DS-e519e73d-a13d-4c72-8f44-e1701e368b53,DISK], DatanodeInfoWithStorage[127.0.0.1:46811,DS-5069dee0-cbac-46da-82e2-68b9ddd121a4,DISK], DatanodeInfoWithStorage[127.0.0.1:38714,DS-c54d09fe-63df-4ba4-9d92-07c458b822c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41846,DS-fb1fd031-511c-4427-bdf5-3fbe0a05ed8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.caller.context.enabled
component: hdfs:NameNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-264401187-172.17.0.21-1595303006727:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34025,DS-97822779-35a1-4df9-801e-3b48329c0e07,DISK], DatanodeInfoWithStorage[127.0.0.1:39299,DS-809c8005-6d05-408e-8872-2fdb3d478ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:45876,DS-fe4b8436-5dfd-4c71-9803-834258d454bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40859,DS-85789a5f-2ec6-444b-9a06-0ecb6c82840b,DISK], DatanodeInfoWithStorage[127.0.0.1:36207,DS-82112ff4-13e7-446d-9296-22ec0916aa3a,DISK], DatanodeInfoWithStorage[127.0.0.1:41678,DS-0b141db8-fe3a-4728-8a5c-85bfe749b6aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35915,DS-8c722afe-b9c4-42a7-a439-145a23006f2b,DISK], DatanodeInfoWithStorage[127.0.0.1:37820,DS-9093e73a-387f-4c41-b721-fbbc13a33e4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-264401187-172.17.0.21-1595303006727:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34025,DS-97822779-35a1-4df9-801e-3b48329c0e07,DISK], DatanodeInfoWithStorage[127.0.0.1:39299,DS-809c8005-6d05-408e-8872-2fdb3d478ad1,DISK], DatanodeInfoWithStorage[127.0.0.1:45876,DS-fe4b8436-5dfd-4c71-9803-834258d454bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40859,DS-85789a5f-2ec6-444b-9a06-0ecb6c82840b,DISK], DatanodeInfoWithStorage[127.0.0.1:36207,DS-82112ff4-13e7-446d-9296-22ec0916aa3a,DISK], DatanodeInfoWithStorage[127.0.0.1:41678,DS-0b141db8-fe3a-4728-8a5c-85bfe749b6aa,DISK], DatanodeInfoWithStorage[127.0.0.1:35915,DS-8c722afe-b9c4-42a7-a439-145a23006f2b,DISK], DatanodeInfoWithStorage[127.0.0.1:37820,DS-9093e73a-387f-4c41-b721-fbbc13a33e4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5305
