reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2012063340-172.17.0.12-1595326155182:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40124,DS-4e7a840c-6e2f-4c65-8456-47a93bb04e9c,DISK], DatanodeInfoWithStorage[127.0.0.1:40526,DS-5d9a71e0-6084-4bee-bd95-9cd7e86ab792,DISK], DatanodeInfoWithStorage[127.0.0.1:44058,DS-3c575cf4-e9ba-4cbc-a49f-80a1a32d0714,DISK], DatanodeInfoWithStorage[127.0.0.1:39314,DS-9688fd25-d29f-4ca1-8665-518733770da4,DISK], DatanodeInfoWithStorage[127.0.0.1:42133,DS-640fe6a2-ec4f-4f6d-be9a-f545fd362392,DISK], DatanodeInfoWithStorage[127.0.0.1:44262,DS-012c58a7-9623-4e66-9477-29bb4a7adaf0,DISK], DatanodeInfoWithStorage[127.0.0.1:45831,DS-39cfc02d-a201-4447-a94b-10d92af8c23d,DISK], DatanodeInfoWithStorage[127.0.0.1:43092,DS-6d1f6454-47c9-435b-8c6e-a9b911beb62a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2012063340-172.17.0.12-1595326155182:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40124,DS-4e7a840c-6e2f-4c65-8456-47a93bb04e9c,DISK], DatanodeInfoWithStorage[127.0.0.1:40526,DS-5d9a71e0-6084-4bee-bd95-9cd7e86ab792,DISK], DatanodeInfoWithStorage[127.0.0.1:44058,DS-3c575cf4-e9ba-4cbc-a49f-80a1a32d0714,DISK], DatanodeInfoWithStorage[127.0.0.1:39314,DS-9688fd25-d29f-4ca1-8665-518733770da4,DISK], DatanodeInfoWithStorage[127.0.0.1:42133,DS-640fe6a2-ec4f-4f6d-be9a-f545fd362392,DISK], DatanodeInfoWithStorage[127.0.0.1:44262,DS-012c58a7-9623-4e66-9477-29bb4a7adaf0,DISK], DatanodeInfoWithStorage[127.0.0.1:45831,DS-39cfc02d-a201-4447-a94b-10d92af8c23d,DISK], DatanodeInfoWithStorage[127.0.0.1:43092,DS-6d1f6454-47c9-435b-8c6e-a9b911beb62a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-875884505-172.17.0.12-1595326194444:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41391,DS-47f45d71-40b6-4f37-b84b-98764869d1cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43763,DS-7de472a7-991c-472e-b9ca-b184eec4195b,DISK], DatanodeInfoWithStorage[127.0.0.1:39866,DS-394ffe7a-b9f1-4394-a2ba-3d0e1a01a118,DISK], DatanodeInfoWithStorage[127.0.0.1:33376,DS-f6b55348-167a-4a8e-b418-ff1d4a83e830,DISK], DatanodeInfoWithStorage[127.0.0.1:38120,DS-f959ff91-4c8c-4e51-bb50-df7c9d678fda,DISK], DatanodeInfoWithStorage[127.0.0.1:43494,DS-748664ed-b17d-4faa-9f9b-2dc120cbfb93,DISK], DatanodeInfoWithStorage[127.0.0.1:36207,DS-7cacbefa-5fe9-4aea-a60c-83a330b7d635,DISK], DatanodeInfoWithStorage[127.0.0.1:43666,DS-a2a674fd-4dae-4a2c-a1d2-f153485058a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-875884505-172.17.0.12-1595326194444:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41391,DS-47f45d71-40b6-4f37-b84b-98764869d1cb,DISK], DatanodeInfoWithStorage[127.0.0.1:43763,DS-7de472a7-991c-472e-b9ca-b184eec4195b,DISK], DatanodeInfoWithStorage[127.0.0.1:39866,DS-394ffe7a-b9f1-4394-a2ba-3d0e1a01a118,DISK], DatanodeInfoWithStorage[127.0.0.1:33376,DS-f6b55348-167a-4a8e-b418-ff1d4a83e830,DISK], DatanodeInfoWithStorage[127.0.0.1:38120,DS-f959ff91-4c8c-4e51-bb50-df7c9d678fda,DISK], DatanodeInfoWithStorage[127.0.0.1:43494,DS-748664ed-b17d-4faa-9f9b-2dc120cbfb93,DISK], DatanodeInfoWithStorage[127.0.0.1:36207,DS-7cacbefa-5fe9-4aea-a60c-83a330b7d635,DISK], DatanodeInfoWithStorage[127.0.0.1:43666,DS-a2a674fd-4dae-4a2c-a1d2-f153485058a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1267786890-172.17.0.12-1595326427943:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34228,DS-bf7a6c1e-e863-4e5f-8581-1ad83bc115f7,DISK], DatanodeInfoWithStorage[127.0.0.1:46136,DS-4a5e4477-9000-4729-b639-a944fa2f5a67,DISK], DatanodeInfoWithStorage[127.0.0.1:34043,DS-019bcb56-35e3-4037-859b-a81ef347a8bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41575,DS-fd7c21bb-7a84-4dab-8350-8ed5c047bc94,DISK], DatanodeInfoWithStorage[127.0.0.1:37212,DS-8adcbb29-bc9b-4d83-b90c-074f00e3791b,DISK], DatanodeInfoWithStorage[127.0.0.1:37233,DS-6936e551-39ea-4726-a15c-3b4f7f26d654,DISK], DatanodeInfoWithStorage[127.0.0.1:34169,DS-aa95954e-fc89-4f91-a453-9e7d26f27ccc,DISK], DatanodeInfoWithStorage[127.0.0.1:33285,DS-2e1ccda8-5795-43c7-bf67-8146a5080740,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1267786890-172.17.0.12-1595326427943:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34228,DS-bf7a6c1e-e863-4e5f-8581-1ad83bc115f7,DISK], DatanodeInfoWithStorage[127.0.0.1:46136,DS-4a5e4477-9000-4729-b639-a944fa2f5a67,DISK], DatanodeInfoWithStorage[127.0.0.1:34043,DS-019bcb56-35e3-4037-859b-a81ef347a8bb,DISK], DatanodeInfoWithStorage[127.0.0.1:41575,DS-fd7c21bb-7a84-4dab-8350-8ed5c047bc94,DISK], DatanodeInfoWithStorage[127.0.0.1:37212,DS-8adcbb29-bc9b-4d83-b90c-074f00e3791b,DISK], DatanodeInfoWithStorage[127.0.0.1:37233,DS-6936e551-39ea-4726-a15c-3b4f7f26d654,DISK], DatanodeInfoWithStorage[127.0.0.1:34169,DS-aa95954e-fc89-4f91-a453-9e7d26f27ccc,DISK], DatanodeInfoWithStorage[127.0.0.1:33285,DS-2e1ccda8-5795-43c7-bf67-8146a5080740,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1522592099-172.17.0.12-1595326749966:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34171,DS-646312c3-c35b-43fc-8b37-ef7058e7e63a,DISK], DatanodeInfoWithStorage[127.0.0.1:41297,DS-aa3a36a7-180a-4837-a2f0-7dd41b0b72b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36699,DS-819ff7e4-b0a3-40a8-9f1a-665703947209,DISK], DatanodeInfoWithStorage[127.0.0.1:37378,DS-727d2696-c863-4a88-86c1-39d9aab59950,DISK], DatanodeInfoWithStorage[127.0.0.1:45106,DS-5ae1be6f-e2fa-4b67-a806-6a927ce05964,DISK], DatanodeInfoWithStorage[127.0.0.1:43713,DS-33268f48-9893-4ef8-959c-9bfbc482a382,DISK], DatanodeInfoWithStorage[127.0.0.1:36478,DS-77394059-dca0-4055-853b-13ad5bf7147d,DISK], DatanodeInfoWithStorage[127.0.0.1:44137,DS-f1b9002d-7109-419b-b755-00404de70754,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1522592099-172.17.0.12-1595326749966:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34171,DS-646312c3-c35b-43fc-8b37-ef7058e7e63a,DISK], DatanodeInfoWithStorage[127.0.0.1:41297,DS-aa3a36a7-180a-4837-a2f0-7dd41b0b72b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36699,DS-819ff7e4-b0a3-40a8-9f1a-665703947209,DISK], DatanodeInfoWithStorage[127.0.0.1:37378,DS-727d2696-c863-4a88-86c1-39d9aab59950,DISK], DatanodeInfoWithStorage[127.0.0.1:45106,DS-5ae1be6f-e2fa-4b67-a806-6a927ce05964,DISK], DatanodeInfoWithStorage[127.0.0.1:43713,DS-33268f48-9893-4ef8-959c-9bfbc482a382,DISK], DatanodeInfoWithStorage[127.0.0.1:36478,DS-77394059-dca0-4055-853b-13ad5bf7147d,DISK], DatanodeInfoWithStorage[127.0.0.1:44137,DS-f1b9002d-7109-419b-b755-00404de70754,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-764104321-172.17.0.12-1595327682096:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35156,DS-c9b12396-5b4e-4e37-b98e-85fe5f0130e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40733,DS-b908bb83-c00c-4ae9-a605-46130edb2e6d,DISK], DatanodeInfoWithStorage[127.0.0.1:45666,DS-8889f690-6da3-4b26-b2cc-4a4b377691f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34498,DS-98f8eb82-509c-4c99-8bf1-476ccca65ceb,DISK], DatanodeInfoWithStorage[127.0.0.1:42281,DS-f691f590-1e91-48ed-bc63-63abd22820b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36595,DS-65cf1beb-ea1f-4502-9337-247aae631f8c,DISK], DatanodeInfoWithStorage[127.0.0.1:36440,DS-5bf7ab95-7f7f-471d-90c0-48d7647ef251,DISK], DatanodeInfoWithStorage[127.0.0.1:33289,DS-fcb219fe-d093-4a38-938a-b88dfcec336b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-764104321-172.17.0.12-1595327682096:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35156,DS-c9b12396-5b4e-4e37-b98e-85fe5f0130e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40733,DS-b908bb83-c00c-4ae9-a605-46130edb2e6d,DISK], DatanodeInfoWithStorage[127.0.0.1:45666,DS-8889f690-6da3-4b26-b2cc-4a4b377691f2,DISK], DatanodeInfoWithStorage[127.0.0.1:34498,DS-98f8eb82-509c-4c99-8bf1-476ccca65ceb,DISK], DatanodeInfoWithStorage[127.0.0.1:42281,DS-f691f590-1e91-48ed-bc63-63abd22820b0,DISK], DatanodeInfoWithStorage[127.0.0.1:36595,DS-65cf1beb-ea1f-4502-9337-247aae631f8c,DISK], DatanodeInfoWithStorage[127.0.0.1:36440,DS-5bf7ab95-7f7f-471d-90c0-48d7647ef251,DISK], DatanodeInfoWithStorage[127.0.0.1:33289,DS-fcb219fe-d093-4a38-938a-b88dfcec336b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-13579927-172.17.0.12-1595328237951:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33050,DS-6c05dd62-e623-4aa3-a323-9b97f41a3e29,DISK], DatanodeInfoWithStorage[127.0.0.1:36437,DS-0b89207b-bfb9-4a7a-ab8a-eca8688fa5b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35045,DS-373a4233-370f-4381-b1ce-8f62e7694e86,DISK], DatanodeInfoWithStorage[127.0.0.1:40112,DS-7578ef43-5cdb-45db-a616-1a13a46621fb,DISK], DatanodeInfoWithStorage[127.0.0.1:43456,DS-9f2cc76f-ee82-4783-8d39-113510eee49e,DISK], DatanodeInfoWithStorage[127.0.0.1:35522,DS-4266efc1-f45e-4db4-aec9-28e3a5c1000c,DISK], DatanodeInfoWithStorage[127.0.0.1:35226,DS-b6fd86e9-ee9a-447e-870b-7d71c39c291a,DISK], DatanodeInfoWithStorage[127.0.0.1:34982,DS-e5414480-c9db-47da-b1ae-f50ea297add3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-13579927-172.17.0.12-1595328237951:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33050,DS-6c05dd62-e623-4aa3-a323-9b97f41a3e29,DISK], DatanodeInfoWithStorage[127.0.0.1:36437,DS-0b89207b-bfb9-4a7a-ab8a-eca8688fa5b8,DISK], DatanodeInfoWithStorage[127.0.0.1:35045,DS-373a4233-370f-4381-b1ce-8f62e7694e86,DISK], DatanodeInfoWithStorage[127.0.0.1:40112,DS-7578ef43-5cdb-45db-a616-1a13a46621fb,DISK], DatanodeInfoWithStorage[127.0.0.1:43456,DS-9f2cc76f-ee82-4783-8d39-113510eee49e,DISK], DatanodeInfoWithStorage[127.0.0.1:35522,DS-4266efc1-f45e-4db4-aec9-28e3a5c1000c,DISK], DatanodeInfoWithStorage[127.0.0.1:35226,DS-b6fd86e9-ee9a-447e-870b-7d71c39c291a,DISK], DatanodeInfoWithStorage[127.0.0.1:34982,DS-e5414480-c9db-47da-b1ae-f50ea297add3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-798232830-172.17.0.12-1595328275204:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32923,DS-066c953e-d12e-4a03-a6f2-1c24c8cd72cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33844,DS-fe8bc7ec-5f27-4f00-8f06-a6e67026bd0b,DISK], DatanodeInfoWithStorage[127.0.0.1:34711,DS-3b14babb-cf8d-4090-950f-d77210384b7b,DISK], DatanodeInfoWithStorage[127.0.0.1:35413,DS-19e357b3-029a-4dff-915b-a8cb61dbed03,DISK], DatanodeInfoWithStorage[127.0.0.1:42816,DS-29716196-2082-4a0a-a4f1-26d4b2da3b88,DISK], DatanodeInfoWithStorage[127.0.0.1:44532,DS-13c79c3c-f2ae-4b11-8961-6301d933e997,DISK], DatanodeInfoWithStorage[127.0.0.1:34400,DS-6c2a9d84-4c9c-4909-ae32-45281611426c,DISK], DatanodeInfoWithStorage[127.0.0.1:46583,DS-30f7e3e7-a337-45d3-96a4-3b7ff0a2d084,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-798232830-172.17.0.12-1595328275204:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32923,DS-066c953e-d12e-4a03-a6f2-1c24c8cd72cc,DISK], DatanodeInfoWithStorage[127.0.0.1:33844,DS-fe8bc7ec-5f27-4f00-8f06-a6e67026bd0b,DISK], DatanodeInfoWithStorage[127.0.0.1:34711,DS-3b14babb-cf8d-4090-950f-d77210384b7b,DISK], DatanodeInfoWithStorage[127.0.0.1:35413,DS-19e357b3-029a-4dff-915b-a8cb61dbed03,DISK], DatanodeInfoWithStorage[127.0.0.1:42816,DS-29716196-2082-4a0a-a4f1-26d4b2da3b88,DISK], DatanodeInfoWithStorage[127.0.0.1:44532,DS-13c79c3c-f2ae-4b11-8961-6301d933e997,DISK], DatanodeInfoWithStorage[127.0.0.1:34400,DS-6c2a9d84-4c9c-4909-ae32-45281611426c,DISK], DatanodeInfoWithStorage[127.0.0.1:46583,DS-30f7e3e7-a337-45d3-96a4-3b7ff0a2d084,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-146651993-172.17.0.12-1595328515367:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37583,DS-5e4ddc8e-d746-42e9-84b8-9fc8974eb1fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37171,DS-cd8be5ad-03e5-4b4d-9ce0-0c8e784f3ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:41913,DS-066e5204-d001-4908-9ef8-87db00e4341c,DISK], DatanodeInfoWithStorage[127.0.0.1:42738,DS-4d7b910e-d0de-4513-87dd-abdeff269af2,DISK], DatanodeInfoWithStorage[127.0.0.1:44960,DS-63fe7cce-5188-4512-82e2-48937fe0f461,DISK], DatanodeInfoWithStorage[127.0.0.1:40944,DS-2db28548-522a-46ee-a3d6-e9896020c050,DISK], DatanodeInfoWithStorage[127.0.0.1:40691,DS-a88303c3-a3f9-40be-a8b0-c47bf356fb3e,DISK], DatanodeInfoWithStorage[127.0.0.1:43963,DS-b8234bae-2b16-4dcc-86bd-0c83cf8d3cd1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-146651993-172.17.0.12-1595328515367:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37583,DS-5e4ddc8e-d746-42e9-84b8-9fc8974eb1fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37171,DS-cd8be5ad-03e5-4b4d-9ce0-0c8e784f3ff3,DISK], DatanodeInfoWithStorage[127.0.0.1:41913,DS-066e5204-d001-4908-9ef8-87db00e4341c,DISK], DatanodeInfoWithStorage[127.0.0.1:42738,DS-4d7b910e-d0de-4513-87dd-abdeff269af2,DISK], DatanodeInfoWithStorage[127.0.0.1:44960,DS-63fe7cce-5188-4512-82e2-48937fe0f461,DISK], DatanodeInfoWithStorage[127.0.0.1:40944,DS-2db28548-522a-46ee-a3d6-e9896020c050,DISK], DatanodeInfoWithStorage[127.0.0.1:40691,DS-a88303c3-a3f9-40be-a8b0-c47bf356fb3e,DISK], DatanodeInfoWithStorage[127.0.0.1:43963,DS-b8234bae-2b16-4dcc-86bd-0c83cf8d3cd1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1349107254-172.17.0.12-1595328903272:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44969,DS-4752910b-a27a-426e-9235-66332e830da9,DISK], DatanodeInfoWithStorage[127.0.0.1:43348,DS-5dd1ebd5-9a51-4700-af08-9020d2e5f495,DISK], DatanodeInfoWithStorage[127.0.0.1:33078,DS-3309e3bc-0e96-4878-9fb8-5674ffc236b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36724,DS-34720bc5-ef7e-430e-8b8d-969a58c9b9ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33247,DS-6e3b29f9-64a8-4fb9-a107-f018c2a3e920,DISK], DatanodeInfoWithStorage[127.0.0.1:43663,DS-bf5c2c6f-0a1c-4255-8097-65d2d6528969,DISK], DatanodeInfoWithStorage[127.0.0.1:45603,DS-66556652-a395-4e37-91b6-2a99cf21c1c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45445,DS-20f4c484-f309-4d1c-805b-1bb3f36b883a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1349107254-172.17.0.12-1595328903272:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44969,DS-4752910b-a27a-426e-9235-66332e830da9,DISK], DatanodeInfoWithStorage[127.0.0.1:43348,DS-5dd1ebd5-9a51-4700-af08-9020d2e5f495,DISK], DatanodeInfoWithStorage[127.0.0.1:33078,DS-3309e3bc-0e96-4878-9fb8-5674ffc236b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36724,DS-34720bc5-ef7e-430e-8b8d-969a58c9b9ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33247,DS-6e3b29f9-64a8-4fb9-a107-f018c2a3e920,DISK], DatanodeInfoWithStorage[127.0.0.1:43663,DS-bf5c2c6f-0a1c-4255-8097-65d2d6528969,DISK], DatanodeInfoWithStorage[127.0.0.1:45603,DS-66556652-a395-4e37-91b6-2a99cf21c1c0,DISK], DatanodeInfoWithStorage[127.0.0.1:45445,DS-20f4c484-f309-4d1c-805b-1bb3f36b883a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-414140956-172.17.0.12-1595329472947:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46144,DS-826d00e7-67db-465c-805e-92a9b15a3c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:40127,DS-0bcfcf6d-123f-4405-82e3-0e74b35fc540,DISK], DatanodeInfoWithStorage[127.0.0.1:45998,DS-b0f0a0f8-81cd-47d3-a5c6-2a86f025847b,DISK], DatanodeInfoWithStorage[127.0.0.1:41527,DS-068dfdb9-9f65-4cf3-b3b0-8271e579d4d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33752,DS-fba2cefe-8472-41b2-9c58-20a023f6feae,DISK], DatanodeInfoWithStorage[127.0.0.1:33380,DS-0571558e-56b3-46c8-b26b-56f2cbd8ce65,DISK], DatanodeInfoWithStorage[127.0.0.1:45270,DS-745e1d7b-5e25-467b-935c-5ac51d926cd1,DISK], DatanodeInfoWithStorage[127.0.0.1:37266,DS-f1628a67-b0e8-48eb-b683-d9c758dbf8b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-414140956-172.17.0.12-1595329472947:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46144,DS-826d00e7-67db-465c-805e-92a9b15a3c6c,DISK], DatanodeInfoWithStorage[127.0.0.1:40127,DS-0bcfcf6d-123f-4405-82e3-0e74b35fc540,DISK], DatanodeInfoWithStorage[127.0.0.1:45998,DS-b0f0a0f8-81cd-47d3-a5c6-2a86f025847b,DISK], DatanodeInfoWithStorage[127.0.0.1:41527,DS-068dfdb9-9f65-4cf3-b3b0-8271e579d4d4,DISK], DatanodeInfoWithStorage[127.0.0.1:33752,DS-fba2cefe-8472-41b2-9c58-20a023f6feae,DISK], DatanodeInfoWithStorage[127.0.0.1:33380,DS-0571558e-56b3-46c8-b26b-56f2cbd8ce65,DISK], DatanodeInfoWithStorage[127.0.0.1:45270,DS-745e1d7b-5e25-467b-935c-5ac51d926cd1,DISK], DatanodeInfoWithStorage[127.0.0.1:37266,DS-f1628a67-b0e8-48eb-b683-d9c758dbf8b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1402975827-172.17.0.12-1595329702559:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35308,DS-197df4bf-a43d-44d8-a87c-eb55abb795b0,DISK], DatanodeInfoWithStorage[127.0.0.1:32807,DS-66156d86-8042-4757-be43-708f9323b7a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41586,DS-90f5adac-0c29-4340-a765-9bf5489324b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40222,DS-74039fe1-9df1-443a-99a0-3b23cbc67cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:37056,DS-b97f9ce4-0565-4fcf-95e4-df022aa61470,DISK], DatanodeInfoWithStorage[127.0.0.1:44034,DS-acfde824-ef5f-4487-9f24-6a8106d701de,DISK], DatanodeInfoWithStorage[127.0.0.1:43123,DS-d3fa5b07-0157-415a-95b5-6c56376d5a51,DISK], DatanodeInfoWithStorage[127.0.0.1:35202,DS-558ccc4e-f045-48d9-8ad2-34acc51fd8a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1402975827-172.17.0.12-1595329702559:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35308,DS-197df4bf-a43d-44d8-a87c-eb55abb795b0,DISK], DatanodeInfoWithStorage[127.0.0.1:32807,DS-66156d86-8042-4757-be43-708f9323b7a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41586,DS-90f5adac-0c29-4340-a765-9bf5489324b4,DISK], DatanodeInfoWithStorage[127.0.0.1:40222,DS-74039fe1-9df1-443a-99a0-3b23cbc67cbe,DISK], DatanodeInfoWithStorage[127.0.0.1:37056,DS-b97f9ce4-0565-4fcf-95e4-df022aa61470,DISK], DatanodeInfoWithStorage[127.0.0.1:44034,DS-acfde824-ef5f-4487-9f24-6a8106d701de,DISK], DatanodeInfoWithStorage[127.0.0.1:43123,DS-d3fa5b07-0157-415a-95b5-6c56376d5a51,DISK], DatanodeInfoWithStorage[127.0.0.1:35202,DS-558ccc4e-f045-48d9-8ad2-34acc51fd8a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1316612744-172.17.0.12-1595329873984:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41554,DS-88cdb33f-1d55-440a-b4ae-506584db02c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38326,DS-ea08db71-a9f8-418f-bb5e-2a6c63fac157,DISK], DatanodeInfoWithStorage[127.0.0.1:36096,DS-b9bb1a6a-7311-43a8-bb47-71447376cc00,DISK], DatanodeInfoWithStorage[127.0.0.1:43668,DS-27ef9ccc-2f89-4a5d-9e5d-2746de7785f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42881,DS-f0b47229-560f-4d1b-9e39-48c5c31f1ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:39246,DS-68810e12-26ce-47bc-bdcf-54295821038a,DISK], DatanodeInfoWithStorage[127.0.0.1:35829,DS-d395cb01-1fbb-4033-a5f9-2dd7224852d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41146,DS-565d0cac-8ed7-4397-b06f-b43a0dc10191,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1316612744-172.17.0.12-1595329873984:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41554,DS-88cdb33f-1d55-440a-b4ae-506584db02c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38326,DS-ea08db71-a9f8-418f-bb5e-2a6c63fac157,DISK], DatanodeInfoWithStorage[127.0.0.1:36096,DS-b9bb1a6a-7311-43a8-bb47-71447376cc00,DISK], DatanodeInfoWithStorage[127.0.0.1:43668,DS-27ef9ccc-2f89-4a5d-9e5d-2746de7785f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42881,DS-f0b47229-560f-4d1b-9e39-48c5c31f1ab7,DISK], DatanodeInfoWithStorage[127.0.0.1:39246,DS-68810e12-26ce-47bc-bdcf-54295821038a,DISK], DatanodeInfoWithStorage[127.0.0.1:35829,DS-d395cb01-1fbb-4033-a5f9-2dd7224852d0,DISK], DatanodeInfoWithStorage[127.0.0.1:41146,DS-565d0cac-8ed7-4397-b06f-b43a0dc10191,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1744854598-172.17.0.12-1595330775362:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40395,DS-8a54b219-b312-46ad-a3ac-b467b20bab9c,DISK], DatanodeInfoWithStorage[127.0.0.1:33024,DS-f434a0cf-4806-455d-b096-c8e30d49b7dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38689,DS-b5c56a78-9b16-47ba-9fde-53301fa9db58,DISK], DatanodeInfoWithStorage[127.0.0.1:46503,DS-fa083a39-2eab-48df-ba6d-25b9bb030557,DISK], DatanodeInfoWithStorage[127.0.0.1:43017,DS-dce2c823-e653-4881-8210-03a4c78597c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37834,DS-4470be88-2706-4fd9-87e8-3438a1f635c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45866,DS-91b76dd8-0a5f-4abe-b7eb-e81d9f80f387,DISK], DatanodeInfoWithStorage[127.0.0.1:45424,DS-daffa39b-81c1-40f4-9f3a-e563096393aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1744854598-172.17.0.12-1595330775362:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40395,DS-8a54b219-b312-46ad-a3ac-b467b20bab9c,DISK], DatanodeInfoWithStorage[127.0.0.1:33024,DS-f434a0cf-4806-455d-b096-c8e30d49b7dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38689,DS-b5c56a78-9b16-47ba-9fde-53301fa9db58,DISK], DatanodeInfoWithStorage[127.0.0.1:46503,DS-fa083a39-2eab-48df-ba6d-25b9bb030557,DISK], DatanodeInfoWithStorage[127.0.0.1:43017,DS-dce2c823-e653-4881-8210-03a4c78597c0,DISK], DatanodeInfoWithStorage[127.0.0.1:37834,DS-4470be88-2706-4fd9-87e8-3438a1f635c6,DISK], DatanodeInfoWithStorage[127.0.0.1:45866,DS-91b76dd8-0a5f-4abe-b7eb-e81d9f80f387,DISK], DatanodeInfoWithStorage[127.0.0.1:45424,DS-daffa39b-81c1-40f4-9f3a-e563096393aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-16567512-172.17.0.12-1595331258494:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40323,DS-57eb0d9b-f2b1-4fa0-90bd-289366f8eaa0,DISK], DatanodeInfoWithStorage[127.0.0.1:46603,DS-a7481cbc-a066-4ba8-b3f6-b9b071b5c2e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45408,DS-ec94cb21-68d1-4b3b-8be4-92bf2627e97d,DISK], DatanodeInfoWithStorage[127.0.0.1:42901,DS-f609928f-a0f4-47a7-b10d-94c23a2ea311,DISK], DatanodeInfoWithStorage[127.0.0.1:36842,DS-258b0f72-b770-46af-b661-532912038edc,DISK], DatanodeInfoWithStorage[127.0.0.1:33129,DS-68a245a6-9841-4489-b8ca-095fa6b353e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36574,DS-cc50d316-0cd7-491f-9a80-b1dfcc050872,DISK], DatanodeInfoWithStorage[127.0.0.1:40843,DS-e46e4ca8-c31d-4a80-b98c-2e48c5ac95b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-16567512-172.17.0.12-1595331258494:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40323,DS-57eb0d9b-f2b1-4fa0-90bd-289366f8eaa0,DISK], DatanodeInfoWithStorage[127.0.0.1:46603,DS-a7481cbc-a066-4ba8-b3f6-b9b071b5c2e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45408,DS-ec94cb21-68d1-4b3b-8be4-92bf2627e97d,DISK], DatanodeInfoWithStorage[127.0.0.1:42901,DS-f609928f-a0f4-47a7-b10d-94c23a2ea311,DISK], DatanodeInfoWithStorage[127.0.0.1:36842,DS-258b0f72-b770-46af-b661-532912038edc,DISK], DatanodeInfoWithStorage[127.0.0.1:33129,DS-68a245a6-9841-4489-b8ca-095fa6b353e0,DISK], DatanodeInfoWithStorage[127.0.0.1:36574,DS-cc50d316-0cd7-491f-9a80-b1dfcc050872,DISK], DatanodeInfoWithStorage[127.0.0.1:40843,DS-e46e4ca8-c31d-4a80-b98c-2e48c5ac95b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.encrypt.data.overwrite.downstream.derived.qop
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-891699618-172.17.0.12-1595331358403:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39738,DS-cd5e5a42-65d0-4867-b3f9-d9b3b874aa2e,DISK], DatanodeInfoWithStorage[127.0.0.1:32794,DS-89676724-f92c-4c18-a5af-69ceaaec9e8d,DISK], DatanodeInfoWithStorage[127.0.0.1:34237,DS-d3dc1123-4356-4b23-9a69-fd1ee800b495,DISK], DatanodeInfoWithStorage[127.0.0.1:40226,DS-4ec8d371-5b9a-47ec-ba2c-a9943e2e26e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46134,DS-94e9cbb9-dae6-42a0-a7b2-c2bf31d7bbb4,DISK], DatanodeInfoWithStorage[127.0.0.1:43396,DS-609f9911-2ebe-4b3b-b51c-5a72a0e0238f,DISK], DatanodeInfoWithStorage[127.0.0.1:34147,DS-8bd9e177-86e1-4ef4-b673-8e8fa58e67c4,DISK], DatanodeInfoWithStorage[127.0.0.1:37837,DS-f0fb7647-915c-4e77-93ab-cb851a8a86ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-891699618-172.17.0.12-1595331358403:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39738,DS-cd5e5a42-65d0-4867-b3f9-d9b3b874aa2e,DISK], DatanodeInfoWithStorage[127.0.0.1:32794,DS-89676724-f92c-4c18-a5af-69ceaaec9e8d,DISK], DatanodeInfoWithStorage[127.0.0.1:34237,DS-d3dc1123-4356-4b23-9a69-fd1ee800b495,DISK], DatanodeInfoWithStorage[127.0.0.1:40226,DS-4ec8d371-5b9a-47ec-ba2c-a9943e2e26e3,DISK], DatanodeInfoWithStorage[127.0.0.1:46134,DS-94e9cbb9-dae6-42a0-a7b2-c2bf31d7bbb4,DISK], DatanodeInfoWithStorage[127.0.0.1:43396,DS-609f9911-2ebe-4b3b-b51c-5a72a0e0238f,DISK], DatanodeInfoWithStorage[127.0.0.1:34147,DS-8bd9e177-86e1-4ef4-b673-8e8fa58e67c4,DISK], DatanodeInfoWithStorage[127.0.0.1:37837,DS-f0fb7647-915c-4e77-93ab-cb851a8a86ed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 8 out of 50
result: false positive !!!
Total execution time in seconds : 5430
