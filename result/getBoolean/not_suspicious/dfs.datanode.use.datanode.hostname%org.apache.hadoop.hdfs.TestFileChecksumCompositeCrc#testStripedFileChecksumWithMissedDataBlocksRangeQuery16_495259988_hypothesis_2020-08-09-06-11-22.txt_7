reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1848221080-172.17.0.14-1596953684465:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41289,DS-c5711558-16fa-4c16-8581-86155fde9d40,DISK], DatanodeInfoWithStorage[127.0.0.1:36563,DS-2aa1b355-7855-47ab-8123-1c579e72e130,DISK], DatanodeInfoWithStorage[127.0.0.1:37243,DS-01609a01-5388-44a3-8606-cdcd01a744a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41734,DS-a1814bc8-471f-4b8f-90f0-b8950b8920f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41751,DS-2754bb7c-5b7b-4d12-b28f-4c51b196254d,DISK], DatanodeInfoWithStorage[127.0.0.1:34408,DS-79d6d291-98f4-4709-b804-d1488430a0c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38860,DS-25a90027-edf4-4b56-8669-2f9ca3a414ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41391,DS-f97ae62d-aa26-4c3e-995f-0b57feeda5f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1848221080-172.17.0.14-1596953684465:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41289,DS-c5711558-16fa-4c16-8581-86155fde9d40,DISK], DatanodeInfoWithStorage[127.0.0.1:36563,DS-2aa1b355-7855-47ab-8123-1c579e72e130,DISK], DatanodeInfoWithStorage[127.0.0.1:37243,DS-01609a01-5388-44a3-8606-cdcd01a744a7,DISK], DatanodeInfoWithStorage[127.0.0.1:41734,DS-a1814bc8-471f-4b8f-90f0-b8950b8920f7,DISK], DatanodeInfoWithStorage[127.0.0.1:41751,DS-2754bb7c-5b7b-4d12-b28f-4c51b196254d,DISK], DatanodeInfoWithStorage[127.0.0.1:34408,DS-79d6d291-98f4-4709-b804-d1488430a0c6,DISK], DatanodeInfoWithStorage[127.0.0.1:38860,DS-25a90027-edf4-4b56-8669-2f9ca3a414ef,DISK], DatanodeInfoWithStorage[127.0.0.1:41391,DS-f97ae62d-aa26-4c3e-995f-0b57feeda5f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1491422238-172.17.0.14-1596953720604:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37471,DS-8aeeb462-a171-44a1-8b37-19135199722a,DISK], DatanodeInfoWithStorage[127.0.0.1:37343,DS-30c0792c-5e0c-4ccc-a250-9a604460acaa,DISK], DatanodeInfoWithStorage[127.0.0.1:37586,DS-97c1ab8d-4f28-4c82-bbf4-b2c5fbe1b04b,DISK], DatanodeInfoWithStorage[127.0.0.1:45916,DS-92333a5f-afb0-48a4-b6d9-92a8267b6086,DISK], DatanodeInfoWithStorage[127.0.0.1:34203,DS-4161fc6e-cff2-48cc-afa7-73e52eaebe7a,DISK], DatanodeInfoWithStorage[127.0.0.1:41598,DS-88d8b7ce-0892-41b2-8f88-6f0b316d45bd,DISK], DatanodeInfoWithStorage[127.0.0.1:46263,DS-992a748c-56de-4333-b2d8-b67d1e813996,DISK], DatanodeInfoWithStorage[127.0.0.1:36509,DS-fb232025-e0e1-4ac4-9ec5-06c2b9f0a84f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1491422238-172.17.0.14-1596953720604:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37471,DS-8aeeb462-a171-44a1-8b37-19135199722a,DISK], DatanodeInfoWithStorage[127.0.0.1:37343,DS-30c0792c-5e0c-4ccc-a250-9a604460acaa,DISK], DatanodeInfoWithStorage[127.0.0.1:37586,DS-97c1ab8d-4f28-4c82-bbf4-b2c5fbe1b04b,DISK], DatanodeInfoWithStorage[127.0.0.1:45916,DS-92333a5f-afb0-48a4-b6d9-92a8267b6086,DISK], DatanodeInfoWithStorage[127.0.0.1:34203,DS-4161fc6e-cff2-48cc-afa7-73e52eaebe7a,DISK], DatanodeInfoWithStorage[127.0.0.1:41598,DS-88d8b7ce-0892-41b2-8f88-6f0b316d45bd,DISK], DatanodeInfoWithStorage[127.0.0.1:46263,DS-992a748c-56de-4333-b2d8-b67d1e813996,DISK], DatanodeInfoWithStorage[127.0.0.1:36509,DS-fb232025-e0e1-4ac4-9ec5-06c2b9f0a84f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1702893614-172.17.0.14-1596953799338:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36125,DS-eabaacbe-c329-4e92-ba03-62fd2b1c3e50,DISK], DatanodeInfoWithStorage[127.0.0.1:45442,DS-36863fb2-0188-4ea9-9cf9-23390210aa62,DISK], DatanodeInfoWithStorage[127.0.0.1:34741,DS-d0991b08-ab3c-4687-ab82-ec5d530b925b,DISK], DatanodeInfoWithStorage[127.0.0.1:35775,DS-5678cb36-0faf-46b0-8ff3-ce7513b5907c,DISK], DatanodeInfoWithStorage[127.0.0.1:43540,DS-5cc259ea-4ad2-43b8-9716-95e14b7d55dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36709,DS-6dddc68d-6575-44e8-99fa-a041eaa8f9dd,DISK], DatanodeInfoWithStorage[127.0.0.1:35280,DS-e562dd8d-cae2-4e04-9656-b7f6aec4bb7e,DISK], DatanodeInfoWithStorage[127.0.0.1:46677,DS-48ad1374-e18d-4fcb-9441-0409f2985013,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1702893614-172.17.0.14-1596953799338:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36125,DS-eabaacbe-c329-4e92-ba03-62fd2b1c3e50,DISK], DatanodeInfoWithStorage[127.0.0.1:45442,DS-36863fb2-0188-4ea9-9cf9-23390210aa62,DISK], DatanodeInfoWithStorage[127.0.0.1:34741,DS-d0991b08-ab3c-4687-ab82-ec5d530b925b,DISK], DatanodeInfoWithStorage[127.0.0.1:35775,DS-5678cb36-0faf-46b0-8ff3-ce7513b5907c,DISK], DatanodeInfoWithStorage[127.0.0.1:43540,DS-5cc259ea-4ad2-43b8-9716-95e14b7d55dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36709,DS-6dddc68d-6575-44e8-99fa-a041eaa8f9dd,DISK], DatanodeInfoWithStorage[127.0.0.1:35280,DS-e562dd8d-cae2-4e04-9656-b7f6aec4bb7e,DISK], DatanodeInfoWithStorage[127.0.0.1:46677,DS-48ad1374-e18d-4fcb-9441-0409f2985013,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-338975304-172.17.0.14-1596953912621:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34727,DS-f23e878d-21d9-4706-ade3-fdfb2f3fb77c,DISK], DatanodeInfoWithStorage[127.0.0.1:44053,DS-9731f374-9fb3-4c76-809f-bd878f570e85,DISK], DatanodeInfoWithStorage[127.0.0.1:45870,DS-d7affbf9-4907-40bb-826f-e407d3dec600,DISK], DatanodeInfoWithStorage[127.0.0.1:38426,DS-3f1f97da-5ebe-49a4-9ac1-a3bceb00c162,DISK], DatanodeInfoWithStorage[127.0.0.1:44792,DS-4c6527bb-793a-42c4-a612-43f0e253b076,DISK], DatanodeInfoWithStorage[127.0.0.1:38850,DS-158f49ba-9d63-4cae-aa64-006300251edb,DISK], DatanodeInfoWithStorage[127.0.0.1:34086,DS-5afdacdb-9149-4da9-873e-b734e4e5a0e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35822,DS-3a95dab4-7bfb-4b24-8aab-3ddcdf97466e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-338975304-172.17.0.14-1596953912621:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34727,DS-f23e878d-21d9-4706-ade3-fdfb2f3fb77c,DISK], DatanodeInfoWithStorage[127.0.0.1:44053,DS-9731f374-9fb3-4c76-809f-bd878f570e85,DISK], DatanodeInfoWithStorage[127.0.0.1:45870,DS-d7affbf9-4907-40bb-826f-e407d3dec600,DISK], DatanodeInfoWithStorage[127.0.0.1:38426,DS-3f1f97da-5ebe-49a4-9ac1-a3bceb00c162,DISK], DatanodeInfoWithStorage[127.0.0.1:44792,DS-4c6527bb-793a-42c4-a612-43f0e253b076,DISK], DatanodeInfoWithStorage[127.0.0.1:38850,DS-158f49ba-9d63-4cae-aa64-006300251edb,DISK], DatanodeInfoWithStorage[127.0.0.1:34086,DS-5afdacdb-9149-4da9-873e-b734e4e5a0e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35822,DS-3a95dab4-7bfb-4b24-8aab-3ddcdf97466e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1358427363-172.17.0.14-1596954256221:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39075,DS-19e45839-bebc-42f8-9167-f9e7160817a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34582,DS-b5b816ce-94e9-4668-a091-143b0af4e2e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40984,DS-e43feeaa-7033-4550-9b23-8313693fe500,DISK], DatanodeInfoWithStorage[127.0.0.1:43911,DS-65661905-0627-4880-bf99-fc44f22ef3a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38317,DS-d2085a21-0c0d-4457-a868-ad21a8bc0a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:35421,DS-c167de6d-e850-4aab-b37f-5f69654b730a,DISK], DatanodeInfoWithStorage[127.0.0.1:38323,DS-f7b0d1ce-c9b2-4af7-9436-efc9d98f74dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41329,DS-f0db824e-a9aa-4b4c-b266-021a3c28f4b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1358427363-172.17.0.14-1596954256221:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39075,DS-19e45839-bebc-42f8-9167-f9e7160817a2,DISK], DatanodeInfoWithStorage[127.0.0.1:34582,DS-b5b816ce-94e9-4668-a091-143b0af4e2e0,DISK], DatanodeInfoWithStorage[127.0.0.1:40984,DS-e43feeaa-7033-4550-9b23-8313693fe500,DISK], DatanodeInfoWithStorage[127.0.0.1:43911,DS-65661905-0627-4880-bf99-fc44f22ef3a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38317,DS-d2085a21-0c0d-4457-a868-ad21a8bc0a2d,DISK], DatanodeInfoWithStorage[127.0.0.1:35421,DS-c167de6d-e850-4aab-b37f-5f69654b730a,DISK], DatanodeInfoWithStorage[127.0.0.1:38323,DS-f7b0d1ce-c9b2-4af7-9436-efc9d98f74dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41329,DS-f0db824e-a9aa-4b4c-b266-021a3c28f4b0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-683332315-172.17.0.14-1596954319185:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43588,DS-1e0ea24c-f79f-447a-9974-d990ebd9aa02,DISK], DatanodeInfoWithStorage[127.0.0.1:35107,DS-08a36c46-f36c-4036-b986-c37cc9479c49,DISK], DatanodeInfoWithStorage[127.0.0.1:36959,DS-bd4f3ce5-478e-4793-a6e9-4e52ba745586,DISK], DatanodeInfoWithStorage[127.0.0.1:44488,DS-2a7bf31f-bcad-4444-b9f5-b7ff3652744b,DISK], DatanodeInfoWithStorage[127.0.0.1:45057,DS-647bcf8c-5cd4-4dd4-ac15-4b05512936af,DISK], DatanodeInfoWithStorage[127.0.0.1:37557,DS-d4d72c77-96b7-4e01-a409-328e2c264698,DISK], DatanodeInfoWithStorage[127.0.0.1:36458,DS-48d9313f-f6dd-49f8-a525-eb8868222075,DISK], DatanodeInfoWithStorage[127.0.0.1:35678,DS-8b5f98ad-4936-41cd-8482-283d519a9186,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-683332315-172.17.0.14-1596954319185:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43588,DS-1e0ea24c-f79f-447a-9974-d990ebd9aa02,DISK], DatanodeInfoWithStorage[127.0.0.1:35107,DS-08a36c46-f36c-4036-b986-c37cc9479c49,DISK], DatanodeInfoWithStorage[127.0.0.1:36959,DS-bd4f3ce5-478e-4793-a6e9-4e52ba745586,DISK], DatanodeInfoWithStorage[127.0.0.1:44488,DS-2a7bf31f-bcad-4444-b9f5-b7ff3652744b,DISK], DatanodeInfoWithStorage[127.0.0.1:45057,DS-647bcf8c-5cd4-4dd4-ac15-4b05512936af,DISK], DatanodeInfoWithStorage[127.0.0.1:37557,DS-d4d72c77-96b7-4e01-a409-328e2c264698,DISK], DatanodeInfoWithStorage[127.0.0.1:36458,DS-48d9313f-f6dd-49f8-a525-eb8868222075,DISK], DatanodeInfoWithStorage[127.0.0.1:35678,DS-8b5f98ad-4936-41cd-8482-283d519a9186,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1701578561-172.17.0.14-1596954386455:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40020,DS-b600d806-2a87-4dae-9c79-1fef5f49f248,DISK], DatanodeInfoWithStorage[127.0.0.1:44476,DS-45aa576b-ec66-40e5-840e-8d2dcb610041,DISK], DatanodeInfoWithStorage[127.0.0.1:35194,DS-8c5a2c10-f7a6-4ee4-a8e7-13b6d9a97d05,DISK], DatanodeInfoWithStorage[127.0.0.1:41379,DS-4ab0e2d5-f8db-41c1-96eb-821e4e6a65a6,DISK], DatanodeInfoWithStorage[127.0.0.1:43329,DS-aba869c2-319e-4814-81b2-11eb34481c79,DISK], DatanodeInfoWithStorage[127.0.0.1:39829,DS-e82f3121-886b-44ba-8593-ace63fff4e9c,DISK], DatanodeInfoWithStorage[127.0.0.1:43726,DS-1da7ffe3-1399-4583-834b-0555ee98bf22,DISK], DatanodeInfoWithStorage[127.0.0.1:42597,DS-0d2574a6-ef20-460b-a365-6dbf7654a846,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1701578561-172.17.0.14-1596954386455:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40020,DS-b600d806-2a87-4dae-9c79-1fef5f49f248,DISK], DatanodeInfoWithStorage[127.0.0.1:44476,DS-45aa576b-ec66-40e5-840e-8d2dcb610041,DISK], DatanodeInfoWithStorage[127.0.0.1:35194,DS-8c5a2c10-f7a6-4ee4-a8e7-13b6d9a97d05,DISK], DatanodeInfoWithStorage[127.0.0.1:41379,DS-4ab0e2d5-f8db-41c1-96eb-821e4e6a65a6,DISK], DatanodeInfoWithStorage[127.0.0.1:43329,DS-aba869c2-319e-4814-81b2-11eb34481c79,DISK], DatanodeInfoWithStorage[127.0.0.1:39829,DS-e82f3121-886b-44ba-8593-ace63fff4e9c,DISK], DatanodeInfoWithStorage[127.0.0.1:43726,DS-1da7ffe3-1399-4583-834b-0555ee98bf22,DISK], DatanodeInfoWithStorage[127.0.0.1:42597,DS-0d2574a6-ef20-460b-a365-6dbf7654a846,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1458716363-172.17.0.14-1596954624676:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42554,DS-865bd2f7-0f72-49e4-b023-9dbb038df640,DISK], DatanodeInfoWithStorage[127.0.0.1:45836,DS-4461b156-b800-4cea-a0b1-61d828f27abf,DISK], DatanodeInfoWithStorage[127.0.0.1:38564,DS-4158d336-ee49-4f66-938e-b3455098233d,DISK], DatanodeInfoWithStorage[127.0.0.1:36717,DS-d4ab28b0-d3d6-4646-9cda-bd4311f3ba9f,DISK], DatanodeInfoWithStorage[127.0.0.1:36611,DS-db02114f-2dd2-438e-8aa2-9cc8807582d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44562,DS-89513f96-dd39-42f2-83d1-9329a24e9b70,DISK], DatanodeInfoWithStorage[127.0.0.1:43988,DS-78a2c7ca-71f3-4ae1-84be-dbd154b0c4cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44837,DS-b8386dbb-7ecb-4c11-aca5-3f9cd78ff791,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1458716363-172.17.0.14-1596954624676:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42554,DS-865bd2f7-0f72-49e4-b023-9dbb038df640,DISK], DatanodeInfoWithStorage[127.0.0.1:45836,DS-4461b156-b800-4cea-a0b1-61d828f27abf,DISK], DatanodeInfoWithStorage[127.0.0.1:38564,DS-4158d336-ee49-4f66-938e-b3455098233d,DISK], DatanodeInfoWithStorage[127.0.0.1:36717,DS-d4ab28b0-d3d6-4646-9cda-bd4311f3ba9f,DISK], DatanodeInfoWithStorage[127.0.0.1:36611,DS-db02114f-2dd2-438e-8aa2-9cc8807582d4,DISK], DatanodeInfoWithStorage[127.0.0.1:44562,DS-89513f96-dd39-42f2-83d1-9329a24e9b70,DISK], DatanodeInfoWithStorage[127.0.0.1:43988,DS-78a2c7ca-71f3-4ae1-84be-dbd154b0c4cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44837,DS-b8386dbb-7ecb-4c11-aca5-3f9cd78ff791,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1204356360-172.17.0.14-1596955778621:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42535,DS-d96d3074-2ec6-45fc-a122-e6e32077d1ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33476,DS-81e0dd24-ca09-46e1-9083-3cd3269fc06b,DISK], DatanodeInfoWithStorage[127.0.0.1:39125,DS-72180638-21a6-4cb3-b24f-2b955058bdee,DISK], DatanodeInfoWithStorage[127.0.0.1:36433,DS-663de465-16f6-4c2c-86a2-61754c9f527d,DISK], DatanodeInfoWithStorage[127.0.0.1:33265,DS-e4afcdc1-f983-48b6-b395-f5a8b1fe124f,DISK], DatanodeInfoWithStorage[127.0.0.1:38681,DS-bc354cf8-e378-45fe-bbcf-9d121642b824,DISK], DatanodeInfoWithStorage[127.0.0.1:34450,DS-d2c7d28b-77c2-45e8-ace8-d32e66c816c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45834,DS-10cce0a6-175f-4a28-b08f-448c5c5899e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1204356360-172.17.0.14-1596955778621:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42535,DS-d96d3074-2ec6-45fc-a122-e6e32077d1ad,DISK], DatanodeInfoWithStorage[127.0.0.1:33476,DS-81e0dd24-ca09-46e1-9083-3cd3269fc06b,DISK], DatanodeInfoWithStorage[127.0.0.1:39125,DS-72180638-21a6-4cb3-b24f-2b955058bdee,DISK], DatanodeInfoWithStorage[127.0.0.1:36433,DS-663de465-16f6-4c2c-86a2-61754c9f527d,DISK], DatanodeInfoWithStorage[127.0.0.1:33265,DS-e4afcdc1-f983-48b6-b395-f5a8b1fe124f,DISK], DatanodeInfoWithStorage[127.0.0.1:38681,DS-bc354cf8-e378-45fe-bbcf-9d121642b824,DISK], DatanodeInfoWithStorage[127.0.0.1:34450,DS-d2c7d28b-77c2-45e8-ace8-d32e66c816c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45834,DS-10cce0a6-175f-4a28-b08f-448c5c5899e2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-290185625-172.17.0.14-1596955885845:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40495,DS-e143302d-2b81-42b3-bbf2-37d8352147fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45075,DS-5477b44d-fc91-4a7c-a909-7464a405280f,DISK], DatanodeInfoWithStorage[127.0.0.1:34220,DS-84e1f04b-7c18-4d60-874e-af418ce1c600,DISK], DatanodeInfoWithStorage[127.0.0.1:37077,DS-9f9e88b5-966e-47b2-ba8a-a89eabf48856,DISK], DatanodeInfoWithStorage[127.0.0.1:38195,DS-33338197-4037-44ce-8561-d76227d5177e,DISK], DatanodeInfoWithStorage[127.0.0.1:38214,DS-524eedef-3783-4a85-a79d-421c725fbe8d,DISK], DatanodeInfoWithStorage[127.0.0.1:46162,DS-705dd5c0-2660-41f7-8d29-43cf9ab0fcaa,DISK], DatanodeInfoWithStorage[127.0.0.1:40211,DS-994780ca-9ede-484d-89a4-4d187b08f1b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-290185625-172.17.0.14-1596955885845:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40495,DS-e143302d-2b81-42b3-bbf2-37d8352147fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45075,DS-5477b44d-fc91-4a7c-a909-7464a405280f,DISK], DatanodeInfoWithStorage[127.0.0.1:34220,DS-84e1f04b-7c18-4d60-874e-af418ce1c600,DISK], DatanodeInfoWithStorage[127.0.0.1:37077,DS-9f9e88b5-966e-47b2-ba8a-a89eabf48856,DISK], DatanodeInfoWithStorage[127.0.0.1:38195,DS-33338197-4037-44ce-8561-d76227d5177e,DISK], DatanodeInfoWithStorage[127.0.0.1:38214,DS-524eedef-3783-4a85-a79d-421c725fbe8d,DISK], DatanodeInfoWithStorage[127.0.0.1:46162,DS-705dd5c0-2660-41f7-8d29-43cf9ab0fcaa,DISK], DatanodeInfoWithStorage[127.0.0.1:40211,DS-994780ca-9ede-484d-89a4-4d187b08f1b9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1928186136-172.17.0.14-1596955957828:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38192,DS-cf8732c8-ff9b-496f-af2d-e7bd851037c5,DISK], DatanodeInfoWithStorage[127.0.0.1:36400,DS-918747df-8728-4fd7-9d9b-0656a28060e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42213,DS-2bebfef1-e79f-467b-b171-69a83046b45c,DISK], DatanodeInfoWithStorage[127.0.0.1:35179,DS-d25c5922-d930-4d98-8114-95823a33e12e,DISK], DatanodeInfoWithStorage[127.0.0.1:41999,DS-a566d968-b36d-40fc-a655-2bd5130cc1ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33740,DS-367e31f1-d4d5-4794-8eb3-c27dd4bbd2f8,DISK], DatanodeInfoWithStorage[127.0.0.1:43811,DS-c1821a8b-b26d-4232-99eb-eddf1da92dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:39382,DS-3f9f9f65-27bc-4faf-abfb-6ff1e521bb42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1928186136-172.17.0.14-1596955957828:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38192,DS-cf8732c8-ff9b-496f-af2d-e7bd851037c5,DISK], DatanodeInfoWithStorage[127.0.0.1:36400,DS-918747df-8728-4fd7-9d9b-0656a28060e6,DISK], DatanodeInfoWithStorage[127.0.0.1:42213,DS-2bebfef1-e79f-467b-b171-69a83046b45c,DISK], DatanodeInfoWithStorage[127.0.0.1:35179,DS-d25c5922-d930-4d98-8114-95823a33e12e,DISK], DatanodeInfoWithStorage[127.0.0.1:41999,DS-a566d968-b36d-40fc-a655-2bd5130cc1ca,DISK], DatanodeInfoWithStorage[127.0.0.1:33740,DS-367e31f1-d4d5-4794-8eb3-c27dd4bbd2f8,DISK], DatanodeInfoWithStorage[127.0.0.1:43811,DS-c1821a8b-b26d-4232-99eb-eddf1da92dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:39382,DS-3f9f9f65-27bc-4faf-abfb-6ff1e521bb42,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1199190535-172.17.0.14-1596956707609:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32974,DS-a256422a-563a-4a35-b88e-c13fb16c5f93,DISK], DatanodeInfoWithStorage[127.0.0.1:39362,DS-25e4c0e5-0424-4453-b3a4-209317cfc01a,DISK], DatanodeInfoWithStorage[127.0.0.1:38962,DS-0c864b32-8f17-478a-9b33-bcb2028388a9,DISK], DatanodeInfoWithStorage[127.0.0.1:40577,DS-60675fb4-a92d-4ee2-9046-a8d787bc9bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:46680,DS-d3b0b13e-b9d1-456d-a728-566121975ef1,DISK], DatanodeInfoWithStorage[127.0.0.1:33052,DS-4fab2272-ddc5-4b9c-a6bf-704c8d1011ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44746,DS-a4b799e6-c993-4706-ac95-e970b287cc3f,DISK], DatanodeInfoWithStorage[127.0.0.1:46744,DS-f42e30aa-c42d-497f-8d31-a49475d0f2c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1199190535-172.17.0.14-1596956707609:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32974,DS-a256422a-563a-4a35-b88e-c13fb16c5f93,DISK], DatanodeInfoWithStorage[127.0.0.1:39362,DS-25e4c0e5-0424-4453-b3a4-209317cfc01a,DISK], DatanodeInfoWithStorage[127.0.0.1:38962,DS-0c864b32-8f17-478a-9b33-bcb2028388a9,DISK], DatanodeInfoWithStorage[127.0.0.1:40577,DS-60675fb4-a92d-4ee2-9046-a8d787bc9bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:46680,DS-d3b0b13e-b9d1-456d-a728-566121975ef1,DISK], DatanodeInfoWithStorage[127.0.0.1:33052,DS-4fab2272-ddc5-4b9c-a6bf-704c8d1011ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44746,DS-a4b799e6-c993-4706-ac95-e970b287cc3f,DISK], DatanodeInfoWithStorage[127.0.0.1:46744,DS-f42e30aa-c42d-497f-8d31-a49475d0f2c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1555181673-172.17.0.14-1596956772130:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39841,DS-c56c24f8-a190-4ed0-8a41-859367ae130d,DISK], DatanodeInfoWithStorage[127.0.0.1:38485,DS-1a8996fb-489c-48ed-a5d7-7f82b7390dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:35155,DS-02a13487-7a8e-4f61-9405-79f49c03694c,DISK], DatanodeInfoWithStorage[127.0.0.1:42796,DS-8f6fb028-a3f0-46e6-a50c-df82191b5905,DISK], DatanodeInfoWithStorage[127.0.0.1:35850,DS-3430d2ef-ef7d-484f-bd53-699002853ebd,DISK], DatanodeInfoWithStorage[127.0.0.1:45776,DS-36ab5b7b-19e5-4fa1-87aa-5c6ee81b9ed2,DISK], DatanodeInfoWithStorage[127.0.0.1:37232,DS-619d5b2a-d424-410b-be8c-4bb6a2998520,DISK], DatanodeInfoWithStorage[127.0.0.1:40513,DS-cc16ccf6-58bb-4159-a4d4-540455a608e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1555181673-172.17.0.14-1596956772130:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39841,DS-c56c24f8-a190-4ed0-8a41-859367ae130d,DISK], DatanodeInfoWithStorage[127.0.0.1:38485,DS-1a8996fb-489c-48ed-a5d7-7f82b7390dc3,DISK], DatanodeInfoWithStorage[127.0.0.1:35155,DS-02a13487-7a8e-4f61-9405-79f49c03694c,DISK], DatanodeInfoWithStorage[127.0.0.1:42796,DS-8f6fb028-a3f0-46e6-a50c-df82191b5905,DISK], DatanodeInfoWithStorage[127.0.0.1:35850,DS-3430d2ef-ef7d-484f-bd53-699002853ebd,DISK], DatanodeInfoWithStorage[127.0.0.1:45776,DS-36ab5b7b-19e5-4fa1-87aa-5c6ee81b9ed2,DISK], DatanodeInfoWithStorage[127.0.0.1:37232,DS-619d5b2a-d424-410b-be8c-4bb6a2998520,DISK], DatanodeInfoWithStorage[127.0.0.1:40513,DS-cc16ccf6-58bb-4159-a4d4-540455a608e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1199116406-172.17.0.14-1596957237788:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37314,DS-4661120e-9a4f-4154-b10f-1cdbc662b1a8,DISK], DatanodeInfoWithStorage[127.0.0.1:33774,DS-a5c4c82d-683b-4c3b-ac3d-22cb92df03bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44034,DS-6ace95db-917e-496c-95b9-bf195a3e0185,DISK], DatanodeInfoWithStorage[127.0.0.1:36376,DS-c0c068a9-cbba-4239-9524-f69f2e150af0,DISK], DatanodeInfoWithStorage[127.0.0.1:35998,DS-79d49316-160b-4005-ad3d-c7bb254f9442,DISK], DatanodeInfoWithStorage[127.0.0.1:33443,DS-254cc85e-cac6-4da0-82f9-08722d24ed74,DISK], DatanodeInfoWithStorage[127.0.0.1:36576,DS-83d78b80-aab3-4a41-813e-ec3232448fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:39894,DS-15affe00-97ce-40ea-a387-bb1fc26a39d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1199116406-172.17.0.14-1596957237788:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37314,DS-4661120e-9a4f-4154-b10f-1cdbc662b1a8,DISK], DatanodeInfoWithStorage[127.0.0.1:33774,DS-a5c4c82d-683b-4c3b-ac3d-22cb92df03bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44034,DS-6ace95db-917e-496c-95b9-bf195a3e0185,DISK], DatanodeInfoWithStorage[127.0.0.1:36376,DS-c0c068a9-cbba-4239-9524-f69f2e150af0,DISK], DatanodeInfoWithStorage[127.0.0.1:35998,DS-79d49316-160b-4005-ad3d-c7bb254f9442,DISK], DatanodeInfoWithStorage[127.0.0.1:33443,DS-254cc85e-cac6-4da0-82f9-08722d24ed74,DISK], DatanodeInfoWithStorage[127.0.0.1:36576,DS-83d78b80-aab3-4a41-813e-ec3232448fe0,DISK], DatanodeInfoWithStorage[127.0.0.1:39894,DS-15affe00-97ce-40ea-a387-bb1fc26a39d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1399950284-172.17.0.14-1596957615810:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45870,DS-a4c7fd97-3b8d-46a3-88bd-a3c48c4162b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42900,DS-f450f0aa-eeee-4f3e-be3f-14e8f7cbb330,DISK], DatanodeInfoWithStorage[127.0.0.1:42117,DS-c3c3a221-9cc8-4337-a003-926adef74044,DISK], DatanodeInfoWithStorage[127.0.0.1:37207,DS-29c7016a-159e-4cab-85f3-bd5219a77954,DISK], DatanodeInfoWithStorage[127.0.0.1:44526,DS-7344b701-6bb1-4e96-af03-ce1869a50886,DISK], DatanodeInfoWithStorage[127.0.0.1:44451,DS-dc06e393-eb16-416c-9d3b-fb5efa5c922d,DISK], DatanodeInfoWithStorage[127.0.0.1:41567,DS-b5177c74-9aa0-4e1e-a78b-cfa410df3f22,DISK], DatanodeInfoWithStorage[127.0.0.1:40649,DS-d42a8bcd-008f-4497-96a1-24c4233d4f67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1399950284-172.17.0.14-1596957615810:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45870,DS-a4c7fd97-3b8d-46a3-88bd-a3c48c4162b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42900,DS-f450f0aa-eeee-4f3e-be3f-14e8f7cbb330,DISK], DatanodeInfoWithStorage[127.0.0.1:42117,DS-c3c3a221-9cc8-4337-a003-926adef74044,DISK], DatanodeInfoWithStorage[127.0.0.1:37207,DS-29c7016a-159e-4cab-85f3-bd5219a77954,DISK], DatanodeInfoWithStorage[127.0.0.1:44526,DS-7344b701-6bb1-4e96-af03-ce1869a50886,DISK], DatanodeInfoWithStorage[127.0.0.1:44451,DS-dc06e393-eb16-416c-9d3b-fb5efa5c922d,DISK], DatanodeInfoWithStorage[127.0.0.1:41567,DS-b5177c74-9aa0-4e1e-a78b-cfa410df3f22,DISK], DatanodeInfoWithStorage[127.0.0.1:40649,DS-d42a8bcd-008f-4497-96a1-24c4233d4f67,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1270004331-172.17.0.14-1596957984120:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46289,DS-24c7aabf-2ec0-478c-9e94-89d3762cd5dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35235,DS-3a95617e-7712-4ab3-93d5-1aba87f4e1bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44129,DS-9ab93b90-47da-4343-8a17-09802eece0a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35559,DS-dc4b1b69-ab63-4655-89ef-32b34687a22c,DISK], DatanodeInfoWithStorage[127.0.0.1:33732,DS-a88a3d2b-22aa-41f1-ac42-7f86c49ce88e,DISK], DatanodeInfoWithStorage[127.0.0.1:43337,DS-d7ed7398-fb8c-4ca8-ade3-2eeafef540f9,DISK], DatanodeInfoWithStorage[127.0.0.1:40148,DS-fcba386c-b86e-48e0-87ed-e24ae6380a34,DISK], DatanodeInfoWithStorage[127.0.0.1:43851,DS-43577212-f4b2-4bcb-a8b8-3e329674bdf9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1270004331-172.17.0.14-1596957984120:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46289,DS-24c7aabf-2ec0-478c-9e94-89d3762cd5dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35235,DS-3a95617e-7712-4ab3-93d5-1aba87f4e1bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44129,DS-9ab93b90-47da-4343-8a17-09802eece0a3,DISK], DatanodeInfoWithStorage[127.0.0.1:35559,DS-dc4b1b69-ab63-4655-89ef-32b34687a22c,DISK], DatanodeInfoWithStorage[127.0.0.1:33732,DS-a88a3d2b-22aa-41f1-ac42-7f86c49ce88e,DISK], DatanodeInfoWithStorage[127.0.0.1:43337,DS-d7ed7398-fb8c-4ca8-ade3-2eeafef540f9,DISK], DatanodeInfoWithStorage[127.0.0.1:40148,DS-fcba386c-b86e-48e0-87ed-e24ae6380a34,DISK], DatanodeInfoWithStorage[127.0.0.1:43851,DS-43577212-f4b2-4bcb-a8b8-3e329674bdf9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.use.datanode.hostname
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-708872397-172.17.0.14-1596958016170:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39175,DS-25880702-0190-4041-98f0-e73af8254be1,DISK], DatanodeInfoWithStorage[127.0.0.1:43836,DS-c9c76e68-e639-4f15-81fc-0bad9456b688,DISK], DatanodeInfoWithStorage[127.0.0.1:40696,DS-f642fabc-ff25-4cdd-ab60-395074288398,DISK], DatanodeInfoWithStorage[127.0.0.1:39052,DS-207aa69c-2972-42f8-8010-55001fe55a6d,DISK], DatanodeInfoWithStorage[127.0.0.1:34413,DS-cddfb998-259f-4159-abed-bd34f58287b1,DISK], DatanodeInfoWithStorage[127.0.0.1:39967,DS-f65af856-27cd-4b2b-9ce1-795a6e9d8fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:32908,DS-97aba2ba-8383-4e39-9a8c-06a7e19c3e9b,DISK], DatanodeInfoWithStorage[127.0.0.1:34070,DS-91a8e0d6-6b30-46bd-bc55-70359b0cd574,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-708872397-172.17.0.14-1596958016170:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39175,DS-25880702-0190-4041-98f0-e73af8254be1,DISK], DatanodeInfoWithStorage[127.0.0.1:43836,DS-c9c76e68-e639-4f15-81fc-0bad9456b688,DISK], DatanodeInfoWithStorage[127.0.0.1:40696,DS-f642fabc-ff25-4cdd-ab60-395074288398,DISK], DatanodeInfoWithStorage[127.0.0.1:39052,DS-207aa69c-2972-42f8-8010-55001fe55a6d,DISK], DatanodeInfoWithStorage[127.0.0.1:34413,DS-cddfb998-259f-4159-abed-bd34f58287b1,DISK], DatanodeInfoWithStorage[127.0.0.1:39967,DS-f65af856-27cd-4b2b-9ce1-795a6e9d8fa2,DISK], DatanodeInfoWithStorage[127.0.0.1:32908,DS-97aba2ba-8383-4e39-9a8c-06a7e19c3e9b,DISK], DatanodeInfoWithStorage[127.0.0.1:34070,DS-91a8e0d6-6b30-46bd-bc55-70359b0cd574,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5127
