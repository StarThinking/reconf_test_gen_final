reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2116926367-172.17.0.5-1596963664770:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36882,DS-b1b39f52-e05f-4ab8-a0c4-00eb1f9c19f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38688,DS-48a24753-3263-4d02-8886-97018fb1b85d,DISK], DatanodeInfoWithStorage[127.0.0.1:35020,DS-9f66662d-bba7-4a64-9832-125ca3f62530,DISK], DatanodeInfoWithStorage[127.0.0.1:39886,DS-bbac394f-3ef4-407c-a781-3acffb1ec66e,DISK], DatanodeInfoWithStorage[127.0.0.1:43305,DS-acdcb928-51a1-4b1b-a562-1b046288c260,DISK], DatanodeInfoWithStorage[127.0.0.1:44931,DS-00d48b83-0896-405b-93b0-5130a8153056,DISK], DatanodeInfoWithStorage[127.0.0.1:38768,DS-cc64e8d5-c118-4e81-aa8e-791309470752,DISK], DatanodeInfoWithStorage[127.0.0.1:37146,DS-13b2e025-5216-4bd3-abf5-29aee84d7249,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2116926367-172.17.0.5-1596963664770:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36882,DS-b1b39f52-e05f-4ab8-a0c4-00eb1f9c19f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38688,DS-48a24753-3263-4d02-8886-97018fb1b85d,DISK], DatanodeInfoWithStorage[127.0.0.1:35020,DS-9f66662d-bba7-4a64-9832-125ca3f62530,DISK], DatanodeInfoWithStorage[127.0.0.1:39886,DS-bbac394f-3ef4-407c-a781-3acffb1ec66e,DISK], DatanodeInfoWithStorage[127.0.0.1:43305,DS-acdcb928-51a1-4b1b-a562-1b046288c260,DISK], DatanodeInfoWithStorage[127.0.0.1:44931,DS-00d48b83-0896-405b-93b0-5130a8153056,DISK], DatanodeInfoWithStorage[127.0.0.1:38768,DS-cc64e8d5-c118-4e81-aa8e-791309470752,DISK], DatanodeInfoWithStorage[127.0.0.1:37146,DS-13b2e025-5216-4bd3-abf5-29aee84d7249,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-865148272-172.17.0.5-1596963946181:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34919,DS-422c97a1-5fef-4f76-aa78-92b29dca39d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46805,DS-231d88fd-6cf2-4e8c-a177-b0f09e8d5574,DISK], DatanodeInfoWithStorage[127.0.0.1:43582,DS-6a14ca0e-15f1-413a-a218-d384c72a5f5e,DISK], DatanodeInfoWithStorage[127.0.0.1:34334,DS-8f7ff7e9-fbf7-4842-be05-35e9129dbb08,DISK], DatanodeInfoWithStorage[127.0.0.1:39546,DS-8b6ba055-b88a-4ad5-af78-fda0072db213,DISK], DatanodeInfoWithStorage[127.0.0.1:33584,DS-c92e24a3-b91f-447d-b640-b7e4bec592bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41670,DS-a00641c1-f4af-416c-a147-003a70816429,DISK], DatanodeInfoWithStorage[127.0.0.1:38603,DS-69faf952-6b3b-4b26-958f-9171c5bc7f81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-865148272-172.17.0.5-1596963946181:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34919,DS-422c97a1-5fef-4f76-aa78-92b29dca39d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46805,DS-231d88fd-6cf2-4e8c-a177-b0f09e8d5574,DISK], DatanodeInfoWithStorage[127.0.0.1:43582,DS-6a14ca0e-15f1-413a-a218-d384c72a5f5e,DISK], DatanodeInfoWithStorage[127.0.0.1:34334,DS-8f7ff7e9-fbf7-4842-be05-35e9129dbb08,DISK], DatanodeInfoWithStorage[127.0.0.1:39546,DS-8b6ba055-b88a-4ad5-af78-fda0072db213,DISK], DatanodeInfoWithStorage[127.0.0.1:33584,DS-c92e24a3-b91f-447d-b640-b7e4bec592bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41670,DS-a00641c1-f4af-416c-a147-003a70816429,DISK], DatanodeInfoWithStorage[127.0.0.1:38603,DS-69faf952-6b3b-4b26-958f-9171c5bc7f81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-728464950-172.17.0.5-1596964058189:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33579,DS-ce65ec10-f275-473c-a799-791de95c85dd,DISK], DatanodeInfoWithStorage[127.0.0.1:46667,DS-d19f1ce3-ca5b-4ecc-91ab-499cb0938670,DISK], DatanodeInfoWithStorage[127.0.0.1:36861,DS-dbf31dea-d4ad-4484-bcb1-50d040d033d5,DISK], DatanodeInfoWithStorage[127.0.0.1:43117,DS-3470857b-672d-46f0-aa23-6cef0ba9fd31,DISK], DatanodeInfoWithStorage[127.0.0.1:46371,DS-49565764-f9b2-4258-916d-a56e86a61557,DISK], DatanodeInfoWithStorage[127.0.0.1:37742,DS-833a7b4a-b1f2-4f6f-b793-76d030b9f314,DISK], DatanodeInfoWithStorage[127.0.0.1:35587,DS-8d8bfeed-2342-4264-b27a-2a8b055366a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40169,DS-837dcd54-8a3a-466f-9859-505497764ea0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-728464950-172.17.0.5-1596964058189:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33579,DS-ce65ec10-f275-473c-a799-791de95c85dd,DISK], DatanodeInfoWithStorage[127.0.0.1:46667,DS-d19f1ce3-ca5b-4ecc-91ab-499cb0938670,DISK], DatanodeInfoWithStorage[127.0.0.1:36861,DS-dbf31dea-d4ad-4484-bcb1-50d040d033d5,DISK], DatanodeInfoWithStorage[127.0.0.1:43117,DS-3470857b-672d-46f0-aa23-6cef0ba9fd31,DISK], DatanodeInfoWithStorage[127.0.0.1:46371,DS-49565764-f9b2-4258-916d-a56e86a61557,DISK], DatanodeInfoWithStorage[127.0.0.1:37742,DS-833a7b4a-b1f2-4f6f-b793-76d030b9f314,DISK], DatanodeInfoWithStorage[127.0.0.1:35587,DS-8d8bfeed-2342-4264-b27a-2a8b055366a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40169,DS-837dcd54-8a3a-466f-9859-505497764ea0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1739417635-172.17.0.5-1596964398307:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37094,DS-2b117a49-bc09-4eb3-8823-25545e9b1272,DISK], DatanodeInfoWithStorage[127.0.0.1:37896,DS-2da3c2ec-b1e3-4a66-ae99-13aba908d6e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40801,DS-d8ea4c61-13cc-439f-b239-a73fec007a30,DISK], DatanodeInfoWithStorage[127.0.0.1:39078,DS-0c0af9d2-4ee1-4e75-b3ce-3cd5177579c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38659,DS-eefa97ee-0d69-44c7-b433-e19693674909,DISK], DatanodeInfoWithStorage[127.0.0.1:37403,DS-ebf2f63a-1533-4c79-8e47-0c580566fea8,DISK], DatanodeInfoWithStorage[127.0.0.1:46880,DS-7cb49d49-3948-4f57-aa88-fde54e5bab7e,DISK], DatanodeInfoWithStorage[127.0.0.1:38816,DS-59fddc81-5452-47f1-aa88-e9bb8a879086,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1739417635-172.17.0.5-1596964398307:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37094,DS-2b117a49-bc09-4eb3-8823-25545e9b1272,DISK], DatanodeInfoWithStorage[127.0.0.1:37896,DS-2da3c2ec-b1e3-4a66-ae99-13aba908d6e3,DISK], DatanodeInfoWithStorage[127.0.0.1:40801,DS-d8ea4c61-13cc-439f-b239-a73fec007a30,DISK], DatanodeInfoWithStorage[127.0.0.1:39078,DS-0c0af9d2-4ee1-4e75-b3ce-3cd5177579c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38659,DS-eefa97ee-0d69-44c7-b433-e19693674909,DISK], DatanodeInfoWithStorage[127.0.0.1:37403,DS-ebf2f63a-1533-4c79-8e47-0c580566fea8,DISK], DatanodeInfoWithStorage[127.0.0.1:46880,DS-7cb49d49-3948-4f57-aa88-fde54e5bab7e,DISK], DatanodeInfoWithStorage[127.0.0.1:38816,DS-59fddc81-5452-47f1-aa88-e9bb8a879086,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-750242936-172.17.0.5-1596965311534:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36825,DS-e4b324c6-d9cb-40c8-ab71-809463726686,DISK], DatanodeInfoWithStorage[127.0.0.1:42065,DS-685c6be4-17c8-429c-ac35-3aec693a1157,DISK], DatanodeInfoWithStorage[127.0.0.1:36237,DS-ca102213-baee-4002-ae0d-4a1be1396709,DISK], DatanodeInfoWithStorage[127.0.0.1:34079,DS-cc0e18e1-7a32-492d-9a58-d080fedf71a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44545,DS-6ece3568-0116-4998-9a8b-38e266cb6591,DISK], DatanodeInfoWithStorage[127.0.0.1:37069,DS-0c154988-dd2b-452f-80c8-3cc2d591f329,DISK], DatanodeInfoWithStorage[127.0.0.1:44724,DS-f726fd6d-3c93-4203-a9c7-4e47671312ce,DISK], DatanodeInfoWithStorage[127.0.0.1:39139,DS-8bf83a5e-4cbb-4854-8b4d-16eb1a1c3743,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-750242936-172.17.0.5-1596965311534:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36825,DS-e4b324c6-d9cb-40c8-ab71-809463726686,DISK], DatanodeInfoWithStorage[127.0.0.1:42065,DS-685c6be4-17c8-429c-ac35-3aec693a1157,DISK], DatanodeInfoWithStorage[127.0.0.1:36237,DS-ca102213-baee-4002-ae0d-4a1be1396709,DISK], DatanodeInfoWithStorage[127.0.0.1:34079,DS-cc0e18e1-7a32-492d-9a58-d080fedf71a4,DISK], DatanodeInfoWithStorage[127.0.0.1:44545,DS-6ece3568-0116-4998-9a8b-38e266cb6591,DISK], DatanodeInfoWithStorage[127.0.0.1:37069,DS-0c154988-dd2b-452f-80c8-3cc2d591f329,DISK], DatanodeInfoWithStorage[127.0.0.1:44724,DS-f726fd6d-3c93-4203-a9c7-4e47671312ce,DISK], DatanodeInfoWithStorage[127.0.0.1:39139,DS-8bf83a5e-4cbb-4854-8b4d-16eb1a1c3743,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1155221496-172.17.0.5-1596965830954:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42715,DS-9a07729b-a716-4779-8cb3-f3ec8ffe7ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:35010,DS-172a0e32-7af9-4652-abdc-e9e160609b3d,DISK], DatanodeInfoWithStorage[127.0.0.1:42748,DS-e025ef30-fda2-442f-8331-acb9bf24e449,DISK], DatanodeInfoWithStorage[127.0.0.1:35411,DS-85a25b00-ce2f-4372-b168-b756bba36b23,DISK], DatanodeInfoWithStorage[127.0.0.1:33811,DS-8abf4b86-9d39-4d19-85f7-0d7e500a1713,DISK], DatanodeInfoWithStorage[127.0.0.1:33906,DS-3549c976-0598-4c17-8a43-c5bb453b28a5,DISK], DatanodeInfoWithStorage[127.0.0.1:36062,DS-e844e03a-fe96-4796-ab8d-0f9a9e2903ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39666,DS-eff0aa5f-8625-40de-b57e-b0a9fa9cb42a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1155221496-172.17.0.5-1596965830954:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42715,DS-9a07729b-a716-4779-8cb3-f3ec8ffe7ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:35010,DS-172a0e32-7af9-4652-abdc-e9e160609b3d,DISK], DatanodeInfoWithStorage[127.0.0.1:42748,DS-e025ef30-fda2-442f-8331-acb9bf24e449,DISK], DatanodeInfoWithStorage[127.0.0.1:35411,DS-85a25b00-ce2f-4372-b168-b756bba36b23,DISK], DatanodeInfoWithStorage[127.0.0.1:33811,DS-8abf4b86-9d39-4d19-85f7-0d7e500a1713,DISK], DatanodeInfoWithStorage[127.0.0.1:33906,DS-3549c976-0598-4c17-8a43-c5bb453b28a5,DISK], DatanodeInfoWithStorage[127.0.0.1:36062,DS-e844e03a-fe96-4796-ab8d-0f9a9e2903ae,DISK], DatanodeInfoWithStorage[127.0.0.1:39666,DS-eff0aa5f-8625-40de-b57e-b0a9fa9cb42a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1386116189-172.17.0.5-1596966130871:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41737,DS-a60a9d84-1d49-4ca1-a264-9e2ab9232fd4,DISK], DatanodeInfoWithStorage[127.0.0.1:43032,DS-467ffbfc-fdf2-4491-803b-c96d7ebeb669,DISK], DatanodeInfoWithStorage[127.0.0.1:40827,DS-6d018327-f9ff-4b8b-91ba-761736050ea9,DISK], DatanodeInfoWithStorage[127.0.0.1:41445,DS-38202220-a5de-45b8-b09b-5dc8c6ef9e32,DISK], DatanodeInfoWithStorage[127.0.0.1:36978,DS-66eb57b3-e0fa-4204-8d4f-d67c612f7bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:41663,DS-5245ec7f-5bc8-42a2-936f-bd5b95b50a24,DISK], DatanodeInfoWithStorage[127.0.0.1:35403,DS-4d89b72c-578d-4f74-b791-26e5cf377906,DISK], DatanodeInfoWithStorage[127.0.0.1:38295,DS-7d22380b-b385-4eb3-9870-4ec7535f6b4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1386116189-172.17.0.5-1596966130871:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41737,DS-a60a9d84-1d49-4ca1-a264-9e2ab9232fd4,DISK], DatanodeInfoWithStorage[127.0.0.1:43032,DS-467ffbfc-fdf2-4491-803b-c96d7ebeb669,DISK], DatanodeInfoWithStorage[127.0.0.1:40827,DS-6d018327-f9ff-4b8b-91ba-761736050ea9,DISK], DatanodeInfoWithStorage[127.0.0.1:41445,DS-38202220-a5de-45b8-b09b-5dc8c6ef9e32,DISK], DatanodeInfoWithStorage[127.0.0.1:36978,DS-66eb57b3-e0fa-4204-8d4f-d67c612f7bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:41663,DS-5245ec7f-5bc8-42a2-936f-bd5b95b50a24,DISK], DatanodeInfoWithStorage[127.0.0.1:35403,DS-4d89b72c-578d-4f74-b791-26e5cf377906,DISK], DatanodeInfoWithStorage[127.0.0.1:38295,DS-7d22380b-b385-4eb3-9870-4ec7535f6b4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1269690958-172.17.0.5-1596967238319:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36070,DS-b1a57210-61f1-4567-8b18-3e7ce9172f43,DISK], DatanodeInfoWithStorage[127.0.0.1:40722,DS-bd5e46fb-366d-4911-a64a-73a47597494c,DISK], DatanodeInfoWithStorage[127.0.0.1:41589,DS-d32487fe-2e6d-43ea-bdfc-4e38448b9365,DISK], DatanodeInfoWithStorage[127.0.0.1:45047,DS-2aef965e-88c6-4929-9bb9-086a1919d373,DISK], DatanodeInfoWithStorage[127.0.0.1:45060,DS-0bb5ec85-39b2-4f9f-9e26-e26f2f5bb1b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40904,DS-b6067e7d-6fbe-46e1-b3a4-6fc715535682,DISK], DatanodeInfoWithStorage[127.0.0.1:45380,DS-aa3ad9d5-fbcb-4e71-9746-3f3271a42723,DISK], DatanodeInfoWithStorage[127.0.0.1:37607,DS-66a7a006-ee71-4f7a-9952-0fbec61a0680,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1269690958-172.17.0.5-1596967238319:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36070,DS-b1a57210-61f1-4567-8b18-3e7ce9172f43,DISK], DatanodeInfoWithStorage[127.0.0.1:40722,DS-bd5e46fb-366d-4911-a64a-73a47597494c,DISK], DatanodeInfoWithStorage[127.0.0.1:41589,DS-d32487fe-2e6d-43ea-bdfc-4e38448b9365,DISK], DatanodeInfoWithStorage[127.0.0.1:45047,DS-2aef965e-88c6-4929-9bb9-086a1919d373,DISK], DatanodeInfoWithStorage[127.0.0.1:45060,DS-0bb5ec85-39b2-4f9f-9e26-e26f2f5bb1b3,DISK], DatanodeInfoWithStorage[127.0.0.1:40904,DS-b6067e7d-6fbe-46e1-b3a4-6fc715535682,DISK], DatanodeInfoWithStorage[127.0.0.1:45380,DS-aa3ad9d5-fbcb-4e71-9746-3f3271a42723,DISK], DatanodeInfoWithStorage[127.0.0.1:37607,DS-66a7a006-ee71-4f7a-9952-0fbec61a0680,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1643674467-172.17.0.5-1596967391508:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44051,DS-86e39486-f20d-4ea2-99e8-dd4a4ee2f1fe,DISK], DatanodeInfoWithStorage[127.0.0.1:40345,DS-50bb177a-3e36-4647-817d-0199f857981f,DISK], DatanodeInfoWithStorage[127.0.0.1:37216,DS-ec92071b-d7ed-46fd-8794-d87b7a668f15,DISK], DatanodeInfoWithStorage[127.0.0.1:43117,DS-ed4bac73-ed2f-4b0e-960e-f6c643bbad4d,DISK], DatanodeInfoWithStorage[127.0.0.1:38326,DS-2311cff3-7caf-47ba-a4cc-0b20ed8bddd3,DISK], DatanodeInfoWithStorage[127.0.0.1:40116,DS-f39a718f-9939-4029-9dad-a03b16ab9ce3,DISK], DatanodeInfoWithStorage[127.0.0.1:45525,DS-9e1ee5db-7fa2-4531-b58b-a5d57fe95bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:43723,DS-ca3319c6-5860-4d27-a9d9-00975b835fd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1643674467-172.17.0.5-1596967391508:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44051,DS-86e39486-f20d-4ea2-99e8-dd4a4ee2f1fe,DISK], DatanodeInfoWithStorage[127.0.0.1:40345,DS-50bb177a-3e36-4647-817d-0199f857981f,DISK], DatanodeInfoWithStorage[127.0.0.1:37216,DS-ec92071b-d7ed-46fd-8794-d87b7a668f15,DISK], DatanodeInfoWithStorage[127.0.0.1:43117,DS-ed4bac73-ed2f-4b0e-960e-f6c643bbad4d,DISK], DatanodeInfoWithStorage[127.0.0.1:38326,DS-2311cff3-7caf-47ba-a4cc-0b20ed8bddd3,DISK], DatanodeInfoWithStorage[127.0.0.1:40116,DS-f39a718f-9939-4029-9dad-a03b16ab9ce3,DISK], DatanodeInfoWithStorage[127.0.0.1:45525,DS-9e1ee5db-7fa2-4531-b58b-a5d57fe95bd7,DISK], DatanodeInfoWithStorage[127.0.0.1:43723,DS-ca3319c6-5860-4d27-a9d9-00975b835fd3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2002648718-172.17.0.5-1596967573804:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42422,DS-20cf3b2e-9dd3-4432-b69e-e897cca7aefb,DISK], DatanodeInfoWithStorage[127.0.0.1:41499,DS-60808bc4-7438-4ea1-b430-fe0d742384e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34224,DS-4bfd8d32-1295-4b00-aeff-0f4da4387c88,DISK], DatanodeInfoWithStorage[127.0.0.1:39211,DS-3be11d8c-d1a7-49a6-b9d8-7cb577f6a6e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39916,DS-7bdebdc4-2b40-43bf-889e-7a77ec6e95bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35918,DS-4c3c9e10-7ee6-46da-8a7b-1d05aca887ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45225,DS-c4391eb0-7412-4495-bcd0-f126e361e066,DISK], DatanodeInfoWithStorage[127.0.0.1:42785,DS-3772cf4f-9502-4d2e-99fc-425168584a03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2002648718-172.17.0.5-1596967573804:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42422,DS-20cf3b2e-9dd3-4432-b69e-e897cca7aefb,DISK], DatanodeInfoWithStorage[127.0.0.1:41499,DS-60808bc4-7438-4ea1-b430-fe0d742384e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34224,DS-4bfd8d32-1295-4b00-aeff-0f4da4387c88,DISK], DatanodeInfoWithStorage[127.0.0.1:39211,DS-3be11d8c-d1a7-49a6-b9d8-7cb577f6a6e2,DISK], DatanodeInfoWithStorage[127.0.0.1:39916,DS-7bdebdc4-2b40-43bf-889e-7a77ec6e95bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35918,DS-4c3c9e10-7ee6-46da-8a7b-1d05aca887ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45225,DS-c4391eb0-7412-4495-bcd0-f126e361e066,DISK], DatanodeInfoWithStorage[127.0.0.1:42785,DS-3772cf4f-9502-4d2e-99fc-425168584a03,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-48821316-172.17.0.5-1596967961001:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45088,DS-89b393bc-595d-404b-b44d-62da125a8333,DISK], DatanodeInfoWithStorage[127.0.0.1:46371,DS-7ac9aa4e-a908-44f5-b573-43741d1c07e7,DISK], DatanodeInfoWithStorage[127.0.0.1:46651,DS-97de9149-4a29-44bd-b406-34a6c49e68a9,DISK], DatanodeInfoWithStorage[127.0.0.1:40034,DS-16774dae-eaa7-4fa7-aab5-362041fe8a8b,DISK], DatanodeInfoWithStorage[127.0.0.1:44270,DS-aab00c29-9921-4a05-a7c9-d060559362b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41580,DS-6635efaa-49cb-4687-9bda-2b46d54c37b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34163,DS-03dfea1b-2dfe-48c0-ae49-7dc0c18abba7,DISK], DatanodeInfoWithStorage[127.0.0.1:35022,DS-f5babb9c-dc52-4c78-8217-08cbc7d723fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-48821316-172.17.0.5-1596967961001:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45088,DS-89b393bc-595d-404b-b44d-62da125a8333,DISK], DatanodeInfoWithStorage[127.0.0.1:46371,DS-7ac9aa4e-a908-44f5-b573-43741d1c07e7,DISK], DatanodeInfoWithStorage[127.0.0.1:46651,DS-97de9149-4a29-44bd-b406-34a6c49e68a9,DISK], DatanodeInfoWithStorage[127.0.0.1:40034,DS-16774dae-eaa7-4fa7-aab5-362041fe8a8b,DISK], DatanodeInfoWithStorage[127.0.0.1:44270,DS-aab00c29-9921-4a05-a7c9-d060559362b4,DISK], DatanodeInfoWithStorage[127.0.0.1:41580,DS-6635efaa-49cb-4687-9bda-2b46d54c37b9,DISK], DatanodeInfoWithStorage[127.0.0.1:34163,DS-03dfea1b-2dfe-48c0-ae49-7dc0c18abba7,DISK], DatanodeInfoWithStorage[127.0.0.1:35022,DS-f5babb9c-dc52-4c78-8217-08cbc7d723fa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.permissions.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1152372219-172.17.0.5-1596969058085:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39930,DS-70eea563-4f6c-4aef-b99f-44c8db4f253b,DISK], DatanodeInfoWithStorage[127.0.0.1:46652,DS-7a57110d-0b9d-42bb-b525-e16277f54f93,DISK], DatanodeInfoWithStorage[127.0.0.1:41630,DS-a5ad9106-c6e2-4e03-870b-08179ddd93a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40860,DS-d1d968f2-cc14-4951-803c-cbba1286aeb6,DISK], DatanodeInfoWithStorage[127.0.0.1:38604,DS-76859903-5405-475f-a58a-ba11f5cf17b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43625,DS-4f35f3d1-7012-4374-889f-68dd75d72f27,DISK], DatanodeInfoWithStorage[127.0.0.1:42944,DS-9d56572a-0b92-4c12-ab2e-99a9820605de,DISK], DatanodeInfoWithStorage[127.0.0.1:38095,DS-9f0a5aa3-d99b-47e2-82f5-2857762e798e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1152372219-172.17.0.5-1596969058085:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39930,DS-70eea563-4f6c-4aef-b99f-44c8db4f253b,DISK], DatanodeInfoWithStorage[127.0.0.1:46652,DS-7a57110d-0b9d-42bb-b525-e16277f54f93,DISK], DatanodeInfoWithStorage[127.0.0.1:41630,DS-a5ad9106-c6e2-4e03-870b-08179ddd93a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40860,DS-d1d968f2-cc14-4951-803c-cbba1286aeb6,DISK], DatanodeInfoWithStorage[127.0.0.1:38604,DS-76859903-5405-475f-a58a-ba11f5cf17b6,DISK], DatanodeInfoWithStorage[127.0.0.1:43625,DS-4f35f3d1-7012-4374-889f-68dd75d72f27,DISK], DatanodeInfoWithStorage[127.0.0.1:42944,DS-9d56572a-0b92-4c12-ab2e-99a9820605de,DISK], DatanodeInfoWithStorage[127.0.0.1:38095,DS-9f0a5aa3-d99b-47e2-82f5-2857762e798e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: false positive !!!
Total execution time in seconds : 6322
