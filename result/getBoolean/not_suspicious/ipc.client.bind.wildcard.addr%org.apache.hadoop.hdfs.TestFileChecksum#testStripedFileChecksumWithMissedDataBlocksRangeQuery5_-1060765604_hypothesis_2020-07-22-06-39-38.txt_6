reconf_parameter: ipc.client.bind.wildcard.addr
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.bind.wildcard.addr
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1023025415-172.17.0.2-1595400123083:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33345,DS-2edf7d15-4cb8-48f1-93ac-45d9b48cb1c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46689,DS-81eb4590-f020-4699-8960-0ae170479204,DISK], DatanodeInfoWithStorage[127.0.0.1:33789,DS-3c2f7c61-ebe3-4a49-a94e-7985d12a6a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:43958,DS-15123e9d-7f78-4936-ab8f-7a258ec58d76,DISK], DatanodeInfoWithStorage[127.0.0.1:39465,DS-ef1e7614-20e6-4b7a-bfba-41daf19a067c,DISK], DatanodeInfoWithStorage[127.0.0.1:33828,DS-1e8a1f7c-ec94-4cad-8b38-89b2aefd2ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:32886,DS-a1f550f2-3e8c-4334-8f2d-d1f82b706097,DISK], DatanodeInfoWithStorage[127.0.0.1:43306,DS-9639be7c-a293-42d0-a0db-ce3eb11a3807,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1023025415-172.17.0.2-1595400123083:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33345,DS-2edf7d15-4cb8-48f1-93ac-45d9b48cb1c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46689,DS-81eb4590-f020-4699-8960-0ae170479204,DISK], DatanodeInfoWithStorage[127.0.0.1:33789,DS-3c2f7c61-ebe3-4a49-a94e-7985d12a6a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:43958,DS-15123e9d-7f78-4936-ab8f-7a258ec58d76,DISK], DatanodeInfoWithStorage[127.0.0.1:39465,DS-ef1e7614-20e6-4b7a-bfba-41daf19a067c,DISK], DatanodeInfoWithStorage[127.0.0.1:33828,DS-1e8a1f7c-ec94-4cad-8b38-89b2aefd2ff8,DISK], DatanodeInfoWithStorage[127.0.0.1:32886,DS-a1f550f2-3e8c-4334-8f2d-d1f82b706097,DISK], DatanodeInfoWithStorage[127.0.0.1:43306,DS-9639be7c-a293-42d0-a0db-ce3eb11a3807,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.bind.wildcard.addr
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1512028145-172.17.0.2-1595400819017:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42313,DS-23cbc8d9-c94c-4d0f-95d8-c97c42a71b00,DISK], DatanodeInfoWithStorage[127.0.0.1:34288,DS-b349e1b1-1f64-4f0d-8998-766b7670f96f,DISK], DatanodeInfoWithStorage[127.0.0.1:33574,DS-a0783bcc-9439-4fc8-b5cf-d5b21dd7965e,DISK], DatanodeInfoWithStorage[127.0.0.1:45698,DS-fdbe656b-89f5-4c36-821e-c06afb6fbd72,DISK], DatanodeInfoWithStorage[127.0.0.1:40292,DS-42316ddf-b931-4578-b6ec-7bed4e3dd875,DISK], DatanodeInfoWithStorage[127.0.0.1:42558,DS-ca1979e9-81a1-4c4d-8b8f-7b92b1706011,DISK], DatanodeInfoWithStorage[127.0.0.1:34544,DS-fd3cf177-7471-4adb-9e75-c463e2bb75f4,DISK], DatanodeInfoWithStorage[127.0.0.1:35989,DS-13539acc-3bfb-4d44-ba33-87bd35284e37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1512028145-172.17.0.2-1595400819017:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42313,DS-23cbc8d9-c94c-4d0f-95d8-c97c42a71b00,DISK], DatanodeInfoWithStorage[127.0.0.1:34288,DS-b349e1b1-1f64-4f0d-8998-766b7670f96f,DISK], DatanodeInfoWithStorage[127.0.0.1:33574,DS-a0783bcc-9439-4fc8-b5cf-d5b21dd7965e,DISK], DatanodeInfoWithStorage[127.0.0.1:45698,DS-fdbe656b-89f5-4c36-821e-c06afb6fbd72,DISK], DatanodeInfoWithStorage[127.0.0.1:40292,DS-42316ddf-b931-4578-b6ec-7bed4e3dd875,DISK], DatanodeInfoWithStorage[127.0.0.1:42558,DS-ca1979e9-81a1-4c4d-8b8f-7b92b1706011,DISK], DatanodeInfoWithStorage[127.0.0.1:34544,DS-fd3cf177-7471-4adb-9e75-c463e2bb75f4,DISK], DatanodeInfoWithStorage[127.0.0.1:35989,DS-13539acc-3bfb-4d44-ba33-87bd35284e37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.bind.wildcard.addr
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-549244191-172.17.0.2-1595400991327:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37520,DS-884749ac-d610-4534-83e7-30b7c96077a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41598,DS-c299d723-43d5-44ef-88c0-9689d7f3dcda,DISK], DatanodeInfoWithStorage[127.0.0.1:40395,DS-321eb477-91d3-4e37-9dc1-7b8c51227830,DISK], DatanodeInfoWithStorage[127.0.0.1:35815,DS-9ce63fc4-a68b-429b-a683-688f11a461ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37432,DS-3940c9f0-fcd0-4fb5-8d1b-cd920ff903f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40814,DS-9ef00b2a-bc95-46f9-aa09-7bbffab7dbe1,DISK], DatanodeInfoWithStorage[127.0.0.1:45854,DS-9ad76232-dffb-4431-afa8-13e96aad6249,DISK], DatanodeInfoWithStorage[127.0.0.1:42740,DS-dbf74005-35a3-42c2-9f02-2c789611af8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-549244191-172.17.0.2-1595400991327:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37520,DS-884749ac-d610-4534-83e7-30b7c96077a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41598,DS-c299d723-43d5-44ef-88c0-9689d7f3dcda,DISK], DatanodeInfoWithStorage[127.0.0.1:40395,DS-321eb477-91d3-4e37-9dc1-7b8c51227830,DISK], DatanodeInfoWithStorage[127.0.0.1:35815,DS-9ce63fc4-a68b-429b-a683-688f11a461ea,DISK], DatanodeInfoWithStorage[127.0.0.1:37432,DS-3940c9f0-fcd0-4fb5-8d1b-cd920ff903f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40814,DS-9ef00b2a-bc95-46f9-aa09-7bbffab7dbe1,DISK], DatanodeInfoWithStorage[127.0.0.1:45854,DS-9ad76232-dffb-4431-afa8-13e96aad6249,DISK], DatanodeInfoWithStorage[127.0.0.1:42740,DS-dbf74005-35a3-42c2-9f02-2c789611af8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.bind.wildcard.addr
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1855882700-172.17.0.2-1595401208504:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45838,DS-691b0019-e76f-47da-802b-5372900c4b80,DISK], DatanodeInfoWithStorage[127.0.0.1:36546,DS-4e10954a-4df1-4102-88fa-7a4025125aa6,DISK], DatanodeInfoWithStorage[127.0.0.1:33836,DS-d86e8539-5dff-4c1b-950e-fb24f7d01976,DISK], DatanodeInfoWithStorage[127.0.0.1:39544,DS-7f2dd740-abf8-4fd1-a706-294dae6ab398,DISK], DatanodeInfoWithStorage[127.0.0.1:37361,DS-b77b4451-d20a-477e-b964-ce84dc416990,DISK], DatanodeInfoWithStorage[127.0.0.1:37842,DS-8561c2aa-2e2b-484e-be23-17136e2acee0,DISK], DatanodeInfoWithStorage[127.0.0.1:45294,DS-73b7b3a2-21f3-410c-ab63-75b24777f93b,DISK], DatanodeInfoWithStorage[127.0.0.1:40835,DS-7d4f8f16-ba49-4fd5-9482-9ed26f8b786d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1855882700-172.17.0.2-1595401208504:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45838,DS-691b0019-e76f-47da-802b-5372900c4b80,DISK], DatanodeInfoWithStorage[127.0.0.1:36546,DS-4e10954a-4df1-4102-88fa-7a4025125aa6,DISK], DatanodeInfoWithStorage[127.0.0.1:33836,DS-d86e8539-5dff-4c1b-950e-fb24f7d01976,DISK], DatanodeInfoWithStorage[127.0.0.1:39544,DS-7f2dd740-abf8-4fd1-a706-294dae6ab398,DISK], DatanodeInfoWithStorage[127.0.0.1:37361,DS-b77b4451-d20a-477e-b964-ce84dc416990,DISK], DatanodeInfoWithStorage[127.0.0.1:37842,DS-8561c2aa-2e2b-484e-be23-17136e2acee0,DISK], DatanodeInfoWithStorage[127.0.0.1:45294,DS-73b7b3a2-21f3-410c-ab63-75b24777f93b,DISK], DatanodeInfoWithStorage[127.0.0.1:40835,DS-7d4f8f16-ba49-4fd5-9482-9ed26f8b786d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.bind.wildcard.addr
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-941298967-172.17.0.2-1595401310639:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33884,DS-d942cc98-75fb-44d4-8034-938a7441a66c,DISK], DatanodeInfoWithStorage[127.0.0.1:39089,DS-4826ffd2-981f-4dc5-8487-76c00411da9f,DISK], DatanodeInfoWithStorage[127.0.0.1:46774,DS-e89f183c-c8bf-4bb8-b9df-16665c6acf79,DISK], DatanodeInfoWithStorage[127.0.0.1:40899,DS-666d1730-be18-43ab-b51b-337ac3f2777a,DISK], DatanodeInfoWithStorage[127.0.0.1:36464,DS-b15c0e52-8fe5-4504-b6c7-c69b4895067a,DISK], DatanodeInfoWithStorage[127.0.0.1:46337,DS-c3e85f0e-1da6-4c03-90d6-bc8e7ede87b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33607,DS-621ec3ac-7598-403e-b712-c708aeb64181,DISK], DatanodeInfoWithStorage[127.0.0.1:42745,DS-a46088bd-c6e9-4498-b934-4570794d203b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-941298967-172.17.0.2-1595401310639:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33884,DS-d942cc98-75fb-44d4-8034-938a7441a66c,DISK], DatanodeInfoWithStorage[127.0.0.1:39089,DS-4826ffd2-981f-4dc5-8487-76c00411da9f,DISK], DatanodeInfoWithStorage[127.0.0.1:46774,DS-e89f183c-c8bf-4bb8-b9df-16665c6acf79,DISK], DatanodeInfoWithStorage[127.0.0.1:40899,DS-666d1730-be18-43ab-b51b-337ac3f2777a,DISK], DatanodeInfoWithStorage[127.0.0.1:36464,DS-b15c0e52-8fe5-4504-b6c7-c69b4895067a,DISK], DatanodeInfoWithStorage[127.0.0.1:46337,DS-c3e85f0e-1da6-4c03-90d6-bc8e7ede87b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33607,DS-621ec3ac-7598-403e-b712-c708aeb64181,DISK], DatanodeInfoWithStorage[127.0.0.1:42745,DS-a46088bd-c6e9-4498-b934-4570794d203b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.bind.wildcard.addr
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1206586443-172.17.0.2-1595401594772:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41809,DS-3467392d-b21a-42e4-9ccc-198f72928f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:37120,DS-9ea5dc0e-f0c9-4ab9-9e89-9e92c91fa360,DISK], DatanodeInfoWithStorage[127.0.0.1:37027,DS-7dff7ef8-f2df-40db-8179-0cd911575864,DISK], DatanodeInfoWithStorage[127.0.0.1:36444,DS-b2a94689-f440-4d36-a4dc-4687b3c47e07,DISK], DatanodeInfoWithStorage[127.0.0.1:40278,DS-1abd5ca3-f3c8-4b07-a45b-911d8ffb0e9e,DISK], DatanodeInfoWithStorage[127.0.0.1:41476,DS-cff8c799-f52e-4358-8301-6c41e93fa1b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44968,DS-eafd2708-8d3d-4e41-ae57-d8c31bb9cf8e,DISK], DatanodeInfoWithStorage[127.0.0.1:38488,DS-94f429fc-d41f-4be2-b7df-7e95b6852e2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1206586443-172.17.0.2-1595401594772:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41809,DS-3467392d-b21a-42e4-9ccc-198f72928f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:37120,DS-9ea5dc0e-f0c9-4ab9-9e89-9e92c91fa360,DISK], DatanodeInfoWithStorage[127.0.0.1:37027,DS-7dff7ef8-f2df-40db-8179-0cd911575864,DISK], DatanodeInfoWithStorage[127.0.0.1:36444,DS-b2a94689-f440-4d36-a4dc-4687b3c47e07,DISK], DatanodeInfoWithStorage[127.0.0.1:40278,DS-1abd5ca3-f3c8-4b07-a45b-911d8ffb0e9e,DISK], DatanodeInfoWithStorage[127.0.0.1:41476,DS-cff8c799-f52e-4358-8301-6c41e93fa1b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44968,DS-eafd2708-8d3d-4e41-ae57-d8c31bb9cf8e,DISK], DatanodeInfoWithStorage[127.0.0.1:38488,DS-94f429fc-d41f-4be2-b7df-7e95b6852e2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.bind.wildcard.addr
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-667688136-172.17.0.2-1595402085227:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39904,DS-8735c92f-981a-433e-be61-d5b9ea7c8080,DISK], DatanodeInfoWithStorage[127.0.0.1:36227,DS-6d268474-3582-43d3-85d6-fa069346d53e,DISK], DatanodeInfoWithStorage[127.0.0.1:46083,DS-3e949b67-fec1-4e41-9a2c-c08e10370f0f,DISK], DatanodeInfoWithStorage[127.0.0.1:39456,DS-1b7279b1-3042-45ab-b378-983207cb735a,DISK], DatanodeInfoWithStorage[127.0.0.1:38078,DS-431f41fb-e2d8-4ad6-a476-b47314cd7703,DISK], DatanodeInfoWithStorage[127.0.0.1:45891,DS-2ced96c8-c912-493f-80ec-d521f74ef338,DISK], DatanodeInfoWithStorage[127.0.0.1:35040,DS-d92d7784-bc29-4103-81fb-5237ee619f3e,DISK], DatanodeInfoWithStorage[127.0.0.1:37070,DS-94ae4d30-d1ba-43b0-a8e3-cffd0b5bb3f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-667688136-172.17.0.2-1595402085227:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39904,DS-8735c92f-981a-433e-be61-d5b9ea7c8080,DISK], DatanodeInfoWithStorage[127.0.0.1:36227,DS-6d268474-3582-43d3-85d6-fa069346d53e,DISK], DatanodeInfoWithStorage[127.0.0.1:46083,DS-3e949b67-fec1-4e41-9a2c-c08e10370f0f,DISK], DatanodeInfoWithStorage[127.0.0.1:39456,DS-1b7279b1-3042-45ab-b378-983207cb735a,DISK], DatanodeInfoWithStorage[127.0.0.1:38078,DS-431f41fb-e2d8-4ad6-a476-b47314cd7703,DISK], DatanodeInfoWithStorage[127.0.0.1:45891,DS-2ced96c8-c912-493f-80ec-d521f74ef338,DISK], DatanodeInfoWithStorage[127.0.0.1:35040,DS-d92d7784-bc29-4103-81fb-5237ee619f3e,DISK], DatanodeInfoWithStorage[127.0.0.1:37070,DS-94ae4d30-d1ba-43b0-a8e3-cffd0b5bb3f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.bind.wildcard.addr
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1634635329-172.17.0.2-1595402356575:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37370,DS-dbdf9f42-f057-4dad-b4e4-49ea51b2d4e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44975,DS-1d098f09-1543-4af8-bf89-b921771f9ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:41455,DS-baba1c3a-6d26-451b-bb51-339dba5ce0aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33330,DS-a5a9b142-7825-4f41-b803-d190aa35261a,DISK], DatanodeInfoWithStorage[127.0.0.1:40046,DS-1ca399cc-4e26-494f-aafc-d7705a634e91,DISK], DatanodeInfoWithStorage[127.0.0.1:35279,DS-7775657f-093b-433f-a9e3-876558ace465,DISK], DatanodeInfoWithStorage[127.0.0.1:45882,DS-8bb5a4fd-47cf-4934-9904-c56b3fe4f185,DISK], DatanodeInfoWithStorage[127.0.0.1:35112,DS-8082bd2f-da43-4eb1-b039-1702595c977f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1634635329-172.17.0.2-1595402356575:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37370,DS-dbdf9f42-f057-4dad-b4e4-49ea51b2d4e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44975,DS-1d098f09-1543-4af8-bf89-b921771f9ba6,DISK], DatanodeInfoWithStorage[127.0.0.1:41455,DS-baba1c3a-6d26-451b-bb51-339dba5ce0aa,DISK], DatanodeInfoWithStorage[127.0.0.1:33330,DS-a5a9b142-7825-4f41-b803-d190aa35261a,DISK], DatanodeInfoWithStorage[127.0.0.1:40046,DS-1ca399cc-4e26-494f-aafc-d7705a634e91,DISK], DatanodeInfoWithStorage[127.0.0.1:35279,DS-7775657f-093b-433f-a9e3-876558ace465,DISK], DatanodeInfoWithStorage[127.0.0.1:45882,DS-8bb5a4fd-47cf-4934-9904-c56b3fe4f185,DISK], DatanodeInfoWithStorage[127.0.0.1:35112,DS-8082bd2f-da43-4eb1-b039-1702595c977f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.bind.wildcard.addr
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1870675648-172.17.0.2-1595402390378:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43021,DS-039c1b9f-6890-44bb-aebf-91af0dc2383c,DISK], DatanodeInfoWithStorage[127.0.0.1:33995,DS-baf232aa-518c-4866-84a0-8cfdb6b572a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40661,DS-7e0d108f-1b14-4b06-824a-504d71eddbe6,DISK], DatanodeInfoWithStorage[127.0.0.1:45529,DS-b36220b5-f333-4323-bdb2-6cc0b56f1756,DISK], DatanodeInfoWithStorage[127.0.0.1:38036,DS-4a3721eb-b8e6-4c84-9ef8-05167363bc13,DISK], DatanodeInfoWithStorage[127.0.0.1:38927,DS-7e6c2dc9-c294-4431-9c35-facd4aaf7ee8,DISK], DatanodeInfoWithStorage[127.0.0.1:43359,DS-13ef8abd-548b-4f47-97ac-22ca5130cd9e,DISK], DatanodeInfoWithStorage[127.0.0.1:41355,DS-ba8f4afe-3719-49f4-b95d-74d041cab591,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1870675648-172.17.0.2-1595402390378:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43021,DS-039c1b9f-6890-44bb-aebf-91af0dc2383c,DISK], DatanodeInfoWithStorage[127.0.0.1:33995,DS-baf232aa-518c-4866-84a0-8cfdb6b572a5,DISK], DatanodeInfoWithStorage[127.0.0.1:40661,DS-7e0d108f-1b14-4b06-824a-504d71eddbe6,DISK], DatanodeInfoWithStorage[127.0.0.1:45529,DS-b36220b5-f333-4323-bdb2-6cc0b56f1756,DISK], DatanodeInfoWithStorage[127.0.0.1:38036,DS-4a3721eb-b8e6-4c84-9ef8-05167363bc13,DISK], DatanodeInfoWithStorage[127.0.0.1:38927,DS-7e6c2dc9-c294-4431-9c35-facd4aaf7ee8,DISK], DatanodeInfoWithStorage[127.0.0.1:43359,DS-13ef8abd-548b-4f47-97ac-22ca5130cd9e,DISK], DatanodeInfoWithStorage[127.0.0.1:41355,DS-ba8f4afe-3719-49f4-b95d-74d041cab591,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.bind.wildcard.addr
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-606591858-172.17.0.2-1595402733759:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46130,DS-1b0eae61-6a4d-4400-9983-41519a1cedca,DISK], DatanodeInfoWithStorage[127.0.0.1:46802,DS-59d0c8d8-bf6f-433f-8df1-443a8fc1f778,DISK], DatanodeInfoWithStorage[127.0.0.1:39244,DS-868d522f-859d-48c3-b5b5-06858604f61d,DISK], DatanodeInfoWithStorage[127.0.0.1:36716,DS-f5536595-b63f-45bb-bde3-eb8c1001ba52,DISK], DatanodeInfoWithStorage[127.0.0.1:39376,DS-68e1d273-8acf-491b-9a7d-22ed9085a031,DISK], DatanodeInfoWithStorage[127.0.0.1:44501,DS-8de877ce-2e41-42f8-a044-758e1f5eaf2c,DISK], DatanodeInfoWithStorage[127.0.0.1:43759,DS-5ec3c545-84b9-4d19-8333-52887dea273f,DISK], DatanodeInfoWithStorage[127.0.0.1:40681,DS-ab0192b2-ec74-4a5e-8db9-31524bedf79c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-606591858-172.17.0.2-1595402733759:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46130,DS-1b0eae61-6a4d-4400-9983-41519a1cedca,DISK], DatanodeInfoWithStorage[127.0.0.1:46802,DS-59d0c8d8-bf6f-433f-8df1-443a8fc1f778,DISK], DatanodeInfoWithStorage[127.0.0.1:39244,DS-868d522f-859d-48c3-b5b5-06858604f61d,DISK], DatanodeInfoWithStorage[127.0.0.1:36716,DS-f5536595-b63f-45bb-bde3-eb8c1001ba52,DISK], DatanodeInfoWithStorage[127.0.0.1:39376,DS-68e1d273-8acf-491b-9a7d-22ed9085a031,DISK], DatanodeInfoWithStorage[127.0.0.1:44501,DS-8de877ce-2e41-42f8-a044-758e1f5eaf2c,DISK], DatanodeInfoWithStorage[127.0.0.1:43759,DS-5ec3c545-84b9-4d19-8333-52887dea273f,DISK], DatanodeInfoWithStorage[127.0.0.1:40681,DS-ab0192b2-ec74-4a5e-8db9-31524bedf79c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.bind.wildcard.addr
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1304995723-172.17.0.2-1595402792353:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42894,DS-52e420fe-f166-48bc-9d21-dfabe0d7156b,DISK], DatanodeInfoWithStorage[127.0.0.1:43988,DS-36fadff2-3090-4e4f-b857-fb33a9a49742,DISK], DatanodeInfoWithStorage[127.0.0.1:41560,DS-e9a55b92-ebc5-4598-9451-696c650d75ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39379,DS-edf3536e-595b-4db6-8293-eb7088e4ad8e,DISK], DatanodeInfoWithStorage[127.0.0.1:43019,DS-5859ed8c-4c91-44c3-b8a9-de2b82a2575d,DISK], DatanodeInfoWithStorage[127.0.0.1:32895,DS-8863acc8-6175-4544-9c78-d6e9b2b29437,DISK], DatanodeInfoWithStorage[127.0.0.1:37230,DS-a11764fe-3221-4875-bdd0-e9a7e9e3d68e,DISK], DatanodeInfoWithStorage[127.0.0.1:34820,DS-a01876f4-f59d-4f64-96ce-bf99192d9a0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1304995723-172.17.0.2-1595402792353:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42894,DS-52e420fe-f166-48bc-9d21-dfabe0d7156b,DISK], DatanodeInfoWithStorage[127.0.0.1:43988,DS-36fadff2-3090-4e4f-b857-fb33a9a49742,DISK], DatanodeInfoWithStorage[127.0.0.1:41560,DS-e9a55b92-ebc5-4598-9451-696c650d75ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39379,DS-edf3536e-595b-4db6-8293-eb7088e4ad8e,DISK], DatanodeInfoWithStorage[127.0.0.1:43019,DS-5859ed8c-4c91-44c3-b8a9-de2b82a2575d,DISK], DatanodeInfoWithStorage[127.0.0.1:32895,DS-8863acc8-6175-4544-9c78-d6e9b2b29437,DISK], DatanodeInfoWithStorage[127.0.0.1:37230,DS-a11764fe-3221-4875-bdd0-e9a7e9e3d68e,DISK], DatanodeInfoWithStorage[127.0.0.1:34820,DS-a01876f4-f59d-4f64-96ce-bf99192d9a0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.bind.wildcard.addr
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-876557655-172.17.0.2-1595403259110:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34433,DS-4bdb6407-592e-4fda-a6b4-abc87fdee2bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36844,DS-90529c6e-4359-4c12-82d6-341a2dc93c69,DISK], DatanodeInfoWithStorage[127.0.0.1:43535,DS-6a26a5c6-7cd7-42fd-9adf-20f162e1540b,DISK], DatanodeInfoWithStorage[127.0.0.1:41886,DS-f22a620f-0a5e-4e2f-9aee-b069ee6125cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33502,DS-7bacb7f3-399a-492a-afa9-a645e5421b58,DISK], DatanodeInfoWithStorage[127.0.0.1:33368,DS-a61fa87f-4a83-427c-9828-72848c1e0e24,DISK], DatanodeInfoWithStorage[127.0.0.1:35865,DS-ef3d3616-c829-413a-9479-2df601dcd7d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38120,DS-2dc9d791-2a1f-4d45-8051-5f660cab00ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-876557655-172.17.0.2-1595403259110:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34433,DS-4bdb6407-592e-4fda-a6b4-abc87fdee2bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36844,DS-90529c6e-4359-4c12-82d6-341a2dc93c69,DISK], DatanodeInfoWithStorage[127.0.0.1:43535,DS-6a26a5c6-7cd7-42fd-9adf-20f162e1540b,DISK], DatanodeInfoWithStorage[127.0.0.1:41886,DS-f22a620f-0a5e-4e2f-9aee-b069ee6125cb,DISK], DatanodeInfoWithStorage[127.0.0.1:33502,DS-7bacb7f3-399a-492a-afa9-a645e5421b58,DISK], DatanodeInfoWithStorage[127.0.0.1:33368,DS-a61fa87f-4a83-427c-9828-72848c1e0e24,DISK], DatanodeInfoWithStorage[127.0.0.1:35865,DS-ef3d3616-c829-413a-9479-2df601dcd7d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38120,DS-2dc9d791-2a1f-4d45-8051-5f660cab00ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.bind.wildcard.addr
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1771393097-172.17.0.2-1595403804231:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43591,DS-d579064e-15b3-42eb-9dc9-ac81f071aa43,DISK], DatanodeInfoWithStorage[127.0.0.1:46650,DS-8ffc1a02-c86c-4c25-9eef-a29dd35594af,DISK], DatanodeInfoWithStorage[127.0.0.1:46038,DS-a555560f-df32-4996-88dd-27b908440435,DISK], DatanodeInfoWithStorage[127.0.0.1:38830,DS-1a85c023-61ed-4ee6-8a05-9e3752926a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:38025,DS-18492763-9fe8-4ee0-807b-af21f56b9123,DISK], DatanodeInfoWithStorage[127.0.0.1:33989,DS-ab5728ec-afa6-4927-9b44-c529fe564cd0,DISK], DatanodeInfoWithStorage[127.0.0.1:36969,DS-e5c2b44d-d4a9-4e44-8f1b-009993d30498,DISK], DatanodeInfoWithStorage[127.0.0.1:44821,DS-ffd90d01-3211-447b-ab1b-7b772392f9b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1771393097-172.17.0.2-1595403804231:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43591,DS-d579064e-15b3-42eb-9dc9-ac81f071aa43,DISK], DatanodeInfoWithStorage[127.0.0.1:46650,DS-8ffc1a02-c86c-4c25-9eef-a29dd35594af,DISK], DatanodeInfoWithStorage[127.0.0.1:46038,DS-a555560f-df32-4996-88dd-27b908440435,DISK], DatanodeInfoWithStorage[127.0.0.1:38830,DS-1a85c023-61ed-4ee6-8a05-9e3752926a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:38025,DS-18492763-9fe8-4ee0-807b-af21f56b9123,DISK], DatanodeInfoWithStorage[127.0.0.1:33989,DS-ab5728ec-afa6-4927-9b44-c529fe564cd0,DISK], DatanodeInfoWithStorage[127.0.0.1:36969,DS-e5c2b44d-d4a9-4e44-8f1b-009993d30498,DISK], DatanodeInfoWithStorage[127.0.0.1:44821,DS-ffd90d01-3211-447b-ab1b-7b772392f9b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.bind.wildcard.addr
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-824721344-172.17.0.2-1595404265216:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38384,DS-d9f81dfc-bf25-4283-a572-6e516d34c256,DISK], DatanodeInfoWithStorage[127.0.0.1:35056,DS-034277d8-737f-4d40-90ba-8d88e08ae438,DISK], DatanodeInfoWithStorage[127.0.0.1:35295,DS-b3124534-bec4-41a8-b51e-e9cb15259a26,DISK], DatanodeInfoWithStorage[127.0.0.1:46166,DS-86066e64-809b-4d90-bb89-8166c0bc38ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36394,DS-0079424b-b8a5-4399-bdc9-95e2fcbe4d05,DISK], DatanodeInfoWithStorage[127.0.0.1:44847,DS-470ecca1-da15-4b12-aa7c-2aa4b4b1965a,DISK], DatanodeInfoWithStorage[127.0.0.1:34274,DS-57bb89ea-39dc-47e3-beb2-3d73b08fd95b,DISK], DatanodeInfoWithStorage[127.0.0.1:40043,DS-104462c6-664a-4a5e-beb3-ce58ac215348,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-824721344-172.17.0.2-1595404265216:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38384,DS-d9f81dfc-bf25-4283-a572-6e516d34c256,DISK], DatanodeInfoWithStorage[127.0.0.1:35056,DS-034277d8-737f-4d40-90ba-8d88e08ae438,DISK], DatanodeInfoWithStorage[127.0.0.1:35295,DS-b3124534-bec4-41a8-b51e-e9cb15259a26,DISK], DatanodeInfoWithStorage[127.0.0.1:46166,DS-86066e64-809b-4d90-bb89-8166c0bc38ca,DISK], DatanodeInfoWithStorage[127.0.0.1:36394,DS-0079424b-b8a5-4399-bdc9-95e2fcbe4d05,DISK], DatanodeInfoWithStorage[127.0.0.1:44847,DS-470ecca1-da15-4b12-aa7c-2aa4b4b1965a,DISK], DatanodeInfoWithStorage[127.0.0.1:34274,DS-57bb89ea-39dc-47e3-beb2-3d73b08fd95b,DISK], DatanodeInfoWithStorage[127.0.0.1:40043,DS-104462c6-664a-4a5e-beb3-ce58ac215348,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.bind.wildcard.addr
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1143116675-172.17.0.2-1595404416926:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44314,DS-e34b908b-e057-4da2-9d0e-05b17685166e,DISK], DatanodeInfoWithStorage[127.0.0.1:39484,DS-ef98c978-93c4-42c5-8060-68aaccf29718,DISK], DatanodeInfoWithStorage[127.0.0.1:36158,DS-323d2600-f560-4178-82a6-401987a5955d,DISK], DatanodeInfoWithStorage[127.0.0.1:32886,DS-e7011de0-2177-47a6-840e-07e42b43ef1c,DISK], DatanodeInfoWithStorage[127.0.0.1:37436,DS-663c6804-3ed1-4f02-8caa-7fec848df8f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37668,DS-d11b7cc4-ab5c-46a8-a1e3-ae1e4efd18f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45472,DS-bd46b678-af2a-4359-bb94-f9b4c77681b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40260,DS-59cc0869-22c9-4a6f-9370-157fc2e3caf6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1143116675-172.17.0.2-1595404416926:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44314,DS-e34b908b-e057-4da2-9d0e-05b17685166e,DISK], DatanodeInfoWithStorage[127.0.0.1:39484,DS-ef98c978-93c4-42c5-8060-68aaccf29718,DISK], DatanodeInfoWithStorage[127.0.0.1:36158,DS-323d2600-f560-4178-82a6-401987a5955d,DISK], DatanodeInfoWithStorage[127.0.0.1:32886,DS-e7011de0-2177-47a6-840e-07e42b43ef1c,DISK], DatanodeInfoWithStorage[127.0.0.1:37436,DS-663c6804-3ed1-4f02-8caa-7fec848df8f3,DISK], DatanodeInfoWithStorage[127.0.0.1:37668,DS-d11b7cc4-ab5c-46a8-a1e3-ae1e4efd18f0,DISK], DatanodeInfoWithStorage[127.0.0.1:45472,DS-bd46b678-af2a-4359-bb94-f9b4c77681b1,DISK], DatanodeInfoWithStorage[127.0.0.1:40260,DS-59cc0869-22c9-4a6f-9370-157fc2e3caf6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: ipc.client.bind.wildcard.addr
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2092471618-172.17.0.2-1595404444066:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38740,DS-0245e066-e7b6-4304-abf0-a8afe3e563ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41566,DS-ad3aca42-abd4-4091-80c9-e6d41170bc31,DISK], DatanodeInfoWithStorage[127.0.0.1:40473,DS-d2aeaa8e-c26e-45dd-8819-95d8f97393d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36672,DS-1bc5f2d1-9545-4d9a-8c75-a430dfe163e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33200,DS-58387583-ee9d-4fcb-a99a-f7183cb17d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:38789,DS-4c16b5bf-ffa6-44ea-8ede-fc6f3f4b275f,DISK], DatanodeInfoWithStorage[127.0.0.1:39483,DS-f4a7d9e6-2a30-4b3e-aa6f-31c00cc3eaf0,DISK], DatanodeInfoWithStorage[127.0.0.1:41541,DS-929d5780-6d46-4f1b-8481-ba39c8ed991c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2092471618-172.17.0.2-1595404444066:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38740,DS-0245e066-e7b6-4304-abf0-a8afe3e563ac,DISK], DatanodeInfoWithStorage[127.0.0.1:41566,DS-ad3aca42-abd4-4091-80c9-e6d41170bc31,DISK], DatanodeInfoWithStorage[127.0.0.1:40473,DS-d2aeaa8e-c26e-45dd-8819-95d8f97393d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36672,DS-1bc5f2d1-9545-4d9a-8c75-a430dfe163e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33200,DS-58387583-ee9d-4fcb-a99a-f7183cb17d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:38789,DS-4c16b5bf-ffa6-44ea-8ede-fc6f3f4b275f,DISK], DatanodeInfoWithStorage[127.0.0.1:39483,DS-f4a7d9e6-2a30-4b3e-aa6f-31c00cc3eaf0,DISK], DatanodeInfoWithStorage[127.0.0.1:41541,DS-929d5780-6d46-4f1b-8481-ba39c8ed991c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: ipc.client.bind.wildcard.addr
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1850729911-172.17.0.2-1595404475490:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33227,DS-b87145e2-aebc-482d-b707-025c6278a794,DISK], DatanodeInfoWithStorage[127.0.0.1:35521,DS-45bdfcb1-2ca5-4972-92cd-43d8024bea56,DISK], DatanodeInfoWithStorage[127.0.0.1:44486,DS-48c85c7b-107c-4e30-8f4b-8e5ea4965dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:36248,DS-5c483b61-9e4e-4c06-b145-214dff9bd79b,DISK], DatanodeInfoWithStorage[127.0.0.1:42720,DS-5761fe56-dd39-4835-8dc3-2deca5b7d00a,DISK], DatanodeInfoWithStorage[127.0.0.1:44648,DS-317f9766-1a1c-445b-be99-9cffcdfaa651,DISK], DatanodeInfoWithStorage[127.0.0.1:46074,DS-acc96eca-10a6-4ddd-8da8-dd240143a3da,DISK], DatanodeInfoWithStorage[127.0.0.1:46178,DS-f25a4dbf-cd90-47b0-a668-b0065f865822,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1850729911-172.17.0.2-1595404475490:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33227,DS-b87145e2-aebc-482d-b707-025c6278a794,DISK], DatanodeInfoWithStorage[127.0.0.1:35521,DS-45bdfcb1-2ca5-4972-92cd-43d8024bea56,DISK], DatanodeInfoWithStorage[127.0.0.1:44486,DS-48c85c7b-107c-4e30-8f4b-8e5ea4965dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:36248,DS-5c483b61-9e4e-4c06-b145-214dff9bd79b,DISK], DatanodeInfoWithStorage[127.0.0.1:42720,DS-5761fe56-dd39-4835-8dc3-2deca5b7d00a,DISK], DatanodeInfoWithStorage[127.0.0.1:44648,DS-317f9766-1a1c-445b-be99-9cffcdfaa651,DISK], DatanodeInfoWithStorage[127.0.0.1:46074,DS-acc96eca-10a6-4ddd-8da8-dd240143a3da,DISK], DatanodeInfoWithStorage[127.0.0.1:46178,DS-f25a4dbf-cd90-47b0-a668-b0065f865822,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: ipc.client.bind.wildcard.addr
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2064472749-172.17.0.2-1595404599013:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36787,DS-18742aee-1103-4828-bb6b-fa8c71e4d54c,DISK], DatanodeInfoWithStorage[127.0.0.1:39570,DS-068ee258-6ddf-4f0d-b1fe-459181eed043,DISK], DatanodeInfoWithStorage[127.0.0.1:46139,DS-43edae10-0c20-40d6-bc49-a34274daea4d,DISK], DatanodeInfoWithStorage[127.0.0.1:44252,DS-e8c2e3e9-a665-4cca-b7cb-78108c8e7363,DISK], DatanodeInfoWithStorage[127.0.0.1:40383,DS-ec30de67-e3e9-45d3-95ec-05ddc25ba77b,DISK], DatanodeInfoWithStorage[127.0.0.1:45758,DS-15aba960-e672-42e9-b396-f0d6e3b3d7c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39863,DS-a09eea79-844f-4d48-9804-d4c8ff26e8f8,DISK], DatanodeInfoWithStorage[127.0.0.1:45795,DS-e5f3fe0b-eec9-4757-963e-59c54a11a484,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2064472749-172.17.0.2-1595404599013:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36787,DS-18742aee-1103-4828-bb6b-fa8c71e4d54c,DISK], DatanodeInfoWithStorage[127.0.0.1:39570,DS-068ee258-6ddf-4f0d-b1fe-459181eed043,DISK], DatanodeInfoWithStorage[127.0.0.1:46139,DS-43edae10-0c20-40d6-bc49-a34274daea4d,DISK], DatanodeInfoWithStorage[127.0.0.1:44252,DS-e8c2e3e9-a665-4cca-b7cb-78108c8e7363,DISK], DatanodeInfoWithStorage[127.0.0.1:40383,DS-ec30de67-e3e9-45d3-95ec-05ddc25ba77b,DISK], DatanodeInfoWithStorage[127.0.0.1:45758,DS-15aba960-e672-42e9-b396-f0d6e3b3d7c1,DISK], DatanodeInfoWithStorage[127.0.0.1:39863,DS-a09eea79-844f-4d48-9804-d4c8ff26e8f8,DISK], DatanodeInfoWithStorage[127.0.0.1:45795,DS-e5f3fe0b-eec9-4757-963e-59c54a11a484,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5100
