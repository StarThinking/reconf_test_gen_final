reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-180786494-172.17.0.12-1596923136088:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42076,DS-d57643c2-26a0-4db1-a553-fbe29a9056d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46572,DS-59feec75-2c4d-4ed9-9b1f-2160d3153954,DISK], DatanodeInfoWithStorage[127.0.0.1:39566,DS-80c77b29-8f43-43b3-87b7-fdec2383a118,DISK], DatanodeInfoWithStorage[127.0.0.1:40734,DS-b5a83c59-67c0-4134-b3c1-82768d19f6e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34937,DS-90262eab-4e8b-4537-8f5b-db714b59e46d,DISK], DatanodeInfoWithStorage[127.0.0.1:36659,DS-a7b4fa92-d8b9-494d-b563-2e2e4da073d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37330,DS-00b892cf-c6e8-4cf5-b077-8ef5cf9a2afd,DISK], DatanodeInfoWithStorage[127.0.0.1:36622,DS-689664dc-3519-4f04-be9f-8e12de7d0a36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-180786494-172.17.0.12-1596923136088:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42076,DS-d57643c2-26a0-4db1-a553-fbe29a9056d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46572,DS-59feec75-2c4d-4ed9-9b1f-2160d3153954,DISK], DatanodeInfoWithStorage[127.0.0.1:39566,DS-80c77b29-8f43-43b3-87b7-fdec2383a118,DISK], DatanodeInfoWithStorage[127.0.0.1:40734,DS-b5a83c59-67c0-4134-b3c1-82768d19f6e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34937,DS-90262eab-4e8b-4537-8f5b-db714b59e46d,DISK], DatanodeInfoWithStorage[127.0.0.1:36659,DS-a7b4fa92-d8b9-494d-b563-2e2e4da073d3,DISK], DatanodeInfoWithStorage[127.0.0.1:37330,DS-00b892cf-c6e8-4cf5-b077-8ef5cf9a2afd,DISK], DatanodeInfoWithStorage[127.0.0.1:36622,DS-689664dc-3519-4f04-be9f-8e12de7d0a36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-486775363-172.17.0.12-1596924602703:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45621,DS-15ea1e08-5f76-46e0-8be9-03200165b21d,DISK], DatanodeInfoWithStorage[127.0.0.1:44108,DS-f585b66f-5dec-4877-ae86-448c59ff239c,DISK], DatanodeInfoWithStorage[127.0.0.1:44929,DS-c11cfe41-3474-4674-913b-66d0bfdf9eeb,DISK], DatanodeInfoWithStorage[127.0.0.1:43007,DS-079f0ec1-0d1b-4be0-a172-ea588ec10997,DISK], DatanodeInfoWithStorage[127.0.0.1:37560,DS-236a6826-d33a-4e73-85ee-cbd251a628a9,DISK], DatanodeInfoWithStorage[127.0.0.1:32884,DS-e53d305d-c509-42bf-a63b-2802b60ab47e,DISK], DatanodeInfoWithStorage[127.0.0.1:39991,DS-e04e5990-9445-4ea1-9107-2827c0026c80,DISK], DatanodeInfoWithStorage[127.0.0.1:44520,DS-299240ca-e7e8-4e25-b23c-4d3221838fad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-486775363-172.17.0.12-1596924602703:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45621,DS-15ea1e08-5f76-46e0-8be9-03200165b21d,DISK], DatanodeInfoWithStorage[127.0.0.1:44108,DS-f585b66f-5dec-4877-ae86-448c59ff239c,DISK], DatanodeInfoWithStorage[127.0.0.1:44929,DS-c11cfe41-3474-4674-913b-66d0bfdf9eeb,DISK], DatanodeInfoWithStorage[127.0.0.1:43007,DS-079f0ec1-0d1b-4be0-a172-ea588ec10997,DISK], DatanodeInfoWithStorage[127.0.0.1:37560,DS-236a6826-d33a-4e73-85ee-cbd251a628a9,DISK], DatanodeInfoWithStorage[127.0.0.1:32884,DS-e53d305d-c509-42bf-a63b-2802b60ab47e,DISK], DatanodeInfoWithStorage[127.0.0.1:39991,DS-e04e5990-9445-4ea1-9107-2827c0026c80,DISK], DatanodeInfoWithStorage[127.0.0.1:44520,DS-299240ca-e7e8-4e25-b23c-4d3221838fad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-901784770-172.17.0.12-1596924669824:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40624,DS-204440aa-3ae8-4ab1-b4a0-0e533ed232c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33750,DS-db302b65-e722-4c48-a48a-e0c503cf5aaa,DISK], DatanodeInfoWithStorage[127.0.0.1:42061,DS-ebc417f3-c73a-4512-b766-9422a3a8a2ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46361,DS-d5b87ed8-a0d6-4ec8-be55-514e75126e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:46717,DS-5a3d47ed-da4c-46fe-b202-8f842b3a8898,DISK], DatanodeInfoWithStorage[127.0.0.1:35020,DS-9d0b9686-eb06-4ce6-997b-bd18d8435a54,DISK], DatanodeInfoWithStorage[127.0.0.1:41371,DS-481fb7a1-afe9-430d-870c-b09aa092b9a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42599,DS-b587d5ab-2872-40a0-a9c0-a203fee995ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-901784770-172.17.0.12-1596924669824:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40624,DS-204440aa-3ae8-4ab1-b4a0-0e533ed232c2,DISK], DatanodeInfoWithStorage[127.0.0.1:33750,DS-db302b65-e722-4c48-a48a-e0c503cf5aaa,DISK], DatanodeInfoWithStorage[127.0.0.1:42061,DS-ebc417f3-c73a-4512-b766-9422a3a8a2ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46361,DS-d5b87ed8-a0d6-4ec8-be55-514e75126e3f,DISK], DatanodeInfoWithStorage[127.0.0.1:46717,DS-5a3d47ed-da4c-46fe-b202-8f842b3a8898,DISK], DatanodeInfoWithStorage[127.0.0.1:35020,DS-9d0b9686-eb06-4ce6-997b-bd18d8435a54,DISK], DatanodeInfoWithStorage[127.0.0.1:41371,DS-481fb7a1-afe9-430d-870c-b09aa092b9a9,DISK], DatanodeInfoWithStorage[127.0.0.1:42599,DS-b587d5ab-2872-40a0-a9c0-a203fee995ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1890880631-172.17.0.12-1596924703699:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43996,DS-e82fc4d0-1071-47f7-8db7-828ef689c9ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33322,DS-3029bc07-71dd-4064-ae9a-7dd03be6366c,DISK], DatanodeInfoWithStorage[127.0.0.1:37037,DS-21d49c1a-6de1-41c7-ac04-4e59eba19ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:38990,DS-4f3559a3-534f-4bf2-a036-959ed8501dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:37840,DS-0c3f0c71-43df-49ec-b6ee-96050600de4e,DISK], DatanodeInfoWithStorage[127.0.0.1:36012,DS-48594e0d-d948-4f2a-b444-a4cf06ed4ebd,DISK], DatanodeInfoWithStorage[127.0.0.1:43473,DS-f855b62c-ae76-4bb7-b3de-87de129f6003,DISK], DatanodeInfoWithStorage[127.0.0.1:33534,DS-df11ea0c-6283-43b3-92ab-d5c7ae9dbe9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1890880631-172.17.0.12-1596924703699:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43996,DS-e82fc4d0-1071-47f7-8db7-828ef689c9ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33322,DS-3029bc07-71dd-4064-ae9a-7dd03be6366c,DISK], DatanodeInfoWithStorage[127.0.0.1:37037,DS-21d49c1a-6de1-41c7-ac04-4e59eba19ee5,DISK], DatanodeInfoWithStorage[127.0.0.1:38990,DS-4f3559a3-534f-4bf2-a036-959ed8501dfc,DISK], DatanodeInfoWithStorage[127.0.0.1:37840,DS-0c3f0c71-43df-49ec-b6ee-96050600de4e,DISK], DatanodeInfoWithStorage[127.0.0.1:36012,DS-48594e0d-d948-4f2a-b444-a4cf06ed4ebd,DISK], DatanodeInfoWithStorage[127.0.0.1:43473,DS-f855b62c-ae76-4bb7-b3de-87de129f6003,DISK], DatanodeInfoWithStorage[127.0.0.1:33534,DS-df11ea0c-6283-43b3-92ab-d5c7ae9dbe9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-321726564-172.17.0.12-1596924851227:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34021,DS-009257f5-23e9-4fff-b6b2-18aca6c06c61,DISK], DatanodeInfoWithStorage[127.0.0.1:45226,DS-03ec8d62-9233-40d4-9986-a855f77bd163,DISK], DatanodeInfoWithStorage[127.0.0.1:42714,DS-83c49fbc-6734-4aef-b2cb-2e10505d3b69,DISK], DatanodeInfoWithStorage[127.0.0.1:35923,DS-38019b2b-93a4-4a6c-81d9-ef9b0ac2071f,DISK], DatanodeInfoWithStorage[127.0.0.1:43660,DS-29d7fa3a-7c92-47c0-8545-c213aa33b696,DISK], DatanodeInfoWithStorage[127.0.0.1:35795,DS-aad3fd5a-5963-4cdd-9cbe-93c5df772b63,DISK], DatanodeInfoWithStorage[127.0.0.1:35216,DS-624359a6-4cb2-480b-b268-2b5699a9348d,DISK], DatanodeInfoWithStorage[127.0.0.1:34084,DS-1af70484-ee57-4dcb-977d-622ac28f2aa8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-321726564-172.17.0.12-1596924851227:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34021,DS-009257f5-23e9-4fff-b6b2-18aca6c06c61,DISK], DatanodeInfoWithStorage[127.0.0.1:45226,DS-03ec8d62-9233-40d4-9986-a855f77bd163,DISK], DatanodeInfoWithStorage[127.0.0.1:42714,DS-83c49fbc-6734-4aef-b2cb-2e10505d3b69,DISK], DatanodeInfoWithStorage[127.0.0.1:35923,DS-38019b2b-93a4-4a6c-81d9-ef9b0ac2071f,DISK], DatanodeInfoWithStorage[127.0.0.1:43660,DS-29d7fa3a-7c92-47c0-8545-c213aa33b696,DISK], DatanodeInfoWithStorage[127.0.0.1:35795,DS-aad3fd5a-5963-4cdd-9cbe-93c5df772b63,DISK], DatanodeInfoWithStorage[127.0.0.1:35216,DS-624359a6-4cb2-480b-b268-2b5699a9348d,DISK], DatanodeInfoWithStorage[127.0.0.1:34084,DS-1af70484-ee57-4dcb-977d-622ac28f2aa8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1472657903-172.17.0.12-1596925139486:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37602,DS-dab835c0-6912-4c29-8c70-a094ef884c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:38149,DS-caaaa96c-a7c1-4ce1-9a6c-afceec1e3e63,DISK], DatanodeInfoWithStorage[127.0.0.1:42860,DS-b1e98470-c984-4839-8549-58f2c9146be1,DISK], DatanodeInfoWithStorage[127.0.0.1:44630,DS-d8c70398-5c77-48c7-897c-0efd8cc39671,DISK], DatanodeInfoWithStorage[127.0.0.1:42463,DS-0fcf40e1-98cc-4142-93de-9a7fef7a2ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:41201,DS-348d9506-c7bc-4f48-af3d-6f2df06c80dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36556,DS-c19e7125-f9b0-4c8a-97fe-4a979df2e7e8,DISK], DatanodeInfoWithStorage[127.0.0.1:46029,DS-b6e4f35c-8712-4506-a5a3-f8812140c1b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1472657903-172.17.0.12-1596925139486:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37602,DS-dab835c0-6912-4c29-8c70-a094ef884c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:38149,DS-caaaa96c-a7c1-4ce1-9a6c-afceec1e3e63,DISK], DatanodeInfoWithStorage[127.0.0.1:42860,DS-b1e98470-c984-4839-8549-58f2c9146be1,DISK], DatanodeInfoWithStorage[127.0.0.1:44630,DS-d8c70398-5c77-48c7-897c-0efd8cc39671,DISK], DatanodeInfoWithStorage[127.0.0.1:42463,DS-0fcf40e1-98cc-4142-93de-9a7fef7a2ad8,DISK], DatanodeInfoWithStorage[127.0.0.1:41201,DS-348d9506-c7bc-4f48-af3d-6f2df06c80dc,DISK], DatanodeInfoWithStorage[127.0.0.1:36556,DS-c19e7125-f9b0-4c8a-97fe-4a979df2e7e8,DISK], DatanodeInfoWithStorage[127.0.0.1:46029,DS-b6e4f35c-8712-4506-a5a3-f8812140c1b7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-255766427-172.17.0.12-1596925450763:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41168,DS-2a8e3dd5-e284-49f5-a4e4-a388e03215c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35522,DS-831a175d-0461-4440-88f3-a5eedd0504cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45226,DS-baeeed28-f9a1-4d0d-9b19-1e1ee0c57836,DISK], DatanodeInfoWithStorage[127.0.0.1:34504,DS-c7afd567-b80c-47f9-8bf3-42b7e0f17057,DISK], DatanodeInfoWithStorage[127.0.0.1:42434,DS-8b545071-b765-4772-a9f1-4e796d016a12,DISK], DatanodeInfoWithStorage[127.0.0.1:36871,DS-6a270719-8c84-4cc3-9767-938ee7acb782,DISK], DatanodeInfoWithStorage[127.0.0.1:35790,DS-774ba547-9f88-4488-9cbf-853194ad5b2b,DISK], DatanodeInfoWithStorage[127.0.0.1:44286,DS-4c2764d6-aa99-43da-bda0-53b83e853158,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-255766427-172.17.0.12-1596925450763:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41168,DS-2a8e3dd5-e284-49f5-a4e4-a388e03215c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35522,DS-831a175d-0461-4440-88f3-a5eedd0504cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45226,DS-baeeed28-f9a1-4d0d-9b19-1e1ee0c57836,DISK], DatanodeInfoWithStorage[127.0.0.1:34504,DS-c7afd567-b80c-47f9-8bf3-42b7e0f17057,DISK], DatanodeInfoWithStorage[127.0.0.1:42434,DS-8b545071-b765-4772-a9f1-4e796d016a12,DISK], DatanodeInfoWithStorage[127.0.0.1:36871,DS-6a270719-8c84-4cc3-9767-938ee7acb782,DISK], DatanodeInfoWithStorage[127.0.0.1:35790,DS-774ba547-9f88-4488-9cbf-853194ad5b2b,DISK], DatanodeInfoWithStorage[127.0.0.1:44286,DS-4c2764d6-aa99-43da-bda0-53b83e853158,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-715974974-172.17.0.12-1596925817732:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40981,DS-468dfc7a-b411-4ff9-8620-f7b6cf2da29d,DISK], DatanodeInfoWithStorage[127.0.0.1:37864,DS-7d2e3975-ab25-44f0-8d31-aa575f9679a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35249,DS-008b65c8-6925-4323-a4fc-3dd50a42ff8f,DISK], DatanodeInfoWithStorage[127.0.0.1:43977,DS-9fc85d26-7700-45d8-8e0a-6af639604fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:40833,DS-8b4a5f14-3341-448c-a593-2483ff374fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:45034,DS-54655a12-915b-4089-831f-199aa4893327,DISK], DatanodeInfoWithStorage[127.0.0.1:32898,DS-8484f4d8-dc3b-4db0-bc80-58720872aac6,DISK], DatanodeInfoWithStorage[127.0.0.1:33701,DS-eaf51a2f-9241-4537-9039-1f46db35ab90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-715974974-172.17.0.12-1596925817732:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40981,DS-468dfc7a-b411-4ff9-8620-f7b6cf2da29d,DISK], DatanodeInfoWithStorage[127.0.0.1:37864,DS-7d2e3975-ab25-44f0-8d31-aa575f9679a5,DISK], DatanodeInfoWithStorage[127.0.0.1:35249,DS-008b65c8-6925-4323-a4fc-3dd50a42ff8f,DISK], DatanodeInfoWithStorage[127.0.0.1:43977,DS-9fc85d26-7700-45d8-8e0a-6af639604fa6,DISK], DatanodeInfoWithStorage[127.0.0.1:40833,DS-8b4a5f14-3341-448c-a593-2483ff374fbe,DISK], DatanodeInfoWithStorage[127.0.0.1:45034,DS-54655a12-915b-4089-831f-199aa4893327,DISK], DatanodeInfoWithStorage[127.0.0.1:32898,DS-8484f4d8-dc3b-4db0-bc80-58720872aac6,DISK], DatanodeInfoWithStorage[127.0.0.1:33701,DS-eaf51a2f-9241-4537-9039-1f46db35ab90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-506979733-172.17.0.12-1596925893256:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41713,DS-d7b91439-3d4f-47d7-b62d-6a1ea665ccac,DISK], DatanodeInfoWithStorage[127.0.0.1:37330,DS-e4203795-1c48-430d-bc8c-147a5825ac59,DISK], DatanodeInfoWithStorage[127.0.0.1:40055,DS-d6301aaf-476e-411b-b765-6e204fb89afc,DISK], DatanodeInfoWithStorage[127.0.0.1:44619,DS-8b28ef41-f577-4eb3-af62-4f4dea913cef,DISK], DatanodeInfoWithStorage[127.0.0.1:35448,DS-b3ff2b09-ff87-44cf-8411-c620edf71d20,DISK], DatanodeInfoWithStorage[127.0.0.1:45688,DS-121f3934-b4ba-44ad-ad81-a6dbb18df328,DISK], DatanodeInfoWithStorage[127.0.0.1:34427,DS-45b8fc9b-c855-4e71-8c00-0179687d497a,DISK], DatanodeInfoWithStorage[127.0.0.1:40019,DS-c4f47ce2-e2fc-4828-8f70-fffc4a1acb93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-506979733-172.17.0.12-1596925893256:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41713,DS-d7b91439-3d4f-47d7-b62d-6a1ea665ccac,DISK], DatanodeInfoWithStorage[127.0.0.1:37330,DS-e4203795-1c48-430d-bc8c-147a5825ac59,DISK], DatanodeInfoWithStorage[127.0.0.1:40055,DS-d6301aaf-476e-411b-b765-6e204fb89afc,DISK], DatanodeInfoWithStorage[127.0.0.1:44619,DS-8b28ef41-f577-4eb3-af62-4f4dea913cef,DISK], DatanodeInfoWithStorage[127.0.0.1:35448,DS-b3ff2b09-ff87-44cf-8411-c620edf71d20,DISK], DatanodeInfoWithStorage[127.0.0.1:45688,DS-121f3934-b4ba-44ad-ad81-a6dbb18df328,DISK], DatanodeInfoWithStorage[127.0.0.1:34427,DS-45b8fc9b-c855-4e71-8c00-0179687d497a,DISK], DatanodeInfoWithStorage[127.0.0.1:40019,DS-c4f47ce2-e2fc-4828-8f70-fffc4a1acb93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-555781721-172.17.0.12-1596926804283:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42348,DS-bd003d8f-1c49-47d1-82ca-14719f749f67,DISK], DatanodeInfoWithStorage[127.0.0.1:38859,DS-278b2a9b-6b59-4a8a-bfb0-c516ac666562,DISK], DatanodeInfoWithStorage[127.0.0.1:34366,DS-02f400b7-91ba-4396-a87a-d652299a25f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39982,DS-2989a051-be1d-4414-8a7f-f18998b22615,DISK], DatanodeInfoWithStorage[127.0.0.1:34425,DS-5b5a5619-e93f-4089-bcd6-f28d5f7357f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44772,DS-b445f6bd-b481-4030-a0f2-10917a14fdae,DISK], DatanodeInfoWithStorage[127.0.0.1:45720,DS-015a1f7d-3609-47a5-94d8-edecc926e289,DISK], DatanodeInfoWithStorage[127.0.0.1:46339,DS-b1d7db9e-cd5b-4cd0-b7d4-fe79f13734e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-555781721-172.17.0.12-1596926804283:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42348,DS-bd003d8f-1c49-47d1-82ca-14719f749f67,DISK], DatanodeInfoWithStorage[127.0.0.1:38859,DS-278b2a9b-6b59-4a8a-bfb0-c516ac666562,DISK], DatanodeInfoWithStorage[127.0.0.1:34366,DS-02f400b7-91ba-4396-a87a-d652299a25f5,DISK], DatanodeInfoWithStorage[127.0.0.1:39982,DS-2989a051-be1d-4414-8a7f-f18998b22615,DISK], DatanodeInfoWithStorage[127.0.0.1:34425,DS-5b5a5619-e93f-4089-bcd6-f28d5f7357f8,DISK], DatanodeInfoWithStorage[127.0.0.1:44772,DS-b445f6bd-b481-4030-a0f2-10917a14fdae,DISK], DatanodeInfoWithStorage[127.0.0.1:45720,DS-015a1f7d-3609-47a5-94d8-edecc926e289,DISK], DatanodeInfoWithStorage[127.0.0.1:46339,DS-b1d7db9e-cd5b-4cd0-b7d4-fe79f13734e5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-388459171-172.17.0.12-1596926967363:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33226,DS-cbdfbbc7-594b-401e-90ea-8e8c7a0b9722,DISK], DatanodeInfoWithStorage[127.0.0.1:39940,DS-70304263-a1e6-42f6-b30a-0e3752b9f38d,DISK], DatanodeInfoWithStorage[127.0.0.1:35940,DS-246b7135-0448-4263-8378-442f3eec3627,DISK], DatanodeInfoWithStorage[127.0.0.1:38988,DS-b19262f0-ec82-4238-860a-e01600f685dd,DISK], DatanodeInfoWithStorage[127.0.0.1:35876,DS-d1b1d494-99ae-43a3-be15-256e1cf5b081,DISK], DatanodeInfoWithStorage[127.0.0.1:36905,DS-ac0af31f-98f1-47bb-b9eb-19ee9f7fa2bb,DISK], DatanodeInfoWithStorage[127.0.0.1:42117,DS-8f052d45-9b82-498b-8bac-db8559021755,DISK], DatanodeInfoWithStorage[127.0.0.1:39972,DS-ecf1d915-7066-4285-a186-27ff2e6b3374,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-388459171-172.17.0.12-1596926967363:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33226,DS-cbdfbbc7-594b-401e-90ea-8e8c7a0b9722,DISK], DatanodeInfoWithStorage[127.0.0.1:39940,DS-70304263-a1e6-42f6-b30a-0e3752b9f38d,DISK], DatanodeInfoWithStorage[127.0.0.1:35940,DS-246b7135-0448-4263-8378-442f3eec3627,DISK], DatanodeInfoWithStorage[127.0.0.1:38988,DS-b19262f0-ec82-4238-860a-e01600f685dd,DISK], DatanodeInfoWithStorage[127.0.0.1:35876,DS-d1b1d494-99ae-43a3-be15-256e1cf5b081,DISK], DatanodeInfoWithStorage[127.0.0.1:36905,DS-ac0af31f-98f1-47bb-b9eb-19ee9f7fa2bb,DISK], DatanodeInfoWithStorage[127.0.0.1:42117,DS-8f052d45-9b82-498b-8bac-db8559021755,DISK], DatanodeInfoWithStorage[127.0.0.1:39972,DS-ecf1d915-7066-4285-a186-27ff2e6b3374,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-966917153-172.17.0.12-1596926997646:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45649,DS-8f544e3a-94d1-4a55-b1db-f0c174ed688c,DISK], DatanodeInfoWithStorage[127.0.0.1:44721,DS-b1e564b6-4e96-4514-88a7-a6f998e53f47,DISK], DatanodeInfoWithStorage[127.0.0.1:34531,DS-bb7c4bc4-4ea3-460a-9fae-0698fbc8d482,DISK], DatanodeInfoWithStorage[127.0.0.1:35517,DS-2581afc0-cc29-4cd5-a176-93d5d436c846,DISK], DatanodeInfoWithStorage[127.0.0.1:45486,DS-8803d822-e50f-4213-9e0f-d15acb1275cf,DISK], DatanodeInfoWithStorage[127.0.0.1:43862,DS-8b8acc40-d097-4a85-9d54-abd15cb90f58,DISK], DatanodeInfoWithStorage[127.0.0.1:45247,DS-8c3588ae-a941-474e-ba22-51de8cb2e9d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36042,DS-70523a54-95c3-4b80-913b-a41960a1a04e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-966917153-172.17.0.12-1596926997646:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45649,DS-8f544e3a-94d1-4a55-b1db-f0c174ed688c,DISK], DatanodeInfoWithStorage[127.0.0.1:44721,DS-b1e564b6-4e96-4514-88a7-a6f998e53f47,DISK], DatanodeInfoWithStorage[127.0.0.1:34531,DS-bb7c4bc4-4ea3-460a-9fae-0698fbc8d482,DISK], DatanodeInfoWithStorage[127.0.0.1:35517,DS-2581afc0-cc29-4cd5-a176-93d5d436c846,DISK], DatanodeInfoWithStorage[127.0.0.1:45486,DS-8803d822-e50f-4213-9e0f-d15acb1275cf,DISK], DatanodeInfoWithStorage[127.0.0.1:43862,DS-8b8acc40-d097-4a85-9d54-abd15cb90f58,DISK], DatanodeInfoWithStorage[127.0.0.1:45247,DS-8c3588ae-a941-474e-ba22-51de8cb2e9d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36042,DS-70523a54-95c3-4b80-913b-a41960a1a04e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1685523945-172.17.0.12-1596927062208:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43604,DS-186f2405-7f77-48d2-acb6-0fca0bf65b25,DISK], DatanodeInfoWithStorage[127.0.0.1:46855,DS-a9da474f-0b9a-4e21-b7a0-052a7f91864d,DISK], DatanodeInfoWithStorage[127.0.0.1:46802,DS-4e8d4531-b0e4-470c-bdc2-f17d9d0d8644,DISK], DatanodeInfoWithStorage[127.0.0.1:42498,DS-b12ef055-2f50-4c82-a932-7c00770abce7,DISK], DatanodeInfoWithStorage[127.0.0.1:37828,DS-2bbf6a91-a1a0-4c95-92e0-f419fd82dd63,DISK], DatanodeInfoWithStorage[127.0.0.1:37747,DS-a885e01a-47f3-4f3f-9fdb-2a8ae93db778,DISK], DatanodeInfoWithStorage[127.0.0.1:41989,DS-421573f3-1585-4eb0-8a4b-5da39c36efec,DISK], DatanodeInfoWithStorage[127.0.0.1:34035,DS-7e043343-8fac-422c-808d-8c6dae1c4980,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1685523945-172.17.0.12-1596927062208:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43604,DS-186f2405-7f77-48d2-acb6-0fca0bf65b25,DISK], DatanodeInfoWithStorage[127.0.0.1:46855,DS-a9da474f-0b9a-4e21-b7a0-052a7f91864d,DISK], DatanodeInfoWithStorage[127.0.0.1:46802,DS-4e8d4531-b0e4-470c-bdc2-f17d9d0d8644,DISK], DatanodeInfoWithStorage[127.0.0.1:42498,DS-b12ef055-2f50-4c82-a932-7c00770abce7,DISK], DatanodeInfoWithStorage[127.0.0.1:37828,DS-2bbf6a91-a1a0-4c95-92e0-f419fd82dd63,DISK], DatanodeInfoWithStorage[127.0.0.1:37747,DS-a885e01a-47f3-4f3f-9fdb-2a8ae93db778,DISK], DatanodeInfoWithStorage[127.0.0.1:41989,DS-421573f3-1585-4eb0-8a4b-5da39c36efec,DISK], DatanodeInfoWithStorage[127.0.0.1:34035,DS-7e043343-8fac-422c-808d-8c6dae1c4980,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-852264263-172.17.0.12-1596927190448:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39514,DS-5eda8468-5a24-46f8-af23-c587ff39cb87,DISK], DatanodeInfoWithStorage[127.0.0.1:45346,DS-be9b3582-170a-4683-ba92-21fbcf98a2a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42287,DS-356252b5-44fe-4996-a4d9-d57e62417d8d,DISK], DatanodeInfoWithStorage[127.0.0.1:36867,DS-1892235f-1a8e-44d9-af15-4210020a209f,DISK], DatanodeInfoWithStorage[127.0.0.1:38532,DS-f6830408-0c83-4639-b045-b5c02e70a9fd,DISK], DatanodeInfoWithStorage[127.0.0.1:35992,DS-25fbc9b9-6648-43d6-abe7-38010f69156c,DISK], DatanodeInfoWithStorage[127.0.0.1:43027,DS-451a6253-1d0b-46b9-a11b-4320e430b240,DISK], DatanodeInfoWithStorage[127.0.0.1:35512,DS-f3314f92-89d2-46a7-91cd-333e1d6a934b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-852264263-172.17.0.12-1596927190448:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39514,DS-5eda8468-5a24-46f8-af23-c587ff39cb87,DISK], DatanodeInfoWithStorage[127.0.0.1:45346,DS-be9b3582-170a-4683-ba92-21fbcf98a2a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42287,DS-356252b5-44fe-4996-a4d9-d57e62417d8d,DISK], DatanodeInfoWithStorage[127.0.0.1:36867,DS-1892235f-1a8e-44d9-af15-4210020a209f,DISK], DatanodeInfoWithStorage[127.0.0.1:38532,DS-f6830408-0c83-4639-b045-b5c02e70a9fd,DISK], DatanodeInfoWithStorage[127.0.0.1:35992,DS-25fbc9b9-6648-43d6-abe7-38010f69156c,DISK], DatanodeInfoWithStorage[127.0.0.1:43027,DS-451a6253-1d0b-46b9-a11b-4320e430b240,DISK], DatanodeInfoWithStorage[127.0.0.1:35512,DS-f3314f92-89d2-46a7-91cd-333e1d6a934b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1503415297-172.17.0.12-1596927704402:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33648,DS-8c0d00c3-4409-46b8-b98a-b34a9677de5d,DISK], DatanodeInfoWithStorage[127.0.0.1:36786,DS-20467c97-a8ab-49c6-9a70-7747c51bd64b,DISK], DatanodeInfoWithStorage[127.0.0.1:40146,DS-e10c4b58-9fa7-4549-9c24-95018977c1e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42516,DS-2a3c9258-b4bd-4c97-a7f2-ccfffd15eb4f,DISK], DatanodeInfoWithStorage[127.0.0.1:38248,DS-1d362fe9-3e11-4686-9753-a450fbe7cb62,DISK], DatanodeInfoWithStorage[127.0.0.1:38379,DS-428a51f6-31b2-4bec-a794-b5b7c4e88fee,DISK], DatanodeInfoWithStorage[127.0.0.1:38921,DS-83fa0fb1-b0d7-4cc6-9e1e-c23bf0b563dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37924,DS-46a912b7-8f73-4077-bd6e-9fbf73ca96cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1503415297-172.17.0.12-1596927704402:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33648,DS-8c0d00c3-4409-46b8-b98a-b34a9677de5d,DISK], DatanodeInfoWithStorage[127.0.0.1:36786,DS-20467c97-a8ab-49c6-9a70-7747c51bd64b,DISK], DatanodeInfoWithStorage[127.0.0.1:40146,DS-e10c4b58-9fa7-4549-9c24-95018977c1e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42516,DS-2a3c9258-b4bd-4c97-a7f2-ccfffd15eb4f,DISK], DatanodeInfoWithStorage[127.0.0.1:38248,DS-1d362fe9-3e11-4686-9753-a450fbe7cb62,DISK], DatanodeInfoWithStorage[127.0.0.1:38379,DS-428a51f6-31b2-4bec-a794-b5b7c4e88fee,DISK], DatanodeInfoWithStorage[127.0.0.1:38921,DS-83fa0fb1-b0d7-4cc6-9e1e-c23bf0b563dd,DISK], DatanodeInfoWithStorage[127.0.0.1:37924,DS-46a912b7-8f73-4077-bd6e-9fbf73ca96cb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1486971909-172.17.0.12-1596927950967:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36102,DS-f975cdba-ab38-4ea1-b8fe-1d7e31e4cc76,DISK], DatanodeInfoWithStorage[127.0.0.1:37005,DS-7c3ba5c0-7444-4209-9bcd-9dfe68a541b6,DISK], DatanodeInfoWithStorage[127.0.0.1:42062,DS-a84b2d5f-6a6f-46d7-b1fb-ad6d3aca8357,DISK], DatanodeInfoWithStorage[127.0.0.1:37641,DS-92330209-aade-498f-86e4-f95082fc1031,DISK], DatanodeInfoWithStorage[127.0.0.1:45805,DS-cbd58079-4597-4491-b5a4-75cb7451b47a,DISK], DatanodeInfoWithStorage[127.0.0.1:41290,DS-4103eff0-aea6-437f-af5d-02eeebac6f63,DISK], DatanodeInfoWithStorage[127.0.0.1:34913,DS-33884bb6-dd3e-48c5-8e95-503c85764b08,DISK], DatanodeInfoWithStorage[127.0.0.1:33176,DS-7c899658-f377-4f4c-ab73-65906c71c31a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1486971909-172.17.0.12-1596927950967:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36102,DS-f975cdba-ab38-4ea1-b8fe-1d7e31e4cc76,DISK], DatanodeInfoWithStorage[127.0.0.1:37005,DS-7c3ba5c0-7444-4209-9bcd-9dfe68a541b6,DISK], DatanodeInfoWithStorage[127.0.0.1:42062,DS-a84b2d5f-6a6f-46d7-b1fb-ad6d3aca8357,DISK], DatanodeInfoWithStorage[127.0.0.1:37641,DS-92330209-aade-498f-86e4-f95082fc1031,DISK], DatanodeInfoWithStorage[127.0.0.1:45805,DS-cbd58079-4597-4491-b5a4-75cb7451b47a,DISK], DatanodeInfoWithStorage[127.0.0.1:41290,DS-4103eff0-aea6-437f-af5d-02eeebac6f63,DISK], DatanodeInfoWithStorage[127.0.0.1:34913,DS-33884bb6-dd3e-48c5-8e95-503c85764b08,DISK], DatanodeInfoWithStorage[127.0.0.1:33176,DS-7c899658-f377-4f4c-ab73-65906c71c31a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-39190523-172.17.0.12-1596928234557:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42607,DS-385772f1-f314-45d9-ae5b-e7f6a57b5387,DISK], DatanodeInfoWithStorage[127.0.0.1:45504,DS-eaf62088-a864-496e-95fc-b7d8747ec552,DISK], DatanodeInfoWithStorage[127.0.0.1:46439,DS-50d1374f-356d-4bf8-8f74-4329f48f9d97,DISK], DatanodeInfoWithStorage[127.0.0.1:35596,DS-758c877f-6c48-4235-a532-f18d4adffae7,DISK], DatanodeInfoWithStorage[127.0.0.1:35616,DS-73342934-bbd2-472a-907a-2cb33117751e,DISK], DatanodeInfoWithStorage[127.0.0.1:33438,DS-f9b8387c-630a-41d8-ab62-60c52befd3ba,DISK], DatanodeInfoWithStorage[127.0.0.1:46444,DS-eb12403f-5a85-4a01-a565-6b471f5eccf1,DISK], DatanodeInfoWithStorage[127.0.0.1:45197,DS-53553d41-e283-4aa8-aa25-aefa746d5658,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-39190523-172.17.0.12-1596928234557:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42607,DS-385772f1-f314-45d9-ae5b-e7f6a57b5387,DISK], DatanodeInfoWithStorage[127.0.0.1:45504,DS-eaf62088-a864-496e-95fc-b7d8747ec552,DISK], DatanodeInfoWithStorage[127.0.0.1:46439,DS-50d1374f-356d-4bf8-8f74-4329f48f9d97,DISK], DatanodeInfoWithStorage[127.0.0.1:35596,DS-758c877f-6c48-4235-a532-f18d4adffae7,DISK], DatanodeInfoWithStorage[127.0.0.1:35616,DS-73342934-bbd2-472a-907a-2cb33117751e,DISK], DatanodeInfoWithStorage[127.0.0.1:33438,DS-f9b8387c-630a-41d8-ab62-60c52befd3ba,DISK], DatanodeInfoWithStorage[127.0.0.1:46444,DS-eb12403f-5a85-4a01-a565-6b471f5eccf1,DISK], DatanodeInfoWithStorage[127.0.0.1:45197,DS-53553d41-e283-4aa8-aa25-aefa746d5658,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-424086036-172.17.0.12-1596928358600:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37532,DS-f866b816-3b9a-4a6b-9345-240dd4199cd6,DISK], DatanodeInfoWithStorage[127.0.0.1:41536,DS-bd560b11-ec65-4984-9cb6-5789b4b2863b,DISK], DatanodeInfoWithStorage[127.0.0.1:42344,DS-73893053-0c9e-40d5-8d81-784d7b8332b6,DISK], DatanodeInfoWithStorage[127.0.0.1:42857,DS-d8a3c5fa-f75a-45a9-8b5b-004e7e0a7866,DISK], DatanodeInfoWithStorage[127.0.0.1:37788,DS-bfa891aa-dbf8-45d1-a139-13f7d434ad77,DISK], DatanodeInfoWithStorage[127.0.0.1:45162,DS-033fbb31-57e4-415b-b995-a4e3761bd129,DISK], DatanodeInfoWithStorage[127.0.0.1:40469,DS-07e9270d-0eec-4832-8d67-a2257792afd5,DISK], DatanodeInfoWithStorage[127.0.0.1:46706,DS-aa26f1b9-3eba-44d9-ae6a-99d2995360a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-424086036-172.17.0.12-1596928358600:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37532,DS-f866b816-3b9a-4a6b-9345-240dd4199cd6,DISK], DatanodeInfoWithStorage[127.0.0.1:41536,DS-bd560b11-ec65-4984-9cb6-5789b4b2863b,DISK], DatanodeInfoWithStorage[127.0.0.1:42344,DS-73893053-0c9e-40d5-8d81-784d7b8332b6,DISK], DatanodeInfoWithStorage[127.0.0.1:42857,DS-d8a3c5fa-f75a-45a9-8b5b-004e7e0a7866,DISK], DatanodeInfoWithStorage[127.0.0.1:37788,DS-bfa891aa-dbf8-45d1-a139-13f7d434ad77,DISK], DatanodeInfoWithStorage[127.0.0.1:45162,DS-033fbb31-57e4-415b-b995-a4e3761bd129,DISK], DatanodeInfoWithStorage[127.0.0.1:40469,DS-07e9270d-0eec-4832-8d67-a2257792afd5,DISK], DatanodeInfoWithStorage[127.0.0.1:46706,DS-aa26f1b9-3eba-44d9-ae6a-99d2995360a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5293
