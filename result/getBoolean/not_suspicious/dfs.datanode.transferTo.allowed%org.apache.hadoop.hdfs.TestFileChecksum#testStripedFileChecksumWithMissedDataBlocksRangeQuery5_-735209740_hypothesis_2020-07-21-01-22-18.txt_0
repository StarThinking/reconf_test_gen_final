reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1200991559-172.17.0.6-1595294812497:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44181,DS-de35b421-f6a4-4c3e-9c7e-4eac053594dc,DISK], DatanodeInfoWithStorage[127.0.0.1:32991,DS-0885e84c-0c81-498c-b362-9a30e6a0b967,DISK], DatanodeInfoWithStorage[127.0.0.1:45992,DS-f01a4878-e70b-42b8-8acb-1faf331c2c31,DISK], DatanodeInfoWithStorage[127.0.0.1:42100,DS-9641feb4-8ad8-41f3-816f-96e3ebc26fc4,DISK], DatanodeInfoWithStorage[127.0.0.1:35024,DS-9c0042fd-14fd-42b3-9a9a-724ea7ab7aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:41089,DS-5670e8af-90b2-403e-bf62-72353942fd21,DISK], DatanodeInfoWithStorage[127.0.0.1:33461,DS-573a2911-0b12-4157-98c1-5ae277305a12,DISK], DatanodeInfoWithStorage[127.0.0.1:43462,DS-9ad8b36f-5b0d-46b9-bb55-230dc1bea90b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1200991559-172.17.0.6-1595294812497:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44181,DS-de35b421-f6a4-4c3e-9c7e-4eac053594dc,DISK], DatanodeInfoWithStorage[127.0.0.1:32991,DS-0885e84c-0c81-498c-b362-9a30e6a0b967,DISK], DatanodeInfoWithStorage[127.0.0.1:45992,DS-f01a4878-e70b-42b8-8acb-1faf331c2c31,DISK], DatanodeInfoWithStorage[127.0.0.1:42100,DS-9641feb4-8ad8-41f3-816f-96e3ebc26fc4,DISK], DatanodeInfoWithStorage[127.0.0.1:35024,DS-9c0042fd-14fd-42b3-9a9a-724ea7ab7aaf,DISK], DatanodeInfoWithStorage[127.0.0.1:41089,DS-5670e8af-90b2-403e-bf62-72353942fd21,DISK], DatanodeInfoWithStorage[127.0.0.1:33461,DS-573a2911-0b12-4157-98c1-5ae277305a12,DISK], DatanodeInfoWithStorage[127.0.0.1:43462,DS-9ad8b36f-5b0d-46b9-bb55-230dc1bea90b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-144801890-172.17.0.6-1595294953411:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38245,DS-e019a2c1-048d-444d-8094-49da222b9c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:43613,DS-61917e10-d51a-42cd-b198-df26cd847ffd,DISK], DatanodeInfoWithStorage[127.0.0.1:40463,DS-d8cb4671-9d78-4080-a364-8fe3492cf505,DISK], DatanodeInfoWithStorage[127.0.0.1:38325,DS-5f1b9c4a-6610-4399-97cc-827ee16f5fd0,DISK], DatanodeInfoWithStorage[127.0.0.1:33728,DS-c01b437b-a185-4bd6-8aff-e06f708a0157,DISK], DatanodeInfoWithStorage[127.0.0.1:37039,DS-5f38e05a-b78e-48a2-bdfa-294f89bb82b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41501,DS-3113ef14-783b-4711-b483-5b8588709f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:43534,DS-8900afe5-1cc8-4230-9562-1714edd296e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-144801890-172.17.0.6-1595294953411:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38245,DS-e019a2c1-048d-444d-8094-49da222b9c7c,DISK], DatanodeInfoWithStorage[127.0.0.1:43613,DS-61917e10-d51a-42cd-b198-df26cd847ffd,DISK], DatanodeInfoWithStorage[127.0.0.1:40463,DS-d8cb4671-9d78-4080-a364-8fe3492cf505,DISK], DatanodeInfoWithStorage[127.0.0.1:38325,DS-5f1b9c4a-6610-4399-97cc-827ee16f5fd0,DISK], DatanodeInfoWithStorage[127.0.0.1:33728,DS-c01b437b-a185-4bd6-8aff-e06f708a0157,DISK], DatanodeInfoWithStorage[127.0.0.1:37039,DS-5f38e05a-b78e-48a2-bdfa-294f89bb82b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41501,DS-3113ef14-783b-4711-b483-5b8588709f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:43534,DS-8900afe5-1cc8-4230-9562-1714edd296e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-536283170-172.17.0.6-1595295658460:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44554,DS-3b7e219b-6b69-4f0a-ae7f-9010c896ef77,DISK], DatanodeInfoWithStorage[127.0.0.1:46047,DS-a7ad56c6-f14d-4d58-8aef-5e9a1eab3327,DISK], DatanodeInfoWithStorage[127.0.0.1:44058,DS-108a92f6-7adc-4c08-ba82-ff6dc7688cce,DISK], DatanodeInfoWithStorage[127.0.0.1:39189,DS-5c8acfec-f82e-441a-aa94-c7f4f9e6c36e,DISK], DatanodeInfoWithStorage[127.0.0.1:35287,DS-348becd1-ba39-4ee7-887e-f0e36c7e4faf,DISK], DatanodeInfoWithStorage[127.0.0.1:34413,DS-4d524a50-3eff-4f60-a1c3-682692217b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:45400,DS-79f2ee03-98ad-4dab-b477-a86c9729fa2a,DISK], DatanodeInfoWithStorage[127.0.0.1:39102,DS-7f8d4d01-7b13-40b3-b92e-cef26475d3e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-536283170-172.17.0.6-1595295658460:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44554,DS-3b7e219b-6b69-4f0a-ae7f-9010c896ef77,DISK], DatanodeInfoWithStorage[127.0.0.1:46047,DS-a7ad56c6-f14d-4d58-8aef-5e9a1eab3327,DISK], DatanodeInfoWithStorage[127.0.0.1:44058,DS-108a92f6-7adc-4c08-ba82-ff6dc7688cce,DISK], DatanodeInfoWithStorage[127.0.0.1:39189,DS-5c8acfec-f82e-441a-aa94-c7f4f9e6c36e,DISK], DatanodeInfoWithStorage[127.0.0.1:35287,DS-348becd1-ba39-4ee7-887e-f0e36c7e4faf,DISK], DatanodeInfoWithStorage[127.0.0.1:34413,DS-4d524a50-3eff-4f60-a1c3-682692217b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:45400,DS-79f2ee03-98ad-4dab-b477-a86c9729fa2a,DISK], DatanodeInfoWithStorage[127.0.0.1:39102,DS-7f8d4d01-7b13-40b3-b92e-cef26475d3e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1451607462-172.17.0.6-1595295705680:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45209,DS-58dc743f-1c31-44a5-b785-fd78288641cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37092,DS-553eeaa6-d49d-4b8c-8554-00f2781ba195,DISK], DatanodeInfoWithStorage[127.0.0.1:43380,DS-cb9c9fdd-0af7-4574-aa66-2ddcbc722e53,DISK], DatanodeInfoWithStorage[127.0.0.1:39748,DS-8e7afb63-434a-4fda-94aa-8dfac232f3dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35318,DS-632445d8-66d4-472f-9054-5399290929e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42546,DS-4500365d-5856-4f0b-83a4-8e5f14534be8,DISK], DatanodeInfoWithStorage[127.0.0.1:32842,DS-3e112b8a-1f2c-4274-8b5b-98231c86b8e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34435,DS-7c34ee96-0e87-4b85-9ec7-e0e15a3b194e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1451607462-172.17.0.6-1595295705680:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45209,DS-58dc743f-1c31-44a5-b785-fd78288641cb,DISK], DatanodeInfoWithStorage[127.0.0.1:37092,DS-553eeaa6-d49d-4b8c-8554-00f2781ba195,DISK], DatanodeInfoWithStorage[127.0.0.1:43380,DS-cb9c9fdd-0af7-4574-aa66-2ddcbc722e53,DISK], DatanodeInfoWithStorage[127.0.0.1:39748,DS-8e7afb63-434a-4fda-94aa-8dfac232f3dc,DISK], DatanodeInfoWithStorage[127.0.0.1:35318,DS-632445d8-66d4-472f-9054-5399290929e0,DISK], DatanodeInfoWithStorage[127.0.0.1:42546,DS-4500365d-5856-4f0b-83a4-8e5f14534be8,DISK], DatanodeInfoWithStorage[127.0.0.1:32842,DS-3e112b8a-1f2c-4274-8b5b-98231c86b8e1,DISK], DatanodeInfoWithStorage[127.0.0.1:34435,DS-7c34ee96-0e87-4b85-9ec7-e0e15a3b194e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1889125297-172.17.0.6-1595295755454:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44389,DS-d1c43301-8cc4-46a6-89c8-71ac4e4a47e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35248,DS-2a485b96-dae2-4c3a-914c-444b384c4255,DISK], DatanodeInfoWithStorage[127.0.0.1:35368,DS-2db0a7d0-0e72-4321-90ac-53e223ae4a85,DISK], DatanodeInfoWithStorage[127.0.0.1:37994,DS-2f9362c7-a07e-4b45-af3e-e961dafcb68c,DISK], DatanodeInfoWithStorage[127.0.0.1:36388,DS-db684d27-f7bc-4bc7-975f-395f6b05f4b8,DISK], DatanodeInfoWithStorage[127.0.0.1:38579,DS-26b286bf-66db-4966-84ce-a9e0dc2ccce4,DISK], DatanodeInfoWithStorage[127.0.0.1:40092,DS-e2175ba4-cb20-474a-a143-e4c8d96a36ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34240,DS-93567288-c9e0-4195-8795-43c8e0677218,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1889125297-172.17.0.6-1595295755454:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44389,DS-d1c43301-8cc4-46a6-89c8-71ac4e4a47e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35248,DS-2a485b96-dae2-4c3a-914c-444b384c4255,DISK], DatanodeInfoWithStorage[127.0.0.1:35368,DS-2db0a7d0-0e72-4321-90ac-53e223ae4a85,DISK], DatanodeInfoWithStorage[127.0.0.1:37994,DS-2f9362c7-a07e-4b45-af3e-e961dafcb68c,DISK], DatanodeInfoWithStorage[127.0.0.1:36388,DS-db684d27-f7bc-4bc7-975f-395f6b05f4b8,DISK], DatanodeInfoWithStorage[127.0.0.1:38579,DS-26b286bf-66db-4966-84ce-a9e0dc2ccce4,DISK], DatanodeInfoWithStorage[127.0.0.1:40092,DS-e2175ba4-cb20-474a-a143-e4c8d96a36ce,DISK], DatanodeInfoWithStorage[127.0.0.1:34240,DS-93567288-c9e0-4195-8795-43c8e0677218,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-312764286-172.17.0.6-1595295807457:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40690,DS-d462ef8e-d3cf-4299-99e3-2aef7bdbe3e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44233,DS-bca9fc7e-0ce6-455d-8439-06b62fa6b89c,DISK], DatanodeInfoWithStorage[127.0.0.1:41935,DS-0e360efd-d307-435e-bcaf-2848b9b9bcb3,DISK], DatanodeInfoWithStorage[127.0.0.1:35814,DS-ffe94d67-5508-47ca-9482-b966aa5178ee,DISK], DatanodeInfoWithStorage[127.0.0.1:46433,DS-c2718941-50ff-4fbd-af5e-e8379e6c9198,DISK], DatanodeInfoWithStorage[127.0.0.1:45828,DS-88a99fcc-a8ff-4a8b-b934-63f60524783b,DISK], DatanodeInfoWithStorage[127.0.0.1:44293,DS-30febddb-a350-489d-81f1-1c019d0ff62f,DISK], DatanodeInfoWithStorage[127.0.0.1:44960,DS-70228fe1-75df-46c5-a09e-a97e9023af36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-312764286-172.17.0.6-1595295807457:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40690,DS-d462ef8e-d3cf-4299-99e3-2aef7bdbe3e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44233,DS-bca9fc7e-0ce6-455d-8439-06b62fa6b89c,DISK], DatanodeInfoWithStorage[127.0.0.1:41935,DS-0e360efd-d307-435e-bcaf-2848b9b9bcb3,DISK], DatanodeInfoWithStorage[127.0.0.1:35814,DS-ffe94d67-5508-47ca-9482-b966aa5178ee,DISK], DatanodeInfoWithStorage[127.0.0.1:46433,DS-c2718941-50ff-4fbd-af5e-e8379e6c9198,DISK], DatanodeInfoWithStorage[127.0.0.1:45828,DS-88a99fcc-a8ff-4a8b-b934-63f60524783b,DISK], DatanodeInfoWithStorage[127.0.0.1:44293,DS-30febddb-a350-489d-81f1-1c019d0ff62f,DISK], DatanodeInfoWithStorage[127.0.0.1:44960,DS-70228fe1-75df-46c5-a09e-a97e9023af36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1933956861-172.17.0.6-1595295988958:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44639,DS-f270c735-1931-4e81-b65c-091f853c650e,DISK], DatanodeInfoWithStorage[127.0.0.1:38091,DS-4156113e-a48b-4705-9e01-3ae7885b71d5,DISK], DatanodeInfoWithStorage[127.0.0.1:39080,DS-179661a4-85c2-4c43-b36b-e54fa284050a,DISK], DatanodeInfoWithStorage[127.0.0.1:40019,DS-201df214-e4dc-4b6a-8d2b-30c81b695a49,DISK], DatanodeInfoWithStorage[127.0.0.1:46777,DS-027c24a1-ab37-4343-b3a5-f7d7f4adfe26,DISK], DatanodeInfoWithStorage[127.0.0.1:34994,DS-9c4fd89f-035d-45ca-bda2-40251bd49d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:42781,DS-eca80215-db79-465a-b233-d4c88afea964,DISK], DatanodeInfoWithStorage[127.0.0.1:43547,DS-8b252563-d242-41d1-9c5c-bc628f11589e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1933956861-172.17.0.6-1595295988958:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44639,DS-f270c735-1931-4e81-b65c-091f853c650e,DISK], DatanodeInfoWithStorage[127.0.0.1:38091,DS-4156113e-a48b-4705-9e01-3ae7885b71d5,DISK], DatanodeInfoWithStorage[127.0.0.1:39080,DS-179661a4-85c2-4c43-b36b-e54fa284050a,DISK], DatanodeInfoWithStorage[127.0.0.1:40019,DS-201df214-e4dc-4b6a-8d2b-30c81b695a49,DISK], DatanodeInfoWithStorage[127.0.0.1:46777,DS-027c24a1-ab37-4343-b3a5-f7d7f4adfe26,DISK], DatanodeInfoWithStorage[127.0.0.1:34994,DS-9c4fd89f-035d-45ca-bda2-40251bd49d0e,DISK], DatanodeInfoWithStorage[127.0.0.1:42781,DS-eca80215-db79-465a-b233-d4c88afea964,DISK], DatanodeInfoWithStorage[127.0.0.1:43547,DS-8b252563-d242-41d1-9c5c-bc628f11589e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-472969827-172.17.0.6-1595296118467:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46694,DS-61d8128e-d894-4c64-a109-2a36147ec71d,DISK], DatanodeInfoWithStorage[127.0.0.1:43361,DS-b12ee7b1-bbd3-4e70-82ca-ea02c52dc498,DISK], DatanodeInfoWithStorage[127.0.0.1:34388,DS-a8ba3859-6e81-4a23-b6f4-952b5cd7dc4d,DISK], DatanodeInfoWithStorage[127.0.0.1:43969,DS-0882a858-01ad-42b6-9390-6c3a5f6017af,DISK], DatanodeInfoWithStorage[127.0.0.1:37531,DS-ed4522db-bc7c-4175-9b6f-f616a6b2eb2d,DISK], DatanodeInfoWithStorage[127.0.0.1:37708,DS-0e2ce75c-3114-4898-9b79-a192a5bfe43c,DISK], DatanodeInfoWithStorage[127.0.0.1:36511,DS-a3212f66-a96f-40f2-a1b6-3e35443d53b0,DISK], DatanodeInfoWithStorage[127.0.0.1:34497,DS-aa3254f7-3ae9-4f94-87c1-2dcc9652db86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-472969827-172.17.0.6-1595296118467:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46694,DS-61d8128e-d894-4c64-a109-2a36147ec71d,DISK], DatanodeInfoWithStorage[127.0.0.1:43361,DS-b12ee7b1-bbd3-4e70-82ca-ea02c52dc498,DISK], DatanodeInfoWithStorage[127.0.0.1:34388,DS-a8ba3859-6e81-4a23-b6f4-952b5cd7dc4d,DISK], DatanodeInfoWithStorage[127.0.0.1:43969,DS-0882a858-01ad-42b6-9390-6c3a5f6017af,DISK], DatanodeInfoWithStorage[127.0.0.1:37531,DS-ed4522db-bc7c-4175-9b6f-f616a6b2eb2d,DISK], DatanodeInfoWithStorage[127.0.0.1:37708,DS-0e2ce75c-3114-4898-9b79-a192a5bfe43c,DISK], DatanodeInfoWithStorage[127.0.0.1:36511,DS-a3212f66-a96f-40f2-a1b6-3e35443d53b0,DISK], DatanodeInfoWithStorage[127.0.0.1:34497,DS-aa3254f7-3ae9-4f94-87c1-2dcc9652db86,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1910754889-172.17.0.6-1595296216018:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36910,DS-ee568021-9d3c-4612-86d1-193c4c7922ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34801,DS-6b4aea33-d2e4-4245-9b0a-796fd920a133,DISK], DatanodeInfoWithStorage[127.0.0.1:36166,DS-3fadd40f-ad09-439d-b478-2db33b3194af,DISK], DatanodeInfoWithStorage[127.0.0.1:41020,DS-aac13033-4814-4af2-b69d-a019e320d9eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44214,DS-a32b17ac-5ea1-4d00-aa39-95ffe7c4a6cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38472,DS-2888d3d2-6205-4c8b-9d73-57da8ce742e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38929,DS-448bdd96-e229-4495-b69f-98309c9e40a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36568,DS-2fc67fc5-5256-4181-9550-75f08e1a731e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1910754889-172.17.0.6-1595296216018:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36910,DS-ee568021-9d3c-4612-86d1-193c4c7922ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34801,DS-6b4aea33-d2e4-4245-9b0a-796fd920a133,DISK], DatanodeInfoWithStorage[127.0.0.1:36166,DS-3fadd40f-ad09-439d-b478-2db33b3194af,DISK], DatanodeInfoWithStorage[127.0.0.1:41020,DS-aac13033-4814-4af2-b69d-a019e320d9eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44214,DS-a32b17ac-5ea1-4d00-aa39-95ffe7c4a6cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38472,DS-2888d3d2-6205-4c8b-9d73-57da8ce742e5,DISK], DatanodeInfoWithStorage[127.0.0.1:38929,DS-448bdd96-e229-4495-b69f-98309c9e40a7,DISK], DatanodeInfoWithStorage[127.0.0.1:36568,DS-2fc67fc5-5256-4181-9550-75f08e1a731e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1626131933-172.17.0.6-1595296380184:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36610,DS-bd223201-5487-4ea9-864b-a35762d0d686,DISK], DatanodeInfoWithStorage[127.0.0.1:33701,DS-2c8afeb0-4437-4867-818f-fa8024d86654,DISK], DatanodeInfoWithStorage[127.0.0.1:35701,DS-b0912a84-f2a0-440e-886f-ec8f58a8781c,DISK], DatanodeInfoWithStorage[127.0.0.1:38426,DS-536a3ced-5780-43ca-ab34-bddd7604c77f,DISK], DatanodeInfoWithStorage[127.0.0.1:37013,DS-fce6c648-e907-4985-aa25-7ec10a2ecb16,DISK], DatanodeInfoWithStorage[127.0.0.1:43853,DS-c00993f1-b684-4791-b8b5-b4b4a8ee479b,DISK], DatanodeInfoWithStorage[127.0.0.1:42666,DS-7c452c05-2ead-47b4-8bb4-b59165bc18ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46625,DS-17e5b347-e21c-4618-8d51-670b9f6a8678,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1626131933-172.17.0.6-1595296380184:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36610,DS-bd223201-5487-4ea9-864b-a35762d0d686,DISK], DatanodeInfoWithStorage[127.0.0.1:33701,DS-2c8afeb0-4437-4867-818f-fa8024d86654,DISK], DatanodeInfoWithStorage[127.0.0.1:35701,DS-b0912a84-f2a0-440e-886f-ec8f58a8781c,DISK], DatanodeInfoWithStorage[127.0.0.1:38426,DS-536a3ced-5780-43ca-ab34-bddd7604c77f,DISK], DatanodeInfoWithStorage[127.0.0.1:37013,DS-fce6c648-e907-4985-aa25-7ec10a2ecb16,DISK], DatanodeInfoWithStorage[127.0.0.1:43853,DS-c00993f1-b684-4791-b8b5-b4b4a8ee479b,DISK], DatanodeInfoWithStorage[127.0.0.1:42666,DS-7c452c05-2ead-47b4-8bb4-b59165bc18ec,DISK], DatanodeInfoWithStorage[127.0.0.1:46625,DS-17e5b347-e21c-4618-8d51-670b9f6a8678,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-882694908-172.17.0.6-1595296469956:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43171,DS-71913812-0981-475e-a046-21dd8e17333c,DISK], DatanodeInfoWithStorage[127.0.0.1:40673,DS-b09ea62a-85c2-4b90-ab15-3abfc86bbf18,DISK], DatanodeInfoWithStorage[127.0.0.1:43658,DS-7d0e317f-a805-44d7-adbf-baf4e92006ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36627,DS-36e5547c-7eca-4bbd-9cd6-58cc117d532e,DISK], DatanodeInfoWithStorage[127.0.0.1:43550,DS-c03e2c5b-a794-45e9-a83d-78fab75f995e,DISK], DatanodeInfoWithStorage[127.0.0.1:34541,DS-c717f09f-a45d-47ce-9b67-9c2a462f94bb,DISK], DatanodeInfoWithStorage[127.0.0.1:42867,DS-f9844dcb-8466-4d11-9b7e-0350e7b5c05f,DISK], DatanodeInfoWithStorage[127.0.0.1:34452,DS-be9035fa-9860-4a07-8b31-a49dbf42c14f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-882694908-172.17.0.6-1595296469956:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43171,DS-71913812-0981-475e-a046-21dd8e17333c,DISK], DatanodeInfoWithStorage[127.0.0.1:40673,DS-b09ea62a-85c2-4b90-ab15-3abfc86bbf18,DISK], DatanodeInfoWithStorage[127.0.0.1:43658,DS-7d0e317f-a805-44d7-adbf-baf4e92006ec,DISK], DatanodeInfoWithStorage[127.0.0.1:36627,DS-36e5547c-7eca-4bbd-9cd6-58cc117d532e,DISK], DatanodeInfoWithStorage[127.0.0.1:43550,DS-c03e2c5b-a794-45e9-a83d-78fab75f995e,DISK], DatanodeInfoWithStorage[127.0.0.1:34541,DS-c717f09f-a45d-47ce-9b67-9c2a462f94bb,DISK], DatanodeInfoWithStorage[127.0.0.1:42867,DS-f9844dcb-8466-4d11-9b7e-0350e7b5c05f,DISK], DatanodeInfoWithStorage[127.0.0.1:34452,DS-be9035fa-9860-4a07-8b31-a49dbf42c14f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-141192002-172.17.0.6-1595297097459:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35231,DS-59c3e0da-72ee-4c60-92e9-e73bf135cadd,DISK], DatanodeInfoWithStorage[127.0.0.1:41617,DS-e0475376-af3a-450c-86d8-8d95b559d723,DISK], DatanodeInfoWithStorage[127.0.0.1:33896,DS-dcee40f0-f11a-4e03-b907-04e0e3ff9646,DISK], DatanodeInfoWithStorage[127.0.0.1:38508,DS-0c3636fe-7e09-4b0f-8551-b9216dad7ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:42720,DS-cf2927fa-27fc-44a5-a7b9-9ce287dbf730,DISK], DatanodeInfoWithStorage[127.0.0.1:33663,DS-0ee76e90-dfc9-4c4f-a20f-94774dc3e4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43611,DS-3fb34e41-5cf9-477a-8b23-14fe5f0dfe83,DISK], DatanodeInfoWithStorage[127.0.0.1:39936,DS-b7366b7a-caf6-422b-87b1-d6043cebab22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-141192002-172.17.0.6-1595297097459:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35231,DS-59c3e0da-72ee-4c60-92e9-e73bf135cadd,DISK], DatanodeInfoWithStorage[127.0.0.1:41617,DS-e0475376-af3a-450c-86d8-8d95b559d723,DISK], DatanodeInfoWithStorage[127.0.0.1:33896,DS-dcee40f0-f11a-4e03-b907-04e0e3ff9646,DISK], DatanodeInfoWithStorage[127.0.0.1:38508,DS-0c3636fe-7e09-4b0f-8551-b9216dad7ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:42720,DS-cf2927fa-27fc-44a5-a7b9-9ce287dbf730,DISK], DatanodeInfoWithStorage[127.0.0.1:33663,DS-0ee76e90-dfc9-4c4f-a20f-94774dc3e4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:43611,DS-3fb34e41-5cf9-477a-8b23-14fe5f0dfe83,DISK], DatanodeInfoWithStorage[127.0.0.1:39936,DS-b7366b7a-caf6-422b-87b1-d6043cebab22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1367129632-172.17.0.6-1595297810250:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46207,DS-fc206cab-ae4e-46c7-b311-5a5bcbcde35d,DISK], DatanodeInfoWithStorage[127.0.0.1:35729,DS-863bca6e-4bc3-48ac-b656-4c2b23b40d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:38273,DS-9c63ea0b-6d89-41c6-aacb-05bfb20cabaf,DISK], DatanodeInfoWithStorage[127.0.0.1:42567,DS-82141fc9-0478-48cb-b3f8-3e23f1ca97f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44097,DS-0b5fbeac-734c-4b64-bc22-5c13a4bb1b88,DISK], DatanodeInfoWithStorage[127.0.0.1:34676,DS-c895f3b5-ff68-43dd-97c6-0b0ee2155979,DISK], DatanodeInfoWithStorage[127.0.0.1:42505,DS-6c4b2ad3-7631-4a6f-9349-b2244da54c06,DISK], DatanodeInfoWithStorage[127.0.0.1:36280,DS-7b6ad083-de9a-4922-8b6a-724566060dc3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1367129632-172.17.0.6-1595297810250:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46207,DS-fc206cab-ae4e-46c7-b311-5a5bcbcde35d,DISK], DatanodeInfoWithStorage[127.0.0.1:35729,DS-863bca6e-4bc3-48ac-b656-4c2b23b40d6f,DISK], DatanodeInfoWithStorage[127.0.0.1:38273,DS-9c63ea0b-6d89-41c6-aacb-05bfb20cabaf,DISK], DatanodeInfoWithStorage[127.0.0.1:42567,DS-82141fc9-0478-48cb-b3f8-3e23f1ca97f3,DISK], DatanodeInfoWithStorage[127.0.0.1:44097,DS-0b5fbeac-734c-4b64-bc22-5c13a4bb1b88,DISK], DatanodeInfoWithStorage[127.0.0.1:34676,DS-c895f3b5-ff68-43dd-97c6-0b0ee2155979,DISK], DatanodeInfoWithStorage[127.0.0.1:42505,DS-6c4b2ad3-7631-4a6f-9349-b2244da54c06,DISK], DatanodeInfoWithStorage[127.0.0.1:36280,DS-7b6ad083-de9a-4922-8b6a-724566060dc3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-779984792-172.17.0.6-1595297947493:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46248,DS-42620f7f-0be2-4f2a-b6bc-645613835bde,DISK], DatanodeInfoWithStorage[127.0.0.1:37083,DS-39509318-a115-4622-9629-4ed07899508a,DISK], DatanodeInfoWithStorage[127.0.0.1:44533,DS-2808c534-8109-4722-ae7c-37ae38234cb5,DISK], DatanodeInfoWithStorage[127.0.0.1:40721,DS-3c7f92ef-38be-485f-80b6-6cdf9fb7e804,DISK], DatanodeInfoWithStorage[127.0.0.1:32940,DS-26d5ffe2-bf18-435a-86f4-69fe0b0964b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42335,DS-c15a6956-2992-46bf-988d-24a08243d62c,DISK], DatanodeInfoWithStorage[127.0.0.1:37965,DS-98acbf2e-5cca-423b-b546-91aae4b18f4a,DISK], DatanodeInfoWithStorage[127.0.0.1:37964,DS-c6b7069f-9d3c-4286-ac6f-3e545cd43ffd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-779984792-172.17.0.6-1595297947493:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46248,DS-42620f7f-0be2-4f2a-b6bc-645613835bde,DISK], DatanodeInfoWithStorage[127.0.0.1:37083,DS-39509318-a115-4622-9629-4ed07899508a,DISK], DatanodeInfoWithStorage[127.0.0.1:44533,DS-2808c534-8109-4722-ae7c-37ae38234cb5,DISK], DatanodeInfoWithStorage[127.0.0.1:40721,DS-3c7f92ef-38be-485f-80b6-6cdf9fb7e804,DISK], DatanodeInfoWithStorage[127.0.0.1:32940,DS-26d5ffe2-bf18-435a-86f4-69fe0b0964b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42335,DS-c15a6956-2992-46bf-988d-24a08243d62c,DISK], DatanodeInfoWithStorage[127.0.0.1:37965,DS-98acbf2e-5cca-423b-b546-91aae4b18f4a,DISK], DatanodeInfoWithStorage[127.0.0.1:37964,DS-c6b7069f-9d3c-4286-ac6f-3e545cd43ffd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1684458260-172.17.0.6-1595298040179:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44777,DS-04969447-7f27-4441-9804-e191a931902e,DISK], DatanodeInfoWithStorage[127.0.0.1:45490,DS-c954f2a1-a4ae-470e-ba1d-730ac805a60b,DISK], DatanodeInfoWithStorage[127.0.0.1:40141,DS-a53a1f4e-068c-425e-882f-e3915d2558ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40162,DS-5656e2c2-0b65-4a64-8912-2d69e79e6e72,DISK], DatanodeInfoWithStorage[127.0.0.1:36714,DS-2a73dd42-fbb9-4e0c-94e7-8602a39cf1ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40606,DS-ebeb3947-eee7-4cc5-b5fa-d1ff4fc6db08,DISK], DatanodeInfoWithStorage[127.0.0.1:35525,DS-dc0767a4-e0c6-4930-981c-75d2ccf78038,DISK], DatanodeInfoWithStorage[127.0.0.1:42640,DS-42598d95-87d6-4d61-b2be-113f71b12478,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1684458260-172.17.0.6-1595298040179:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44777,DS-04969447-7f27-4441-9804-e191a931902e,DISK], DatanodeInfoWithStorage[127.0.0.1:45490,DS-c954f2a1-a4ae-470e-ba1d-730ac805a60b,DISK], DatanodeInfoWithStorage[127.0.0.1:40141,DS-a53a1f4e-068c-425e-882f-e3915d2558ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40162,DS-5656e2c2-0b65-4a64-8912-2d69e79e6e72,DISK], DatanodeInfoWithStorage[127.0.0.1:36714,DS-2a73dd42-fbb9-4e0c-94e7-8602a39cf1ad,DISK], DatanodeInfoWithStorage[127.0.0.1:40606,DS-ebeb3947-eee7-4cc5-b5fa-d1ff4fc6db08,DISK], DatanodeInfoWithStorage[127.0.0.1:35525,DS-dc0767a4-e0c6-4930-981c-75d2ccf78038,DISK], DatanodeInfoWithStorage[127.0.0.1:42640,DS-42598d95-87d6-4d61-b2be-113f71b12478,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-943321789-172.17.0.6-1595298175482:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33796,DS-de66cf98-569a-4b7d-9a1f-fe28abbc0d91,DISK], DatanodeInfoWithStorage[127.0.0.1:45371,DS-51784f79-4e0e-4c9f-90c2-f7498c2821fe,DISK], DatanodeInfoWithStorage[127.0.0.1:33011,DS-f9af5c3e-f1dc-49da-b458-bbb4125ce982,DISK], DatanodeInfoWithStorage[127.0.0.1:36406,DS-0cb8020b-1752-4c92-b733-5d3c8a9543f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33630,DS-8b279e03-9d5d-461f-afcb-cd4f02eb8a09,DISK], DatanodeInfoWithStorage[127.0.0.1:37786,DS-c87e6d13-95c8-4b16-b0f2-f741a4154509,DISK], DatanodeInfoWithStorage[127.0.0.1:39042,DS-6cf27874-ee7c-4ad6-944c-60d3b2b0d2a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41011,DS-2f344870-21a8-40b1-a098-5b05b045e9d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-943321789-172.17.0.6-1595298175482:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33796,DS-de66cf98-569a-4b7d-9a1f-fe28abbc0d91,DISK], DatanodeInfoWithStorage[127.0.0.1:45371,DS-51784f79-4e0e-4c9f-90c2-f7498c2821fe,DISK], DatanodeInfoWithStorage[127.0.0.1:33011,DS-f9af5c3e-f1dc-49da-b458-bbb4125ce982,DISK], DatanodeInfoWithStorage[127.0.0.1:36406,DS-0cb8020b-1752-4c92-b733-5d3c8a9543f6,DISK], DatanodeInfoWithStorage[127.0.0.1:33630,DS-8b279e03-9d5d-461f-afcb-cd4f02eb8a09,DISK], DatanodeInfoWithStorage[127.0.0.1:37786,DS-c87e6d13-95c8-4b16-b0f2-f741a4154509,DISK], DatanodeInfoWithStorage[127.0.0.1:39042,DS-6cf27874-ee7c-4ad6-944c-60d3b2b0d2a1,DISK], DatanodeInfoWithStorage[127.0.0.1:41011,DS-2f344870-21a8-40b1-a098-5b05b045e9d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-955459481-172.17.0.6-1595299061943:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33123,DS-6dd3bb37-d31e-49b7-b30d-d05d548ad8d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45451,DS-241eded6-594b-4ffd-8842-b37e7a60adc8,DISK], DatanodeInfoWithStorage[127.0.0.1:33362,DS-614d3354-b31d-4e92-9a94-5a331cb1b87e,DISK], DatanodeInfoWithStorage[127.0.0.1:37858,DS-a1cd7b4e-35e6-4930-9339-a7410409fecf,DISK], DatanodeInfoWithStorage[127.0.0.1:41857,DS-0d7061c1-8a67-4f51-ab19-ca04f7276b77,DISK], DatanodeInfoWithStorage[127.0.0.1:36428,DS-61073001-f93f-4d3e-a451-f8bf4141b7c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44951,DS-e89fa924-d7c6-4a09-ae37-8d0a0aad1faf,DISK], DatanodeInfoWithStorage[127.0.0.1:40058,DS-164c7daf-faa2-4624-aa0e-b075706933d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-955459481-172.17.0.6-1595299061943:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33123,DS-6dd3bb37-d31e-49b7-b30d-d05d548ad8d6,DISK], DatanodeInfoWithStorage[127.0.0.1:45451,DS-241eded6-594b-4ffd-8842-b37e7a60adc8,DISK], DatanodeInfoWithStorage[127.0.0.1:33362,DS-614d3354-b31d-4e92-9a94-5a331cb1b87e,DISK], DatanodeInfoWithStorage[127.0.0.1:37858,DS-a1cd7b4e-35e6-4930-9339-a7410409fecf,DISK], DatanodeInfoWithStorage[127.0.0.1:41857,DS-0d7061c1-8a67-4f51-ab19-ca04f7276b77,DISK], DatanodeInfoWithStorage[127.0.0.1:36428,DS-61073001-f93f-4d3e-a451-f8bf4141b7c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44951,DS-e89fa924-d7c6-4a09-ae37-8d0a0aad1faf,DISK], DatanodeInfoWithStorage[127.0.0.1:40058,DS-164c7daf-faa2-4624-aa0e-b075706933d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-249949906-172.17.0.6-1595299141803:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39886,DS-ca310259-3fd8-4c28-a030-fdaace63b07d,DISK], DatanodeInfoWithStorage[127.0.0.1:39385,DS-b4e73eea-3fd0-47b9-9d19-682eabf3774f,DISK], DatanodeInfoWithStorage[127.0.0.1:42075,DS-e23b2573-7e93-43d2-81cf-50210e47aacc,DISK], DatanodeInfoWithStorage[127.0.0.1:43923,DS-dff8fe60-8391-42c7-a140-9fadb41ea5a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44111,DS-bd720e54-ada9-4307-b7c4-89e0b0f57dde,DISK], DatanodeInfoWithStorage[127.0.0.1:33928,DS-8e44c6ed-b39b-4c76-8bf9-fde7f6c922fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46080,DS-377bf48d-572d-4d73-bc38-d8ee181c006e,DISK], DatanodeInfoWithStorage[127.0.0.1:39985,DS-927cb51f-2fc8-496a-af59-1f04940ee650,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-249949906-172.17.0.6-1595299141803:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39886,DS-ca310259-3fd8-4c28-a030-fdaace63b07d,DISK], DatanodeInfoWithStorage[127.0.0.1:39385,DS-b4e73eea-3fd0-47b9-9d19-682eabf3774f,DISK], DatanodeInfoWithStorage[127.0.0.1:42075,DS-e23b2573-7e93-43d2-81cf-50210e47aacc,DISK], DatanodeInfoWithStorage[127.0.0.1:43923,DS-dff8fe60-8391-42c7-a140-9fadb41ea5a2,DISK], DatanodeInfoWithStorage[127.0.0.1:44111,DS-bd720e54-ada9-4307-b7c4-89e0b0f57dde,DISK], DatanodeInfoWithStorage[127.0.0.1:33928,DS-8e44c6ed-b39b-4c76-8bf9-fde7f6c922fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46080,DS-377bf48d-572d-4d73-bc38-d8ee181c006e,DISK], DatanodeInfoWithStorage[127.0.0.1:39985,DS-927cb51f-2fc8-496a-af59-1f04940ee650,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-756346879-172.17.0.6-1595299759163:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35963,DS-94f55510-990a-40fb-9feb-5005e18ac9ce,DISK], DatanodeInfoWithStorage[127.0.0.1:39768,DS-0f7c6821-7d48-471b-a764-33f3b812132c,DISK], DatanodeInfoWithStorage[127.0.0.1:40356,DS-f440471c-c77e-4e0c-9a76-578184b84d00,DISK], DatanodeInfoWithStorage[127.0.0.1:40253,DS-bc7b6d89-fb96-40ea-9a27-3b9a3bfa940e,DISK], DatanodeInfoWithStorage[127.0.0.1:45216,DS-2443ac6d-386c-4606-a858-ced91853c451,DISK], DatanodeInfoWithStorage[127.0.0.1:36600,DS-898ffddb-3c2d-4a36-8d30-ede41f1d2902,DISK], DatanodeInfoWithStorage[127.0.0.1:35105,DS-c77d46ea-2c46-4123-bb56-e3307eb1682d,DISK], DatanodeInfoWithStorage[127.0.0.1:44642,DS-58a7f2a6-f5d6-4dc0-805f-fbcee83e596f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-756346879-172.17.0.6-1595299759163:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35963,DS-94f55510-990a-40fb-9feb-5005e18ac9ce,DISK], DatanodeInfoWithStorage[127.0.0.1:39768,DS-0f7c6821-7d48-471b-a764-33f3b812132c,DISK], DatanodeInfoWithStorage[127.0.0.1:40356,DS-f440471c-c77e-4e0c-9a76-578184b84d00,DISK], DatanodeInfoWithStorage[127.0.0.1:40253,DS-bc7b6d89-fb96-40ea-9a27-3b9a3bfa940e,DISK], DatanodeInfoWithStorage[127.0.0.1:45216,DS-2443ac6d-386c-4606-a858-ced91853c451,DISK], DatanodeInfoWithStorage[127.0.0.1:36600,DS-898ffddb-3c2d-4a36-8d30-ede41f1d2902,DISK], DatanodeInfoWithStorage[127.0.0.1:35105,DS-c77d46ea-2c46-4123-bb56-e3307eb1682d,DISK], DatanodeInfoWithStorage[127.0.0.1:44642,DS-58a7f2a6-f5d6-4dc0-805f-fbcee83e596f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2003405038-172.17.0.6-1595299947784:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36588,DS-daa8d03b-aa00-4efc-8b79-888527a32a1b,DISK], DatanodeInfoWithStorage[127.0.0.1:36958,DS-fb011b9e-00cf-4382-b6d2-df01fe9bb410,DISK], DatanodeInfoWithStorage[127.0.0.1:35968,DS-d60b6cb4-56ba-4f42-9fb0-64a3399aa405,DISK], DatanodeInfoWithStorage[127.0.0.1:35048,DS-e152b415-7453-4710-8a0e-b073718d1431,DISK], DatanodeInfoWithStorage[127.0.0.1:44639,DS-371cfe0d-b360-4aee-8a24-4612ce663e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:44281,DS-a3fa3652-f8a3-4917-813e-20a417c75887,DISK], DatanodeInfoWithStorage[127.0.0.1:40622,DS-4f268f52-413f-4737-a884-b475a1a0437a,DISK], DatanodeInfoWithStorage[127.0.0.1:38927,DS-bdd4b7cd-43ba-488c-af23-8c92cd78886c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2003405038-172.17.0.6-1595299947784:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36588,DS-daa8d03b-aa00-4efc-8b79-888527a32a1b,DISK], DatanodeInfoWithStorage[127.0.0.1:36958,DS-fb011b9e-00cf-4382-b6d2-df01fe9bb410,DISK], DatanodeInfoWithStorage[127.0.0.1:35968,DS-d60b6cb4-56ba-4f42-9fb0-64a3399aa405,DISK], DatanodeInfoWithStorage[127.0.0.1:35048,DS-e152b415-7453-4710-8a0e-b073718d1431,DISK], DatanodeInfoWithStorage[127.0.0.1:44639,DS-371cfe0d-b360-4aee-8a24-4612ce663e9d,DISK], DatanodeInfoWithStorage[127.0.0.1:44281,DS-a3fa3652-f8a3-4917-813e-20a417c75887,DISK], DatanodeInfoWithStorage[127.0.0.1:40622,DS-4f268f52-413f-4737-a884-b475a1a0437a,DISK], DatanodeInfoWithStorage[127.0.0.1:38927,DS-bdd4b7cd-43ba-488c-af23-8c92cd78886c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1943992287-172.17.0.6-1595300133995:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38380,DS-32b63e34-aa44-4b0c-aaef-8bd6065b682d,DISK], DatanodeInfoWithStorage[127.0.0.1:39392,DS-faf8794e-e53d-43c8-9225-ad912f39dd4b,DISK], DatanodeInfoWithStorage[127.0.0.1:42078,DS-91244428-28d7-49ba-9c49-5a89f32a90b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36938,DS-cafc51e2-d864-4ade-bde3-06af8f7b2812,DISK], DatanodeInfoWithStorage[127.0.0.1:40125,DS-0efb82a0-1c12-407e-8557-6f73695e2721,DISK], DatanodeInfoWithStorage[127.0.0.1:36566,DS-089c2de0-df35-4993-a4fa-468568e2ddda,DISK], DatanodeInfoWithStorage[127.0.0.1:46341,DS-87cf028b-cecd-4285-baff-cd238bb854c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37811,DS-dbc275b4-bf41-479f-9a8c-43a49201ac45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1943992287-172.17.0.6-1595300133995:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38380,DS-32b63e34-aa44-4b0c-aaef-8bd6065b682d,DISK], DatanodeInfoWithStorage[127.0.0.1:39392,DS-faf8794e-e53d-43c8-9225-ad912f39dd4b,DISK], DatanodeInfoWithStorage[127.0.0.1:42078,DS-91244428-28d7-49ba-9c49-5a89f32a90b1,DISK], DatanodeInfoWithStorage[127.0.0.1:36938,DS-cafc51e2-d864-4ade-bde3-06af8f7b2812,DISK], DatanodeInfoWithStorage[127.0.0.1:40125,DS-0efb82a0-1c12-407e-8557-6f73695e2721,DISK], DatanodeInfoWithStorage[127.0.0.1:36566,DS-089c2de0-df35-4993-a4fa-468568e2ddda,DISK], DatanodeInfoWithStorage[127.0.0.1:46341,DS-87cf028b-cecd-4285-baff-cd238bb854c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37811,DS-dbc275b4-bf41-479f-9a8c-43a49201ac45,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1781600429-172.17.0.6-1595300231683:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41349,DS-542fd530-65f7-4653-956c-a5d78cc1dd2c,DISK], DatanodeInfoWithStorage[127.0.0.1:44126,DS-3ba4440e-0e90-4c2d-954d-08233c7f6968,DISK], DatanodeInfoWithStorage[127.0.0.1:35198,DS-e370f4a3-9bf9-4087-a2a6-45ad79dab20d,DISK], DatanodeInfoWithStorage[127.0.0.1:39225,DS-a5443b5d-5d6a-400d-9829-214fa4dafc11,DISK], DatanodeInfoWithStorage[127.0.0.1:36170,DS-6e4d653a-0d82-46f1-a2f8-b0b8ca315806,DISK], DatanodeInfoWithStorage[127.0.0.1:43869,DS-1c174fe8-068c-4a88-99b0-abeca25df48e,DISK], DatanodeInfoWithStorage[127.0.0.1:38049,DS-5e5faf1d-db77-4b7b-9197-d4c0a1032c52,DISK], DatanodeInfoWithStorage[127.0.0.1:36173,DS-c2b07b06-acc0-4b2c-81fb-3f12c9b38d3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1781600429-172.17.0.6-1595300231683:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41349,DS-542fd530-65f7-4653-956c-a5d78cc1dd2c,DISK], DatanodeInfoWithStorage[127.0.0.1:44126,DS-3ba4440e-0e90-4c2d-954d-08233c7f6968,DISK], DatanodeInfoWithStorage[127.0.0.1:35198,DS-e370f4a3-9bf9-4087-a2a6-45ad79dab20d,DISK], DatanodeInfoWithStorage[127.0.0.1:39225,DS-a5443b5d-5d6a-400d-9829-214fa4dafc11,DISK], DatanodeInfoWithStorage[127.0.0.1:36170,DS-6e4d653a-0d82-46f1-a2f8-b0b8ca315806,DISK], DatanodeInfoWithStorage[127.0.0.1:43869,DS-1c174fe8-068c-4a88-99b0-abeca25df48e,DISK], DatanodeInfoWithStorage[127.0.0.1:38049,DS-5e5faf1d-db77-4b7b-9197-d4c0a1032c52,DISK], DatanodeInfoWithStorage[127.0.0.1:36173,DS-c2b07b06-acc0-4b2c-81fb-3f12c9b38d3a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1972835150-172.17.0.6-1595300953990:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43436,DS-4857495d-8342-4d52-a17f-35ded09eac36,DISK], DatanodeInfoWithStorage[127.0.0.1:46333,DS-27a269cd-26af-4f66-96ae-eb87715f390e,DISK], DatanodeInfoWithStorage[127.0.0.1:38675,DS-b400d808-2fe3-406c-b40f-de6fa951261d,DISK], DatanodeInfoWithStorage[127.0.0.1:34462,DS-21f34054-8380-4e7f-a599-374953825ef8,DISK], DatanodeInfoWithStorage[127.0.0.1:43101,DS-d86222e0-3a55-4c79-8463-a2ce4842e9c4,DISK], DatanodeInfoWithStorage[127.0.0.1:37432,DS-1ec2c023-5a17-446d-bee4-ca4bf6c731ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43243,DS-b4c33136-7e5c-4344-95f6-3d9de6e6aa68,DISK], DatanodeInfoWithStorage[127.0.0.1:33844,DS-1512e29e-f2a6-477b-9f0a-31905fdb3329,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1972835150-172.17.0.6-1595300953990:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43436,DS-4857495d-8342-4d52-a17f-35ded09eac36,DISK], DatanodeInfoWithStorage[127.0.0.1:46333,DS-27a269cd-26af-4f66-96ae-eb87715f390e,DISK], DatanodeInfoWithStorage[127.0.0.1:38675,DS-b400d808-2fe3-406c-b40f-de6fa951261d,DISK], DatanodeInfoWithStorage[127.0.0.1:34462,DS-21f34054-8380-4e7f-a599-374953825ef8,DISK], DatanodeInfoWithStorage[127.0.0.1:43101,DS-d86222e0-3a55-4c79-8463-a2ce4842e9c4,DISK], DatanodeInfoWithStorage[127.0.0.1:37432,DS-1ec2c023-5a17-446d-bee4-ca4bf6c731ca,DISK], DatanodeInfoWithStorage[127.0.0.1:43243,DS-b4c33136-7e5c-4344-95f6-3d9de6e6aa68,DISK], DatanodeInfoWithStorage[127.0.0.1:33844,DS-1512e29e-f2a6-477b-9f0a-31905fdb3329,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1774349021-172.17.0.6-1595301087297:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33961,DS-7e600353-63bc-48c9-b963-bc163cffcfd6,DISK], DatanodeInfoWithStorage[127.0.0.1:41837,DS-77b9b6e9-b9ce-4306-9743-5860d6d85deb,DISK], DatanodeInfoWithStorage[127.0.0.1:45601,DS-06071015-7dfb-4635-a85f-64d330498c94,DISK], DatanodeInfoWithStorage[127.0.0.1:44443,DS-0e16d956-a23d-47b7-8f35-8acfa38f3e30,DISK], DatanodeInfoWithStorage[127.0.0.1:37405,DS-0de5d0b5-fdc2-4a67-b119-a85afe516cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:34717,DS-51bc5ed3-0eb6-4476-a983-47f236fdd8a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45991,DS-10cc7bb1-e065-4e37-bf91-e89f15e4d75a,DISK], DatanodeInfoWithStorage[127.0.0.1:35011,DS-2280c591-471a-4e83-8254-453fa2c9f305,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1774349021-172.17.0.6-1595301087297:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33961,DS-7e600353-63bc-48c9-b963-bc163cffcfd6,DISK], DatanodeInfoWithStorage[127.0.0.1:41837,DS-77b9b6e9-b9ce-4306-9743-5860d6d85deb,DISK], DatanodeInfoWithStorage[127.0.0.1:45601,DS-06071015-7dfb-4635-a85f-64d330498c94,DISK], DatanodeInfoWithStorage[127.0.0.1:44443,DS-0e16d956-a23d-47b7-8f35-8acfa38f3e30,DISK], DatanodeInfoWithStorage[127.0.0.1:37405,DS-0de5d0b5-fdc2-4a67-b119-a85afe516cb6,DISK], DatanodeInfoWithStorage[127.0.0.1:34717,DS-51bc5ed3-0eb6-4476-a983-47f236fdd8a0,DISK], DatanodeInfoWithStorage[127.0.0.1:45991,DS-10cc7bb1-e065-4e37-bf91-e89f15e4d75a,DISK], DatanodeInfoWithStorage[127.0.0.1:35011,DS-2280c591-471a-4e83-8254-453fa2c9f305,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.transferTo.allowed
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1631358228-172.17.0.6-1595301134728:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45046,DS-e9ab76a8-7ea7-4374-895d-a0145ea610e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39024,DS-0002adbe-343e-408d-aad7-a37170f1a5e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39525,DS-1fecd633-9d9f-44f5-bc74-289c2bfd9cd7,DISK], DatanodeInfoWithStorage[127.0.0.1:39057,DS-777ec9ea-e673-4de0-93a0-85d1f86e8f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:38500,DS-9e29cc4e-961a-4447-b113-868a8409451d,DISK], DatanodeInfoWithStorage[127.0.0.1:35540,DS-e8924c8e-33c2-4db6-9165-0d345b9b39bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33487,DS-857e3c52-e092-44aa-81c6-b7a69081bdb7,DISK], DatanodeInfoWithStorage[127.0.0.1:39833,DS-5f04a8f1-6021-4519-86c9-cb1c01050f98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1631358228-172.17.0.6-1595301134728:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45046,DS-e9ab76a8-7ea7-4374-895d-a0145ea610e6,DISK], DatanodeInfoWithStorage[127.0.0.1:39024,DS-0002adbe-343e-408d-aad7-a37170f1a5e8,DISK], DatanodeInfoWithStorage[127.0.0.1:39525,DS-1fecd633-9d9f-44f5-bc74-289c2bfd9cd7,DISK], DatanodeInfoWithStorage[127.0.0.1:39057,DS-777ec9ea-e673-4de0-93a0-85d1f86e8f3c,DISK], DatanodeInfoWithStorage[127.0.0.1:38500,DS-9e29cc4e-961a-4447-b113-868a8409451d,DISK], DatanodeInfoWithStorage[127.0.0.1:35540,DS-e8924c8e-33c2-4db6-9165-0d345b9b39bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33487,DS-857e3c52-e092-44aa-81c6-b7a69081bdb7,DISK], DatanodeInfoWithStorage[127.0.0.1:39833,DS-5f04a8f1-6021-4519-86c9-cb1c01050f98,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 6895
