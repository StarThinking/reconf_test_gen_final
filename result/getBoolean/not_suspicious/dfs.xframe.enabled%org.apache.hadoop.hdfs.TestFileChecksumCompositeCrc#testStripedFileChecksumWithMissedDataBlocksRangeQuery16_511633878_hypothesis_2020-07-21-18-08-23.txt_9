reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1548115319-172.17.0.4-1595355578555:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44721,DS-364653bf-e0bf-4b26-a6dc-1b8721c01033,DISK], DatanodeInfoWithStorage[127.0.0.1:40960,DS-27682df4-ca30-4e55-bf6c-90d9184ed522,DISK], DatanodeInfoWithStorage[127.0.0.1:40909,DS-0ddc1723-5aba-456d-96d4-39a1fcfff2b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34179,DS-f886f7d2-cdda-4eb8-909b-acf2db96de5b,DISK], DatanodeInfoWithStorage[127.0.0.1:44234,DS-8ad6b79a-e463-4199-905f-ab95a4eac2ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34041,DS-d24c1382-822b-4847-b588-b9850386dd50,DISK], DatanodeInfoWithStorage[127.0.0.1:39389,DS-c3b391db-23fb-4a39-a7ea-ca86d5e02f74,DISK], DatanodeInfoWithStorage[127.0.0.1:36820,DS-66d62dea-82ed-46b7-b572-e98575b9119a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1548115319-172.17.0.4-1595355578555:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44721,DS-364653bf-e0bf-4b26-a6dc-1b8721c01033,DISK], DatanodeInfoWithStorage[127.0.0.1:40960,DS-27682df4-ca30-4e55-bf6c-90d9184ed522,DISK], DatanodeInfoWithStorage[127.0.0.1:40909,DS-0ddc1723-5aba-456d-96d4-39a1fcfff2b7,DISK], DatanodeInfoWithStorage[127.0.0.1:34179,DS-f886f7d2-cdda-4eb8-909b-acf2db96de5b,DISK], DatanodeInfoWithStorage[127.0.0.1:44234,DS-8ad6b79a-e463-4199-905f-ab95a4eac2ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34041,DS-d24c1382-822b-4847-b588-b9850386dd50,DISK], DatanodeInfoWithStorage[127.0.0.1:39389,DS-c3b391db-23fb-4a39-a7ea-ca86d5e02f74,DISK], DatanodeInfoWithStorage[127.0.0.1:36820,DS-66d62dea-82ed-46b7-b572-e98575b9119a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-721507031-172.17.0.4-1595355889346:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34653,DS-70e73c27-c70b-4504-9a52-1d849a149e15,DISK], DatanodeInfoWithStorage[127.0.0.1:37328,DS-3374e032-171f-40cf-a2fc-eff745cbb9df,DISK], DatanodeInfoWithStorage[127.0.0.1:37798,DS-2e8b4af0-f93b-4e2a-bc75-de0b41fcb598,DISK], DatanodeInfoWithStorage[127.0.0.1:36854,DS-c4f567f8-32c3-48b1-859c-d504b85377ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37357,DS-7f3e9ea5-e844-4f28-90e0-1ae3f3ddaef0,DISK], DatanodeInfoWithStorage[127.0.0.1:35391,DS-2078fe48-1a22-493c-a4ab-ac3796f3fd53,DISK], DatanodeInfoWithStorage[127.0.0.1:36245,DS-9cb1c3bf-6492-42f4-adee-b66094dc694f,DISK], DatanodeInfoWithStorage[127.0.0.1:46473,DS-29b21e2a-0b5e-40b9-a1ad-80cdcc3c4ace,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-721507031-172.17.0.4-1595355889346:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34653,DS-70e73c27-c70b-4504-9a52-1d849a149e15,DISK], DatanodeInfoWithStorage[127.0.0.1:37328,DS-3374e032-171f-40cf-a2fc-eff745cbb9df,DISK], DatanodeInfoWithStorage[127.0.0.1:37798,DS-2e8b4af0-f93b-4e2a-bc75-de0b41fcb598,DISK], DatanodeInfoWithStorage[127.0.0.1:36854,DS-c4f567f8-32c3-48b1-859c-d504b85377ec,DISK], DatanodeInfoWithStorage[127.0.0.1:37357,DS-7f3e9ea5-e844-4f28-90e0-1ae3f3ddaef0,DISK], DatanodeInfoWithStorage[127.0.0.1:35391,DS-2078fe48-1a22-493c-a4ab-ac3796f3fd53,DISK], DatanodeInfoWithStorage[127.0.0.1:36245,DS-9cb1c3bf-6492-42f4-adee-b66094dc694f,DISK], DatanodeInfoWithStorage[127.0.0.1:46473,DS-29b21e2a-0b5e-40b9-a1ad-80cdcc3c4ace,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1912820795-172.17.0.4-1595356029731:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41008,DS-a641d6cb-b0af-468d-bb2a-c7847446736e,DISK], DatanodeInfoWithStorage[127.0.0.1:37970,DS-27fadf2b-b817-4735-bc90-65b9d1bb4d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:40973,DS-654df723-04fa-46a0-9574-8116acc28832,DISK], DatanodeInfoWithStorage[127.0.0.1:37456,DS-22e50aa1-4181-43b3-b64e-cafad2b9e3aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45877,DS-618a04fd-ef68-4203-8dff-01fd2fe731ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42549,DS-d25a1cab-ccdc-40c1-9949-71887127f305,DISK], DatanodeInfoWithStorage[127.0.0.1:43814,DS-d6e533ee-660e-49cd-a596-9fb4f0d47081,DISK], DatanodeInfoWithStorage[127.0.0.1:34136,DS-933059e0-656d-4cf1-ae47-6cfb3000f2d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1912820795-172.17.0.4-1595356029731:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41008,DS-a641d6cb-b0af-468d-bb2a-c7847446736e,DISK], DatanodeInfoWithStorage[127.0.0.1:37970,DS-27fadf2b-b817-4735-bc90-65b9d1bb4d2f,DISK], DatanodeInfoWithStorage[127.0.0.1:40973,DS-654df723-04fa-46a0-9574-8116acc28832,DISK], DatanodeInfoWithStorage[127.0.0.1:37456,DS-22e50aa1-4181-43b3-b64e-cafad2b9e3aa,DISK], DatanodeInfoWithStorage[127.0.0.1:45877,DS-618a04fd-ef68-4203-8dff-01fd2fe731ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42549,DS-d25a1cab-ccdc-40c1-9949-71887127f305,DISK], DatanodeInfoWithStorage[127.0.0.1:43814,DS-d6e533ee-660e-49cd-a596-9fb4f0d47081,DISK], DatanodeInfoWithStorage[127.0.0.1:34136,DS-933059e0-656d-4cf1-ae47-6cfb3000f2d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-951612202-172.17.0.4-1595356071444:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43520,DS-1253ad71-1dfd-4dc1-9979-f58524c640d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42397,DS-806fcb94-a881-40a1-9030-275fbb21462f,DISK], DatanodeInfoWithStorage[127.0.0.1:40983,DS-748a260a-790b-48d2-ae7b-4f93d9c421e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41554,DS-4beec1e7-7af6-4d4c-a10d-33555c1799da,DISK], DatanodeInfoWithStorage[127.0.0.1:36711,DS-0c694764-5615-4033-ba00-ba76b9af44f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41470,DS-2d2bff16-288f-4bd0-bf52-bf17e1835ae7,DISK], DatanodeInfoWithStorage[127.0.0.1:33988,DS-32f2835e-30b4-444c-a483-e2b6b49f4ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:43439,DS-aa92b262-0a5a-443d-a2a7-59b567b6e5a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-951612202-172.17.0.4-1595356071444:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43520,DS-1253ad71-1dfd-4dc1-9979-f58524c640d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42397,DS-806fcb94-a881-40a1-9030-275fbb21462f,DISK], DatanodeInfoWithStorage[127.0.0.1:40983,DS-748a260a-790b-48d2-ae7b-4f93d9c421e3,DISK], DatanodeInfoWithStorage[127.0.0.1:41554,DS-4beec1e7-7af6-4d4c-a10d-33555c1799da,DISK], DatanodeInfoWithStorage[127.0.0.1:36711,DS-0c694764-5615-4033-ba00-ba76b9af44f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41470,DS-2d2bff16-288f-4bd0-bf52-bf17e1835ae7,DISK], DatanodeInfoWithStorage[127.0.0.1:33988,DS-32f2835e-30b4-444c-a483-e2b6b49f4ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:43439,DS-aa92b262-0a5a-443d-a2a7-59b567b6e5a2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-286178375-172.17.0.4-1595356210681:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35582,DS-43b32ea1-e14d-4100-9708-52232850661e,DISK], DatanodeInfoWithStorage[127.0.0.1:37795,DS-c5227fe6-cfc5-4fe6-902c-6f5c18ea1aba,DISK], DatanodeInfoWithStorage[127.0.0.1:45665,DS-57ee46e5-2254-454c-b8ce-99612559bf4f,DISK], DatanodeInfoWithStorage[127.0.0.1:43403,DS-a3667878-531c-4563-b18b-ca3a725beb97,DISK], DatanodeInfoWithStorage[127.0.0.1:34321,DS-c557476f-298e-4cb2-9cb7-0faec26c4918,DISK], DatanodeInfoWithStorage[127.0.0.1:46039,DS-bdf1440c-36c6-4bb3-a357-23912299b6d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34002,DS-0add975d-c97a-435b-aafe-8c3974cffb56,DISK], DatanodeInfoWithStorage[127.0.0.1:45592,DS-5b8485fa-2e67-41af-96bc-ac50b76272a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-286178375-172.17.0.4-1595356210681:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35582,DS-43b32ea1-e14d-4100-9708-52232850661e,DISK], DatanodeInfoWithStorage[127.0.0.1:37795,DS-c5227fe6-cfc5-4fe6-902c-6f5c18ea1aba,DISK], DatanodeInfoWithStorage[127.0.0.1:45665,DS-57ee46e5-2254-454c-b8ce-99612559bf4f,DISK], DatanodeInfoWithStorage[127.0.0.1:43403,DS-a3667878-531c-4563-b18b-ca3a725beb97,DISK], DatanodeInfoWithStorage[127.0.0.1:34321,DS-c557476f-298e-4cb2-9cb7-0faec26c4918,DISK], DatanodeInfoWithStorage[127.0.0.1:46039,DS-bdf1440c-36c6-4bb3-a357-23912299b6d6,DISK], DatanodeInfoWithStorage[127.0.0.1:34002,DS-0add975d-c97a-435b-aafe-8c3974cffb56,DISK], DatanodeInfoWithStorage[127.0.0.1:45592,DS-5b8485fa-2e67-41af-96bc-ac50b76272a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1088451585-172.17.0.4-1595356577562:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39440,DS-30f5aa80-43ea-4fd0-a057-af4a11f9745e,DISK], DatanodeInfoWithStorage[127.0.0.1:37638,DS-3f7ad915-42f8-4b86-9245-85dee803b414,DISK], DatanodeInfoWithStorage[127.0.0.1:36489,DS-3d3ad7e2-fadb-46e7-a2b3-9fb222f03b67,DISK], DatanodeInfoWithStorage[127.0.0.1:41056,DS-96b25460-7e84-4492-bfd4-cd5c14164c04,DISK], DatanodeInfoWithStorage[127.0.0.1:39682,DS-73f9dd91-18da-43d2-b7bd-4bd85bf283e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37177,DS-5db26d15-50a9-426b-b03e-30b881eed5b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33196,DS-c03f322a-d614-435a-aee4-69912ad66230,DISK], DatanodeInfoWithStorage[127.0.0.1:36657,DS-b493f236-9398-40ac-b087-26e66b5f09a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1088451585-172.17.0.4-1595356577562:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39440,DS-30f5aa80-43ea-4fd0-a057-af4a11f9745e,DISK], DatanodeInfoWithStorage[127.0.0.1:37638,DS-3f7ad915-42f8-4b86-9245-85dee803b414,DISK], DatanodeInfoWithStorage[127.0.0.1:36489,DS-3d3ad7e2-fadb-46e7-a2b3-9fb222f03b67,DISK], DatanodeInfoWithStorage[127.0.0.1:41056,DS-96b25460-7e84-4492-bfd4-cd5c14164c04,DISK], DatanodeInfoWithStorage[127.0.0.1:39682,DS-73f9dd91-18da-43d2-b7bd-4bd85bf283e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37177,DS-5db26d15-50a9-426b-b03e-30b881eed5b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33196,DS-c03f322a-d614-435a-aee4-69912ad66230,DISK], DatanodeInfoWithStorage[127.0.0.1:36657,DS-b493f236-9398-40ac-b087-26e66b5f09a6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-210281396-172.17.0.4-1595356609317:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35794,DS-74cc1419-5b73-464b-abf3-d0001fe3abf6,DISK], DatanodeInfoWithStorage[127.0.0.1:39205,DS-08f0ed46-d561-4bd1-8e10-8ac18f6ae15f,DISK], DatanodeInfoWithStorage[127.0.0.1:33672,DS-c32b6b3f-7149-4151-9f95-dcdf32517245,DISK], DatanodeInfoWithStorage[127.0.0.1:45888,DS-4256ca50-5dff-493c-89f1-4e8ff43ba644,DISK], DatanodeInfoWithStorage[127.0.0.1:38545,DS-d1e1bb1e-6160-4168-93c3-20a111f7e906,DISK], DatanodeInfoWithStorage[127.0.0.1:39670,DS-50afdccc-8d7b-4857-9e2f-6e2007a248c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46705,DS-ae342a73-0ec4-46a0-af62-a67fbddc2874,DISK], DatanodeInfoWithStorage[127.0.0.1:33232,DS-c221c200-3ec0-422e-94ed-95d1d74edda3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-210281396-172.17.0.4-1595356609317:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35794,DS-74cc1419-5b73-464b-abf3-d0001fe3abf6,DISK], DatanodeInfoWithStorage[127.0.0.1:39205,DS-08f0ed46-d561-4bd1-8e10-8ac18f6ae15f,DISK], DatanodeInfoWithStorage[127.0.0.1:33672,DS-c32b6b3f-7149-4151-9f95-dcdf32517245,DISK], DatanodeInfoWithStorage[127.0.0.1:45888,DS-4256ca50-5dff-493c-89f1-4e8ff43ba644,DISK], DatanodeInfoWithStorage[127.0.0.1:38545,DS-d1e1bb1e-6160-4168-93c3-20a111f7e906,DISK], DatanodeInfoWithStorage[127.0.0.1:39670,DS-50afdccc-8d7b-4857-9e2f-6e2007a248c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46705,DS-ae342a73-0ec4-46a0-af62-a67fbddc2874,DISK], DatanodeInfoWithStorage[127.0.0.1:33232,DS-c221c200-3ec0-422e-94ed-95d1d74edda3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1541742078-172.17.0.4-1595356673005:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36916,DS-e735caa1-2975-4d13-a27b-8ef58b01bb8b,DISK], DatanodeInfoWithStorage[127.0.0.1:44851,DS-fa5432f8-535b-4d3d-a06d-b8da7fdb65f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42506,DS-b1f061d6-14c5-4c27-b153-cf3f36a045dc,DISK], DatanodeInfoWithStorage[127.0.0.1:34942,DS-e6fa9063-76b7-46fb-8aec-1d658aff6782,DISK], DatanodeInfoWithStorage[127.0.0.1:46385,DS-b91d92f6-9d33-4c12-aa61-e5e7ab533f3a,DISK], DatanodeInfoWithStorage[127.0.0.1:41221,DS-6c77c611-4990-42bf-b402-815495bd068d,DISK], DatanodeInfoWithStorage[127.0.0.1:45123,DS-42410414-7587-40b4-8738-7c6324b2a5a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34340,DS-9509ce49-749d-4d41-8202-c4419d077e5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1541742078-172.17.0.4-1595356673005:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36916,DS-e735caa1-2975-4d13-a27b-8ef58b01bb8b,DISK], DatanodeInfoWithStorage[127.0.0.1:44851,DS-fa5432f8-535b-4d3d-a06d-b8da7fdb65f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42506,DS-b1f061d6-14c5-4c27-b153-cf3f36a045dc,DISK], DatanodeInfoWithStorage[127.0.0.1:34942,DS-e6fa9063-76b7-46fb-8aec-1d658aff6782,DISK], DatanodeInfoWithStorage[127.0.0.1:46385,DS-b91d92f6-9d33-4c12-aa61-e5e7ab533f3a,DISK], DatanodeInfoWithStorage[127.0.0.1:41221,DS-6c77c611-4990-42bf-b402-815495bd068d,DISK], DatanodeInfoWithStorage[127.0.0.1:45123,DS-42410414-7587-40b4-8738-7c6324b2a5a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34340,DS-9509ce49-749d-4d41-8202-c4419d077e5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-16303912-172.17.0.4-1595356854137:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34866,DS-8a9f50fe-115b-4fa1-89ca-6c40de0f55a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34307,DS-e3cfc314-dca2-4aef-87f0-b3696b34be98,DISK], DatanodeInfoWithStorage[127.0.0.1:42459,DS-1846b959-912e-4423-851e-51759687cc04,DISK], DatanodeInfoWithStorage[127.0.0.1:33313,DS-f5291cfc-73c6-48d1-a568-4d1120c4e555,DISK], DatanodeInfoWithStorage[127.0.0.1:44315,DS-7e539d09-8ccf-4593-9928-f3d181303efa,DISK], DatanodeInfoWithStorage[127.0.0.1:43660,DS-b1e5dc06-81f7-47a3-95d6-e546a06fdf8c,DISK], DatanodeInfoWithStorage[127.0.0.1:34303,DS-fa28bfaf-22c3-4e99-af91-d0004d07d8b6,DISK], DatanodeInfoWithStorage[127.0.0.1:46458,DS-a5cb9b96-7a4f-409f-9549-d95143e8425a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-16303912-172.17.0.4-1595356854137:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34866,DS-8a9f50fe-115b-4fa1-89ca-6c40de0f55a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34307,DS-e3cfc314-dca2-4aef-87f0-b3696b34be98,DISK], DatanodeInfoWithStorage[127.0.0.1:42459,DS-1846b959-912e-4423-851e-51759687cc04,DISK], DatanodeInfoWithStorage[127.0.0.1:33313,DS-f5291cfc-73c6-48d1-a568-4d1120c4e555,DISK], DatanodeInfoWithStorage[127.0.0.1:44315,DS-7e539d09-8ccf-4593-9928-f3d181303efa,DISK], DatanodeInfoWithStorage[127.0.0.1:43660,DS-b1e5dc06-81f7-47a3-95d6-e546a06fdf8c,DISK], DatanodeInfoWithStorage[127.0.0.1:34303,DS-fa28bfaf-22c3-4e99-af91-d0004d07d8b6,DISK], DatanodeInfoWithStorage[127.0.0.1:46458,DS-a5cb9b96-7a4f-409f-9549-d95143e8425a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2106357933-172.17.0.4-1595357031487:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43564,DS-37015094-8063-40ec-81fa-f35075e934a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37225,DS-64436c18-aeb9-4801-a0c4-a06e6ccac2ca,DISK], DatanodeInfoWithStorage[127.0.0.1:44750,DS-6045b53b-10ce-4f22-b941-836fb7958412,DISK], DatanodeInfoWithStorage[127.0.0.1:35923,DS-db4d75f8-ccec-49da-9fb6-93fe6d69f571,DISK], DatanodeInfoWithStorage[127.0.0.1:38244,DS-cad2d6f0-af09-4589-b572-1f102c777c98,DISK], DatanodeInfoWithStorage[127.0.0.1:45991,DS-bb66d540-0df7-4a97-8548-4e15101d5f16,DISK], DatanodeInfoWithStorage[127.0.0.1:42904,DS-4b8e7a09-16bb-4741-ae9e-bcc8dc479b9b,DISK], DatanodeInfoWithStorage[127.0.0.1:37008,DS-cb4300a2-2a7d-486b-9e48-f6c0ce4330d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2106357933-172.17.0.4-1595357031487:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43564,DS-37015094-8063-40ec-81fa-f35075e934a6,DISK], DatanodeInfoWithStorage[127.0.0.1:37225,DS-64436c18-aeb9-4801-a0c4-a06e6ccac2ca,DISK], DatanodeInfoWithStorage[127.0.0.1:44750,DS-6045b53b-10ce-4f22-b941-836fb7958412,DISK], DatanodeInfoWithStorage[127.0.0.1:35923,DS-db4d75f8-ccec-49da-9fb6-93fe6d69f571,DISK], DatanodeInfoWithStorage[127.0.0.1:38244,DS-cad2d6f0-af09-4589-b572-1f102c777c98,DISK], DatanodeInfoWithStorage[127.0.0.1:45991,DS-bb66d540-0df7-4a97-8548-4e15101d5f16,DISK], DatanodeInfoWithStorage[127.0.0.1:42904,DS-4b8e7a09-16bb-4741-ae9e-bcc8dc479b9b,DISK], DatanodeInfoWithStorage[127.0.0.1:37008,DS-cb4300a2-2a7d-486b-9e48-f6c0ce4330d3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-720163204-172.17.0.4-1595357183174:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44098,DS-adcb3d89-78ef-49df-ae4a-b67472053a7c,DISK], DatanodeInfoWithStorage[127.0.0.1:34463,DS-7f0c23be-63cf-48b8-814c-d9bef63cbe17,DISK], DatanodeInfoWithStorage[127.0.0.1:40332,DS-9bab7f19-a031-474e-bc9d-6dad4ccec746,DISK], DatanodeInfoWithStorage[127.0.0.1:36179,DS-1d5df1ec-8b10-4ba3-bc80-072886c78f2f,DISK], DatanodeInfoWithStorage[127.0.0.1:40434,DS-253e7b08-a013-42e9-827f-bd88edd2f443,DISK], DatanodeInfoWithStorage[127.0.0.1:39132,DS-998be56e-104d-479f-b15a-7eee7c100724,DISK], DatanodeInfoWithStorage[127.0.0.1:41201,DS-6c0ae276-01de-4dc6-83bb-ddf351d0a219,DISK], DatanodeInfoWithStorage[127.0.0.1:42205,DS-b8c0c980-844c-46b2-9b96-62e492c828e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-720163204-172.17.0.4-1595357183174:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44098,DS-adcb3d89-78ef-49df-ae4a-b67472053a7c,DISK], DatanodeInfoWithStorage[127.0.0.1:34463,DS-7f0c23be-63cf-48b8-814c-d9bef63cbe17,DISK], DatanodeInfoWithStorage[127.0.0.1:40332,DS-9bab7f19-a031-474e-bc9d-6dad4ccec746,DISK], DatanodeInfoWithStorage[127.0.0.1:36179,DS-1d5df1ec-8b10-4ba3-bc80-072886c78f2f,DISK], DatanodeInfoWithStorage[127.0.0.1:40434,DS-253e7b08-a013-42e9-827f-bd88edd2f443,DISK], DatanodeInfoWithStorage[127.0.0.1:39132,DS-998be56e-104d-479f-b15a-7eee7c100724,DISK], DatanodeInfoWithStorage[127.0.0.1:41201,DS-6c0ae276-01de-4dc6-83bb-ddf351d0a219,DISK], DatanodeInfoWithStorage[127.0.0.1:42205,DS-b8c0c980-844c-46b2-9b96-62e492c828e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2137775371-172.17.0.4-1595357453169:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37722,DS-5608812e-a5c3-4dfb-94d2-6f9bb9e6c826,DISK], DatanodeInfoWithStorage[127.0.0.1:34589,DS-50af10fe-7365-40d2-9ec2-7680ef3a65b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40377,DS-469bd54a-7af5-42bb-9ebe-ad7846c1156a,DISK], DatanodeInfoWithStorage[127.0.0.1:43807,DS-fc5fa006-e63e-46db-8fb0-d8ace84ac18a,DISK], DatanodeInfoWithStorage[127.0.0.1:36849,DS-67e14ff5-bbd0-412d-9073-ca4e06e3b4cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44949,DS-bc865f5d-2104-49be-81fe-fbe451deed88,DISK], DatanodeInfoWithStorage[127.0.0.1:35479,DS-edc2291f-aba8-4095-8b8e-0de9672f936e,DISK], DatanodeInfoWithStorage[127.0.0.1:41923,DS-5315f553-8715-44f7-94bf-4f27599fc48c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2137775371-172.17.0.4-1595357453169:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37722,DS-5608812e-a5c3-4dfb-94d2-6f9bb9e6c826,DISK], DatanodeInfoWithStorage[127.0.0.1:34589,DS-50af10fe-7365-40d2-9ec2-7680ef3a65b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40377,DS-469bd54a-7af5-42bb-9ebe-ad7846c1156a,DISK], DatanodeInfoWithStorage[127.0.0.1:43807,DS-fc5fa006-e63e-46db-8fb0-d8ace84ac18a,DISK], DatanodeInfoWithStorage[127.0.0.1:36849,DS-67e14ff5-bbd0-412d-9073-ca4e06e3b4cc,DISK], DatanodeInfoWithStorage[127.0.0.1:44949,DS-bc865f5d-2104-49be-81fe-fbe451deed88,DISK], DatanodeInfoWithStorage[127.0.0.1:35479,DS-edc2291f-aba8-4095-8b8e-0de9672f936e,DISK], DatanodeInfoWithStorage[127.0.0.1:41923,DS-5315f553-8715-44f7-94bf-4f27599fc48c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-803414530-172.17.0.4-1595357880488:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44154,DS-a34ef8b3-9b0a-4fa2-baa6-3c36c25b5313,DISK], DatanodeInfoWithStorage[127.0.0.1:42052,DS-9fc2a258-68d3-4b9d-b9a4-d9365e677caa,DISK], DatanodeInfoWithStorage[127.0.0.1:42045,DS-ee9d2f1c-cb2c-4738-b12c-9b3362003e50,DISK], DatanodeInfoWithStorage[127.0.0.1:33411,DS-0e62be62-e838-4835-8629-d0ac209a3852,DISK], DatanodeInfoWithStorage[127.0.0.1:40626,DS-63018a92-ed02-4daf-9193-00ebf730474f,DISK], DatanodeInfoWithStorage[127.0.0.1:45609,DS-f8bdf6cb-84ef-43b7-8dda-3fc6ccc91600,DISK], DatanodeInfoWithStorage[127.0.0.1:37290,DS-395a0fe3-5bdf-4dc2-9074-7615fa232351,DISK], DatanodeInfoWithStorage[127.0.0.1:41675,DS-361aed49-e69a-4dff-b477-ee29d671506a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-803414530-172.17.0.4-1595357880488:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44154,DS-a34ef8b3-9b0a-4fa2-baa6-3c36c25b5313,DISK], DatanodeInfoWithStorage[127.0.0.1:42052,DS-9fc2a258-68d3-4b9d-b9a4-d9365e677caa,DISK], DatanodeInfoWithStorage[127.0.0.1:42045,DS-ee9d2f1c-cb2c-4738-b12c-9b3362003e50,DISK], DatanodeInfoWithStorage[127.0.0.1:33411,DS-0e62be62-e838-4835-8629-d0ac209a3852,DISK], DatanodeInfoWithStorage[127.0.0.1:40626,DS-63018a92-ed02-4daf-9193-00ebf730474f,DISK], DatanodeInfoWithStorage[127.0.0.1:45609,DS-f8bdf6cb-84ef-43b7-8dda-3fc6ccc91600,DISK], DatanodeInfoWithStorage[127.0.0.1:37290,DS-395a0fe3-5bdf-4dc2-9074-7615fa232351,DISK], DatanodeInfoWithStorage[127.0.0.1:41675,DS-361aed49-e69a-4dff-b477-ee29d671506a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-845143511-172.17.0.4-1595358667125:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39730,DS-2f3bf46b-6aca-4f4e-a05b-f6c9bc34a0f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40723,DS-435daccf-1c0b-4386-bdd0-510f7c0b37b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41201,DS-cd062be0-5e10-41a8-8be4-df8930c5d7ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37740,DS-48e867ac-b9e4-4eb2-84af-94170b270285,DISK], DatanodeInfoWithStorage[127.0.0.1:41039,DS-b180bf7a-16e1-4797-9aea-c2212c6791fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39058,DS-2f1ecdf3-d899-4528-a816-c277c53c3412,DISK], DatanodeInfoWithStorage[127.0.0.1:37256,DS-e0ca1c1f-4b93-4f10-8cff-101751e5519e,DISK], DatanodeInfoWithStorage[127.0.0.1:34275,DS-05b2ae7e-5a20-4386-adbb-cbf506d37b38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-845143511-172.17.0.4-1595358667125:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39730,DS-2f3bf46b-6aca-4f4e-a05b-f6c9bc34a0f5,DISK], DatanodeInfoWithStorage[127.0.0.1:40723,DS-435daccf-1c0b-4386-bdd0-510f7c0b37b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41201,DS-cd062be0-5e10-41a8-8be4-df8930c5d7ab,DISK], DatanodeInfoWithStorage[127.0.0.1:37740,DS-48e867ac-b9e4-4eb2-84af-94170b270285,DISK], DatanodeInfoWithStorage[127.0.0.1:41039,DS-b180bf7a-16e1-4797-9aea-c2212c6791fe,DISK], DatanodeInfoWithStorage[127.0.0.1:39058,DS-2f1ecdf3-d899-4528-a816-c277c53c3412,DISK], DatanodeInfoWithStorage[127.0.0.1:37256,DS-e0ca1c1f-4b93-4f10-8cff-101751e5519e,DISK], DatanodeInfoWithStorage[127.0.0.1:34275,DS-05b2ae7e-5a20-4386-adbb-cbf506d37b38,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1108666615-172.17.0.4-1595358763819:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46354,DS-d2a9def1-7efd-47d3-8ee1-0b7b0b13882c,DISK], DatanodeInfoWithStorage[127.0.0.1:35383,DS-f5ebf7d3-d963-464e-91ec-05f6f5754066,DISK], DatanodeInfoWithStorage[127.0.0.1:41056,DS-63341ab2-0d41-456e-9e3a-21c298ebbf00,DISK], DatanodeInfoWithStorage[127.0.0.1:42687,DS-d41e2ba7-5aef-43ce-82bc-6acffbccd815,DISK], DatanodeInfoWithStorage[127.0.0.1:33740,DS-0b3cdaea-873f-4266-b5be-7b648445a3c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36217,DS-fd87e7c4-f016-46f9-82cc-68f99f7ee22a,DISK], DatanodeInfoWithStorage[127.0.0.1:38803,DS-12774436-157b-4ea8-962b-77466694b092,DISK], DatanodeInfoWithStorage[127.0.0.1:42991,DS-df987c17-341c-41b2-b6bc-5f1c24ddf073,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1108666615-172.17.0.4-1595358763819:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46354,DS-d2a9def1-7efd-47d3-8ee1-0b7b0b13882c,DISK], DatanodeInfoWithStorage[127.0.0.1:35383,DS-f5ebf7d3-d963-464e-91ec-05f6f5754066,DISK], DatanodeInfoWithStorage[127.0.0.1:41056,DS-63341ab2-0d41-456e-9e3a-21c298ebbf00,DISK], DatanodeInfoWithStorage[127.0.0.1:42687,DS-d41e2ba7-5aef-43ce-82bc-6acffbccd815,DISK], DatanodeInfoWithStorage[127.0.0.1:33740,DS-0b3cdaea-873f-4266-b5be-7b648445a3c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36217,DS-fd87e7c4-f016-46f9-82cc-68f99f7ee22a,DISK], DatanodeInfoWithStorage[127.0.0.1:38803,DS-12774436-157b-4ea8-962b-77466694b092,DISK], DatanodeInfoWithStorage[127.0.0.1:42991,DS-df987c17-341c-41b2-b6bc-5f1c24ddf073,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-302791333-172.17.0.4-1595359396388:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43451,DS-b0a76117-d780-49b1-b5bf-0a32d7e41c82,DISK], DatanodeInfoWithStorage[127.0.0.1:33649,DS-dd2108d6-13a3-4d03-8fce-d76015d08aae,DISK], DatanodeInfoWithStorage[127.0.0.1:43172,DS-0bb126ba-5569-4d3d-97e7-42be66ffcbd5,DISK], DatanodeInfoWithStorage[127.0.0.1:44582,DS-eab4a149-0935-4e85-8c8f-45da83e401fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46316,DS-5ae3a2aa-4135-4cc4-9b23-c386397eedcc,DISK], DatanodeInfoWithStorage[127.0.0.1:45436,DS-c7c87d3c-e9e5-48cb-a5e3-bebf7a9492a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34175,DS-f3953399-512d-4ad5-8e0f-e60c61a6c3eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33001,DS-c2f5ab9d-8222-42ea-ba3d-c066126223ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-302791333-172.17.0.4-1595359396388:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43451,DS-b0a76117-d780-49b1-b5bf-0a32d7e41c82,DISK], DatanodeInfoWithStorage[127.0.0.1:33649,DS-dd2108d6-13a3-4d03-8fce-d76015d08aae,DISK], DatanodeInfoWithStorage[127.0.0.1:43172,DS-0bb126ba-5569-4d3d-97e7-42be66ffcbd5,DISK], DatanodeInfoWithStorage[127.0.0.1:44582,DS-eab4a149-0935-4e85-8c8f-45da83e401fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46316,DS-5ae3a2aa-4135-4cc4-9b23-c386397eedcc,DISK], DatanodeInfoWithStorage[127.0.0.1:45436,DS-c7c87d3c-e9e5-48cb-a5e3-bebf7a9492a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34175,DS-f3953399-512d-4ad5-8e0f-e60c61a6c3eb,DISK], DatanodeInfoWithStorage[127.0.0.1:33001,DS-c2f5ab9d-8222-42ea-ba3d-c066126223ef,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.xframe.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-451923562-172.17.0.4-1595359704562:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45411,DS-a10b18a5-25f0-4277-84f8-87f222905ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:46850,DS-633ec67b-4962-4c3f-a412-b83833a9f765,DISK], DatanodeInfoWithStorage[127.0.0.1:45170,DS-fdbf2510-17cf-4b9d-98f7-88ffb980daf6,DISK], DatanodeInfoWithStorage[127.0.0.1:33552,DS-77ec1482-0a85-4190-adc7-58228f3d0d21,DISK], DatanodeInfoWithStorage[127.0.0.1:33306,DS-83840bf5-febf-4997-8d6b-3d7524e9d761,DISK], DatanodeInfoWithStorage[127.0.0.1:38300,DS-5136356e-f16e-49d2-9e24-8d1b6ba413af,DISK], DatanodeInfoWithStorage[127.0.0.1:43362,DS-6dad9621-bd57-486e-bdf2-8554ff0a6b26,DISK], DatanodeInfoWithStorage[127.0.0.1:37258,DS-2e6e2fa8-7bf9-4469-b736-85861412873a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-451923562-172.17.0.4-1595359704562:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45411,DS-a10b18a5-25f0-4277-84f8-87f222905ce2,DISK], DatanodeInfoWithStorage[127.0.0.1:46850,DS-633ec67b-4962-4c3f-a412-b83833a9f765,DISK], DatanodeInfoWithStorage[127.0.0.1:45170,DS-fdbf2510-17cf-4b9d-98f7-88ffb980daf6,DISK], DatanodeInfoWithStorage[127.0.0.1:33552,DS-77ec1482-0a85-4190-adc7-58228f3d0d21,DISK], DatanodeInfoWithStorage[127.0.0.1:33306,DS-83840bf5-febf-4997-8d6b-3d7524e9d761,DISK], DatanodeInfoWithStorage[127.0.0.1:38300,DS-5136356e-f16e-49d2-9e24-8d1b6ba413af,DISK], DatanodeInfoWithStorage[127.0.0.1:43362,DS-6dad9621-bd57-486e-bdf2-8554ff0a6b26,DISK], DatanodeInfoWithStorage[127.0.0.1:37258,DS-2e6e2fa8-7bf9-4469-b736-85861412873a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5030
