reconf_parameter: hadoop.security.authorization
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-694927630-172.17.0.4-1596915206522:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41328,DS-6e818c21-e146-42ba-af4e-a30e91e595d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43676,DS-cea05d27-e289-4535-af4f-61b3514dd696,DISK], DatanodeInfoWithStorage[127.0.0.1:41022,DS-dd6f0e3d-436e-4346-b1bb-f5975633bdf5,DISK], DatanodeInfoWithStorage[127.0.0.1:38667,DS-d6f38a59-7e51-4003-9641-048b4f1f5d7a,DISK], DatanodeInfoWithStorage[127.0.0.1:34028,DS-782aa75b-59e1-4903-9bea-fec24e7e3d55,DISK], DatanodeInfoWithStorage[127.0.0.1:34477,DS-b44f0f4a-5fa5-4a6f-8361-7a10d35ccc93,DISK], DatanodeInfoWithStorage[127.0.0.1:41605,DS-07bd64e8-2ee8-4cc5-b257-e464d46d665f,DISK], DatanodeInfoWithStorage[127.0.0.1:40411,DS-5e1bec8c-4a6e-4b3b-a80a-3f1c56de5ea9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-694927630-172.17.0.4-1596915206522:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41328,DS-6e818c21-e146-42ba-af4e-a30e91e595d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43676,DS-cea05d27-e289-4535-af4f-61b3514dd696,DISK], DatanodeInfoWithStorage[127.0.0.1:41022,DS-dd6f0e3d-436e-4346-b1bb-f5975633bdf5,DISK], DatanodeInfoWithStorage[127.0.0.1:38667,DS-d6f38a59-7e51-4003-9641-048b4f1f5d7a,DISK], DatanodeInfoWithStorage[127.0.0.1:34028,DS-782aa75b-59e1-4903-9bea-fec24e7e3d55,DISK], DatanodeInfoWithStorage[127.0.0.1:34477,DS-b44f0f4a-5fa5-4a6f-8361-7a10d35ccc93,DISK], DatanodeInfoWithStorage[127.0.0.1:41605,DS-07bd64e8-2ee8-4cc5-b257-e464d46d665f,DISK], DatanodeInfoWithStorage[127.0.0.1:40411,DS-5e1bec8c-4a6e-4b3b-a80a-3f1c56de5ea9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.security.authorization
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1756415929-172.17.0.4-1596915248522:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44891,DS-59d3e243-d8ba-4b75-b47f-23636f7a4616,DISK], DatanodeInfoWithStorage[127.0.0.1:39762,DS-87d72612-283d-487d-84fa-462878a88fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:44326,DS-1e0519ed-9432-4804-b09b-fe5737adc07c,DISK], DatanodeInfoWithStorage[127.0.0.1:33252,DS-657f3e09-e359-447e-afba-a8d9e3cff157,DISK], DatanodeInfoWithStorage[127.0.0.1:42440,DS-29bc1cf2-ff4c-488f-aaf2-e6617fd98f3a,DISK], DatanodeInfoWithStorage[127.0.0.1:43315,DS-4c8ec4bf-d245-43c6-899b-b3026ea1ec39,DISK], DatanodeInfoWithStorage[127.0.0.1:46005,DS-08b95c0c-9a8b-46f2-9b47-0a1c1055777c,DISK], DatanodeInfoWithStorage[127.0.0.1:36363,DS-89952fd1-4882-4456-bad3-73f53ae53bf5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1756415929-172.17.0.4-1596915248522:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44891,DS-59d3e243-d8ba-4b75-b47f-23636f7a4616,DISK], DatanodeInfoWithStorage[127.0.0.1:39762,DS-87d72612-283d-487d-84fa-462878a88fdd,DISK], DatanodeInfoWithStorage[127.0.0.1:44326,DS-1e0519ed-9432-4804-b09b-fe5737adc07c,DISK], DatanodeInfoWithStorage[127.0.0.1:33252,DS-657f3e09-e359-447e-afba-a8d9e3cff157,DISK], DatanodeInfoWithStorage[127.0.0.1:42440,DS-29bc1cf2-ff4c-488f-aaf2-e6617fd98f3a,DISK], DatanodeInfoWithStorage[127.0.0.1:43315,DS-4c8ec4bf-d245-43c6-899b-b3026ea1ec39,DISK], DatanodeInfoWithStorage[127.0.0.1:46005,DS-08b95c0c-9a8b-46f2-9b47-0a1c1055777c,DISK], DatanodeInfoWithStorage[127.0.0.1:36363,DS-89952fd1-4882-4456-bad3-73f53ae53bf5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1610874381-172.17.0.4-1596915739252:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39092,DS-1e76aa5e-0576-44fd-9682-07f2a6d91746,DISK], DatanodeInfoWithStorage[127.0.0.1:35066,DS-564a4431-76ff-453a-872e-528835cfd5f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38369,DS-d96d7f0c-c811-405d-9af8-7486b6e15b90,DISK], DatanodeInfoWithStorage[127.0.0.1:35678,DS-51f79307-7dde-4ba4-976c-05624f0f1a34,DISK], DatanodeInfoWithStorage[127.0.0.1:43100,DS-a381f8d3-9969-47ad-adf8-64af5c562043,DISK], DatanodeInfoWithStorage[127.0.0.1:44284,DS-df1dbb47-5b8c-4c9d-a474-0e77dae25e54,DISK], DatanodeInfoWithStorage[127.0.0.1:45520,DS-dea29779-64f8-468d-82df-dcd7729ef8be,DISK], DatanodeInfoWithStorage[127.0.0.1:35693,DS-fbaad4f0-793c-47da-9be5-e216eaef0b0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1610874381-172.17.0.4-1596915739252:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39092,DS-1e76aa5e-0576-44fd-9682-07f2a6d91746,DISK], DatanodeInfoWithStorage[127.0.0.1:35066,DS-564a4431-76ff-453a-872e-528835cfd5f2,DISK], DatanodeInfoWithStorage[127.0.0.1:38369,DS-d96d7f0c-c811-405d-9af8-7486b6e15b90,DISK], DatanodeInfoWithStorage[127.0.0.1:35678,DS-51f79307-7dde-4ba4-976c-05624f0f1a34,DISK], DatanodeInfoWithStorage[127.0.0.1:43100,DS-a381f8d3-9969-47ad-adf8-64af5c562043,DISK], DatanodeInfoWithStorage[127.0.0.1:44284,DS-df1dbb47-5b8c-4c9d-a474-0e77dae25e54,DISK], DatanodeInfoWithStorage[127.0.0.1:45520,DS-dea29779-64f8-468d-82df-dcd7729ef8be,DISK], DatanodeInfoWithStorage[127.0.0.1:35693,DS-fbaad4f0-793c-47da-9be5-e216eaef0b0b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-276328712-172.17.0.4-1596915952411:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42352,DS-62501afd-d320-4c26-ac23-80c2e2d0febf,DISK], DatanodeInfoWithStorage[127.0.0.1:39797,DS-9b84ca13-3a75-4d8b-ada5-1106927c1cd3,DISK], DatanodeInfoWithStorage[127.0.0.1:34096,DS-296008b8-ae52-479e-8c74-563bf771fbad,DISK], DatanodeInfoWithStorage[127.0.0.1:39750,DS-c4486fd2-94a6-4c8f-a8dd-5b3c0b4ebaa2,DISK], DatanodeInfoWithStorage[127.0.0.1:42604,DS-4aec1dec-85ff-46dd-a71d-3c6f33227de7,DISK], DatanodeInfoWithStorage[127.0.0.1:35369,DS-748a96ea-138a-41fd-a2ac-9da5136d8200,DISK], DatanodeInfoWithStorage[127.0.0.1:42385,DS-ce46ebe4-d3d5-42bd-ac31-dd7580cb76c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38356,DS-fd1f75a8-dd16-476d-9b87-395ef3c524e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-276328712-172.17.0.4-1596915952411:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42352,DS-62501afd-d320-4c26-ac23-80c2e2d0febf,DISK], DatanodeInfoWithStorage[127.0.0.1:39797,DS-9b84ca13-3a75-4d8b-ada5-1106927c1cd3,DISK], DatanodeInfoWithStorage[127.0.0.1:34096,DS-296008b8-ae52-479e-8c74-563bf771fbad,DISK], DatanodeInfoWithStorage[127.0.0.1:39750,DS-c4486fd2-94a6-4c8f-a8dd-5b3c0b4ebaa2,DISK], DatanodeInfoWithStorage[127.0.0.1:42604,DS-4aec1dec-85ff-46dd-a71d-3c6f33227de7,DISK], DatanodeInfoWithStorage[127.0.0.1:35369,DS-748a96ea-138a-41fd-a2ac-9da5136d8200,DISK], DatanodeInfoWithStorage[127.0.0.1:42385,DS-ce46ebe4-d3d5-42bd-ac31-dd7580cb76c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38356,DS-fd1f75a8-dd16-476d-9b87-395ef3c524e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1037391414-172.17.0.4-1596916051402:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45903,DS-df93b25c-5df8-469d-a5f4-52ac97d9e471,DISK], DatanodeInfoWithStorage[127.0.0.1:42698,DS-8c3a59ee-51c7-4400-a888-dfcb81acf871,DISK], DatanodeInfoWithStorage[127.0.0.1:37956,DS-44c43fc1-195b-4a12-8684-10eb3651e1a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36654,DS-aa0770a3-5f28-42f1-905b-71e4b4c852fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45430,DS-40a64808-0696-4361-9ab0-4e0c04c68227,DISK], DatanodeInfoWithStorage[127.0.0.1:35625,DS-1cae517b-9a1a-40a5-84f2-2ebb124c517d,DISK], DatanodeInfoWithStorage[127.0.0.1:35353,DS-59f73108-cccf-4c4c-aab2-e846cbb315e6,DISK], DatanodeInfoWithStorage[127.0.0.1:34867,DS-881d8e2f-a21a-4b68-a1e1-7dac82dd1911,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1037391414-172.17.0.4-1596916051402:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45903,DS-df93b25c-5df8-469d-a5f4-52ac97d9e471,DISK], DatanodeInfoWithStorage[127.0.0.1:42698,DS-8c3a59ee-51c7-4400-a888-dfcb81acf871,DISK], DatanodeInfoWithStorage[127.0.0.1:37956,DS-44c43fc1-195b-4a12-8684-10eb3651e1a3,DISK], DatanodeInfoWithStorage[127.0.0.1:36654,DS-aa0770a3-5f28-42f1-905b-71e4b4c852fd,DISK], DatanodeInfoWithStorage[127.0.0.1:45430,DS-40a64808-0696-4361-9ab0-4e0c04c68227,DISK], DatanodeInfoWithStorage[127.0.0.1:35625,DS-1cae517b-9a1a-40a5-84f2-2ebb124c517d,DISK], DatanodeInfoWithStorage[127.0.0.1:35353,DS-59f73108-cccf-4c4c-aab2-e846cbb315e6,DISK], DatanodeInfoWithStorage[127.0.0.1:34867,DS-881d8e2f-a21a-4b68-a1e1-7dac82dd1911,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1850580845-172.17.0.4-1596916621222:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35000,DS-f7490d6c-13c8-46e6-a7cd-ae694b620c97,DISK], DatanodeInfoWithStorage[127.0.0.1:40779,DS-92f2b8e0-aebc-4d73-95fa-2316e7a0db0d,DISK], DatanodeInfoWithStorage[127.0.0.1:40980,DS-c46dc046-89a9-4f37-b05b-12a5a40b1b11,DISK], DatanodeInfoWithStorage[127.0.0.1:46749,DS-c52aaab6-6728-447c-8928-7e5c8e01cf08,DISK], DatanodeInfoWithStorage[127.0.0.1:41926,DS-9a80fc6f-e4eb-4f47-b1dd-1be940917451,DISK], DatanodeInfoWithStorage[127.0.0.1:32846,DS-f85f5c05-0e3b-4e48-88dc-2707311fe2bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40207,DS-05b28679-6264-45be-a5ed-1e22ebfe03be,DISK], DatanodeInfoWithStorage[127.0.0.1:42056,DS-456a7aaa-ce00-4df4-b8c7-db8bbe545fc0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1850580845-172.17.0.4-1596916621222:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35000,DS-f7490d6c-13c8-46e6-a7cd-ae694b620c97,DISK], DatanodeInfoWithStorage[127.0.0.1:40779,DS-92f2b8e0-aebc-4d73-95fa-2316e7a0db0d,DISK], DatanodeInfoWithStorage[127.0.0.1:40980,DS-c46dc046-89a9-4f37-b05b-12a5a40b1b11,DISK], DatanodeInfoWithStorage[127.0.0.1:46749,DS-c52aaab6-6728-447c-8928-7e5c8e01cf08,DISK], DatanodeInfoWithStorage[127.0.0.1:41926,DS-9a80fc6f-e4eb-4f47-b1dd-1be940917451,DISK], DatanodeInfoWithStorage[127.0.0.1:32846,DS-f85f5c05-0e3b-4e48-88dc-2707311fe2bf,DISK], DatanodeInfoWithStorage[127.0.0.1:40207,DS-05b28679-6264-45be-a5ed-1e22ebfe03be,DISK], DatanodeInfoWithStorage[127.0.0.1:42056,DS-456a7aaa-ce00-4df4-b8c7-db8bbe545fc0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-327736418-172.17.0.4-1596917048197:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36225,DS-6de7a64a-91f7-498c-acd0-7dc604375294,DISK], DatanodeInfoWithStorage[127.0.0.1:37909,DS-1c05ec5a-3ec9-4f02-9933-1328b7f7690e,DISK], DatanodeInfoWithStorage[127.0.0.1:43793,DS-8cf7ea34-247b-4370-bea9-a3f58b634882,DISK], DatanodeInfoWithStorage[127.0.0.1:43816,DS-c7ef1b54-2175-4eb6-965f-8da63b572856,DISK], DatanodeInfoWithStorage[127.0.0.1:39660,DS-e58a7e29-fe26-4444-a9a2-57a2eef513a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33696,DS-d06011f2-e2ea-4d89-8abf-a12907a64ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:40901,DS-0b651fce-2541-4676-9691-130aae0c51e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40232,DS-424b2ea2-c3a0-4a21-9103-e98457a71c87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-327736418-172.17.0.4-1596917048197:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36225,DS-6de7a64a-91f7-498c-acd0-7dc604375294,DISK], DatanodeInfoWithStorage[127.0.0.1:37909,DS-1c05ec5a-3ec9-4f02-9933-1328b7f7690e,DISK], DatanodeInfoWithStorage[127.0.0.1:43793,DS-8cf7ea34-247b-4370-bea9-a3f58b634882,DISK], DatanodeInfoWithStorage[127.0.0.1:43816,DS-c7ef1b54-2175-4eb6-965f-8da63b572856,DISK], DatanodeInfoWithStorage[127.0.0.1:39660,DS-e58a7e29-fe26-4444-a9a2-57a2eef513a2,DISK], DatanodeInfoWithStorage[127.0.0.1:33696,DS-d06011f2-e2ea-4d89-8abf-a12907a64ddb,DISK], DatanodeInfoWithStorage[127.0.0.1:40901,DS-0b651fce-2541-4676-9691-130aae0c51e7,DISK], DatanodeInfoWithStorage[127.0.0.1:40232,DS-424b2ea2-c3a0-4a21-9103-e98457a71c87,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1080021372-172.17.0.4-1596917466723:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46021,DS-0e7b2ff0-3562-4267-8f13-329d4fb5c08b,DISK], DatanodeInfoWithStorage[127.0.0.1:40981,DS-d8da7fa6-1964-4aa5-aa53-0906e3f672c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40218,DS-1cb76238-710c-475c-84b2-b77f365800d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37399,DS-b9686b04-d629-4c12-ad7f-9e60abc5197e,DISK], DatanodeInfoWithStorage[127.0.0.1:40650,DS-609c9b41-72ce-4a2f-a2c4-3450398cf307,DISK], DatanodeInfoWithStorage[127.0.0.1:39828,DS-76439f8e-3c30-44f0-b5d8-a609caba161a,DISK], DatanodeInfoWithStorage[127.0.0.1:39378,DS-0d48ff82-a3da-4580-b395-e825e3ce6a85,DISK], DatanodeInfoWithStorage[127.0.0.1:46287,DS-4a84674d-4128-49d1-8c8c-5793967f2e6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1080021372-172.17.0.4-1596917466723:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46021,DS-0e7b2ff0-3562-4267-8f13-329d4fb5c08b,DISK], DatanodeInfoWithStorage[127.0.0.1:40981,DS-d8da7fa6-1964-4aa5-aa53-0906e3f672c7,DISK], DatanodeInfoWithStorage[127.0.0.1:40218,DS-1cb76238-710c-475c-84b2-b77f365800d8,DISK], DatanodeInfoWithStorage[127.0.0.1:37399,DS-b9686b04-d629-4c12-ad7f-9e60abc5197e,DISK], DatanodeInfoWithStorage[127.0.0.1:40650,DS-609c9b41-72ce-4a2f-a2c4-3450398cf307,DISK], DatanodeInfoWithStorage[127.0.0.1:39828,DS-76439f8e-3c30-44f0-b5d8-a609caba161a,DISK], DatanodeInfoWithStorage[127.0.0.1:39378,DS-0d48ff82-a3da-4580-b395-e825e3ce6a85,DISK], DatanodeInfoWithStorage[127.0.0.1:46287,DS-4a84674d-4128-49d1-8c8c-5793967f2e6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.security.authorization
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1881332520-172.17.0.4-1596917499400:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36222,DS-5ac945c9-9425-45a1-84e5-106fc8841f8b,DISK], DatanodeInfoWithStorage[127.0.0.1:38253,DS-118656e5-3098-4849-860a-eb757ba7fcdd,DISK], DatanodeInfoWithStorage[127.0.0.1:41566,DS-4428de6c-265c-4ef2-a5d4-be6fe8b3793f,DISK], DatanodeInfoWithStorage[127.0.0.1:34929,DS-bcbfbb5c-7daa-4b3c-9366-4151f53ec07c,DISK], DatanodeInfoWithStorage[127.0.0.1:46748,DS-7ce66bea-d1a0-4409-9474-f7e0df503373,DISK], DatanodeInfoWithStorage[127.0.0.1:41664,DS-6b3256f9-7d64-4297-924d-7cea918ffc3c,DISK], DatanodeInfoWithStorage[127.0.0.1:45333,DS-c209ed19-c716-4cd2-81b8-671d19809926,DISK], DatanodeInfoWithStorage[127.0.0.1:37318,DS-accf7a57-c277-4cc9-b47f-3a0f6519a9ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1881332520-172.17.0.4-1596917499400:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36222,DS-5ac945c9-9425-45a1-84e5-106fc8841f8b,DISK], DatanodeInfoWithStorage[127.0.0.1:38253,DS-118656e5-3098-4849-860a-eb757ba7fcdd,DISK], DatanodeInfoWithStorage[127.0.0.1:41566,DS-4428de6c-265c-4ef2-a5d4-be6fe8b3793f,DISK], DatanodeInfoWithStorage[127.0.0.1:34929,DS-bcbfbb5c-7daa-4b3c-9366-4151f53ec07c,DISK], DatanodeInfoWithStorage[127.0.0.1:46748,DS-7ce66bea-d1a0-4409-9474-f7e0df503373,DISK], DatanodeInfoWithStorage[127.0.0.1:41664,DS-6b3256f9-7d64-4297-924d-7cea918ffc3c,DISK], DatanodeInfoWithStorage[127.0.0.1:45333,DS-c209ed19-c716-4cd2-81b8-671d19809926,DISK], DatanodeInfoWithStorage[127.0.0.1:37318,DS-accf7a57-c277-4cc9-b47f-3a0f6519a9ba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-576321072-172.17.0.4-1596917667108:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42917,DS-25105c63-4c5e-4d2e-9fcc-cf526010a99f,DISK], DatanodeInfoWithStorage[127.0.0.1:43590,DS-f7989d5e-5236-480c-bcd3-f9576d293be0,DISK], DatanodeInfoWithStorage[127.0.0.1:44630,DS-46c26df6-b5a8-4844-b404-31ca9d2a0b51,DISK], DatanodeInfoWithStorage[127.0.0.1:33331,DS-fb3d8a1c-88f8-444a-8a6e-481ff244f5d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37868,DS-02bc75cc-cc06-4f81-b457-79056e14744d,DISK], DatanodeInfoWithStorage[127.0.0.1:41978,DS-38676950-b3f7-4be8-b426-c5634e3671eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34387,DS-9058eb34-46ff-4e4a-ab01-0d8093f24105,DISK], DatanodeInfoWithStorage[127.0.0.1:38402,DS-0d736c51-27a7-4387-8730-179312fbb319,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-576321072-172.17.0.4-1596917667108:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42917,DS-25105c63-4c5e-4d2e-9fcc-cf526010a99f,DISK], DatanodeInfoWithStorage[127.0.0.1:43590,DS-f7989d5e-5236-480c-bcd3-f9576d293be0,DISK], DatanodeInfoWithStorage[127.0.0.1:44630,DS-46c26df6-b5a8-4844-b404-31ca9d2a0b51,DISK], DatanodeInfoWithStorage[127.0.0.1:33331,DS-fb3d8a1c-88f8-444a-8a6e-481ff244f5d1,DISK], DatanodeInfoWithStorage[127.0.0.1:37868,DS-02bc75cc-cc06-4f81-b457-79056e14744d,DISK], DatanodeInfoWithStorage[127.0.0.1:41978,DS-38676950-b3f7-4be8-b426-c5634e3671eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34387,DS-9058eb34-46ff-4e4a-ab01-0d8093f24105,DISK], DatanodeInfoWithStorage[127.0.0.1:38402,DS-0d736c51-27a7-4387-8730-179312fbb319,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-231610028-172.17.0.4-1596917817715:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40800,DS-3d995081-4999-4169-a60e-283b2dcf2b82,DISK], DatanodeInfoWithStorage[127.0.0.1:36675,DS-68203003-c221-498b-b72d-fd6d6053aabd,DISK], DatanodeInfoWithStorage[127.0.0.1:34596,DS-40661b3e-2485-4789-9042-a15eff9236ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42700,DS-64832651-bdfe-404f-be96-c81bad765671,DISK], DatanodeInfoWithStorage[127.0.0.1:36699,DS-6628ca45-e7ff-4a7f-9a4f-073b7c3ee512,DISK], DatanodeInfoWithStorage[127.0.0.1:39449,DS-e0d88f3d-a282-4003-b641-4272aec68be4,DISK], DatanodeInfoWithStorage[127.0.0.1:46440,DS-3b260877-d441-4a45-884b-7353a9c3ae92,DISK], DatanodeInfoWithStorage[127.0.0.1:37380,DS-79660507-a313-46ac-8ff8-7199d35e2a65,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-231610028-172.17.0.4-1596917817715:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40800,DS-3d995081-4999-4169-a60e-283b2dcf2b82,DISK], DatanodeInfoWithStorage[127.0.0.1:36675,DS-68203003-c221-498b-b72d-fd6d6053aabd,DISK], DatanodeInfoWithStorage[127.0.0.1:34596,DS-40661b3e-2485-4789-9042-a15eff9236ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42700,DS-64832651-bdfe-404f-be96-c81bad765671,DISK], DatanodeInfoWithStorage[127.0.0.1:36699,DS-6628ca45-e7ff-4a7f-9a4f-073b7c3ee512,DISK], DatanodeInfoWithStorage[127.0.0.1:39449,DS-e0d88f3d-a282-4003-b641-4272aec68be4,DISK], DatanodeInfoWithStorage[127.0.0.1:46440,DS-3b260877-d441-4a45-884b-7353a9c3ae92,DISK], DatanodeInfoWithStorage[127.0.0.1:37380,DS-79660507-a313-46ac-8ff8-7199d35e2a65,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1243960861-172.17.0.4-1596918046342:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36158,DS-9285d06b-0cf9-4237-b7bd-1891c0d7ff78,DISK], DatanodeInfoWithStorage[127.0.0.1:37235,DS-6bbbef4a-5091-4685-bbe2-91761649b21d,DISK], DatanodeInfoWithStorage[127.0.0.1:46802,DS-cd4971b6-7d14-4655-a63f-76d4e00844f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44912,DS-98aa6959-cb0c-48ac-a32e-9bf10e8910b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45688,DS-08026bc3-eb84-4c21-b112-2297c6a3247e,DISK], DatanodeInfoWithStorage[127.0.0.1:37154,DS-ffd546b3-99ff-494f-8b82-d42c7785ab85,DISK], DatanodeInfoWithStorage[127.0.0.1:45049,DS-a7b97f7d-abec-4e91-bd04-d9b225325aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:37393,DS-c700a28a-7ef0-479d-b5b4-38d75b928ef2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1243960861-172.17.0.4-1596918046342:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36158,DS-9285d06b-0cf9-4237-b7bd-1891c0d7ff78,DISK], DatanodeInfoWithStorage[127.0.0.1:37235,DS-6bbbef4a-5091-4685-bbe2-91761649b21d,DISK], DatanodeInfoWithStorage[127.0.0.1:46802,DS-cd4971b6-7d14-4655-a63f-76d4e00844f2,DISK], DatanodeInfoWithStorage[127.0.0.1:44912,DS-98aa6959-cb0c-48ac-a32e-9bf10e8910b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45688,DS-08026bc3-eb84-4c21-b112-2297c6a3247e,DISK], DatanodeInfoWithStorage[127.0.0.1:37154,DS-ffd546b3-99ff-494f-8b82-d42c7785ab85,DISK], DatanodeInfoWithStorage[127.0.0.1:45049,DS-a7b97f7d-abec-4e91-bd04-d9b225325aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:37393,DS-c700a28a-7ef0-479d-b5b4-38d75b928ef2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2055974001-172.17.0.4-1596918773930:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32886,DS-8c9d4e8a-e094-40f4-9c00-0c4b7a19c04a,DISK], DatanodeInfoWithStorage[127.0.0.1:33338,DS-ccde3062-3388-4135-a61c-316f012339ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34417,DS-cb6dde01-33a2-452f-a4d9-6fe7eb4fed25,DISK], DatanodeInfoWithStorage[127.0.0.1:40152,DS-e8929b0c-ad68-45a0-be27-bd444217c0ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46373,DS-0070a0ac-0447-4ea8-8852-e7de2b1c16aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36852,DS-99c9255b-2c02-4c4e-a940-e484ea929d28,DISK], DatanodeInfoWithStorage[127.0.0.1:43056,DS-28e950ac-757e-4c60-bff6-4b6261224c44,DISK], DatanodeInfoWithStorage[127.0.0.1:38040,DS-191b698e-c3fd-4fe2-84f5-ac1ccae61f91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2055974001-172.17.0.4-1596918773930:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32886,DS-8c9d4e8a-e094-40f4-9c00-0c4b7a19c04a,DISK], DatanodeInfoWithStorage[127.0.0.1:33338,DS-ccde3062-3388-4135-a61c-316f012339ca,DISK], DatanodeInfoWithStorage[127.0.0.1:34417,DS-cb6dde01-33a2-452f-a4d9-6fe7eb4fed25,DISK], DatanodeInfoWithStorage[127.0.0.1:40152,DS-e8929b0c-ad68-45a0-be27-bd444217c0ad,DISK], DatanodeInfoWithStorage[127.0.0.1:46373,DS-0070a0ac-0447-4ea8-8852-e7de2b1c16aa,DISK], DatanodeInfoWithStorage[127.0.0.1:36852,DS-99c9255b-2c02-4c4e-a940-e484ea929d28,DISK], DatanodeInfoWithStorage[127.0.0.1:43056,DS-28e950ac-757e-4c60-bff6-4b6261224c44,DISK], DatanodeInfoWithStorage[127.0.0.1:38040,DS-191b698e-c3fd-4fe2-84f5-ac1ccae61f91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-530787135-172.17.0.4-1596918805705:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38406,DS-26c3b548-c279-4244-8be2-aa89b3946640,DISK], DatanodeInfoWithStorage[127.0.0.1:38938,DS-b7e04424-f003-4aa3-a35d-d8e81d7fc540,DISK], DatanodeInfoWithStorage[127.0.0.1:38229,DS-52d2f8de-5822-4574-ae78-ef61392d0fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:45883,DS-4ef11fc1-34d2-4370-bbc5-a86a71dafb63,DISK], DatanodeInfoWithStorage[127.0.0.1:36042,DS-6319f7bb-b1ac-4e3b-8f58-5d5a8d278e39,DISK], DatanodeInfoWithStorage[127.0.0.1:44009,DS-7e4f7464-3239-4689-8ba5-ef87de91ab86,DISK], DatanodeInfoWithStorage[127.0.0.1:37740,DS-43350897-e599-4e3f-9f31-0ef0d1e383e6,DISK], DatanodeInfoWithStorage[127.0.0.1:43623,DS-137b113f-e6bb-41e8-8db6-dc3350373fea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-530787135-172.17.0.4-1596918805705:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38406,DS-26c3b548-c279-4244-8be2-aa89b3946640,DISK], DatanodeInfoWithStorage[127.0.0.1:38938,DS-b7e04424-f003-4aa3-a35d-d8e81d7fc540,DISK], DatanodeInfoWithStorage[127.0.0.1:38229,DS-52d2f8de-5822-4574-ae78-ef61392d0fc5,DISK], DatanodeInfoWithStorage[127.0.0.1:45883,DS-4ef11fc1-34d2-4370-bbc5-a86a71dafb63,DISK], DatanodeInfoWithStorage[127.0.0.1:36042,DS-6319f7bb-b1ac-4e3b-8f58-5d5a8d278e39,DISK], DatanodeInfoWithStorage[127.0.0.1:44009,DS-7e4f7464-3239-4689-8ba5-ef87de91ab86,DISK], DatanodeInfoWithStorage[127.0.0.1:37740,DS-43350897-e599-4e3f-9f31-0ef0d1e383e6,DISK], DatanodeInfoWithStorage[127.0.0.1:43623,DS-137b113f-e6bb-41e8-8db6-dc3350373fea,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1577088360-172.17.0.4-1596919050132:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39021,DS-b820fef8-dc91-4514-adfc-65ecacb16849,DISK], DatanodeInfoWithStorage[127.0.0.1:42163,DS-db584f36-8a2d-459c-bb02-6ffee9bebcab,DISK], DatanodeInfoWithStorage[127.0.0.1:39975,DS-07db0ee3-905b-4409-a6fc-520734b4899c,DISK], DatanodeInfoWithStorage[127.0.0.1:41563,DS-a675d098-89c4-40e1-b0b0-9b7fe6c51d68,DISK], DatanodeInfoWithStorage[127.0.0.1:38712,DS-9a25b486-17fb-4c09-92ce-4993acfea28a,DISK], DatanodeInfoWithStorage[127.0.0.1:37589,DS-43400e00-0f49-4d1a-aec1-b769592c8db1,DISK], DatanodeInfoWithStorage[127.0.0.1:37558,DS-30e748f1-6756-4043-a893-74fd73eee898,DISK], DatanodeInfoWithStorage[127.0.0.1:41059,DS-bc0e6459-0361-4375-a7af-0ffef865d5f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1577088360-172.17.0.4-1596919050132:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39021,DS-b820fef8-dc91-4514-adfc-65ecacb16849,DISK], DatanodeInfoWithStorage[127.0.0.1:42163,DS-db584f36-8a2d-459c-bb02-6ffee9bebcab,DISK], DatanodeInfoWithStorage[127.0.0.1:39975,DS-07db0ee3-905b-4409-a6fc-520734b4899c,DISK], DatanodeInfoWithStorage[127.0.0.1:41563,DS-a675d098-89c4-40e1-b0b0-9b7fe6c51d68,DISK], DatanodeInfoWithStorage[127.0.0.1:38712,DS-9a25b486-17fb-4c09-92ce-4993acfea28a,DISK], DatanodeInfoWithStorage[127.0.0.1:37589,DS-43400e00-0f49-4d1a-aec1-b769592c8db1,DISK], DatanodeInfoWithStorage[127.0.0.1:37558,DS-30e748f1-6756-4043-a893-74fd73eee898,DISK], DatanodeInfoWithStorage[127.0.0.1:41059,DS-bc0e6459-0361-4375-a7af-0ffef865d5f1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-426925406-172.17.0.4-1596919372936:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34842,DS-25329b8c-b626-40a8-b5cd-f456a8a7fefd,DISK], DatanodeInfoWithStorage[127.0.0.1:32863,DS-7db16aa9-bcfc-40cb-b55b-65f4214a8a89,DISK], DatanodeInfoWithStorage[127.0.0.1:41237,DS-b30edb90-b0f3-40a8-ac30-35411ef7beb9,DISK], DatanodeInfoWithStorage[127.0.0.1:40967,DS-bbf483ef-0787-4dbd-a975-5600e0d8c4f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37778,DS-443fa629-d15e-45b6-9343-ca730a80ca47,DISK], DatanodeInfoWithStorage[127.0.0.1:45769,DS-8fc77860-d32e-4848-916c-626e994e4e77,DISK], DatanodeInfoWithStorage[127.0.0.1:33779,DS-1995c118-f09c-4237-b043-bd025caac523,DISK], DatanodeInfoWithStorage[127.0.0.1:38394,DS-dfb7b396-dac1-4bb9-9a04-06bba0c7ef60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-426925406-172.17.0.4-1596919372936:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34842,DS-25329b8c-b626-40a8-b5cd-f456a8a7fefd,DISK], DatanodeInfoWithStorage[127.0.0.1:32863,DS-7db16aa9-bcfc-40cb-b55b-65f4214a8a89,DISK], DatanodeInfoWithStorage[127.0.0.1:41237,DS-b30edb90-b0f3-40a8-ac30-35411ef7beb9,DISK], DatanodeInfoWithStorage[127.0.0.1:40967,DS-bbf483ef-0787-4dbd-a975-5600e0d8c4f2,DISK], DatanodeInfoWithStorage[127.0.0.1:37778,DS-443fa629-d15e-45b6-9343-ca730a80ca47,DISK], DatanodeInfoWithStorage[127.0.0.1:45769,DS-8fc77860-d32e-4848-916c-626e994e4e77,DISK], DatanodeInfoWithStorage[127.0.0.1:33779,DS-1995c118-f09c-4237-b043-bd025caac523,DISK], DatanodeInfoWithStorage[127.0.0.1:38394,DS-dfb7b396-dac1-4bb9-9a04-06bba0c7ef60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-335806391-172.17.0.4-1596919558292:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46176,DS-d7bc1e1e-e067-403e-97b9-bd2c74dd4505,DISK], DatanodeInfoWithStorage[127.0.0.1:45506,DS-06c2191c-a9b2-4e25-85c1-c0267e815bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:41012,DS-b25bdaa5-1bab-4bb7-a577-2375aa943383,DISK], DatanodeInfoWithStorage[127.0.0.1:45558,DS-a319f6f7-5045-43a1-8634-1a26654fc390,DISK], DatanodeInfoWithStorage[127.0.0.1:38880,DS-3d080bbc-ce68-49f5-80da-b4d091ef095a,DISK], DatanodeInfoWithStorage[127.0.0.1:39463,DS-0b2101ae-088a-4bef-8d46-b806a678ea98,DISK], DatanodeInfoWithStorage[127.0.0.1:42128,DS-a8d6cd28-84ac-4bd2-8194-b419ffe0b5e7,DISK], DatanodeInfoWithStorage[127.0.0.1:35382,DS-18a583a6-1a4c-4218-a3c3-f87c959264aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-335806391-172.17.0.4-1596919558292:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46176,DS-d7bc1e1e-e067-403e-97b9-bd2c74dd4505,DISK], DatanodeInfoWithStorage[127.0.0.1:45506,DS-06c2191c-a9b2-4e25-85c1-c0267e815bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:41012,DS-b25bdaa5-1bab-4bb7-a577-2375aa943383,DISK], DatanodeInfoWithStorage[127.0.0.1:45558,DS-a319f6f7-5045-43a1-8634-1a26654fc390,DISK], DatanodeInfoWithStorage[127.0.0.1:38880,DS-3d080bbc-ce68-49f5-80da-b4d091ef095a,DISK], DatanodeInfoWithStorage[127.0.0.1:39463,DS-0b2101ae-088a-4bef-8d46-b806a678ea98,DISK], DatanodeInfoWithStorage[127.0.0.1:42128,DS-a8d6cd28-84ac-4bd2-8194-b419ffe0b5e7,DISK], DatanodeInfoWithStorage[127.0.0.1:35382,DS-18a583a6-1a4c-4218-a3c3-f87c959264aa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2044589330-172.17.0.4-1596919736449:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42331,DS-98f471d4-63ee-4fcc-bed9-acf7d7eb544c,DISK], DatanodeInfoWithStorage[127.0.0.1:35076,DS-99b54465-84fa-4ff1-9721-142627aa9232,DISK], DatanodeInfoWithStorage[127.0.0.1:35513,DS-3e950976-14e8-4c0d-934b-ef74eb25cbb8,DISK], DatanodeInfoWithStorage[127.0.0.1:34431,DS-74dcab13-75cf-4a8c-a967-21b0b12e116d,DISK], DatanodeInfoWithStorage[127.0.0.1:45278,DS-cb6f9f45-ed24-4555-9b4a-f54a05f3019a,DISK], DatanodeInfoWithStorage[127.0.0.1:44309,DS-df724884-4f57-4f21-864b-b6d7d16e37bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44784,DS-eb14876e-511f-4269-b78e-908c252ba0af,DISK], DatanodeInfoWithStorage[127.0.0.1:34589,DS-23e2f4af-7f7a-4ed9-95e6-06f9e3e94e0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2044589330-172.17.0.4-1596919736449:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42331,DS-98f471d4-63ee-4fcc-bed9-acf7d7eb544c,DISK], DatanodeInfoWithStorage[127.0.0.1:35076,DS-99b54465-84fa-4ff1-9721-142627aa9232,DISK], DatanodeInfoWithStorage[127.0.0.1:35513,DS-3e950976-14e8-4c0d-934b-ef74eb25cbb8,DISK], DatanodeInfoWithStorage[127.0.0.1:34431,DS-74dcab13-75cf-4a8c-a967-21b0b12e116d,DISK], DatanodeInfoWithStorage[127.0.0.1:45278,DS-cb6f9f45-ed24-4555-9b4a-f54a05f3019a,DISK], DatanodeInfoWithStorage[127.0.0.1:44309,DS-df724884-4f57-4f21-864b-b6d7d16e37bd,DISK], DatanodeInfoWithStorage[127.0.0.1:44784,DS-eb14876e-511f-4269-b78e-908c252ba0af,DISK], DatanodeInfoWithStorage[127.0.0.1:34589,DS-23e2f4af-7f7a-4ed9-95e6-06f9e3e94e0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-87216026-172.17.0.4-1596920155682:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46103,DS-97d1fba4-8995-4230-8783-78433f4e34a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46060,DS-3a8fbd66-21d1-437f-9659-ddf95b6540db,DISK], DatanodeInfoWithStorage[127.0.0.1:34868,DS-c1c380b6-fe2f-4a27-8f47-dcee4452dc91,DISK], DatanodeInfoWithStorage[127.0.0.1:36962,DS-704a15a5-ab03-46cd-b722-cc2f0af8f361,DISK], DatanodeInfoWithStorage[127.0.0.1:33169,DS-bca0079a-b695-4c90-9e5f-55903c28ca43,DISK], DatanodeInfoWithStorage[127.0.0.1:37028,DS-1af3d4b1-cacc-45d7-852d-a81c8fd2c7a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44805,DS-b6d80170-ca33-4fa1-aed9-e77cd71e2c71,DISK], DatanodeInfoWithStorage[127.0.0.1:41649,DS-7832d486-68b7-4aec-8979-74aa05fe918c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-87216026-172.17.0.4-1596920155682:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46103,DS-97d1fba4-8995-4230-8783-78433f4e34a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46060,DS-3a8fbd66-21d1-437f-9659-ddf95b6540db,DISK], DatanodeInfoWithStorage[127.0.0.1:34868,DS-c1c380b6-fe2f-4a27-8f47-dcee4452dc91,DISK], DatanodeInfoWithStorage[127.0.0.1:36962,DS-704a15a5-ab03-46cd-b722-cc2f0af8f361,DISK], DatanodeInfoWithStorage[127.0.0.1:33169,DS-bca0079a-b695-4c90-9e5f-55903c28ca43,DISK], DatanodeInfoWithStorage[127.0.0.1:37028,DS-1af3d4b1-cacc-45d7-852d-a81c8fd2c7a5,DISK], DatanodeInfoWithStorage[127.0.0.1:44805,DS-b6d80170-ca33-4fa1-aed9-e77cd71e2c71,DISK], DatanodeInfoWithStorage[127.0.0.1:41649,DS-7832d486-68b7-4aec-8979-74aa05fe918c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 4 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5187
