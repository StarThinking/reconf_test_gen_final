reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1501649867-172.17.0.12-1595343831227:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44633,DS-52851075-f005-4e15-9d79-5aeb12f582b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34608,DS-d0848013-6478-46e3-8607-48762b82d148,DISK], DatanodeInfoWithStorage[127.0.0.1:37213,DS-fe02d472-645e-43f1-8802-8486b30ee311,DISK], DatanodeInfoWithStorage[127.0.0.1:41681,DS-cb3ed28e-e49f-47a1-a4e6-526c4807eef7,DISK], DatanodeInfoWithStorage[127.0.0.1:42293,DS-36c61b3f-7324-41cd-bbf8-6249e46165b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36510,DS-d7f400d0-e9be-43a8-ae88-27fb04db5e99,DISK], DatanodeInfoWithStorage[127.0.0.1:34276,DS-fad46ced-5113-4093-bedf-eee1af9d34d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46614,DS-2e2e99b4-e841-47ac-9123-4eeb9943682e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1501649867-172.17.0.12-1595343831227:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44633,DS-52851075-f005-4e15-9d79-5aeb12f582b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34608,DS-d0848013-6478-46e3-8607-48762b82d148,DISK], DatanodeInfoWithStorage[127.0.0.1:37213,DS-fe02d472-645e-43f1-8802-8486b30ee311,DISK], DatanodeInfoWithStorage[127.0.0.1:41681,DS-cb3ed28e-e49f-47a1-a4e6-526c4807eef7,DISK], DatanodeInfoWithStorage[127.0.0.1:42293,DS-36c61b3f-7324-41cd-bbf8-6249e46165b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36510,DS-d7f400d0-e9be-43a8-ae88-27fb04db5e99,DISK], DatanodeInfoWithStorage[127.0.0.1:34276,DS-fad46ced-5113-4093-bedf-eee1af9d34d3,DISK], DatanodeInfoWithStorage[127.0.0.1:46614,DS-2e2e99b4-e841-47ac-9123-4eeb9943682e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-456902953-172.17.0.12-1595344314781:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35194,DS-31abaeab-71aa-41cb-a353-286a5abaf8c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36427,DS-94692242-840f-4b12-ba44-4ffab3db3f85,DISK], DatanodeInfoWithStorage[127.0.0.1:40236,DS-50ad3b51-db98-4609-b574-f8344733d7d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36500,DS-fe468cbe-cb0d-4f7f-bd69-3d7059709de9,DISK], DatanodeInfoWithStorage[127.0.0.1:33135,DS-8cc7acdd-e4c5-4a82-8048-3aa062e9ba29,DISK], DatanodeInfoWithStorage[127.0.0.1:39816,DS-433e09db-a4b4-40f8-82d8-f9f2ac90a577,DISK], DatanodeInfoWithStorage[127.0.0.1:42565,DS-a0b8e94a-9428-43ec-8566-37e75dd7ab5f,DISK], DatanodeInfoWithStorage[127.0.0.1:43596,DS-2e85c9a4-6548-45de-8916-0163da57a738,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-456902953-172.17.0.12-1595344314781:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35194,DS-31abaeab-71aa-41cb-a353-286a5abaf8c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36427,DS-94692242-840f-4b12-ba44-4ffab3db3f85,DISK], DatanodeInfoWithStorage[127.0.0.1:40236,DS-50ad3b51-db98-4609-b574-f8344733d7d0,DISK], DatanodeInfoWithStorage[127.0.0.1:36500,DS-fe468cbe-cb0d-4f7f-bd69-3d7059709de9,DISK], DatanodeInfoWithStorage[127.0.0.1:33135,DS-8cc7acdd-e4c5-4a82-8048-3aa062e9ba29,DISK], DatanodeInfoWithStorage[127.0.0.1:39816,DS-433e09db-a4b4-40f8-82d8-f9f2ac90a577,DISK], DatanodeInfoWithStorage[127.0.0.1:42565,DS-a0b8e94a-9428-43ec-8566-37e75dd7ab5f,DISK], DatanodeInfoWithStorage[127.0.0.1:43596,DS-2e85c9a4-6548-45de-8916-0163da57a738,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-300845331-172.17.0.12-1595345446135:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32977,DS-5a5e908a-a353-4e53-95c7-fbf2837311bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40673,DS-ca651fab-2f00-43a0-880c-62c60b3c1a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:34134,DS-02ff1ba1-840f-4a82-8dbf-c364219a80c0,DISK], DatanodeInfoWithStorage[127.0.0.1:44920,DS-e75f1a9a-e6f2-45cc-8e33-6f998601f9a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42484,DS-d1d5a606-aaf3-41b0-8e3e-2c09773c1da0,DISK], DatanodeInfoWithStorage[127.0.0.1:42172,DS-fca719a5-031c-4a36-9d3d-f5a2ec8e88b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38984,DS-ccafbd36-d7d6-4f40-8a63-13a3f74b5ada,DISK], DatanodeInfoWithStorage[127.0.0.1:35259,DS-4f6d9150-30a4-46da-a62f-d67958d2b4c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-300845331-172.17.0.12-1595345446135:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32977,DS-5a5e908a-a353-4e53-95c7-fbf2837311bb,DISK], DatanodeInfoWithStorage[127.0.0.1:40673,DS-ca651fab-2f00-43a0-880c-62c60b3c1a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:34134,DS-02ff1ba1-840f-4a82-8dbf-c364219a80c0,DISK], DatanodeInfoWithStorage[127.0.0.1:44920,DS-e75f1a9a-e6f2-45cc-8e33-6f998601f9a1,DISK], DatanodeInfoWithStorage[127.0.0.1:42484,DS-d1d5a606-aaf3-41b0-8e3e-2c09773c1da0,DISK], DatanodeInfoWithStorage[127.0.0.1:42172,DS-fca719a5-031c-4a36-9d3d-f5a2ec8e88b4,DISK], DatanodeInfoWithStorage[127.0.0.1:38984,DS-ccafbd36-d7d6-4f40-8a63-13a3f74b5ada,DISK], DatanodeInfoWithStorage[127.0.0.1:35259,DS-4f6d9150-30a4-46da-a62f-d67958d2b4c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-636317124-172.17.0.12-1595345598796:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36271,DS-8e453d9d-a20b-4930-b570-dc78536b3726,DISK], DatanodeInfoWithStorage[127.0.0.1:35316,DS-d9fabdfb-0860-44ad-a206-7e3d85831c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:36922,DS-79ce2892-af03-4331-833f-390d05a983d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40130,DS-cbd1c4b8-5daf-4838-9a58-03100e52068f,DISK], DatanodeInfoWithStorage[127.0.0.1:36879,DS-e7a4ef76-2b4d-441e-8e6c-a1ce8e7a9842,DISK], DatanodeInfoWithStorage[127.0.0.1:35217,DS-ee49f535-4877-4bbc-ac48-1cdbff283e69,DISK], DatanodeInfoWithStorage[127.0.0.1:46373,DS-c534a0b4-0e25-4330-b897-dddefca6c681,DISK], DatanodeInfoWithStorage[127.0.0.1:32826,DS-74722e38-22df-42f5-bb3a-4d50acb6d053,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-636317124-172.17.0.12-1595345598796:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36271,DS-8e453d9d-a20b-4930-b570-dc78536b3726,DISK], DatanodeInfoWithStorage[127.0.0.1:35316,DS-d9fabdfb-0860-44ad-a206-7e3d85831c8f,DISK], DatanodeInfoWithStorage[127.0.0.1:36922,DS-79ce2892-af03-4331-833f-390d05a983d2,DISK], DatanodeInfoWithStorage[127.0.0.1:40130,DS-cbd1c4b8-5daf-4838-9a58-03100e52068f,DISK], DatanodeInfoWithStorage[127.0.0.1:36879,DS-e7a4ef76-2b4d-441e-8e6c-a1ce8e7a9842,DISK], DatanodeInfoWithStorage[127.0.0.1:35217,DS-ee49f535-4877-4bbc-ac48-1cdbff283e69,DISK], DatanodeInfoWithStorage[127.0.0.1:46373,DS-c534a0b4-0e25-4330-b897-dddefca6c681,DISK], DatanodeInfoWithStorage[127.0.0.1:32826,DS-74722e38-22df-42f5-bb3a-4d50acb6d053,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-608919909-172.17.0.12-1595346612046:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34516,DS-e8b81f89-9cdf-4fa4-be20-006eeee0a6cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37179,DS-2c37a07b-d978-43ab-a505-a7edb6ebfb89,DISK], DatanodeInfoWithStorage[127.0.0.1:35896,DS-c6725055-9c6a-4360-aedc-3c784a992587,DISK], DatanodeInfoWithStorage[127.0.0.1:33595,DS-63b4f0be-a250-4f98-b340-3fba56996794,DISK], DatanodeInfoWithStorage[127.0.0.1:46075,DS-95dfc886-1cd6-4145-97f0-d5aa1d254b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:40288,DS-a4c7566f-6992-4efc-93c8-927ada66f173,DISK], DatanodeInfoWithStorage[127.0.0.1:46258,DS-f46eb75f-7970-4986-bc2e-6dd03bfc1fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:44062,DS-0488f111-0199-48b1-b650-3ba1c8a1d954,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-608919909-172.17.0.12-1595346612046:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34516,DS-e8b81f89-9cdf-4fa4-be20-006eeee0a6cc,DISK], DatanodeInfoWithStorage[127.0.0.1:37179,DS-2c37a07b-d978-43ab-a505-a7edb6ebfb89,DISK], DatanodeInfoWithStorage[127.0.0.1:35896,DS-c6725055-9c6a-4360-aedc-3c784a992587,DISK], DatanodeInfoWithStorage[127.0.0.1:33595,DS-63b4f0be-a250-4f98-b340-3fba56996794,DISK], DatanodeInfoWithStorage[127.0.0.1:46075,DS-95dfc886-1cd6-4145-97f0-d5aa1d254b5f,DISK], DatanodeInfoWithStorage[127.0.0.1:40288,DS-a4c7566f-6992-4efc-93c8-927ada66f173,DISK], DatanodeInfoWithStorage[127.0.0.1:46258,DS-f46eb75f-7970-4986-bc2e-6dd03bfc1fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:44062,DS-0488f111-0199-48b1-b650-3ba1c8a1d954,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1145213863-172.17.0.12-1595347034286:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42099,DS-c950b745-4885-4b8b-8d7c-e368359cb91e,DISK], DatanodeInfoWithStorage[127.0.0.1:46565,DS-888ee1a9-83da-4921-9a8c-66b1a935c78e,DISK], DatanodeInfoWithStorage[127.0.0.1:37537,DS-d714135d-5274-4662-a9b9-d4fcde1be14f,DISK], DatanodeInfoWithStorage[127.0.0.1:44559,DS-e3cb28b5-3d14-4695-8355-4a791ee0923b,DISK], DatanodeInfoWithStorage[127.0.0.1:44791,DS-a42ad407-fc16-4999-9cce-acdaf9448b8b,DISK], DatanodeInfoWithStorage[127.0.0.1:44341,DS-aeaf1c98-c90d-412b-81c0-d2868fd7caea,DISK], DatanodeInfoWithStorage[127.0.0.1:39827,DS-a54aac64-6c88-4d44-b29a-f12968e5eec6,DISK], DatanodeInfoWithStorage[127.0.0.1:42153,DS-1ab20b92-98a6-4c25-94cc-2dde1f066b46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1145213863-172.17.0.12-1595347034286:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42099,DS-c950b745-4885-4b8b-8d7c-e368359cb91e,DISK], DatanodeInfoWithStorage[127.0.0.1:46565,DS-888ee1a9-83da-4921-9a8c-66b1a935c78e,DISK], DatanodeInfoWithStorage[127.0.0.1:37537,DS-d714135d-5274-4662-a9b9-d4fcde1be14f,DISK], DatanodeInfoWithStorage[127.0.0.1:44559,DS-e3cb28b5-3d14-4695-8355-4a791ee0923b,DISK], DatanodeInfoWithStorage[127.0.0.1:44791,DS-a42ad407-fc16-4999-9cce-acdaf9448b8b,DISK], DatanodeInfoWithStorage[127.0.0.1:44341,DS-aeaf1c98-c90d-412b-81c0-d2868fd7caea,DISK], DatanodeInfoWithStorage[127.0.0.1:39827,DS-a54aac64-6c88-4d44-b29a-f12968e5eec6,DISK], DatanodeInfoWithStorage[127.0.0.1:42153,DS-1ab20b92-98a6-4c25-94cc-2dde1f066b46,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1148928397-172.17.0.12-1595347188869:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37584,DS-c63c28ba-a550-47d8-95e7-7ecf09a48b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:33440,DS-3bff1034-68c6-4045-be0b-77119cac7e20,DISK], DatanodeInfoWithStorage[127.0.0.1:33489,DS-42c0a7c9-0261-4bd3-894d-45e5305e1094,DISK], DatanodeInfoWithStorage[127.0.0.1:32990,DS-524853b1-8851-4839-b48d-5233e8160489,DISK], DatanodeInfoWithStorage[127.0.0.1:32929,DS-a6b43d4b-840e-4b3d-93af-97ff56ee1957,DISK], DatanodeInfoWithStorage[127.0.0.1:45115,DS-842a92d1-f999-4415-b0db-9306852615ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40011,DS-5f0a898a-c473-483c-9d15-ea1158190351,DISK], DatanodeInfoWithStorage[127.0.0.1:46784,DS-9cb9f1b9-8a94-42e7-9812-e6d098579859,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1148928397-172.17.0.12-1595347188869:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37584,DS-c63c28ba-a550-47d8-95e7-7ecf09a48b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:33440,DS-3bff1034-68c6-4045-be0b-77119cac7e20,DISK], DatanodeInfoWithStorage[127.0.0.1:33489,DS-42c0a7c9-0261-4bd3-894d-45e5305e1094,DISK], DatanodeInfoWithStorage[127.0.0.1:32990,DS-524853b1-8851-4839-b48d-5233e8160489,DISK], DatanodeInfoWithStorage[127.0.0.1:32929,DS-a6b43d4b-840e-4b3d-93af-97ff56ee1957,DISK], DatanodeInfoWithStorage[127.0.0.1:45115,DS-842a92d1-f999-4415-b0db-9306852615ac,DISK], DatanodeInfoWithStorage[127.0.0.1:40011,DS-5f0a898a-c473-483c-9d15-ea1158190351,DISK], DatanodeInfoWithStorage[127.0.0.1:46784,DS-9cb9f1b9-8a94-42e7-9812-e6d098579859,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-546856936-172.17.0.12-1595347319906:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36279,DS-cf36535a-28b7-405e-a00e-556bfdc1fd54,DISK], DatanodeInfoWithStorage[127.0.0.1:43906,DS-4799d10e-6509-4ef5-bad0-f8ba3759100d,DISK], DatanodeInfoWithStorage[127.0.0.1:33134,DS-9dbd5643-ef3d-4c6d-b2a4-9fbb83798093,DISK], DatanodeInfoWithStorage[127.0.0.1:40858,DS-5918d63a-ea98-4f1c-8fff-333eba765049,DISK], DatanodeInfoWithStorage[127.0.0.1:38519,DS-f4854657-1fae-4f27-85b7-fda1e446cb6e,DISK], DatanodeInfoWithStorage[127.0.0.1:42899,DS-e9769009-5f80-4e1e-a59b-e37955bcca09,DISK], DatanodeInfoWithStorage[127.0.0.1:45910,DS-3c288248-50c7-4329-a1bb-9c4dda65ed60,DISK], DatanodeInfoWithStorage[127.0.0.1:41333,DS-2e882c90-4b42-474e-b31f-8eff32cb4c0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-546856936-172.17.0.12-1595347319906:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36279,DS-cf36535a-28b7-405e-a00e-556bfdc1fd54,DISK], DatanodeInfoWithStorage[127.0.0.1:43906,DS-4799d10e-6509-4ef5-bad0-f8ba3759100d,DISK], DatanodeInfoWithStorage[127.0.0.1:33134,DS-9dbd5643-ef3d-4c6d-b2a4-9fbb83798093,DISK], DatanodeInfoWithStorage[127.0.0.1:40858,DS-5918d63a-ea98-4f1c-8fff-333eba765049,DISK], DatanodeInfoWithStorage[127.0.0.1:38519,DS-f4854657-1fae-4f27-85b7-fda1e446cb6e,DISK], DatanodeInfoWithStorage[127.0.0.1:42899,DS-e9769009-5f80-4e1e-a59b-e37955bcca09,DISK], DatanodeInfoWithStorage[127.0.0.1:45910,DS-3c288248-50c7-4329-a1bb-9c4dda65ed60,DISK], DatanodeInfoWithStorage[127.0.0.1:41333,DS-2e882c90-4b42-474e-b31f-8eff32cb4c0e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-78393917-172.17.0.12-1595347754020:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39937,DS-001abe03-1375-482e-ac7f-843d479dc6b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35085,DS-1c197341-998c-4971-a553-51d33d90271f,DISK], DatanodeInfoWithStorage[127.0.0.1:43448,DS-50f86071-a2ea-4968-b6c0-4ae5da03bd8f,DISK], DatanodeInfoWithStorage[127.0.0.1:34046,DS-7771dd20-157c-40d1-92eb-9b7406d11844,DISK], DatanodeInfoWithStorage[127.0.0.1:40732,DS-f6517bb1-d5e9-443b-8d4b-a8a1b279d308,DISK], DatanodeInfoWithStorage[127.0.0.1:35977,DS-95315ca3-1fc9-47bc-bf55-73cac91e8842,DISK], DatanodeInfoWithStorage[127.0.0.1:34332,DS-2436da77-1570-40ae-ac45-4e1c8f044cda,DISK], DatanodeInfoWithStorage[127.0.0.1:42619,DS-9068c158-5264-448e-bb2c-7184f57dcce4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-78393917-172.17.0.12-1595347754020:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39937,DS-001abe03-1375-482e-ac7f-843d479dc6b7,DISK], DatanodeInfoWithStorage[127.0.0.1:35085,DS-1c197341-998c-4971-a553-51d33d90271f,DISK], DatanodeInfoWithStorage[127.0.0.1:43448,DS-50f86071-a2ea-4968-b6c0-4ae5da03bd8f,DISK], DatanodeInfoWithStorage[127.0.0.1:34046,DS-7771dd20-157c-40d1-92eb-9b7406d11844,DISK], DatanodeInfoWithStorage[127.0.0.1:40732,DS-f6517bb1-d5e9-443b-8d4b-a8a1b279d308,DISK], DatanodeInfoWithStorage[127.0.0.1:35977,DS-95315ca3-1fc9-47bc-bf55-73cac91e8842,DISK], DatanodeInfoWithStorage[127.0.0.1:34332,DS-2436da77-1570-40ae-ac45-4e1c8f044cda,DISK], DatanodeInfoWithStorage[127.0.0.1:42619,DS-9068c158-5264-448e-bb2c-7184f57dcce4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1513428684-172.17.0.12-1595347874212:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46669,DS-b7ee8304-8cec-4f0f-8e04-03a8abdb3574,DISK], DatanodeInfoWithStorage[127.0.0.1:45350,DS-908ae1b6-9998-4cdc-93d6-20e88cb10b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:36353,DS-7ed93642-f81a-45d1-a748-21d9680e8f99,DISK], DatanodeInfoWithStorage[127.0.0.1:35722,DS-b308b4dc-099b-489f-8201-26a970b0b42b,DISK], DatanodeInfoWithStorage[127.0.0.1:33371,DS-e4ba78cf-5361-4380-9e8a-7c35f1e54e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:43782,DS-5bf9e3f7-8d00-408b-8da5-344a40a5af31,DISK], DatanodeInfoWithStorage[127.0.0.1:35381,DS-fd89378d-9372-4073-a844-f6c514be2a3f,DISK], DatanodeInfoWithStorage[127.0.0.1:41999,DS-b87afb97-ffff-40f2-a437-39dd7d21721b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1513428684-172.17.0.12-1595347874212:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46669,DS-b7ee8304-8cec-4f0f-8e04-03a8abdb3574,DISK], DatanodeInfoWithStorage[127.0.0.1:45350,DS-908ae1b6-9998-4cdc-93d6-20e88cb10b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:36353,DS-7ed93642-f81a-45d1-a748-21d9680e8f99,DISK], DatanodeInfoWithStorage[127.0.0.1:35722,DS-b308b4dc-099b-489f-8201-26a970b0b42b,DISK], DatanodeInfoWithStorage[127.0.0.1:33371,DS-e4ba78cf-5361-4380-9e8a-7c35f1e54e4e,DISK], DatanodeInfoWithStorage[127.0.0.1:43782,DS-5bf9e3f7-8d00-408b-8da5-344a40a5af31,DISK], DatanodeInfoWithStorage[127.0.0.1:35381,DS-fd89378d-9372-4073-a844-f6c514be2a3f,DISK], DatanodeInfoWithStorage[127.0.0.1:41999,DS-b87afb97-ffff-40f2-a437-39dd7d21721b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-285598101-172.17.0.12-1595347980939:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39124,DS-d3cd5afd-0040-4571-8830-1955dadaed83,DISK], DatanodeInfoWithStorage[127.0.0.1:38955,DS-5b82f3d0-12bf-430c-995f-19fb53eb83a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44800,DS-2870f822-e596-4335-bc42-887241ed5f0c,DISK], DatanodeInfoWithStorage[127.0.0.1:38518,DS-b6587afb-301c-4b35-b4a7-c2e8fb931757,DISK], DatanodeInfoWithStorage[127.0.0.1:35977,DS-4a0f45dd-bf15-4291-a843-e425944b8a63,DISK], DatanodeInfoWithStorage[127.0.0.1:33146,DS-e4996ae6-9340-453c-a561-d7ef6d4f4fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:34927,DS-161dd81d-ac62-41cf-b825-6ca9dea7a740,DISK], DatanodeInfoWithStorage[127.0.0.1:36088,DS-de2fe1c2-1b10-47be-a964-42ea23409489,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-285598101-172.17.0.12-1595347980939:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39124,DS-d3cd5afd-0040-4571-8830-1955dadaed83,DISK], DatanodeInfoWithStorage[127.0.0.1:38955,DS-5b82f3d0-12bf-430c-995f-19fb53eb83a8,DISK], DatanodeInfoWithStorage[127.0.0.1:44800,DS-2870f822-e596-4335-bc42-887241ed5f0c,DISK], DatanodeInfoWithStorage[127.0.0.1:38518,DS-b6587afb-301c-4b35-b4a7-c2e8fb931757,DISK], DatanodeInfoWithStorage[127.0.0.1:35977,DS-4a0f45dd-bf15-4291-a843-e425944b8a63,DISK], DatanodeInfoWithStorage[127.0.0.1:33146,DS-e4996ae6-9340-453c-a561-d7ef6d4f4fa5,DISK], DatanodeInfoWithStorage[127.0.0.1:34927,DS-161dd81d-ac62-41cf-b825-6ca9dea7a740,DISK], DatanodeInfoWithStorage[127.0.0.1:36088,DS-de2fe1c2-1b10-47be-a964-42ea23409489,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2033655377-172.17.0.12-1595348136896:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43939,DS-c0c296f7-b560-4e0c-9a47-e1d62e8808a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45029,DS-168dec42-ab5d-4ed1-813f-7bc26a346911,DISK], DatanodeInfoWithStorage[127.0.0.1:44667,DS-eb54e88f-6274-4118-830f-e2f32d4a2b02,DISK], DatanodeInfoWithStorage[127.0.0.1:40517,DS-1418da4c-8fbb-4680-8250-df7f69f08237,DISK], DatanodeInfoWithStorage[127.0.0.1:35146,DS-032d005f-831d-4465-87ca-3862e9df971c,DISK], DatanodeInfoWithStorage[127.0.0.1:39222,DS-1869f2d7-cc08-48b0-81e1-bf9df0488447,DISK], DatanodeInfoWithStorage[127.0.0.1:40227,DS-78112dba-d72c-4b00-a4f2-5ad62b1a28cc,DISK], DatanodeInfoWithStorage[127.0.0.1:41672,DS-ffc641a4-3646-45fe-97f7-a83a2c359907,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2033655377-172.17.0.12-1595348136896:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43939,DS-c0c296f7-b560-4e0c-9a47-e1d62e8808a1,DISK], DatanodeInfoWithStorage[127.0.0.1:45029,DS-168dec42-ab5d-4ed1-813f-7bc26a346911,DISK], DatanodeInfoWithStorage[127.0.0.1:44667,DS-eb54e88f-6274-4118-830f-e2f32d4a2b02,DISK], DatanodeInfoWithStorage[127.0.0.1:40517,DS-1418da4c-8fbb-4680-8250-df7f69f08237,DISK], DatanodeInfoWithStorage[127.0.0.1:35146,DS-032d005f-831d-4465-87ca-3862e9df971c,DISK], DatanodeInfoWithStorage[127.0.0.1:39222,DS-1869f2d7-cc08-48b0-81e1-bf9df0488447,DISK], DatanodeInfoWithStorage[127.0.0.1:40227,DS-78112dba-d72c-4b00-a4f2-5ad62b1a28cc,DISK], DatanodeInfoWithStorage[127.0.0.1:41672,DS-ffc641a4-3646-45fe-97f7-a83a2c359907,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1442498425-172.17.0.12-1595348375612:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43724,DS-91fd061b-72d7-430a-a2f0-dec28a200477,DISK], DatanodeInfoWithStorage[127.0.0.1:35027,DS-85443001-0606-450b-9656-cca19340a603,DISK], DatanodeInfoWithStorage[127.0.0.1:42169,DS-2721d0e6-29c8-4ae9-b70b-a7ca18a82ce0,DISK], DatanodeInfoWithStorage[127.0.0.1:39192,DS-143a45c7-721c-40b0-91bc-4e2f58916698,DISK], DatanodeInfoWithStorage[127.0.0.1:39947,DS-26bab90d-7336-4d7b-8a34-e0fb2847b9d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35544,DS-7d8462cd-2f36-468d-a29f-6321bbf1797b,DISK], DatanodeInfoWithStorage[127.0.0.1:39786,DS-20df893c-61a7-49cc-9e1f-31ec51383329,DISK], DatanodeInfoWithStorage[127.0.0.1:35076,DS-5cdadfd7-a7b6-426c-8353-536945a2e61c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1442498425-172.17.0.12-1595348375612:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43724,DS-91fd061b-72d7-430a-a2f0-dec28a200477,DISK], DatanodeInfoWithStorage[127.0.0.1:35027,DS-85443001-0606-450b-9656-cca19340a603,DISK], DatanodeInfoWithStorage[127.0.0.1:42169,DS-2721d0e6-29c8-4ae9-b70b-a7ca18a82ce0,DISK], DatanodeInfoWithStorage[127.0.0.1:39192,DS-143a45c7-721c-40b0-91bc-4e2f58916698,DISK], DatanodeInfoWithStorage[127.0.0.1:39947,DS-26bab90d-7336-4d7b-8a34-e0fb2847b9d4,DISK], DatanodeInfoWithStorage[127.0.0.1:35544,DS-7d8462cd-2f36-468d-a29f-6321bbf1797b,DISK], DatanodeInfoWithStorage[127.0.0.1:39786,DS-20df893c-61a7-49cc-9e1f-31ec51383329,DISK], DatanodeInfoWithStorage[127.0.0.1:35076,DS-5cdadfd7-a7b6-426c-8353-536945a2e61c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2102151244-172.17.0.12-1595348478440:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41119,DS-3f6a1f2f-e1d1-4fa9-b269-5f4ca63db61f,DISK], DatanodeInfoWithStorage[127.0.0.1:39205,DS-33226e96-eb63-4b4b-bd09-183f3c6f22de,DISK], DatanodeInfoWithStorage[127.0.0.1:37149,DS-232d6cfc-0496-426e-bb58-6f2450f47a13,DISK], DatanodeInfoWithStorage[127.0.0.1:39116,DS-4fd216c3-1384-43ef-ac75-0131d73aacfc,DISK], DatanodeInfoWithStorage[127.0.0.1:42372,DS-f05e49c5-c890-4657-b956-3e889dabbdb1,DISK], DatanodeInfoWithStorage[127.0.0.1:38213,DS-f1b5f47c-3a43-4006-bd82-066903e3fb96,DISK], DatanodeInfoWithStorage[127.0.0.1:45666,DS-2096d70c-962e-4ea1-877c-8afc59af3b56,DISK], DatanodeInfoWithStorage[127.0.0.1:40385,DS-96e0c818-b570-416e-9f22-763a98402f08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2102151244-172.17.0.12-1595348478440:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41119,DS-3f6a1f2f-e1d1-4fa9-b269-5f4ca63db61f,DISK], DatanodeInfoWithStorage[127.0.0.1:39205,DS-33226e96-eb63-4b4b-bd09-183f3c6f22de,DISK], DatanodeInfoWithStorage[127.0.0.1:37149,DS-232d6cfc-0496-426e-bb58-6f2450f47a13,DISK], DatanodeInfoWithStorage[127.0.0.1:39116,DS-4fd216c3-1384-43ef-ac75-0131d73aacfc,DISK], DatanodeInfoWithStorage[127.0.0.1:42372,DS-f05e49c5-c890-4657-b956-3e889dabbdb1,DISK], DatanodeInfoWithStorage[127.0.0.1:38213,DS-f1b5f47c-3a43-4006-bd82-066903e3fb96,DISK], DatanodeInfoWithStorage[127.0.0.1:45666,DS-2096d70c-962e-4ea1-877c-8afc59af3b56,DISK], DatanodeInfoWithStorage[127.0.0.1:40385,DS-96e0c818-b570-416e-9f22-763a98402f08,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 11 out of 50
result: false positive !!!
Total execution time in seconds : 5088
