reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1937989133-172.17.0.7-1596954550350:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42610,DS-e960dee6-7f6d-41ee-ae29-286df254cb57,DISK], DatanodeInfoWithStorage[127.0.0.1:33860,DS-4f6d8d09-4711-4029-83a3-73e635239e67,DISK], DatanodeInfoWithStorage[127.0.0.1:38268,DS-2d03293c-718f-4ffc-850e-08747892dc1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42435,DS-8f702975-6624-46a1-b42c-7924e0a20ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:33577,DS-3324c2d8-041a-479e-a7d8-f585ca584a9d,DISK], DatanodeInfoWithStorage[127.0.0.1:36025,DS-5182d45d-8df9-4422-b0b9-a9dd01abbf7e,DISK], DatanodeInfoWithStorage[127.0.0.1:39271,DS-e61b20a0-9fc1-4464-b025-df58eb0e9636,DISK], DatanodeInfoWithStorage[127.0.0.1:46059,DS-c9e377c0-dd47-4e38-a2d0-dfdff7b54c2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1937989133-172.17.0.7-1596954550350:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42610,DS-e960dee6-7f6d-41ee-ae29-286df254cb57,DISK], DatanodeInfoWithStorage[127.0.0.1:33860,DS-4f6d8d09-4711-4029-83a3-73e635239e67,DISK], DatanodeInfoWithStorage[127.0.0.1:38268,DS-2d03293c-718f-4ffc-850e-08747892dc1c,DISK], DatanodeInfoWithStorage[127.0.0.1:42435,DS-8f702975-6624-46a1-b42c-7924e0a20ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:33577,DS-3324c2d8-041a-479e-a7d8-f585ca584a9d,DISK], DatanodeInfoWithStorage[127.0.0.1:36025,DS-5182d45d-8df9-4422-b0b9-a9dd01abbf7e,DISK], DatanodeInfoWithStorage[127.0.0.1:39271,DS-e61b20a0-9fc1-4464-b025-df58eb0e9636,DISK], DatanodeInfoWithStorage[127.0.0.1:46059,DS-c9e377c0-dd47-4e38-a2d0-dfdff7b54c2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-590073743-172.17.0.7-1596954581251:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39467,DS-3c49d3cf-5903-411f-ba56-587393cde43d,DISK], DatanodeInfoWithStorage[127.0.0.1:40661,DS-6883e8ff-a0e3-4ea6-8cc2-f036fe13d9aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40801,DS-39f31daa-fa65-4692-bc38-dddb3b4b52f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37915,DS-ea0ba3ca-8a1c-45b4-b661-974d3d963fad,DISK], DatanodeInfoWithStorage[127.0.0.1:33648,DS-70cb8f4f-1b1e-48bb-8c8a-742fd13d4678,DISK], DatanodeInfoWithStorage[127.0.0.1:35831,DS-c7c2cb52-a8d6-4b72-9ef1-9c1dd8573500,DISK], DatanodeInfoWithStorage[127.0.0.1:44333,DS-76940cbc-77e1-4ef9-8362-c2ec18820433,DISK], DatanodeInfoWithStorage[127.0.0.1:46148,DS-417775f8-9079-4aa1-bfdd-cf259a7c0b8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-590073743-172.17.0.7-1596954581251:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39467,DS-3c49d3cf-5903-411f-ba56-587393cde43d,DISK], DatanodeInfoWithStorage[127.0.0.1:40661,DS-6883e8ff-a0e3-4ea6-8cc2-f036fe13d9aa,DISK], DatanodeInfoWithStorage[127.0.0.1:40801,DS-39f31daa-fa65-4692-bc38-dddb3b4b52f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37915,DS-ea0ba3ca-8a1c-45b4-b661-974d3d963fad,DISK], DatanodeInfoWithStorage[127.0.0.1:33648,DS-70cb8f4f-1b1e-48bb-8c8a-742fd13d4678,DISK], DatanodeInfoWithStorage[127.0.0.1:35831,DS-c7c2cb52-a8d6-4b72-9ef1-9c1dd8573500,DISK], DatanodeInfoWithStorage[127.0.0.1:44333,DS-76940cbc-77e1-4ef9-8362-c2ec18820433,DISK], DatanodeInfoWithStorage[127.0.0.1:46148,DS-417775f8-9079-4aa1-bfdd-cf259a7c0b8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-906364134-172.17.0.7-1596954863832:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37272,DS-42ca1cf1-662d-448d-978a-55d77abc5e9e,DISK], DatanodeInfoWithStorage[127.0.0.1:41544,DS-64ee2735-3022-4385-93c4-23a8f811a100,DISK], DatanodeInfoWithStorage[127.0.0.1:42137,DS-f828510f-ac1a-4515-83c1-4bd389b91e14,DISK], DatanodeInfoWithStorage[127.0.0.1:34078,DS-08132f54-0932-40bb-83b5-d040ba4e43d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34481,DS-b81d8d46-748b-471e-a6a0-3e0606b9fb86,DISK], DatanodeInfoWithStorage[127.0.0.1:36792,DS-bdf8fcf8-c26a-4971-85af-603744c540dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38977,DS-d63cd558-dd58-445d-a719-f58aa1a2df53,DISK], DatanodeInfoWithStorage[127.0.0.1:38671,DS-7ec306aa-2578-4635-890b-8c9cbbd9993f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-906364134-172.17.0.7-1596954863832:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37272,DS-42ca1cf1-662d-448d-978a-55d77abc5e9e,DISK], DatanodeInfoWithStorage[127.0.0.1:41544,DS-64ee2735-3022-4385-93c4-23a8f811a100,DISK], DatanodeInfoWithStorage[127.0.0.1:42137,DS-f828510f-ac1a-4515-83c1-4bd389b91e14,DISK], DatanodeInfoWithStorage[127.0.0.1:34078,DS-08132f54-0932-40bb-83b5-d040ba4e43d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34481,DS-b81d8d46-748b-471e-a6a0-3e0606b9fb86,DISK], DatanodeInfoWithStorage[127.0.0.1:36792,DS-bdf8fcf8-c26a-4971-85af-603744c540dc,DISK], DatanodeInfoWithStorage[127.0.0.1:38977,DS-d63cd558-dd58-445d-a719-f58aa1a2df53,DISK], DatanodeInfoWithStorage[127.0.0.1:38671,DS-7ec306aa-2578-4635-890b-8c9cbbd9993f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-354083586-172.17.0.7-1596954897413:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35929,DS-08753f95-c149-44ed-9ae8-13e48d9cf4e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36404,DS-6786bab1-4f98-4319-883d-2305f43693b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35852,DS-f17c490e-27d7-4e31-91d6-e54dac891f2f,DISK], DatanodeInfoWithStorage[127.0.0.1:38449,DS-d7ff756f-8dda-484a-823b-e911fe0893f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43817,DS-4d537646-7c7d-4b23-b0dc-30d65abaea95,DISK], DatanodeInfoWithStorage[127.0.0.1:42654,DS-b5b9882b-3f4c-4be1-aeeb-4223ae1ad649,DISK], DatanodeInfoWithStorage[127.0.0.1:33232,DS-739fc7f4-6055-4ecd-81e9-46c1d64d453d,DISK], DatanodeInfoWithStorage[127.0.0.1:46716,DS-e551e8e3-a189-44bb-b957-1e3f28cf572b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-354083586-172.17.0.7-1596954897413:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35929,DS-08753f95-c149-44ed-9ae8-13e48d9cf4e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36404,DS-6786bab1-4f98-4319-883d-2305f43693b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35852,DS-f17c490e-27d7-4e31-91d6-e54dac891f2f,DISK], DatanodeInfoWithStorage[127.0.0.1:38449,DS-d7ff756f-8dda-484a-823b-e911fe0893f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43817,DS-4d537646-7c7d-4b23-b0dc-30d65abaea95,DISK], DatanodeInfoWithStorage[127.0.0.1:42654,DS-b5b9882b-3f4c-4be1-aeeb-4223ae1ad649,DISK], DatanodeInfoWithStorage[127.0.0.1:33232,DS-739fc7f4-6055-4ecd-81e9-46c1d64d453d,DISK], DatanodeInfoWithStorage[127.0.0.1:46716,DS-e551e8e3-a189-44bb-b957-1e3f28cf572b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-297609809-172.17.0.7-1596955102046:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41688,DS-d69ad81d-dc05-4787-ab35-1f5a6b4f7f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:37889,DS-23e9fc8a-df8d-4d29-92fb-e384db54c34c,DISK], DatanodeInfoWithStorage[127.0.0.1:44575,DS-aba34f45-8fa4-4f01-a728-829eef60a59d,DISK], DatanodeInfoWithStorage[127.0.0.1:40475,DS-839fd448-e742-4302-be98-a0c1d14eed27,DISK], DatanodeInfoWithStorage[127.0.0.1:33636,DS-7b1b31ca-3e61-4932-95b6-882c49d196ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38539,DS-ed1f8a59-9829-4f6a-abb0-8744f0e930fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38802,DS-adb28994-893d-42a5-91db-6dbde0b33517,DISK], DatanodeInfoWithStorage[127.0.0.1:35918,DS-d0483d33-bbbf-4eff-93c4-b2645b55a2e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-297609809-172.17.0.7-1596955102046:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41688,DS-d69ad81d-dc05-4787-ab35-1f5a6b4f7f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:37889,DS-23e9fc8a-df8d-4d29-92fb-e384db54c34c,DISK], DatanodeInfoWithStorage[127.0.0.1:44575,DS-aba34f45-8fa4-4f01-a728-829eef60a59d,DISK], DatanodeInfoWithStorage[127.0.0.1:40475,DS-839fd448-e742-4302-be98-a0c1d14eed27,DISK], DatanodeInfoWithStorage[127.0.0.1:33636,DS-7b1b31ca-3e61-4932-95b6-882c49d196ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38539,DS-ed1f8a59-9829-4f6a-abb0-8744f0e930fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38802,DS-adb28994-893d-42a5-91db-6dbde0b33517,DISK], DatanodeInfoWithStorage[127.0.0.1:35918,DS-d0483d33-bbbf-4eff-93c4-b2645b55a2e9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-419155204-172.17.0.7-1596955287322:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44542,DS-86ba7e42-02c4-4456-a5e2-2c4712addfe8,DISK], DatanodeInfoWithStorage[127.0.0.1:45229,DS-17fb4d67-ded7-4084-884a-616d224dfb51,DISK], DatanodeInfoWithStorage[127.0.0.1:45505,DS-7a0bcc77-d9da-4432-a038-d9f2c427586c,DISK], DatanodeInfoWithStorage[127.0.0.1:32847,DS-4401a5b6-2efd-4300-b514-58dabdb24db3,DISK], DatanodeInfoWithStorage[127.0.0.1:35452,DS-65c1fa1b-9fda-4cc4-96f6-005069cc5fca,DISK], DatanodeInfoWithStorage[127.0.0.1:34501,DS-b9d02f66-99da-411d-b960-fa84fa17412e,DISK], DatanodeInfoWithStorage[127.0.0.1:44758,DS-4714c3b5-ce35-4d42-ab6d-7c55c940662e,DISK], DatanodeInfoWithStorage[127.0.0.1:32992,DS-d66ed6af-777b-434c-af61-d82fd2a40a0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-419155204-172.17.0.7-1596955287322:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44542,DS-86ba7e42-02c4-4456-a5e2-2c4712addfe8,DISK], DatanodeInfoWithStorage[127.0.0.1:45229,DS-17fb4d67-ded7-4084-884a-616d224dfb51,DISK], DatanodeInfoWithStorage[127.0.0.1:45505,DS-7a0bcc77-d9da-4432-a038-d9f2c427586c,DISK], DatanodeInfoWithStorage[127.0.0.1:32847,DS-4401a5b6-2efd-4300-b514-58dabdb24db3,DISK], DatanodeInfoWithStorage[127.0.0.1:35452,DS-65c1fa1b-9fda-4cc4-96f6-005069cc5fca,DISK], DatanodeInfoWithStorage[127.0.0.1:34501,DS-b9d02f66-99da-411d-b960-fa84fa17412e,DISK], DatanodeInfoWithStorage[127.0.0.1:44758,DS-4714c3b5-ce35-4d42-ab6d-7c55c940662e,DISK], DatanodeInfoWithStorage[127.0.0.1:32992,DS-d66ed6af-777b-434c-af61-d82fd2a40a0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1085424398-172.17.0.7-1596955529541:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34295,DS-acac9022-92fd-4651-8d89-a5920cc2bec9,DISK], DatanodeInfoWithStorage[127.0.0.1:41500,DS-22494a65-2db1-4bc5-89b9-813a3be1bafb,DISK], DatanodeInfoWithStorage[127.0.0.1:34573,DS-0138be30-1b6a-42a4-9557-217547a5ae48,DISK], DatanodeInfoWithStorage[127.0.0.1:36500,DS-f5201db7-44f2-4a65-8c1e-f901385f6f5e,DISK], DatanodeInfoWithStorage[127.0.0.1:38637,DS-9375ef65-3084-4ff0-9e88-c0d7e0f7fb2d,DISK], DatanodeInfoWithStorage[127.0.0.1:38112,DS-2c6e8489-16fe-422f-9211-a7991736c7e9,DISK], DatanodeInfoWithStorage[127.0.0.1:38113,DS-d77e296a-7f77-4a6f-958a-6f5bae1b8ea9,DISK], DatanodeInfoWithStorage[127.0.0.1:38111,DS-e45b9402-cc6e-46b0-998b-3c37f12e0399,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1085424398-172.17.0.7-1596955529541:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34295,DS-acac9022-92fd-4651-8d89-a5920cc2bec9,DISK], DatanodeInfoWithStorage[127.0.0.1:41500,DS-22494a65-2db1-4bc5-89b9-813a3be1bafb,DISK], DatanodeInfoWithStorage[127.0.0.1:34573,DS-0138be30-1b6a-42a4-9557-217547a5ae48,DISK], DatanodeInfoWithStorage[127.0.0.1:36500,DS-f5201db7-44f2-4a65-8c1e-f901385f6f5e,DISK], DatanodeInfoWithStorage[127.0.0.1:38637,DS-9375ef65-3084-4ff0-9e88-c0d7e0f7fb2d,DISK], DatanodeInfoWithStorage[127.0.0.1:38112,DS-2c6e8489-16fe-422f-9211-a7991736c7e9,DISK], DatanodeInfoWithStorage[127.0.0.1:38113,DS-d77e296a-7f77-4a6f-958a-6f5bae1b8ea9,DISK], DatanodeInfoWithStorage[127.0.0.1:38111,DS-e45b9402-cc6e-46b0-998b-3c37f12e0399,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1414208145-172.17.0.7-1596955733290:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45524,DS-c179a19a-5a4f-4db3-b179-1616685cc549,DISK], DatanodeInfoWithStorage[127.0.0.1:43198,DS-afaf7a71-3bbc-48e5-8a7e-8bb554ad37df,DISK], DatanodeInfoWithStorage[127.0.0.1:42263,DS-3b57df29-4d93-45fa-8098-293b57e15922,DISK], DatanodeInfoWithStorage[127.0.0.1:42475,DS-8dae99c6-9e64-4b15-aa60-6aef0859ac94,DISK], DatanodeInfoWithStorage[127.0.0.1:34134,DS-e26c85ff-a5dd-4b0a-98ac-40b4bac1f1e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35434,DS-995c9d32-608b-46bf-a22d-ed5407cd5ef0,DISK], DatanodeInfoWithStorage[127.0.0.1:43008,DS-894dae15-89a5-4a00-a938-0c27ce829bac,DISK], DatanodeInfoWithStorage[127.0.0.1:40874,DS-b1570be9-787d-4283-bd19-27ee7560420a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1414208145-172.17.0.7-1596955733290:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45524,DS-c179a19a-5a4f-4db3-b179-1616685cc549,DISK], DatanodeInfoWithStorage[127.0.0.1:43198,DS-afaf7a71-3bbc-48e5-8a7e-8bb554ad37df,DISK], DatanodeInfoWithStorage[127.0.0.1:42263,DS-3b57df29-4d93-45fa-8098-293b57e15922,DISK], DatanodeInfoWithStorage[127.0.0.1:42475,DS-8dae99c6-9e64-4b15-aa60-6aef0859ac94,DISK], DatanodeInfoWithStorage[127.0.0.1:34134,DS-e26c85ff-a5dd-4b0a-98ac-40b4bac1f1e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35434,DS-995c9d32-608b-46bf-a22d-ed5407cd5ef0,DISK], DatanodeInfoWithStorage[127.0.0.1:43008,DS-894dae15-89a5-4a00-a938-0c27ce829bac,DISK], DatanodeInfoWithStorage[127.0.0.1:40874,DS-b1570be9-787d-4283-bd19-27ee7560420a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-96262158-172.17.0.7-1596955839672:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37240,DS-c22b2b58-8ff1-43c0-bbb9-1f2c5963dd62,DISK], DatanodeInfoWithStorage[127.0.0.1:39989,DS-59f368b6-ba8c-4752-a194-c9d48feabbfb,DISK], DatanodeInfoWithStorage[127.0.0.1:33728,DS-64c4dc5b-85dc-49e2-8b30-cef52a2494ed,DISK], DatanodeInfoWithStorage[127.0.0.1:46313,DS-457225bc-b782-41da-8144-bf3f2ae87f90,DISK], DatanodeInfoWithStorage[127.0.0.1:42008,DS-923b7e94-ebb3-4a1a-b4e6-30cb56c0ca29,DISK], DatanodeInfoWithStorage[127.0.0.1:44427,DS-f6191cc9-ce63-4e49-9f95-bef17280adef,DISK], DatanodeInfoWithStorage[127.0.0.1:43605,DS-8c2439fd-762f-4560-9731-67179a5fffbd,DISK], DatanodeInfoWithStorage[127.0.0.1:45941,DS-d3fd667a-3141-4d32-a144-7349994cdbc6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-96262158-172.17.0.7-1596955839672:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37240,DS-c22b2b58-8ff1-43c0-bbb9-1f2c5963dd62,DISK], DatanodeInfoWithStorage[127.0.0.1:39989,DS-59f368b6-ba8c-4752-a194-c9d48feabbfb,DISK], DatanodeInfoWithStorage[127.0.0.1:33728,DS-64c4dc5b-85dc-49e2-8b30-cef52a2494ed,DISK], DatanodeInfoWithStorage[127.0.0.1:46313,DS-457225bc-b782-41da-8144-bf3f2ae87f90,DISK], DatanodeInfoWithStorage[127.0.0.1:42008,DS-923b7e94-ebb3-4a1a-b4e6-30cb56c0ca29,DISK], DatanodeInfoWithStorage[127.0.0.1:44427,DS-f6191cc9-ce63-4e49-9f95-bef17280adef,DISK], DatanodeInfoWithStorage[127.0.0.1:43605,DS-8c2439fd-762f-4560-9731-67179a5fffbd,DISK], DatanodeInfoWithStorage[127.0.0.1:45941,DS-d3fd667a-3141-4d32-a144-7349994cdbc6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1714152792-172.17.0.7-1596956001429:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40513,DS-db5609c1-1bdb-4bea-bff6-953655a94610,DISK], DatanodeInfoWithStorage[127.0.0.1:41915,DS-70178ff2-13a0-40e3-bd24-2aa4835cdedf,DISK], DatanodeInfoWithStorage[127.0.0.1:46632,DS-7d6f9604-0734-45ef-80e4-cc9411bd3966,DISK], DatanodeInfoWithStorage[127.0.0.1:33207,DS-865b9822-f4f3-48eb-8e5a-122b0396387f,DISK], DatanodeInfoWithStorage[127.0.0.1:43681,DS-7d24822b-b852-4b05-8163-ea2f5ebdbc73,DISK], DatanodeInfoWithStorage[127.0.0.1:37156,DS-7c7e6275-6b3a-4e6f-9eb8-b7935165f791,DISK], DatanodeInfoWithStorage[127.0.0.1:38674,DS-932d05d1-3bb5-419b-b4e3-f5cd3df2e9ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33707,DS-473a4478-b764-4565-a043-3f0f2fcf6b78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1714152792-172.17.0.7-1596956001429:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40513,DS-db5609c1-1bdb-4bea-bff6-953655a94610,DISK], DatanodeInfoWithStorage[127.0.0.1:41915,DS-70178ff2-13a0-40e3-bd24-2aa4835cdedf,DISK], DatanodeInfoWithStorage[127.0.0.1:46632,DS-7d6f9604-0734-45ef-80e4-cc9411bd3966,DISK], DatanodeInfoWithStorage[127.0.0.1:33207,DS-865b9822-f4f3-48eb-8e5a-122b0396387f,DISK], DatanodeInfoWithStorage[127.0.0.1:43681,DS-7d24822b-b852-4b05-8163-ea2f5ebdbc73,DISK], DatanodeInfoWithStorage[127.0.0.1:37156,DS-7c7e6275-6b3a-4e6f-9eb8-b7935165f791,DISK], DatanodeInfoWithStorage[127.0.0.1:38674,DS-932d05d1-3bb5-419b-b4e3-f5cd3df2e9ee,DISK], DatanodeInfoWithStorage[127.0.0.1:33707,DS-473a4478-b764-4565-a043-3f0f2fcf6b78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1496663912-172.17.0.7-1596956626433:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43787,DS-23f7c230-a340-4a05-8884-7bb333b2902c,DISK], DatanodeInfoWithStorage[127.0.0.1:33789,DS-431243a1-bee4-4c1a-9351-d2d3f79ee359,DISK], DatanodeInfoWithStorage[127.0.0.1:35472,DS-55e41b21-2f51-4026-90ea-179a6a1f8f10,DISK], DatanodeInfoWithStorage[127.0.0.1:34826,DS-b28494aa-dcd9-4d4f-b32b-a7b95deb5868,DISK], DatanodeInfoWithStorage[127.0.0.1:36259,DS-c20a4011-cabd-42e3-a3f0-0b670a4f98e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36827,DS-dae6200f-a54e-4977-99b0-e6242b9d079c,DISK], DatanodeInfoWithStorage[127.0.0.1:35042,DS-b67a572d-d2a8-424f-9e43-9cd7b3dba69a,DISK], DatanodeInfoWithStorage[127.0.0.1:45521,DS-0ae322de-fd8a-4a9a-a54f-64bbf8076878,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1496663912-172.17.0.7-1596956626433:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43787,DS-23f7c230-a340-4a05-8884-7bb333b2902c,DISK], DatanodeInfoWithStorage[127.0.0.1:33789,DS-431243a1-bee4-4c1a-9351-d2d3f79ee359,DISK], DatanodeInfoWithStorage[127.0.0.1:35472,DS-55e41b21-2f51-4026-90ea-179a6a1f8f10,DISK], DatanodeInfoWithStorage[127.0.0.1:34826,DS-b28494aa-dcd9-4d4f-b32b-a7b95deb5868,DISK], DatanodeInfoWithStorage[127.0.0.1:36259,DS-c20a4011-cabd-42e3-a3f0-0b670a4f98e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36827,DS-dae6200f-a54e-4977-99b0-e6242b9d079c,DISK], DatanodeInfoWithStorage[127.0.0.1:35042,DS-b67a572d-d2a8-424f-9e43-9cd7b3dba69a,DISK], DatanodeInfoWithStorage[127.0.0.1:45521,DS-0ae322de-fd8a-4a9a-a54f-64bbf8076878,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1048229488-172.17.0.7-1596956662141:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44687,DS-d6348611-7976-482e-aab7-9156323fe3e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36019,DS-bd690d21-8977-4043-98d3-2f9a7c8d22d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38055,DS-807f0c58-391d-4109-a2ef-16bb92af5d4b,DISK], DatanodeInfoWithStorage[127.0.0.1:41412,DS-5544b142-a7fa-4e7d-b5a3-c27db1fa45ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40283,DS-4310f49a-bf5e-4db7-9b3f-1ec3de4669a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45874,DS-c9e21d8c-3264-4296-96e7-98924fc3067a,DISK], DatanodeInfoWithStorage[127.0.0.1:36232,DS-fb15d521-4db3-4ce1-b536-07d99615620a,DISK], DatanodeInfoWithStorage[127.0.0.1:33196,DS-c0c11870-ca86-47c0-925e-1066edb33ddd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1048229488-172.17.0.7-1596956662141:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44687,DS-d6348611-7976-482e-aab7-9156323fe3e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36019,DS-bd690d21-8977-4043-98d3-2f9a7c8d22d4,DISK], DatanodeInfoWithStorage[127.0.0.1:38055,DS-807f0c58-391d-4109-a2ef-16bb92af5d4b,DISK], DatanodeInfoWithStorage[127.0.0.1:41412,DS-5544b142-a7fa-4e7d-b5a3-c27db1fa45ce,DISK], DatanodeInfoWithStorage[127.0.0.1:40283,DS-4310f49a-bf5e-4db7-9b3f-1ec3de4669a2,DISK], DatanodeInfoWithStorage[127.0.0.1:45874,DS-c9e21d8c-3264-4296-96e7-98924fc3067a,DISK], DatanodeInfoWithStorage[127.0.0.1:36232,DS-fb15d521-4db3-4ce1-b536-07d99615620a,DISK], DatanodeInfoWithStorage[127.0.0.1:33196,DS-c0c11870-ca86-47c0-925e-1066edb33ddd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1667958375-172.17.0.7-1596956787436:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46095,DS-d58b7baf-ad8f-4324-a1b1-569b1421b9f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44786,DS-0c83eb85-2dd3-4529-836e-e55e885a7cff,DISK], DatanodeInfoWithStorage[127.0.0.1:41641,DS-a21eb2df-fef2-4633-8ee8-5d3dd54b9be5,DISK], DatanodeInfoWithStorage[127.0.0.1:37689,DS-b059d0d0-bbb3-4465-aa85-526a76e808ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42059,DS-9fcbc39c-ef83-46f0-801c-af6d13dc7205,DISK], DatanodeInfoWithStorage[127.0.0.1:39365,DS-1543044e-2175-45b8-ab7d-bfc9391cb2de,DISK], DatanodeInfoWithStorage[127.0.0.1:41117,DS-cfa428a2-384c-41a7-a30b-4016d6d41bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:33293,DS-98f5a74b-961c-4ff9-b447-685348f59ffa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1667958375-172.17.0.7-1596956787436:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46095,DS-d58b7baf-ad8f-4324-a1b1-569b1421b9f4,DISK], DatanodeInfoWithStorage[127.0.0.1:44786,DS-0c83eb85-2dd3-4529-836e-e55e885a7cff,DISK], DatanodeInfoWithStorage[127.0.0.1:41641,DS-a21eb2df-fef2-4633-8ee8-5d3dd54b9be5,DISK], DatanodeInfoWithStorage[127.0.0.1:37689,DS-b059d0d0-bbb3-4465-aa85-526a76e808ac,DISK], DatanodeInfoWithStorage[127.0.0.1:42059,DS-9fcbc39c-ef83-46f0-801c-af6d13dc7205,DISK], DatanodeInfoWithStorage[127.0.0.1:39365,DS-1543044e-2175-45b8-ab7d-bfc9391cb2de,DISK], DatanodeInfoWithStorage[127.0.0.1:41117,DS-cfa428a2-384c-41a7-a30b-4016d6d41bd0,DISK], DatanodeInfoWithStorage[127.0.0.1:33293,DS-98f5a74b-961c-4ff9-b447-685348f59ffa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1229163604-172.17.0.7-1596957175179:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33330,DS-c9059fee-ca7f-4add-8a08-ce27103bb819,DISK], DatanodeInfoWithStorage[127.0.0.1:40747,DS-4e550f9d-fa80-4334-8834-666af361c8cd,DISK], DatanodeInfoWithStorage[127.0.0.1:35480,DS-c6f39bec-4acc-4079-a08b-6ae68f8060a8,DISK], DatanodeInfoWithStorage[127.0.0.1:32898,DS-3b069c00-f614-4fc6-9205-0966394d05e9,DISK], DatanodeInfoWithStorage[127.0.0.1:38336,DS-c5ddfb42-2303-471d-a4e2-34d4f6655b84,DISK], DatanodeInfoWithStorage[127.0.0.1:37497,DS-f98ea5d4-fef6-4269-8230-d2dd7c97e7a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43949,DS-9f46b2b9-afdf-4b74-a94f-dcac0eed4a45,DISK], DatanodeInfoWithStorage[127.0.0.1:38492,DS-ce5e9d5d-92c8-4859-b794-d2f4804f4b9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1229163604-172.17.0.7-1596957175179:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33330,DS-c9059fee-ca7f-4add-8a08-ce27103bb819,DISK], DatanodeInfoWithStorage[127.0.0.1:40747,DS-4e550f9d-fa80-4334-8834-666af361c8cd,DISK], DatanodeInfoWithStorage[127.0.0.1:35480,DS-c6f39bec-4acc-4079-a08b-6ae68f8060a8,DISK], DatanodeInfoWithStorage[127.0.0.1:32898,DS-3b069c00-f614-4fc6-9205-0966394d05e9,DISK], DatanodeInfoWithStorage[127.0.0.1:38336,DS-c5ddfb42-2303-471d-a4e2-34d4f6655b84,DISK], DatanodeInfoWithStorage[127.0.0.1:37497,DS-f98ea5d4-fef6-4269-8230-d2dd7c97e7a9,DISK], DatanodeInfoWithStorage[127.0.0.1:43949,DS-9f46b2b9-afdf-4b74-a94f-dcac0eed4a45,DISK], DatanodeInfoWithStorage[127.0.0.1:38492,DS-ce5e9d5d-92c8-4859-b794-d2f4804f4b9b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-459768128-172.17.0.7-1596957401010:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41521,DS-f277ca59-b160-4060-8b85-f470fe0b6062,DISK], DatanodeInfoWithStorage[127.0.0.1:39239,DS-5b65616d-789e-47a8-bba8-bba95f65db99,DISK], DatanodeInfoWithStorage[127.0.0.1:42293,DS-608480f5-9266-4b03-981a-1ed56fe6d580,DISK], DatanodeInfoWithStorage[127.0.0.1:41885,DS-5208aea6-ac02-4731-92b8-30223bf2dac6,DISK], DatanodeInfoWithStorage[127.0.0.1:34703,DS-5814dd45-9de8-4664-a721-bbd433b32cf3,DISK], DatanodeInfoWithStorage[127.0.0.1:44626,DS-dd677e14-67e9-4bee-bfc8-a5e2843c3ae5,DISK], DatanodeInfoWithStorage[127.0.0.1:33028,DS-df7e251e-9f8b-40ce-a5ea-e55338bad826,DISK], DatanodeInfoWithStorage[127.0.0.1:38883,DS-17fc2570-329b-4f5b-871e-4fb1bfbf2144,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-459768128-172.17.0.7-1596957401010:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41521,DS-f277ca59-b160-4060-8b85-f470fe0b6062,DISK], DatanodeInfoWithStorage[127.0.0.1:39239,DS-5b65616d-789e-47a8-bba8-bba95f65db99,DISK], DatanodeInfoWithStorage[127.0.0.1:42293,DS-608480f5-9266-4b03-981a-1ed56fe6d580,DISK], DatanodeInfoWithStorage[127.0.0.1:41885,DS-5208aea6-ac02-4731-92b8-30223bf2dac6,DISK], DatanodeInfoWithStorage[127.0.0.1:34703,DS-5814dd45-9de8-4664-a721-bbd433b32cf3,DISK], DatanodeInfoWithStorage[127.0.0.1:44626,DS-dd677e14-67e9-4bee-bfc8-a5e2843c3ae5,DISK], DatanodeInfoWithStorage[127.0.0.1:33028,DS-df7e251e-9f8b-40ce-a5ea-e55338bad826,DISK], DatanodeInfoWithStorage[127.0.0.1:38883,DS-17fc2570-329b-4f5b-871e-4fb1bfbf2144,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-407107536-172.17.0.7-1596957625859:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36928,DS-45275344-80cd-486c-a15c-a0e072dbe714,DISK], DatanodeInfoWithStorage[127.0.0.1:34183,DS-62246345-423b-4b63-b14d-7092ffd9f3c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35914,DS-21dbaee9-a1a1-438f-829b-bcf0eafa53bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40954,DS-9385e66c-5c74-4b5d-99dc-4cdb9496ab14,DISK], DatanodeInfoWithStorage[127.0.0.1:41371,DS-45f98566-5d86-4082-ae82-04ec8c767f4d,DISK], DatanodeInfoWithStorage[127.0.0.1:33508,DS-959829c2-49b7-496e-a7e0-2a2a5f4f2f95,DISK], DatanodeInfoWithStorage[127.0.0.1:42855,DS-403cd10a-1c0e-4554-bcd3-f4d5c62bc743,DISK], DatanodeInfoWithStorage[127.0.0.1:39325,DS-6e60735f-c2c6-4263-9619-179e9580624b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-407107536-172.17.0.7-1596957625859:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36928,DS-45275344-80cd-486c-a15c-a0e072dbe714,DISK], DatanodeInfoWithStorage[127.0.0.1:34183,DS-62246345-423b-4b63-b14d-7092ffd9f3c8,DISK], DatanodeInfoWithStorage[127.0.0.1:35914,DS-21dbaee9-a1a1-438f-829b-bcf0eafa53bd,DISK], DatanodeInfoWithStorage[127.0.0.1:40954,DS-9385e66c-5c74-4b5d-99dc-4cdb9496ab14,DISK], DatanodeInfoWithStorage[127.0.0.1:41371,DS-45f98566-5d86-4082-ae82-04ec8c767f4d,DISK], DatanodeInfoWithStorage[127.0.0.1:33508,DS-959829c2-49b7-496e-a7e0-2a2a5f4f2f95,DISK], DatanodeInfoWithStorage[127.0.0.1:42855,DS-403cd10a-1c0e-4554-bcd3-f4d5c62bc743,DISK], DatanodeInfoWithStorage[127.0.0.1:39325,DS-6e60735f-c2c6-4263-9619-179e9580624b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-702272258-172.17.0.7-1596957688322:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36939,DS-e923801a-1ce1-4717-975b-ec316fb8d5ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35819,DS-b66fa15d-a19a-4242-93c3-73eed367e1fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45327,DS-4ce5e2ac-279f-40d6-818f-20a1ec8865dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36753,DS-62813177-2d6b-4ca4-90b8-5ed0298f0d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:45544,DS-47de7f86-ef1f-4359-ae58-2ad9cb0d307f,DISK], DatanodeInfoWithStorage[127.0.0.1:43177,DS-df9dc67a-4ccf-47bf-848b-a4976fa86594,DISK], DatanodeInfoWithStorage[127.0.0.1:41977,DS-6cc7587c-9795-4e1a-91cd-7ab74d624137,DISK], DatanodeInfoWithStorage[127.0.0.1:38579,DS-d968d8af-f6fb-4f7b-b3f5-17dd1ba1fd27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-702272258-172.17.0.7-1596957688322:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36939,DS-e923801a-1ce1-4717-975b-ec316fb8d5ae,DISK], DatanodeInfoWithStorage[127.0.0.1:35819,DS-b66fa15d-a19a-4242-93c3-73eed367e1fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45327,DS-4ce5e2ac-279f-40d6-818f-20a1ec8865dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36753,DS-62813177-2d6b-4ca4-90b8-5ed0298f0d6a,DISK], DatanodeInfoWithStorage[127.0.0.1:45544,DS-47de7f86-ef1f-4359-ae58-2ad9cb0d307f,DISK], DatanodeInfoWithStorage[127.0.0.1:43177,DS-df9dc67a-4ccf-47bf-848b-a4976fa86594,DISK], DatanodeInfoWithStorage[127.0.0.1:41977,DS-6cc7587c-9795-4e1a-91cd-7ab74d624137,DISK], DatanodeInfoWithStorage[127.0.0.1:38579,DS-d968d8af-f6fb-4f7b-b3f5-17dd1ba1fd27,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2116060775-172.17.0.7-1596957968239:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46302,DS-b3dd2d9a-abd1-49e6-bc98-e8e37e58ccad,DISK], DatanodeInfoWithStorage[127.0.0.1:33565,DS-c8418b34-1998-44e7-b03f-82ad39dc3201,DISK], DatanodeInfoWithStorage[127.0.0.1:35241,DS-2da487a8-86a3-4ce2-ad21-c9f7e47bd36f,DISK], DatanodeInfoWithStorage[127.0.0.1:38522,DS-d24cc4cc-d5f0-429e-bb6f-848060097345,DISK], DatanodeInfoWithStorage[127.0.0.1:36887,DS-d709aa6a-06a1-4ac2-a5cf-5b783ae5f6e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45229,DS-8394df0f-c498-4a48-8ae5-5dbc83568ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:42832,DS-0a93ab28-8c0a-4b43-8de0-fea3cb0f6ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:38516,DS-8c28533b-fd6a-4a28-8c45-775a52ac777f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2116060775-172.17.0.7-1596957968239:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46302,DS-b3dd2d9a-abd1-49e6-bc98-e8e37e58ccad,DISK], DatanodeInfoWithStorage[127.0.0.1:33565,DS-c8418b34-1998-44e7-b03f-82ad39dc3201,DISK], DatanodeInfoWithStorage[127.0.0.1:35241,DS-2da487a8-86a3-4ce2-ad21-c9f7e47bd36f,DISK], DatanodeInfoWithStorage[127.0.0.1:38522,DS-d24cc4cc-d5f0-429e-bb6f-848060097345,DISK], DatanodeInfoWithStorage[127.0.0.1:36887,DS-d709aa6a-06a1-4ac2-a5cf-5b783ae5f6e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45229,DS-8394df0f-c498-4a48-8ae5-5dbc83568ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:42832,DS-0a93ab28-8c0a-4b43-8de0-fea3cb0f6ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:38516,DS-8c28533b-fd6a-4a28-8c45-775a52ac777f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-467427073-172.17.0.7-1596958238005:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44966,DS-61eb4154-f7fa-43a2-b0de-4947ea483363,DISK], DatanodeInfoWithStorage[127.0.0.1:46646,DS-3be60a6c-dcc2-41c5-8d49-8f858c1ace4c,DISK], DatanodeInfoWithStorage[127.0.0.1:34779,DS-eb964cac-1a4a-4d36-bc5d-b1a9edf473e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34011,DS-cd2fa9c3-db14-4997-82ca-83f6ba00dead,DISK], DatanodeInfoWithStorage[127.0.0.1:44053,DS-dc1b181a-fc54-49cc-acd2-1189781a8336,DISK], DatanodeInfoWithStorage[127.0.0.1:45833,DS-26a302fe-d3c1-4871-b681-063e5a6a8b98,DISK], DatanodeInfoWithStorage[127.0.0.1:38031,DS-29c10789-6b10-4315-a9d6-5eece2909ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:43830,DS-a9a0b712-864c-4e51-8975-b9029fd77184,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-467427073-172.17.0.7-1596958238005:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44966,DS-61eb4154-f7fa-43a2-b0de-4947ea483363,DISK], DatanodeInfoWithStorage[127.0.0.1:46646,DS-3be60a6c-dcc2-41c5-8d49-8f858c1ace4c,DISK], DatanodeInfoWithStorage[127.0.0.1:34779,DS-eb964cac-1a4a-4d36-bc5d-b1a9edf473e4,DISK], DatanodeInfoWithStorage[127.0.0.1:34011,DS-cd2fa9c3-db14-4997-82ca-83f6ba00dead,DISK], DatanodeInfoWithStorage[127.0.0.1:44053,DS-dc1b181a-fc54-49cc-acd2-1189781a8336,DISK], DatanodeInfoWithStorage[127.0.0.1:45833,DS-26a302fe-d3c1-4871-b681-063e5a6a8b98,DISK], DatanodeInfoWithStorage[127.0.0.1:38031,DS-29c10789-6b10-4315-a9d6-5eece2909ccd,DISK], DatanodeInfoWithStorage[127.0.0.1:43830,DS-a9a0b712-864c-4e51-8975-b9029fd77184,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1557768397-172.17.0.7-1596958295723:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40877,DS-7c9c6d53-363e-4f8a-9c60-33eee5b8208d,DISK], DatanodeInfoWithStorage[127.0.0.1:43567,DS-8640ab1e-5c9d-44e3-b961-e9b185b53ba3,DISK], DatanodeInfoWithStorage[127.0.0.1:41726,DS-515ccf50-f019-4dc4-aec7-f202ca3620ee,DISK], DatanodeInfoWithStorage[127.0.0.1:46634,DS-6ab81190-f1d6-460e-8b30-2a29511b1a05,DISK], DatanodeInfoWithStorage[127.0.0.1:37122,DS-287535d7-cb2c-4d0e-8333-f2a86c224949,DISK], DatanodeInfoWithStorage[127.0.0.1:34765,DS-df4e37fc-fedb-4436-aa96-1f696eb4225e,DISK], DatanodeInfoWithStorage[127.0.0.1:40706,DS-661c3323-c605-4175-bc4b-6df436a56acf,DISK], DatanodeInfoWithStorage[127.0.0.1:33813,DS-a2ba220b-c006-4956-a56b-79c7e5a0a66e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1557768397-172.17.0.7-1596958295723:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40877,DS-7c9c6d53-363e-4f8a-9c60-33eee5b8208d,DISK], DatanodeInfoWithStorage[127.0.0.1:43567,DS-8640ab1e-5c9d-44e3-b961-e9b185b53ba3,DISK], DatanodeInfoWithStorage[127.0.0.1:41726,DS-515ccf50-f019-4dc4-aec7-f202ca3620ee,DISK], DatanodeInfoWithStorage[127.0.0.1:46634,DS-6ab81190-f1d6-460e-8b30-2a29511b1a05,DISK], DatanodeInfoWithStorage[127.0.0.1:37122,DS-287535d7-cb2c-4d0e-8333-f2a86c224949,DISK], DatanodeInfoWithStorage[127.0.0.1:34765,DS-df4e37fc-fedb-4436-aa96-1f696eb4225e,DISK], DatanodeInfoWithStorage[127.0.0.1:40706,DS-661c3323-c605-4175-bc4b-6df436a56acf,DISK], DatanodeInfoWithStorage[127.0.0.1:33813,DS-a2ba220b-c006-4956-a56b-79c7e5a0a66e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.provided.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-63997707-172.17.0.7-1596958581661:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42379,DS-4dc6c7df-eceb-4ac5-ab4d-723f6fe6d476,DISK], DatanodeInfoWithStorage[127.0.0.1:37497,DS-9bbf517b-ee78-44f3-9066-f90737454baa,DISK], DatanodeInfoWithStorage[127.0.0.1:35539,DS-8ea2d0f1-66f0-4ffd-a1b0-7a5e4411f2a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43817,DS-5e1c7fa4-3c49-461e-9d5d-887b2a3d41e6,DISK], DatanodeInfoWithStorage[127.0.0.1:43593,DS-b8cd9781-3d93-45ab-a08b-a39165af80c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36761,DS-9fac9c92-e7f8-4b8b-9986-0ddea1a88f27,DISK], DatanodeInfoWithStorage[127.0.0.1:36849,DS-bea6a309-c272-4446-9902-8ecb7057cbbf,DISK], DatanodeInfoWithStorage[127.0.0.1:39409,DS-e740c9fc-437f-4203-8539-1c5c255e4aaa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-63997707-172.17.0.7-1596958581661:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42379,DS-4dc6c7df-eceb-4ac5-ab4d-723f6fe6d476,DISK], DatanodeInfoWithStorage[127.0.0.1:37497,DS-9bbf517b-ee78-44f3-9066-f90737454baa,DISK], DatanodeInfoWithStorage[127.0.0.1:35539,DS-8ea2d0f1-66f0-4ffd-a1b0-7a5e4411f2a2,DISK], DatanodeInfoWithStorage[127.0.0.1:43817,DS-5e1c7fa4-3c49-461e-9d5d-887b2a3d41e6,DISK], DatanodeInfoWithStorage[127.0.0.1:43593,DS-b8cd9781-3d93-45ab-a08b-a39165af80c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36761,DS-9fac9c92-e7f8-4b8b-9986-0ddea1a88f27,DISK], DatanodeInfoWithStorage[127.0.0.1:36849,DS-bea6a309-c272-4446-9902-8ecb7057cbbf,DISK], DatanodeInfoWithStorage[127.0.0.1:39409,DS-e740c9fc-437f-4203-8539-1c5c255e4aaa,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5105
