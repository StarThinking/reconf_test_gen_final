reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-453858839-172.17.0.6-1595351065744:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43678,DS-d50cd562-fa6a-40be-9e85-69b3c16d27fa,DISK], DatanodeInfoWithStorage[127.0.0.1:34186,DS-0dc64bc1-e255-40a1-bfc8-01cea60d6b11,DISK], DatanodeInfoWithStorage[127.0.0.1:44135,DS-454014c0-2780-4af5-9545-0c9a1ccea5d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42469,DS-d40b580e-fdd6-4ee4-95a7-cb6df6d5f25c,DISK], DatanodeInfoWithStorage[127.0.0.1:38736,DS-fe203d14-e381-45ff-a644-74db86fdf257,DISK], DatanodeInfoWithStorage[127.0.0.1:44651,DS-070f89e3-c164-4057-a71d-e57d40059f9d,DISK], DatanodeInfoWithStorage[127.0.0.1:45250,DS-c3d5e1bf-a8f9-4dfc-8068-cf14fa3c84f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38561,DS-6f949613-9561-47b2-9342-1623191424fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-453858839-172.17.0.6-1595351065744:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43678,DS-d50cd562-fa6a-40be-9e85-69b3c16d27fa,DISK], DatanodeInfoWithStorage[127.0.0.1:34186,DS-0dc64bc1-e255-40a1-bfc8-01cea60d6b11,DISK], DatanodeInfoWithStorage[127.0.0.1:44135,DS-454014c0-2780-4af5-9545-0c9a1ccea5d8,DISK], DatanodeInfoWithStorage[127.0.0.1:42469,DS-d40b580e-fdd6-4ee4-95a7-cb6df6d5f25c,DISK], DatanodeInfoWithStorage[127.0.0.1:38736,DS-fe203d14-e381-45ff-a644-74db86fdf257,DISK], DatanodeInfoWithStorage[127.0.0.1:44651,DS-070f89e3-c164-4057-a71d-e57d40059f9d,DISK], DatanodeInfoWithStorage[127.0.0.1:45250,DS-c3d5e1bf-a8f9-4dfc-8068-cf14fa3c84f7,DISK], DatanodeInfoWithStorage[127.0.0.1:38561,DS-6f949613-9561-47b2-9342-1623191424fb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1727992256-172.17.0.6-1595351429513:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44621,DS-7137fc8b-02fe-4cf2-84b9-c319ff91e822,DISK], DatanodeInfoWithStorage[127.0.0.1:33256,DS-d7a19ea5-bf4d-4ce1-8d68-e016b4d9b1b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40606,DS-0a21eae7-8377-4984-8e16-4a7995e7cbd0,DISK], DatanodeInfoWithStorage[127.0.0.1:42423,DS-3b20af7b-9e13-49c5-a7cd-a1d1c958c42d,DISK], DatanodeInfoWithStorage[127.0.0.1:35445,DS-b136124a-a9f3-4969-9c97-1ee5b54072ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35217,DS-91dc2545-40ea-4d8e-94d5-a45b419ce2e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34722,DS-e3bc1fb7-191d-4185-8ee8-6fd2f308b313,DISK], DatanodeInfoWithStorage[127.0.0.1:41651,DS-a96924b9-8c6b-4369-85da-80518aadc79d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1727992256-172.17.0.6-1595351429513:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44621,DS-7137fc8b-02fe-4cf2-84b9-c319ff91e822,DISK], DatanodeInfoWithStorage[127.0.0.1:33256,DS-d7a19ea5-bf4d-4ce1-8d68-e016b4d9b1b8,DISK], DatanodeInfoWithStorage[127.0.0.1:40606,DS-0a21eae7-8377-4984-8e16-4a7995e7cbd0,DISK], DatanodeInfoWithStorage[127.0.0.1:42423,DS-3b20af7b-9e13-49c5-a7cd-a1d1c958c42d,DISK], DatanodeInfoWithStorage[127.0.0.1:35445,DS-b136124a-a9f3-4969-9c97-1ee5b54072ea,DISK], DatanodeInfoWithStorage[127.0.0.1:35217,DS-91dc2545-40ea-4d8e-94d5-a45b419ce2e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34722,DS-e3bc1fb7-191d-4185-8ee8-6fd2f308b313,DISK], DatanodeInfoWithStorage[127.0.0.1:41651,DS-a96924b9-8c6b-4369-85da-80518aadc79d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1021468740-172.17.0.6-1595351615734:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46807,DS-32a4c1e4-cd53-490d-8eb1-f2d8edb48acb,DISK], DatanodeInfoWithStorage[127.0.0.1:36388,DS-b99b7bb6-428a-488f-a449-f54e9694a938,DISK], DatanodeInfoWithStorage[127.0.0.1:37081,DS-bbc1904c-bc80-4021-aa20-8b75d2e0667e,DISK], DatanodeInfoWithStorage[127.0.0.1:44941,DS-c18f499a-846a-4eef-8c47-e06bd5018b83,DISK], DatanodeInfoWithStorage[127.0.0.1:45388,DS-90a6118d-c5ee-4327-8360-22b7ca90fba1,DISK], DatanodeInfoWithStorage[127.0.0.1:43024,DS-d60e5877-c6b3-4118-867f-0a1d02dcc3b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34147,DS-97dac3e5-b3ac-4e9d-81e2-2197d1e397a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36048,DS-91ffae30-f6fa-43c1-bcac-53e720c0c7a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1021468740-172.17.0.6-1595351615734:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46807,DS-32a4c1e4-cd53-490d-8eb1-f2d8edb48acb,DISK], DatanodeInfoWithStorage[127.0.0.1:36388,DS-b99b7bb6-428a-488f-a449-f54e9694a938,DISK], DatanodeInfoWithStorage[127.0.0.1:37081,DS-bbc1904c-bc80-4021-aa20-8b75d2e0667e,DISK], DatanodeInfoWithStorage[127.0.0.1:44941,DS-c18f499a-846a-4eef-8c47-e06bd5018b83,DISK], DatanodeInfoWithStorage[127.0.0.1:45388,DS-90a6118d-c5ee-4327-8360-22b7ca90fba1,DISK], DatanodeInfoWithStorage[127.0.0.1:43024,DS-d60e5877-c6b3-4118-867f-0a1d02dcc3b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34147,DS-97dac3e5-b3ac-4e9d-81e2-2197d1e397a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36048,DS-91ffae30-f6fa-43c1-bcac-53e720c0c7a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1194942431-172.17.0.6-1595351719554:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33533,DS-d00e508a-16d3-48ac-aad5-994236cb3c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:35376,DS-9defddfc-9099-4cd9-b048-9f9d69845be4,DISK], DatanodeInfoWithStorage[127.0.0.1:37123,DS-f8bf9ddf-e601-49f5-b88b-be2345d9b009,DISK], DatanodeInfoWithStorage[127.0.0.1:37977,DS-509c36ba-13da-4b99-a5e5-3a8ac7a21c25,DISK], DatanodeInfoWithStorage[127.0.0.1:38368,DS-cf6be780-7389-4e80-8c2d-90b91550e72d,DISK], DatanodeInfoWithStorage[127.0.0.1:35520,DS-def17707-a49b-4995-be4f-abd6ccc624c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35954,DS-357fc7ef-f923-41f9-a91e-e833b6985c77,DISK], DatanodeInfoWithStorage[127.0.0.1:39980,DS-af72f142-8268-45a7-a8a1-4ba4b0871d15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1194942431-172.17.0.6-1595351719554:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33533,DS-d00e508a-16d3-48ac-aad5-994236cb3c1b,DISK], DatanodeInfoWithStorage[127.0.0.1:35376,DS-9defddfc-9099-4cd9-b048-9f9d69845be4,DISK], DatanodeInfoWithStorage[127.0.0.1:37123,DS-f8bf9ddf-e601-49f5-b88b-be2345d9b009,DISK], DatanodeInfoWithStorage[127.0.0.1:37977,DS-509c36ba-13da-4b99-a5e5-3a8ac7a21c25,DISK], DatanodeInfoWithStorage[127.0.0.1:38368,DS-cf6be780-7389-4e80-8c2d-90b91550e72d,DISK], DatanodeInfoWithStorage[127.0.0.1:35520,DS-def17707-a49b-4995-be4f-abd6ccc624c9,DISK], DatanodeInfoWithStorage[127.0.0.1:35954,DS-357fc7ef-f923-41f9-a91e-e833b6985c77,DISK], DatanodeInfoWithStorage[127.0.0.1:39980,DS-af72f142-8268-45a7-a8a1-4ba4b0871d15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1120864535-172.17.0.6-1595351873265:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46337,DS-9ab941d1-b9b6-412d-9bae-ca0207a92672,DISK], DatanodeInfoWithStorage[127.0.0.1:37850,DS-780d6b16-4d69-4413-afca-cc94cb4c1015,DISK], DatanodeInfoWithStorage[127.0.0.1:37157,DS-2ae06325-66c9-481e-bbff-d77d7d3c5ebe,DISK], DatanodeInfoWithStorage[127.0.0.1:36607,DS-a5a4f707-b4c2-4a3d-928c-652a5e3bc023,DISK], DatanodeInfoWithStorage[127.0.0.1:35145,DS-b1fad0ab-7b96-428e-add3-ba638006fa31,DISK], DatanodeInfoWithStorage[127.0.0.1:33465,DS-863b22a7-8fae-4486-b280-de4249a18081,DISK], DatanodeInfoWithStorage[127.0.0.1:32987,DS-68b3937d-1687-4e77-bcbf-7bef8cc6df2c,DISK], DatanodeInfoWithStorage[127.0.0.1:34816,DS-7abc0f3c-bb62-4902-a662-83fc1be745fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1120864535-172.17.0.6-1595351873265:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46337,DS-9ab941d1-b9b6-412d-9bae-ca0207a92672,DISK], DatanodeInfoWithStorage[127.0.0.1:37850,DS-780d6b16-4d69-4413-afca-cc94cb4c1015,DISK], DatanodeInfoWithStorage[127.0.0.1:37157,DS-2ae06325-66c9-481e-bbff-d77d7d3c5ebe,DISK], DatanodeInfoWithStorage[127.0.0.1:36607,DS-a5a4f707-b4c2-4a3d-928c-652a5e3bc023,DISK], DatanodeInfoWithStorage[127.0.0.1:35145,DS-b1fad0ab-7b96-428e-add3-ba638006fa31,DISK], DatanodeInfoWithStorage[127.0.0.1:33465,DS-863b22a7-8fae-4486-b280-de4249a18081,DISK], DatanodeInfoWithStorage[127.0.0.1:32987,DS-68b3937d-1687-4e77-bcbf-7bef8cc6df2c,DISK], DatanodeInfoWithStorage[127.0.0.1:34816,DS-7abc0f3c-bb62-4902-a662-83fc1be745fd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1616846948-172.17.0.6-1595352114724:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44886,DS-76ea6cb2-aadc-4d93-9db2-0357bd759cdf,DISK], DatanodeInfoWithStorage[127.0.0.1:38759,DS-732e1d0b-1500-4be0-b694-25f95a435098,DISK], DatanodeInfoWithStorage[127.0.0.1:42235,DS-8786405f-f75e-4f7e-91b7-395eee8a460e,DISK], DatanodeInfoWithStorage[127.0.0.1:42421,DS-18325941-d23e-41ab-aaa3-56d44be5535a,DISK], DatanodeInfoWithStorage[127.0.0.1:42415,DS-1bb0e0ee-651d-4d75-a25d-405712d070b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45632,DS-aaba3db0-6177-458d-9253-b2914e973200,DISK], DatanodeInfoWithStorage[127.0.0.1:41298,DS-c54fcec8-3e9b-4a3b-b0e6-b60f5516acf4,DISK], DatanodeInfoWithStorage[127.0.0.1:33279,DS-d8c90e2d-0e36-4564-b4ed-1c2141e390c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1616846948-172.17.0.6-1595352114724:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44886,DS-76ea6cb2-aadc-4d93-9db2-0357bd759cdf,DISK], DatanodeInfoWithStorage[127.0.0.1:38759,DS-732e1d0b-1500-4be0-b694-25f95a435098,DISK], DatanodeInfoWithStorage[127.0.0.1:42235,DS-8786405f-f75e-4f7e-91b7-395eee8a460e,DISK], DatanodeInfoWithStorage[127.0.0.1:42421,DS-18325941-d23e-41ab-aaa3-56d44be5535a,DISK], DatanodeInfoWithStorage[127.0.0.1:42415,DS-1bb0e0ee-651d-4d75-a25d-405712d070b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45632,DS-aaba3db0-6177-458d-9253-b2914e973200,DISK], DatanodeInfoWithStorage[127.0.0.1:41298,DS-c54fcec8-3e9b-4a3b-b0e6-b60f5516acf4,DISK], DatanodeInfoWithStorage[127.0.0.1:33279,DS-d8c90e2d-0e36-4564-b4ed-1c2141e390c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1327876907-172.17.0.6-1595352182858:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45636,DS-bc7a5825-7843-4ecf-b570-c6e29415ef3a,DISK], DatanodeInfoWithStorage[127.0.0.1:42244,DS-8a20a896-ca53-4797-b1fd-832dc3ccf658,DISK], DatanodeInfoWithStorage[127.0.0.1:37104,DS-eb2907e1-87fb-4fad-9ea9-141d1f0cefc9,DISK], DatanodeInfoWithStorage[127.0.0.1:36382,DS-e1e77297-4b8f-48f3-9fbb-4397155bd7e0,DISK], DatanodeInfoWithStorage[127.0.0.1:38140,DS-301b7daf-bc7e-44da-9194-a9131b79537c,DISK], DatanodeInfoWithStorage[127.0.0.1:39905,DS-861e5ba4-c401-45e5-8712-b301ce0c56cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41676,DS-64c7ce4e-dd75-4c7a-8be7-730a79fb7dfb,DISK], DatanodeInfoWithStorage[127.0.0.1:37326,DS-e026ae87-a310-43c0-8030-25ad0be3d3d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1327876907-172.17.0.6-1595352182858:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45636,DS-bc7a5825-7843-4ecf-b570-c6e29415ef3a,DISK], DatanodeInfoWithStorage[127.0.0.1:42244,DS-8a20a896-ca53-4797-b1fd-832dc3ccf658,DISK], DatanodeInfoWithStorage[127.0.0.1:37104,DS-eb2907e1-87fb-4fad-9ea9-141d1f0cefc9,DISK], DatanodeInfoWithStorage[127.0.0.1:36382,DS-e1e77297-4b8f-48f3-9fbb-4397155bd7e0,DISK], DatanodeInfoWithStorage[127.0.0.1:38140,DS-301b7daf-bc7e-44da-9194-a9131b79537c,DISK], DatanodeInfoWithStorage[127.0.0.1:39905,DS-861e5ba4-c401-45e5-8712-b301ce0c56cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41676,DS-64c7ce4e-dd75-4c7a-8be7-730a79fb7dfb,DISK], DatanodeInfoWithStorage[127.0.0.1:37326,DS-e026ae87-a310-43c0-8030-25ad0be3d3d1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1310662117-172.17.0.6-1595352337707:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38667,DS-bbce9763-684f-4ff1-9cac-44654fef06be,DISK], DatanodeInfoWithStorage[127.0.0.1:36172,DS-af1e59c5-d500-43c5-bc48-316dea16db5f,DISK], DatanodeInfoWithStorage[127.0.0.1:43351,DS-ba86ff0f-17c0-45bd-a08d-66268e96cf76,DISK], DatanodeInfoWithStorage[127.0.0.1:34889,DS-162df94b-3958-4367-b2b2-b55e782f6d69,DISK], DatanodeInfoWithStorage[127.0.0.1:36086,DS-b370527c-c33a-4415-ad83-ab50bf74e49a,DISK], DatanodeInfoWithStorage[127.0.0.1:44807,DS-69da4c9d-7a15-4dd9-a12e-0da94f0c9c36,DISK], DatanodeInfoWithStorage[127.0.0.1:43630,DS-c3b8f7e2-847f-4a2c-aae7-39b99028aa2c,DISK], DatanodeInfoWithStorage[127.0.0.1:42589,DS-5c9614fb-5d38-40ed-b8cd-f5a594741ff4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1310662117-172.17.0.6-1595352337707:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38667,DS-bbce9763-684f-4ff1-9cac-44654fef06be,DISK], DatanodeInfoWithStorage[127.0.0.1:36172,DS-af1e59c5-d500-43c5-bc48-316dea16db5f,DISK], DatanodeInfoWithStorage[127.0.0.1:43351,DS-ba86ff0f-17c0-45bd-a08d-66268e96cf76,DISK], DatanodeInfoWithStorage[127.0.0.1:34889,DS-162df94b-3958-4367-b2b2-b55e782f6d69,DISK], DatanodeInfoWithStorage[127.0.0.1:36086,DS-b370527c-c33a-4415-ad83-ab50bf74e49a,DISK], DatanodeInfoWithStorage[127.0.0.1:44807,DS-69da4c9d-7a15-4dd9-a12e-0da94f0c9c36,DISK], DatanodeInfoWithStorage[127.0.0.1:43630,DS-c3b8f7e2-847f-4a2c-aae7-39b99028aa2c,DISK], DatanodeInfoWithStorage[127.0.0.1:42589,DS-5c9614fb-5d38-40ed-b8cd-f5a594741ff4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-187119381-172.17.0.6-1595352450873:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34721,DS-7baf0f7c-d059-4813-bded-e1cd15c89075,DISK], DatanodeInfoWithStorage[127.0.0.1:35425,DS-0197c795-566f-41ef-b03e-b8b5762356e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38313,DS-2f852fd1-97f5-4077-8b77-18abb4354a83,DISK], DatanodeInfoWithStorage[127.0.0.1:44011,DS-ae62814a-e223-48cb-9158-89dda3a85580,DISK], DatanodeInfoWithStorage[127.0.0.1:45292,DS-cf1ebf4f-3a2c-416f-8146-b2421af7236f,DISK], DatanodeInfoWithStorage[127.0.0.1:42004,DS-fb05a227-075f-43c7-8ddc-86d34747bf5e,DISK], DatanodeInfoWithStorage[127.0.0.1:43509,DS-d3639611-eeff-4fde-beea-c71ac1d29463,DISK], DatanodeInfoWithStorage[127.0.0.1:42181,DS-22e2b81b-3f53-4034-b749-bc55cc26266f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-187119381-172.17.0.6-1595352450873:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34721,DS-7baf0f7c-d059-4813-bded-e1cd15c89075,DISK], DatanodeInfoWithStorage[127.0.0.1:35425,DS-0197c795-566f-41ef-b03e-b8b5762356e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38313,DS-2f852fd1-97f5-4077-8b77-18abb4354a83,DISK], DatanodeInfoWithStorage[127.0.0.1:44011,DS-ae62814a-e223-48cb-9158-89dda3a85580,DISK], DatanodeInfoWithStorage[127.0.0.1:45292,DS-cf1ebf4f-3a2c-416f-8146-b2421af7236f,DISK], DatanodeInfoWithStorage[127.0.0.1:42004,DS-fb05a227-075f-43c7-8ddc-86d34747bf5e,DISK], DatanodeInfoWithStorage[127.0.0.1:43509,DS-d3639611-eeff-4fde-beea-c71ac1d29463,DISK], DatanodeInfoWithStorage[127.0.0.1:42181,DS-22e2b81b-3f53-4034-b749-bc55cc26266f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-679858533-172.17.0.6-1595352767640:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44625,DS-1c2691b0-aaed-473f-8293-0f165c9ed501,DISK], DatanodeInfoWithStorage[127.0.0.1:36033,DS-dcf83d4e-d7a5-43eb-8c90-742dbeeaf509,DISK], DatanodeInfoWithStorage[127.0.0.1:46021,DS-2e06d997-0d77-4bbf-8de4-a28b0d8b2893,DISK], DatanodeInfoWithStorage[127.0.0.1:39110,DS-2a8ad28f-1ed5-4f2d-90b9-aea38f129c3f,DISK], DatanodeInfoWithStorage[127.0.0.1:38545,DS-1479f3aa-8f64-4562-b082-20f35242cf43,DISK], DatanodeInfoWithStorage[127.0.0.1:38164,DS-56d7b1ff-753a-4cb3-bd11-11c7156b15cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42133,DS-ef6c1bf3-7f51-48b9-b0c3-2c06a307b310,DISK], DatanodeInfoWithStorage[127.0.0.1:40140,DS-eef4e366-bc33-477f-b64e-3d6e62d377f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-679858533-172.17.0.6-1595352767640:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44625,DS-1c2691b0-aaed-473f-8293-0f165c9ed501,DISK], DatanodeInfoWithStorage[127.0.0.1:36033,DS-dcf83d4e-d7a5-43eb-8c90-742dbeeaf509,DISK], DatanodeInfoWithStorage[127.0.0.1:46021,DS-2e06d997-0d77-4bbf-8de4-a28b0d8b2893,DISK], DatanodeInfoWithStorage[127.0.0.1:39110,DS-2a8ad28f-1ed5-4f2d-90b9-aea38f129c3f,DISK], DatanodeInfoWithStorage[127.0.0.1:38545,DS-1479f3aa-8f64-4562-b082-20f35242cf43,DISK], DatanodeInfoWithStorage[127.0.0.1:38164,DS-56d7b1ff-753a-4cb3-bd11-11c7156b15cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42133,DS-ef6c1bf3-7f51-48b9-b0c3-2c06a307b310,DISK], DatanodeInfoWithStorage[127.0.0.1:40140,DS-eef4e366-bc33-477f-b64e-3d6e62d377f7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-158105803-172.17.0.6-1595353281910:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32973,DS-74785816-8f55-4487-8c9b-1c8da0dce566,DISK], DatanodeInfoWithStorage[127.0.0.1:33319,DS-f139e56d-b691-4b04-a40b-5f85b3ddfd45,DISK], DatanodeInfoWithStorage[127.0.0.1:37807,DS-efe0ec3a-cc80-44e4-a945-ee72d35ec7f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35504,DS-745fad71-b079-4007-b3b1-c1ac4210cf8c,DISK], DatanodeInfoWithStorage[127.0.0.1:42492,DS-a4f05c09-7476-4e3f-a19a-a26bbe58db90,DISK], DatanodeInfoWithStorage[127.0.0.1:33310,DS-069cd38c-93be-426a-a0d8-12352145435c,DISK], DatanodeInfoWithStorage[127.0.0.1:44787,DS-1bf661d4-3188-48fc-b8e9-8e450682317e,DISK], DatanodeInfoWithStorage[127.0.0.1:45169,DS-905b4bcc-d71c-4e03-be39-d3a267364a78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-158105803-172.17.0.6-1595353281910:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32973,DS-74785816-8f55-4487-8c9b-1c8da0dce566,DISK], DatanodeInfoWithStorage[127.0.0.1:33319,DS-f139e56d-b691-4b04-a40b-5f85b3ddfd45,DISK], DatanodeInfoWithStorage[127.0.0.1:37807,DS-efe0ec3a-cc80-44e4-a945-ee72d35ec7f0,DISK], DatanodeInfoWithStorage[127.0.0.1:35504,DS-745fad71-b079-4007-b3b1-c1ac4210cf8c,DISK], DatanodeInfoWithStorage[127.0.0.1:42492,DS-a4f05c09-7476-4e3f-a19a-a26bbe58db90,DISK], DatanodeInfoWithStorage[127.0.0.1:33310,DS-069cd38c-93be-426a-a0d8-12352145435c,DISK], DatanodeInfoWithStorage[127.0.0.1:44787,DS-1bf661d4-3188-48fc-b8e9-8e450682317e,DISK], DatanodeInfoWithStorage[127.0.0.1:45169,DS-905b4bcc-d71c-4e03-be39-d3a267364a78,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-273058130-172.17.0.6-1595353623767:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36203,DS-d01e24e3-24fc-4b7b-be5e-4a23920cc27d,DISK], DatanodeInfoWithStorage[127.0.0.1:46738,DS-51ad1b03-6df7-4329-80ef-5e3221c7bbd8,DISK], DatanodeInfoWithStorage[127.0.0.1:34599,DS-9af83c65-5cb4-4901-a6d3-25b20269b95a,DISK], DatanodeInfoWithStorage[127.0.0.1:41891,DS-b5f56f8f-44fe-4cf4-b70c-b4a47430d86d,DISK], DatanodeInfoWithStorage[127.0.0.1:36262,DS-f40ee29e-0134-4e57-9630-598055175542,DISK], DatanodeInfoWithStorage[127.0.0.1:41976,DS-6a6dd484-c7a6-45dd-bed9-c402ee33e0a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34657,DS-42dd8319-1c12-411c-b36c-a6953fb2f99a,DISK], DatanodeInfoWithStorage[127.0.0.1:34823,DS-88dcba8f-e305-4176-9a70-2702753b1812,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-273058130-172.17.0.6-1595353623767:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36203,DS-d01e24e3-24fc-4b7b-be5e-4a23920cc27d,DISK], DatanodeInfoWithStorage[127.0.0.1:46738,DS-51ad1b03-6df7-4329-80ef-5e3221c7bbd8,DISK], DatanodeInfoWithStorage[127.0.0.1:34599,DS-9af83c65-5cb4-4901-a6d3-25b20269b95a,DISK], DatanodeInfoWithStorage[127.0.0.1:41891,DS-b5f56f8f-44fe-4cf4-b70c-b4a47430d86d,DISK], DatanodeInfoWithStorage[127.0.0.1:36262,DS-f40ee29e-0134-4e57-9630-598055175542,DISK], DatanodeInfoWithStorage[127.0.0.1:41976,DS-6a6dd484-c7a6-45dd-bed9-c402ee33e0a8,DISK], DatanodeInfoWithStorage[127.0.0.1:34657,DS-42dd8319-1c12-411c-b36c-a6953fb2f99a,DISK], DatanodeInfoWithStorage[127.0.0.1:34823,DS-88dcba8f-e305-4176-9a70-2702753b1812,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-853100706-172.17.0.6-1595353722803:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42881,DS-d485f3e2-5040-48f9-a98e-758007458a7c,DISK], DatanodeInfoWithStorage[127.0.0.1:36335,DS-cb6eb3ca-c6c1-44bf-96f0-a9b27b75434f,DISK], DatanodeInfoWithStorage[127.0.0.1:37672,DS-6a3e2ebb-2549-4611-bac9-5d76ca5031f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35465,DS-45e419be-548e-46f3-8b98-59e0189dce80,DISK], DatanodeInfoWithStorage[127.0.0.1:43691,DS-9fa01691-c37f-46d2-addc-95329a884d20,DISK], DatanodeInfoWithStorage[127.0.0.1:33530,DS-fa67b30f-5ac3-4cd8-b581-f361ed29e027,DISK], DatanodeInfoWithStorage[127.0.0.1:32973,DS-c77b32fe-3579-40bf-b2b7-ce5a5b86cc65,DISK], DatanodeInfoWithStorage[127.0.0.1:44505,DS-4db93118-92bc-41ea-b916-b249122e1b15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-853100706-172.17.0.6-1595353722803:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42881,DS-d485f3e2-5040-48f9-a98e-758007458a7c,DISK], DatanodeInfoWithStorage[127.0.0.1:36335,DS-cb6eb3ca-c6c1-44bf-96f0-a9b27b75434f,DISK], DatanodeInfoWithStorage[127.0.0.1:37672,DS-6a3e2ebb-2549-4611-bac9-5d76ca5031f6,DISK], DatanodeInfoWithStorage[127.0.0.1:35465,DS-45e419be-548e-46f3-8b98-59e0189dce80,DISK], DatanodeInfoWithStorage[127.0.0.1:43691,DS-9fa01691-c37f-46d2-addc-95329a884d20,DISK], DatanodeInfoWithStorage[127.0.0.1:33530,DS-fa67b30f-5ac3-4cd8-b581-f361ed29e027,DISK], DatanodeInfoWithStorage[127.0.0.1:32973,DS-c77b32fe-3579-40bf-b2b7-ce5a5b86cc65,DISK], DatanodeInfoWithStorage[127.0.0.1:44505,DS-4db93118-92bc-41ea-b916-b249122e1b15,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2121864568-172.17.0.6-1595354088522:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43317,DS-cf1b8ea1-b2e3-4578-a629-a7793e18ea08,DISK], DatanodeInfoWithStorage[127.0.0.1:45968,DS-0c678e03-4a6a-4c9c-b443-d56a5981177c,DISK], DatanodeInfoWithStorage[127.0.0.1:33119,DS-22617976-4fc6-4c11-9935-d82f2e2b65cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38122,DS-322109a5-6ad2-4866-92d0-b0ef692bc659,DISK], DatanodeInfoWithStorage[127.0.0.1:45479,DS-b329980a-f7d9-4c30-93f0-7695e27a5e20,DISK], DatanodeInfoWithStorage[127.0.0.1:41108,DS-ece0aa37-e93e-4331-93e8-ce33ac99b46c,DISK], DatanodeInfoWithStorage[127.0.0.1:44394,DS-4ec8b243-08fd-49ff-add0-512bc9a94ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:45328,DS-46919e68-f22b-403f-9cbe-1ecac968f1ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2121864568-172.17.0.6-1595354088522:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43317,DS-cf1b8ea1-b2e3-4578-a629-a7793e18ea08,DISK], DatanodeInfoWithStorage[127.0.0.1:45968,DS-0c678e03-4a6a-4c9c-b443-d56a5981177c,DISK], DatanodeInfoWithStorage[127.0.0.1:33119,DS-22617976-4fc6-4c11-9935-d82f2e2b65cf,DISK], DatanodeInfoWithStorage[127.0.0.1:38122,DS-322109a5-6ad2-4866-92d0-b0ef692bc659,DISK], DatanodeInfoWithStorage[127.0.0.1:45479,DS-b329980a-f7d9-4c30-93f0-7695e27a5e20,DISK], DatanodeInfoWithStorage[127.0.0.1:41108,DS-ece0aa37-e93e-4331-93e8-ce33ac99b46c,DISK], DatanodeInfoWithStorage[127.0.0.1:44394,DS-4ec8b243-08fd-49ff-add0-512bc9a94ca7,DISK], DatanodeInfoWithStorage[127.0.0.1:45328,DS-46919e68-f22b-403f-9cbe-1ecac968f1ac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1819115196-172.17.0.6-1595354118180:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38677,DS-e0ea1006-f939-4106-a3e8-9e9f6edf0ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:33429,DS-05fc2907-4708-47a5-ba3f-1c4aeeb2555e,DISK], DatanodeInfoWithStorage[127.0.0.1:36275,DS-f504e0f8-8f0e-4465-930c-9c5700803ef0,DISK], DatanodeInfoWithStorage[127.0.0.1:42807,DS-2474f0b4-5f68-45d8-bf22-b389c7b82a14,DISK], DatanodeInfoWithStorage[127.0.0.1:41845,DS-fcced00a-2093-45da-9c39-254be95f1b8c,DISK], DatanodeInfoWithStorage[127.0.0.1:43276,DS-3807d76a-b035-4718-bde6-bf85e5a261f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40587,DS-961b3c3b-4148-4f03-b13a-8184c7894437,DISK], DatanodeInfoWithStorage[127.0.0.1:33340,DS-4289a591-1420-4e52-9c0e-0eb2001ec169,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1819115196-172.17.0.6-1595354118180:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38677,DS-e0ea1006-f939-4106-a3e8-9e9f6edf0ecf,DISK], DatanodeInfoWithStorage[127.0.0.1:33429,DS-05fc2907-4708-47a5-ba3f-1c4aeeb2555e,DISK], DatanodeInfoWithStorage[127.0.0.1:36275,DS-f504e0f8-8f0e-4465-930c-9c5700803ef0,DISK], DatanodeInfoWithStorage[127.0.0.1:42807,DS-2474f0b4-5f68-45d8-bf22-b389c7b82a14,DISK], DatanodeInfoWithStorage[127.0.0.1:41845,DS-fcced00a-2093-45da-9c39-254be95f1b8c,DISK], DatanodeInfoWithStorage[127.0.0.1:43276,DS-3807d76a-b035-4718-bde6-bf85e5a261f7,DISK], DatanodeInfoWithStorage[127.0.0.1:40587,DS-961b3c3b-4148-4f03-b13a-8184c7894437,DISK], DatanodeInfoWithStorage[127.0.0.1:33340,DS-4289a591-1420-4e52-9c0e-0eb2001ec169,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-312170372-172.17.0.6-1595354226654:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43347,DS-7db11616-a8e7-400d-9266-4386a95ff0b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41816,DS-51fc8b16-ea84-47fb-8914-6fc60878afd1,DISK], DatanodeInfoWithStorage[127.0.0.1:34862,DS-f2a90c0f-83df-4cb4-b35a-d004274ed1d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34949,DS-10264c85-eb52-48e4-b379-9b2a1a8fc3f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45425,DS-e5cac00e-16af-4bf8-a5c7-9dfbb4a50782,DISK], DatanodeInfoWithStorage[127.0.0.1:41291,DS-eb121fb5-7783-41bc-b54e-beed4eeb24d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38676,DS-1646e9df-e6c4-479e-98c4-aab15788396e,DISK], DatanodeInfoWithStorage[127.0.0.1:43152,DS-788ff402-40a5-4006-acac-038edf059e7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-312170372-172.17.0.6-1595354226654:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43347,DS-7db11616-a8e7-400d-9266-4386a95ff0b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41816,DS-51fc8b16-ea84-47fb-8914-6fc60878afd1,DISK], DatanodeInfoWithStorage[127.0.0.1:34862,DS-f2a90c0f-83df-4cb4-b35a-d004274ed1d2,DISK], DatanodeInfoWithStorage[127.0.0.1:34949,DS-10264c85-eb52-48e4-b379-9b2a1a8fc3f6,DISK], DatanodeInfoWithStorage[127.0.0.1:45425,DS-e5cac00e-16af-4bf8-a5c7-9dfbb4a50782,DISK], DatanodeInfoWithStorage[127.0.0.1:41291,DS-eb121fb5-7783-41bc-b54e-beed4eeb24d8,DISK], DatanodeInfoWithStorage[127.0.0.1:38676,DS-1646e9df-e6c4-479e-98c4-aab15788396e,DISK], DatanodeInfoWithStorage[127.0.0.1:43152,DS-788ff402-40a5-4006-acac-038edf059e7e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1544582025-172.17.0.6-1595354269027:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39232,DS-ff31ce39-0427-413d-a3f3-9de64f468f24,DISK], DatanodeInfoWithStorage[127.0.0.1:37301,DS-8fe0bb2f-af2c-4882-87fe-80fe916bdfbb,DISK], DatanodeInfoWithStorage[127.0.0.1:44908,DS-46c305dd-5a87-40cb-8005-c55284b8fdab,DISK], DatanodeInfoWithStorage[127.0.0.1:45810,DS-4046e008-8345-4d00-abea-160648f638f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36474,DS-81a80530-bb3e-4ee4-a264-a8440954c32f,DISK], DatanodeInfoWithStorage[127.0.0.1:33157,DS-f72807cd-25bc-4275-a7a4-12d518e44996,DISK], DatanodeInfoWithStorage[127.0.0.1:36906,DS-98216fac-eae1-4917-af64-3bc8eef2a229,DISK], DatanodeInfoWithStorage[127.0.0.1:42078,DS-19354b2a-553b-4998-a093-8165112d6dbf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1544582025-172.17.0.6-1595354269027:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39232,DS-ff31ce39-0427-413d-a3f3-9de64f468f24,DISK], DatanodeInfoWithStorage[127.0.0.1:37301,DS-8fe0bb2f-af2c-4882-87fe-80fe916bdfbb,DISK], DatanodeInfoWithStorage[127.0.0.1:44908,DS-46c305dd-5a87-40cb-8005-c55284b8fdab,DISK], DatanodeInfoWithStorage[127.0.0.1:45810,DS-4046e008-8345-4d00-abea-160648f638f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36474,DS-81a80530-bb3e-4ee4-a264-a8440954c32f,DISK], DatanodeInfoWithStorage[127.0.0.1:33157,DS-f72807cd-25bc-4275-a7a4-12d518e44996,DISK], DatanodeInfoWithStorage[127.0.0.1:36906,DS-98216fac-eae1-4917-af64-3bc8eef2a229,DISK], DatanodeInfoWithStorage[127.0.0.1:42078,DS-19354b2a-553b-4998-a093-8165112d6dbf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2013648785-172.17.0.6-1595354532716:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41878,DS-fae871a4-f5d9-48ce-8eeb-c3098316e814,DISK], DatanodeInfoWithStorage[127.0.0.1:39502,DS-8b171161-5d18-42af-befe-3ddfcb2fc905,DISK], DatanodeInfoWithStorage[127.0.0.1:45159,DS-238fb18f-cda3-4f8a-8fa9-056c21a92c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:46760,DS-edc75c1e-7634-4636-ad03-cb765cf36293,DISK], DatanodeInfoWithStorage[127.0.0.1:37374,DS-68622510-cc1a-40bb-adb4-4dce29ef261d,DISK], DatanodeInfoWithStorage[127.0.0.1:42865,DS-e5383cb4-296a-4ff5-9cff-5277f1ed02b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41388,DS-a9bb6b62-1041-4977-8070-2fc71d3c3d95,DISK], DatanodeInfoWithStorage[127.0.0.1:46229,DS-fe84f4b0-b871-4ed2-9368-7c5183191f70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2013648785-172.17.0.6-1595354532716:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41878,DS-fae871a4-f5d9-48ce-8eeb-c3098316e814,DISK], DatanodeInfoWithStorage[127.0.0.1:39502,DS-8b171161-5d18-42af-befe-3ddfcb2fc905,DISK], DatanodeInfoWithStorage[127.0.0.1:45159,DS-238fb18f-cda3-4f8a-8fa9-056c21a92c4e,DISK], DatanodeInfoWithStorage[127.0.0.1:46760,DS-edc75c1e-7634-4636-ad03-cb765cf36293,DISK], DatanodeInfoWithStorage[127.0.0.1:37374,DS-68622510-cc1a-40bb-adb4-4dce29ef261d,DISK], DatanodeInfoWithStorage[127.0.0.1:42865,DS-e5383cb4-296a-4ff5-9cff-5277f1ed02b8,DISK], DatanodeInfoWithStorage[127.0.0.1:41388,DS-a9bb6b62-1041-4977-8070-2fc71d3c3d95,DISK], DatanodeInfoWithStorage[127.0.0.1:46229,DS-fe84f4b0-b871-4ed2-9368-7c5183191f70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-965130596-172.17.0.6-1595354846237:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39544,DS-517e1598-ea6a-4782-aed8-c1b195565d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:32805,DS-e685e832-1cd0-486c-a2b6-8ec0101271d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44158,DS-08f0ea90-4f1c-4c35-bdfe-1ac53eecfe1c,DISK], DatanodeInfoWithStorage[127.0.0.1:35327,DS-a7737434-b6d5-4f59-b0e0-57fd3fd7614e,DISK], DatanodeInfoWithStorage[127.0.0.1:36113,DS-fd37ac09-6d56-4c34-9b7c-7d29d5715795,DISK], DatanodeInfoWithStorage[127.0.0.1:36878,DS-4260d439-a405-439a-9f98-ac782103388c,DISK], DatanodeInfoWithStorage[127.0.0.1:40963,DS-c9a091ed-c4b6-45a9-8f09-18be285cd377,DISK], DatanodeInfoWithStorage[127.0.0.1:36430,DS-9fcc0f6f-7b3d-42e6-96a7-2331be275a50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-965130596-172.17.0.6-1595354846237:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39544,DS-517e1598-ea6a-4782-aed8-c1b195565d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:32805,DS-e685e832-1cd0-486c-a2b6-8ec0101271d6,DISK], DatanodeInfoWithStorage[127.0.0.1:44158,DS-08f0ea90-4f1c-4c35-bdfe-1ac53eecfe1c,DISK], DatanodeInfoWithStorage[127.0.0.1:35327,DS-a7737434-b6d5-4f59-b0e0-57fd3fd7614e,DISK], DatanodeInfoWithStorage[127.0.0.1:36113,DS-fd37ac09-6d56-4c34-9b7c-7d29d5715795,DISK], DatanodeInfoWithStorage[127.0.0.1:36878,DS-4260d439-a405-439a-9f98-ac782103388c,DISK], DatanodeInfoWithStorage[127.0.0.1:40963,DS-c9a091ed-c4b6-45a9-8f09-18be285cd377,DISK], DatanodeInfoWithStorage[127.0.0.1:36430,DS-9fcc0f6f-7b3d-42e6-96a7-2331be275a50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-825556528-172.17.0.6-1595354884119:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38536,DS-5fc6968e-81bc-447e-a476-a3356dee6ea9,DISK], DatanodeInfoWithStorage[127.0.0.1:37895,DS-6cb6d074-8827-42d1-8f91-1870bed9cfa6,DISK], DatanodeInfoWithStorage[127.0.0.1:37176,DS-2a8b0c6d-27d1-499d-89cd-93da3d7b732b,DISK], DatanodeInfoWithStorage[127.0.0.1:44947,DS-fd9af1eb-af74-4c9b-a573-0d313c28b6ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44493,DS-4694d977-949f-4520-a71b-efd725873125,DISK], DatanodeInfoWithStorage[127.0.0.1:33804,DS-c8c8ee67-fe30-4fef-a822-bdd9accaccd5,DISK], DatanodeInfoWithStorage[127.0.0.1:43051,DS-5b0b96f9-31a6-4822-b636-aac0428f21a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35088,DS-8f12ce07-0d02-417c-b2f0-5a4ad57d45cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-825556528-172.17.0.6-1595354884119:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38536,DS-5fc6968e-81bc-447e-a476-a3356dee6ea9,DISK], DatanodeInfoWithStorage[127.0.0.1:37895,DS-6cb6d074-8827-42d1-8f91-1870bed9cfa6,DISK], DatanodeInfoWithStorage[127.0.0.1:37176,DS-2a8b0c6d-27d1-499d-89cd-93da3d7b732b,DISK], DatanodeInfoWithStorage[127.0.0.1:44947,DS-fd9af1eb-af74-4c9b-a573-0d313c28b6ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44493,DS-4694d977-949f-4520-a71b-efd725873125,DISK], DatanodeInfoWithStorage[127.0.0.1:33804,DS-c8c8ee67-fe30-4fef-a822-bdd9accaccd5,DISK], DatanodeInfoWithStorage[127.0.0.1:43051,DS-5b0b96f9-31a6-4822-b636-aac0428f21a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35088,DS-8f12ce07-0d02-417c-b2f0-5a4ad57d45cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.storage.policy.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1953219946-172.17.0.6-1595355671807:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39250,DS-2dcc4499-d578-44b8-9ab8-64e455f05e00,DISK], DatanodeInfoWithStorage[127.0.0.1:37752,DS-f391a3e0-5484-4518-b9fb-8512a6c372fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34848,DS-be437210-5fda-4727-82a1-3b91c0ebc66a,DISK], DatanodeInfoWithStorage[127.0.0.1:41384,DS-1a01b0be-7f98-458b-9bfb-75c37c5f6730,DISK], DatanodeInfoWithStorage[127.0.0.1:42427,DS-e95c3e35-d33b-40b2-afd5-f54c4013c146,DISK], DatanodeInfoWithStorage[127.0.0.1:37539,DS-dde9c839-2735-4ca0-b76d-60e7738e04e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35056,DS-c3f8d976-a613-4320-8842-7bc63827bf48,DISK], DatanodeInfoWithStorage[127.0.0.1:39080,DS-40211faa-8c13-4583-8f3d-414d38616b2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1953219946-172.17.0.6-1595355671807:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39250,DS-2dcc4499-d578-44b8-9ab8-64e455f05e00,DISK], DatanodeInfoWithStorage[127.0.0.1:37752,DS-f391a3e0-5484-4518-b9fb-8512a6c372fe,DISK], DatanodeInfoWithStorage[127.0.0.1:34848,DS-be437210-5fda-4727-82a1-3b91c0ebc66a,DISK], DatanodeInfoWithStorage[127.0.0.1:41384,DS-1a01b0be-7f98-458b-9bfb-75c37c5f6730,DISK], DatanodeInfoWithStorage[127.0.0.1:42427,DS-e95c3e35-d33b-40b2-afd5-f54c4013c146,DISK], DatanodeInfoWithStorage[127.0.0.1:37539,DS-dde9c839-2735-4ca0-b76d-60e7738e04e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35056,DS-c3f8d976-a613-4320-8842-7bc63827bf48,DISK], DatanodeInfoWithStorage[127.0.0.1:39080,DS-40211faa-8c13-4583-8f3d-414d38616b2c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 6 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 5355
