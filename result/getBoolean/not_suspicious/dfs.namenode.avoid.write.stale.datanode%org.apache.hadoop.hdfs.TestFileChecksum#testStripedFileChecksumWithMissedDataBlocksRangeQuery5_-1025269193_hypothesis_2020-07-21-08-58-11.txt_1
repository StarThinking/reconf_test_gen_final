reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-155617829-172.17.0.20-1595322206070:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34704,DS-0eeab44f-02d2-4c09-9170-a5567de3ad0a,DISK], DatanodeInfoWithStorage[127.0.0.1:42228,DS-d2588e77-4ba7-4722-9c7e-2d36d0347d23,DISK], DatanodeInfoWithStorage[127.0.0.1:36696,DS-8f1c462e-f827-4be8-8621-4d7ea2547299,DISK], DatanodeInfoWithStorage[127.0.0.1:39882,DS-fd648154-5c63-4990-bc20-a746dd3e336d,DISK], DatanodeInfoWithStorage[127.0.0.1:46114,DS-3fde0469-95ac-4fe0-884d-c11fd96e9945,DISK], DatanodeInfoWithStorage[127.0.0.1:44515,DS-85bf025b-e49f-468e-8745-95b6731bb2b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41093,DS-a0ff8377-cc65-47e6-bf00-3826d555347c,DISK], DatanodeInfoWithStorage[127.0.0.1:39244,DS-dc1a0a1b-4b76-4741-8264-bc0bcdab21bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-155617829-172.17.0.20-1595322206070:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34704,DS-0eeab44f-02d2-4c09-9170-a5567de3ad0a,DISK], DatanodeInfoWithStorage[127.0.0.1:42228,DS-d2588e77-4ba7-4722-9c7e-2d36d0347d23,DISK], DatanodeInfoWithStorage[127.0.0.1:36696,DS-8f1c462e-f827-4be8-8621-4d7ea2547299,DISK], DatanodeInfoWithStorage[127.0.0.1:39882,DS-fd648154-5c63-4990-bc20-a746dd3e336d,DISK], DatanodeInfoWithStorage[127.0.0.1:46114,DS-3fde0469-95ac-4fe0-884d-c11fd96e9945,DISK], DatanodeInfoWithStorage[127.0.0.1:44515,DS-85bf025b-e49f-468e-8745-95b6731bb2b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41093,DS-a0ff8377-cc65-47e6-bf00-3826d555347c,DISK], DatanodeInfoWithStorage[127.0.0.1:39244,DS-dc1a0a1b-4b76-4741-8264-bc0bcdab21bf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-82509078-172.17.0.20-1595322243025:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38094,DS-77a56d97-491c-4c65-851f-9a89daf29d67,DISK], DatanodeInfoWithStorage[127.0.0.1:33774,DS-d61212dc-03fe-4049-a782-ae2d40285a56,DISK], DatanodeInfoWithStorage[127.0.0.1:38814,DS-b464cdd4-26a6-4330-835e-d65990340e17,DISK], DatanodeInfoWithStorage[127.0.0.1:33449,DS-82ed1d99-d027-42b3-9535-3d02269ecfcf,DISK], DatanodeInfoWithStorage[127.0.0.1:36614,DS-dad94385-7880-47ea-8c06-1fbbafecdf88,DISK], DatanodeInfoWithStorage[127.0.0.1:42296,DS-8de9ec7d-9b73-44d1-8806-1a3ec7c5750f,DISK], DatanodeInfoWithStorage[127.0.0.1:46135,DS-61100671-a0a2-454b-b355-5d4a6fe6fb5f,DISK], DatanodeInfoWithStorage[127.0.0.1:33041,DS-16282241-4e1b-4a8f-a66d-2b2a148c5e63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-82509078-172.17.0.20-1595322243025:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38094,DS-77a56d97-491c-4c65-851f-9a89daf29d67,DISK], DatanodeInfoWithStorage[127.0.0.1:33774,DS-d61212dc-03fe-4049-a782-ae2d40285a56,DISK], DatanodeInfoWithStorage[127.0.0.1:38814,DS-b464cdd4-26a6-4330-835e-d65990340e17,DISK], DatanodeInfoWithStorage[127.0.0.1:33449,DS-82ed1d99-d027-42b3-9535-3d02269ecfcf,DISK], DatanodeInfoWithStorage[127.0.0.1:36614,DS-dad94385-7880-47ea-8c06-1fbbafecdf88,DISK], DatanodeInfoWithStorage[127.0.0.1:42296,DS-8de9ec7d-9b73-44d1-8806-1a3ec7c5750f,DISK], DatanodeInfoWithStorage[127.0.0.1:46135,DS-61100671-a0a2-454b-b355-5d4a6fe6fb5f,DISK], DatanodeInfoWithStorage[127.0.0.1:33041,DS-16282241-4e1b-4a8f-a66d-2b2a148c5e63,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-683862719-172.17.0.20-1595322676247:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44191,DS-e2c1f2da-269b-45f6-83ae-517e5d75ef9d,DISK], DatanodeInfoWithStorage[127.0.0.1:45117,DS-250cc3ba-b6c0-4006-8141-a0bc18775eca,DISK], DatanodeInfoWithStorage[127.0.0.1:38112,DS-0c3ad774-eca6-4520-b006-714c22ad09fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37666,DS-c8dd8183-bc83-48b1-9c50-e107526dae53,DISK], DatanodeInfoWithStorage[127.0.0.1:41619,DS-cf1fbcc5-0687-495f-8a57-fc9aca143062,DISK], DatanodeInfoWithStorage[127.0.0.1:39957,DS-4047c2e6-a1d5-40fa-8703-a38515ccee6d,DISK], DatanodeInfoWithStorage[127.0.0.1:36577,DS-036483ae-4726-429c-a807-85fff920437d,DISK], DatanodeInfoWithStorage[127.0.0.1:44023,DS-99275515-ddd1-41d5-aa38-8d578ecd4083,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-683862719-172.17.0.20-1595322676247:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44191,DS-e2c1f2da-269b-45f6-83ae-517e5d75ef9d,DISK], DatanodeInfoWithStorage[127.0.0.1:45117,DS-250cc3ba-b6c0-4006-8141-a0bc18775eca,DISK], DatanodeInfoWithStorage[127.0.0.1:38112,DS-0c3ad774-eca6-4520-b006-714c22ad09fd,DISK], DatanodeInfoWithStorage[127.0.0.1:37666,DS-c8dd8183-bc83-48b1-9c50-e107526dae53,DISK], DatanodeInfoWithStorage[127.0.0.1:41619,DS-cf1fbcc5-0687-495f-8a57-fc9aca143062,DISK], DatanodeInfoWithStorage[127.0.0.1:39957,DS-4047c2e6-a1d5-40fa-8703-a38515ccee6d,DISK], DatanodeInfoWithStorage[127.0.0.1:36577,DS-036483ae-4726-429c-a807-85fff920437d,DISK], DatanodeInfoWithStorage[127.0.0.1:44023,DS-99275515-ddd1-41d5-aa38-8d578ecd4083,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1644791431-172.17.0.20-1595323113799:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41811,DS-ba50f1cb-0528-4703-b927-f82e56587ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:40482,DS-85b87241-4300-47bb-bbc7-4b82e3389fc0,DISK], DatanodeInfoWithStorage[127.0.0.1:40628,DS-1b5939c9-c35a-4739-b20f-1c02db8d82de,DISK], DatanodeInfoWithStorage[127.0.0.1:45416,DS-4c8371f6-1a96-48ad-9227-6af317290acb,DISK], DatanodeInfoWithStorage[127.0.0.1:46736,DS-80e1c6fd-e19b-48a4-815c-df4667c22560,DISK], DatanodeInfoWithStorage[127.0.0.1:38431,DS-484c7424-0fde-4229-a261-927c0bec13fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41160,DS-f26ae860-9deb-4b4d-80c4-59815b3689bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33688,DS-bee03959-e700-41e3-8452-c60a09bc7ac4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1644791431-172.17.0.20-1595323113799:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41811,DS-ba50f1cb-0528-4703-b927-f82e56587ea0,DISK], DatanodeInfoWithStorage[127.0.0.1:40482,DS-85b87241-4300-47bb-bbc7-4b82e3389fc0,DISK], DatanodeInfoWithStorage[127.0.0.1:40628,DS-1b5939c9-c35a-4739-b20f-1c02db8d82de,DISK], DatanodeInfoWithStorage[127.0.0.1:45416,DS-4c8371f6-1a96-48ad-9227-6af317290acb,DISK], DatanodeInfoWithStorage[127.0.0.1:46736,DS-80e1c6fd-e19b-48a4-815c-df4667c22560,DISK], DatanodeInfoWithStorage[127.0.0.1:38431,DS-484c7424-0fde-4229-a261-927c0bec13fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41160,DS-f26ae860-9deb-4b4d-80c4-59815b3689bc,DISK], DatanodeInfoWithStorage[127.0.0.1:33688,DS-bee03959-e700-41e3-8452-c60a09bc7ac4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-25354874-172.17.0.20-1595323263902:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34213,DS-ee4445fb-ccdc-4978-9a14-2a4d51183892,DISK], DatanodeInfoWithStorage[127.0.0.1:43078,DS-448a8f4f-b416-42ad-be65-7720f282272c,DISK], DatanodeInfoWithStorage[127.0.0.1:37079,DS-c877d5d2-57df-4257-b187-6e8b047202bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39819,DS-92f8d0f8-c5f0-457b-ba33-dec44106198b,DISK], DatanodeInfoWithStorage[127.0.0.1:38876,DS-7beefdcc-8dc4-4484-a842-e7eb6e6bc6ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44686,DS-60f34c6b-d8fe-4e0d-90eb-4ce3b035e4dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44045,DS-0e8e91b0-57a0-4c62-b259-e87cd8c6dfff,DISK], DatanodeInfoWithStorage[127.0.0.1:42556,DS-4eda63de-4698-42d9-8665-587584efbcd2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-25354874-172.17.0.20-1595323263902:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34213,DS-ee4445fb-ccdc-4978-9a14-2a4d51183892,DISK], DatanodeInfoWithStorage[127.0.0.1:43078,DS-448a8f4f-b416-42ad-be65-7720f282272c,DISK], DatanodeInfoWithStorage[127.0.0.1:37079,DS-c877d5d2-57df-4257-b187-6e8b047202bc,DISK], DatanodeInfoWithStorage[127.0.0.1:39819,DS-92f8d0f8-c5f0-457b-ba33-dec44106198b,DISK], DatanodeInfoWithStorage[127.0.0.1:38876,DS-7beefdcc-8dc4-4484-a842-e7eb6e6bc6ce,DISK], DatanodeInfoWithStorage[127.0.0.1:44686,DS-60f34c6b-d8fe-4e0d-90eb-4ce3b035e4dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44045,DS-0e8e91b0-57a0-4c62-b259-e87cd8c6dfff,DISK], DatanodeInfoWithStorage[127.0.0.1:42556,DS-4eda63de-4698-42d9-8665-587584efbcd2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-991286414-172.17.0.20-1595323343614:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37150,DS-bdeea369-4d04-4f9b-a9b2-fccac1e9d32f,DISK], DatanodeInfoWithStorage[127.0.0.1:44123,DS-e8331784-b320-47bb-a085-85395821d268,DISK], DatanodeInfoWithStorage[127.0.0.1:33538,DS-ddf74e9f-7283-4eea-a173-f582bd902649,DISK], DatanodeInfoWithStorage[127.0.0.1:45158,DS-5c06e25e-a9a9-4ab0-a48e-4a35221c650d,DISK], DatanodeInfoWithStorage[127.0.0.1:41861,DS-0db063dd-6b07-43e6-885c-16fa538c9ad3,DISK], DatanodeInfoWithStorage[127.0.0.1:36676,DS-0d80fb25-b79b-4ad7-b424-ccce672927a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35635,DS-8096181c-a422-4607-946e-0a16fa9e9ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:35370,DS-56a153c8-1e7c-4ef7-8031-6ddd3b23d185,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-991286414-172.17.0.20-1595323343614:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37150,DS-bdeea369-4d04-4f9b-a9b2-fccac1e9d32f,DISK], DatanodeInfoWithStorage[127.0.0.1:44123,DS-e8331784-b320-47bb-a085-85395821d268,DISK], DatanodeInfoWithStorage[127.0.0.1:33538,DS-ddf74e9f-7283-4eea-a173-f582bd902649,DISK], DatanodeInfoWithStorage[127.0.0.1:45158,DS-5c06e25e-a9a9-4ab0-a48e-4a35221c650d,DISK], DatanodeInfoWithStorage[127.0.0.1:41861,DS-0db063dd-6b07-43e6-885c-16fa538c9ad3,DISK], DatanodeInfoWithStorage[127.0.0.1:36676,DS-0d80fb25-b79b-4ad7-b424-ccce672927a7,DISK], DatanodeInfoWithStorage[127.0.0.1:35635,DS-8096181c-a422-4607-946e-0a16fa9e9ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:35370,DS-56a153c8-1e7c-4ef7-8031-6ddd3b23d185,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1182496543-172.17.0.20-1595323481268:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35044,DS-aa778baf-7b0a-4225-9e0b-2a21461c66d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43130,DS-4eec6645-8b9d-4aa4-9077-c09b8e6a3fe6,DISK], DatanodeInfoWithStorage[127.0.0.1:44975,DS-9703d715-6ce9-4e20-978f-ab8ee60b9cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:38549,DS-938fcb42-dbbb-4c5f-bc45-2b0a0bb3571b,DISK], DatanodeInfoWithStorage[127.0.0.1:36079,DS-ce21b024-ee4f-4610-9f14-e5cdff12938a,DISK], DatanodeInfoWithStorage[127.0.0.1:36570,DS-3980767f-3ffd-4f0a-b5a4-518d00d3c96c,DISK], DatanodeInfoWithStorage[127.0.0.1:45025,DS-26b7f0f8-0213-4258-8151-28f6d9ec83ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44050,DS-eacc9e37-c988-4bcb-9cd3-6eaa39231beb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1182496543-172.17.0.20-1595323481268:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35044,DS-aa778baf-7b0a-4225-9e0b-2a21461c66d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43130,DS-4eec6645-8b9d-4aa4-9077-c09b8e6a3fe6,DISK], DatanodeInfoWithStorage[127.0.0.1:44975,DS-9703d715-6ce9-4e20-978f-ab8ee60b9cb2,DISK], DatanodeInfoWithStorage[127.0.0.1:38549,DS-938fcb42-dbbb-4c5f-bc45-2b0a0bb3571b,DISK], DatanodeInfoWithStorage[127.0.0.1:36079,DS-ce21b024-ee4f-4610-9f14-e5cdff12938a,DISK], DatanodeInfoWithStorage[127.0.0.1:36570,DS-3980767f-3ffd-4f0a-b5a4-518d00d3c96c,DISK], DatanodeInfoWithStorage[127.0.0.1:45025,DS-26b7f0f8-0213-4258-8151-28f6d9ec83ae,DISK], DatanodeInfoWithStorage[127.0.0.1:44050,DS-eacc9e37-c988-4bcb-9cd3-6eaa39231beb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-687116579-172.17.0.20-1595324733548:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37631,DS-ddb26013-c89f-4be8-ad48-f8f43a29bf11,DISK], DatanodeInfoWithStorage[127.0.0.1:38123,DS-b447fe81-2b90-454a-9dab-5c24c6f21bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:34289,DS-d5dcfc12-af0f-4aec-9f3c-709d7f4938b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39263,DS-d6ec2514-481c-421a-8865-d67a0bfe4dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:40951,DS-bcf9dbbe-3ebf-4e60-9496-3960ae5bc092,DISK], DatanodeInfoWithStorage[127.0.0.1:35506,DS-03542bc2-6da7-4506-9960-d3a4e5fd804d,DISK], DatanodeInfoWithStorage[127.0.0.1:46617,DS-4ab531a5-d723-4495-9bd8-36960bf7a559,DISK], DatanodeInfoWithStorage[127.0.0.1:38080,DS-73df5138-b836-4072-a964-ecee154eb73f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-687116579-172.17.0.20-1595324733548:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37631,DS-ddb26013-c89f-4be8-ad48-f8f43a29bf11,DISK], DatanodeInfoWithStorage[127.0.0.1:38123,DS-b447fe81-2b90-454a-9dab-5c24c6f21bfd,DISK], DatanodeInfoWithStorage[127.0.0.1:34289,DS-d5dcfc12-af0f-4aec-9f3c-709d7f4938b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39263,DS-d6ec2514-481c-421a-8865-d67a0bfe4dd4,DISK], DatanodeInfoWithStorage[127.0.0.1:40951,DS-bcf9dbbe-3ebf-4e60-9496-3960ae5bc092,DISK], DatanodeInfoWithStorage[127.0.0.1:35506,DS-03542bc2-6da7-4506-9960-d3a4e5fd804d,DISK], DatanodeInfoWithStorage[127.0.0.1:46617,DS-4ab531a5-d723-4495-9bd8-36960bf7a559,DISK], DatanodeInfoWithStorage[127.0.0.1:38080,DS-73df5138-b836-4072-a964-ecee154eb73f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-840846624-172.17.0.20-1595325147482:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34166,DS-66722e56-8354-4ac4-9f41-38e1313cd671,DISK], DatanodeInfoWithStorage[127.0.0.1:44545,DS-df2b2d10-d721-4ab7-ad37-8d8f01d60506,DISK], DatanodeInfoWithStorage[127.0.0.1:45826,DS-eecc22f6-35fa-47f8-9266-3bebc14ebe38,DISK], DatanodeInfoWithStorage[127.0.0.1:42456,DS-e8c2ea17-68d7-4c6c-86c8-1fdde01f0b08,DISK], DatanodeInfoWithStorage[127.0.0.1:33840,DS-778f6342-fbc5-4dc8-81bd-d046c8c1a3df,DISK], DatanodeInfoWithStorage[127.0.0.1:43843,DS-82b982e5-726f-4fd4-987a-b4408d3db864,DISK], DatanodeInfoWithStorage[127.0.0.1:42044,DS-06f4c434-6b6e-4b89-830a-4202026fc211,DISK], DatanodeInfoWithStorage[127.0.0.1:42101,DS-6e90d891-2587-4d3e-8228-32eedddf63af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-840846624-172.17.0.20-1595325147482:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34166,DS-66722e56-8354-4ac4-9f41-38e1313cd671,DISK], DatanodeInfoWithStorage[127.0.0.1:44545,DS-df2b2d10-d721-4ab7-ad37-8d8f01d60506,DISK], DatanodeInfoWithStorage[127.0.0.1:45826,DS-eecc22f6-35fa-47f8-9266-3bebc14ebe38,DISK], DatanodeInfoWithStorage[127.0.0.1:42456,DS-e8c2ea17-68d7-4c6c-86c8-1fdde01f0b08,DISK], DatanodeInfoWithStorage[127.0.0.1:33840,DS-778f6342-fbc5-4dc8-81bd-d046c8c1a3df,DISK], DatanodeInfoWithStorage[127.0.0.1:43843,DS-82b982e5-726f-4fd4-987a-b4408d3db864,DISK], DatanodeInfoWithStorage[127.0.0.1:42044,DS-06f4c434-6b6e-4b89-830a-4202026fc211,DISK], DatanodeInfoWithStorage[127.0.0.1:42101,DS-6e90d891-2587-4d3e-8228-32eedddf63af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1522917999-172.17.0.20-1595325325203:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42428,DS-01ffd369-25cf-4c12-9dec-9441918bc044,DISK], DatanodeInfoWithStorage[127.0.0.1:35160,DS-bbe020c2-8e87-4568-881c-3e352e824f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:39249,DS-bb378f75-d953-404c-938c-b34911161ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:35174,DS-7a53c8a3-2d53-40e3-9513-6312651ede55,DISK], DatanodeInfoWithStorage[127.0.0.1:36285,DS-9c581e09-7ce3-470a-9c3c-e31ca31148c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36041,DS-794f205a-fffd-4776-ab4c-0121b8d0c6d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43119,DS-d2b8b60d-792b-410f-b49a-a9c51b3fc1ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43661,DS-a2630817-c63f-4e62-83a7-4bc5b1573d61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1522917999-172.17.0.20-1595325325203:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42428,DS-01ffd369-25cf-4c12-9dec-9441918bc044,DISK], DatanodeInfoWithStorage[127.0.0.1:35160,DS-bbe020c2-8e87-4568-881c-3e352e824f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:39249,DS-bb378f75-d953-404c-938c-b34911161ca3,DISK], DatanodeInfoWithStorage[127.0.0.1:35174,DS-7a53c8a3-2d53-40e3-9513-6312651ede55,DISK], DatanodeInfoWithStorage[127.0.0.1:36285,DS-9c581e09-7ce3-470a-9c3c-e31ca31148c8,DISK], DatanodeInfoWithStorage[127.0.0.1:36041,DS-794f205a-fffd-4776-ab4c-0121b8d0c6d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43119,DS-d2b8b60d-792b-410f-b49a-a9c51b3fc1ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43661,DS-a2630817-c63f-4e62-83a7-4bc5b1573d61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-109206010-172.17.0.20-1595325390143:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44094,DS-cb396de8-f529-4119-b3c4-618ef7856907,DISK], DatanodeInfoWithStorage[127.0.0.1:46454,DS-c5406455-13a8-4722-ae83-d33a658976b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39475,DS-fb1735da-cea2-4b8c-a9b2-06a27c1708fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37935,DS-19534ebb-0796-4c19-bbc1-edc707320f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:43280,DS-0bbb69e6-0c02-4fc6-915e-ee71c00882de,DISK], DatanodeInfoWithStorage[127.0.0.1:36493,DS-b737799c-ca29-4316-abdf-09c906c07b8c,DISK], DatanodeInfoWithStorage[127.0.0.1:41004,DS-77925c06-eed2-4a3e-abaa-49fb7ce206f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44590,DS-5eaf80aa-41b0-44f2-9cc9-61f318b9f72c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-109206010-172.17.0.20-1595325390143:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44094,DS-cb396de8-f529-4119-b3c4-618ef7856907,DISK], DatanodeInfoWithStorage[127.0.0.1:46454,DS-c5406455-13a8-4722-ae83-d33a658976b3,DISK], DatanodeInfoWithStorage[127.0.0.1:39475,DS-fb1735da-cea2-4b8c-a9b2-06a27c1708fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37935,DS-19534ebb-0796-4c19-bbc1-edc707320f1b,DISK], DatanodeInfoWithStorage[127.0.0.1:43280,DS-0bbb69e6-0c02-4fc6-915e-ee71c00882de,DISK], DatanodeInfoWithStorage[127.0.0.1:36493,DS-b737799c-ca29-4316-abdf-09c906c07b8c,DISK], DatanodeInfoWithStorage[127.0.0.1:41004,DS-77925c06-eed2-4a3e-abaa-49fb7ce206f6,DISK], DatanodeInfoWithStorage[127.0.0.1:44590,DS-5eaf80aa-41b0-44f2-9cc9-61f318b9f72c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-451893784-172.17.0.20-1595325679128:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33155,DS-f2581b87-c76b-48af-b536-3ff2ff1ea4c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43578,DS-aba1bd62-d414-44b7-8a46-85e03c5dda17,DISK], DatanodeInfoWithStorage[127.0.0.1:38394,DS-e4dd41da-90c2-4071-a6b3-75951c670545,DISK], DatanodeInfoWithStorage[127.0.0.1:35020,DS-25c52e56-bda2-4715-a6ef-0f16fa2fa4c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38875,DS-be5497dd-61c0-471a-a9f1-9569ab07b35b,DISK], DatanodeInfoWithStorage[127.0.0.1:40108,DS-e6754622-0c3c-4f47-b10c-0b85e631d6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:36463,DS-5f78d7a1-9b20-4251-9283-83a22ef33c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:36602,DS-1e011ee6-3d1a-44d4-93eb-9052a501729a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-451893784-172.17.0.20-1595325679128:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33155,DS-f2581b87-c76b-48af-b536-3ff2ff1ea4c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43578,DS-aba1bd62-d414-44b7-8a46-85e03c5dda17,DISK], DatanodeInfoWithStorage[127.0.0.1:38394,DS-e4dd41da-90c2-4071-a6b3-75951c670545,DISK], DatanodeInfoWithStorage[127.0.0.1:35020,DS-25c52e56-bda2-4715-a6ef-0f16fa2fa4c5,DISK], DatanodeInfoWithStorage[127.0.0.1:38875,DS-be5497dd-61c0-471a-a9f1-9569ab07b35b,DISK], DatanodeInfoWithStorage[127.0.0.1:40108,DS-e6754622-0c3c-4f47-b10c-0b85e631d6e1,DISK], DatanodeInfoWithStorage[127.0.0.1:36463,DS-5f78d7a1-9b20-4251-9283-83a22ef33c4d,DISK], DatanodeInfoWithStorage[127.0.0.1:36602,DS-1e011ee6-3d1a-44d4-93eb-9052a501729a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-608741559-172.17.0.20-1595325888611:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37853,DS-baf3e539-aad0-49e6-a774-8c1e28b347b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43113,DS-3025cb93-46fb-4f98-8ae7-ec99317e2edc,DISK], DatanodeInfoWithStorage[127.0.0.1:33139,DS-5826daf1-62ab-4f9d-9790-08f85039caa1,DISK], DatanodeInfoWithStorage[127.0.0.1:38280,DS-13e4bbb4-1a23-47c3-a315-bdd012e9cb93,DISK], DatanodeInfoWithStorage[127.0.0.1:44164,DS-c9af5372-e15e-465d-836b-5b8438b6f3f7,DISK], DatanodeInfoWithStorage[127.0.0.1:46167,DS-43d24218-0784-476b-9351-a38d8a5e755f,DISK], DatanodeInfoWithStorage[127.0.0.1:37437,DS-c16abe9a-8999-4982-9d77-620de1176a12,DISK], DatanodeInfoWithStorage[127.0.0.1:41400,DS-5f6d1b17-bf6a-4c0b-80bf-3859fe3449e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-608741559-172.17.0.20-1595325888611:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37853,DS-baf3e539-aad0-49e6-a774-8c1e28b347b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43113,DS-3025cb93-46fb-4f98-8ae7-ec99317e2edc,DISK], DatanodeInfoWithStorage[127.0.0.1:33139,DS-5826daf1-62ab-4f9d-9790-08f85039caa1,DISK], DatanodeInfoWithStorage[127.0.0.1:38280,DS-13e4bbb4-1a23-47c3-a315-bdd012e9cb93,DISK], DatanodeInfoWithStorage[127.0.0.1:44164,DS-c9af5372-e15e-465d-836b-5b8438b6f3f7,DISK], DatanodeInfoWithStorage[127.0.0.1:46167,DS-43d24218-0784-476b-9351-a38d8a5e755f,DISK], DatanodeInfoWithStorage[127.0.0.1:37437,DS-c16abe9a-8999-4982-9d77-620de1176a12,DISK], DatanodeInfoWithStorage[127.0.0.1:41400,DS-5f6d1b17-bf6a-4c0b-80bf-3859fe3449e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-70559708-172.17.0.20-1595325921222:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38408,DS-6d97848d-a88f-4057-8a14-48c09789aacf,DISK], DatanodeInfoWithStorage[127.0.0.1:44142,DS-0489f9dd-9a08-4235-b266-245a36301659,DISK], DatanodeInfoWithStorage[127.0.0.1:41952,DS-fcb678b4-2c48-4496-909d-994979aa67b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44916,DS-acc0fc67-d6f6-48a9-8425-417320574965,DISK], DatanodeInfoWithStorage[127.0.0.1:37612,DS-98cdea8b-8c73-4a95-af5a-010f3697c1b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40033,DS-945976d2-a874-4fcb-bd4d-8c6bc7983040,DISK], DatanodeInfoWithStorage[127.0.0.1:34040,DS-271fdd6f-a430-45c6-b323-2273f6329049,DISK], DatanodeInfoWithStorage[127.0.0.1:44724,DS-62fd860f-bc52-4a72-94c3-88d6464aa34f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-70559708-172.17.0.20-1595325921222:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38408,DS-6d97848d-a88f-4057-8a14-48c09789aacf,DISK], DatanodeInfoWithStorage[127.0.0.1:44142,DS-0489f9dd-9a08-4235-b266-245a36301659,DISK], DatanodeInfoWithStorage[127.0.0.1:41952,DS-fcb678b4-2c48-4496-909d-994979aa67b8,DISK], DatanodeInfoWithStorage[127.0.0.1:44916,DS-acc0fc67-d6f6-48a9-8425-417320574965,DISK], DatanodeInfoWithStorage[127.0.0.1:37612,DS-98cdea8b-8c73-4a95-af5a-010f3697c1b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40033,DS-945976d2-a874-4fcb-bd4d-8c6bc7983040,DISK], DatanodeInfoWithStorage[127.0.0.1:34040,DS-271fdd6f-a430-45c6-b323-2273f6329049,DISK], DatanodeInfoWithStorage[127.0.0.1:44724,DS-62fd860f-bc52-4a72-94c3-88d6464aa34f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-771056171-172.17.0.20-1595326146499:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39236,DS-8cc60154-b8aa-4926-a7a5-31638a7c3ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:39365,DS-552c3e06-f58e-40e3-998c-c4a439e9b8d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38972,DS-c40fbb16-c1cd-4a4d-83b5-9837a1ac8aeb,DISK], DatanodeInfoWithStorage[127.0.0.1:45518,DS-420df369-56c0-4bc7-be14-fc77b958b4c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42998,DS-b3f77a1a-ea0b-4ba8-9bd6-5f5b7b1aac6b,DISK], DatanodeInfoWithStorage[127.0.0.1:40714,DS-1589b7ea-7141-4b63-a03c-913fbab105dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33569,DS-c4434044-c6c1-498e-bc75-d6413f5f56d5,DISK], DatanodeInfoWithStorage[127.0.0.1:32874,DS-d812c8be-d183-449f-878c-49d77eb71102,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-771056171-172.17.0.20-1595326146499:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39236,DS-8cc60154-b8aa-4926-a7a5-31638a7c3ea2,DISK], DatanodeInfoWithStorage[127.0.0.1:39365,DS-552c3e06-f58e-40e3-998c-c4a439e9b8d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38972,DS-c40fbb16-c1cd-4a4d-83b5-9837a1ac8aeb,DISK], DatanodeInfoWithStorage[127.0.0.1:45518,DS-420df369-56c0-4bc7-be14-fc77b958b4c0,DISK], DatanodeInfoWithStorage[127.0.0.1:42998,DS-b3f77a1a-ea0b-4ba8-9bd6-5f5b7b1aac6b,DISK], DatanodeInfoWithStorage[127.0.0.1:40714,DS-1589b7ea-7141-4b63-a03c-913fbab105dc,DISK], DatanodeInfoWithStorage[127.0.0.1:33569,DS-c4434044-c6c1-498e-bc75-d6413f5f56d5,DISK], DatanodeInfoWithStorage[127.0.0.1:32874,DS-d812c8be-d183-449f-878c-49d77eb71102,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-27362386-172.17.0.20-1595326915758:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38630,DS-8879c8c8-3b3f-4578-a0e9-0f011a9c8c88,DISK], DatanodeInfoWithStorage[127.0.0.1:44834,DS-d55cc40d-9438-4fef-a4d8-7ae312066595,DISK], DatanodeInfoWithStorage[127.0.0.1:45650,DS-cc2e0474-46cd-4ff8-98f7-4ed787ac354e,DISK], DatanodeInfoWithStorage[127.0.0.1:38457,DS-c6bf98e1-8ac7-4f1b-94d0-950b533b7638,DISK], DatanodeInfoWithStorage[127.0.0.1:35435,DS-9ad5b86e-2c10-422d-b629-543fdba96038,DISK], DatanodeInfoWithStorage[127.0.0.1:37413,DS-058b8e52-9a44-486a-9ce3-d32b7be2a93b,DISK], DatanodeInfoWithStorage[127.0.0.1:34750,DS-6905af95-396d-4ff4-8ca7-eca6975fe596,DISK], DatanodeInfoWithStorage[127.0.0.1:38703,DS-987315ed-e9eb-42ca-a852-848c14679734,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-27362386-172.17.0.20-1595326915758:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38630,DS-8879c8c8-3b3f-4578-a0e9-0f011a9c8c88,DISK], DatanodeInfoWithStorage[127.0.0.1:44834,DS-d55cc40d-9438-4fef-a4d8-7ae312066595,DISK], DatanodeInfoWithStorage[127.0.0.1:45650,DS-cc2e0474-46cd-4ff8-98f7-4ed787ac354e,DISK], DatanodeInfoWithStorage[127.0.0.1:38457,DS-c6bf98e1-8ac7-4f1b-94d0-950b533b7638,DISK], DatanodeInfoWithStorage[127.0.0.1:35435,DS-9ad5b86e-2c10-422d-b629-543fdba96038,DISK], DatanodeInfoWithStorage[127.0.0.1:37413,DS-058b8e52-9a44-486a-9ce3-d32b7be2a93b,DISK], DatanodeInfoWithStorage[127.0.0.1:34750,DS-6905af95-396d-4ff4-8ca7-eca6975fe596,DISK], DatanodeInfoWithStorage[127.0.0.1:38703,DS-987315ed-e9eb-42ca-a852-848c14679734,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.avoid.write.stale.datanode
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery5
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-237608377-172.17.0.20-1595327188647:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38291,DS-56dbf0f0-d79a-49c7-8113-2cb5c7ed2b89,DISK], DatanodeInfoWithStorage[127.0.0.1:33892,DS-4543f687-1d55-470a-a842-5293b3b0648b,DISK], DatanodeInfoWithStorage[127.0.0.1:33792,DS-7c43b386-3332-4b3f-8e1d-1dbf3b609673,DISK], DatanodeInfoWithStorage[127.0.0.1:41864,DS-95a806bb-0fea-4766-9c8a-59d13011301c,DISK], DatanodeInfoWithStorage[127.0.0.1:41825,DS-998a3186-332e-41b7-bea7-ce2873a6737c,DISK], DatanodeInfoWithStorage[127.0.0.1:37055,DS-b701572f-c718-42bf-b765-966ff4adff2f,DISK], DatanodeInfoWithStorage[127.0.0.1:39141,DS-8680fac5-1d8d-4c96-903c-2e1791d9f47b,DISK], DatanodeInfoWithStorage[127.0.0.1:35660,DS-f30764dc-d913-4693-bddd-10d3f88a7fed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-237608377-172.17.0.20-1595327188647:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38291,DS-56dbf0f0-d79a-49c7-8113-2cb5c7ed2b89,DISK], DatanodeInfoWithStorage[127.0.0.1:33892,DS-4543f687-1d55-470a-a842-5293b3b0648b,DISK], DatanodeInfoWithStorage[127.0.0.1:33792,DS-7c43b386-3332-4b3f-8e1d-1dbf3b609673,DISK], DatanodeInfoWithStorage[127.0.0.1:41864,DS-95a806bb-0fea-4766-9c8a-59d13011301c,DISK], DatanodeInfoWithStorage[127.0.0.1:41825,DS-998a3186-332e-41b7-bea7-ce2873a6737c,DISK], DatanodeInfoWithStorage[127.0.0.1:37055,DS-b701572f-c718-42bf-b765-966ff4adff2f,DISK], DatanodeInfoWithStorage[127.0.0.1:39141,DS-8680fac5-1d8d-4c96-903c-2e1791d9f47b,DISK], DatanodeInfoWithStorage[127.0.0.1:35660,DS-f30764dc-d913-4693-bddd-10d3f88a7fed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery5(TestFileChecksum.java:355)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 9 out of 50
result: false positive !!!
Total execution time in seconds : 5387
