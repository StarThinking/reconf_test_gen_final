reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1297583082-172.17.0.12-1596937449460:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43809,DS-465fa481-fa97-488c-a76f-00a66ce67c4f,DISK], DatanodeInfoWithStorage[127.0.0.1:38245,DS-49230bc5-d761-487f-ba39-6828eb5b3350,DISK], DatanodeInfoWithStorage[127.0.0.1:36393,DS-66bc0c5e-e213-443f-83a7-ca6146110b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:40134,DS-30e66a2c-cfe9-4df6-89f5-430edb2e0017,DISK], DatanodeInfoWithStorage[127.0.0.1:33874,DS-70b74fd7-ae49-42d3-bc46-a1094a9bd7b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44355,DS-26b0e6ce-354c-4350-a5e6-75b2042064f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36515,DS-83ccd99e-2d23-4142-85e1-1e384025003a,DISK], DatanodeInfoWithStorage[127.0.0.1:43797,DS-89aa1f12-e32d-48c7-b0e9-0028c0574049,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1297583082-172.17.0.12-1596937449460:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43809,DS-465fa481-fa97-488c-a76f-00a66ce67c4f,DISK], DatanodeInfoWithStorage[127.0.0.1:38245,DS-49230bc5-d761-487f-ba39-6828eb5b3350,DISK], DatanodeInfoWithStorage[127.0.0.1:36393,DS-66bc0c5e-e213-443f-83a7-ca6146110b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:40134,DS-30e66a2c-cfe9-4df6-89f5-430edb2e0017,DISK], DatanodeInfoWithStorage[127.0.0.1:33874,DS-70b74fd7-ae49-42d3-bc46-a1094a9bd7b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44355,DS-26b0e6ce-354c-4350-a5e6-75b2042064f1,DISK], DatanodeInfoWithStorage[127.0.0.1:36515,DS-83ccd99e-2d23-4142-85e1-1e384025003a,DISK], DatanodeInfoWithStorage[127.0.0.1:43797,DS-89aa1f12-e32d-48c7-b0e9-0028c0574049,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1151780650-172.17.0.12-1596938128383:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37049,DS-b64cebbc-cb9b-417f-bcc0-b6e607e81fa9,DISK], DatanodeInfoWithStorage[127.0.0.1:40502,DS-20c74df7-5fac-4205-af9b-78a1c164a6c3,DISK], DatanodeInfoWithStorage[127.0.0.1:36011,DS-c220948e-0751-4bb8-bdca-9d009eefff48,DISK], DatanodeInfoWithStorage[127.0.0.1:46165,DS-6ac4cb14-b17d-44ef-86cf-748108db7e32,DISK], DatanodeInfoWithStorage[127.0.0.1:41768,DS-79be944e-2d26-4bfe-bae4-276a5d428a19,DISK], DatanodeInfoWithStorage[127.0.0.1:38620,DS-f6a6cb7d-8bfc-4b5d-a202-f93d2a8256f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34957,DS-0080eecc-500b-4236-9d4b-ed50e7f12934,DISK], DatanodeInfoWithStorage[127.0.0.1:45572,DS-14121080-33a6-4c80-96b8-5762807f979e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1151780650-172.17.0.12-1596938128383:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37049,DS-b64cebbc-cb9b-417f-bcc0-b6e607e81fa9,DISK], DatanodeInfoWithStorage[127.0.0.1:40502,DS-20c74df7-5fac-4205-af9b-78a1c164a6c3,DISK], DatanodeInfoWithStorage[127.0.0.1:36011,DS-c220948e-0751-4bb8-bdca-9d009eefff48,DISK], DatanodeInfoWithStorage[127.0.0.1:46165,DS-6ac4cb14-b17d-44ef-86cf-748108db7e32,DISK], DatanodeInfoWithStorage[127.0.0.1:41768,DS-79be944e-2d26-4bfe-bae4-276a5d428a19,DISK], DatanodeInfoWithStorage[127.0.0.1:38620,DS-f6a6cb7d-8bfc-4b5d-a202-f93d2a8256f6,DISK], DatanodeInfoWithStorage[127.0.0.1:34957,DS-0080eecc-500b-4236-9d4b-ed50e7f12934,DISK], DatanodeInfoWithStorage[127.0.0.1:45572,DS-14121080-33a6-4c80-96b8-5762807f979e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1254426933-172.17.0.12-1596938529389:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44217,DS-7f609d27-2a30-47ff-8518-60c816ed0fb8,DISK], DatanodeInfoWithStorage[127.0.0.1:40160,DS-c7276821-bb4f-49ed-8f07-ecfc5e159e54,DISK], DatanodeInfoWithStorage[127.0.0.1:33575,DS-fbe52397-efbe-4950-aafc-77957e80f0fb,DISK], DatanodeInfoWithStorage[127.0.0.1:33764,DS-e6ce5886-48e7-42bd-908c-8032a17ea8cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34306,DS-fadcc690-d64b-4358-925a-3c42c0174e34,DISK], DatanodeInfoWithStorage[127.0.0.1:46245,DS-ae01cb38-bf99-45f0-a75d-9494e73baa4b,DISK], DatanodeInfoWithStorage[127.0.0.1:41292,DS-f21d903e-2225-4e52-871a-f262cf011630,DISK], DatanodeInfoWithStorage[127.0.0.1:36752,DS-535812cd-5a53-406e-af6f-8fa2a234754f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1254426933-172.17.0.12-1596938529389:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44217,DS-7f609d27-2a30-47ff-8518-60c816ed0fb8,DISK], DatanodeInfoWithStorage[127.0.0.1:40160,DS-c7276821-bb4f-49ed-8f07-ecfc5e159e54,DISK], DatanodeInfoWithStorage[127.0.0.1:33575,DS-fbe52397-efbe-4950-aafc-77957e80f0fb,DISK], DatanodeInfoWithStorage[127.0.0.1:33764,DS-e6ce5886-48e7-42bd-908c-8032a17ea8cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34306,DS-fadcc690-d64b-4358-925a-3c42c0174e34,DISK], DatanodeInfoWithStorage[127.0.0.1:46245,DS-ae01cb38-bf99-45f0-a75d-9494e73baa4b,DISK], DatanodeInfoWithStorage[127.0.0.1:41292,DS-f21d903e-2225-4e52-871a-f262cf011630,DISK], DatanodeInfoWithStorage[127.0.0.1:36752,DS-535812cd-5a53-406e-af6f-8fa2a234754f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-713378527-172.17.0.12-1596938984519:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39506,DS-d940f351-87c3-4d3e-a32e-b2fa0f2907ec,DISK], DatanodeInfoWithStorage[127.0.0.1:42127,DS-e4fb5441-d3e5-4271-a67c-2b3e4bdef5a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33677,DS-602f98d0-736a-4bfb-98d3-92f7843b34b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41985,DS-e30d67c7-69cd-4bfd-b951-bcbffa1aeca3,DISK], DatanodeInfoWithStorage[127.0.0.1:45241,DS-9a409e2e-7687-4d67-95f5-ac384a81532b,DISK], DatanodeInfoWithStorage[127.0.0.1:35733,DS-f3bf8466-bf83-4f40-8573-5b4ae06abe82,DISK], DatanodeInfoWithStorage[127.0.0.1:45522,DS-f3e159ec-5286-4dd9-8786-8390f4edbf60,DISK], DatanodeInfoWithStorage[127.0.0.1:34062,DS-3656cdbf-8915-4abe-92f9-515100b5ac9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-713378527-172.17.0.12-1596938984519:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39506,DS-d940f351-87c3-4d3e-a32e-b2fa0f2907ec,DISK], DatanodeInfoWithStorage[127.0.0.1:42127,DS-e4fb5441-d3e5-4271-a67c-2b3e4bdef5a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33677,DS-602f98d0-736a-4bfb-98d3-92f7843b34b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41985,DS-e30d67c7-69cd-4bfd-b951-bcbffa1aeca3,DISK], DatanodeInfoWithStorage[127.0.0.1:45241,DS-9a409e2e-7687-4d67-95f5-ac384a81532b,DISK], DatanodeInfoWithStorage[127.0.0.1:35733,DS-f3bf8466-bf83-4f40-8573-5b4ae06abe82,DISK], DatanodeInfoWithStorage[127.0.0.1:45522,DS-f3e159ec-5286-4dd9-8786-8390f4edbf60,DISK], DatanodeInfoWithStorage[127.0.0.1:34062,DS-3656cdbf-8915-4abe-92f9-515100b5ac9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-700613334-172.17.0.12-1596939347149:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41038,DS-0b992d93-9976-41b6-843d-b9940530deca,DISK], DatanodeInfoWithStorage[127.0.0.1:33549,DS-fe4adf79-47d9-40fb-97b9-47f97eaa74b8,DISK], DatanodeInfoWithStorage[127.0.0.1:36891,DS-72fe9d9a-795f-408e-9b03-102946368420,DISK], DatanodeInfoWithStorage[127.0.0.1:46109,DS-0e047fee-ee7a-4254-bdbb-3ff65c979b1d,DISK], DatanodeInfoWithStorage[127.0.0.1:42634,DS-86ed9d98-6b7f-4f6b-abe4-95f824d231f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43433,DS-72a98196-bdb9-415a-935c-a11a984cf5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:46718,DS-52bf3730-d00d-474a-9514-0c9624dd87a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37226,DS-bf0c0723-8ca1-413e-b5ae-c65239528edc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-700613334-172.17.0.12-1596939347149:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41038,DS-0b992d93-9976-41b6-843d-b9940530deca,DISK], DatanodeInfoWithStorage[127.0.0.1:33549,DS-fe4adf79-47d9-40fb-97b9-47f97eaa74b8,DISK], DatanodeInfoWithStorage[127.0.0.1:36891,DS-72fe9d9a-795f-408e-9b03-102946368420,DISK], DatanodeInfoWithStorage[127.0.0.1:46109,DS-0e047fee-ee7a-4254-bdbb-3ff65c979b1d,DISK], DatanodeInfoWithStorage[127.0.0.1:42634,DS-86ed9d98-6b7f-4f6b-abe4-95f824d231f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43433,DS-72a98196-bdb9-415a-935c-a11a984cf5a6,DISK], DatanodeInfoWithStorage[127.0.0.1:46718,DS-52bf3730-d00d-474a-9514-0c9624dd87a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37226,DS-bf0c0723-8ca1-413e-b5ae-c65239528edc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-725291428-172.17.0.12-1596939382149:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41534,DS-804836c1-71ea-4c89-895b-ed2a60eb7444,DISK], DatanodeInfoWithStorage[127.0.0.1:42609,DS-0dd8d7e7-1025-449e-9964-a689b17f0bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:34699,DS-b9fe83c7-d96a-4da1-976d-15b3136ca2d8,DISK], DatanodeInfoWithStorage[127.0.0.1:34102,DS-6c876047-2aee-41b2-bc0a-bc534746f0ae,DISK], DatanodeInfoWithStorage[127.0.0.1:46782,DS-80534979-97d6-4166-8cad-3c12213dcba1,DISK], DatanodeInfoWithStorage[127.0.0.1:34946,DS-f2f3e500-468d-47af-9656-9fe6acc02a92,DISK], DatanodeInfoWithStorage[127.0.0.1:39958,DS-7d506423-0675-407d-8b3e-3dad8d585b5c,DISK], DatanodeInfoWithStorage[127.0.0.1:36849,DS-3dc6ac0d-cf89-4bd0-8148-6178c9b16a60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-725291428-172.17.0.12-1596939382149:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41534,DS-804836c1-71ea-4c89-895b-ed2a60eb7444,DISK], DatanodeInfoWithStorage[127.0.0.1:42609,DS-0dd8d7e7-1025-449e-9964-a689b17f0bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:34699,DS-b9fe83c7-d96a-4da1-976d-15b3136ca2d8,DISK], DatanodeInfoWithStorage[127.0.0.1:34102,DS-6c876047-2aee-41b2-bc0a-bc534746f0ae,DISK], DatanodeInfoWithStorage[127.0.0.1:46782,DS-80534979-97d6-4166-8cad-3c12213dcba1,DISK], DatanodeInfoWithStorage[127.0.0.1:34946,DS-f2f3e500-468d-47af-9656-9fe6acc02a92,DISK], DatanodeInfoWithStorage[127.0.0.1:39958,DS-7d506423-0675-407d-8b3e-3dad8d585b5c,DISK], DatanodeInfoWithStorage[127.0.0.1:36849,DS-3dc6ac0d-cf89-4bd0-8148-6178c9b16a60,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1766938832-172.17.0.12-1596939585705:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37910,DS-79062bf5-a542-4e92-8447-b94b9b549ab1,DISK], DatanodeInfoWithStorage[127.0.0.1:45133,DS-03a70083-fc07-4323-bf11-6b4494c4687c,DISK], DatanodeInfoWithStorage[127.0.0.1:38608,DS-a54676ef-c63e-45dc-9a2f-503343f58bf4,DISK], DatanodeInfoWithStorage[127.0.0.1:36360,DS-e34f3b12-0c89-471a-a121-bd21469444c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43017,DS-9293642e-1676-465f-9754-416ec3202d49,DISK], DatanodeInfoWithStorage[127.0.0.1:45762,DS-916f29ad-c434-425b-ab77-c058ebf996ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45542,DS-a609d227-5dbd-4f4f-b107-8652dfdcbb67,DISK], DatanodeInfoWithStorage[127.0.0.1:38926,DS-5fd897bd-a6e9-43f0-8e4d-4c2c1f4e18a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1766938832-172.17.0.12-1596939585705:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37910,DS-79062bf5-a542-4e92-8447-b94b9b549ab1,DISK], DatanodeInfoWithStorage[127.0.0.1:45133,DS-03a70083-fc07-4323-bf11-6b4494c4687c,DISK], DatanodeInfoWithStorage[127.0.0.1:38608,DS-a54676ef-c63e-45dc-9a2f-503343f58bf4,DISK], DatanodeInfoWithStorage[127.0.0.1:36360,DS-e34f3b12-0c89-471a-a121-bd21469444c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43017,DS-9293642e-1676-465f-9754-416ec3202d49,DISK], DatanodeInfoWithStorage[127.0.0.1:45762,DS-916f29ad-c434-425b-ab77-c058ebf996ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45542,DS-a609d227-5dbd-4f4f-b107-8652dfdcbb67,DISK], DatanodeInfoWithStorage[127.0.0.1:38926,DS-5fd897bd-a6e9-43f0-8e4d-4c2c1f4e18a3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1815936099-172.17.0.12-1596939723743:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41437,DS-ca6023fb-50f9-4878-8062-f4a3a0422e8e,DISK], DatanodeInfoWithStorage[127.0.0.1:37476,DS-33d7fc58-fbd7-45f5-8ef9-50aaa6a75a78,DISK], DatanodeInfoWithStorage[127.0.0.1:37782,DS-c80878cd-c3c1-49fa-9846-1715ebeb484f,DISK], DatanodeInfoWithStorage[127.0.0.1:37761,DS-ad9e9a9c-655f-4b86-8ae4-9f2f6eb81e70,DISK], DatanodeInfoWithStorage[127.0.0.1:39119,DS-d5fa3d9d-0f20-4ecc-939b-5334db7b27e1,DISK], DatanodeInfoWithStorage[127.0.0.1:36620,DS-e1e7ec69-21f2-4362-857e-b0146451510f,DISK], DatanodeInfoWithStorage[127.0.0.1:44174,DS-304cb453-e626-485f-8811-2436977ce32e,DISK], DatanodeInfoWithStorage[127.0.0.1:43911,DS-8f8975e0-9e16-4169-842d-6c375a4aa383,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1815936099-172.17.0.12-1596939723743:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41437,DS-ca6023fb-50f9-4878-8062-f4a3a0422e8e,DISK], DatanodeInfoWithStorage[127.0.0.1:37476,DS-33d7fc58-fbd7-45f5-8ef9-50aaa6a75a78,DISK], DatanodeInfoWithStorage[127.0.0.1:37782,DS-c80878cd-c3c1-49fa-9846-1715ebeb484f,DISK], DatanodeInfoWithStorage[127.0.0.1:37761,DS-ad9e9a9c-655f-4b86-8ae4-9f2f6eb81e70,DISK], DatanodeInfoWithStorage[127.0.0.1:39119,DS-d5fa3d9d-0f20-4ecc-939b-5334db7b27e1,DISK], DatanodeInfoWithStorage[127.0.0.1:36620,DS-e1e7ec69-21f2-4362-857e-b0146451510f,DISK], DatanodeInfoWithStorage[127.0.0.1:44174,DS-304cb453-e626-485f-8811-2436977ce32e,DISK], DatanodeInfoWithStorage[127.0.0.1:43911,DS-8f8975e0-9e16-4169-842d-6c375a4aa383,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1805270851-172.17.0.12-1596939863534:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45103,DS-eee02b8a-446f-4000-af17-8fcbf691bf37,DISK], DatanodeInfoWithStorage[127.0.0.1:38453,DS-3065ac76-ad4d-4906-b497-52923e3c8191,DISK], DatanodeInfoWithStorage[127.0.0.1:43267,DS-d7eff233-fbdf-47a8-88a6-04b59b3b16a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34142,DS-7fef6b0a-e2d3-45e6-b47d-6ba9fee2b7a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41430,DS-813fd34f-2964-4160-ae6f-2c176551c377,DISK], DatanodeInfoWithStorage[127.0.0.1:42802,DS-d68241b7-ff1a-4a7a-84a8-3c60c2f66b0a,DISK], DatanodeInfoWithStorage[127.0.0.1:33920,DS-c75c426e-2c12-4684-a71e-e3a71812baba,DISK], DatanodeInfoWithStorage[127.0.0.1:32841,DS-7e635a55-2005-42cf-8d73-6c692b592e04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1805270851-172.17.0.12-1596939863534:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45103,DS-eee02b8a-446f-4000-af17-8fcbf691bf37,DISK], DatanodeInfoWithStorage[127.0.0.1:38453,DS-3065ac76-ad4d-4906-b497-52923e3c8191,DISK], DatanodeInfoWithStorage[127.0.0.1:43267,DS-d7eff233-fbdf-47a8-88a6-04b59b3b16a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34142,DS-7fef6b0a-e2d3-45e6-b47d-6ba9fee2b7a3,DISK], DatanodeInfoWithStorage[127.0.0.1:41430,DS-813fd34f-2964-4160-ae6f-2c176551c377,DISK], DatanodeInfoWithStorage[127.0.0.1:42802,DS-d68241b7-ff1a-4a7a-84a8-3c60c2f66b0a,DISK], DatanodeInfoWithStorage[127.0.0.1:33920,DS-c75c426e-2c12-4684-a71e-e3a71812baba,DISK], DatanodeInfoWithStorage[127.0.0.1:32841,DS-7e635a55-2005-42cf-8d73-6c692b592e04,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1242386974-172.17.0.12-1596939927402:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36920,DS-1ff9c09a-9445-4f09-a0ba-1406a6fa4e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:38241,DS-410f04e9-6d57-4ebd-bac0-6e8f40903bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:43663,DS-755f2d36-b92d-4a64-91ed-c43218fd6272,DISK], DatanodeInfoWithStorage[127.0.0.1:35971,DS-20d37fae-aeb8-4159-9d95-5cd04327041e,DISK], DatanodeInfoWithStorage[127.0.0.1:46489,DS-dee3f69c-ad4e-4873-b80a-67e83648d23f,DISK], DatanodeInfoWithStorage[127.0.0.1:44633,DS-9553d989-a32a-4689-a162-2a7907570809,DISK], DatanodeInfoWithStorage[127.0.0.1:33404,DS-5bd8bea8-6497-42df-ae28-3c45687f6e28,DISK], DatanodeInfoWithStorage[127.0.0.1:46666,DS-0c1bf236-054b-48ef-981c-66d6e2783083,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1242386974-172.17.0.12-1596939927402:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36920,DS-1ff9c09a-9445-4f09-a0ba-1406a6fa4e5a,DISK], DatanodeInfoWithStorage[127.0.0.1:38241,DS-410f04e9-6d57-4ebd-bac0-6e8f40903bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:43663,DS-755f2d36-b92d-4a64-91ed-c43218fd6272,DISK], DatanodeInfoWithStorage[127.0.0.1:35971,DS-20d37fae-aeb8-4159-9d95-5cd04327041e,DISK], DatanodeInfoWithStorage[127.0.0.1:46489,DS-dee3f69c-ad4e-4873-b80a-67e83648d23f,DISK], DatanodeInfoWithStorage[127.0.0.1:44633,DS-9553d989-a32a-4689-a162-2a7907570809,DISK], DatanodeInfoWithStorage[127.0.0.1:33404,DS-5bd8bea8-6497-42df-ae28-3c45687f6e28,DISK], DatanodeInfoWithStorage[127.0.0.1:46666,DS-0c1bf236-054b-48ef-981c-66d6e2783083,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-944991747-172.17.0.12-1596940842175:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45355,DS-02441af8-17c8-42d7-8338-145278f8eb30,DISK], DatanodeInfoWithStorage[127.0.0.1:41307,DS-9ddfc827-4fb9-4c88-a4f4-b249a21b574a,DISK], DatanodeInfoWithStorage[127.0.0.1:41180,DS-07c95775-f655-44a6-98e1-23186d7cf217,DISK], DatanodeInfoWithStorage[127.0.0.1:39719,DS-ad503903-6e6d-4d0e-8828-7d15363b494b,DISK], DatanodeInfoWithStorage[127.0.0.1:42735,DS-700567ff-b68f-4a16-8c63-af254c3be4cb,DISK], DatanodeInfoWithStorage[127.0.0.1:44304,DS-2cd2ccda-a345-48cb-81ca-e13e7b6e5656,DISK], DatanodeInfoWithStorage[127.0.0.1:42865,DS-f0b6aaa1-f2a8-42ab-9d09-1d8bb6209902,DISK], DatanodeInfoWithStorage[127.0.0.1:34299,DS-c517cd0c-70f9-43e5-b5a9-413d5b0f48c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-944991747-172.17.0.12-1596940842175:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45355,DS-02441af8-17c8-42d7-8338-145278f8eb30,DISK], DatanodeInfoWithStorage[127.0.0.1:41307,DS-9ddfc827-4fb9-4c88-a4f4-b249a21b574a,DISK], DatanodeInfoWithStorage[127.0.0.1:41180,DS-07c95775-f655-44a6-98e1-23186d7cf217,DISK], DatanodeInfoWithStorage[127.0.0.1:39719,DS-ad503903-6e6d-4d0e-8828-7d15363b494b,DISK], DatanodeInfoWithStorage[127.0.0.1:42735,DS-700567ff-b68f-4a16-8c63-af254c3be4cb,DISK], DatanodeInfoWithStorage[127.0.0.1:44304,DS-2cd2ccda-a345-48cb-81ca-e13e7b6e5656,DISK], DatanodeInfoWithStorage[127.0.0.1:42865,DS-f0b6aaa1-f2a8-42ab-9d09-1d8bb6209902,DISK], DatanodeInfoWithStorage[127.0.0.1:34299,DS-c517cd0c-70f9-43e5-b5a9-413d5b0f48c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1423150739-172.17.0.12-1596941048995:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37761,DS-cb49032a-f4fa-4851-84b2-30ad8ecb2670,DISK], DatanodeInfoWithStorage[127.0.0.1:32815,DS-57e20ace-524d-407c-b0ed-4db1837d612c,DISK], DatanodeInfoWithStorage[127.0.0.1:41786,DS-ab08464b-7689-40db-b839-0876b93c5882,DISK], DatanodeInfoWithStorage[127.0.0.1:37434,DS-9e9546b5-9573-4aad-aa41-bc34b45d0674,DISK], DatanodeInfoWithStorage[127.0.0.1:45694,DS-9c1ec556-ff26-4570-bb47-d55de1fa68b8,DISK], DatanodeInfoWithStorage[127.0.0.1:36792,DS-7c26b9bd-0dae-417b-b4bb-981343ddcdec,DISK], DatanodeInfoWithStorage[127.0.0.1:40205,DS-79d88fb0-1fb1-4420-9e63-66ad2a756fbb,DISK], DatanodeInfoWithStorage[127.0.0.1:43607,DS-ff225679-7203-4f3f-abca-23f7bea1ec4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1423150739-172.17.0.12-1596941048995:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37761,DS-cb49032a-f4fa-4851-84b2-30ad8ecb2670,DISK], DatanodeInfoWithStorage[127.0.0.1:32815,DS-57e20ace-524d-407c-b0ed-4db1837d612c,DISK], DatanodeInfoWithStorage[127.0.0.1:41786,DS-ab08464b-7689-40db-b839-0876b93c5882,DISK], DatanodeInfoWithStorage[127.0.0.1:37434,DS-9e9546b5-9573-4aad-aa41-bc34b45d0674,DISK], DatanodeInfoWithStorage[127.0.0.1:45694,DS-9c1ec556-ff26-4570-bb47-d55de1fa68b8,DISK], DatanodeInfoWithStorage[127.0.0.1:36792,DS-7c26b9bd-0dae-417b-b4bb-981343ddcdec,DISK], DatanodeInfoWithStorage[127.0.0.1:40205,DS-79d88fb0-1fb1-4420-9e63-66ad2a756fbb,DISK], DatanodeInfoWithStorage[127.0.0.1:43607,DS-ff225679-7203-4f3f-abca-23f7bea1ec4a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2113679776-172.17.0.12-1596941119197:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34201,DS-133bd263-1f4f-41c9-90e3-59c49c8209ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42224,DS-09ab7056-4ead-458f-ba7d-a6b4792e8b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:39330,DS-3bad3612-b013-4efa-afa1-b8c135fe9cb1,DISK], DatanodeInfoWithStorage[127.0.0.1:43331,DS-f7c3c9e6-27b1-4064-8a73-203a59936b2a,DISK], DatanodeInfoWithStorage[127.0.0.1:44280,DS-c5dd107f-c571-4238-8a4d-a13cf8e04dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:34058,DS-f105792c-70ce-4e84-8293-bf54704c6bc5,DISK], DatanodeInfoWithStorage[127.0.0.1:46754,DS-35fd38c3-3c16-48b4-923f-cbb0c2fad243,DISK], DatanodeInfoWithStorage[127.0.0.1:44249,DS-852efab4-b77c-469d-9b9c-90ec73de6faf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2113679776-172.17.0.12-1596941119197:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34201,DS-133bd263-1f4f-41c9-90e3-59c49c8209ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42224,DS-09ab7056-4ead-458f-ba7d-a6b4792e8b4d,DISK], DatanodeInfoWithStorage[127.0.0.1:39330,DS-3bad3612-b013-4efa-afa1-b8c135fe9cb1,DISK], DatanodeInfoWithStorage[127.0.0.1:43331,DS-f7c3c9e6-27b1-4064-8a73-203a59936b2a,DISK], DatanodeInfoWithStorage[127.0.0.1:44280,DS-c5dd107f-c571-4238-8a4d-a13cf8e04dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:34058,DS-f105792c-70ce-4e84-8293-bf54704c6bc5,DISK], DatanodeInfoWithStorage[127.0.0.1:46754,DS-35fd38c3-3c16-48b4-923f-cbb0c2fad243,DISK], DatanodeInfoWithStorage[127.0.0.1:44249,DS-852efab4-b77c-469d-9b9c-90ec73de6faf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-571218612-172.17.0.12-1596941403206:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33550,DS-65e18819-cfaf-4b0b-b78b-6a9478f0099e,DISK], DatanodeInfoWithStorage[127.0.0.1:36023,DS-8ba4ff01-27dd-4d38-9bbc-620fb0749b19,DISK], DatanodeInfoWithStorage[127.0.0.1:39475,DS-691793bd-203d-4c48-a12e-d64876ad7b2e,DISK], DatanodeInfoWithStorage[127.0.0.1:36779,DS-372f4d6e-703f-4093-8f2c-cf1f9f089f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:45469,DS-f297502c-656f-4562-9c6b-80067146782a,DISK], DatanodeInfoWithStorage[127.0.0.1:36448,DS-6513ebfd-234d-4e57-89c8-98cb3b10d43f,DISK], DatanodeInfoWithStorage[127.0.0.1:38351,DS-1d22d8ad-f189-4763-a5ac-53338eb480a6,DISK], DatanodeInfoWithStorage[127.0.0.1:41405,DS-56b4a1eb-dc33-4e8a-a847-6e441db6552b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-571218612-172.17.0.12-1596941403206:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33550,DS-65e18819-cfaf-4b0b-b78b-6a9478f0099e,DISK], DatanodeInfoWithStorage[127.0.0.1:36023,DS-8ba4ff01-27dd-4d38-9bbc-620fb0749b19,DISK], DatanodeInfoWithStorage[127.0.0.1:39475,DS-691793bd-203d-4c48-a12e-d64876ad7b2e,DISK], DatanodeInfoWithStorage[127.0.0.1:36779,DS-372f4d6e-703f-4093-8f2c-cf1f9f089f0b,DISK], DatanodeInfoWithStorage[127.0.0.1:45469,DS-f297502c-656f-4562-9c6b-80067146782a,DISK], DatanodeInfoWithStorage[127.0.0.1:36448,DS-6513ebfd-234d-4e57-89c8-98cb3b10d43f,DISK], DatanodeInfoWithStorage[127.0.0.1:38351,DS-1d22d8ad-f189-4763-a5ac-53338eb480a6,DISK], DatanodeInfoWithStorage[127.0.0.1:41405,DS-56b4a1eb-dc33-4e8a-a847-6e441db6552b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-218939283-172.17.0.12-1596941600040:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35530,DS-50ecce83-f1a5-4ee5-aa0e-7eaf5d8fc45a,DISK], DatanodeInfoWithStorage[127.0.0.1:37944,DS-ddb2edf7-dc45-45a5-af66-867d73b9c8b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34219,DS-65d7b2d8-8914-4b64-ac3e-b73f4311e403,DISK], DatanodeInfoWithStorage[127.0.0.1:33596,DS-e6930de8-cdb1-4cf2-98a3-194e683c9d69,DISK], DatanodeInfoWithStorage[127.0.0.1:40597,DS-95ae73d1-fd6f-49d2-9cb6-65b656066623,DISK], DatanodeInfoWithStorage[127.0.0.1:45041,DS-a0c68765-d078-476a-832c-6f79aa63909d,DISK], DatanodeInfoWithStorage[127.0.0.1:40723,DS-64e3f7f5-07df-48f4-a86a-21919de87d17,DISK], DatanodeInfoWithStorage[127.0.0.1:44448,DS-91c240b2-a7ad-4e0b-b805-3f6222815c5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-218939283-172.17.0.12-1596941600040:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35530,DS-50ecce83-f1a5-4ee5-aa0e-7eaf5d8fc45a,DISK], DatanodeInfoWithStorage[127.0.0.1:37944,DS-ddb2edf7-dc45-45a5-af66-867d73b9c8b8,DISK], DatanodeInfoWithStorage[127.0.0.1:34219,DS-65d7b2d8-8914-4b64-ac3e-b73f4311e403,DISK], DatanodeInfoWithStorage[127.0.0.1:33596,DS-e6930de8-cdb1-4cf2-98a3-194e683c9d69,DISK], DatanodeInfoWithStorage[127.0.0.1:40597,DS-95ae73d1-fd6f-49d2-9cb6-65b656066623,DISK], DatanodeInfoWithStorage[127.0.0.1:45041,DS-a0c68765-d078-476a-832c-6f79aa63909d,DISK], DatanodeInfoWithStorage[127.0.0.1:40723,DS-64e3f7f5-07df-48f4-a86a-21919de87d17,DISK], DatanodeInfoWithStorage[127.0.0.1:44448,DS-91c240b2-a7ad-4e0b-b805-3f6222815c5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 13 out of 50
result: false positive !!!
Total execution time in seconds : 5249
