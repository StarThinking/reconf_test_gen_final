reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-846997267-172.17.0.11-1596880966503:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39564,DS-a05d871e-6571-4564-b992-5533438848f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43616,DS-d6ffffb2-8a5b-4d8d-8926-b7b030e6b77b,DISK], DatanodeInfoWithStorage[127.0.0.1:34420,DS-5b3479fd-7eb3-49bc-a2b8-9b0670145a30,DISK], DatanodeInfoWithStorage[127.0.0.1:39574,DS-4c64b35c-3d66-4442-aa96-8ca0001a3389,DISK], DatanodeInfoWithStorage[127.0.0.1:37461,DS-e95ff3d8-05e2-4f1a-bc7d-7a2c245e429b,DISK], DatanodeInfoWithStorage[127.0.0.1:46749,DS-ff467c27-8bd0-4121-90b1-c57d57688e39,DISK], DatanodeInfoWithStorage[127.0.0.1:35585,DS-19dcef58-8c54-41f0-ba54-ef746bbaae47,DISK], DatanodeInfoWithStorage[127.0.0.1:36100,DS-1c1533d0-b04a-4013-9ca9-180cf415439a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-846997267-172.17.0.11-1596880966503:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39564,DS-a05d871e-6571-4564-b992-5533438848f2,DISK], DatanodeInfoWithStorage[127.0.0.1:43616,DS-d6ffffb2-8a5b-4d8d-8926-b7b030e6b77b,DISK], DatanodeInfoWithStorage[127.0.0.1:34420,DS-5b3479fd-7eb3-49bc-a2b8-9b0670145a30,DISK], DatanodeInfoWithStorage[127.0.0.1:39574,DS-4c64b35c-3d66-4442-aa96-8ca0001a3389,DISK], DatanodeInfoWithStorage[127.0.0.1:37461,DS-e95ff3d8-05e2-4f1a-bc7d-7a2c245e429b,DISK], DatanodeInfoWithStorage[127.0.0.1:46749,DS-ff467c27-8bd0-4121-90b1-c57d57688e39,DISK], DatanodeInfoWithStorage[127.0.0.1:35585,DS-19dcef58-8c54-41f0-ba54-ef746bbaae47,DISK], DatanodeInfoWithStorage[127.0.0.1:36100,DS-1c1533d0-b04a-4013-9ca9-180cf415439a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1776983030-172.17.0.11-1596881253970:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40251,DS-71f8bed2-fb4e-4ec0-a528-18b515822ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:37737,DS-4ebed5a9-be98-411d-bc85-096b1946b9d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34224,DS-18bc9308-6833-47ef-bbc2-82638f690984,DISK], DatanodeInfoWithStorage[127.0.0.1:34662,DS-47de64ce-d2e2-42d9-9da4-90d801d023ce,DISK], DatanodeInfoWithStorage[127.0.0.1:39758,DS-55284dce-2423-4cc2-8635-250b42ea6593,DISK], DatanodeInfoWithStorage[127.0.0.1:44971,DS-b342ca0d-3f80-462c-b83e-57b3e09e5b79,DISK], DatanodeInfoWithStorage[127.0.0.1:34967,DS-a2e7ddc7-66bf-4755-8138-6e695a6d4c54,DISK], DatanodeInfoWithStorage[127.0.0.1:40486,DS-95ecb92e-b1a8-465f-81b5-82f4987a7218,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1776983030-172.17.0.11-1596881253970:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40251,DS-71f8bed2-fb4e-4ec0-a528-18b515822ba9,DISK], DatanodeInfoWithStorage[127.0.0.1:37737,DS-4ebed5a9-be98-411d-bc85-096b1946b9d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34224,DS-18bc9308-6833-47ef-bbc2-82638f690984,DISK], DatanodeInfoWithStorage[127.0.0.1:34662,DS-47de64ce-d2e2-42d9-9da4-90d801d023ce,DISK], DatanodeInfoWithStorage[127.0.0.1:39758,DS-55284dce-2423-4cc2-8635-250b42ea6593,DISK], DatanodeInfoWithStorage[127.0.0.1:44971,DS-b342ca0d-3f80-462c-b83e-57b3e09e5b79,DISK], DatanodeInfoWithStorage[127.0.0.1:34967,DS-a2e7ddc7-66bf-4755-8138-6e695a6d4c54,DISK], DatanodeInfoWithStorage[127.0.0.1:40486,DS-95ecb92e-b1a8-465f-81b5-82f4987a7218,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2104493461-172.17.0.11-1596881336446:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38472,DS-06682068-e409-4fc9-8731-ac0bc8e4f7bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44686,DS-38b398a3-ee09-4062-bfce-888708c022b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41040,DS-f6ee20c4-08de-4214-b928-ca398a47594a,DISK], DatanodeInfoWithStorage[127.0.0.1:37247,DS-6aa40a39-baa3-4487-92a6-8fcfe9e90224,DISK], DatanodeInfoWithStorage[127.0.0.1:45123,DS-605239ec-0f3c-4e5b-8609-14f6e429fd55,DISK], DatanodeInfoWithStorage[127.0.0.1:36210,DS-b88a8a71-9834-436e-b8b8-f50d498858f8,DISK], DatanodeInfoWithStorage[127.0.0.1:32905,DS-64d3026e-d884-4fd7-ae75-a1804cfa8376,DISK], DatanodeInfoWithStorage[127.0.0.1:45388,DS-78a21e6b-4a1a-4d03-9666-106841f85c5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2104493461-172.17.0.11-1596881336446:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38472,DS-06682068-e409-4fc9-8731-ac0bc8e4f7bf,DISK], DatanodeInfoWithStorage[127.0.0.1:44686,DS-38b398a3-ee09-4062-bfce-888708c022b7,DISK], DatanodeInfoWithStorage[127.0.0.1:41040,DS-f6ee20c4-08de-4214-b928-ca398a47594a,DISK], DatanodeInfoWithStorage[127.0.0.1:37247,DS-6aa40a39-baa3-4487-92a6-8fcfe9e90224,DISK], DatanodeInfoWithStorage[127.0.0.1:45123,DS-605239ec-0f3c-4e5b-8609-14f6e429fd55,DISK], DatanodeInfoWithStorage[127.0.0.1:36210,DS-b88a8a71-9834-436e-b8b8-f50d498858f8,DISK], DatanodeInfoWithStorage[127.0.0.1:32905,DS-64d3026e-d884-4fd7-ae75-a1804cfa8376,DISK], DatanodeInfoWithStorage[127.0.0.1:45388,DS-78a21e6b-4a1a-4d03-9666-106841f85c5e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1314059146-172.17.0.11-1596881629254:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43780,DS-4a79ccea-3886-417d-a5fa-f658373e2eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:35296,DS-9496d560-55f2-4420-bbd2-c9080aae6354,DISK], DatanodeInfoWithStorage[127.0.0.1:36932,DS-a5b0ce01-816b-4d77-8bdb-a9b2df3c1fc9,DISK], DatanodeInfoWithStorage[127.0.0.1:41721,DS-b5e1b636-2eff-47d8-9a71-aa30606f0e26,DISK], DatanodeInfoWithStorage[127.0.0.1:45197,DS-53638fc2-9cf4-4c9d-aaed-a3831af8d033,DISK], DatanodeInfoWithStorage[127.0.0.1:35646,DS-499342db-65fc-41ab-b5f6-c6609ef83f4e,DISK], DatanodeInfoWithStorage[127.0.0.1:45066,DS-1b6c966c-f25c-4804-affe-3611d0970677,DISK], DatanodeInfoWithStorage[127.0.0.1:46834,DS-0f62d93b-66b7-4b15-b9d0-05c26bd2d268,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1314059146-172.17.0.11-1596881629254:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43780,DS-4a79ccea-3886-417d-a5fa-f658373e2eb1,DISK], DatanodeInfoWithStorage[127.0.0.1:35296,DS-9496d560-55f2-4420-bbd2-c9080aae6354,DISK], DatanodeInfoWithStorage[127.0.0.1:36932,DS-a5b0ce01-816b-4d77-8bdb-a9b2df3c1fc9,DISK], DatanodeInfoWithStorage[127.0.0.1:41721,DS-b5e1b636-2eff-47d8-9a71-aa30606f0e26,DISK], DatanodeInfoWithStorage[127.0.0.1:45197,DS-53638fc2-9cf4-4c9d-aaed-a3831af8d033,DISK], DatanodeInfoWithStorage[127.0.0.1:35646,DS-499342db-65fc-41ab-b5f6-c6609ef83f4e,DISK], DatanodeInfoWithStorage[127.0.0.1:45066,DS-1b6c966c-f25c-4804-affe-3611d0970677,DISK], DatanodeInfoWithStorage[127.0.0.1:46834,DS-0f62d93b-66b7-4b15-b9d0-05c26bd2d268,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1298403321-172.17.0.11-1596881980429:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44329,DS-f4b6380d-599a-4a50-89fe-a953da4f12e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40968,DS-bc3a6cdd-ee56-439b-b56a-43d8b2577014,DISK], DatanodeInfoWithStorage[127.0.0.1:34927,DS-e3a6d192-6dfd-4ae5-bf02-4ac7201d50bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36777,DS-538cc442-78d6-4e0e-b2d8-72bf70cbad3d,DISK], DatanodeInfoWithStorage[127.0.0.1:37237,DS-38a8a8bd-b696-49a2-9456-25e3deb843f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36939,DS-e0fb8500-a318-41eb-9f34-8fc2c143f883,DISK], DatanodeInfoWithStorage[127.0.0.1:32769,DS-3c6ba155-740b-49bb-b68c-bcaed23cfd90,DISK], DatanodeInfoWithStorage[127.0.0.1:37693,DS-8149694d-9b53-4db4-9c7e-0721adbeafa9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1298403321-172.17.0.11-1596881980429:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44329,DS-f4b6380d-599a-4a50-89fe-a953da4f12e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40968,DS-bc3a6cdd-ee56-439b-b56a-43d8b2577014,DISK], DatanodeInfoWithStorage[127.0.0.1:34927,DS-e3a6d192-6dfd-4ae5-bf02-4ac7201d50bb,DISK], DatanodeInfoWithStorage[127.0.0.1:36777,DS-538cc442-78d6-4e0e-b2d8-72bf70cbad3d,DISK], DatanodeInfoWithStorage[127.0.0.1:37237,DS-38a8a8bd-b696-49a2-9456-25e3deb843f8,DISK], DatanodeInfoWithStorage[127.0.0.1:36939,DS-e0fb8500-a318-41eb-9f34-8fc2c143f883,DISK], DatanodeInfoWithStorage[127.0.0.1:32769,DS-3c6ba155-740b-49bb-b68c-bcaed23cfd90,DISK], DatanodeInfoWithStorage[127.0.0.1:37693,DS-8149694d-9b53-4db4-9c7e-0721adbeafa9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1165668804-172.17.0.11-1596882205779:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43372,DS-677c722f-24f4-4686-9b0e-009bc9bfa4c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36607,DS-84fe65b0-9699-4c7d-91be-ab7a45a75246,DISK], DatanodeInfoWithStorage[127.0.0.1:40857,DS-f1c7f44a-a359-4ea6-a399-c55bb6e6bd24,DISK], DatanodeInfoWithStorage[127.0.0.1:35273,DS-d3564660-d227-40e0-8fb6-f5989ff4a6bd,DISK], DatanodeInfoWithStorage[127.0.0.1:46621,DS-7961319d-d85c-4422-83aa-976a2722349a,DISK], DatanodeInfoWithStorage[127.0.0.1:39206,DS-26433e38-5791-4ad9-bf45-f6210d533f07,DISK], DatanodeInfoWithStorage[127.0.0.1:42362,DS-354d2603-b9a0-43f1-9c98-a12ad979b208,DISK], DatanodeInfoWithStorage[127.0.0.1:46179,DS-32d146f6-2b63-470c-91af-7e9596ee6e86,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1165668804-172.17.0.11-1596882205779:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43372,DS-677c722f-24f4-4686-9b0e-009bc9bfa4c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36607,DS-84fe65b0-9699-4c7d-91be-ab7a45a75246,DISK], DatanodeInfoWithStorage[127.0.0.1:40857,DS-f1c7f44a-a359-4ea6-a399-c55bb6e6bd24,DISK], DatanodeInfoWithStorage[127.0.0.1:35273,DS-d3564660-d227-40e0-8fb6-f5989ff4a6bd,DISK], DatanodeInfoWithStorage[127.0.0.1:46621,DS-7961319d-d85c-4422-83aa-976a2722349a,DISK], DatanodeInfoWithStorage[127.0.0.1:39206,DS-26433e38-5791-4ad9-bf45-f6210d533f07,DISK], DatanodeInfoWithStorage[127.0.0.1:42362,DS-354d2603-b9a0-43f1-9c98-a12ad979b208,DISK], DatanodeInfoWithStorage[127.0.0.1:46179,DS-32d146f6-2b63-470c-91af-7e9596ee6e86,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1993742573-172.17.0.11-1596882298902:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46058,DS-ec759436-8d0f-4f6d-b1de-6ff9ff9fe0a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45557,DS-4ddb3d0f-20ca-45c3-b322-434889c7ebac,DISK], DatanodeInfoWithStorage[127.0.0.1:36189,DS-6711c033-9d8a-401b-b9f3-f8bafd4904a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35053,DS-d0f863ff-683c-449f-8235-0a31371600f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46552,DS-ce4e6fb6-7729-48ad-b858-99ee4c28db55,DISK], DatanodeInfoWithStorage[127.0.0.1:45200,DS-dbbbd038-a7a1-426c-bd3d-4e70358aae88,DISK], DatanodeInfoWithStorage[127.0.0.1:35173,DS-823e75c4-8823-4236-affb-56b664481ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:39830,DS-0b3c0065-24bc-4b12-ac5b-9ed935393fef,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1993742573-172.17.0.11-1596882298902:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46058,DS-ec759436-8d0f-4f6d-b1de-6ff9ff9fe0a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45557,DS-4ddb3d0f-20ca-45c3-b322-434889c7ebac,DISK], DatanodeInfoWithStorage[127.0.0.1:36189,DS-6711c033-9d8a-401b-b9f3-f8bafd4904a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35053,DS-d0f863ff-683c-449f-8235-0a31371600f4,DISK], DatanodeInfoWithStorage[127.0.0.1:46552,DS-ce4e6fb6-7729-48ad-b858-99ee4c28db55,DISK], DatanodeInfoWithStorage[127.0.0.1:45200,DS-dbbbd038-a7a1-426c-bd3d-4e70358aae88,DISK], DatanodeInfoWithStorage[127.0.0.1:35173,DS-823e75c4-8823-4236-affb-56b664481ef6,DISK], DatanodeInfoWithStorage[127.0.0.1:39830,DS-0b3c0065-24bc-4b12-ac5b-9ed935393fef,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-735606247-172.17.0.11-1596882456643:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41732,DS-e1639598-527f-47ca-a722-dac901cd0b8b,DISK], DatanodeInfoWithStorage[127.0.0.1:45720,DS-7db40b12-e960-4bce-b076-0a0e58a032f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46750,DS-8d729683-1ab6-426c-98d7-5b4d86dcb09b,DISK], DatanodeInfoWithStorage[127.0.0.1:42404,DS-a614c261-857a-4407-a1fa-3590b9ae9c83,DISK], DatanodeInfoWithStorage[127.0.0.1:34242,DS-3e6fd1e8-e4f6-4851-ac0d-2594f4e80653,DISK], DatanodeInfoWithStorage[127.0.0.1:42783,DS-ffae8c4a-6679-42e6-a127-fe97eaca288c,DISK], DatanodeInfoWithStorage[127.0.0.1:45982,DS-c1596e2a-cc61-4510-87a4-8994d6744982,DISK], DatanodeInfoWithStorage[127.0.0.1:44981,DS-44742af6-a374-44e1-a62a-bc519bf6d3ba,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-735606247-172.17.0.11-1596882456643:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41732,DS-e1639598-527f-47ca-a722-dac901cd0b8b,DISK], DatanodeInfoWithStorage[127.0.0.1:45720,DS-7db40b12-e960-4bce-b076-0a0e58a032f8,DISK], DatanodeInfoWithStorage[127.0.0.1:46750,DS-8d729683-1ab6-426c-98d7-5b4d86dcb09b,DISK], DatanodeInfoWithStorage[127.0.0.1:42404,DS-a614c261-857a-4407-a1fa-3590b9ae9c83,DISK], DatanodeInfoWithStorage[127.0.0.1:34242,DS-3e6fd1e8-e4f6-4851-ac0d-2594f4e80653,DISK], DatanodeInfoWithStorage[127.0.0.1:42783,DS-ffae8c4a-6679-42e6-a127-fe97eaca288c,DISK], DatanodeInfoWithStorage[127.0.0.1:45982,DS-c1596e2a-cc61-4510-87a4-8994d6744982,DISK], DatanodeInfoWithStorage[127.0.0.1:44981,DS-44742af6-a374-44e1-a62a-bc519bf6d3ba,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1751006598-172.17.0.11-1596882677187:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43715,DS-41d72166-f556-4fc7-bb48-2abc93b3fdc8,DISK], DatanodeInfoWithStorage[127.0.0.1:44449,DS-59456f47-a8d1-474d-8dd2-6c18834c824e,DISK], DatanodeInfoWithStorage[127.0.0.1:34034,DS-cc216a79-48fc-478d-9596-3f7715bf1262,DISK], DatanodeInfoWithStorage[127.0.0.1:41200,DS-6719b32a-600f-4371-b6d3-9fca10ec5ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:45524,DS-7d6e9b3f-687c-4cd2-b671-1ca4aac77058,DISK], DatanodeInfoWithStorage[127.0.0.1:40868,DS-17cb33d2-87bf-45ad-81f4-b6d07a13dd1b,DISK], DatanodeInfoWithStorage[127.0.0.1:43827,DS-b0a3cc93-c329-4d1c-b354-893561ba10b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41058,DS-e06cddba-9463-4f23-93ea-2a1b02c75c2e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1751006598-172.17.0.11-1596882677187:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43715,DS-41d72166-f556-4fc7-bb48-2abc93b3fdc8,DISK], DatanodeInfoWithStorage[127.0.0.1:44449,DS-59456f47-a8d1-474d-8dd2-6c18834c824e,DISK], DatanodeInfoWithStorage[127.0.0.1:34034,DS-cc216a79-48fc-478d-9596-3f7715bf1262,DISK], DatanodeInfoWithStorage[127.0.0.1:41200,DS-6719b32a-600f-4371-b6d3-9fca10ec5ffc,DISK], DatanodeInfoWithStorage[127.0.0.1:45524,DS-7d6e9b3f-687c-4cd2-b671-1ca4aac77058,DISK], DatanodeInfoWithStorage[127.0.0.1:40868,DS-17cb33d2-87bf-45ad-81f4-b6d07a13dd1b,DISK], DatanodeInfoWithStorage[127.0.0.1:43827,DS-b0a3cc93-c329-4d1c-b354-893561ba10b2,DISK], DatanodeInfoWithStorage[127.0.0.1:41058,DS-e06cddba-9463-4f23-93ea-2a1b02c75c2e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1992518910-172.17.0.11-1596882756183:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36075,DS-5c2d8aa6-456e-429f-ad75-088ebed48033,DISK], DatanodeInfoWithStorage[127.0.0.1:44533,DS-b638c23b-2c72-415a-8e23-87c604a46868,DISK], DatanodeInfoWithStorage[127.0.0.1:35623,DS-8f624d20-2848-44b4-9568-23753f5ae3bf,DISK], DatanodeInfoWithStorage[127.0.0.1:45148,DS-359cd99d-deb3-46d6-a32c-f7451bf0a417,DISK], DatanodeInfoWithStorage[127.0.0.1:39117,DS-bdcf7255-afc8-4df1-8356-87628ce505a5,DISK], DatanodeInfoWithStorage[127.0.0.1:45347,DS-68b0be03-8c50-4ce4-b98f-66eea8f0b403,DISK], DatanodeInfoWithStorage[127.0.0.1:33914,DS-6a40554a-7e9e-4327-863d-08552d5b0a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:37854,DS-174e4984-030d-4e01-a5b0-bdb60fda2f2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1992518910-172.17.0.11-1596882756183:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36075,DS-5c2d8aa6-456e-429f-ad75-088ebed48033,DISK], DatanodeInfoWithStorage[127.0.0.1:44533,DS-b638c23b-2c72-415a-8e23-87c604a46868,DISK], DatanodeInfoWithStorage[127.0.0.1:35623,DS-8f624d20-2848-44b4-9568-23753f5ae3bf,DISK], DatanodeInfoWithStorage[127.0.0.1:45148,DS-359cd99d-deb3-46d6-a32c-f7451bf0a417,DISK], DatanodeInfoWithStorage[127.0.0.1:39117,DS-bdcf7255-afc8-4df1-8356-87628ce505a5,DISK], DatanodeInfoWithStorage[127.0.0.1:45347,DS-68b0be03-8c50-4ce4-b98f-66eea8f0b403,DISK], DatanodeInfoWithStorage[127.0.0.1:33914,DS-6a40554a-7e9e-4327-863d-08552d5b0a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:37854,DS-174e4984-030d-4e01-a5b0-bdb60fda2f2e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1786139278-172.17.0.11-1596883013857:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38060,DS-4390ad07-e820-4ca1-a437-ee4d68d87547,DISK], DatanodeInfoWithStorage[127.0.0.1:33632,DS-9d7e8f49-0ea2-4a5d-aca1-9a484306a63f,DISK], DatanodeInfoWithStorage[127.0.0.1:45965,DS-fd3b63be-bccf-4ce3-ad48-5c10606b35f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43333,DS-560e776b-fccb-43d7-9504-f03b9be05475,DISK], DatanodeInfoWithStorage[127.0.0.1:41252,DS-41ae3c1f-069f-4bc5-ad20-739271d67f4e,DISK], DatanodeInfoWithStorage[127.0.0.1:40875,DS-48006f48-f3ff-4e36-b8b1-634613595a54,DISK], DatanodeInfoWithStorage[127.0.0.1:38887,DS-c359a3e5-a031-4646-88e2-f98a171a185b,DISK], DatanodeInfoWithStorage[127.0.0.1:35190,DS-17bb3821-ede8-4467-9fda-0b6394b9cf32,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1786139278-172.17.0.11-1596883013857:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38060,DS-4390ad07-e820-4ca1-a437-ee4d68d87547,DISK], DatanodeInfoWithStorage[127.0.0.1:33632,DS-9d7e8f49-0ea2-4a5d-aca1-9a484306a63f,DISK], DatanodeInfoWithStorage[127.0.0.1:45965,DS-fd3b63be-bccf-4ce3-ad48-5c10606b35f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43333,DS-560e776b-fccb-43d7-9504-f03b9be05475,DISK], DatanodeInfoWithStorage[127.0.0.1:41252,DS-41ae3c1f-069f-4bc5-ad20-739271d67f4e,DISK], DatanodeInfoWithStorage[127.0.0.1:40875,DS-48006f48-f3ff-4e36-b8b1-634613595a54,DISK], DatanodeInfoWithStorage[127.0.0.1:38887,DS-c359a3e5-a031-4646-88e2-f98a171a185b,DISK], DatanodeInfoWithStorage[127.0.0.1:35190,DS-17bb3821-ede8-4467-9fda-0b6394b9cf32,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1653277442-172.17.0.11-1596883196087:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43958,DS-2d20a942-6ee1-44f4-bfd1-7050e59662c5,DISK], DatanodeInfoWithStorage[127.0.0.1:36714,DS-725e687d-ef4e-4b0e-a88a-e79a9a171287,DISK], DatanodeInfoWithStorage[127.0.0.1:36270,DS-e56d7463-e009-43e7-96ff-f7a28ee1add2,DISK], DatanodeInfoWithStorage[127.0.0.1:34966,DS-75006c99-b4cf-407c-9b8e-c7c939d19811,DISK], DatanodeInfoWithStorage[127.0.0.1:41811,DS-70c93256-b609-42d5-87b9-f2d9ea075e8d,DISK], DatanodeInfoWithStorage[127.0.0.1:33382,DS-8feeb2e0-8eb0-406d-8a6f-a34208b5f8e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41194,DS-d460051d-8804-426e-909e-dd48c70d322f,DISK], DatanodeInfoWithStorage[127.0.0.1:45347,DS-09a7dd8c-849e-4b76-8e9e-c674b207610d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1653277442-172.17.0.11-1596883196087:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43958,DS-2d20a942-6ee1-44f4-bfd1-7050e59662c5,DISK], DatanodeInfoWithStorage[127.0.0.1:36714,DS-725e687d-ef4e-4b0e-a88a-e79a9a171287,DISK], DatanodeInfoWithStorage[127.0.0.1:36270,DS-e56d7463-e009-43e7-96ff-f7a28ee1add2,DISK], DatanodeInfoWithStorage[127.0.0.1:34966,DS-75006c99-b4cf-407c-9b8e-c7c939d19811,DISK], DatanodeInfoWithStorage[127.0.0.1:41811,DS-70c93256-b609-42d5-87b9-f2d9ea075e8d,DISK], DatanodeInfoWithStorage[127.0.0.1:33382,DS-8feeb2e0-8eb0-406d-8a6f-a34208b5f8e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41194,DS-d460051d-8804-426e-909e-dd48c70d322f,DISK], DatanodeInfoWithStorage[127.0.0.1:45347,DS-09a7dd8c-849e-4b76-8e9e-c674b207610d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-546117763-172.17.0.11-1596883233220:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36418,DS-c7373763-a59a-4944-9309-364fdda120b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35191,DS-1ee0a4d2-1d2a-4b27-a89d-dcf286bd9de8,DISK], DatanodeInfoWithStorage[127.0.0.1:34230,DS-7fd54221-8acf-497e-a77b-8a0f7810a991,DISK], DatanodeInfoWithStorage[127.0.0.1:43908,DS-c7d53926-9dbb-4f22-8844-fc45402a1f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:35879,DS-f22f1585-5707-4d99-8b9e-8ccbd964cecc,DISK], DatanodeInfoWithStorage[127.0.0.1:41174,DS-00fd49cf-580f-45c5-852b-f35c4d2c7f06,DISK], DatanodeInfoWithStorage[127.0.0.1:44740,DS-57c4f22a-3eae-47dc-9232-3631814bd07e,DISK], DatanodeInfoWithStorage[127.0.0.1:44818,DS-3a760003-3eb0-4010-b943-1122cb401cd8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-546117763-172.17.0.11-1596883233220:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36418,DS-c7373763-a59a-4944-9309-364fdda120b9,DISK], DatanodeInfoWithStorage[127.0.0.1:35191,DS-1ee0a4d2-1d2a-4b27-a89d-dcf286bd9de8,DISK], DatanodeInfoWithStorage[127.0.0.1:34230,DS-7fd54221-8acf-497e-a77b-8a0f7810a991,DISK], DatanodeInfoWithStorage[127.0.0.1:43908,DS-c7d53926-9dbb-4f22-8844-fc45402a1f3b,DISK], DatanodeInfoWithStorage[127.0.0.1:35879,DS-f22f1585-5707-4d99-8b9e-8ccbd964cecc,DISK], DatanodeInfoWithStorage[127.0.0.1:41174,DS-00fd49cf-580f-45c5-852b-f35c4d2c7f06,DISK], DatanodeInfoWithStorage[127.0.0.1:44740,DS-57c4f22a-3eae-47dc-9232-3631814bd07e,DISK], DatanodeInfoWithStorage[127.0.0.1:44818,DS-3a760003-3eb0-4010-b943-1122cb401cd8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-889432652-172.17.0.11-1596883716562:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41861,DS-61a9c327-5133-4998-af2a-51efef9ffaad,DISK], DatanodeInfoWithStorage[127.0.0.1:44054,DS-6e6d9ce8-9392-4bca-afda-33bde0abb616,DISK], DatanodeInfoWithStorage[127.0.0.1:42652,DS-25da295b-1353-4db4-ac9e-e9a7d84c85f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39158,DS-2b53e256-a2e8-49db-9100-12f23670e4bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45079,DS-f0f4972e-7199-46f9-8a97-cd53e43fd556,DISK], DatanodeInfoWithStorage[127.0.0.1:38592,DS-acf8d1af-a8a8-474e-8e34-35a3739059d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39935,DS-69f6b3b5-de77-4320-804a-44dfd58869bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41594,DS-004cf353-b884-439a-b987-a819df3a9bb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-889432652-172.17.0.11-1596883716562:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41861,DS-61a9c327-5133-4998-af2a-51efef9ffaad,DISK], DatanodeInfoWithStorage[127.0.0.1:44054,DS-6e6d9ce8-9392-4bca-afda-33bde0abb616,DISK], DatanodeInfoWithStorage[127.0.0.1:42652,DS-25da295b-1353-4db4-ac9e-e9a7d84c85f1,DISK], DatanodeInfoWithStorage[127.0.0.1:39158,DS-2b53e256-a2e8-49db-9100-12f23670e4bc,DISK], DatanodeInfoWithStorage[127.0.0.1:45079,DS-f0f4972e-7199-46f9-8a97-cd53e43fd556,DISK], DatanodeInfoWithStorage[127.0.0.1:38592,DS-acf8d1af-a8a8-474e-8e34-35a3739059d2,DISK], DatanodeInfoWithStorage[127.0.0.1:39935,DS-69f6b3b5-de77-4320-804a-44dfd58869bd,DISK], DatanodeInfoWithStorage[127.0.0.1:41594,DS-004cf353-b884-439a-b987-a819df3a9bb4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1904565888-172.17.0.11-1596884358682:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38691,DS-308432e5-3025-4f88-87d9-c3d112baa7cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39308,DS-ae978a5d-b09f-4893-ad86-b980479df22b,DISK], DatanodeInfoWithStorage[127.0.0.1:45639,DS-59059ff6-f65f-4574-852a-4aa65e43e52a,DISK], DatanodeInfoWithStorage[127.0.0.1:43658,DS-c2249333-aab0-4902-8629-0c16500bdd2e,DISK], DatanodeInfoWithStorage[127.0.0.1:36620,DS-ce56af22-8b88-427a-853a-8aeb5cf1b7e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40408,DS-869fe3a0-cd7e-4444-883d-f91b03b4ff03,DISK], DatanodeInfoWithStorage[127.0.0.1:34790,DS-f67b1e64-dfd1-4db3-951d-7343d5241edd,DISK], DatanodeInfoWithStorage[127.0.0.1:39257,DS-63cc4d32-df33-443a-8840-75ef7983d61d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1904565888-172.17.0.11-1596884358682:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38691,DS-308432e5-3025-4f88-87d9-c3d112baa7cc,DISK], DatanodeInfoWithStorage[127.0.0.1:39308,DS-ae978a5d-b09f-4893-ad86-b980479df22b,DISK], DatanodeInfoWithStorage[127.0.0.1:45639,DS-59059ff6-f65f-4574-852a-4aa65e43e52a,DISK], DatanodeInfoWithStorage[127.0.0.1:43658,DS-c2249333-aab0-4902-8629-0c16500bdd2e,DISK], DatanodeInfoWithStorage[127.0.0.1:36620,DS-ce56af22-8b88-427a-853a-8aeb5cf1b7e5,DISK], DatanodeInfoWithStorage[127.0.0.1:40408,DS-869fe3a0-cd7e-4444-883d-f91b03b4ff03,DISK], DatanodeInfoWithStorage[127.0.0.1:34790,DS-f67b1e64-dfd1-4db3-951d-7343d5241edd,DISK], DatanodeInfoWithStorage[127.0.0.1:39257,DS-63cc4d32-df33-443a-8840-75ef7983d61d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1406066028-172.17.0.11-1596884919250:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33011,DS-dc6f2784-e252-4543-9b0c-15129c33febe,DISK], DatanodeInfoWithStorage[127.0.0.1:35220,DS-2c91db83-0eab-46fe-b624-9dcf4f0802ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40563,DS-ed255a88-a859-40db-be60-a92b172290a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36413,DS-68e49abb-1c12-4075-98b7-c432761271df,DISK], DatanodeInfoWithStorage[127.0.0.1:35714,DS-868d3cde-da96-4e8c-889d-fc5b6e29efe4,DISK], DatanodeInfoWithStorage[127.0.0.1:34764,DS-d8e4ddee-a1a1-4c09-9843-1ab210f4d25d,DISK], DatanodeInfoWithStorage[127.0.0.1:37122,DS-035b7c63-97fa-4d70-8d6e-1f14a2224cad,DISK], DatanodeInfoWithStorage[127.0.0.1:35600,DS-571ae70c-bb1b-468f-a776-f6d11f668f85,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1406066028-172.17.0.11-1596884919250:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33011,DS-dc6f2784-e252-4543-9b0c-15129c33febe,DISK], DatanodeInfoWithStorage[127.0.0.1:35220,DS-2c91db83-0eab-46fe-b624-9dcf4f0802ec,DISK], DatanodeInfoWithStorage[127.0.0.1:40563,DS-ed255a88-a859-40db-be60-a92b172290a9,DISK], DatanodeInfoWithStorage[127.0.0.1:36413,DS-68e49abb-1c12-4075-98b7-c432761271df,DISK], DatanodeInfoWithStorage[127.0.0.1:35714,DS-868d3cde-da96-4e8c-889d-fc5b6e29efe4,DISK], DatanodeInfoWithStorage[127.0.0.1:34764,DS-d8e4ddee-a1a1-4c09-9843-1ab210f4d25d,DISK], DatanodeInfoWithStorage[127.0.0.1:37122,DS-035b7c63-97fa-4d70-8d6e-1f14a2224cad,DISK], DatanodeInfoWithStorage[127.0.0.1:35600,DS-571ae70c-bb1b-468f-a776-f6d11f668f85,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1844789981-172.17.0.11-1596885063222:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37161,DS-10ea439f-8091-41c7-bcfa-50dec459d84e,DISK], DatanodeInfoWithStorage[127.0.0.1:46689,DS-b2651e6b-575d-4a86-b3e8-5962da3e46c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38765,DS-3585b9ba-7365-4e7f-a568-4732d6ea3140,DISK], DatanodeInfoWithStorage[127.0.0.1:42431,DS-338037f8-e421-4740-a79a-d4ae1d685aa8,DISK], DatanodeInfoWithStorage[127.0.0.1:41688,DS-5f254c3f-d09c-433a-b536-7e732603fefe,DISK], DatanodeInfoWithStorage[127.0.0.1:34762,DS-3f183203-c9d3-46d4-9397-8f4f0319479b,DISK], DatanodeInfoWithStorage[127.0.0.1:43825,DS-532ce78d-293c-4f4c-9955-1e9ce80356bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34408,DS-8297c89d-06d9-4acd-8950-d63f4fa03a6f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1844789981-172.17.0.11-1596885063222:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37161,DS-10ea439f-8091-41c7-bcfa-50dec459d84e,DISK], DatanodeInfoWithStorage[127.0.0.1:46689,DS-b2651e6b-575d-4a86-b3e8-5962da3e46c1,DISK], DatanodeInfoWithStorage[127.0.0.1:38765,DS-3585b9ba-7365-4e7f-a568-4732d6ea3140,DISK], DatanodeInfoWithStorage[127.0.0.1:42431,DS-338037f8-e421-4740-a79a-d4ae1d685aa8,DISK], DatanodeInfoWithStorage[127.0.0.1:41688,DS-5f254c3f-d09c-433a-b536-7e732603fefe,DISK], DatanodeInfoWithStorage[127.0.0.1:34762,DS-3f183203-c9d3-46d4-9397-8f4f0319479b,DISK], DatanodeInfoWithStorage[127.0.0.1:43825,DS-532ce78d-293c-4f4c-9955-1e9ce80356bc,DISK], DatanodeInfoWithStorage[127.0.0.1:34408,DS-8297c89d-06d9-4acd-8950-d63f4fa03a6f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-678122053-172.17.0.11-1596885647965:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43682,DS-f6345c00-eb55-4cca-87f7-36e2f04230a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40297,DS-16cf53aa-1734-4dc9-9d40-f82180a9df45,DISK], DatanodeInfoWithStorage[127.0.0.1:45630,DS-14975585-352e-4f8f-945e-8810616873d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42302,DS-008c3359-82af-4c25-9e81-23ef87a5040e,DISK], DatanodeInfoWithStorage[127.0.0.1:42456,DS-c17afff8-57c3-4e14-861b-70a34412f0fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37123,DS-7324b534-1532-479e-8e5b-c888eeed93ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45074,DS-f960a722-af1e-482e-8ff8-042bb6825485,DISK], DatanodeInfoWithStorage[127.0.0.1:46011,DS-6d2040be-4462-457a-99a8-f4f318149837,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-678122053-172.17.0.11-1596885647965:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43682,DS-f6345c00-eb55-4cca-87f7-36e2f04230a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40297,DS-16cf53aa-1734-4dc9-9d40-f82180a9df45,DISK], DatanodeInfoWithStorage[127.0.0.1:45630,DS-14975585-352e-4f8f-945e-8810616873d7,DISK], DatanodeInfoWithStorage[127.0.0.1:42302,DS-008c3359-82af-4c25-9e81-23ef87a5040e,DISK], DatanodeInfoWithStorage[127.0.0.1:42456,DS-c17afff8-57c3-4e14-861b-70a34412f0fe,DISK], DatanodeInfoWithStorage[127.0.0.1:37123,DS-7324b534-1532-479e-8e5b-c888eeed93ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45074,DS-f960a722-af1e-482e-8ff8-042bb6825485,DISK], DatanodeInfoWithStorage[127.0.0.1:46011,DS-6d2040be-4462-457a-99a8-f4f318149837,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-386904597-172.17.0.11-1596885781495:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35190,DS-a17a9f62-31b7-4a93-9d5d-837c692e1572,DISK], DatanodeInfoWithStorage[127.0.0.1:34305,DS-56225eca-9f98-43e4-b9cd-49b8e0a6df96,DISK], DatanodeInfoWithStorage[127.0.0.1:43385,DS-8af7d9cf-1fff-4c4b-9a9e-1dd64c873d30,DISK], DatanodeInfoWithStorage[127.0.0.1:44391,DS-33d8d822-26e3-4ca7-b6bc-459455fec317,DISK], DatanodeInfoWithStorage[127.0.0.1:44548,DS-23cdb594-914e-46aa-b30d-c8231591de77,DISK], DatanodeInfoWithStorage[127.0.0.1:44646,DS-ea77c8ce-db2f-443a-a669-bc77903e55cc,DISK], DatanodeInfoWithStorage[127.0.0.1:41384,DS-c62c3e42-ab6f-40f5-a9a2-93902a2ea47a,DISK], DatanodeInfoWithStorage[127.0.0.1:37492,DS-ff3301d1-2389-4151-947e-2aa7ec38bac9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-386904597-172.17.0.11-1596885781495:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35190,DS-a17a9f62-31b7-4a93-9d5d-837c692e1572,DISK], DatanodeInfoWithStorage[127.0.0.1:34305,DS-56225eca-9f98-43e4-b9cd-49b8e0a6df96,DISK], DatanodeInfoWithStorage[127.0.0.1:43385,DS-8af7d9cf-1fff-4c4b-9a9e-1dd64c873d30,DISK], DatanodeInfoWithStorage[127.0.0.1:44391,DS-33d8d822-26e3-4ca7-b6bc-459455fec317,DISK], DatanodeInfoWithStorage[127.0.0.1:44548,DS-23cdb594-914e-46aa-b30d-c8231591de77,DISK], DatanodeInfoWithStorage[127.0.0.1:44646,DS-ea77c8ce-db2f-443a-a669-bc77903e55cc,DISK], DatanodeInfoWithStorage[127.0.0.1:41384,DS-c62c3e42-ab6f-40f5-a9a2-93902a2ea47a,DISK], DatanodeInfoWithStorage[127.0.0.1:37492,DS-ff3301d1-2389-4151-947e-2aa7ec38bac9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-194343903-172.17.0.11-1596885832455:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45674,DS-e61db211-9727-49b7-b393-be092b8d7163,DISK], DatanodeInfoWithStorage[127.0.0.1:33053,DS-1a2b2344-bc57-47a7-9a2e-fa0fd569b156,DISK], DatanodeInfoWithStorage[127.0.0.1:37088,DS-94ce27d3-c4b9-4404-9a55-d239f80239de,DISK], DatanodeInfoWithStorage[127.0.0.1:38270,DS-beb0eb97-b33c-4482-8687-f5177893bd63,DISK], DatanodeInfoWithStorage[127.0.0.1:43511,DS-a04c5b25-1c51-4ae6-a52b-95e0c1410e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:41691,DS-d2530bb7-c6f6-4a9a-a356-74f65a00a07f,DISK], DatanodeInfoWithStorage[127.0.0.1:46615,DS-47c770b8-7458-4950-b50e-33264d3ef5cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35310,DS-be69554c-f3c5-472a-8bc7-df1ebfa4d8e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-194343903-172.17.0.11-1596885832455:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45674,DS-e61db211-9727-49b7-b393-be092b8d7163,DISK], DatanodeInfoWithStorage[127.0.0.1:33053,DS-1a2b2344-bc57-47a7-9a2e-fa0fd569b156,DISK], DatanodeInfoWithStorage[127.0.0.1:37088,DS-94ce27d3-c4b9-4404-9a55-d239f80239de,DISK], DatanodeInfoWithStorage[127.0.0.1:38270,DS-beb0eb97-b33c-4482-8687-f5177893bd63,DISK], DatanodeInfoWithStorage[127.0.0.1:43511,DS-a04c5b25-1c51-4ae6-a52b-95e0c1410e0a,DISK], DatanodeInfoWithStorage[127.0.0.1:41691,DS-d2530bb7-c6f6-4a9a-a356-74f65a00a07f,DISK], DatanodeInfoWithStorage[127.0.0.1:46615,DS-47c770b8-7458-4950-b50e-33264d3ef5cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35310,DS-be69554c-f3c5-472a-8bc7-df1ebfa4d8e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1407712140-172.17.0.11-1596886024410:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46626,DS-4f522d6d-be79-4970-a995-fb576ffd1477,DISK], DatanodeInfoWithStorage[127.0.0.1:37794,DS-53542a64-f1b8-4d13-90e9-e8c9df11354c,DISK], DatanodeInfoWithStorage[127.0.0.1:39338,DS-a5782a58-3a37-4710-914a-64541f706110,DISK], DatanodeInfoWithStorage[127.0.0.1:34226,DS-f0ca456c-8a72-4480-8096-f28ddad3bdf0,DISK], DatanodeInfoWithStorage[127.0.0.1:35213,DS-7040fe7c-e85c-4d69-adea-84990a08d5d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44294,DS-0366909a-7764-46d6-9a9d-ff10ab79dbc7,DISK], DatanodeInfoWithStorage[127.0.0.1:41334,DS-d193f4c5-38d0-438d-98b2-a5a1a1fadef4,DISK], DatanodeInfoWithStorage[127.0.0.1:33975,DS-a8d8ddca-6a04-4478-9824-339c55825095,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1407712140-172.17.0.11-1596886024410:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46626,DS-4f522d6d-be79-4970-a995-fb576ffd1477,DISK], DatanodeInfoWithStorage[127.0.0.1:37794,DS-53542a64-f1b8-4d13-90e9-e8c9df11354c,DISK], DatanodeInfoWithStorage[127.0.0.1:39338,DS-a5782a58-3a37-4710-914a-64541f706110,DISK], DatanodeInfoWithStorage[127.0.0.1:34226,DS-f0ca456c-8a72-4480-8096-f28ddad3bdf0,DISK], DatanodeInfoWithStorage[127.0.0.1:35213,DS-7040fe7c-e85c-4d69-adea-84990a08d5d1,DISK], DatanodeInfoWithStorage[127.0.0.1:44294,DS-0366909a-7764-46d6-9a9d-ff10ab79dbc7,DISK], DatanodeInfoWithStorage[127.0.0.1:41334,DS-d193f4c5-38d0-438d-98b2-a5a1a1fadef4,DISK], DatanodeInfoWithStorage[127.0.0.1:33975,DS-a8d8ddca-6a04-4478-9824-339c55825095,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1794670205-172.17.0.11-1596886485572:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34379,DS-b27745be-7ad1-49f4-975d-79424778cd12,DISK], DatanodeInfoWithStorage[127.0.0.1:46631,DS-e773a349-27cb-41fc-acb2-e40b717626df,DISK], DatanodeInfoWithStorage[127.0.0.1:46442,DS-93c8b042-e8d8-4b34-aa53-8dc9fd5374b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34851,DS-ca43d38d-0b57-4a52-b5b0-9970b329a280,DISK], DatanodeInfoWithStorage[127.0.0.1:35544,DS-2cc76495-040e-48d2-b04a-d18da2eebcac,DISK], DatanodeInfoWithStorage[127.0.0.1:39744,DS-74fd6903-1983-4ca7-9900-6fa515d4c53d,DISK], DatanodeInfoWithStorage[127.0.0.1:44224,DS-142d3dc9-f4e7-484f-9ddd-482520cf43de,DISK], DatanodeInfoWithStorage[127.0.0.1:37092,DS-92d892a4-f3b7-4afe-82a2-d8e20886ee89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1794670205-172.17.0.11-1596886485572:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34379,DS-b27745be-7ad1-49f4-975d-79424778cd12,DISK], DatanodeInfoWithStorage[127.0.0.1:46631,DS-e773a349-27cb-41fc-acb2-e40b717626df,DISK], DatanodeInfoWithStorage[127.0.0.1:46442,DS-93c8b042-e8d8-4b34-aa53-8dc9fd5374b3,DISK], DatanodeInfoWithStorage[127.0.0.1:34851,DS-ca43d38d-0b57-4a52-b5b0-9970b329a280,DISK], DatanodeInfoWithStorage[127.0.0.1:35544,DS-2cc76495-040e-48d2-b04a-d18da2eebcac,DISK], DatanodeInfoWithStorage[127.0.0.1:39744,DS-74fd6903-1983-4ca7-9900-6fa515d4c53d,DISK], DatanodeInfoWithStorage[127.0.0.1:44224,DS-142d3dc9-f4e7-484f-9ddd-482520cf43de,DISK], DatanodeInfoWithStorage[127.0.0.1:37092,DS-92d892a4-f3b7-4afe-82a2-d8e20886ee89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1076371279-172.17.0.11-1596886612029:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42597,DS-36c4ad54-4f9f-4481-a891-de8764e72b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:39637,DS-0e3f64c2-5dd2-4b38-ba37-9cc68b0c9431,DISK], DatanodeInfoWithStorage[127.0.0.1:35622,DS-13ed0d7b-5240-46d6-bdb4-65838de7c4f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37015,DS-f9759e14-f29d-40f0-9e4b-b2e3386545eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45182,DS-942e6194-6e62-4da8-a2b7-7a0a325001de,DISK], DatanodeInfoWithStorage[127.0.0.1:39084,DS-071e4a87-4b64-4cb0-a70b-a0e842724e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:36998,DS-88e2d0ab-6bde-408d-a696-53f78ef6a2bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39029,DS-8679f81b-c069-4e81-9033-c0ff1178f152,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1076371279-172.17.0.11-1596886612029:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42597,DS-36c4ad54-4f9f-4481-a891-de8764e72b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:39637,DS-0e3f64c2-5dd2-4b38-ba37-9cc68b0c9431,DISK], DatanodeInfoWithStorage[127.0.0.1:35622,DS-13ed0d7b-5240-46d6-bdb4-65838de7c4f8,DISK], DatanodeInfoWithStorage[127.0.0.1:37015,DS-f9759e14-f29d-40f0-9e4b-b2e3386545eb,DISK], DatanodeInfoWithStorage[127.0.0.1:45182,DS-942e6194-6e62-4da8-a2b7-7a0a325001de,DISK], DatanodeInfoWithStorage[127.0.0.1:39084,DS-071e4a87-4b64-4cb0-a70b-a0e842724e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:36998,DS-88e2d0ab-6bde-408d-a696-53f78ef6a2bf,DISK], DatanodeInfoWithStorage[127.0.0.1:39029,DS-8679f81b-c069-4e81-9033-c0ff1178f152,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.security.authorization
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-655250381-172.17.0.11-1596887088849:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46025,DS-e5571a7e-6d62-414a-ad1b-ac0698d79868,DISK], DatanodeInfoWithStorage[127.0.0.1:33169,DS-e58bf092-7b03-4780-8c4a-a69025c5c56b,DISK], DatanodeInfoWithStorage[127.0.0.1:38593,DS-74614c83-1c67-4597-ab18-efbbbb918c5c,DISK], DatanodeInfoWithStorage[127.0.0.1:34021,DS-7d62fb26-2c42-4a5b-a8c6-53d3a34666ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36932,DS-0c6a6d29-cec5-4743-aa70-ff771b9fad12,DISK], DatanodeInfoWithStorage[127.0.0.1:39550,DS-11c8a83d-603f-4889-937e-3ad19bbeaa5f,DISK], DatanodeInfoWithStorage[127.0.0.1:45283,DS-f838aaa9-7b1a-4bf8-a3e4-0677ca8c61d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33909,DS-793a3d88-2ac9-4040-b1f5-e2bfa49d5c76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-655250381-172.17.0.11-1596887088849:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46025,DS-e5571a7e-6d62-414a-ad1b-ac0698d79868,DISK], DatanodeInfoWithStorage[127.0.0.1:33169,DS-e58bf092-7b03-4780-8c4a-a69025c5c56b,DISK], DatanodeInfoWithStorage[127.0.0.1:38593,DS-74614c83-1c67-4597-ab18-efbbbb918c5c,DISK], DatanodeInfoWithStorage[127.0.0.1:34021,DS-7d62fb26-2c42-4a5b-a8c6-53d3a34666ad,DISK], DatanodeInfoWithStorage[127.0.0.1:36932,DS-0c6a6d29-cec5-4743-aa70-ff771b9fad12,DISK], DatanodeInfoWithStorage[127.0.0.1:39550,DS-11c8a83d-603f-4889-937e-3ad19bbeaa5f,DISK], DatanodeInfoWithStorage[127.0.0.1:45283,DS-f838aaa9-7b1a-4bf8-a3e4-0677ca8c61d3,DISK], DatanodeInfoWithStorage[127.0.0.1:33909,DS-793a3d88-2ac9-4040-b1f5-e2bfa49d5c76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 8 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 6693
