reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2018274444-172.17.0.8-1595414860334:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45504,DS-c9e97917-4103-45d3-bbe7-18a778e6af42,DISK], DatanodeInfoWithStorage[127.0.0.1:41160,DS-4341284b-5226-4ddf-82e5-930a9029fcbf,DISK], DatanodeInfoWithStorage[127.0.0.1:45641,DS-18a0df93-ce49-4be5-8615-8acc58ae8658,DISK], DatanodeInfoWithStorage[127.0.0.1:35150,DS-964bb7ea-138f-412f-93cb-84ead22678f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34036,DS-403d5c93-09a0-4ab6-84af-781937099e13,DISK], DatanodeInfoWithStorage[127.0.0.1:36319,DS-c3c3fa58-1129-4037-9e99-2d08722fc281,DISK], DatanodeInfoWithStorage[127.0.0.1:34994,DS-a076f17e-b54f-449a-88d8-d0ee09ab2b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:33403,DS-ba55da23-8bd5-4322-be21-575a4eaff2a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2018274444-172.17.0.8-1595414860334:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45504,DS-c9e97917-4103-45d3-bbe7-18a778e6af42,DISK], DatanodeInfoWithStorage[127.0.0.1:41160,DS-4341284b-5226-4ddf-82e5-930a9029fcbf,DISK], DatanodeInfoWithStorage[127.0.0.1:45641,DS-18a0df93-ce49-4be5-8615-8acc58ae8658,DISK], DatanodeInfoWithStorage[127.0.0.1:35150,DS-964bb7ea-138f-412f-93cb-84ead22678f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34036,DS-403d5c93-09a0-4ab6-84af-781937099e13,DISK], DatanodeInfoWithStorage[127.0.0.1:36319,DS-c3c3fa58-1129-4037-9e99-2d08722fc281,DISK], DatanodeInfoWithStorage[127.0.0.1:34994,DS-a076f17e-b54f-449a-88d8-d0ee09ab2b9d,DISK], DatanodeInfoWithStorage[127.0.0.1:33403,DS-ba55da23-8bd5-4322-be21-575a4eaff2a1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-678652909-172.17.0.8-1595416206410:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41464,DS-c5456239-64c0-47bc-b9e3-abf690907eda,DISK], DatanodeInfoWithStorage[127.0.0.1:36412,DS-e71fc545-ada4-4e33-b961-cf92ef36acd2,DISK], DatanodeInfoWithStorage[127.0.0.1:40376,DS-43c9f08d-6b4c-47bd-a9a3-33ac87793096,DISK], DatanodeInfoWithStorage[127.0.0.1:43987,DS-8bc44cd3-005e-4bb6-b95e-2e8053f219a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38673,DS-5fbc0c7f-9ca5-4c9a-bc74-8e4dcb6c89ed,DISK], DatanodeInfoWithStorage[127.0.0.1:35385,DS-46e6021c-eee1-4175-ac60-e4d1dbe24e29,DISK], DatanodeInfoWithStorage[127.0.0.1:33469,DS-7a58fdce-9532-48ac-9ce1-778db09a567c,DISK], DatanodeInfoWithStorage[127.0.0.1:35706,DS-2c5f1303-8b09-41a1-81de-ecd360b4de69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-678652909-172.17.0.8-1595416206410:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41464,DS-c5456239-64c0-47bc-b9e3-abf690907eda,DISK], DatanodeInfoWithStorage[127.0.0.1:36412,DS-e71fc545-ada4-4e33-b961-cf92ef36acd2,DISK], DatanodeInfoWithStorage[127.0.0.1:40376,DS-43c9f08d-6b4c-47bd-a9a3-33ac87793096,DISK], DatanodeInfoWithStorage[127.0.0.1:43987,DS-8bc44cd3-005e-4bb6-b95e-2e8053f219a8,DISK], DatanodeInfoWithStorage[127.0.0.1:38673,DS-5fbc0c7f-9ca5-4c9a-bc74-8e4dcb6c89ed,DISK], DatanodeInfoWithStorage[127.0.0.1:35385,DS-46e6021c-eee1-4175-ac60-e4d1dbe24e29,DISK], DatanodeInfoWithStorage[127.0.0.1:33469,DS-7a58fdce-9532-48ac-9ce1-778db09a567c,DISK], DatanodeInfoWithStorage[127.0.0.1:35706,DS-2c5f1303-8b09-41a1-81de-ecd360b4de69,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1173789656-172.17.0.8-1595416316960:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34131,DS-7bfc63a0-6408-40ff-b7e1-e7977f81dd1b,DISK], DatanodeInfoWithStorage[127.0.0.1:43818,DS-f2024cc8-283d-41b1-ab09-eba7cfe1eecf,DISK], DatanodeInfoWithStorage[127.0.0.1:36550,DS-a4c702cf-b2e4-4371-ae47-83d262fc7aca,DISK], DatanodeInfoWithStorage[127.0.0.1:46761,DS-546e2a2d-f7b3-40d0-b155-4ee1bff57c66,DISK], DatanodeInfoWithStorage[127.0.0.1:46305,DS-60ccc82e-a59b-48a4-961b-645c4dcc53f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40693,DS-5c2890ba-9242-4dc1-9a3d-f29bab6b1678,DISK], DatanodeInfoWithStorage[127.0.0.1:42905,DS-ac390ed5-f423-4dab-9a36-542a29d15047,DISK], DatanodeInfoWithStorage[127.0.0.1:32860,DS-0da117d2-ba3c-4d73-bd95-5e65051de13e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1173789656-172.17.0.8-1595416316960:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34131,DS-7bfc63a0-6408-40ff-b7e1-e7977f81dd1b,DISK], DatanodeInfoWithStorage[127.0.0.1:43818,DS-f2024cc8-283d-41b1-ab09-eba7cfe1eecf,DISK], DatanodeInfoWithStorage[127.0.0.1:36550,DS-a4c702cf-b2e4-4371-ae47-83d262fc7aca,DISK], DatanodeInfoWithStorage[127.0.0.1:46761,DS-546e2a2d-f7b3-40d0-b155-4ee1bff57c66,DISK], DatanodeInfoWithStorage[127.0.0.1:46305,DS-60ccc82e-a59b-48a4-961b-645c4dcc53f4,DISK], DatanodeInfoWithStorage[127.0.0.1:40693,DS-5c2890ba-9242-4dc1-9a3d-f29bab6b1678,DISK], DatanodeInfoWithStorage[127.0.0.1:42905,DS-ac390ed5-f423-4dab-9a36-542a29d15047,DISK], DatanodeInfoWithStorage[127.0.0.1:32860,DS-0da117d2-ba3c-4d73-bd95-5e65051de13e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1250330581-172.17.0.8-1595417250986:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36323,DS-3d790ee9-1b65-42b7-8b46-6188aac39061,DISK], DatanodeInfoWithStorage[127.0.0.1:35237,DS-2d431671-558c-4dc3-a906-3a32acd60116,DISK], DatanodeInfoWithStorage[127.0.0.1:33064,DS-338ccdcb-8612-441c-810a-f3509302d393,DISK], DatanodeInfoWithStorage[127.0.0.1:45667,DS-a634a359-a994-4dde-b097-dde8380ae1b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41653,DS-f07f08df-863a-46a5-a173-d1afcd16074f,DISK], DatanodeInfoWithStorage[127.0.0.1:44961,DS-4f1a83ee-2e19-420f-afc0-9346efb10444,DISK], DatanodeInfoWithStorage[127.0.0.1:37101,DS-7d11c7f9-4533-426f-9a3b-87c08923619d,DISK], DatanodeInfoWithStorage[127.0.0.1:33721,DS-14f3d35c-7f3a-41de-bc7b-676e17443122,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1250330581-172.17.0.8-1595417250986:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36323,DS-3d790ee9-1b65-42b7-8b46-6188aac39061,DISK], DatanodeInfoWithStorage[127.0.0.1:35237,DS-2d431671-558c-4dc3-a906-3a32acd60116,DISK], DatanodeInfoWithStorage[127.0.0.1:33064,DS-338ccdcb-8612-441c-810a-f3509302d393,DISK], DatanodeInfoWithStorage[127.0.0.1:45667,DS-a634a359-a994-4dde-b097-dde8380ae1b5,DISK], DatanodeInfoWithStorage[127.0.0.1:41653,DS-f07f08df-863a-46a5-a173-d1afcd16074f,DISK], DatanodeInfoWithStorage[127.0.0.1:44961,DS-4f1a83ee-2e19-420f-afc0-9346efb10444,DISK], DatanodeInfoWithStorage[127.0.0.1:37101,DS-7d11c7f9-4533-426f-9a3b-87c08923619d,DISK], DatanodeInfoWithStorage[127.0.0.1:33721,DS-14f3d35c-7f3a-41de-bc7b-676e17443122,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1125617547-172.17.0.8-1595417313348:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35458,DS-e1f52f4e-71ce-480e-8da2-30758a52fc0b,DISK], DatanodeInfoWithStorage[127.0.0.1:40801,DS-9fc3fdc2-871d-4de8-818f-6a0715bed9f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42461,DS-1073018c-c56b-4917-9822-4500da188587,DISK], DatanodeInfoWithStorage[127.0.0.1:34644,DS-cc117431-644f-4fc3-a5e1-eddf06b2ca03,DISK], DatanodeInfoWithStorage[127.0.0.1:33242,DS-f953d454-8277-44be-907d-2bd6ab227e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:38352,DS-ed76ac3b-eb83-4d4f-ae39-ce40255af7a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33922,DS-d15bb8e3-653d-4a79-be14-aed008f426dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44048,DS-7f537d5c-d259-4e2f-b779-2060f786bff8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1125617547-172.17.0.8-1595417313348:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35458,DS-e1f52f4e-71ce-480e-8da2-30758a52fc0b,DISK], DatanodeInfoWithStorage[127.0.0.1:40801,DS-9fc3fdc2-871d-4de8-818f-6a0715bed9f7,DISK], DatanodeInfoWithStorage[127.0.0.1:42461,DS-1073018c-c56b-4917-9822-4500da188587,DISK], DatanodeInfoWithStorage[127.0.0.1:34644,DS-cc117431-644f-4fc3-a5e1-eddf06b2ca03,DISK], DatanodeInfoWithStorage[127.0.0.1:33242,DS-f953d454-8277-44be-907d-2bd6ab227e0e,DISK], DatanodeInfoWithStorage[127.0.0.1:38352,DS-ed76ac3b-eb83-4d4f-ae39-ce40255af7a7,DISK], DatanodeInfoWithStorage[127.0.0.1:33922,DS-d15bb8e3-653d-4a79-be14-aed008f426dc,DISK], DatanodeInfoWithStorage[127.0.0.1:44048,DS-7f537d5c-d259-4e2f-b779-2060f786bff8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-6081729-172.17.0.8-1595418137643:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34330,DS-7789f978-ce3c-441e-bd29-589ba3dd92b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41223,DS-05897bd1-90aa-4ca1-a6d2-9a6f96a8a74e,DISK], DatanodeInfoWithStorage[127.0.0.1:38688,DS-ed9d6e3a-9129-4676-afaf-874d39666943,DISK], DatanodeInfoWithStorage[127.0.0.1:33481,DS-ed1b9133-017e-4352-928f-25c0cac24308,DISK], DatanodeInfoWithStorage[127.0.0.1:46738,DS-9b695304-5972-4591-be5e-8b741891ca2d,DISK], DatanodeInfoWithStorage[127.0.0.1:38394,DS-e74a6256-e1f8-4f61-956e-ed59302fe4f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45912,DS-56d861f7-0462-4903-a3b4-d7e143ea925f,DISK], DatanodeInfoWithStorage[127.0.0.1:33493,DS-22cffffc-f068-43b5-85b2-1effb48cd05d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-6081729-172.17.0.8-1595418137643:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34330,DS-7789f978-ce3c-441e-bd29-589ba3dd92b3,DISK], DatanodeInfoWithStorage[127.0.0.1:41223,DS-05897bd1-90aa-4ca1-a6d2-9a6f96a8a74e,DISK], DatanodeInfoWithStorage[127.0.0.1:38688,DS-ed9d6e3a-9129-4676-afaf-874d39666943,DISK], DatanodeInfoWithStorage[127.0.0.1:33481,DS-ed1b9133-017e-4352-928f-25c0cac24308,DISK], DatanodeInfoWithStorage[127.0.0.1:46738,DS-9b695304-5972-4591-be5e-8b741891ca2d,DISK], DatanodeInfoWithStorage[127.0.0.1:38394,DS-e74a6256-e1f8-4f61-956e-ed59302fe4f4,DISK], DatanodeInfoWithStorage[127.0.0.1:45912,DS-56d861f7-0462-4903-a3b4-d7e143ea925f,DISK], DatanodeInfoWithStorage[127.0.0.1:33493,DS-22cffffc-f068-43b5-85b2-1effb48cd05d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-173459298-172.17.0.8-1595418170918:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36631,DS-3e4b44da-dd28-40ec-ae09-60a169b5339f,DISK], DatanodeInfoWithStorage[127.0.0.1:44158,DS-f44cbe4b-d473-4768-bc65-ee54010d52e4,DISK], DatanodeInfoWithStorage[127.0.0.1:37872,DS-7938f8ad-31c9-4f09-a01d-a8f4ef350002,DISK], DatanodeInfoWithStorage[127.0.0.1:34490,DS-83e2dbf5-c3bf-43b9-8408-8818b3be381f,DISK], DatanodeInfoWithStorage[127.0.0.1:43677,DS-ef3158df-a801-40e0-931f-4d836eab128a,DISK], DatanodeInfoWithStorage[127.0.0.1:39581,DS-7fdae26c-b5c0-4f26-8c4f-71076f9fb55a,DISK], DatanodeInfoWithStorage[127.0.0.1:46570,DS-2d16f8ca-1540-4ce7-8515-2261bd5a942a,DISK], DatanodeInfoWithStorage[127.0.0.1:37540,DS-4de98c7d-5100-4d5f-ad8e-7349857fb420,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-173459298-172.17.0.8-1595418170918:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36631,DS-3e4b44da-dd28-40ec-ae09-60a169b5339f,DISK], DatanodeInfoWithStorage[127.0.0.1:44158,DS-f44cbe4b-d473-4768-bc65-ee54010d52e4,DISK], DatanodeInfoWithStorage[127.0.0.1:37872,DS-7938f8ad-31c9-4f09-a01d-a8f4ef350002,DISK], DatanodeInfoWithStorage[127.0.0.1:34490,DS-83e2dbf5-c3bf-43b9-8408-8818b3be381f,DISK], DatanodeInfoWithStorage[127.0.0.1:43677,DS-ef3158df-a801-40e0-931f-4d836eab128a,DISK], DatanodeInfoWithStorage[127.0.0.1:39581,DS-7fdae26c-b5c0-4f26-8c4f-71076f9fb55a,DISK], DatanodeInfoWithStorage[127.0.0.1:46570,DS-2d16f8ca-1540-4ce7-8515-2261bd5a942a,DISK], DatanodeInfoWithStorage[127.0.0.1:37540,DS-4de98c7d-5100-4d5f-ad8e-7349857fb420,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1580591507-172.17.0.8-1595418354139:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35259,DS-70c97748-4dda-433d-aa6c-a7b2f080f0de,DISK], DatanodeInfoWithStorage[127.0.0.1:39742,DS-308e5941-ce0e-499e-86eb-8e358e944872,DISK], DatanodeInfoWithStorage[127.0.0.1:35241,DS-ee17e8d2-84be-453c-a550-eab01f2cf7b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39696,DS-28c7b6a1-64cb-4a38-822b-a8271aa504c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38337,DS-ef3ad0a2-98d2-4067-88d7-bda82fc906c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36290,DS-649a79e6-e4c0-4833-9024-2513b038ffd6,DISK], DatanodeInfoWithStorage[127.0.0.1:44558,DS-5c198182-573b-4003-873b-02a7c3e8aa8f,DISK], DatanodeInfoWithStorage[127.0.0.1:42943,DS-a91caca3-41a6-4330-8d97-2c919cc24869,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1580591507-172.17.0.8-1595418354139:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35259,DS-70c97748-4dda-433d-aa6c-a7b2f080f0de,DISK], DatanodeInfoWithStorage[127.0.0.1:39742,DS-308e5941-ce0e-499e-86eb-8e358e944872,DISK], DatanodeInfoWithStorage[127.0.0.1:35241,DS-ee17e8d2-84be-453c-a550-eab01f2cf7b9,DISK], DatanodeInfoWithStorage[127.0.0.1:39696,DS-28c7b6a1-64cb-4a38-822b-a8271aa504c7,DISK], DatanodeInfoWithStorage[127.0.0.1:38337,DS-ef3ad0a2-98d2-4067-88d7-bda82fc906c1,DISK], DatanodeInfoWithStorage[127.0.0.1:36290,DS-649a79e6-e4c0-4833-9024-2513b038ffd6,DISK], DatanodeInfoWithStorage[127.0.0.1:44558,DS-5c198182-573b-4003-873b-02a7c3e8aa8f,DISK], DatanodeInfoWithStorage[127.0.0.1:42943,DS-a91caca3-41a6-4330-8d97-2c919cc24869,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.reads
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1864877011-172.17.0.8-1595419171244:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39580,DS-b8856ff9-0b88-4ed7-876b-ad7921e7170e,DISK], DatanodeInfoWithStorage[127.0.0.1:35534,DS-e9eb79bc-a7b6-4835-8de1-47d5a179b0a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36409,DS-2f8aac8c-097b-462d-be49-def45b8b6a15,DISK], DatanodeInfoWithStorage[127.0.0.1:40813,DS-6a167ce0-d37e-487d-ad67-5dada36f11c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43716,DS-5f6081b3-78fb-4242-8f4e-083477931c91,DISK], DatanodeInfoWithStorage[127.0.0.1:35573,DS-dbfd9ccb-033f-4e47-b1b6-882e747b56c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35893,DS-aab138c7-8887-4a07-9fde-f964d31c9808,DISK], DatanodeInfoWithStorage[127.0.0.1:36594,DS-8d755fb8-3139-4f61-b9d5-5824c0903830,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1864877011-172.17.0.8-1595419171244:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39580,DS-b8856ff9-0b88-4ed7-876b-ad7921e7170e,DISK], DatanodeInfoWithStorage[127.0.0.1:35534,DS-e9eb79bc-a7b6-4835-8de1-47d5a179b0a4,DISK], DatanodeInfoWithStorage[127.0.0.1:36409,DS-2f8aac8c-097b-462d-be49-def45b8b6a15,DISK], DatanodeInfoWithStorage[127.0.0.1:40813,DS-6a167ce0-d37e-487d-ad67-5dada36f11c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43716,DS-5f6081b3-78fb-4242-8f4e-083477931c91,DISK], DatanodeInfoWithStorage[127.0.0.1:35573,DS-dbfd9ccb-033f-4e47-b1b6-882e747b56c3,DISK], DatanodeInfoWithStorage[127.0.0.1:35893,DS-aab138c7-8887-4a07-9fde-f964d31c9808,DISK], DatanodeInfoWithStorage[127.0.0.1:36594,DS-8d755fb8-3139-4f61-b9d5-5824c0903830,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 2 out of 50
v1v1v2v2 failed with probability 6 out of 50
result: false positive !!!
Total execution time in seconds : 4961
