reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1847095896-172.17.0.5-1595431891965:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37692,DS-ab8ec6b9-442b-4676-8edc-d586fe701cdb,DISK], DatanodeInfoWithStorage[127.0.0.1:45042,DS-f0a20d88-8f0b-4521-80e9-fa3e2bf6d63f,DISK], DatanodeInfoWithStorage[127.0.0.1:40233,DS-60cdfce6-e908-49dc-8e40-4c6cb7442858,DISK], DatanodeInfoWithStorage[127.0.0.1:35670,DS-401b46ac-1578-4f80-900a-b16669398c02,DISK], DatanodeInfoWithStorage[127.0.0.1:40994,DS-4c492026-e100-4557-b8f3-54ee1797f6cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42611,DS-9ff04614-4bfd-4942-9615-e14b69d6a125,DISK], DatanodeInfoWithStorage[127.0.0.1:33648,DS-0be6946c-1fcf-4e0e-a175-1c7757854e49,DISK], DatanodeInfoWithStorage[127.0.0.1:42920,DS-51ca529d-dfcb-4aa8-a48e-8abc3d4a3053,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1847095896-172.17.0.5-1595431891965:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37692,DS-ab8ec6b9-442b-4676-8edc-d586fe701cdb,DISK], DatanodeInfoWithStorage[127.0.0.1:45042,DS-f0a20d88-8f0b-4521-80e9-fa3e2bf6d63f,DISK], DatanodeInfoWithStorage[127.0.0.1:40233,DS-60cdfce6-e908-49dc-8e40-4c6cb7442858,DISK], DatanodeInfoWithStorage[127.0.0.1:35670,DS-401b46ac-1578-4f80-900a-b16669398c02,DISK], DatanodeInfoWithStorage[127.0.0.1:40994,DS-4c492026-e100-4557-b8f3-54ee1797f6cf,DISK], DatanodeInfoWithStorage[127.0.0.1:42611,DS-9ff04614-4bfd-4942-9615-e14b69d6a125,DISK], DatanodeInfoWithStorage[127.0.0.1:33648,DS-0be6946c-1fcf-4e0e-a175-1c7757854e49,DISK], DatanodeInfoWithStorage[127.0.0.1:42920,DS-51ca529d-dfcb-4aa8-a48e-8abc3d4a3053,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1831194357-172.17.0.5-1595432376701:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39441,DS-cca833a3-f768-420d-a18a-1828c6ba2445,DISK], DatanodeInfoWithStorage[127.0.0.1:43750,DS-94edbc59-19ef-4c9f-80a9-7a154f47c609,DISK], DatanodeInfoWithStorage[127.0.0.1:36723,DS-ce8353b7-a883-42cd-bd82-9eff0db386fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45801,DS-de6812b7-675f-4865-8a5a-e9ff844e1402,DISK], DatanodeInfoWithStorage[127.0.0.1:44123,DS-07fb2e47-d35d-4bdf-8965-23f4a9b7215a,DISK], DatanodeInfoWithStorage[127.0.0.1:40156,DS-24672d17-0af2-4169-b78f-4555ae78295b,DISK], DatanodeInfoWithStorage[127.0.0.1:34357,DS-b9e7af2c-228d-44cc-809a-2cc6f2774ced,DISK], DatanodeInfoWithStorage[127.0.0.1:43280,DS-e4472418-5dcf-4203-9fbb-99a87d4955c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1831194357-172.17.0.5-1595432376701:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39441,DS-cca833a3-f768-420d-a18a-1828c6ba2445,DISK], DatanodeInfoWithStorage[127.0.0.1:43750,DS-94edbc59-19ef-4c9f-80a9-7a154f47c609,DISK], DatanodeInfoWithStorage[127.0.0.1:36723,DS-ce8353b7-a883-42cd-bd82-9eff0db386fa,DISK], DatanodeInfoWithStorage[127.0.0.1:45801,DS-de6812b7-675f-4865-8a5a-e9ff844e1402,DISK], DatanodeInfoWithStorage[127.0.0.1:44123,DS-07fb2e47-d35d-4bdf-8965-23f4a9b7215a,DISK], DatanodeInfoWithStorage[127.0.0.1:40156,DS-24672d17-0af2-4169-b78f-4555ae78295b,DISK], DatanodeInfoWithStorage[127.0.0.1:34357,DS-b9e7af2c-228d-44cc-809a-2cc6f2774ced,DISK], DatanodeInfoWithStorage[127.0.0.1:43280,DS-e4472418-5dcf-4203-9fbb-99a87d4955c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1901247313-172.17.0.5-1595432819884:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35372,DS-e664bf68-cb5a-4c09-bcdf-71b17d421047,DISK], DatanodeInfoWithStorage[127.0.0.1:37977,DS-51311995-5450-4ccc-b0d3-9418da7bb67a,DISK], DatanodeInfoWithStorage[127.0.0.1:37455,DS-5623ad44-d944-4352-ac3e-abc5453ec36d,DISK], DatanodeInfoWithStorage[127.0.0.1:35258,DS-9194cc12-d4a5-4350-b789-572af1c94eb5,DISK], DatanodeInfoWithStorage[127.0.0.1:44773,DS-aa2e81d8-75c5-440b-8d0d-6bffaf770018,DISK], DatanodeInfoWithStorage[127.0.0.1:42096,DS-61018134-bcc9-4768-a5cc-89c3281610a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37020,DS-9fa0436d-7488-4d4b-8de6-48769cf626c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38666,DS-8b1340c8-5574-4baa-9c05-e247557a0fc2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1901247313-172.17.0.5-1595432819884:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35372,DS-e664bf68-cb5a-4c09-bcdf-71b17d421047,DISK], DatanodeInfoWithStorage[127.0.0.1:37977,DS-51311995-5450-4ccc-b0d3-9418da7bb67a,DISK], DatanodeInfoWithStorage[127.0.0.1:37455,DS-5623ad44-d944-4352-ac3e-abc5453ec36d,DISK], DatanodeInfoWithStorage[127.0.0.1:35258,DS-9194cc12-d4a5-4350-b789-572af1c94eb5,DISK], DatanodeInfoWithStorage[127.0.0.1:44773,DS-aa2e81d8-75c5-440b-8d0d-6bffaf770018,DISK], DatanodeInfoWithStorage[127.0.0.1:42096,DS-61018134-bcc9-4768-a5cc-89c3281610a9,DISK], DatanodeInfoWithStorage[127.0.0.1:37020,DS-9fa0436d-7488-4d4b-8de6-48769cf626c2,DISK], DatanodeInfoWithStorage[127.0.0.1:38666,DS-8b1340c8-5574-4baa-9c05-e247557a0fc2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-897273625-172.17.0.5-1595432957606:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44013,DS-1bf62a02-dcdb-4d00-aa09-abe17b48bafb,DISK], DatanodeInfoWithStorage[127.0.0.1:40867,DS-b9cddb0e-8b5a-45b3-b8f9-3fe13e889922,DISK], DatanodeInfoWithStorage[127.0.0.1:43866,DS-49dbc7c1-f87a-476e-8793-1698edd4bd1b,DISK], DatanodeInfoWithStorage[127.0.0.1:37937,DS-09c6ff9c-c85c-47e9-89a3-177b3f5fed15,DISK], DatanodeInfoWithStorage[127.0.0.1:40816,DS-75c5c513-3a14-400e-a472-7b4704a7b69d,DISK], DatanodeInfoWithStorage[127.0.0.1:37267,DS-6c5d5248-d38a-4e5f-9a1f-cd8066b6a6fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42303,DS-b1da0b40-55dc-4723-b1cc-90498339f3cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34215,DS-812dc2b6-2804-4f50-a2ce-b396f9a73fa5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-897273625-172.17.0.5-1595432957606:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44013,DS-1bf62a02-dcdb-4d00-aa09-abe17b48bafb,DISK], DatanodeInfoWithStorage[127.0.0.1:40867,DS-b9cddb0e-8b5a-45b3-b8f9-3fe13e889922,DISK], DatanodeInfoWithStorage[127.0.0.1:43866,DS-49dbc7c1-f87a-476e-8793-1698edd4bd1b,DISK], DatanodeInfoWithStorage[127.0.0.1:37937,DS-09c6ff9c-c85c-47e9-89a3-177b3f5fed15,DISK], DatanodeInfoWithStorage[127.0.0.1:40816,DS-75c5c513-3a14-400e-a472-7b4704a7b69d,DISK], DatanodeInfoWithStorage[127.0.0.1:37267,DS-6c5d5248-d38a-4e5f-9a1f-cd8066b6a6fe,DISK], DatanodeInfoWithStorage[127.0.0.1:42303,DS-b1da0b40-55dc-4723-b1cc-90498339f3cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34215,DS-812dc2b6-2804-4f50-a2ce-b396f9a73fa5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1416850688-172.17.0.5-1595433045548:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34272,DS-9b7ca48f-04c7-4b8d-8646-3717e048f2d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36393,DS-bc2a49b9-ad03-4e51-a6ef-3e3adcd9f257,DISK], DatanodeInfoWithStorage[127.0.0.1:42091,DS-66a0695b-f460-4522-b6fb-05a3e224c66e,DISK], DatanodeInfoWithStorage[127.0.0.1:41050,DS-05e6529e-3a60-4298-b72e-33741f51b530,DISK], DatanodeInfoWithStorage[127.0.0.1:38944,DS-ac3ec081-79fe-4fe4-814a-74de3d813413,DISK], DatanodeInfoWithStorage[127.0.0.1:38329,DS-a5a256f9-f873-4df4-9db3-496c47954b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:42747,DS-70cd8671-43ee-4b35-9ee5-98c44bf76d93,DISK], DatanodeInfoWithStorage[127.0.0.1:41210,DS-a82c09db-36a6-468c-9837-08c6cce93915,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1416850688-172.17.0.5-1595433045548:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34272,DS-9b7ca48f-04c7-4b8d-8646-3717e048f2d4,DISK], DatanodeInfoWithStorage[127.0.0.1:36393,DS-bc2a49b9-ad03-4e51-a6ef-3e3adcd9f257,DISK], DatanodeInfoWithStorage[127.0.0.1:42091,DS-66a0695b-f460-4522-b6fb-05a3e224c66e,DISK], DatanodeInfoWithStorage[127.0.0.1:41050,DS-05e6529e-3a60-4298-b72e-33741f51b530,DISK], DatanodeInfoWithStorage[127.0.0.1:38944,DS-ac3ec081-79fe-4fe4-814a-74de3d813413,DISK], DatanodeInfoWithStorage[127.0.0.1:38329,DS-a5a256f9-f873-4df4-9db3-496c47954b1e,DISK], DatanodeInfoWithStorage[127.0.0.1:42747,DS-70cd8671-43ee-4b35-9ee5-98c44bf76d93,DISK], DatanodeInfoWithStorage[127.0.0.1:41210,DS-a82c09db-36a6-468c-9837-08c6cce93915,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1587858-172.17.0.5-1595433130164:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38421,DS-193cd738-3df3-432e-bf39-07e142f8f418,DISK], DatanodeInfoWithStorage[127.0.0.1:46803,DS-2ae109cc-7e15-4d9f-b4c1-ce50ed2b3227,DISK], DatanodeInfoWithStorage[127.0.0.1:45461,DS-b5353eb5-934d-423f-b52b-d06bbba7fd75,DISK], DatanodeInfoWithStorage[127.0.0.1:46879,DS-be160ca0-2833-4bfd-a5e3-3c8ecb7f29c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38274,DS-a8fb2fca-c74b-4c11-aa10-85394375e985,DISK], DatanodeInfoWithStorage[127.0.0.1:40337,DS-bd67c05e-b176-4e60-9d5f-bc286acb25b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42909,DS-2d5cc07a-cf2a-4f69-bd70-8ae475106532,DISK], DatanodeInfoWithStorage[127.0.0.1:34564,DS-8a2f9446-d95e-4f24-b9f2-5aec312f4f6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1587858-172.17.0.5-1595433130164:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38421,DS-193cd738-3df3-432e-bf39-07e142f8f418,DISK], DatanodeInfoWithStorage[127.0.0.1:46803,DS-2ae109cc-7e15-4d9f-b4c1-ce50ed2b3227,DISK], DatanodeInfoWithStorage[127.0.0.1:45461,DS-b5353eb5-934d-423f-b52b-d06bbba7fd75,DISK], DatanodeInfoWithStorage[127.0.0.1:46879,DS-be160ca0-2833-4bfd-a5e3-3c8ecb7f29c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38274,DS-a8fb2fca-c74b-4c11-aa10-85394375e985,DISK], DatanodeInfoWithStorage[127.0.0.1:40337,DS-bd67c05e-b176-4e60-9d5f-bc286acb25b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42909,DS-2d5cc07a-cf2a-4f69-bd70-8ae475106532,DISK], DatanodeInfoWithStorage[127.0.0.1:34564,DS-8a2f9446-d95e-4f24-b9f2-5aec312f4f6d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1520650358-172.17.0.5-1595434145757:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45790,DS-1efbb3d7-efd4-473c-bc94-4778b7db6e30,DISK], DatanodeInfoWithStorage[127.0.0.1:43151,DS-0dde85ed-ea07-440e-9c82-206994638853,DISK], DatanodeInfoWithStorage[127.0.0.1:46683,DS-f6104ef9-838c-4d0e-9b97-1a4b9ec98518,DISK], DatanodeInfoWithStorage[127.0.0.1:41198,DS-2067d5e1-3beb-48ed-bc03-ede752071852,DISK], DatanodeInfoWithStorage[127.0.0.1:38478,DS-b599a97e-b1fb-4603-a2f7-8c452aad6028,DISK], DatanodeInfoWithStorage[127.0.0.1:41018,DS-fd6021ee-374e-41f7-820c-ab494df6163c,DISK], DatanodeInfoWithStorage[127.0.0.1:38464,DS-3798505b-1792-48b1-ac38-807c914b701c,DISK], DatanodeInfoWithStorage[127.0.0.1:34904,DS-f472a180-ea80-447c-a8b5-6a9b962dbb1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1520650358-172.17.0.5-1595434145757:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45790,DS-1efbb3d7-efd4-473c-bc94-4778b7db6e30,DISK], DatanodeInfoWithStorage[127.0.0.1:43151,DS-0dde85ed-ea07-440e-9c82-206994638853,DISK], DatanodeInfoWithStorage[127.0.0.1:46683,DS-f6104ef9-838c-4d0e-9b97-1a4b9ec98518,DISK], DatanodeInfoWithStorage[127.0.0.1:41198,DS-2067d5e1-3beb-48ed-bc03-ede752071852,DISK], DatanodeInfoWithStorage[127.0.0.1:38478,DS-b599a97e-b1fb-4603-a2f7-8c452aad6028,DISK], DatanodeInfoWithStorage[127.0.0.1:41018,DS-fd6021ee-374e-41f7-820c-ab494df6163c,DISK], DatanodeInfoWithStorage[127.0.0.1:38464,DS-3798505b-1792-48b1-ac38-807c914b701c,DISK], DatanodeInfoWithStorage[127.0.0.1:34904,DS-f472a180-ea80-447c-a8b5-6a9b962dbb1c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1824692194-172.17.0.5-1595434225352:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46276,DS-76ea2ee0-b543-4d25-943e-fe15f53c73c3,DISK], DatanodeInfoWithStorage[127.0.0.1:36752,DS-693db818-d77e-41f3-91fe-237f0057dfdb,DISK], DatanodeInfoWithStorage[127.0.0.1:38958,DS-f3e04730-088f-445a-a677-43e91194db5b,DISK], DatanodeInfoWithStorage[127.0.0.1:39833,DS-351ec921-6d34-4242-a4de-a2dd16548eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:38359,DS-d34d55ae-7681-4071-824d-0b39e175f5c9,DISK], DatanodeInfoWithStorage[127.0.0.1:37012,DS-83a7e37c-a2c8-4061-bba8-09e43d1397d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34995,DS-e1b1fb78-9566-42aa-bca2-0586f17e315b,DISK], DatanodeInfoWithStorage[127.0.0.1:43610,DS-bffa97e5-ead5-4f50-9b20-e1e0971cf4eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1824692194-172.17.0.5-1595434225352:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46276,DS-76ea2ee0-b543-4d25-943e-fe15f53c73c3,DISK], DatanodeInfoWithStorage[127.0.0.1:36752,DS-693db818-d77e-41f3-91fe-237f0057dfdb,DISK], DatanodeInfoWithStorage[127.0.0.1:38958,DS-f3e04730-088f-445a-a677-43e91194db5b,DISK], DatanodeInfoWithStorage[127.0.0.1:39833,DS-351ec921-6d34-4242-a4de-a2dd16548eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:38359,DS-d34d55ae-7681-4071-824d-0b39e175f5c9,DISK], DatanodeInfoWithStorage[127.0.0.1:37012,DS-83a7e37c-a2c8-4061-bba8-09e43d1397d5,DISK], DatanodeInfoWithStorage[127.0.0.1:34995,DS-e1b1fb78-9566-42aa-bca2-0586f17e315b,DISK], DatanodeInfoWithStorage[127.0.0.1:43610,DS-bffa97e5-ead5-4f50-9b20-e1e0971cf4eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-77905891-172.17.0.5-1595434266424:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41726,DS-7b55c29c-f880-4af5-af6f-3585bb14c6e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42633,DS-b6c52a27-a7ce-4766-8d52-e48743474156,DISK], DatanodeInfoWithStorage[127.0.0.1:37656,DS-91621cc8-890a-46c8-9bcd-8fa3e7afaf13,DISK], DatanodeInfoWithStorage[127.0.0.1:41421,DS-8cedbf9f-2744-4617-b774-c6f4b0beb321,DISK], DatanodeInfoWithStorage[127.0.0.1:38473,DS-15326c57-a63f-427e-9d74-b30e1a7d3c18,DISK], DatanodeInfoWithStorage[127.0.0.1:45886,DS-deef23c7-3a6d-4144-9ebb-25bf09d177e1,DISK], DatanodeInfoWithStorage[127.0.0.1:36739,DS-9cace43b-1a7a-488a-8043-fb8e194fb8e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45982,DS-7e73312a-4beb-4b5f-851f-cdb1a409e1c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-77905891-172.17.0.5-1595434266424:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41726,DS-7b55c29c-f880-4af5-af6f-3585bb14c6e4,DISK], DatanodeInfoWithStorage[127.0.0.1:42633,DS-b6c52a27-a7ce-4766-8d52-e48743474156,DISK], DatanodeInfoWithStorage[127.0.0.1:37656,DS-91621cc8-890a-46c8-9bcd-8fa3e7afaf13,DISK], DatanodeInfoWithStorage[127.0.0.1:41421,DS-8cedbf9f-2744-4617-b774-c6f4b0beb321,DISK], DatanodeInfoWithStorage[127.0.0.1:38473,DS-15326c57-a63f-427e-9d74-b30e1a7d3c18,DISK], DatanodeInfoWithStorage[127.0.0.1:45886,DS-deef23c7-3a6d-4144-9ebb-25bf09d177e1,DISK], DatanodeInfoWithStorage[127.0.0.1:36739,DS-9cace43b-1a7a-488a-8043-fb8e194fb8e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45982,DS-7e73312a-4beb-4b5f-851f-cdb1a409e1c0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-435539969-172.17.0.5-1595435065722:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44285,DS-b8b88fd3-d8c4-4ed1-9eee-3c4e85b0efc4,DISK], DatanodeInfoWithStorage[127.0.0.1:45587,DS-f4e1a2d8-dc91-4d64-97e9-ba2bd2c3e4d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35022,DS-b0f1f541-8196-42f5-a735-eff511810f83,DISK], DatanodeInfoWithStorage[127.0.0.1:37312,DS-92373cd4-97a9-455e-ab0f-10a2cfb07626,DISK], DatanodeInfoWithStorage[127.0.0.1:45014,DS-4ad2720d-9296-44f4-a3d5-b394e8f17528,DISK], DatanodeInfoWithStorage[127.0.0.1:44658,DS-86d4c4a9-0045-46ee-9f03-7a835934043f,DISK], DatanodeInfoWithStorage[127.0.0.1:43492,DS-93e47aa3-a798-412b-b8a4-3b7ff33b5856,DISK], DatanodeInfoWithStorage[127.0.0.1:46432,DS-8dce21cb-c407-4056-8cc8-8904c2dd5514,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-435539969-172.17.0.5-1595435065722:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44285,DS-b8b88fd3-d8c4-4ed1-9eee-3c4e85b0efc4,DISK], DatanodeInfoWithStorage[127.0.0.1:45587,DS-f4e1a2d8-dc91-4d64-97e9-ba2bd2c3e4d9,DISK], DatanodeInfoWithStorage[127.0.0.1:35022,DS-b0f1f541-8196-42f5-a735-eff511810f83,DISK], DatanodeInfoWithStorage[127.0.0.1:37312,DS-92373cd4-97a9-455e-ab0f-10a2cfb07626,DISK], DatanodeInfoWithStorage[127.0.0.1:45014,DS-4ad2720d-9296-44f4-a3d5-b394e8f17528,DISK], DatanodeInfoWithStorage[127.0.0.1:44658,DS-86d4c4a9-0045-46ee-9f03-7a835934043f,DISK], DatanodeInfoWithStorage[127.0.0.1:43492,DS-93e47aa3-a798-412b-b8a4-3b7ff33b5856,DISK], DatanodeInfoWithStorage[127.0.0.1:46432,DS-8dce21cb-c407-4056-8cc8-8904c2dd5514,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1553058614-172.17.0.5-1595435477746:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38334,DS-01005798-dee8-4889-a958-d2344d5d25b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44015,DS-60912c11-2e7b-4014-b88e-bd1dcbed9ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:43300,DS-156baa08-13b6-438b-b5b3-ea48f01fd5ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41712,DS-e7fb5aa1-7332-4531-b600-cdda9fe77c10,DISK], DatanodeInfoWithStorage[127.0.0.1:43852,DS-06564d56-458e-48b2-aba1-d2345c284859,DISK], DatanodeInfoWithStorage[127.0.0.1:33427,DS-fb97ed06-7e01-4649-b880-bfb4dbabca14,DISK], DatanodeInfoWithStorage[127.0.0.1:44294,DS-60d20e6e-c0f5-4e75-b2c0-bcf4bb3ea282,DISK], DatanodeInfoWithStorage[127.0.0.1:32922,DS-1e3b65ec-b429-4c44-b668-28f037a81d01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1553058614-172.17.0.5-1595435477746:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38334,DS-01005798-dee8-4889-a958-d2344d5d25b3,DISK], DatanodeInfoWithStorage[127.0.0.1:44015,DS-60912c11-2e7b-4014-b88e-bd1dcbed9ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:43300,DS-156baa08-13b6-438b-b5b3-ea48f01fd5ee,DISK], DatanodeInfoWithStorage[127.0.0.1:41712,DS-e7fb5aa1-7332-4531-b600-cdda9fe77c10,DISK], DatanodeInfoWithStorage[127.0.0.1:43852,DS-06564d56-458e-48b2-aba1-d2345c284859,DISK], DatanodeInfoWithStorage[127.0.0.1:33427,DS-fb97ed06-7e01-4649-b880-bfb4dbabca14,DISK], DatanodeInfoWithStorage[127.0.0.1:44294,DS-60d20e6e-c0f5-4e75-b2c0-bcf4bb3ea282,DISK], DatanodeInfoWithStorage[127.0.0.1:32922,DS-1e3b65ec-b429-4c44-b668-28f037a81d01,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-803889501-172.17.0.5-1595435822280:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39368,DS-25b13794-8388-494e-a99d-8596481663d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44681,DS-9794de6a-b6ad-4651-a17e-83b47602a7b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36604,DS-4c6ed80d-4c36-48fc-9547-c6475360f1ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39781,DS-5e2eacb6-4e0b-4960-b636-6353a13b6d51,DISK], DatanodeInfoWithStorage[127.0.0.1:45032,DS-375a69e1-f49b-4713-8a21-94c9188c9014,DISK], DatanodeInfoWithStorage[127.0.0.1:40333,DS-6316c9b3-1655-4f2b-bafb-2e274d9eb3fe,DISK], DatanodeInfoWithStorage[127.0.0.1:44305,DS-0438c012-2e47-4f6b-92fe-50517e9827c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43579,DS-9f5f0dda-bef7-4088-849a-3c4749032629,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-803889501-172.17.0.5-1595435822280:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39368,DS-25b13794-8388-494e-a99d-8596481663d0,DISK], DatanodeInfoWithStorage[127.0.0.1:44681,DS-9794de6a-b6ad-4651-a17e-83b47602a7b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36604,DS-4c6ed80d-4c36-48fc-9547-c6475360f1ff,DISK], DatanodeInfoWithStorage[127.0.0.1:39781,DS-5e2eacb6-4e0b-4960-b636-6353a13b6d51,DISK], DatanodeInfoWithStorage[127.0.0.1:45032,DS-375a69e1-f49b-4713-8a21-94c9188c9014,DISK], DatanodeInfoWithStorage[127.0.0.1:40333,DS-6316c9b3-1655-4f2b-bafb-2e274d9eb3fe,DISK], DatanodeInfoWithStorage[127.0.0.1:44305,DS-0438c012-2e47-4f6b-92fe-50517e9827c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43579,DS-9f5f0dda-bef7-4088-849a-3c4749032629,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-133457128-172.17.0.5-1595436297977:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37213,DS-5ec0ad25-7dc2-4093-b82c-ab1bd9e7bddd,DISK], DatanodeInfoWithStorage[127.0.0.1:37222,DS-1a47de1f-2345-4d88-b2db-bba73001066a,DISK], DatanodeInfoWithStorage[127.0.0.1:40731,DS-eadaf3dc-1bcc-49f4-ab8a-7575da37dafd,DISK], DatanodeInfoWithStorage[127.0.0.1:43026,DS-1da88ae5-7ae4-472d-90bb-5bb154169148,DISK], DatanodeInfoWithStorage[127.0.0.1:35453,DS-793e6ae1-325a-4ce7-a8b3-5d40c14ce1fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38187,DS-295612ec-c61d-4cb0-97ca-f8c04806f386,DISK], DatanodeInfoWithStorage[127.0.0.1:45078,DS-96ef46a4-4df8-4477-a65e-d0440524b21b,DISK], DatanodeInfoWithStorage[127.0.0.1:37442,DS-81a6b638-7d73-4710-bc00-cbc55271189d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-133457128-172.17.0.5-1595436297977:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37213,DS-5ec0ad25-7dc2-4093-b82c-ab1bd9e7bddd,DISK], DatanodeInfoWithStorage[127.0.0.1:37222,DS-1a47de1f-2345-4d88-b2db-bba73001066a,DISK], DatanodeInfoWithStorage[127.0.0.1:40731,DS-eadaf3dc-1bcc-49f4-ab8a-7575da37dafd,DISK], DatanodeInfoWithStorage[127.0.0.1:43026,DS-1da88ae5-7ae4-472d-90bb-5bb154169148,DISK], DatanodeInfoWithStorage[127.0.0.1:35453,DS-793e6ae1-325a-4ce7-a8b3-5d40c14ce1fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38187,DS-295612ec-c61d-4cb0-97ca-f8c04806f386,DISK], DatanodeInfoWithStorage[127.0.0.1:45078,DS-96ef46a4-4df8-4477-a65e-d0440524b21b,DISK], DatanodeInfoWithStorage[127.0.0.1:37442,DS-81a6b638-7d73-4710-bc00-cbc55271189d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-22364491-172.17.0.5-1595436467240:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45678,DS-c0d0ae6b-1d9d-446b-9f62-0abfba42942d,DISK], DatanodeInfoWithStorage[127.0.0.1:36233,DS-1049e804-9c67-4356-8e8d-ecb90e947fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:46639,DS-c98a0bdc-6b30-4225-b49d-36e12407a50f,DISK], DatanodeInfoWithStorage[127.0.0.1:35615,DS-adc6b98a-e390-405f-8b48-556bb2badf1d,DISK], DatanodeInfoWithStorage[127.0.0.1:37460,DS-d914b5e9-ea4e-4163-8767-f24fe2b9759d,DISK], DatanodeInfoWithStorage[127.0.0.1:40287,DS-cbb11e14-1e5b-40cc-b64e-2d25d9cae6fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35731,DS-6f2e4432-c448-4134-b291-21806c082082,DISK], DatanodeInfoWithStorage[127.0.0.1:40508,DS-3abcf065-86d0-4dfe-835c-b99947698cbd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-22364491-172.17.0.5-1595436467240:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45678,DS-c0d0ae6b-1d9d-446b-9f62-0abfba42942d,DISK], DatanodeInfoWithStorage[127.0.0.1:36233,DS-1049e804-9c67-4356-8e8d-ecb90e947fe1,DISK], DatanodeInfoWithStorage[127.0.0.1:46639,DS-c98a0bdc-6b30-4225-b49d-36e12407a50f,DISK], DatanodeInfoWithStorage[127.0.0.1:35615,DS-adc6b98a-e390-405f-8b48-556bb2badf1d,DISK], DatanodeInfoWithStorage[127.0.0.1:37460,DS-d914b5e9-ea4e-4163-8767-f24fe2b9759d,DISK], DatanodeInfoWithStorage[127.0.0.1:40287,DS-cbb11e14-1e5b-40cc-b64e-2d25d9cae6fa,DISK], DatanodeInfoWithStorage[127.0.0.1:35731,DS-6f2e4432-c448-4134-b291-21806c082082,DISK], DatanodeInfoWithStorage[127.0.0.1:40508,DS-3abcf065-86d0-4dfe-835c-b99947698cbd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1682971483-172.17.0.5-1595436586862:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38941,DS-d9687ae3-526a-4d89-b02d-5e8a47067948,DISK], DatanodeInfoWithStorage[127.0.0.1:40660,DS-fecd745c-bf8d-4b8e-8ac6-433a1147cf77,DISK], DatanodeInfoWithStorage[127.0.0.1:38145,DS-a2df7db6-ea93-4f45-8424-2feb7d3788d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46778,DS-b6185aa4-53cf-44ae-8c08-26459d6f4382,DISK], DatanodeInfoWithStorage[127.0.0.1:41836,DS-f1d4e2b2-2724-4037-afbf-e7ce55205422,DISK], DatanodeInfoWithStorage[127.0.0.1:44123,DS-1484fa82-e08a-4303-853b-5133f045f9c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34341,DS-578e10ee-771d-43d3-9c88-8773ba025c8b,DISK], DatanodeInfoWithStorage[127.0.0.1:36520,DS-af9a8699-0c52-4566-a1d3-0723eca33d70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1682971483-172.17.0.5-1595436586862:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38941,DS-d9687ae3-526a-4d89-b02d-5e8a47067948,DISK], DatanodeInfoWithStorage[127.0.0.1:40660,DS-fecd745c-bf8d-4b8e-8ac6-433a1147cf77,DISK], DatanodeInfoWithStorage[127.0.0.1:38145,DS-a2df7db6-ea93-4f45-8424-2feb7d3788d2,DISK], DatanodeInfoWithStorage[127.0.0.1:46778,DS-b6185aa4-53cf-44ae-8c08-26459d6f4382,DISK], DatanodeInfoWithStorage[127.0.0.1:41836,DS-f1d4e2b2-2724-4037-afbf-e7ce55205422,DISK], DatanodeInfoWithStorage[127.0.0.1:44123,DS-1484fa82-e08a-4303-853b-5133f045f9c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34341,DS-578e10ee-771d-43d3-9c88-8773ba025c8b,DISK], DatanodeInfoWithStorage[127.0.0.1:36520,DS-af9a8699-0c52-4566-a1d3-0723eca33d70,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-404552337-172.17.0.5-1595436859888:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35643,DS-3b331a04-2d87-4ce5-97cf-1d62e4cdbd30,DISK], DatanodeInfoWithStorage[127.0.0.1:33125,DS-de0e10db-f295-4a19-8e0b-90cccbaf23fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36116,DS-d57eb3f1-7380-4505-9e32-2632c971a4e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42627,DS-299926de-bea0-49fd-a97c-574301c98670,DISK], DatanodeInfoWithStorage[127.0.0.1:34874,DS-fb5285ff-0c2b-42bc-ab20-eadf9074b0d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43552,DS-139061b6-7a00-49ae-beb6-3d295a91d61f,DISK], DatanodeInfoWithStorage[127.0.0.1:44580,DS-b4664dc1-f0ff-47df-917c-492f5720c1b3,DISK], DatanodeInfoWithStorage[127.0.0.1:38100,DS-a96b4bbb-a73f-4016-93d4-9b3294044914,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-404552337-172.17.0.5-1595436859888:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35643,DS-3b331a04-2d87-4ce5-97cf-1d62e4cdbd30,DISK], DatanodeInfoWithStorage[127.0.0.1:33125,DS-de0e10db-f295-4a19-8e0b-90cccbaf23fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36116,DS-d57eb3f1-7380-4505-9e32-2632c971a4e3,DISK], DatanodeInfoWithStorage[127.0.0.1:42627,DS-299926de-bea0-49fd-a97c-574301c98670,DISK], DatanodeInfoWithStorage[127.0.0.1:34874,DS-fb5285ff-0c2b-42bc-ab20-eadf9074b0d1,DISK], DatanodeInfoWithStorage[127.0.0.1:43552,DS-139061b6-7a00-49ae-beb6-3d295a91d61f,DISK], DatanodeInfoWithStorage[127.0.0.1:44580,DS-b4664dc1-f0ff-47df-917c-492f5720c1b3,DISK], DatanodeInfoWithStorage[127.0.0.1:38100,DS-a96b4bbb-a73f-4016-93d4-9b3294044914,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2026340003-172.17.0.5-1595437047349:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43069,DS-a72398e3-afc9-427a-9597-1d156955ea1d,DISK], DatanodeInfoWithStorage[127.0.0.1:45491,DS-a9998933-84f0-4225-8099-13c5663d46af,DISK], DatanodeInfoWithStorage[127.0.0.1:43734,DS-61fda2ee-c624-4d5a-9bae-d683e9f8fdc2,DISK], DatanodeInfoWithStorage[127.0.0.1:42474,DS-eeda0910-a4d6-425a-8702-f712107d346f,DISK], DatanodeInfoWithStorage[127.0.0.1:35423,DS-5f4dd8d8-bb8d-4d88-8567-1d57398baa82,DISK], DatanodeInfoWithStorage[127.0.0.1:39146,DS-606ce868-0434-49b8-9630-7a07fa264b65,DISK], DatanodeInfoWithStorage[127.0.0.1:38478,DS-e3c6e051-f3ef-408e-8ae7-60b4490653b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43870,DS-df88bf8f-8438-47c6-933a-b478d365beb3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2026340003-172.17.0.5-1595437047349:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43069,DS-a72398e3-afc9-427a-9597-1d156955ea1d,DISK], DatanodeInfoWithStorage[127.0.0.1:45491,DS-a9998933-84f0-4225-8099-13c5663d46af,DISK], DatanodeInfoWithStorage[127.0.0.1:43734,DS-61fda2ee-c624-4d5a-9bae-d683e9f8fdc2,DISK], DatanodeInfoWithStorage[127.0.0.1:42474,DS-eeda0910-a4d6-425a-8702-f712107d346f,DISK], DatanodeInfoWithStorage[127.0.0.1:35423,DS-5f4dd8d8-bb8d-4d88-8567-1d57398baa82,DISK], DatanodeInfoWithStorage[127.0.0.1:39146,DS-606ce868-0434-49b8-9630-7a07fa264b65,DISK], DatanodeInfoWithStorage[127.0.0.1:38478,DS-e3c6e051-f3ef-408e-8ae7-60b4490653b8,DISK], DatanodeInfoWithStorage[127.0.0.1:43870,DS-df88bf8f-8438-47c6-933a-b478d365beb3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-743760135-172.17.0.5-1595437132972:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41592,DS-146438b7-069f-4a12-9705-b5a68108d4ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35156,DS-121c49d8-76f8-4346-8bff-6ea7c0248139,DISK], DatanodeInfoWithStorage[127.0.0.1:44313,DS-43f51d60-9c29-4bad-ab3c-2b2065129d13,DISK], DatanodeInfoWithStorage[127.0.0.1:39735,DS-b5281d7e-0f90-4665-8729-d7b671fe5ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:34417,DS-d9c98b96-fe3d-4b8a-a520-390099746619,DISK], DatanodeInfoWithStorage[127.0.0.1:35152,DS-b3b84863-1432-4c09-a33b-1534ae34c063,DISK], DatanodeInfoWithStorage[127.0.0.1:33338,DS-c669e523-ee7f-44eb-ae69-62a7f3678a17,DISK], DatanodeInfoWithStorage[127.0.0.1:46542,DS-d631fa33-4ba4-467f-95c2-e44c0e94bc4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-743760135-172.17.0.5-1595437132972:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41592,DS-146438b7-069f-4a12-9705-b5a68108d4ca,DISK], DatanodeInfoWithStorage[127.0.0.1:35156,DS-121c49d8-76f8-4346-8bff-6ea7c0248139,DISK], DatanodeInfoWithStorage[127.0.0.1:44313,DS-43f51d60-9c29-4bad-ab3c-2b2065129d13,DISK], DatanodeInfoWithStorage[127.0.0.1:39735,DS-b5281d7e-0f90-4665-8729-d7b671fe5ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:34417,DS-d9c98b96-fe3d-4b8a-a520-390099746619,DISK], DatanodeInfoWithStorage[127.0.0.1:35152,DS-b3b84863-1432-4c09-a33b-1534ae34c063,DISK], DatanodeInfoWithStorage[127.0.0.1:33338,DS-c669e523-ee7f-44eb-ae69-62a7f3678a17,DISK], DatanodeInfoWithStorage[127.0.0.1:46542,DS-d631fa33-4ba4-467f-95c2-e44c0e94bc4e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-67172349-172.17.0.5-1595437169385:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39581,DS-e0a7fa59-8c33-4da2-bca2-27eb4b531c41,DISK], DatanodeInfoWithStorage[127.0.0.1:39143,DS-74607899-ba19-4269-9094-fbc8abf98ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:33994,DS-479732c8-aa54-45fc-baf7-f4bd54c9573b,DISK], DatanodeInfoWithStorage[127.0.0.1:33592,DS-ec637ab0-3e38-4c77-82fb-822c09d1f982,DISK], DatanodeInfoWithStorage[127.0.0.1:44653,DS-26a3455a-65e6-4c40-b3c1-b8bdb4720902,DISK], DatanodeInfoWithStorage[127.0.0.1:41465,DS-3ef4d6d2-14db-4ae9-b8e0-e6ba1ff069d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35054,DS-da617f70-809b-45f0-bab1-24ceaa58f4ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34701,DS-e82db45e-4bb0-4685-90a1-5dbcb43dff09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-67172349-172.17.0.5-1595437169385:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39581,DS-e0a7fa59-8c33-4da2-bca2-27eb4b531c41,DISK], DatanodeInfoWithStorage[127.0.0.1:39143,DS-74607899-ba19-4269-9094-fbc8abf98ed5,DISK], DatanodeInfoWithStorage[127.0.0.1:33994,DS-479732c8-aa54-45fc-baf7-f4bd54c9573b,DISK], DatanodeInfoWithStorage[127.0.0.1:33592,DS-ec637ab0-3e38-4c77-82fb-822c09d1f982,DISK], DatanodeInfoWithStorage[127.0.0.1:44653,DS-26a3455a-65e6-4c40-b3c1-b8bdb4720902,DISK], DatanodeInfoWithStorage[127.0.0.1:41465,DS-3ef4d6d2-14db-4ae9-b8e0-e6ba1ff069d0,DISK], DatanodeInfoWithStorage[127.0.0.1:35054,DS-da617f70-809b-45f0-bab1-24ceaa58f4ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34701,DS-e82db45e-4bb0-4685-90a1-5dbcb43dff09,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1377437057-172.17.0.5-1595437338261:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36017,DS-aeb33f19-0ff4-4ee8-a429-722978690dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:36525,DS-433c8208-c866-46d3-8511-64eaeda3c752,DISK], DatanodeInfoWithStorage[127.0.0.1:33728,DS-434f633f-e1fb-4964-8e97-601b3a0ddb64,DISK], DatanodeInfoWithStorage[127.0.0.1:36503,DS-11badbfb-a133-470f-859f-62b793f5ef86,DISK], DatanodeInfoWithStorage[127.0.0.1:35543,DS-c82ac265-067f-4484-b838-3e47758ba606,DISK], DatanodeInfoWithStorage[127.0.0.1:33975,DS-577a80b5-ae7c-470a-9c1b-8c1c7d37ea4e,DISK], DatanodeInfoWithStorage[127.0.0.1:42868,DS-34d1a4d8-9c34-45aa-b03c-933c665348e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33788,DS-a96bcb09-aa2a-45a9-b02a-0695ea230149,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1377437057-172.17.0.5-1595437338261:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36017,DS-aeb33f19-0ff4-4ee8-a429-722978690dd7,DISK], DatanodeInfoWithStorage[127.0.0.1:36525,DS-433c8208-c866-46d3-8511-64eaeda3c752,DISK], DatanodeInfoWithStorage[127.0.0.1:33728,DS-434f633f-e1fb-4964-8e97-601b3a0ddb64,DISK], DatanodeInfoWithStorage[127.0.0.1:36503,DS-11badbfb-a133-470f-859f-62b793f5ef86,DISK], DatanodeInfoWithStorage[127.0.0.1:35543,DS-c82ac265-067f-4484-b838-3e47758ba606,DISK], DatanodeInfoWithStorage[127.0.0.1:33975,DS-577a80b5-ae7c-470a-9c1b-8c1c7d37ea4e,DISK], DatanodeInfoWithStorage[127.0.0.1:42868,DS-34d1a4d8-9c34-45aa-b03c-933c665348e1,DISK], DatanodeInfoWithStorage[127.0.0.1:33788,DS-a96bcb09-aa2a-45a9-b02a-0695ea230149,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1422030867-172.17.0.5-1595437519189:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42507,DS-42a3974c-6682-4372-94fe-1fff347177ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38950,DS-415fc869-f521-4874-9627-92dee462f59c,DISK], DatanodeInfoWithStorage[127.0.0.1:42587,DS-3daf0683-5f45-4c12-9409-fc411a84dde4,DISK], DatanodeInfoWithStorage[127.0.0.1:44599,DS-dda70a84-099c-4ecd-be24-833f9f6336c5,DISK], DatanodeInfoWithStorage[127.0.0.1:46328,DS-0b564ef0-9b09-4bad-850c-cd7a92aec979,DISK], DatanodeInfoWithStorage[127.0.0.1:32987,DS-97bd5e58-e157-4721-bbcb-c8c5ea543380,DISK], DatanodeInfoWithStorage[127.0.0.1:39036,DS-d6731410-8146-4947-94ec-38cc9c31b64b,DISK], DatanodeInfoWithStorage[127.0.0.1:38432,DS-4f86155f-c5ef-4c9c-9269-bfaf3b97ce9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1422030867-172.17.0.5-1595437519189:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42507,DS-42a3974c-6682-4372-94fe-1fff347177ba,DISK], DatanodeInfoWithStorage[127.0.0.1:38950,DS-415fc869-f521-4874-9627-92dee462f59c,DISK], DatanodeInfoWithStorage[127.0.0.1:42587,DS-3daf0683-5f45-4c12-9409-fc411a84dde4,DISK], DatanodeInfoWithStorage[127.0.0.1:44599,DS-dda70a84-099c-4ecd-be24-833f9f6336c5,DISK], DatanodeInfoWithStorage[127.0.0.1:46328,DS-0b564ef0-9b09-4bad-850c-cd7a92aec979,DISK], DatanodeInfoWithStorage[127.0.0.1:32987,DS-97bd5e58-e157-4721-bbcb-c8c5ea543380,DISK], DatanodeInfoWithStorage[127.0.0.1:39036,DS-d6731410-8146-4947-94ec-38cc9c31b64b,DISK], DatanodeInfoWithStorage[127.0.0.1:38432,DS-4f86155f-c5ef-4c9c-9269-bfaf3b97ce9e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1219648611-172.17.0.5-1595437989027:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40875,DS-fce213c7-3fc5-436b-8305-9ac4735bbbd7,DISK], DatanodeInfoWithStorage[127.0.0.1:41318,DS-719f66e3-0232-4f50-8cca-ecd6c7aa5d22,DISK], DatanodeInfoWithStorage[127.0.0.1:39083,DS-783e9acb-a076-4f32-848f-8bfea295c476,DISK], DatanodeInfoWithStorage[127.0.0.1:38955,DS-af584a86-f65a-479b-a93e-4d13f8da0f39,DISK], DatanodeInfoWithStorage[127.0.0.1:37120,DS-618f2537-fcbb-4f65-9784-37ed4fdb854f,DISK], DatanodeInfoWithStorage[127.0.0.1:46465,DS-87a4af16-fbce-4e15-9493-485c00d98226,DISK], DatanodeInfoWithStorage[127.0.0.1:46279,DS-6238ff6a-b75d-4341-b45e-a5c2569d6c38,DISK], DatanodeInfoWithStorage[127.0.0.1:37960,DS-30f15e2a-2161-4931-ae8d-2cf22fe3a7dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1219648611-172.17.0.5-1595437989027:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40875,DS-fce213c7-3fc5-436b-8305-9ac4735bbbd7,DISK], DatanodeInfoWithStorage[127.0.0.1:41318,DS-719f66e3-0232-4f50-8cca-ecd6c7aa5d22,DISK], DatanodeInfoWithStorage[127.0.0.1:39083,DS-783e9acb-a076-4f32-848f-8bfea295c476,DISK], DatanodeInfoWithStorage[127.0.0.1:38955,DS-af584a86-f65a-479b-a93e-4d13f8da0f39,DISK], DatanodeInfoWithStorage[127.0.0.1:37120,DS-618f2537-fcbb-4f65-9784-37ed4fdb854f,DISK], DatanodeInfoWithStorage[127.0.0.1:46465,DS-87a4af16-fbce-4e15-9493-485c00d98226,DISK], DatanodeInfoWithStorage[127.0.0.1:46279,DS-6238ff6a-b75d-4341-b45e-a5c2569d6c38,DISK], DatanodeInfoWithStorage[127.0.0.1:37960,DS-30f15e2a-2161-4931-ae8d-2cf22fe3a7dc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-216641736-172.17.0.5-1595438166627:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45308,DS-79aad716-879a-4257-af80-e4129c9c07f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36557,DS-fbfecb8f-fabf-4edd-82ee-baf7ce27bc92,DISK], DatanodeInfoWithStorage[127.0.0.1:42460,DS-8481260d-c48d-4cb8-9ccf-9c08749a1742,DISK], DatanodeInfoWithStorage[127.0.0.1:33093,DS-ce1524a5-8296-4c90-9b4d-9e0106b9224c,DISK], DatanodeInfoWithStorage[127.0.0.1:34144,DS-adc7d52c-d57c-481e-912b-03c8d2160eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:38939,DS-eb7d2ae3-5652-4a4f-b3f5-20441d70dcae,DISK], DatanodeInfoWithStorage[127.0.0.1:46461,DS-66a9581d-ef49-423b-81ee-706ac586ac0c,DISK], DatanodeInfoWithStorage[127.0.0.1:42580,DS-dbc0721d-b0ac-417c-ad3c-34a4ac65b19d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-216641736-172.17.0.5-1595438166627:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45308,DS-79aad716-879a-4257-af80-e4129c9c07f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36557,DS-fbfecb8f-fabf-4edd-82ee-baf7ce27bc92,DISK], DatanodeInfoWithStorage[127.0.0.1:42460,DS-8481260d-c48d-4cb8-9ccf-9c08749a1742,DISK], DatanodeInfoWithStorage[127.0.0.1:33093,DS-ce1524a5-8296-4c90-9b4d-9e0106b9224c,DISK], DatanodeInfoWithStorage[127.0.0.1:34144,DS-adc7d52c-d57c-481e-912b-03c8d2160eb9,DISK], DatanodeInfoWithStorage[127.0.0.1:38939,DS-eb7d2ae3-5652-4a4f-b3f5-20441d70dcae,DISK], DatanodeInfoWithStorage[127.0.0.1:46461,DS-66a9581d-ef49-423b-81ee-706ac586ac0c,DISK], DatanodeInfoWithStorage[127.0.0.1:42580,DS-dbc0721d-b0ac-417c-ad3c-34a4ac65b19d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1336326775-172.17.0.5-1595438220165:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38129,DS-580368bb-53f4-4463-887d-90aacfa9ac72,DISK], DatanodeInfoWithStorage[127.0.0.1:36062,DS-77befe79-8df0-43e1-8349-d00031fc27fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36439,DS-05a0a3a7-1e25-4c87-a69b-66e64bb8b2be,DISK], DatanodeInfoWithStorage[127.0.0.1:38306,DS-744f4fff-1f89-41ac-9c8d-99c49950bfae,DISK], DatanodeInfoWithStorage[127.0.0.1:45366,DS-a044bc8c-f406-415c-b72d-1b3007f83c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:36019,DS-c4b01549-ee18-4c0a-886c-35eede4a030a,DISK], DatanodeInfoWithStorage[127.0.0.1:36593,DS-94919bf2-5d33-4b9d-b2c1-13fc45d18b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:40484,DS-eab8cb17-f4db-4de2-85ae-d49d5543d56e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1336326775-172.17.0.5-1595438220165:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38129,DS-580368bb-53f4-4463-887d-90aacfa9ac72,DISK], DatanodeInfoWithStorage[127.0.0.1:36062,DS-77befe79-8df0-43e1-8349-d00031fc27fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36439,DS-05a0a3a7-1e25-4c87-a69b-66e64bb8b2be,DISK], DatanodeInfoWithStorage[127.0.0.1:38306,DS-744f4fff-1f89-41ac-9c8d-99c49950bfae,DISK], DatanodeInfoWithStorage[127.0.0.1:45366,DS-a044bc8c-f406-415c-b72d-1b3007f83c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:36019,DS-c4b01549-ee18-4c0a-886c-35eede4a030a,DISK], DatanodeInfoWithStorage[127.0.0.1:36593,DS-94919bf2-5d33-4b9d-b2c1-13fc45d18b7e,DISK], DatanodeInfoWithStorage[127.0.0.1:40484,DS-eab8cb17-f4db-4de2-85ae-d49d5543d56e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-473737672-172.17.0.5-1595438259553:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41150,DS-d87226a0-87d8-420e-b294-b91f04b3bcb3,DISK], DatanodeInfoWithStorage[127.0.0.1:44971,DS-45b44076-2bbc-446d-b635-8f0274ec15c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46850,DS-bd2f25d8-a9cb-4009-982f-84a26e407f58,DISK], DatanodeInfoWithStorage[127.0.0.1:35765,DS-717f7f58-4f5e-44bb-b8d9-8ba14787c68e,DISK], DatanodeInfoWithStorage[127.0.0.1:33982,DS-3b979a26-81dc-4a09-be60-68225f6fedcd,DISK], DatanodeInfoWithStorage[127.0.0.1:36627,DS-5c1c9a5d-4ed2-4d99-a83c-743a90ba00b7,DISK], DatanodeInfoWithStorage[127.0.0.1:42672,DS-8cfee880-1043-478e-9dcd-dbf71c46348f,DISK], DatanodeInfoWithStorage[127.0.0.1:42424,DS-a9bb86c8-1ac1-4269-af50-bdf0034442d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-473737672-172.17.0.5-1595438259553:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41150,DS-d87226a0-87d8-420e-b294-b91f04b3bcb3,DISK], DatanodeInfoWithStorage[127.0.0.1:44971,DS-45b44076-2bbc-446d-b635-8f0274ec15c1,DISK], DatanodeInfoWithStorage[127.0.0.1:46850,DS-bd2f25d8-a9cb-4009-982f-84a26e407f58,DISK], DatanodeInfoWithStorage[127.0.0.1:35765,DS-717f7f58-4f5e-44bb-b8d9-8ba14787c68e,DISK], DatanodeInfoWithStorage[127.0.0.1:33982,DS-3b979a26-81dc-4a09-be60-68225f6fedcd,DISK], DatanodeInfoWithStorage[127.0.0.1:36627,DS-5c1c9a5d-4ed2-4d99-a83c-743a90ba00b7,DISK], DatanodeInfoWithStorage[127.0.0.1:42672,DS-8cfee880-1043-478e-9dcd-dbf71c46348f,DISK], DatanodeInfoWithStorage[127.0.0.1:42424,DS-a9bb86c8-1ac1-4269-af50-bdf0034442d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.drop.cache.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1501618889-172.17.0.5-1595438300119:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36291,DS-25856df9-3c46-4aae-9558-d4e878724a39,DISK], DatanodeInfoWithStorage[127.0.0.1:46034,DS-5062e92c-5b5c-4222-be6e-dd760f412c4a,DISK], DatanodeInfoWithStorage[127.0.0.1:36908,DS-359fe4c4-47ad-4b7d-b73a-f0a96385b4b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40277,DS-48b37f97-87d0-410b-ad49-efd9c828c231,DISK], DatanodeInfoWithStorage[127.0.0.1:34158,DS-0fb2b311-4ad5-47fc-b1c6-aa977a357020,DISK], DatanodeInfoWithStorage[127.0.0.1:35913,DS-d7d7f6cb-2bc8-478d-aac8-6ba72b06ba5e,DISK], DatanodeInfoWithStorage[127.0.0.1:35531,DS-18094e39-4260-4657-99dc-d2a3765a0b83,DISK], DatanodeInfoWithStorage[127.0.0.1:34005,DS-3bfe76db-27b9-4781-8133-02d9755e0c9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1501618889-172.17.0.5-1595438300119:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36291,DS-25856df9-3c46-4aae-9558-d4e878724a39,DISK], DatanodeInfoWithStorage[127.0.0.1:46034,DS-5062e92c-5b5c-4222-be6e-dd760f412c4a,DISK], DatanodeInfoWithStorage[127.0.0.1:36908,DS-359fe4c4-47ad-4b7d-b73a-f0a96385b4b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40277,DS-48b37f97-87d0-410b-ad49-efd9c828c231,DISK], DatanodeInfoWithStorage[127.0.0.1:34158,DS-0fb2b311-4ad5-47fc-b1c6-aa977a357020,DISK], DatanodeInfoWithStorage[127.0.0.1:35913,DS-d7d7f6cb-2bc8-478d-aac8-6ba72b06ba5e,DISK], DatanodeInfoWithStorage[127.0.0.1:35531,DS-18094e39-4260-4657-99dc-d2a3765a0b83,DISK], DatanodeInfoWithStorage[127.0.0.1:34005,DS-3bfe76db-27b9-4781-8133-02d9755e0c9c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 6581
