reconf_parameter: dfs.client.cache.drop.behind.reads
component: hdfs:NameNode
v1: true
v2: null
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.reads
component: hdfs:NameNode
v1: true
v2: null
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-445063647-172.17.0.7-1596961364403:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46780,DS-c025110d-d8eb-4705-9656-9a275ec7244a,DISK], DatanodeInfoWithStorage[127.0.0.1:43683,DS-2c985217-b827-45b9-9172-06cf5e177350,DISK], DatanodeInfoWithStorage[127.0.0.1:34555,DS-5a714758-ed6a-4151-a8eb-fddd81890fa3,DISK], DatanodeInfoWithStorage[127.0.0.1:34300,DS-c0189d63-2120-4751-974e-e46fa6da36af,DISK], DatanodeInfoWithStorage[127.0.0.1:44414,DS-7a7442da-5f5f-4ee9-a0b8-ff14c2836844,DISK], DatanodeInfoWithStorage[127.0.0.1:32886,DS-7bc8db37-7228-4e45-9f42-068ebed22d24,DISK], DatanodeInfoWithStorage[127.0.0.1:37325,DS-3e44014d-b550-4a59-aa35-8a56a90483f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45659,DS-4d36c397-38f8-4e40-b648-354536cb50a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-445063647-172.17.0.7-1596961364403:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46780,DS-c025110d-d8eb-4705-9656-9a275ec7244a,DISK], DatanodeInfoWithStorage[127.0.0.1:43683,DS-2c985217-b827-45b9-9172-06cf5e177350,DISK], DatanodeInfoWithStorage[127.0.0.1:34555,DS-5a714758-ed6a-4151-a8eb-fddd81890fa3,DISK], DatanodeInfoWithStorage[127.0.0.1:34300,DS-c0189d63-2120-4751-974e-e46fa6da36af,DISK], DatanodeInfoWithStorage[127.0.0.1:44414,DS-7a7442da-5f5f-4ee9-a0b8-ff14c2836844,DISK], DatanodeInfoWithStorage[127.0.0.1:32886,DS-7bc8db37-7228-4e45-9f42-068ebed22d24,DISK], DatanodeInfoWithStorage[127.0.0.1:37325,DS-3e44014d-b550-4a59-aa35-8a56a90483f9,DISK], DatanodeInfoWithStorage[127.0.0.1:45659,DS-4d36c397-38f8-4e40-b648-354536cb50a4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.reads
component: hdfs:NameNode
v1: true
v2: null
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1852027756-172.17.0.7-1596961400197:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35282,DS-03dc5437-7c0b-490b-85e4-9ad5aa094aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:44252,DS-61a4450b-cc18-48d2-8526-b655b72ca0dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38899,DS-23c1bab9-1265-475a-9c77-047a5853f8ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35554,DS-33ca9415-4677-4f74-b61d-a967723f1177,DISK], DatanodeInfoWithStorage[127.0.0.1:33053,DS-c2b8ad9e-ee0c-447c-a6a4-704f325b0d81,DISK], DatanodeInfoWithStorage[127.0.0.1:32785,DS-f710b253-2468-405d-bb58-dc6616d1a9da,DISK], DatanodeInfoWithStorage[127.0.0.1:35634,DS-92c6a6d8-4457-43e3-b7a9-b1bbd2267c42,DISK], DatanodeInfoWithStorage[127.0.0.1:46553,DS-53d0d42b-bbda-4e08-b65d-09172a4722c7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1852027756-172.17.0.7-1596961400197:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35282,DS-03dc5437-7c0b-490b-85e4-9ad5aa094aa0,DISK], DatanodeInfoWithStorage[127.0.0.1:44252,DS-61a4450b-cc18-48d2-8526-b655b72ca0dd,DISK], DatanodeInfoWithStorage[127.0.0.1:38899,DS-23c1bab9-1265-475a-9c77-047a5853f8ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35554,DS-33ca9415-4677-4f74-b61d-a967723f1177,DISK], DatanodeInfoWithStorage[127.0.0.1:33053,DS-c2b8ad9e-ee0c-447c-a6a4-704f325b0d81,DISK], DatanodeInfoWithStorage[127.0.0.1:32785,DS-f710b253-2468-405d-bb58-dc6616d1a9da,DISK], DatanodeInfoWithStorage[127.0.0.1:35634,DS-92c6a6d8-4457-43e3-b7a9-b1bbd2267c42,DISK], DatanodeInfoWithStorage[127.0.0.1:46553,DS-53d0d42b-bbda-4e08-b65d-09172a4722c7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.cache.drop.behind.reads
component: hdfs:NameNode
v1: true
v2: null
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-790837078-172.17.0.7-1596961446566:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46470,DS-2ef5d769-db93-403b-b913-9e81b7aa3461,DISK], DatanodeInfoWithStorage[127.0.0.1:37794,DS-ece8137c-5ae6-4c31-80d3-e921c5a83447,DISK], DatanodeInfoWithStorage[127.0.0.1:40067,DS-0aae352d-48cf-4ad6-8835-de6e8c22fbff,DISK], DatanodeInfoWithStorage[127.0.0.1:40945,DS-62e0b154-18a5-4656-81c6-e44a9386691a,DISK], DatanodeInfoWithStorage[127.0.0.1:37235,DS-2aeac82b-c2ef-4bc8-84bc-0730b3d741da,DISK], DatanodeInfoWithStorage[127.0.0.1:34271,DS-fbdac53a-15d2-47e5-91eb-5e6d3cb30d86,DISK], DatanodeInfoWithStorage[127.0.0.1:45796,DS-d4a5afe9-5029-47bb-95dc-7d1e465f43cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43664,DS-9a060ba7-d4bf-46b4-94ba-4e1b1bb589a0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-790837078-172.17.0.7-1596961446566:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46470,DS-2ef5d769-db93-403b-b913-9e81b7aa3461,DISK], DatanodeInfoWithStorage[127.0.0.1:37794,DS-ece8137c-5ae6-4c31-80d3-e921c5a83447,DISK], DatanodeInfoWithStorage[127.0.0.1:40067,DS-0aae352d-48cf-4ad6-8835-de6e8c22fbff,DISK], DatanodeInfoWithStorage[127.0.0.1:40945,DS-62e0b154-18a5-4656-81c6-e44a9386691a,DISK], DatanodeInfoWithStorage[127.0.0.1:37235,DS-2aeac82b-c2ef-4bc8-84bc-0730b3d741da,DISK], DatanodeInfoWithStorage[127.0.0.1:34271,DS-fbdac53a-15d2-47e5-91eb-5e6d3cb30d86,DISK], DatanodeInfoWithStorage[127.0.0.1:45796,DS-d4a5afe9-5029-47bb-95dc-7d1e465f43cd,DISK], DatanodeInfoWithStorage[127.0.0.1:43664,DS-9a060ba7-d4bf-46b4-94ba-4e1b1bb589a0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.reads
component: hdfs:NameNode
v1: true
v2: null
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1657325548-172.17.0.7-1596961844120:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41573,DS-7abda727-8f7f-4dab-9ab9-bbb9822f2657,DISK], DatanodeInfoWithStorage[127.0.0.1:45534,DS-5d35a4cd-5323-4279-8a5b-60b4992ada71,DISK], DatanodeInfoWithStorage[127.0.0.1:42491,DS-685c371c-5e9b-4ec3-b9db-c442ded56327,DISK], DatanodeInfoWithStorage[127.0.0.1:35606,DS-b34dead8-2b1b-4171-9def-20480cde21ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34158,DS-693d9fac-b680-4a50-a949-3b26ceb89651,DISK], DatanodeInfoWithStorage[127.0.0.1:43426,DS-f24a6416-133e-4653-9272-8bc188803863,DISK], DatanodeInfoWithStorage[127.0.0.1:43283,DS-203eaa2e-e346-4dfa-9dfc-46490fad6897,DISK], DatanodeInfoWithStorage[127.0.0.1:36454,DS-fa3cc4fa-e1df-4b92-a458-02ec0e9c31d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1657325548-172.17.0.7-1596961844120:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41573,DS-7abda727-8f7f-4dab-9ab9-bbb9822f2657,DISK], DatanodeInfoWithStorage[127.0.0.1:45534,DS-5d35a4cd-5323-4279-8a5b-60b4992ada71,DISK], DatanodeInfoWithStorage[127.0.0.1:42491,DS-685c371c-5e9b-4ec3-b9db-c442ded56327,DISK], DatanodeInfoWithStorage[127.0.0.1:35606,DS-b34dead8-2b1b-4171-9def-20480cde21ba,DISK], DatanodeInfoWithStorage[127.0.0.1:34158,DS-693d9fac-b680-4a50-a949-3b26ceb89651,DISK], DatanodeInfoWithStorage[127.0.0.1:43426,DS-f24a6416-133e-4653-9272-8bc188803863,DISK], DatanodeInfoWithStorage[127.0.0.1:43283,DS-203eaa2e-e346-4dfa-9dfc-46490fad6897,DISK], DatanodeInfoWithStorage[127.0.0.1:36454,DS-fa3cc4fa-e1df-4b92-a458-02ec0e9c31d9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.reads
component: hdfs:NameNode
v1: true
v2: null
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-686105671-172.17.0.7-1596961981576:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42507,DS-cdcacaa6-857e-4e95-87af-da8c10c5ec74,DISK], DatanodeInfoWithStorage[127.0.0.1:35342,DS-5e95a3e3-7f4f-479c-9ce8-437a5a1273e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35914,DS-d5944b99-b106-477b-a15d-054981ecca88,DISK], DatanodeInfoWithStorage[127.0.0.1:37138,DS-efea75e2-15bf-4ffc-a888-76fa90b10701,DISK], DatanodeInfoWithStorage[127.0.0.1:44802,DS-4d9959f9-d2d5-4716-9e89-854b32e7ee3a,DISK], DatanodeInfoWithStorage[127.0.0.1:32950,DS-a15736e2-66bc-4236-bcce-0d213901187c,DISK], DatanodeInfoWithStorage[127.0.0.1:42067,DS-a1a9fa1d-8875-4f61-83ff-f613ce7025c7,DISK], DatanodeInfoWithStorage[127.0.0.1:41096,DS-8965f186-994d-44be-9b7d-68535a6cf32a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-686105671-172.17.0.7-1596961981576:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42507,DS-cdcacaa6-857e-4e95-87af-da8c10c5ec74,DISK], DatanodeInfoWithStorage[127.0.0.1:35342,DS-5e95a3e3-7f4f-479c-9ce8-437a5a1273e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35914,DS-d5944b99-b106-477b-a15d-054981ecca88,DISK], DatanodeInfoWithStorage[127.0.0.1:37138,DS-efea75e2-15bf-4ffc-a888-76fa90b10701,DISK], DatanodeInfoWithStorage[127.0.0.1:44802,DS-4d9959f9-d2d5-4716-9e89-854b32e7ee3a,DISK], DatanodeInfoWithStorage[127.0.0.1:32950,DS-a15736e2-66bc-4236-bcce-0d213901187c,DISK], DatanodeInfoWithStorage[127.0.0.1:42067,DS-a1a9fa1d-8875-4f61-83ff-f613ce7025c7,DISK], DatanodeInfoWithStorage[127.0.0.1:41096,DS-8965f186-994d-44be-9b7d-68535a6cf32a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.reads
component: hdfs:NameNode
v1: true
v2: null
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1813226288-172.17.0.7-1596962022015:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33488,DS-5ae02701-716c-4649-a2c4-5825640bd14b,DISK], DatanodeInfoWithStorage[127.0.0.1:35107,DS-dc2ae19a-47a1-4212-b15e-e0e41bba0b6c,DISK], DatanodeInfoWithStorage[127.0.0.1:41599,DS-acede1b6-9bf9-41ae-b25f-57088d928f4e,DISK], DatanodeInfoWithStorage[127.0.0.1:39548,DS-f439f745-8359-4015-94e7-aa03cfb6d18d,DISK], DatanodeInfoWithStorage[127.0.0.1:45075,DS-7e7ebf13-71ae-44ff-8b66-fc68db65a60f,DISK], DatanodeInfoWithStorage[127.0.0.1:39339,DS-f00ada5c-4692-4367-8410-8e5b9f4729f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41875,DS-ce9ab2f0-1307-45c7-a255-10bd9909868e,DISK], DatanodeInfoWithStorage[127.0.0.1:34952,DS-a7590a25-ef52-459b-8bc0-b5ab61ea98d1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1813226288-172.17.0.7-1596962022015:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33488,DS-5ae02701-716c-4649-a2c4-5825640bd14b,DISK], DatanodeInfoWithStorage[127.0.0.1:35107,DS-dc2ae19a-47a1-4212-b15e-e0e41bba0b6c,DISK], DatanodeInfoWithStorage[127.0.0.1:41599,DS-acede1b6-9bf9-41ae-b25f-57088d928f4e,DISK], DatanodeInfoWithStorage[127.0.0.1:39548,DS-f439f745-8359-4015-94e7-aa03cfb6d18d,DISK], DatanodeInfoWithStorage[127.0.0.1:45075,DS-7e7ebf13-71ae-44ff-8b66-fc68db65a60f,DISK], DatanodeInfoWithStorage[127.0.0.1:39339,DS-f00ada5c-4692-4367-8410-8e5b9f4729f2,DISK], DatanodeInfoWithStorage[127.0.0.1:41875,DS-ce9ab2f0-1307-45c7-a255-10bd9909868e,DISK], DatanodeInfoWithStorage[127.0.0.1:34952,DS-a7590a25-ef52-459b-8bc0-b5ab61ea98d1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.reads
component: hdfs:NameNode
v1: true
v2: null
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1549828407-172.17.0.7-1596962069774:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37420,DS-4a58650f-8fab-4f8e-ae16-6815f58d7a1d,DISK], DatanodeInfoWithStorage[127.0.0.1:34923,DS-ca38df29-b9b1-4fda-91b9-dd031ebbc205,DISK], DatanodeInfoWithStorage[127.0.0.1:32973,DS-263e4615-b290-4a74-b3ad-f340bd9fd0f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39276,DS-62dfcbd0-7d88-4226-bb23-c6ac6e0e98f1,DISK], DatanodeInfoWithStorage[127.0.0.1:46675,DS-5e9e1a2f-41da-4367-a392-46eda334aa65,DISK], DatanodeInfoWithStorage[127.0.0.1:46586,DS-3e7c68b5-d67e-4aa1-9d0f-49ebbe5bbafa,DISK], DatanodeInfoWithStorage[127.0.0.1:38720,DS-9120a7f9-c3c4-47e5-9378-023584d4541e,DISK], DatanodeInfoWithStorage[127.0.0.1:43273,DS-26c2414f-8ce2-4ded-8019-6e7688433e1d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1549828407-172.17.0.7-1596962069774:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37420,DS-4a58650f-8fab-4f8e-ae16-6815f58d7a1d,DISK], DatanodeInfoWithStorage[127.0.0.1:34923,DS-ca38df29-b9b1-4fda-91b9-dd031ebbc205,DISK], DatanodeInfoWithStorage[127.0.0.1:32973,DS-263e4615-b290-4a74-b3ad-f340bd9fd0f2,DISK], DatanodeInfoWithStorage[127.0.0.1:39276,DS-62dfcbd0-7d88-4226-bb23-c6ac6e0e98f1,DISK], DatanodeInfoWithStorage[127.0.0.1:46675,DS-5e9e1a2f-41da-4367-a392-46eda334aa65,DISK], DatanodeInfoWithStorage[127.0.0.1:46586,DS-3e7c68b5-d67e-4aa1-9d0f-49ebbe5bbafa,DISK], DatanodeInfoWithStorage[127.0.0.1:38720,DS-9120a7f9-c3c4-47e5-9378-023584d4541e,DISK], DatanodeInfoWithStorage[127.0.0.1:43273,DS-26c2414f-8ce2-4ded-8019-6e7688433e1d,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.reads
component: hdfs:NameNode
v1: true
v2: null
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1226191214-172.17.0.7-1596962207021:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45775,DS-0e1417de-f1b7-4418-88e0-10fce630a167,DISK], DatanodeInfoWithStorage[127.0.0.1:35799,DS-e7e42de3-cc1c-4a2e-84c9-1bde0cef76b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33942,DS-9c96b05b-0610-47bd-aed7-00bcf4a37d5a,DISK], DatanodeInfoWithStorage[127.0.0.1:35728,DS-6907da70-9996-42d1-83af-d66e3ef00389,DISK], DatanodeInfoWithStorage[127.0.0.1:40261,DS-d5543aee-603d-4ef1-a7a4-eb93c94a5387,DISK], DatanodeInfoWithStorage[127.0.0.1:33568,DS-8449ba2d-50de-4ef8-8cb1-807255a1ca79,DISK], DatanodeInfoWithStorage[127.0.0.1:36392,DS-4385509e-906c-4310-b5cc-f37bd10d005f,DISK], DatanodeInfoWithStorage[127.0.0.1:34761,DS-84cea36b-da44-4d85-a10a-391cff4014ba,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1226191214-172.17.0.7-1596962207021:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45775,DS-0e1417de-f1b7-4418-88e0-10fce630a167,DISK], DatanodeInfoWithStorage[127.0.0.1:35799,DS-e7e42de3-cc1c-4a2e-84c9-1bde0cef76b8,DISK], DatanodeInfoWithStorage[127.0.0.1:33942,DS-9c96b05b-0610-47bd-aed7-00bcf4a37d5a,DISK], DatanodeInfoWithStorage[127.0.0.1:35728,DS-6907da70-9996-42d1-83af-d66e3ef00389,DISK], DatanodeInfoWithStorage[127.0.0.1:40261,DS-d5543aee-603d-4ef1-a7a4-eb93c94a5387,DISK], DatanodeInfoWithStorage[127.0.0.1:33568,DS-8449ba2d-50de-4ef8-8cb1-807255a1ca79,DISK], DatanodeInfoWithStorage[127.0.0.1:36392,DS-4385509e-906c-4310-b5cc-f37bd10d005f,DISK], DatanodeInfoWithStorage[127.0.0.1:34761,DS-84cea36b-da44-4d85-a10a-391cff4014ba,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.cache.drop.behind.reads
component: hdfs:NameNode
v1: true
v2: null
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-40329987-172.17.0.7-1596962250345:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36996,DS-2279b6f5-75c8-4c08-8e63-584e26323b57,DISK], DatanodeInfoWithStorage[127.0.0.1:33590,DS-5b393372-9ebd-4641-8e22-b01e9a37b17c,DISK], DatanodeInfoWithStorage[127.0.0.1:35634,DS-fbf7749e-d19d-4b3d-83b9-228010aa5e8e,DISK], DatanodeInfoWithStorage[127.0.0.1:35201,DS-a5a4c028-b06c-4b8f-aeae-b8dacc405e41,DISK], DatanodeInfoWithStorage[127.0.0.1:33899,DS-3409dcbb-aa56-4e39-9344-788cd783ebc8,DISK], DatanodeInfoWithStorage[127.0.0.1:44028,DS-c8a60a85-fe85-4e8c-a165-5d3cff47b849,DISK], DatanodeInfoWithStorage[127.0.0.1:37294,DS-183a6281-0d0f-4564-a27e-2428cb533d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:41644,DS-0532ad8e-e4cd-4532-922c-af721e1bd5f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-40329987-172.17.0.7-1596962250345:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36996,DS-2279b6f5-75c8-4c08-8e63-584e26323b57,DISK], DatanodeInfoWithStorage[127.0.0.1:33590,DS-5b393372-9ebd-4641-8e22-b01e9a37b17c,DISK], DatanodeInfoWithStorage[127.0.0.1:35634,DS-fbf7749e-d19d-4b3d-83b9-228010aa5e8e,DISK], DatanodeInfoWithStorage[127.0.0.1:35201,DS-a5a4c028-b06c-4b8f-aeae-b8dacc405e41,DISK], DatanodeInfoWithStorage[127.0.0.1:33899,DS-3409dcbb-aa56-4e39-9344-788cd783ebc8,DISK], DatanodeInfoWithStorage[127.0.0.1:44028,DS-c8a60a85-fe85-4e8c-a165-5d3cff47b849,DISK], DatanodeInfoWithStorage[127.0.0.1:37294,DS-183a6281-0d0f-4564-a27e-2428cb533d2d,DISK], DatanodeInfoWithStorage[127.0.0.1:41644,DS-0532ad8e-e4cd-4532-922c-af721e1bd5f2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.reads
component: hdfs:NameNode
v1: true
v2: null
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-643747539-172.17.0.7-1596962382624:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38314,DS-d8baf443-941f-444a-bfa6-0902309918ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46699,DS-5eb6a00f-6c04-474a-8194-0a71d0dd7e90,DISK], DatanodeInfoWithStorage[127.0.0.1:38005,DS-17868b88-b7e3-446b-8a7f-6b47fab7016e,DISK], DatanodeInfoWithStorage[127.0.0.1:44369,DS-74e75665-fb75-4f72-aafe-7a440350d3a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43886,DS-05942203-b0ba-402a-b799-7634cbecdeff,DISK], DatanodeInfoWithStorage[127.0.0.1:39917,DS-89346c6c-63e0-4601-88dc-01766cf88c94,DISK], DatanodeInfoWithStorage[127.0.0.1:41937,DS-da60c49c-d2b9-4e8f-88f8-f36ae93fb93a,DISK], DatanodeInfoWithStorage[127.0.0.1:34257,DS-1c637c09-40f0-49ec-a979-4405d17c02e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-643747539-172.17.0.7-1596962382624:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38314,DS-d8baf443-941f-444a-bfa6-0902309918ce,DISK], DatanodeInfoWithStorage[127.0.0.1:46699,DS-5eb6a00f-6c04-474a-8194-0a71d0dd7e90,DISK], DatanodeInfoWithStorage[127.0.0.1:38005,DS-17868b88-b7e3-446b-8a7f-6b47fab7016e,DISK], DatanodeInfoWithStorage[127.0.0.1:44369,DS-74e75665-fb75-4f72-aafe-7a440350d3a1,DISK], DatanodeInfoWithStorage[127.0.0.1:43886,DS-05942203-b0ba-402a-b799-7634cbecdeff,DISK], DatanodeInfoWithStorage[127.0.0.1:39917,DS-89346c6c-63e0-4601-88dc-01766cf88c94,DISK], DatanodeInfoWithStorage[127.0.0.1:41937,DS-da60c49c-d2b9-4e8f-88f8-f36ae93fb93a,DISK], DatanodeInfoWithStorage[127.0.0.1:34257,DS-1c637c09-40f0-49ec-a979-4405d17c02e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.reads
component: hdfs:NameNode
v1: true
v2: null
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1062495091-172.17.0.7-1596962526017:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40705,DS-85be332c-5f3a-47e8-8cef-841dbe3da4ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42020,DS-d5414319-9668-4d59-8830-f581fb8d1d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:37720,DS-88eeb74f-1e41-4327-8046-9606ad7ffe86,DISK], DatanodeInfoWithStorage[127.0.0.1:40626,DS-6fbc9307-7cab-4b38-b6c1-ad7117357894,DISK], DatanodeInfoWithStorage[127.0.0.1:43765,DS-ce3298f0-b95e-4d7e-9188-70f6db2cf35f,DISK], DatanodeInfoWithStorage[127.0.0.1:42211,DS-4afe989a-4432-4b71-98b9-abcd73d5d35f,DISK], DatanodeInfoWithStorage[127.0.0.1:35810,DS-cd580c7b-3ff6-4f62-ac89-c0d32eb7e260,DISK], DatanodeInfoWithStorage[127.0.0.1:43960,DS-41559924-e548-4520-ad96-e79b2fccbb73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1062495091-172.17.0.7-1596962526017:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40705,DS-85be332c-5f3a-47e8-8cef-841dbe3da4ee,DISK], DatanodeInfoWithStorage[127.0.0.1:42020,DS-d5414319-9668-4d59-8830-f581fb8d1d9d,DISK], DatanodeInfoWithStorage[127.0.0.1:37720,DS-88eeb74f-1e41-4327-8046-9606ad7ffe86,DISK], DatanodeInfoWithStorage[127.0.0.1:40626,DS-6fbc9307-7cab-4b38-b6c1-ad7117357894,DISK], DatanodeInfoWithStorage[127.0.0.1:43765,DS-ce3298f0-b95e-4d7e-9188-70f6db2cf35f,DISK], DatanodeInfoWithStorage[127.0.0.1:42211,DS-4afe989a-4432-4b71-98b9-abcd73d5d35f,DISK], DatanodeInfoWithStorage[127.0.0.1:35810,DS-cd580c7b-3ff6-4f62-ac89-c0d32eb7e260,DISK], DatanodeInfoWithStorage[127.0.0.1:43960,DS-41559924-e548-4520-ad96-e79b2fccbb73,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.reads
component: hdfs:NameNode
v1: true
v2: null
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-298162536-172.17.0.7-1596963096692:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41272,DS-36bae78e-a553-462c-b7ae-6281a25a97cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35896,DS-d4932bcf-d661-4163-b426-49ecbd2c5267,DISK], DatanodeInfoWithStorage[127.0.0.1:34727,DS-8bae4329-0688-447a-b4d5-740b2ddefc20,DISK], DatanodeInfoWithStorage[127.0.0.1:41360,DS-6b0c8f0f-b1a4-4906-abc7-536cb77192fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44729,DS-3694b689-ee12-4034-a569-9c5f8a61e54d,DISK], DatanodeInfoWithStorage[127.0.0.1:36314,DS-a3f1af4f-b79d-46d3-9467-a6fd119bba38,DISK], DatanodeInfoWithStorage[127.0.0.1:44914,DS-cf5c4750-61d0-4ddf-ba0c-c9d6ff464108,DISK], DatanodeInfoWithStorage[127.0.0.1:36087,DS-a140450a-8bc9-40f8-849d-53b0b98e1b31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-298162536-172.17.0.7-1596963096692:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41272,DS-36bae78e-a553-462c-b7ae-6281a25a97cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35896,DS-d4932bcf-d661-4163-b426-49ecbd2c5267,DISK], DatanodeInfoWithStorage[127.0.0.1:34727,DS-8bae4329-0688-447a-b4d5-740b2ddefc20,DISK], DatanodeInfoWithStorage[127.0.0.1:41360,DS-6b0c8f0f-b1a4-4906-abc7-536cb77192fa,DISK], DatanodeInfoWithStorage[127.0.0.1:44729,DS-3694b689-ee12-4034-a569-9c5f8a61e54d,DISK], DatanodeInfoWithStorage[127.0.0.1:36314,DS-a3f1af4f-b79d-46d3-9467-a6fd119bba38,DISK], DatanodeInfoWithStorage[127.0.0.1:44914,DS-cf5c4750-61d0-4ddf-ba0c-c9d6ff464108,DISK], DatanodeInfoWithStorage[127.0.0.1:36087,DS-a140450a-8bc9-40f8-849d-53b0b98e1b31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.reads
component: hdfs:NameNode
v1: true
v2: null
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-529762177-172.17.0.7-1596963178124:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37576,DS-8a5167b7-7720-4deb-8bcf-ca826577c794,DISK], DatanodeInfoWithStorage[127.0.0.1:46753,DS-82655ff8-3410-4d8b-9cbe-052c2bd6ddf3,DISK], DatanodeInfoWithStorage[127.0.0.1:37937,DS-b807fbd9-ead3-4aa9-9f44-c08fb3bd009e,DISK], DatanodeInfoWithStorage[127.0.0.1:44089,DS-0bbe9f5e-4afd-40ff-8741-e41127c2093e,DISK], DatanodeInfoWithStorage[127.0.0.1:44726,DS-2416c3ce-49a8-408d-9fd2-36595343827d,DISK], DatanodeInfoWithStorage[127.0.0.1:40584,DS-1c4da99d-bb1e-4629-ab1e-48daa517c620,DISK], DatanodeInfoWithStorage[127.0.0.1:38564,DS-7e99b9f5-8364-4ed7-a4d8-abc3a4df6b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:42596,DS-d649abe1-d056-4de8-ac67-76f85abe8e90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-529762177-172.17.0.7-1596963178124:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37576,DS-8a5167b7-7720-4deb-8bcf-ca826577c794,DISK], DatanodeInfoWithStorage[127.0.0.1:46753,DS-82655ff8-3410-4d8b-9cbe-052c2bd6ddf3,DISK], DatanodeInfoWithStorage[127.0.0.1:37937,DS-b807fbd9-ead3-4aa9-9f44-c08fb3bd009e,DISK], DatanodeInfoWithStorage[127.0.0.1:44089,DS-0bbe9f5e-4afd-40ff-8741-e41127c2093e,DISK], DatanodeInfoWithStorage[127.0.0.1:44726,DS-2416c3ce-49a8-408d-9fd2-36595343827d,DISK], DatanodeInfoWithStorage[127.0.0.1:40584,DS-1c4da99d-bb1e-4629-ab1e-48daa517c620,DISK], DatanodeInfoWithStorage[127.0.0.1:38564,DS-7e99b9f5-8364-4ed7-a4d8-abc3a4df6b0d,DISK], DatanodeInfoWithStorage[127.0.0.1:42596,DS-d649abe1-d056-4de8-ac67-76f85abe8e90,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.reads
component: hdfs:NameNode
v1: true
v2: null
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-991134636-172.17.0.7-1596963268355:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40239,DS-b1e4d807-732b-4aab-9cf3-42e0d826714d,DISK], DatanodeInfoWithStorage[127.0.0.1:42703,DS-1e075e3a-e045-4c63-a55e-55a89d8ae972,DISK], DatanodeInfoWithStorage[127.0.0.1:37387,DS-9201b870-5d4c-4ec8-9d41-52bdeac4415d,DISK], DatanodeInfoWithStorage[127.0.0.1:41555,DS-67b61fa2-fe00-4f18-b967-04826c4e67d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45226,DS-6a8ac4e3-4ffd-46bf-aa22-9538ecf5bc37,DISK], DatanodeInfoWithStorage[127.0.0.1:40937,DS-fc829d8f-0a8a-4cef-a9d0-0deda6055bed,DISK], DatanodeInfoWithStorage[127.0.0.1:42446,DS-fbf95374-76fd-4417-99b6-d7fda9e61e5d,DISK], DatanodeInfoWithStorage[127.0.0.1:33090,DS-6eb98bb3-9c7e-4ca2-8241-00d47122cec3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-991134636-172.17.0.7-1596963268355:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40239,DS-b1e4d807-732b-4aab-9cf3-42e0d826714d,DISK], DatanodeInfoWithStorage[127.0.0.1:42703,DS-1e075e3a-e045-4c63-a55e-55a89d8ae972,DISK], DatanodeInfoWithStorage[127.0.0.1:37387,DS-9201b870-5d4c-4ec8-9d41-52bdeac4415d,DISK], DatanodeInfoWithStorage[127.0.0.1:41555,DS-67b61fa2-fe00-4f18-b967-04826c4e67d1,DISK], DatanodeInfoWithStorage[127.0.0.1:45226,DS-6a8ac4e3-4ffd-46bf-aa22-9538ecf5bc37,DISK], DatanodeInfoWithStorage[127.0.0.1:40937,DS-fc829d8f-0a8a-4cef-a9d0-0deda6055bed,DISK], DatanodeInfoWithStorage[127.0.0.1:42446,DS-fbf95374-76fd-4417-99b6-d7fda9e61e5d,DISK], DatanodeInfoWithStorage[127.0.0.1:33090,DS-6eb98bb3-9c7e-4ca2-8241-00d47122cec3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.reads
component: hdfs:NameNode
v1: true
v2: null
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-275910577-172.17.0.7-1596963446757:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33631,DS-4cb9f8f4-0338-45ac-b1fe-029186c3cc7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36609,DS-b9ff5c4d-da89-4764-8012-8e76b4b4b8f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43301,DS-1c239583-52ea-429a-9ec1-12eae596d66b,DISK], DatanodeInfoWithStorage[127.0.0.1:35001,DS-b1527541-23fa-445f-af22-dfb3ad8f46e8,DISK], DatanodeInfoWithStorage[127.0.0.1:44073,DS-574c203b-a9af-4b01-8551-43e8bad4b767,DISK], DatanodeInfoWithStorage[127.0.0.1:38515,DS-744126b2-7cfa-41f9-96dd-9dc32c6b81ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44235,DS-ea34a463-be9d-4448-aa97-1a084c5bea08,DISK], DatanodeInfoWithStorage[127.0.0.1:44057,DS-c0a5a5e0-781d-4237-8fa5-ea8372bf9976,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-275910577-172.17.0.7-1596963446757:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33631,DS-4cb9f8f4-0338-45ac-b1fe-029186c3cc7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36609,DS-b9ff5c4d-da89-4764-8012-8e76b4b4b8f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43301,DS-1c239583-52ea-429a-9ec1-12eae596d66b,DISK], DatanodeInfoWithStorage[127.0.0.1:35001,DS-b1527541-23fa-445f-af22-dfb3ad8f46e8,DISK], DatanodeInfoWithStorage[127.0.0.1:44073,DS-574c203b-a9af-4b01-8551-43e8bad4b767,DISK], DatanodeInfoWithStorage[127.0.0.1:38515,DS-744126b2-7cfa-41f9-96dd-9dc32c6b81ac,DISK], DatanodeInfoWithStorage[127.0.0.1:44235,DS-ea34a463-be9d-4448-aa97-1a084c5bea08,DISK], DatanodeInfoWithStorage[127.0.0.1:44057,DS-c0a5a5e0-781d-4237-8fa5-ea8372bf9976,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.reads
component: hdfs:NameNode
v1: true
v2: null
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1617002055-172.17.0.7-1596963712051:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35453,DS-4d7ff39f-58a9-448b-941e-a4ab9bd7a363,DISK], DatanodeInfoWithStorage[127.0.0.1:41069,DS-3a88f4f8-aa1f-4b5b-a0c1-5a75b8ce6034,DISK], DatanodeInfoWithStorage[127.0.0.1:36532,DS-0c1d62c5-f35f-428e-8afd-0612f3a2a077,DISK], DatanodeInfoWithStorage[127.0.0.1:36204,DS-841cea93-49b6-4fab-a960-541455289ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:45526,DS-e332464c-6cff-437c-9d7f-28e49dec355c,DISK], DatanodeInfoWithStorage[127.0.0.1:46680,DS-0aee8b39-a765-4850-a1cf-706a06029515,DISK], DatanodeInfoWithStorage[127.0.0.1:35153,DS-f15e1d24-f217-44bd-bbf2-57aa3c8a87fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40741,DS-7bc0198b-e703-4a6d-aaa0-cfbef742073a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1617002055-172.17.0.7-1596963712051:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35453,DS-4d7ff39f-58a9-448b-941e-a4ab9bd7a363,DISK], DatanodeInfoWithStorage[127.0.0.1:41069,DS-3a88f4f8-aa1f-4b5b-a0c1-5a75b8ce6034,DISK], DatanodeInfoWithStorage[127.0.0.1:36532,DS-0c1d62c5-f35f-428e-8afd-0612f3a2a077,DISK], DatanodeInfoWithStorage[127.0.0.1:36204,DS-841cea93-49b6-4fab-a960-541455289ce4,DISK], DatanodeInfoWithStorage[127.0.0.1:45526,DS-e332464c-6cff-437c-9d7f-28e49dec355c,DISK], DatanodeInfoWithStorage[127.0.0.1:46680,DS-0aee8b39-a765-4850-a1cf-706a06029515,DISK], DatanodeInfoWithStorage[127.0.0.1:35153,DS-f15e1d24-f217-44bd-bbf2-57aa3c8a87fb,DISK], DatanodeInfoWithStorage[127.0.0.1:40741,DS-7bc0198b-e703-4a6d-aaa0-cfbef742073a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.reads
component: hdfs:NameNode
v1: true
v2: null
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1855036340-172.17.0.7-1596963843447:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39179,DS-106f9770-e10b-4394-96a5-1b0177d45971,DISK], DatanodeInfoWithStorage[127.0.0.1:43924,DS-e6e11abf-5c3a-49ba-a17a-846572c3faa8,DISK], DatanodeInfoWithStorage[127.0.0.1:40332,DS-5550fc53-45e7-4833-b87c-d4c2df651753,DISK], DatanodeInfoWithStorage[127.0.0.1:45385,DS-98ad020f-8439-4cc0-bab9-363fd3dc43ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45611,DS-9ffd409c-ab9f-4f5b-8ce1-d21b98225939,DISK], DatanodeInfoWithStorage[127.0.0.1:39304,DS-45f16534-9ed2-493f-86a0-b9c84d558f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:40653,DS-2c61c092-aa6c-40c0-a8e2-fadadbe41d51,DISK], DatanodeInfoWithStorage[127.0.0.1:43146,DS-341ebd6a-b071-443e-a1e1-cf282dfaa346,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1855036340-172.17.0.7-1596963843447:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39179,DS-106f9770-e10b-4394-96a5-1b0177d45971,DISK], DatanodeInfoWithStorage[127.0.0.1:43924,DS-e6e11abf-5c3a-49ba-a17a-846572c3faa8,DISK], DatanodeInfoWithStorage[127.0.0.1:40332,DS-5550fc53-45e7-4833-b87c-d4c2df651753,DISK], DatanodeInfoWithStorage[127.0.0.1:45385,DS-98ad020f-8439-4cc0-bab9-363fd3dc43ec,DISK], DatanodeInfoWithStorage[127.0.0.1:45611,DS-9ffd409c-ab9f-4f5b-8ce1-d21b98225939,DISK], DatanodeInfoWithStorage[127.0.0.1:39304,DS-45f16534-9ed2-493f-86a0-b9c84d558f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:40653,DS-2c61c092-aa6c-40c0-a8e2-fadadbe41d51,DISK], DatanodeInfoWithStorage[127.0.0.1:43146,DS-341ebd6a-b071-443e-a1e1-cf282dfaa346,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.reads
component: hdfs:NameNode
v1: true
v2: null
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1136269152-172.17.0.7-1596963988450:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40391,DS-4eac2f37-0a9a-4483-97dc-e4778191c900,DISK], DatanodeInfoWithStorage[127.0.0.1:35900,DS-38cdeb1f-322b-4ab8-95ee-f2b487cc99a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36562,DS-c5cd5f90-5dca-4681-837d-7ba55e306c8a,DISK], DatanodeInfoWithStorage[127.0.0.1:46385,DS-df1a327f-8422-4a7a-885b-050a34378d63,DISK], DatanodeInfoWithStorage[127.0.0.1:36612,DS-e41c85f6-3417-44f7-8b8f-80809eecfeea,DISK], DatanodeInfoWithStorage[127.0.0.1:42405,DS-058bf394-9aed-4ec9-8586-897aae7c2147,DISK], DatanodeInfoWithStorage[127.0.0.1:46393,DS-0d3bcb67-a962-4616-99bb-bb6eaee3104c,DISK], DatanodeInfoWithStorage[127.0.0.1:33929,DS-59663277-a34f-4d3a-ad6e-6a872f0c57c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1136269152-172.17.0.7-1596963988450:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40391,DS-4eac2f37-0a9a-4483-97dc-e4778191c900,DISK], DatanodeInfoWithStorage[127.0.0.1:35900,DS-38cdeb1f-322b-4ab8-95ee-f2b487cc99a6,DISK], DatanodeInfoWithStorage[127.0.0.1:36562,DS-c5cd5f90-5dca-4681-837d-7ba55e306c8a,DISK], DatanodeInfoWithStorage[127.0.0.1:46385,DS-df1a327f-8422-4a7a-885b-050a34378d63,DISK], DatanodeInfoWithStorage[127.0.0.1:36612,DS-e41c85f6-3417-44f7-8b8f-80809eecfeea,DISK], DatanodeInfoWithStorage[127.0.0.1:42405,DS-058bf394-9aed-4ec9-8586-897aae7c2147,DISK], DatanodeInfoWithStorage[127.0.0.1:46393,DS-0d3bcb67-a962-4616-99bb-bb6eaee3104c,DISK], DatanodeInfoWithStorage[127.0.0.1:33929,DS-59663277-a34f-4d3a-ad6e-6a872f0c57c7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.reads
component: hdfs:NameNode
v1: true
v2: null
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1442875544-172.17.0.7-1596964152326:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37317,DS-791e38a3-0643-4f85-a531-7a4e69988f99,DISK], DatanodeInfoWithStorage[127.0.0.1:37830,DS-b1f6d17b-260d-4ac2-9b94-8d613a34c984,DISK], DatanodeInfoWithStorage[127.0.0.1:35273,DS-9ddea335-120e-4395-bca8-061d43ca2e27,DISK], DatanodeInfoWithStorage[127.0.0.1:37061,DS-60ab5f97-f4b6-4191-ac08-65da5ffb37b5,DISK], DatanodeInfoWithStorage[127.0.0.1:32842,DS-10cf39cd-77dd-478c-a24a-8b8b44d29810,DISK], DatanodeInfoWithStorage[127.0.0.1:35820,DS-8652b987-4baf-4fdb-99d5-30aac27a54a4,DISK], DatanodeInfoWithStorage[127.0.0.1:40576,DS-2d695d71-1475-4794-aa36-54e297077a73,DISK], DatanodeInfoWithStorage[127.0.0.1:37010,DS-38e752a3-e0a9-46b7-92b0-4c42379642b9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1442875544-172.17.0.7-1596964152326:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37317,DS-791e38a3-0643-4f85-a531-7a4e69988f99,DISK], DatanodeInfoWithStorage[127.0.0.1:37830,DS-b1f6d17b-260d-4ac2-9b94-8d613a34c984,DISK], DatanodeInfoWithStorage[127.0.0.1:35273,DS-9ddea335-120e-4395-bca8-061d43ca2e27,DISK], DatanodeInfoWithStorage[127.0.0.1:37061,DS-60ab5f97-f4b6-4191-ac08-65da5ffb37b5,DISK], DatanodeInfoWithStorage[127.0.0.1:32842,DS-10cf39cd-77dd-478c-a24a-8b8b44d29810,DISK], DatanodeInfoWithStorage[127.0.0.1:35820,DS-8652b987-4baf-4fdb-99d5-30aac27a54a4,DISK], DatanodeInfoWithStorage[127.0.0.1:40576,DS-2d695d71-1475-4794-aa36-54e297077a73,DISK], DatanodeInfoWithStorage[127.0.0.1:37010,DS-38e752a3-e0a9-46b7-92b0-4c42379642b9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.reads
component: hdfs:NameNode
v1: true
v2: null
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1970329665-172.17.0.7-1596964238813:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38823,DS-0530ea87-1528-4ef1-b31d-a5e8e52a2ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:44733,DS-bf27cfa8-9d3a-4986-9d9e-59ce8adca743,DISK], DatanodeInfoWithStorage[127.0.0.1:36209,DS-5b6c08e8-f04b-4e93-a949-555c442a2d64,DISK], DatanodeInfoWithStorage[127.0.0.1:45906,DS-39b7a677-f7a7-4084-9ce5-3591da8ce200,DISK], DatanodeInfoWithStorage[127.0.0.1:46848,DS-4b1757ff-9b60-4fd6-b235-519702d9b9e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43409,DS-700a6b50-38ff-4220-8f80-99641a7898e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38093,DS-33cf64ad-12d9-47db-99f0-c5f775a348d3,DISK], DatanodeInfoWithStorage[127.0.0.1:36901,DS-de67b61a-0640-4bfd-8523-0aecbece1ba0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1970329665-172.17.0.7-1596964238813:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38823,DS-0530ea87-1528-4ef1-b31d-a5e8e52a2ea7,DISK], DatanodeInfoWithStorage[127.0.0.1:44733,DS-bf27cfa8-9d3a-4986-9d9e-59ce8adca743,DISK], DatanodeInfoWithStorage[127.0.0.1:36209,DS-5b6c08e8-f04b-4e93-a949-555c442a2d64,DISK], DatanodeInfoWithStorage[127.0.0.1:45906,DS-39b7a677-f7a7-4084-9ce5-3591da8ce200,DISK], DatanodeInfoWithStorage[127.0.0.1:46848,DS-4b1757ff-9b60-4fd6-b235-519702d9b9e9,DISK], DatanodeInfoWithStorage[127.0.0.1:43409,DS-700a6b50-38ff-4220-8f80-99641a7898e1,DISK], DatanodeInfoWithStorage[127.0.0.1:38093,DS-33cf64ad-12d9-47db-99f0-c5f775a348d3,DISK], DatanodeInfoWithStorage[127.0.0.1:36901,DS-de67b61a-0640-4bfd-8523-0aecbece1ba0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.reads
component: hdfs:NameNode
v1: true
v2: null
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1961279328-172.17.0.7-1596964324568:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36523,DS-c3f29a36-2133-4e18-be51-ea9b6f63cdc0,DISK], DatanodeInfoWithStorage[127.0.0.1:41340,DS-dfff9b89-4b96-4a83-a944-499419f59e8a,DISK], DatanodeInfoWithStorage[127.0.0.1:46266,DS-780c6f7d-51e9-4381-a09a-761c30d90096,DISK], DatanodeInfoWithStorage[127.0.0.1:45842,DS-ce3d16c2-c429-4755-b47e-f5bec5c1e472,DISK], DatanodeInfoWithStorage[127.0.0.1:45064,DS-7d9e2aaa-c4eb-4f01-9c39-61b5a5843878,DISK], DatanodeInfoWithStorage[127.0.0.1:38746,DS-2cd54844-3585-45d1-892c-2c54cde762a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45125,DS-55c582cd-3cf1-4265-b709-d4af2633a591,DISK], DatanodeInfoWithStorage[127.0.0.1:45294,DS-58553487-79c5-4ac4-8c1d-c71842b36bba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1961279328-172.17.0.7-1596964324568:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36523,DS-c3f29a36-2133-4e18-be51-ea9b6f63cdc0,DISK], DatanodeInfoWithStorage[127.0.0.1:41340,DS-dfff9b89-4b96-4a83-a944-499419f59e8a,DISK], DatanodeInfoWithStorage[127.0.0.1:46266,DS-780c6f7d-51e9-4381-a09a-761c30d90096,DISK], DatanodeInfoWithStorage[127.0.0.1:45842,DS-ce3d16c2-c429-4755-b47e-f5bec5c1e472,DISK], DatanodeInfoWithStorage[127.0.0.1:45064,DS-7d9e2aaa-c4eb-4f01-9c39-61b5a5843878,DISK], DatanodeInfoWithStorage[127.0.0.1:38746,DS-2cd54844-3585-45d1-892c-2c54cde762a6,DISK], DatanodeInfoWithStorage[127.0.0.1:45125,DS-55c582cd-3cf1-4265-b709-d4af2633a591,DISK], DatanodeInfoWithStorage[127.0.0.1:45294,DS-58553487-79c5-4ac4-8c1d-c71842b36bba,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.reads
component: hdfs:NameNode
v1: true
v2: null
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2114804029-172.17.0.7-1596964685596:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37765,DS-637e75c1-789b-4163-bd00-680e607f3eec,DISK], DatanodeInfoWithStorage[127.0.0.1:46021,DS-38cd31f0-6dec-4ba5-8eb2-301d664f6b57,DISK], DatanodeInfoWithStorage[127.0.0.1:33784,DS-d09d0fb9-0854-477a-a197-2883400ba1d2,DISK], DatanodeInfoWithStorage[127.0.0.1:44745,DS-25ff07ec-b235-42f3-a3d5-d8a389573de2,DISK], DatanodeInfoWithStorage[127.0.0.1:37504,DS-5f46acf4-5c3a-407b-8d80-cc31479b912d,DISK], DatanodeInfoWithStorage[127.0.0.1:42605,DS-392eb12e-ccda-434f-bd14-a1d2ea38d36e,DISK], DatanodeInfoWithStorage[127.0.0.1:45524,DS-c18dde01-f1c8-4056-a93e-0679bb15c118,DISK], DatanodeInfoWithStorage[127.0.0.1:39469,DS-8b25ebd4-33f0-4a8c-a4d3-4ee435531495,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2114804029-172.17.0.7-1596964685596:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37765,DS-637e75c1-789b-4163-bd00-680e607f3eec,DISK], DatanodeInfoWithStorage[127.0.0.1:46021,DS-38cd31f0-6dec-4ba5-8eb2-301d664f6b57,DISK], DatanodeInfoWithStorage[127.0.0.1:33784,DS-d09d0fb9-0854-477a-a197-2883400ba1d2,DISK], DatanodeInfoWithStorage[127.0.0.1:44745,DS-25ff07ec-b235-42f3-a3d5-d8a389573de2,DISK], DatanodeInfoWithStorage[127.0.0.1:37504,DS-5f46acf4-5c3a-407b-8d80-cc31479b912d,DISK], DatanodeInfoWithStorage[127.0.0.1:42605,DS-392eb12e-ccda-434f-bd14-a1d2ea38d36e,DISK], DatanodeInfoWithStorage[127.0.0.1:45524,DS-c18dde01-f1c8-4056-a93e-0679bb15c118,DISK], DatanodeInfoWithStorage[127.0.0.1:39469,DS-8b25ebd4-33f0-4a8c-a4d3-4ee435531495,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.reads
component: hdfs:NameNode
v1: true
v2: null
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1028860353-172.17.0.7-1596964821508:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41436,DS-0e681d69-c877-432a-a56a-acbff029ae7b,DISK], DatanodeInfoWithStorage[127.0.0.1:34563,DS-dd800142-3c64-4573-85f3-d25721f787fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45717,DS-3087b19a-56eb-48c9-9d7c-5294d0c93638,DISK], DatanodeInfoWithStorage[127.0.0.1:46251,DS-7e645e81-8604-48e4-9bd8-5319bc128c77,DISK], DatanodeInfoWithStorage[127.0.0.1:44688,DS-091e02dd-8999-4c14-8aae-01483dea92f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42975,DS-97612fe0-8afa-4a06-9536-6f26195239ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39249,DS-9a1ac32b-b58a-4676-97ef-acb02512a93e,DISK], DatanodeInfoWithStorage[127.0.0.1:38192,DS-6353f21a-14d6-4b7f-beae-7cfc1e65236a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1028860353-172.17.0.7-1596964821508:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41436,DS-0e681d69-c877-432a-a56a-acbff029ae7b,DISK], DatanodeInfoWithStorage[127.0.0.1:34563,DS-dd800142-3c64-4573-85f3-d25721f787fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45717,DS-3087b19a-56eb-48c9-9d7c-5294d0c93638,DISK], DatanodeInfoWithStorage[127.0.0.1:46251,DS-7e645e81-8604-48e4-9bd8-5319bc128c77,DISK], DatanodeInfoWithStorage[127.0.0.1:44688,DS-091e02dd-8999-4c14-8aae-01483dea92f5,DISK], DatanodeInfoWithStorage[127.0.0.1:42975,DS-97612fe0-8afa-4a06-9536-6f26195239ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39249,DS-9a1ac32b-b58a-4676-97ef-acb02512a93e,DISK], DatanodeInfoWithStorage[127.0.0.1:38192,DS-6353f21a-14d6-4b7f-beae-7cfc1e65236a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.reads
component: hdfs:NameNode
v1: true
v2: null
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1373117426-172.17.0.7-1596964998274:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38467,DS-71c432e1-14df-468b-b521-da6e2389aa91,DISK], DatanodeInfoWithStorage[127.0.0.1:36966,DS-9b735e6d-b7e9-4125-8cce-60cea7902574,DISK], DatanodeInfoWithStorage[127.0.0.1:37883,DS-9c05afe4-d4aa-4cd5-b2d8-f1ae383488a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39102,DS-893c3d49-d450-4a5f-9579-dd426e71ccd4,DISK], DatanodeInfoWithStorage[127.0.0.1:36339,DS-89c299c3-4b4f-4595-9dd3-7414cb1156ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34680,DS-b0cbe53c-1cd9-4aad-92ad-ec31e25769a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35071,DS-22e35cef-dd07-4fe8-a72f-0072f9e7f65a,DISK], DatanodeInfoWithStorage[127.0.0.1:33442,DS-4b2c5f02-57ae-4420-84c4-6351932579b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1373117426-172.17.0.7-1596964998274:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38467,DS-71c432e1-14df-468b-b521-da6e2389aa91,DISK], DatanodeInfoWithStorage[127.0.0.1:36966,DS-9b735e6d-b7e9-4125-8cce-60cea7902574,DISK], DatanodeInfoWithStorage[127.0.0.1:37883,DS-9c05afe4-d4aa-4cd5-b2d8-f1ae383488a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39102,DS-893c3d49-d450-4a5f-9579-dd426e71ccd4,DISK], DatanodeInfoWithStorage[127.0.0.1:36339,DS-89c299c3-4b4f-4595-9dd3-7414cb1156ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34680,DS-b0cbe53c-1cd9-4aad-92ad-ec31e25769a4,DISK], DatanodeInfoWithStorage[127.0.0.1:35071,DS-22e35cef-dd07-4fe8-a72f-0072f9e7f65a,DISK], DatanodeInfoWithStorage[127.0.0.1:33442,DS-4b2c5f02-57ae-4420-84c4-6351932579b1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.reads
component: hdfs:NameNode
v1: true
v2: null
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-945009255-172.17.0.7-1596965162986:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40842,DS-36eb86a2-14fa-4fe5-992e-1e0b2b2e3db2,DISK], DatanodeInfoWithStorage[127.0.0.1:41753,DS-334e5317-1691-4654-b026-c80c87aafaa7,DISK], DatanodeInfoWithStorage[127.0.0.1:44293,DS-e9254ed6-5711-414d-8c8d-6f60d2fba355,DISK], DatanodeInfoWithStorage[127.0.0.1:37334,DS-6d44b921-3f3f-4e23-8dd9-5135f84a45c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41448,DS-20339128-dc2a-4584-9eaf-8707dfdcf9b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36410,DS-544502f5-a279-4d59-b8ed-be039949fe7c,DISK], DatanodeInfoWithStorage[127.0.0.1:42757,DS-94233404-9ffa-4e29-9e43-7f9e66b7c96b,DISK], DatanodeInfoWithStorage[127.0.0.1:46325,DS-30af5a8e-b5b5-4750-bed0-effd2e4d80c0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-945009255-172.17.0.7-1596965162986:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40842,DS-36eb86a2-14fa-4fe5-992e-1e0b2b2e3db2,DISK], DatanodeInfoWithStorage[127.0.0.1:41753,DS-334e5317-1691-4654-b026-c80c87aafaa7,DISK], DatanodeInfoWithStorage[127.0.0.1:44293,DS-e9254ed6-5711-414d-8c8d-6f60d2fba355,DISK], DatanodeInfoWithStorage[127.0.0.1:37334,DS-6d44b921-3f3f-4e23-8dd9-5135f84a45c6,DISK], DatanodeInfoWithStorage[127.0.0.1:41448,DS-20339128-dc2a-4584-9eaf-8707dfdcf9b5,DISK], DatanodeInfoWithStorage[127.0.0.1:36410,DS-544502f5-a279-4d59-b8ed-be039949fe7c,DISK], DatanodeInfoWithStorage[127.0.0.1:42757,DS-94233404-9ffa-4e29-9e43-7f9e66b7c96b,DISK], DatanodeInfoWithStorage[127.0.0.1:46325,DS-30af5a8e-b5b5-4750-bed0-effd2e4d80c0,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.reads
component: hdfs:NameNode
v1: true
v2: null
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-193324151-172.17.0.7-1596965321733:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39689,DS-27c5ad0c-5490-499a-9623-ce37a4531fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:39584,DS-8a757f4d-ec3a-4e92-a204-13e6d57e11bc,DISK], DatanodeInfoWithStorage[127.0.0.1:36248,DS-a536526f-e0ef-4296-a44e-db2e6abd046f,DISK], DatanodeInfoWithStorage[127.0.0.1:42239,DS-6afd3fae-3a96-481f-b7ca-473f2fd0e683,DISK], DatanodeInfoWithStorage[127.0.0.1:40849,DS-4b935cef-b2bb-4334-991f-c858ef4bd450,DISK], DatanodeInfoWithStorage[127.0.0.1:37250,DS-20181857-2072-4e5c-92c0-77e1ecdcf3f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43079,DS-8b7de96f-7505-4e8a-8f22-eada75d6adbe,DISK], DatanodeInfoWithStorage[127.0.0.1:34134,DS-794a14f0-73bb-414e-9524-5039ef5bd45b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-193324151-172.17.0.7-1596965321733:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39689,DS-27c5ad0c-5490-499a-9623-ce37a4531fa1,DISK], DatanodeInfoWithStorage[127.0.0.1:39584,DS-8a757f4d-ec3a-4e92-a204-13e6d57e11bc,DISK], DatanodeInfoWithStorage[127.0.0.1:36248,DS-a536526f-e0ef-4296-a44e-db2e6abd046f,DISK], DatanodeInfoWithStorage[127.0.0.1:42239,DS-6afd3fae-3a96-481f-b7ca-473f2fd0e683,DISK], DatanodeInfoWithStorage[127.0.0.1:40849,DS-4b935cef-b2bb-4334-991f-c858ef4bd450,DISK], DatanodeInfoWithStorage[127.0.0.1:37250,DS-20181857-2072-4e5c-92c0-77e1ecdcf3f9,DISK], DatanodeInfoWithStorage[127.0.0.1:43079,DS-8b7de96f-7505-4e8a-8f22-eada75d6adbe,DISK], DatanodeInfoWithStorage[127.0.0.1:34134,DS-794a14f0-73bb-414e-9524-5039ef5bd45b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.reads
component: hdfs:NameNode
v1: true
v2: null
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1246521605-172.17.0.7-1596965407624:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43408,DS-222d9a2c-0394-4afc-8f32-9e99055b061a,DISK], DatanodeInfoWithStorage[127.0.0.1:42822,DS-c48fbdc5-ef95-4b3a-abf5-f3ffda342113,DISK], DatanodeInfoWithStorage[127.0.0.1:46095,DS-86337ad4-702d-47e3-9925-d88c8c98015b,DISK], DatanodeInfoWithStorage[127.0.0.1:40274,DS-8cbb92cc-5e21-4e9c-9982-3f66f87c32e9,DISK], DatanodeInfoWithStorage[127.0.0.1:38812,DS-a71fd64b-5eb7-40e9-8d8d-2a1d520c449d,DISK], DatanodeInfoWithStorage[127.0.0.1:41511,DS-938c30e3-7d59-424e-ae0d-3029471ede62,DISK], DatanodeInfoWithStorage[127.0.0.1:38729,DS-7ef8855c-dd91-4ef4-b3ef-3fbb794a1275,DISK], DatanodeInfoWithStorage[127.0.0.1:37325,DS-26b7f2f2-9b29-42f2-9173-765af1b6b904,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1246521605-172.17.0.7-1596965407624:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43408,DS-222d9a2c-0394-4afc-8f32-9e99055b061a,DISK], DatanodeInfoWithStorage[127.0.0.1:42822,DS-c48fbdc5-ef95-4b3a-abf5-f3ffda342113,DISK], DatanodeInfoWithStorage[127.0.0.1:46095,DS-86337ad4-702d-47e3-9925-d88c8c98015b,DISK], DatanodeInfoWithStorage[127.0.0.1:40274,DS-8cbb92cc-5e21-4e9c-9982-3f66f87c32e9,DISK], DatanodeInfoWithStorage[127.0.0.1:38812,DS-a71fd64b-5eb7-40e9-8d8d-2a1d520c449d,DISK], DatanodeInfoWithStorage[127.0.0.1:41511,DS-938c30e3-7d59-424e-ae0d-3029471ede62,DISK], DatanodeInfoWithStorage[127.0.0.1:38729,DS-7ef8855c-dd91-4ef4-b3ef-3fbb794a1275,DISK], DatanodeInfoWithStorage[127.0.0.1:37325,DS-26b7f2f2-9b29-42f2-9173-765af1b6b904,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.reads
component: hdfs:NameNode
v1: true
v2: null
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1872563136-172.17.0.7-1596965755183:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33349,DS-ed6ac127-4043-4e90-a922-bbb6b5976a04,DISK], DatanodeInfoWithStorage[127.0.0.1:37276,DS-468432a8-b2b4-4535-ad34-e680ece8cd44,DISK], DatanodeInfoWithStorage[127.0.0.1:45224,DS-a6340f87-fda7-4dc9-b51e-3b0f30476ada,DISK], DatanodeInfoWithStorage[127.0.0.1:43935,DS-862e2249-2a8a-4ad8-ab48-caa311390fdc,DISK], DatanodeInfoWithStorage[127.0.0.1:45549,DS-aab3116e-1b58-4b08-a6a8-71c2ada8e599,DISK], DatanodeInfoWithStorage[127.0.0.1:41266,DS-68a0d8a5-395c-47e4-ad06-71d66f8e8e39,DISK], DatanodeInfoWithStorage[127.0.0.1:37610,DS-93298396-765b-48f0-afde-b77446bb40bd,DISK], DatanodeInfoWithStorage[127.0.0.1:46138,DS-be7eecc3-f3b5-4463-b0c8-cff481091bff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1872563136-172.17.0.7-1596965755183:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33349,DS-ed6ac127-4043-4e90-a922-bbb6b5976a04,DISK], DatanodeInfoWithStorage[127.0.0.1:37276,DS-468432a8-b2b4-4535-ad34-e680ece8cd44,DISK], DatanodeInfoWithStorage[127.0.0.1:45224,DS-a6340f87-fda7-4dc9-b51e-3b0f30476ada,DISK], DatanodeInfoWithStorage[127.0.0.1:43935,DS-862e2249-2a8a-4ad8-ab48-caa311390fdc,DISK], DatanodeInfoWithStorage[127.0.0.1:45549,DS-aab3116e-1b58-4b08-a6a8-71c2ada8e599,DISK], DatanodeInfoWithStorage[127.0.0.1:41266,DS-68a0d8a5-395c-47e4-ad06-71d66f8e8e39,DISK], DatanodeInfoWithStorage[127.0.0.1:37610,DS-93298396-765b-48f0-afde-b77446bb40bd,DISK], DatanodeInfoWithStorage[127.0.0.1:46138,DS-be7eecc3-f3b5-4463-b0c8-cff481091bff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.reads
component: hdfs:NameNode
v1: true
v2: null
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-209648353-172.17.0.7-1596965801009:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39327,DS-83804a91-c1f7-4739-9cdf-5e9ebc0863a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35373,DS-79cc51d5-38bf-4f48-90c5-260adf873cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:41249,DS-1ce5e5af-4f03-4640-bf33-28bafd3415e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36419,DS-856ad823-8c60-496d-92e9-4072e32b68db,DISK], DatanodeInfoWithStorage[127.0.0.1:41931,DS-bb05ca81-8b98-426b-b292-2c0109ffdfe3,DISK], DatanodeInfoWithStorage[127.0.0.1:33615,DS-466c5fde-1333-419e-beb3-b215907a1b89,DISK], DatanodeInfoWithStorage[127.0.0.1:32873,DS-5c0ec374-ad0b-489a-8931-d5d7bcbcd376,DISK], DatanodeInfoWithStorage[127.0.0.1:37315,DS-9320c62e-8e8b-4ee9-9f4b-fd199cd3151e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-209648353-172.17.0.7-1596965801009:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39327,DS-83804a91-c1f7-4739-9cdf-5e9ebc0863a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35373,DS-79cc51d5-38bf-4f48-90c5-260adf873cf5,DISK], DatanodeInfoWithStorage[127.0.0.1:41249,DS-1ce5e5af-4f03-4640-bf33-28bafd3415e7,DISK], DatanodeInfoWithStorage[127.0.0.1:36419,DS-856ad823-8c60-496d-92e9-4072e32b68db,DISK], DatanodeInfoWithStorage[127.0.0.1:41931,DS-bb05ca81-8b98-426b-b292-2c0109ffdfe3,DISK], DatanodeInfoWithStorage[127.0.0.1:33615,DS-466c5fde-1333-419e-beb3-b215907a1b89,DISK], DatanodeInfoWithStorage[127.0.0.1:32873,DS-5c0ec374-ad0b-489a-8931-d5d7bcbcd376,DISK], DatanodeInfoWithStorage[127.0.0.1:37315,DS-9320c62e-8e8b-4ee9-9f4b-fd199cd3151e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.reads
component: hdfs:NameNode
v1: true
v2: null
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-887862008-172.17.0.7-1596965898871:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41515,DS-6ffa42b8-ff23-4418-a939-fd2cc3dc596d,DISK], DatanodeInfoWithStorage[127.0.0.1:39917,DS-a78dc902-8a1f-4c2c-b429-35cea0c48a3f,DISK], DatanodeInfoWithStorage[127.0.0.1:43613,DS-ea51d2ad-d71c-4977-b4fd-2db9edc112e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41624,DS-4214ecae-72ba-4fcc-888b-2385d63e264b,DISK], DatanodeInfoWithStorage[127.0.0.1:35769,DS-0384e207-1338-4d83-b706-c181f5311767,DISK], DatanodeInfoWithStorage[127.0.0.1:44234,DS-7a09e225-9e66-4acd-98f7-9fa39a1929e0,DISK], DatanodeInfoWithStorage[127.0.0.1:39430,DS-5f08fd68-3f3f-485a-a156-493b95b8bb45,DISK], DatanodeInfoWithStorage[127.0.0.1:44429,DS-3ceea8d4-ffc9-4382-9d4d-2e4e8b53b0c1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-887862008-172.17.0.7-1596965898871:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41515,DS-6ffa42b8-ff23-4418-a939-fd2cc3dc596d,DISK], DatanodeInfoWithStorage[127.0.0.1:39917,DS-a78dc902-8a1f-4c2c-b429-35cea0c48a3f,DISK], DatanodeInfoWithStorage[127.0.0.1:43613,DS-ea51d2ad-d71c-4977-b4fd-2db9edc112e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41624,DS-4214ecae-72ba-4fcc-888b-2385d63e264b,DISK], DatanodeInfoWithStorage[127.0.0.1:35769,DS-0384e207-1338-4d83-b706-c181f5311767,DISK], DatanodeInfoWithStorage[127.0.0.1:44234,DS-7a09e225-9e66-4acd-98f7-9fa39a1929e0,DISK], DatanodeInfoWithStorage[127.0.0.1:39430,DS-5f08fd68-3f3f-485a-a156-493b95b8bb45,DISK], DatanodeInfoWithStorage[127.0.0.1:44429,DS-3ceea8d4-ffc9-4382-9d4d-2e4e8b53b0c1,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.reads
component: hdfs:NameNode
v1: true
v2: null
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2026595400-172.17.0.7-1596965943460:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35286,DS-273f33df-739d-48c6-92e2-3a372afc02e7,DISK], DatanodeInfoWithStorage[127.0.0.1:41003,DS-bd5ecaa0-35db-4626-abc7-b721d5bff14d,DISK], DatanodeInfoWithStorage[127.0.0.1:36893,DS-e06d1819-1cc8-4933-97e2-fd30c1df7824,DISK], DatanodeInfoWithStorage[127.0.0.1:39040,DS-ef5df56b-c25c-4ef8-94e7-f7984baa9898,DISK], DatanodeInfoWithStorage[127.0.0.1:39195,DS-24e3d337-d97e-41b6-b189-fa3ee4850624,DISK], DatanodeInfoWithStorage[127.0.0.1:41601,DS-c63a961e-2780-4b67-a4b9-088100c35e84,DISK], DatanodeInfoWithStorage[127.0.0.1:43950,DS-d0dbfed4-e40f-4f52-8e29-06677bcd9b25,DISK], DatanodeInfoWithStorage[127.0.0.1:46826,DS-23718a87-e620-41d7-a6fb-b77d38c3c528,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2026595400-172.17.0.7-1596965943460:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35286,DS-273f33df-739d-48c6-92e2-3a372afc02e7,DISK], DatanodeInfoWithStorage[127.0.0.1:41003,DS-bd5ecaa0-35db-4626-abc7-b721d5bff14d,DISK], DatanodeInfoWithStorage[127.0.0.1:36893,DS-e06d1819-1cc8-4933-97e2-fd30c1df7824,DISK], DatanodeInfoWithStorage[127.0.0.1:39040,DS-ef5df56b-c25c-4ef8-94e7-f7984baa9898,DISK], DatanodeInfoWithStorage[127.0.0.1:39195,DS-24e3d337-d97e-41b6-b189-fa3ee4850624,DISK], DatanodeInfoWithStorage[127.0.0.1:41601,DS-c63a961e-2780-4b67-a4b9-088100c35e84,DISK], DatanodeInfoWithStorage[127.0.0.1:43950,DS-d0dbfed4-e40f-4f52-8e29-06677bcd9b25,DISK], DatanodeInfoWithStorage[127.0.0.1:46826,DS-23718a87-e620-41d7-a6fb-b77d38c3c528,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.reads
component: hdfs:NameNode
v1: true
v2: null
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1311031592-172.17.0.7-1596966068377:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40792,DS-b6d72f30-8c50-4582-9608-c23f877a4d53,DISK], DatanodeInfoWithStorage[127.0.0.1:37374,DS-eb61cde7-1498-4e77-8abe-e03a467ec72f,DISK], DatanodeInfoWithStorage[127.0.0.1:46316,DS-9493b9f2-dae8-4c42-872e-cba0c88a6cb7,DISK], DatanodeInfoWithStorage[127.0.0.1:32971,DS-e136e89e-f0fd-4963-b776-ea874a7df64d,DISK], DatanodeInfoWithStorage[127.0.0.1:45130,DS-f629edc5-3c7d-4ad6-9fb5-cfa4baa11eca,DISK], DatanodeInfoWithStorage[127.0.0.1:34227,DS-32d98a1f-7df1-40ff-8f0f-46759575cb02,DISK], DatanodeInfoWithStorage[127.0.0.1:37389,DS-10f09c05-daca-4e17-a21f-a8ba4a1f190c,DISK], DatanodeInfoWithStorage[127.0.0.1:41780,DS-80336da1-7d57-4b4e-8120-f6db57aab0c9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1311031592-172.17.0.7-1596966068377:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40792,DS-b6d72f30-8c50-4582-9608-c23f877a4d53,DISK], DatanodeInfoWithStorage[127.0.0.1:37374,DS-eb61cde7-1498-4e77-8abe-e03a467ec72f,DISK], DatanodeInfoWithStorage[127.0.0.1:46316,DS-9493b9f2-dae8-4c42-872e-cba0c88a6cb7,DISK], DatanodeInfoWithStorage[127.0.0.1:32971,DS-e136e89e-f0fd-4963-b776-ea874a7df64d,DISK], DatanodeInfoWithStorage[127.0.0.1:45130,DS-f629edc5-3c7d-4ad6-9fb5-cfa4baa11eca,DISK], DatanodeInfoWithStorage[127.0.0.1:34227,DS-32d98a1f-7df1-40ff-8f0f-46759575cb02,DISK], DatanodeInfoWithStorage[127.0.0.1:37389,DS-10f09c05-daca-4e17-a21f-a8ba4a1f190c,DISK], DatanodeInfoWithStorage[127.0.0.1:41780,DS-80336da1-7d57-4b4e-8120-f6db57aab0c9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.reads
component: hdfs:NameNode
v1: true
v2: null
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1168973337-172.17.0.7-1596966464043:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34751,DS-c03c2748-5651-4df7-88c1-eadf4cdfc765,DISK], DatanodeInfoWithStorage[127.0.0.1:40906,DS-419652e3-a0f9-489c-aa0a-b07ec872c81b,DISK], DatanodeInfoWithStorage[127.0.0.1:44139,DS-22a38222-7950-4c2b-9e96-cadae0c0be91,DISK], DatanodeInfoWithStorage[127.0.0.1:35550,DS-4e36fba5-6641-4bac-b911-b6efd625b993,DISK], DatanodeInfoWithStorage[127.0.0.1:46236,DS-f4c7989e-6360-4843-b134-74c8e9fff393,DISK], DatanodeInfoWithStorage[127.0.0.1:46256,DS-234df151-9b99-4087-b1d2-2ac7297245af,DISK], DatanodeInfoWithStorage[127.0.0.1:34403,DS-756c162d-8e0c-4408-b305-328f1d61019e,DISK], DatanodeInfoWithStorage[127.0.0.1:46557,DS-6c3ba194-4f5c-482c-b706-bcb8409ce63f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1168973337-172.17.0.7-1596966464043:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34751,DS-c03c2748-5651-4df7-88c1-eadf4cdfc765,DISK], DatanodeInfoWithStorage[127.0.0.1:40906,DS-419652e3-a0f9-489c-aa0a-b07ec872c81b,DISK], DatanodeInfoWithStorage[127.0.0.1:44139,DS-22a38222-7950-4c2b-9e96-cadae0c0be91,DISK], DatanodeInfoWithStorage[127.0.0.1:35550,DS-4e36fba5-6641-4bac-b911-b6efd625b993,DISK], DatanodeInfoWithStorage[127.0.0.1:46236,DS-f4c7989e-6360-4843-b134-74c8e9fff393,DISK], DatanodeInfoWithStorage[127.0.0.1:46256,DS-234df151-9b99-4087-b1d2-2ac7297245af,DISK], DatanodeInfoWithStorage[127.0.0.1:34403,DS-756c162d-8e0c-4408-b305-328f1d61019e,DISK], DatanodeInfoWithStorage[127.0.0.1:46557,DS-6c3ba194-4f5c-482c-b706-bcb8409ce63f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.reads
component: hdfs:NameNode
v1: true
v2: null
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1886991644-172.17.0.7-1596966587420:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36255,DS-3f7fb374-683f-4151-9f86-b5d40b9340b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37526,DS-c2e1812f-f263-4e68-aeee-7cef98b641c4,DISK], DatanodeInfoWithStorage[127.0.0.1:40031,DS-67ae3f38-0f70-4401-9d5a-f03479b07f32,DISK], DatanodeInfoWithStorage[127.0.0.1:37334,DS-9cb5ba60-ccca-4fa0-9c20-3c9bafc88b21,DISK], DatanodeInfoWithStorage[127.0.0.1:41173,DS-56247fb6-4852-489e-81a0-e47d00fcb1c4,DISK], DatanodeInfoWithStorage[127.0.0.1:40191,DS-d0ab26a3-966a-4cb8-b61d-f8bc20f65ebe,DISK], DatanodeInfoWithStorage[127.0.0.1:43778,DS-49fc5607-858b-4619-8998-f88c0f951311,DISK], DatanodeInfoWithStorage[127.0.0.1:43862,DS-6470cb45-ddf8-4433-9b59-39affab5f280,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1886991644-172.17.0.7-1596966587420:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36255,DS-3f7fb374-683f-4151-9f86-b5d40b9340b5,DISK], DatanodeInfoWithStorage[127.0.0.1:37526,DS-c2e1812f-f263-4e68-aeee-7cef98b641c4,DISK], DatanodeInfoWithStorage[127.0.0.1:40031,DS-67ae3f38-0f70-4401-9d5a-f03479b07f32,DISK], DatanodeInfoWithStorage[127.0.0.1:37334,DS-9cb5ba60-ccca-4fa0-9c20-3c9bafc88b21,DISK], DatanodeInfoWithStorage[127.0.0.1:41173,DS-56247fb6-4852-489e-81a0-e47d00fcb1c4,DISK], DatanodeInfoWithStorage[127.0.0.1:40191,DS-d0ab26a3-966a-4cb8-b61d-f8bc20f65ebe,DISK], DatanodeInfoWithStorage[127.0.0.1:43778,DS-49fc5607-858b-4619-8998-f88c0f951311,DISK], DatanodeInfoWithStorage[127.0.0.1:43862,DS-6470cb45-ddf8-4433-9b59-39affab5f280,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.reads
component: hdfs:NameNode
v1: true
v2: null
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1186667940-172.17.0.7-1596966637676:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41842,DS-b886be59-f6dd-4737-8ed5-fd31bbabe011,DISK], DatanodeInfoWithStorage[127.0.0.1:36618,DS-99201340-70c1-4838-8e44-ba54feb2d1e7,DISK], DatanodeInfoWithStorage[127.0.0.1:38854,DS-3338962a-4ee6-49be-8b54-589bb69a7c6f,DISK], DatanodeInfoWithStorage[127.0.0.1:35019,DS-836df8cb-e0b3-4bdc-b2fa-5ec1adc634fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40221,DS-144469c1-997b-40f6-9998-bb59a11f2fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:45625,DS-c08332d4-243f-42b8-b163-458cca7aedf3,DISK], DatanodeInfoWithStorage[127.0.0.1:33816,DS-7ecf2a33-8c2f-462e-9d04-d55342d18069,DISK], DatanodeInfoWithStorage[127.0.0.1:41440,DS-773f9af8-6d4d-4e06-8fec-32048db75e11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1186667940-172.17.0.7-1596966637676:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41842,DS-b886be59-f6dd-4737-8ed5-fd31bbabe011,DISK], DatanodeInfoWithStorage[127.0.0.1:36618,DS-99201340-70c1-4838-8e44-ba54feb2d1e7,DISK], DatanodeInfoWithStorage[127.0.0.1:38854,DS-3338962a-4ee6-49be-8b54-589bb69a7c6f,DISK], DatanodeInfoWithStorage[127.0.0.1:35019,DS-836df8cb-e0b3-4bdc-b2fa-5ec1adc634fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40221,DS-144469c1-997b-40f6-9998-bb59a11f2fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:45625,DS-c08332d4-243f-42b8-b163-458cca7aedf3,DISK], DatanodeInfoWithStorage[127.0.0.1:33816,DS-7ecf2a33-8c2f-462e-9d04-d55342d18069,DISK], DatanodeInfoWithStorage[127.0.0.1:41440,DS-773f9af8-6d4d-4e06-8fec-32048db75e11,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.reads
component: hdfs:NameNode
v1: true
v2: null
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2040430443-172.17.0.7-1596966813590:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39192,DS-e845d868-5fdc-4124-8cbf-1606fee133fa,DISK], DatanodeInfoWithStorage[127.0.0.1:41840,DS-1fe18063-d532-42eb-a799-3fe35e313a62,DISK], DatanodeInfoWithStorage[127.0.0.1:35379,DS-f2639de5-0cee-4585-a914-4f4731c4018e,DISK], DatanodeInfoWithStorage[127.0.0.1:43888,DS-780d5777-148f-4ccf-b028-85f450bc8c46,DISK], DatanodeInfoWithStorage[127.0.0.1:45191,DS-1820b3da-80e0-41e4-89d5-884fd09132da,DISK], DatanodeInfoWithStorage[127.0.0.1:34557,DS-8835c3ca-6089-4820-838a-2abfdbff9677,DISK], DatanodeInfoWithStorage[127.0.0.1:41487,DS-a9727f45-de63-496f-a127-b762c2b9b701,DISK], DatanodeInfoWithStorage[127.0.0.1:41809,DS-23a39bef-1e56-457a-89d8-85da87d8987a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2040430443-172.17.0.7-1596966813590:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39192,DS-e845d868-5fdc-4124-8cbf-1606fee133fa,DISK], DatanodeInfoWithStorage[127.0.0.1:41840,DS-1fe18063-d532-42eb-a799-3fe35e313a62,DISK], DatanodeInfoWithStorage[127.0.0.1:35379,DS-f2639de5-0cee-4585-a914-4f4731c4018e,DISK], DatanodeInfoWithStorage[127.0.0.1:43888,DS-780d5777-148f-4ccf-b028-85f450bc8c46,DISK], DatanodeInfoWithStorage[127.0.0.1:45191,DS-1820b3da-80e0-41e4-89d5-884fd09132da,DISK], DatanodeInfoWithStorage[127.0.0.1:34557,DS-8835c3ca-6089-4820-838a-2abfdbff9677,DISK], DatanodeInfoWithStorage[127.0.0.1:41487,DS-a9727f45-de63-496f-a127-b762c2b9b701,DISK], DatanodeInfoWithStorage[127.0.0.1:41809,DS-23a39bef-1e56-457a-89d8-85da87d8987a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.reads
component: hdfs:NameNode
v1: true
v2: null
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1007817621-172.17.0.7-1596966896788:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35120,DS-3bd1a3cc-e60f-46a0-88bf-1381430aa3d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36226,DS-0f4969b8-2946-4980-8d54-dad5fd69e0a4,DISK], DatanodeInfoWithStorage[127.0.0.1:39488,DS-0c3d9f65-a8e8-4a86-a223-3ff6a8afb1bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38011,DS-1b176854-dcf3-4188-b9f8-25660b8157ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42318,DS-d70311e5-fb89-4def-88a7-14d9561e01ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34337,DS-5e6ff780-0b0a-45cc-a2d4-f1661375650d,DISK], DatanodeInfoWithStorage[127.0.0.1:37055,DS-cf021dab-cc30-4e13-b959-7fe05202d4c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36758,DS-c5ab10d9-e355-411f-9815-7540b80e5268,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1007817621-172.17.0.7-1596966896788:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35120,DS-3bd1a3cc-e60f-46a0-88bf-1381430aa3d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36226,DS-0f4969b8-2946-4980-8d54-dad5fd69e0a4,DISK], DatanodeInfoWithStorage[127.0.0.1:39488,DS-0c3d9f65-a8e8-4a86-a223-3ff6a8afb1bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38011,DS-1b176854-dcf3-4188-b9f8-25660b8157ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42318,DS-d70311e5-fb89-4def-88a7-14d9561e01ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34337,DS-5e6ff780-0b0a-45cc-a2d4-f1661375650d,DISK], DatanodeInfoWithStorage[127.0.0.1:37055,DS-cf021dab-cc30-4e13-b959-7fe05202d4c6,DISK], DatanodeInfoWithStorage[127.0.0.1:36758,DS-c5ab10d9-e355-411f-9815-7540b80e5268,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.cache.drop.behind.reads
component: hdfs:NameNode
v1: true
v2: null
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1354720930-172.17.0.7-1596966946196:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34009,DS-38051f34-cef6-4d2e-acdd-a70aec474803,DISK], DatanodeInfoWithStorage[127.0.0.1:46442,DS-e4fed117-1596-4803-a9ac-915bbbfbbfc1,DISK], DatanodeInfoWithStorage[127.0.0.1:41007,DS-3e83530c-ef2e-4065-9cde-e1d154a685e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36309,DS-62fd7a4c-20bc-4a61-86e2-0283bd492ddf,DISK], DatanodeInfoWithStorage[127.0.0.1:44489,DS-0e431cc6-046c-46fa-b56b-4d739909b98e,DISK], DatanodeInfoWithStorage[127.0.0.1:34883,DS-2495e084-b0d7-4277-be9b-732cd79f1cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:43834,DS-0f542605-636c-479d-8458-be084cc6f4b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43312,DS-1fbdb0db-29df-4397-9e19-3a01bdb56be0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1354720930-172.17.0.7-1596966946196:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34009,DS-38051f34-cef6-4d2e-acdd-a70aec474803,DISK], DatanodeInfoWithStorage[127.0.0.1:46442,DS-e4fed117-1596-4803-a9ac-915bbbfbbfc1,DISK], DatanodeInfoWithStorage[127.0.0.1:41007,DS-3e83530c-ef2e-4065-9cde-e1d154a685e8,DISK], DatanodeInfoWithStorage[127.0.0.1:36309,DS-62fd7a4c-20bc-4a61-86e2-0283bd492ddf,DISK], DatanodeInfoWithStorage[127.0.0.1:44489,DS-0e431cc6-046c-46fa-b56b-4d739909b98e,DISK], DatanodeInfoWithStorage[127.0.0.1:34883,DS-2495e084-b0d7-4277-be9b-732cd79f1cf0,DISK], DatanodeInfoWithStorage[127.0.0.1:43834,DS-0f542605-636c-479d-8458-be084cc6f4b0,DISK], DatanodeInfoWithStorage[127.0.0.1:43312,DS-1fbdb0db-29df-4397-9e19-3a01bdb56be0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.reads
component: hdfs:NameNode
v1: true
v2: null
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-301890092-172.17.0.7-1596967039268:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39809,DS-1e2a8d35-59df-4f9d-bba5-a7406c29c578,DISK], DatanodeInfoWithStorage[127.0.0.1:34066,DS-45b6f240-31dd-4d60-9224-2651038c5089,DISK], DatanodeInfoWithStorage[127.0.0.1:41887,DS-50c5e94d-6421-4e57-b492-e48c35c16fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:39475,DS-abade6b9-464c-4a94-a74b-5eb2d9ca3f4d,DISK], DatanodeInfoWithStorage[127.0.0.1:36101,DS-cdc160e8-e543-4412-b038-69698fefee48,DISK], DatanodeInfoWithStorage[127.0.0.1:41912,DS-15b00e29-4342-472a-9daf-8eb01f65f801,DISK], DatanodeInfoWithStorage[127.0.0.1:39915,DS-c951fcd0-5965-49c9-8fe7-95fe8a88c1c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43175,DS-5fa5e033-c5af-437f-a60f-1effd6a51b8a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-301890092-172.17.0.7-1596967039268:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39809,DS-1e2a8d35-59df-4f9d-bba5-a7406c29c578,DISK], DatanodeInfoWithStorage[127.0.0.1:34066,DS-45b6f240-31dd-4d60-9224-2651038c5089,DISK], DatanodeInfoWithStorage[127.0.0.1:41887,DS-50c5e94d-6421-4e57-b492-e48c35c16fb9,DISK], DatanodeInfoWithStorage[127.0.0.1:39475,DS-abade6b9-464c-4a94-a74b-5eb2d9ca3f4d,DISK], DatanodeInfoWithStorage[127.0.0.1:36101,DS-cdc160e8-e543-4412-b038-69698fefee48,DISK], DatanodeInfoWithStorage[127.0.0.1:41912,DS-15b00e29-4342-472a-9daf-8eb01f65f801,DISK], DatanodeInfoWithStorage[127.0.0.1:39915,DS-c951fcd0-5965-49c9-8fe7-95fe8a88c1c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43175,DS-5fa5e033-c5af-437f-a60f-1effd6a51b8a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.reads
component: hdfs:NameNode
v1: true
v2: null
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-314921379-172.17.0.7-1596967355033:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36656,DS-a2c3dc05-3ee4-459e-8b27-916365c16bad,DISK], DatanodeInfoWithStorage[127.0.0.1:36620,DS-08df850f-0c34-424a-83f9-7616ed866982,DISK], DatanodeInfoWithStorage[127.0.0.1:42240,DS-49f95788-1b1c-487c-ae81-b9901c48b11e,DISK], DatanodeInfoWithStorage[127.0.0.1:33687,DS-35c56284-c40f-42f4-99df-8a152b57eaa0,DISK], DatanodeInfoWithStorage[127.0.0.1:38278,DS-15840143-7fba-48c4-9287-2504105bec80,DISK], DatanodeInfoWithStorage[127.0.0.1:40237,DS-0b3bc1fc-db68-4d24-a890-7137626e721f,DISK], DatanodeInfoWithStorage[127.0.0.1:37585,DS-c31c9520-80ae-4e9d-87cc-cc30e3439f86,DISK], DatanodeInfoWithStorage[127.0.0.1:38895,DS-e2ab19ac-30ce-4908-987c-3d7d1a477e53,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-314921379-172.17.0.7-1596967355033:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36656,DS-a2c3dc05-3ee4-459e-8b27-916365c16bad,DISK], DatanodeInfoWithStorage[127.0.0.1:36620,DS-08df850f-0c34-424a-83f9-7616ed866982,DISK], DatanodeInfoWithStorage[127.0.0.1:42240,DS-49f95788-1b1c-487c-ae81-b9901c48b11e,DISK], DatanodeInfoWithStorage[127.0.0.1:33687,DS-35c56284-c40f-42f4-99df-8a152b57eaa0,DISK], DatanodeInfoWithStorage[127.0.0.1:38278,DS-15840143-7fba-48c4-9287-2504105bec80,DISK], DatanodeInfoWithStorage[127.0.0.1:40237,DS-0b3bc1fc-db68-4d24-a890-7137626e721f,DISK], DatanodeInfoWithStorage[127.0.0.1:37585,DS-c31c9520-80ae-4e9d-87cc-cc30e3439f86,DISK], DatanodeInfoWithStorage[127.0.0.1:38895,DS-e2ab19ac-30ce-4908-987c-3d7d1a477e53,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.reads
component: hdfs:NameNode
v1: true
v2: null
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-736697887-172.17.0.7-1596967441602:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41921,DS-466405e5-6385-4ab1-b52b-6f16675e8250,DISK], DatanodeInfoWithStorage[127.0.0.1:33844,DS-cbbd02c5-7b73-41b8-a3ea-dffb11e42fba,DISK], DatanodeInfoWithStorage[127.0.0.1:44333,DS-3de343d1-4493-48ec-a822-ca8ce94b98b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36467,DS-9cb84307-a707-4a9e-a274-cc02a8a2e10f,DISK], DatanodeInfoWithStorage[127.0.0.1:46489,DS-a8530d6a-013b-4687-8a49-82c569c1edb3,DISK], DatanodeInfoWithStorage[127.0.0.1:33957,DS-7017939f-7278-47ca-be2a-8b43ff41037b,DISK], DatanodeInfoWithStorage[127.0.0.1:35601,DS-229459b9-aa4c-415d-9af7-c75d2dfa9c89,DISK], DatanodeInfoWithStorage[127.0.0.1:42509,DS-584e9601-11b5-4ed7-a316-06cc2b6415e7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-736697887-172.17.0.7-1596967441602:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41921,DS-466405e5-6385-4ab1-b52b-6f16675e8250,DISK], DatanodeInfoWithStorage[127.0.0.1:33844,DS-cbbd02c5-7b73-41b8-a3ea-dffb11e42fba,DISK], DatanodeInfoWithStorage[127.0.0.1:44333,DS-3de343d1-4493-48ec-a822-ca8ce94b98b2,DISK], DatanodeInfoWithStorage[127.0.0.1:36467,DS-9cb84307-a707-4a9e-a274-cc02a8a2e10f,DISK], DatanodeInfoWithStorage[127.0.0.1:46489,DS-a8530d6a-013b-4687-8a49-82c569c1edb3,DISK], DatanodeInfoWithStorage[127.0.0.1:33957,DS-7017939f-7278-47ca-be2a-8b43ff41037b,DISK], DatanodeInfoWithStorage[127.0.0.1:35601,DS-229459b9-aa4c-415d-9af7-c75d2dfa9c89,DISK], DatanodeInfoWithStorage[127.0.0.1:42509,DS-584e9601-11b5-4ed7-a316-06cc2b6415e7,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.client.cache.drop.behind.reads
component: hdfs:NameNode
v1: true
v2: null
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1852414176-172.17.0.7-1596967504597:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36173,DS-cc9cc190-2637-40c2-ab40-d3f9af9fa074,DISK], DatanodeInfoWithStorage[127.0.0.1:44798,DS-50d7d24d-8a9c-4c80-9227-f00d26fea810,DISK], DatanodeInfoWithStorage[127.0.0.1:42320,DS-2ad4890a-b7c8-4060-922e-5b7049ba4d84,DISK], DatanodeInfoWithStorage[127.0.0.1:37493,DS-78fcfece-36f3-4b4a-866d-cc7e6b258a30,DISK], DatanodeInfoWithStorage[127.0.0.1:43615,DS-b796c2ea-4661-46a7-b024-08694f86508f,DISK], DatanodeInfoWithStorage[127.0.0.1:45456,DS-5f8cbdfe-22aa-4d43-a3b7-d8831b3ab48a,DISK], DatanodeInfoWithStorage[127.0.0.1:44500,DS-03f1ab48-4249-4d5f-9f45-79adb5a3fb4a,DISK], DatanodeInfoWithStorage[127.0.0.1:43726,DS-2dfc5556-fac8-4a5a-bf46-eab98d597d98,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1852414176-172.17.0.7-1596967504597:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36173,DS-cc9cc190-2637-40c2-ab40-d3f9af9fa074,DISK], DatanodeInfoWithStorage[127.0.0.1:44798,DS-50d7d24d-8a9c-4c80-9227-f00d26fea810,DISK], DatanodeInfoWithStorage[127.0.0.1:42320,DS-2ad4890a-b7c8-4060-922e-5b7049ba4d84,DISK], DatanodeInfoWithStorage[127.0.0.1:37493,DS-78fcfece-36f3-4b4a-866d-cc7e6b258a30,DISK], DatanodeInfoWithStorage[127.0.0.1:43615,DS-b796c2ea-4661-46a7-b024-08694f86508f,DISK], DatanodeInfoWithStorage[127.0.0.1:45456,DS-5f8cbdfe-22aa-4d43-a3b7-d8831b3ab48a,DISK], DatanodeInfoWithStorage[127.0.0.1:44500,DS-03f1ab48-4249-4d5f-9f45-79adb5a3fb4a,DISK], DatanodeInfoWithStorage[127.0.0.1:43726,DS-2dfc5556-fac8-4a5a-bf46-eab98d597d98,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.cache.drop.behind.reads
component: hdfs:NameNode
v1: true
v2: null
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1305697504-172.17.0.7-1596967636643:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37033,DS-88bedd84-a589-43fc-a49e-dd08a57003f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35674,DS-a00c7a17-4bed-43a9-b88c-fa149340f151,DISK], DatanodeInfoWithStorage[127.0.0.1:38736,DS-2274d1bb-a207-4173-a200-5fbed58f06e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42740,DS-b9e70805-9409-4c35-8d0a-38028c344882,DISK], DatanodeInfoWithStorage[127.0.0.1:43240,DS-fdec82a6-712f-4dda-bb29-998995a7f926,DISK], DatanodeInfoWithStorage[127.0.0.1:41373,DS-214ebaae-bcc9-4817-beb4-975fef8b501b,DISK], DatanodeInfoWithStorage[127.0.0.1:34204,DS-46805493-679a-4d5f-ad52-d9b161f8fd78,DISK], DatanodeInfoWithStorage[127.0.0.1:34219,DS-19df8f4f-32f1-459a-9c06-046654dfd8eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1305697504-172.17.0.7-1596967636643:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37033,DS-88bedd84-a589-43fc-a49e-dd08a57003f8,DISK], DatanodeInfoWithStorage[127.0.0.1:35674,DS-a00c7a17-4bed-43a9-b88c-fa149340f151,DISK], DatanodeInfoWithStorage[127.0.0.1:38736,DS-2274d1bb-a207-4173-a200-5fbed58f06e9,DISK], DatanodeInfoWithStorage[127.0.0.1:42740,DS-b9e70805-9409-4c35-8d0a-38028c344882,DISK], DatanodeInfoWithStorage[127.0.0.1:43240,DS-fdec82a6-712f-4dda-bb29-998995a7f926,DISK], DatanodeInfoWithStorage[127.0.0.1:41373,DS-214ebaae-bcc9-4817-beb4-975fef8b501b,DISK], DatanodeInfoWithStorage[127.0.0.1:34204,DS-46805493-679a-4d5f-ad52-d9b161f8fd78,DISK], DatanodeInfoWithStorage[127.0.0.1:34219,DS-19df8f4f-32f1-459a-9c06-046654dfd8eb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 11 out of 50
v1v1v2v2 failed with probability 28 out of 50
result: false positive !!!
Total execution time in seconds : 6568
