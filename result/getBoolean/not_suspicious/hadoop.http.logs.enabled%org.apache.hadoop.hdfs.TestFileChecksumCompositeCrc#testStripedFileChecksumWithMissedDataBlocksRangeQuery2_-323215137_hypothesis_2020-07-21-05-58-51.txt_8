reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1946994649-172.17.0.8-1595311257960:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38671,DS-1ce9e4d0-264c-4a20-9cb9-8f45e9a2dfbf,DISK], DatanodeInfoWithStorage[127.0.0.1:35313,DS-182194b6-05a9-4294-8f05-3d86ad925155,DISK], DatanodeInfoWithStorage[127.0.0.1:43680,DS-9ac06fa9-3e5a-480d-bbb1-8af4fe0adcca,DISK], DatanodeInfoWithStorage[127.0.0.1:38121,DS-d112a185-fa96-4baf-8075-ee3925c04666,DISK], DatanodeInfoWithStorage[127.0.0.1:46854,DS-4eca85d9-7a99-4799-b470-8276ff919229,DISK], DatanodeInfoWithStorage[127.0.0.1:35422,DS-0645c1c4-915b-46d0-885a-05b4e2e817d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43955,DS-88c3bd20-0ba1-4679-8113-448da9f62638,DISK], DatanodeInfoWithStorage[127.0.0.1:42428,DS-3a1d4184-1dae-4c68-942e-d46483705c9d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1946994649-172.17.0.8-1595311257960:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38671,DS-1ce9e4d0-264c-4a20-9cb9-8f45e9a2dfbf,DISK], DatanodeInfoWithStorage[127.0.0.1:35313,DS-182194b6-05a9-4294-8f05-3d86ad925155,DISK], DatanodeInfoWithStorage[127.0.0.1:43680,DS-9ac06fa9-3e5a-480d-bbb1-8af4fe0adcca,DISK], DatanodeInfoWithStorage[127.0.0.1:38121,DS-d112a185-fa96-4baf-8075-ee3925c04666,DISK], DatanodeInfoWithStorage[127.0.0.1:46854,DS-4eca85d9-7a99-4799-b470-8276ff919229,DISK], DatanodeInfoWithStorage[127.0.0.1:35422,DS-0645c1c4-915b-46d0-885a-05b4e2e817d8,DISK], DatanodeInfoWithStorage[127.0.0.1:43955,DS-88c3bd20-0ba1-4679-8113-448da9f62638,DISK], DatanodeInfoWithStorage[127.0.0.1:42428,DS-3a1d4184-1dae-4c68-942e-d46483705c9d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-609656549-172.17.0.8-1595311356983:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43009,DS-8798eeca-01ea-447a-92f7-0bf925d5f746,DISK], DatanodeInfoWithStorage[127.0.0.1:34518,DS-cd3e8cda-972b-4d25-a340-06ef29bacd86,DISK], DatanodeInfoWithStorage[127.0.0.1:35509,DS-5cd933a6-1791-43d2-941f-6ebe4fb88884,DISK], DatanodeInfoWithStorage[127.0.0.1:34367,DS-5cfa30aa-996a-45ad-a52d-ef3f79c5277f,DISK], DatanodeInfoWithStorage[127.0.0.1:40148,DS-f0e2f8e3-5bab-4d42-9f6a-0105a9cea420,DISK], DatanodeInfoWithStorage[127.0.0.1:42383,DS-66c61d58-16cd-4599-9305-fa172f642d17,DISK], DatanodeInfoWithStorage[127.0.0.1:43026,DS-6b163cfd-73c0-43bc-81d2-f24f7c2a8ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:36751,DS-f11094f5-13ab-4508-90c3-21417d485604,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-609656549-172.17.0.8-1595311356983:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43009,DS-8798eeca-01ea-447a-92f7-0bf925d5f746,DISK], DatanodeInfoWithStorage[127.0.0.1:34518,DS-cd3e8cda-972b-4d25-a340-06ef29bacd86,DISK], DatanodeInfoWithStorage[127.0.0.1:35509,DS-5cd933a6-1791-43d2-941f-6ebe4fb88884,DISK], DatanodeInfoWithStorage[127.0.0.1:34367,DS-5cfa30aa-996a-45ad-a52d-ef3f79c5277f,DISK], DatanodeInfoWithStorage[127.0.0.1:40148,DS-f0e2f8e3-5bab-4d42-9f6a-0105a9cea420,DISK], DatanodeInfoWithStorage[127.0.0.1:42383,DS-66c61d58-16cd-4599-9305-fa172f642d17,DISK], DatanodeInfoWithStorage[127.0.0.1:43026,DS-6b163cfd-73c0-43bc-81d2-f24f7c2a8ab9,DISK], DatanodeInfoWithStorage[127.0.0.1:36751,DS-f11094f5-13ab-4508-90c3-21417d485604,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1336006980-172.17.0.8-1595311537483:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40053,DS-9cd0a6a0-5069-4e95-9007-91d43ae3a865,DISK], DatanodeInfoWithStorage[127.0.0.1:41075,DS-c11f92bc-0c2d-4abc-a77a-e4ed71132e96,DISK], DatanodeInfoWithStorage[127.0.0.1:45699,DS-96611aea-6165-486d-a865-b2621f9cdca9,DISK], DatanodeInfoWithStorage[127.0.0.1:33860,DS-3c82fd40-8171-4ae3-b8ee-0e9d7e8ed233,DISK], DatanodeInfoWithStorage[127.0.0.1:43881,DS-150e0266-eba0-4456-9197-1cb88e8391d5,DISK], DatanodeInfoWithStorage[127.0.0.1:37979,DS-2c7dcf82-62ea-468b-9d2d-c4196d32f7fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38306,DS-2c2f0863-eeef-4b0f-b933-b1fbf8d526b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33056,DS-676844a3-e103-4420-b217-f25d59b6e3ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1336006980-172.17.0.8-1595311537483:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40053,DS-9cd0a6a0-5069-4e95-9007-91d43ae3a865,DISK], DatanodeInfoWithStorage[127.0.0.1:41075,DS-c11f92bc-0c2d-4abc-a77a-e4ed71132e96,DISK], DatanodeInfoWithStorage[127.0.0.1:45699,DS-96611aea-6165-486d-a865-b2621f9cdca9,DISK], DatanodeInfoWithStorage[127.0.0.1:33860,DS-3c82fd40-8171-4ae3-b8ee-0e9d7e8ed233,DISK], DatanodeInfoWithStorage[127.0.0.1:43881,DS-150e0266-eba0-4456-9197-1cb88e8391d5,DISK], DatanodeInfoWithStorage[127.0.0.1:37979,DS-2c7dcf82-62ea-468b-9d2d-c4196d32f7fa,DISK], DatanodeInfoWithStorage[127.0.0.1:38306,DS-2c2f0863-eeef-4b0f-b933-b1fbf8d526b1,DISK], DatanodeInfoWithStorage[127.0.0.1:33056,DS-676844a3-e103-4420-b217-f25d59b6e3ae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1155397287-172.17.0.8-1595311567414:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37744,DS-75ede6db-0c2e-4b42-ab97-b02fe03ba98e,DISK], DatanodeInfoWithStorage[127.0.0.1:41797,DS-5ecceb4e-fcf7-4ab0-8c25-7bcd2ee95fef,DISK], DatanodeInfoWithStorage[127.0.0.1:40384,DS-5e2a112e-2167-4a4b-ba04-3cf124722bbe,DISK], DatanodeInfoWithStorage[127.0.0.1:34528,DS-49dd8445-7941-4802-bba5-f14cb08344af,DISK], DatanodeInfoWithStorage[127.0.0.1:37928,DS-b0da2044-4c7f-44e5-a3e3-903cfc74428f,DISK], DatanodeInfoWithStorage[127.0.0.1:37202,DS-68d14f1a-4971-40c0-88b1-7b6c64d984a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43300,DS-7d922e67-8320-4317-8555-d82e3d0ecf1d,DISK], DatanodeInfoWithStorage[127.0.0.1:41622,DS-334b63de-137e-48d4-9213-049044bce718,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1155397287-172.17.0.8-1595311567414:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37744,DS-75ede6db-0c2e-4b42-ab97-b02fe03ba98e,DISK], DatanodeInfoWithStorage[127.0.0.1:41797,DS-5ecceb4e-fcf7-4ab0-8c25-7bcd2ee95fef,DISK], DatanodeInfoWithStorage[127.0.0.1:40384,DS-5e2a112e-2167-4a4b-ba04-3cf124722bbe,DISK], DatanodeInfoWithStorage[127.0.0.1:34528,DS-49dd8445-7941-4802-bba5-f14cb08344af,DISK], DatanodeInfoWithStorage[127.0.0.1:37928,DS-b0da2044-4c7f-44e5-a3e3-903cfc74428f,DISK], DatanodeInfoWithStorage[127.0.0.1:37202,DS-68d14f1a-4971-40c0-88b1-7b6c64d984a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43300,DS-7d922e67-8320-4317-8555-d82e3d0ecf1d,DISK], DatanodeInfoWithStorage[127.0.0.1:41622,DS-334b63de-137e-48d4-9213-049044bce718,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-192089321-172.17.0.8-1595311876382:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38163,DS-cddddcf0-d90d-4b73-9cf4-2d0addde0619,DISK], DatanodeInfoWithStorage[127.0.0.1:35661,DS-5260b210-5027-464b-8468-83b2bf95d7ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38176,DS-c11b7d96-c459-4fc4-aef3-61c6e3b5160a,DISK], DatanodeInfoWithStorage[127.0.0.1:33102,DS-9a04389b-1eb7-4a4c-aba1-edb5352ee6d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38092,DS-0bd319f9-2208-41d7-8941-2401c2b6ed12,DISK], DatanodeInfoWithStorage[127.0.0.1:42138,DS-1175632e-1419-4c9c-9d56-64e9b4e19290,DISK], DatanodeInfoWithStorage[127.0.0.1:44507,DS-8711a24d-ccdb-4280-a543-420ee33e83ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35741,DS-c61ac727-6833-4f89-a82a-6eebe4e657a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-192089321-172.17.0.8-1595311876382:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38163,DS-cddddcf0-d90d-4b73-9cf4-2d0addde0619,DISK], DatanodeInfoWithStorage[127.0.0.1:35661,DS-5260b210-5027-464b-8468-83b2bf95d7ee,DISK], DatanodeInfoWithStorage[127.0.0.1:38176,DS-c11b7d96-c459-4fc4-aef3-61c6e3b5160a,DISK], DatanodeInfoWithStorage[127.0.0.1:33102,DS-9a04389b-1eb7-4a4c-aba1-edb5352ee6d3,DISK], DatanodeInfoWithStorage[127.0.0.1:38092,DS-0bd319f9-2208-41d7-8941-2401c2b6ed12,DISK], DatanodeInfoWithStorage[127.0.0.1:42138,DS-1175632e-1419-4c9c-9d56-64e9b4e19290,DISK], DatanodeInfoWithStorage[127.0.0.1:44507,DS-8711a24d-ccdb-4280-a543-420ee33e83ad,DISK], DatanodeInfoWithStorage[127.0.0.1:35741,DS-c61ac727-6833-4f89-a82a-6eebe4e657a9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1315188896-172.17.0.8-1595312385644:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36206,DS-07dd9909-f973-4330-bee6-6a6d477dee26,DISK], DatanodeInfoWithStorage[127.0.0.1:41924,DS-efa5fc2e-6ad7-41cc-9796-abfa00af1349,DISK], DatanodeInfoWithStorage[127.0.0.1:42043,DS-6c7275b7-f637-431f-aeab-69b7903485a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42776,DS-28a7cd75-0630-4076-9e25-10377ea9ffa8,DISK], DatanodeInfoWithStorage[127.0.0.1:45813,DS-82e3e564-d990-44ff-900f-95b6b2f7709d,DISK], DatanodeInfoWithStorage[127.0.0.1:44358,DS-09f0b5a7-99d7-4dec-b568-34f24b0d0d8e,DISK], DatanodeInfoWithStorage[127.0.0.1:45281,DS-a1810b0c-552b-4f42-9f5e-5f79fd423f62,DISK], DatanodeInfoWithStorage[127.0.0.1:45131,DS-2c4ec138-de8b-472b-9998-2ad4dd8a83cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1315188896-172.17.0.8-1595312385644:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36206,DS-07dd9909-f973-4330-bee6-6a6d477dee26,DISK], DatanodeInfoWithStorage[127.0.0.1:41924,DS-efa5fc2e-6ad7-41cc-9796-abfa00af1349,DISK], DatanodeInfoWithStorage[127.0.0.1:42043,DS-6c7275b7-f637-431f-aeab-69b7903485a8,DISK], DatanodeInfoWithStorage[127.0.0.1:42776,DS-28a7cd75-0630-4076-9e25-10377ea9ffa8,DISK], DatanodeInfoWithStorage[127.0.0.1:45813,DS-82e3e564-d990-44ff-900f-95b6b2f7709d,DISK], DatanodeInfoWithStorage[127.0.0.1:44358,DS-09f0b5a7-99d7-4dec-b568-34f24b0d0d8e,DISK], DatanodeInfoWithStorage[127.0.0.1:45281,DS-a1810b0c-552b-4f42-9f5e-5f79fd423f62,DISK], DatanodeInfoWithStorage[127.0.0.1:45131,DS-2c4ec138-de8b-472b-9998-2ad4dd8a83cc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-770372972-172.17.0.8-1595313048375:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45776,DS-6a508a87-b113-4ad2-b227-1bf9e5ce3669,DISK], DatanodeInfoWithStorage[127.0.0.1:44905,DS-4a807349-3ce8-495a-b73e-efd682315917,DISK], DatanodeInfoWithStorage[127.0.0.1:46562,DS-3255948f-bc17-41b8-be26-aa4875e087a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37731,DS-639af2c0-f3fe-41c4-b94c-c31199241044,DISK], DatanodeInfoWithStorage[127.0.0.1:33826,DS-07c0356a-cfd0-4734-ac56-1a32d540b034,DISK], DatanodeInfoWithStorage[127.0.0.1:35592,DS-71a6013c-2dee-4a2a-af81-410f41aa0714,DISK], DatanodeInfoWithStorage[127.0.0.1:44465,DS-4482eb11-d49b-489f-bdc8-185f554a3a28,DISK], DatanodeInfoWithStorage[127.0.0.1:40375,DS-e2cfb31a-a326-4ff5-b425-95dd1d53fce6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-770372972-172.17.0.8-1595313048375:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45776,DS-6a508a87-b113-4ad2-b227-1bf9e5ce3669,DISK], DatanodeInfoWithStorage[127.0.0.1:44905,DS-4a807349-3ce8-495a-b73e-efd682315917,DISK], DatanodeInfoWithStorage[127.0.0.1:46562,DS-3255948f-bc17-41b8-be26-aa4875e087a0,DISK], DatanodeInfoWithStorage[127.0.0.1:37731,DS-639af2c0-f3fe-41c4-b94c-c31199241044,DISK], DatanodeInfoWithStorage[127.0.0.1:33826,DS-07c0356a-cfd0-4734-ac56-1a32d540b034,DISK], DatanodeInfoWithStorage[127.0.0.1:35592,DS-71a6013c-2dee-4a2a-af81-410f41aa0714,DISK], DatanodeInfoWithStorage[127.0.0.1:44465,DS-4482eb11-d49b-489f-bdc8-185f554a3a28,DISK], DatanodeInfoWithStorage[127.0.0.1:40375,DS-e2cfb31a-a326-4ff5-b425-95dd1d53fce6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1903057032-172.17.0.8-1595313320308:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44128,DS-01ee5370-0441-4c5d-8676-f115501b5646,DISK], DatanodeInfoWithStorage[127.0.0.1:40528,DS-27b4482c-ca72-4170-bc10-cf6b034fc2da,DISK], DatanodeInfoWithStorage[127.0.0.1:33430,DS-71631307-bd50-455a-b8d2-919296a2563a,DISK], DatanodeInfoWithStorage[127.0.0.1:41238,DS-99b5a4d8-4fa1-4488-9ec4-1a15b867b5d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34411,DS-90b8b5c3-0b34-45de-8d72-498dd90ff0d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44860,DS-044ab647-929f-4fac-a295-dbba06f46fee,DISK], DatanodeInfoWithStorage[127.0.0.1:44222,DS-3377f713-01b5-4e7f-b04a-5c626daaf474,DISK], DatanodeInfoWithStorage[127.0.0.1:37481,DS-8264f4c2-d756-43b7-b4bc-c18da0e6f699,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1903057032-172.17.0.8-1595313320308:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44128,DS-01ee5370-0441-4c5d-8676-f115501b5646,DISK], DatanodeInfoWithStorage[127.0.0.1:40528,DS-27b4482c-ca72-4170-bc10-cf6b034fc2da,DISK], DatanodeInfoWithStorage[127.0.0.1:33430,DS-71631307-bd50-455a-b8d2-919296a2563a,DISK], DatanodeInfoWithStorage[127.0.0.1:41238,DS-99b5a4d8-4fa1-4488-9ec4-1a15b867b5d1,DISK], DatanodeInfoWithStorage[127.0.0.1:34411,DS-90b8b5c3-0b34-45de-8d72-498dd90ff0d8,DISK], DatanodeInfoWithStorage[127.0.0.1:44860,DS-044ab647-929f-4fac-a295-dbba06f46fee,DISK], DatanodeInfoWithStorage[127.0.0.1:44222,DS-3377f713-01b5-4e7f-b04a-5c626daaf474,DISK], DatanodeInfoWithStorage[127.0.0.1:37481,DS-8264f4c2-d756-43b7-b4bc-c18da0e6f699,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-978574070-172.17.0.8-1595313477569:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38624,DS-35a4bd77-c86e-4d4d-90fd-9706e840b74b,DISK], DatanodeInfoWithStorage[127.0.0.1:35971,DS-2a2265b7-d747-46ae-ae34-b11ca003489d,DISK], DatanodeInfoWithStorage[127.0.0.1:38943,DS-defed2ca-2a77-4d79-98fd-eef2e9e2a23e,DISK], DatanodeInfoWithStorage[127.0.0.1:42798,DS-ec6c369c-b365-43c5-9c49-4995a509f8c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45578,DS-855da870-e501-4322-bcb8-6648e9c9886c,DISK], DatanodeInfoWithStorage[127.0.0.1:43923,DS-39926e94-8da3-4022-bfed-bff2dc0ef9f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39937,DS-26d25295-4d35-43e9-8043-318db5d6648b,DISK], DatanodeInfoWithStorage[127.0.0.1:42743,DS-e29809f0-2bce-47b2-8f42-83f8e6fd87f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-978574070-172.17.0.8-1595313477569:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38624,DS-35a4bd77-c86e-4d4d-90fd-9706e840b74b,DISK], DatanodeInfoWithStorage[127.0.0.1:35971,DS-2a2265b7-d747-46ae-ae34-b11ca003489d,DISK], DatanodeInfoWithStorage[127.0.0.1:38943,DS-defed2ca-2a77-4d79-98fd-eef2e9e2a23e,DISK], DatanodeInfoWithStorage[127.0.0.1:42798,DS-ec6c369c-b365-43c5-9c49-4995a509f8c5,DISK], DatanodeInfoWithStorage[127.0.0.1:45578,DS-855da870-e501-4322-bcb8-6648e9c9886c,DISK], DatanodeInfoWithStorage[127.0.0.1:43923,DS-39926e94-8da3-4022-bfed-bff2dc0ef9f7,DISK], DatanodeInfoWithStorage[127.0.0.1:39937,DS-26d25295-4d35-43e9-8043-318db5d6648b,DISK], DatanodeInfoWithStorage[127.0.0.1:42743,DS-e29809f0-2bce-47b2-8f42-83f8e6fd87f9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-15920518-172.17.0.8-1595314170078:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43952,DS-bdbe76fd-a893-4b91-9e1e-b530f355deac,DISK], DatanodeInfoWithStorage[127.0.0.1:36807,DS-58f19e96-f98e-48c1-9342-50b6f3963077,DISK], DatanodeInfoWithStorage[127.0.0.1:39903,DS-2f078e52-789f-48fb-9d7e-640fdc3f04bb,DISK], DatanodeInfoWithStorage[127.0.0.1:32842,DS-c2c5619d-0fd4-40c0-b554-794dc40d54e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36821,DS-0cdca57f-aa74-4e81-81df-aa2410689dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:41157,DS-602bd5a8-0cf0-4f77-955d-e0a7ed26ad4e,DISK], DatanodeInfoWithStorage[127.0.0.1:33101,DS-894c7d63-c34a-4a12-b60c-da10152e3398,DISK], DatanodeInfoWithStorage[127.0.0.1:42980,DS-30bd798b-1438-4427-8d08-beda1fc11c31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-15920518-172.17.0.8-1595314170078:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43952,DS-bdbe76fd-a893-4b91-9e1e-b530f355deac,DISK], DatanodeInfoWithStorage[127.0.0.1:36807,DS-58f19e96-f98e-48c1-9342-50b6f3963077,DISK], DatanodeInfoWithStorage[127.0.0.1:39903,DS-2f078e52-789f-48fb-9d7e-640fdc3f04bb,DISK], DatanodeInfoWithStorage[127.0.0.1:32842,DS-c2c5619d-0fd4-40c0-b554-794dc40d54e3,DISK], DatanodeInfoWithStorage[127.0.0.1:36821,DS-0cdca57f-aa74-4e81-81df-aa2410689dfa,DISK], DatanodeInfoWithStorage[127.0.0.1:41157,DS-602bd5a8-0cf0-4f77-955d-e0a7ed26ad4e,DISK], DatanodeInfoWithStorage[127.0.0.1:33101,DS-894c7d63-c34a-4a12-b60c-da10152e3398,DISK], DatanodeInfoWithStorage[127.0.0.1:42980,DS-30bd798b-1438-4427-8d08-beda1fc11c31,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1337901318-172.17.0.8-1595314375278:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45732,DS-94072ff8-91fe-4221-8b80-e812c084a61a,DISK], DatanodeInfoWithStorage[127.0.0.1:34969,DS-6273e630-914b-4098-89a6-2fe6402d8d7a,DISK], DatanodeInfoWithStorage[127.0.0.1:42637,DS-ee742078-112e-4017-b5e5-b26ca0e810c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43952,DS-99d7d823-b457-4e0b-8677-600b530f3738,DISK], DatanodeInfoWithStorage[127.0.0.1:43687,DS-fcc1be89-980e-4371-a2db-8620b1b1a9c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44407,DS-087c9d9e-388d-4c3c-b7fc-3bf75accc286,DISK], DatanodeInfoWithStorage[127.0.0.1:33193,DS-44f8474e-4f4d-4208-8c6d-82a725a1efd5,DISK], DatanodeInfoWithStorage[127.0.0.1:36605,DS-b6bd1d69-c8a8-42cc-847f-c57b46aafcde,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1337901318-172.17.0.8-1595314375278:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45732,DS-94072ff8-91fe-4221-8b80-e812c084a61a,DISK], DatanodeInfoWithStorage[127.0.0.1:34969,DS-6273e630-914b-4098-89a6-2fe6402d8d7a,DISK], DatanodeInfoWithStorage[127.0.0.1:42637,DS-ee742078-112e-4017-b5e5-b26ca0e810c5,DISK], DatanodeInfoWithStorage[127.0.0.1:43952,DS-99d7d823-b457-4e0b-8677-600b530f3738,DISK], DatanodeInfoWithStorage[127.0.0.1:43687,DS-fcc1be89-980e-4371-a2db-8620b1b1a9c6,DISK], DatanodeInfoWithStorage[127.0.0.1:44407,DS-087c9d9e-388d-4c3c-b7fc-3bf75accc286,DISK], DatanodeInfoWithStorage[127.0.0.1:33193,DS-44f8474e-4f4d-4208-8c6d-82a725a1efd5,DISK], DatanodeInfoWithStorage[127.0.0.1:36605,DS-b6bd1d69-c8a8-42cc-847f-c57b46aafcde,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-737683818-172.17.0.8-1595314451414:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45828,DS-ee155ade-24af-41fa-aafa-8c2802a46ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:40783,DS-39c4d013-3b36-4883-9989-d9d33e7465b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44522,DS-20ca1a10-9d42-45c8-a77c-30df7d45073f,DISK], DatanodeInfoWithStorage[127.0.0.1:46742,DS-2c9c6319-1b04-4fd1-b29b-044ea669d172,DISK], DatanodeInfoWithStorage[127.0.0.1:44122,DS-d6ff55c5-504d-49fb-8db1-3c6e5e1c515e,DISK], DatanodeInfoWithStorage[127.0.0.1:41332,DS-13a79ab4-77a5-43b0-9269-5c05aaa05787,DISK], DatanodeInfoWithStorage[127.0.0.1:38655,DS-7f42522a-3c15-4987-9924-f67211a6f023,DISK], DatanodeInfoWithStorage[127.0.0.1:36274,DS-f4207c45-0f47-4feb-9d16-d9bee22fe099,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-737683818-172.17.0.8-1595314451414:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45828,DS-ee155ade-24af-41fa-aafa-8c2802a46ca9,DISK], DatanodeInfoWithStorage[127.0.0.1:40783,DS-39c4d013-3b36-4883-9989-d9d33e7465b5,DISK], DatanodeInfoWithStorage[127.0.0.1:44522,DS-20ca1a10-9d42-45c8-a77c-30df7d45073f,DISK], DatanodeInfoWithStorage[127.0.0.1:46742,DS-2c9c6319-1b04-4fd1-b29b-044ea669d172,DISK], DatanodeInfoWithStorage[127.0.0.1:44122,DS-d6ff55c5-504d-49fb-8db1-3c6e5e1c515e,DISK], DatanodeInfoWithStorage[127.0.0.1:41332,DS-13a79ab4-77a5-43b0-9269-5c05aaa05787,DISK], DatanodeInfoWithStorage[127.0.0.1:38655,DS-7f42522a-3c15-4987-9924-f67211a6f023,DISK], DatanodeInfoWithStorage[127.0.0.1:36274,DS-f4207c45-0f47-4feb-9d16-d9bee22fe099,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2075018222-172.17.0.8-1595314564694:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39805,DS-2c0cadfc-e8e3-4c06-a183-4976a7c1d587,DISK], DatanodeInfoWithStorage[127.0.0.1:45337,DS-199cffdd-15bf-4d21-b24a-3cae87263084,DISK], DatanodeInfoWithStorage[127.0.0.1:35290,DS-241f41a0-9d5e-440b-9500-9a03dd1a5917,DISK], DatanodeInfoWithStorage[127.0.0.1:42338,DS-d3d16fe1-62ad-4391-bf16-0b44c2aa1abf,DISK], DatanodeInfoWithStorage[127.0.0.1:37621,DS-88c6d4db-a98d-4dad-bd6c-de4f92c574e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40063,DS-5e8e9445-d4a6-407c-ae0c-2e20c0982e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:37983,DS-5729927a-ad68-4e5b-8893-ec11365477c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44648,DS-e9604d87-b0b6-4a58-af23-c65708c3100b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2075018222-172.17.0.8-1595314564694:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39805,DS-2c0cadfc-e8e3-4c06-a183-4976a7c1d587,DISK], DatanodeInfoWithStorage[127.0.0.1:45337,DS-199cffdd-15bf-4d21-b24a-3cae87263084,DISK], DatanodeInfoWithStorage[127.0.0.1:35290,DS-241f41a0-9d5e-440b-9500-9a03dd1a5917,DISK], DatanodeInfoWithStorage[127.0.0.1:42338,DS-d3d16fe1-62ad-4391-bf16-0b44c2aa1abf,DISK], DatanodeInfoWithStorage[127.0.0.1:37621,DS-88c6d4db-a98d-4dad-bd6c-de4f92c574e6,DISK], DatanodeInfoWithStorage[127.0.0.1:40063,DS-5e8e9445-d4a6-407c-ae0c-2e20c0982e0f,DISK], DatanodeInfoWithStorage[127.0.0.1:37983,DS-5729927a-ad68-4e5b-8893-ec11365477c1,DISK], DatanodeInfoWithStorage[127.0.0.1:44648,DS-e9604d87-b0b6-4a58-af23-c65708c3100b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1763429908-172.17.0.8-1595315105592:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46062,DS-563cb121-aa4c-499f-bcb5-246df70541c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44784,DS-d8e9e317-abaa-45af-8af8-0a6dc64dc074,DISK], DatanodeInfoWithStorage[127.0.0.1:41807,DS-c9454062-b4bc-43cc-8904-910b9b6dc8ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34043,DS-a33f2a5c-2fd3-455e-a064-7777ef68d9bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36876,DS-64cb4788-c263-4c38-b995-87a5f1d6e754,DISK], DatanodeInfoWithStorage[127.0.0.1:35408,DS-38fcd829-198f-46dd-9ea0-9189f85deeb9,DISK], DatanodeInfoWithStorage[127.0.0.1:33795,DS-83a00b40-4d0d-4407-a069-258f14070218,DISK], DatanodeInfoWithStorage[127.0.0.1:33584,DS-3ca96bc8-b8ea-4735-8dc6-318e690b4492,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1763429908-172.17.0.8-1595315105592:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46062,DS-563cb121-aa4c-499f-bcb5-246df70541c9,DISK], DatanodeInfoWithStorage[127.0.0.1:44784,DS-d8e9e317-abaa-45af-8af8-0a6dc64dc074,DISK], DatanodeInfoWithStorage[127.0.0.1:41807,DS-c9454062-b4bc-43cc-8904-910b9b6dc8ed,DISK], DatanodeInfoWithStorage[127.0.0.1:34043,DS-a33f2a5c-2fd3-455e-a064-7777ef68d9bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36876,DS-64cb4788-c263-4c38-b995-87a5f1d6e754,DISK], DatanodeInfoWithStorage[127.0.0.1:35408,DS-38fcd829-198f-46dd-9ea0-9189f85deeb9,DISK], DatanodeInfoWithStorage[127.0.0.1:33795,DS-83a00b40-4d0d-4407-a069-258f14070218,DISK], DatanodeInfoWithStorage[127.0.0.1:33584,DS-3ca96bc8-b8ea-4735-8dc6-318e690b4492,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1486964104-172.17.0.8-1595315486247:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45109,DS-d781d982-6106-4822-a75a-f2e1232a2a72,DISK], DatanodeInfoWithStorage[127.0.0.1:38164,DS-11e9eec3-6add-4c81-a821-9a948e170a10,DISK], DatanodeInfoWithStorage[127.0.0.1:44399,DS-cd8e8b01-8bbf-4f65-a14d-9f205f8b298c,DISK], DatanodeInfoWithStorage[127.0.0.1:36403,DS-cf620116-764f-4132-867a-ee3dfe68ae23,DISK], DatanodeInfoWithStorage[127.0.0.1:35408,DS-e01b1401-7ccf-4039-87a0-095cee558824,DISK], DatanodeInfoWithStorage[127.0.0.1:38357,DS-f81d2e22-6661-4f03-9311-b11799b2aa72,DISK], DatanodeInfoWithStorage[127.0.0.1:46102,DS-0dea9415-8b88-40d5-a361-988501d311aa,DISK], DatanodeInfoWithStorage[127.0.0.1:46823,DS-9b468b60-ce92-4626-bf65-afc899d7235f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1486964104-172.17.0.8-1595315486247:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45109,DS-d781d982-6106-4822-a75a-f2e1232a2a72,DISK], DatanodeInfoWithStorage[127.0.0.1:38164,DS-11e9eec3-6add-4c81-a821-9a948e170a10,DISK], DatanodeInfoWithStorage[127.0.0.1:44399,DS-cd8e8b01-8bbf-4f65-a14d-9f205f8b298c,DISK], DatanodeInfoWithStorage[127.0.0.1:36403,DS-cf620116-764f-4132-867a-ee3dfe68ae23,DISK], DatanodeInfoWithStorage[127.0.0.1:35408,DS-e01b1401-7ccf-4039-87a0-095cee558824,DISK], DatanodeInfoWithStorage[127.0.0.1:38357,DS-f81d2e22-6661-4f03-9311-b11799b2aa72,DISK], DatanodeInfoWithStorage[127.0.0.1:46102,DS-0dea9415-8b88-40d5-a361-988501d311aa,DISK], DatanodeInfoWithStorage[127.0.0.1:46823,DS-9b468b60-ce92-4626-bf65-afc899d7235f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: hadoop.http.logs.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1469743272-172.17.0.8-1595315702267:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34553,DS-5929c9d5-43be-4006-985b-3b3c3de449a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36742,DS-272b705a-06aa-4e68-b6b9-30d100f1bc14,DISK], DatanodeInfoWithStorage[127.0.0.1:43258,DS-ede79ef9-1ced-432f-882f-883d6e1271e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45003,DS-638d5328-f4c3-48b4-a570-0167afd511a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37160,DS-c1cf83fb-bd0c-4911-9206-2e85644b4aea,DISK], DatanodeInfoWithStorage[127.0.0.1:40793,DS-a5ffc8c2-28e6-4b4f-a9ec-bfbb1c8b5e67,DISK], DatanodeInfoWithStorage[127.0.0.1:44287,DS-20188079-dfdc-444c-9b14-52aeda834779,DISK], DatanodeInfoWithStorage[127.0.0.1:37464,DS-5e444bef-956b-487b-b6bb-4793bc8c9078,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1469743272-172.17.0.8-1595315702267:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34553,DS-5929c9d5-43be-4006-985b-3b3c3de449a1,DISK], DatanodeInfoWithStorage[127.0.0.1:36742,DS-272b705a-06aa-4e68-b6b9-30d100f1bc14,DISK], DatanodeInfoWithStorage[127.0.0.1:43258,DS-ede79ef9-1ced-432f-882f-883d6e1271e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45003,DS-638d5328-f4c3-48b4-a570-0167afd511a1,DISK], DatanodeInfoWithStorage[127.0.0.1:37160,DS-c1cf83fb-bd0c-4911-9206-2e85644b4aea,DISK], DatanodeInfoWithStorage[127.0.0.1:40793,DS-a5ffc8c2-28e6-4b4f-a9ec-bfbb1c8b5e67,DISK], DatanodeInfoWithStorage[127.0.0.1:44287,DS-20188079-dfdc-444c-9b14-52aeda834779,DISK], DatanodeInfoWithStorage[127.0.0.1:37464,DS-5e444bef-956b-487b-b6bb-4793bc8c9078,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: might be true error
Total execution time in seconds : 5342
