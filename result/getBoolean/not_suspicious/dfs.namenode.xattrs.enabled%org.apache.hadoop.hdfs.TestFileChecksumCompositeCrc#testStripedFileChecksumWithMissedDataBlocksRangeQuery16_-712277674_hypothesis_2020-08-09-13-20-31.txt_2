reconf_parameter: dfs.namenode.xattrs.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.xattrs.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1554387837-172.17.0.19-1596979723027:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40935,DS-5d7d72ec-423e-4c6c-96ef-9b5f68c5f9ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36097,DS-f5a64fbf-5ca4-4469-a47d-6e49e47dd832,DISK], DatanodeInfoWithStorage[127.0.0.1:33116,DS-26dd1aa8-d6ac-47b9-9d41-162dedee7fc4,DISK], DatanodeInfoWithStorage[127.0.0.1:42212,DS-b32ab340-2b9a-4d89-ad45-8cfd55fb14ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36528,DS-9b58066a-21cd-4885-b599-85fbc17d032e,DISK], DatanodeInfoWithStorage[127.0.0.1:43368,DS-885b939b-2b05-477d-840e-a194322e6b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:37997,DS-1646ea17-7647-4c46-b222-f7b758c0807f,DISK], DatanodeInfoWithStorage[127.0.0.1:40819,DS-78cae5c3-1d8f-47f8-b033-2d88cb5cbd7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1554387837-172.17.0.19-1596979723027:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40935,DS-5d7d72ec-423e-4c6c-96ef-9b5f68c5f9ed,DISK], DatanodeInfoWithStorage[127.0.0.1:36097,DS-f5a64fbf-5ca4-4469-a47d-6e49e47dd832,DISK], DatanodeInfoWithStorage[127.0.0.1:33116,DS-26dd1aa8-d6ac-47b9-9d41-162dedee7fc4,DISK], DatanodeInfoWithStorage[127.0.0.1:42212,DS-b32ab340-2b9a-4d89-ad45-8cfd55fb14ab,DISK], DatanodeInfoWithStorage[127.0.0.1:36528,DS-9b58066a-21cd-4885-b599-85fbc17d032e,DISK], DatanodeInfoWithStorage[127.0.0.1:43368,DS-885b939b-2b05-477d-840e-a194322e6b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:37997,DS-1646ea17-7647-4c46-b222-f7b758c0807f,DISK], DatanodeInfoWithStorage[127.0.0.1:40819,DS-78cae5c3-1d8f-47f8-b033-2d88cb5cbd7d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.xattrs.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2145843219-172.17.0.19-1596979822149:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39697,DS-a817b1cf-0158-4442-9593-da42a1930bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:39394,DS-023112b2-1b5b-41f1-b339-508a2d41cd13,DISK], DatanodeInfoWithStorage[127.0.0.1:45725,DS-f5dba469-bfd1-4ca0-a86a-718ac14aba24,DISK], DatanodeInfoWithStorage[127.0.0.1:39154,DS-037204ce-1011-4998-8f0e-412828403f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:39759,DS-e56a6879-92ef-42d6-bf4f-d0a35a9440bc,DISK], DatanodeInfoWithStorage[127.0.0.1:36050,DS-f8fe10c9-dfe0-486c-bfa0-f15fb2292217,DISK], DatanodeInfoWithStorage[127.0.0.1:38937,DS-6d97584b-76e5-4944-a910-7ab25d623d49,DISK], DatanodeInfoWithStorage[127.0.0.1:35156,DS-f6e17fd3-c2c4-463b-b86d-9b23ee22d007,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2145843219-172.17.0.19-1596979822149:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39697,DS-a817b1cf-0158-4442-9593-da42a1930bc9,DISK], DatanodeInfoWithStorage[127.0.0.1:39394,DS-023112b2-1b5b-41f1-b339-508a2d41cd13,DISK], DatanodeInfoWithStorage[127.0.0.1:45725,DS-f5dba469-bfd1-4ca0-a86a-718ac14aba24,DISK], DatanodeInfoWithStorage[127.0.0.1:39154,DS-037204ce-1011-4998-8f0e-412828403f8e,DISK], DatanodeInfoWithStorage[127.0.0.1:39759,DS-e56a6879-92ef-42d6-bf4f-d0a35a9440bc,DISK], DatanodeInfoWithStorage[127.0.0.1:36050,DS-f8fe10c9-dfe0-486c-bfa0-f15fb2292217,DISK], DatanodeInfoWithStorage[127.0.0.1:38937,DS-6d97584b-76e5-4944-a910-7ab25d623d49,DISK], DatanodeInfoWithStorage[127.0.0.1:35156,DS-f6e17fd3-c2c4-463b-b86d-9b23ee22d007,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.xattrs.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-364576612-172.17.0.19-1596980048122:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37813,DS-486099a0-6f60-40c5-9ca2-705d563080a1,DISK], DatanodeInfoWithStorage[127.0.0.1:46027,DS-44b648fb-3d40-4269-b3dc-4e00345d142b,DISK], DatanodeInfoWithStorage[127.0.0.1:32987,DS-a0d48b22-be89-40ec-bbfc-93b1292fa74e,DISK], DatanodeInfoWithStorage[127.0.0.1:44039,DS-f43f29a5-120e-4892-be22-9ae2f4855655,DISK], DatanodeInfoWithStorage[127.0.0.1:38508,DS-44a3c339-d58d-4e85-a78e-711ef49e635c,DISK], DatanodeInfoWithStorage[127.0.0.1:35034,DS-892c6807-6e8a-4dae-8bed-188717ba171f,DISK], DatanodeInfoWithStorage[127.0.0.1:43410,DS-fe80126d-0bf0-4d1f-91d2-633262795f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:43947,DS-42f1db12-2d7c-47bb-b2ea-703ad6ee06e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-364576612-172.17.0.19-1596980048122:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37813,DS-486099a0-6f60-40c5-9ca2-705d563080a1,DISK], DatanodeInfoWithStorage[127.0.0.1:46027,DS-44b648fb-3d40-4269-b3dc-4e00345d142b,DISK], DatanodeInfoWithStorage[127.0.0.1:32987,DS-a0d48b22-be89-40ec-bbfc-93b1292fa74e,DISK], DatanodeInfoWithStorage[127.0.0.1:44039,DS-f43f29a5-120e-4892-be22-9ae2f4855655,DISK], DatanodeInfoWithStorage[127.0.0.1:38508,DS-44a3c339-d58d-4e85-a78e-711ef49e635c,DISK], DatanodeInfoWithStorage[127.0.0.1:35034,DS-892c6807-6e8a-4dae-8bed-188717ba171f,DISK], DatanodeInfoWithStorage[127.0.0.1:43410,DS-fe80126d-0bf0-4d1f-91d2-633262795f8d,DISK], DatanodeInfoWithStorage[127.0.0.1:43947,DS-42f1db12-2d7c-47bb-b2ea-703ad6ee06e1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.xattrs.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1365715357-172.17.0.19-1596980424154:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42315,DS-de44221f-7ef8-4d11-8209-55f978ed84d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38222,DS-5cde2056-1a1c-4458-a40b-a7b25c182dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:45679,DS-f715ac31-ff27-4d36-8b42-f673a971cc2d,DISK], DatanodeInfoWithStorage[127.0.0.1:38810,DS-c5eab117-fa7b-4705-84a7-2788fd0d3abe,DISK], DatanodeInfoWithStorage[127.0.0.1:37939,DS-0f46176e-cd28-4813-a085-10274fc9b7ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42772,DS-ec599293-d9fb-45f7-9142-6f2fbec22784,DISK], DatanodeInfoWithStorage[127.0.0.1:42691,DS-f9a77121-78c1-45fc-b167-37875dba641f,DISK], DatanodeInfoWithStorage[127.0.0.1:36495,DS-20d277b6-66c0-4dbc-a27f-96241914a0e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1365715357-172.17.0.19-1596980424154:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42315,DS-de44221f-7ef8-4d11-8209-55f978ed84d6,DISK], DatanodeInfoWithStorage[127.0.0.1:38222,DS-5cde2056-1a1c-4458-a40b-a7b25c182dfd,DISK], DatanodeInfoWithStorage[127.0.0.1:45679,DS-f715ac31-ff27-4d36-8b42-f673a971cc2d,DISK], DatanodeInfoWithStorage[127.0.0.1:38810,DS-c5eab117-fa7b-4705-84a7-2788fd0d3abe,DISK], DatanodeInfoWithStorage[127.0.0.1:37939,DS-0f46176e-cd28-4813-a085-10274fc9b7ba,DISK], DatanodeInfoWithStorage[127.0.0.1:42772,DS-ec599293-d9fb-45f7-9142-6f2fbec22784,DISK], DatanodeInfoWithStorage[127.0.0.1:42691,DS-f9a77121-78c1-45fc-b167-37875dba641f,DISK], DatanodeInfoWithStorage[127.0.0.1:36495,DS-20d277b6-66c0-4dbc-a27f-96241914a0e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.xattrs.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-494791417-172.17.0.19-1596980740397:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34474,DS-c8bbfc17-8f8a-4da2-a6f5-97265f23441f,DISK], DatanodeInfoWithStorage[127.0.0.1:40089,DS-20e78be2-9452-4036-aa86-94ea06b87f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:35206,DS-a3964a9e-945e-446e-a427-bdc5e8a49cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:43964,DS-aa471c69-5c24-40df-8dbb-d775b263e475,DISK], DatanodeInfoWithStorage[127.0.0.1:39574,DS-0ff1d456-aff7-41e6-9096-461313ccb9dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45472,DS-faca70e0-86c4-49b0-8861-8bb824a7c29e,DISK], DatanodeInfoWithStorage[127.0.0.1:34824,DS-8ae03b8c-eef8-4070-a224-e2135139418a,DISK], DatanodeInfoWithStorage[127.0.0.1:42576,DS-767e0a32-d777-4562-8def-3172812ef1c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-494791417-172.17.0.19-1596980740397:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34474,DS-c8bbfc17-8f8a-4da2-a6f5-97265f23441f,DISK], DatanodeInfoWithStorage[127.0.0.1:40089,DS-20e78be2-9452-4036-aa86-94ea06b87f0a,DISK], DatanodeInfoWithStorage[127.0.0.1:35206,DS-a3964a9e-945e-446e-a427-bdc5e8a49cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:43964,DS-aa471c69-5c24-40df-8dbb-d775b263e475,DISK], DatanodeInfoWithStorage[127.0.0.1:39574,DS-0ff1d456-aff7-41e6-9096-461313ccb9dd,DISK], DatanodeInfoWithStorage[127.0.0.1:45472,DS-faca70e0-86c4-49b0-8861-8bb824a7c29e,DISK], DatanodeInfoWithStorage[127.0.0.1:34824,DS-8ae03b8c-eef8-4070-a224-e2135139418a,DISK], DatanodeInfoWithStorage[127.0.0.1:42576,DS-767e0a32-d777-4562-8def-3172812ef1c2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.xattrs.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1974568772-172.17.0.19-1596980983765:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38703,DS-fc0d4c71-bee6-4609-aa2b-5acb5a833531,DISK], DatanodeInfoWithStorage[127.0.0.1:37919,DS-1a83e723-5e0f-41a7-9433-95a5b64f6748,DISK], DatanodeInfoWithStorage[127.0.0.1:43422,DS-061fcdcb-3e8c-4aaa-a013-38f2665bfa4e,DISK], DatanodeInfoWithStorage[127.0.0.1:33771,DS-c79653b3-2946-463e-9cda-71121d8fad43,DISK], DatanodeInfoWithStorage[127.0.0.1:38897,DS-c07e144a-38f3-462d-bc30-aca5ba270acb,DISK], DatanodeInfoWithStorage[127.0.0.1:45513,DS-33f24242-b234-4cd6-b314-14af23ae557a,DISK], DatanodeInfoWithStorage[127.0.0.1:36507,DS-0803adc3-11d1-4679-8749-617d0cd136db,DISK], DatanodeInfoWithStorage[127.0.0.1:34260,DS-ab3ca589-2948-4f25-9ab8-729afbfa17e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1974568772-172.17.0.19-1596980983765:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38703,DS-fc0d4c71-bee6-4609-aa2b-5acb5a833531,DISK], DatanodeInfoWithStorage[127.0.0.1:37919,DS-1a83e723-5e0f-41a7-9433-95a5b64f6748,DISK], DatanodeInfoWithStorage[127.0.0.1:43422,DS-061fcdcb-3e8c-4aaa-a013-38f2665bfa4e,DISK], DatanodeInfoWithStorage[127.0.0.1:33771,DS-c79653b3-2946-463e-9cda-71121d8fad43,DISK], DatanodeInfoWithStorage[127.0.0.1:38897,DS-c07e144a-38f3-462d-bc30-aca5ba270acb,DISK], DatanodeInfoWithStorage[127.0.0.1:45513,DS-33f24242-b234-4cd6-b314-14af23ae557a,DISK], DatanodeInfoWithStorage[127.0.0.1:36507,DS-0803adc3-11d1-4679-8749-617d0cd136db,DISK], DatanodeInfoWithStorage[127.0.0.1:34260,DS-ab3ca589-2948-4f25-9ab8-729afbfa17e3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.xattrs.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-428106359-172.17.0.19-1596981336913:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33039,DS-a86f623c-3925-41a4-a4ab-4d25f1129dad,DISK], DatanodeInfoWithStorage[127.0.0.1:33807,DS-2a525110-2e20-46a7-901c-da8c1155ee4d,DISK], DatanodeInfoWithStorage[127.0.0.1:43432,DS-e5de65de-4136-4cb0-9699-d3884c8de120,DISK], DatanodeInfoWithStorage[127.0.0.1:36542,DS-aed226ba-1552-4dd6-b562-8d39904e4d3f,DISK], DatanodeInfoWithStorage[127.0.0.1:46402,DS-d6b8cb88-5c7a-4a3e-b132-03e53b2c0c86,DISK], DatanodeInfoWithStorage[127.0.0.1:36636,DS-053c5767-31d6-4d08-9df8-8b7a2c53c13d,DISK], DatanodeInfoWithStorage[127.0.0.1:38786,DS-3d5b10e4-ce2e-4177-bfb6-2a7a0a5055fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45791,DS-e74fca27-c1e4-4edc-abc4-18df12aceb25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-428106359-172.17.0.19-1596981336913:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33039,DS-a86f623c-3925-41a4-a4ab-4d25f1129dad,DISK], DatanodeInfoWithStorage[127.0.0.1:33807,DS-2a525110-2e20-46a7-901c-da8c1155ee4d,DISK], DatanodeInfoWithStorage[127.0.0.1:43432,DS-e5de65de-4136-4cb0-9699-d3884c8de120,DISK], DatanodeInfoWithStorage[127.0.0.1:36542,DS-aed226ba-1552-4dd6-b562-8d39904e4d3f,DISK], DatanodeInfoWithStorage[127.0.0.1:46402,DS-d6b8cb88-5c7a-4a3e-b132-03e53b2c0c86,DISK], DatanodeInfoWithStorage[127.0.0.1:36636,DS-053c5767-31d6-4d08-9df8-8b7a2c53c13d,DISK], DatanodeInfoWithStorage[127.0.0.1:38786,DS-3d5b10e4-ce2e-4177-bfb6-2a7a0a5055fe,DISK], DatanodeInfoWithStorage[127.0.0.1:45791,DS-e74fca27-c1e4-4edc-abc4-18df12aceb25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.xattrs.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2063152819-172.17.0.19-1596981576315:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39702,DS-8ceef107-0b06-4cea-b0f2-49aeb61dd177,DISK], DatanodeInfoWithStorage[127.0.0.1:46736,DS-1efd639d-fd37-4851-97e4-c31300bff0a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43525,DS-cc99c120-fe00-4767-9b16-43eef7e69385,DISK], DatanodeInfoWithStorage[127.0.0.1:39926,DS-17c7fec3-5e60-49dd-bce2-ce7990e92250,DISK], DatanodeInfoWithStorage[127.0.0.1:40973,DS-98e04be1-79ca-4beb-ac01-5f9ddad4df5c,DISK], DatanodeInfoWithStorage[127.0.0.1:40809,DS-98cafada-ccd5-4fe1-891c-c1d9a489a9f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43131,DS-cb4535ae-b67c-4b1a-a712-041d726648a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39736,DS-923dd66b-e248-4108-a84c-bcf752057bbb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2063152819-172.17.0.19-1596981576315:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39702,DS-8ceef107-0b06-4cea-b0f2-49aeb61dd177,DISK], DatanodeInfoWithStorage[127.0.0.1:46736,DS-1efd639d-fd37-4851-97e4-c31300bff0a8,DISK], DatanodeInfoWithStorage[127.0.0.1:43525,DS-cc99c120-fe00-4767-9b16-43eef7e69385,DISK], DatanodeInfoWithStorage[127.0.0.1:39926,DS-17c7fec3-5e60-49dd-bce2-ce7990e92250,DISK], DatanodeInfoWithStorage[127.0.0.1:40973,DS-98e04be1-79ca-4beb-ac01-5f9ddad4df5c,DISK], DatanodeInfoWithStorage[127.0.0.1:40809,DS-98cafada-ccd5-4fe1-891c-c1d9a489a9f6,DISK], DatanodeInfoWithStorage[127.0.0.1:43131,DS-cb4535ae-b67c-4b1a-a712-041d726648a8,DISK], DatanodeInfoWithStorage[127.0.0.1:39736,DS-923dd66b-e248-4108-a84c-bcf752057bbb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.xattrs.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1464102998-172.17.0.19-1596981747802:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38097,DS-df8319d7-44d8-4c57-b3d5-7a1d50cd7bbc,DISK], DatanodeInfoWithStorage[127.0.0.1:45884,DS-9b596aef-eece-4ce3-8023-90d4ab6d9a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:33848,DS-054292d0-0ee4-4ac8-83a3-f4f6b31bc635,DISK], DatanodeInfoWithStorage[127.0.0.1:45556,DS-c9dcff51-6606-4c1e-90e2-06a62c7ae7c8,DISK], DatanodeInfoWithStorage[127.0.0.1:38679,DS-bcf1acde-11fa-4231-96cf-8a4b4367eb8e,DISK], DatanodeInfoWithStorage[127.0.0.1:36888,DS-7d772518-f61c-4658-8c95-6eb5a334d394,DISK], DatanodeInfoWithStorage[127.0.0.1:43525,DS-ee6179b4-9b50-4211-8acf-005ca916072c,DISK], DatanodeInfoWithStorage[127.0.0.1:42258,DS-1b1b9656-0e59-452b-970f-c39b9411134e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1464102998-172.17.0.19-1596981747802:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38097,DS-df8319d7-44d8-4c57-b3d5-7a1d50cd7bbc,DISK], DatanodeInfoWithStorage[127.0.0.1:45884,DS-9b596aef-eece-4ce3-8023-90d4ab6d9a5a,DISK], DatanodeInfoWithStorage[127.0.0.1:33848,DS-054292d0-0ee4-4ac8-83a3-f4f6b31bc635,DISK], DatanodeInfoWithStorage[127.0.0.1:45556,DS-c9dcff51-6606-4c1e-90e2-06a62c7ae7c8,DISK], DatanodeInfoWithStorage[127.0.0.1:38679,DS-bcf1acde-11fa-4231-96cf-8a4b4367eb8e,DISK], DatanodeInfoWithStorage[127.0.0.1:36888,DS-7d772518-f61c-4658-8c95-6eb5a334d394,DISK], DatanodeInfoWithStorage[127.0.0.1:43525,DS-ee6179b4-9b50-4211-8acf-005ca916072c,DISK], DatanodeInfoWithStorage[127.0.0.1:42258,DS-1b1b9656-0e59-452b-970f-c39b9411134e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.xattrs.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-209117009-172.17.0.19-1596981963139:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35390,DS-5fe3e2b2-2f81-4595-99dd-78cabbe62e37,DISK], DatanodeInfoWithStorage[127.0.0.1:36229,DS-3bee55e6-ead7-45c1-a181-f710c03f549c,DISK], DatanodeInfoWithStorage[127.0.0.1:33407,DS-07b36c9e-8a72-4e75-aad2-97238449f570,DISK], DatanodeInfoWithStorage[127.0.0.1:37162,DS-b2a8df43-6408-4783-8bd8-b791bc7d8ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:36022,DS-9c97adc8-0b9d-4943-b375-d9f96b79058f,DISK], DatanodeInfoWithStorage[127.0.0.1:45328,DS-0f934458-3de2-4b8b-b955-b3836004b800,DISK], DatanodeInfoWithStorage[127.0.0.1:42954,DS-3edd39ad-27e8-4448-9fd7-46710eb2cdd8,DISK], DatanodeInfoWithStorage[127.0.0.1:44047,DS-a1e324e4-dfc9-41f9-9a96-ae1cd7197408,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-209117009-172.17.0.19-1596981963139:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35390,DS-5fe3e2b2-2f81-4595-99dd-78cabbe62e37,DISK], DatanodeInfoWithStorage[127.0.0.1:36229,DS-3bee55e6-ead7-45c1-a181-f710c03f549c,DISK], DatanodeInfoWithStorage[127.0.0.1:33407,DS-07b36c9e-8a72-4e75-aad2-97238449f570,DISK], DatanodeInfoWithStorage[127.0.0.1:37162,DS-b2a8df43-6408-4783-8bd8-b791bc7d8ec9,DISK], DatanodeInfoWithStorage[127.0.0.1:36022,DS-9c97adc8-0b9d-4943-b375-d9f96b79058f,DISK], DatanodeInfoWithStorage[127.0.0.1:45328,DS-0f934458-3de2-4b8b-b955-b3836004b800,DISK], DatanodeInfoWithStorage[127.0.0.1:42954,DS-3edd39ad-27e8-4448-9fd7-46710eb2cdd8,DISK], DatanodeInfoWithStorage[127.0.0.1:44047,DS-a1e324e4-dfc9-41f9-9a96-ae1cd7197408,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.xattrs.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1597030790-172.17.0.19-1596982484476:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34343,DS-f89941b3-7283-4d17-8e76-a23d0430dcbc,DISK], DatanodeInfoWithStorage[127.0.0.1:45525,DS-3032b9a2-dbbc-4faa-8528-b59009231866,DISK], DatanodeInfoWithStorage[127.0.0.1:35786,DS-745206f0-088a-441b-b209-4594601ba4b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42420,DS-63a8bbe7-a814-486a-aff4-968ecc628500,DISK], DatanodeInfoWithStorage[127.0.0.1:36549,DS-4320b336-e843-4b8d-8080-45e3333fbd4c,DISK], DatanodeInfoWithStorage[127.0.0.1:37898,DS-75a8707f-4440-492d-853a-983fe0062c23,DISK], DatanodeInfoWithStorage[127.0.0.1:37337,DS-fbc8350f-df1e-46a4-9c3b-63d6ce78642f,DISK], DatanodeInfoWithStorage[127.0.0.1:45544,DS-5ef35544-db21-4463-bc1b-e83def2d2923,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1597030790-172.17.0.19-1596982484476:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34343,DS-f89941b3-7283-4d17-8e76-a23d0430dcbc,DISK], DatanodeInfoWithStorage[127.0.0.1:45525,DS-3032b9a2-dbbc-4faa-8528-b59009231866,DISK], DatanodeInfoWithStorage[127.0.0.1:35786,DS-745206f0-088a-441b-b209-4594601ba4b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42420,DS-63a8bbe7-a814-486a-aff4-968ecc628500,DISK], DatanodeInfoWithStorage[127.0.0.1:36549,DS-4320b336-e843-4b8d-8080-45e3333fbd4c,DISK], DatanodeInfoWithStorage[127.0.0.1:37898,DS-75a8707f-4440-492d-853a-983fe0062c23,DISK], DatanodeInfoWithStorage[127.0.0.1:37337,DS-fbc8350f-df1e-46a4-9c3b-63d6ce78642f,DISK], DatanodeInfoWithStorage[127.0.0.1:45544,DS-5ef35544-db21-4463-bc1b-e83def2d2923,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.xattrs.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-209979077-172.17.0.19-1596982633393:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42682,DS-2c8dd5ac-63f2-4667-bd19-7df5bea5b8e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45733,DS-149ca127-7596-4535-bcba-fcb797080447,DISK], DatanodeInfoWithStorage[127.0.0.1:40485,DS-79d7204f-747c-4fdb-b059-2c4df986f206,DISK], DatanodeInfoWithStorage[127.0.0.1:34211,DS-ee8fd998-a17e-4b79-870e-ffe73b28fb29,DISK], DatanodeInfoWithStorage[127.0.0.1:38716,DS-82f28dba-4213-4c0b-918a-634e8148d210,DISK], DatanodeInfoWithStorage[127.0.0.1:35299,DS-1866ab20-e073-4684-8d47-ebe42aa9b643,DISK], DatanodeInfoWithStorage[127.0.0.1:35492,DS-63d9f541-7e2b-425d-8c95-85b8466fc7a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35141,DS-4026223b-8c57-4f40-83d3-390f76029f44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-209979077-172.17.0.19-1596982633393:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42682,DS-2c8dd5ac-63f2-4667-bd19-7df5bea5b8e2,DISK], DatanodeInfoWithStorage[127.0.0.1:45733,DS-149ca127-7596-4535-bcba-fcb797080447,DISK], DatanodeInfoWithStorage[127.0.0.1:40485,DS-79d7204f-747c-4fdb-b059-2c4df986f206,DISK], DatanodeInfoWithStorage[127.0.0.1:34211,DS-ee8fd998-a17e-4b79-870e-ffe73b28fb29,DISK], DatanodeInfoWithStorage[127.0.0.1:38716,DS-82f28dba-4213-4c0b-918a-634e8148d210,DISK], DatanodeInfoWithStorage[127.0.0.1:35299,DS-1866ab20-e073-4684-8d47-ebe42aa9b643,DISK], DatanodeInfoWithStorage[127.0.0.1:35492,DS-63d9f541-7e2b-425d-8c95-85b8466fc7a8,DISK], DatanodeInfoWithStorage[127.0.0.1:35141,DS-4026223b-8c57-4f40-83d3-390f76029f44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.xattrs.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1804800986-172.17.0.19-1596982737808:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41057,DS-ce56973e-5ffc-4710-8b1a-0b64d054b902,DISK], DatanodeInfoWithStorage[127.0.0.1:40963,DS-6def0918-e2df-41ea-b014-25b25a012b04,DISK], DatanodeInfoWithStorage[127.0.0.1:34128,DS-436631d5-fed6-4712-a1a9-65bbe939c544,DISK], DatanodeInfoWithStorage[127.0.0.1:45128,DS-bdffc5e5-23cb-4ec7-94ec-64dee4a9430b,DISK], DatanodeInfoWithStorage[127.0.0.1:36372,DS-97712beb-c39e-44d5-8c80-41b19fffcfac,DISK], DatanodeInfoWithStorage[127.0.0.1:36912,DS-ed08c6f3-9a22-4bf0-b85d-0f9d4d6b6770,DISK], DatanodeInfoWithStorage[127.0.0.1:34996,DS-962423b9-2188-426b-a4fa-c205f05f8339,DISK], DatanodeInfoWithStorage[127.0.0.1:33354,DS-d82f689d-8f39-437a-8550-63dfbec24ca8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1804800986-172.17.0.19-1596982737808:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41057,DS-ce56973e-5ffc-4710-8b1a-0b64d054b902,DISK], DatanodeInfoWithStorage[127.0.0.1:40963,DS-6def0918-e2df-41ea-b014-25b25a012b04,DISK], DatanodeInfoWithStorage[127.0.0.1:34128,DS-436631d5-fed6-4712-a1a9-65bbe939c544,DISK], DatanodeInfoWithStorage[127.0.0.1:45128,DS-bdffc5e5-23cb-4ec7-94ec-64dee4a9430b,DISK], DatanodeInfoWithStorage[127.0.0.1:36372,DS-97712beb-c39e-44d5-8c80-41b19fffcfac,DISK], DatanodeInfoWithStorage[127.0.0.1:36912,DS-ed08c6f3-9a22-4bf0-b85d-0f9d4d6b6770,DISK], DatanodeInfoWithStorage[127.0.0.1:34996,DS-962423b9-2188-426b-a4fa-c205f05f8339,DISK], DatanodeInfoWithStorage[127.0.0.1:33354,DS-d82f689d-8f39-437a-8550-63dfbec24ca8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.xattrs.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1363859894-172.17.0.19-1596982774564:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37034,DS-a809491e-2492-464c-aaac-45817ea8a90d,DISK], DatanodeInfoWithStorage[127.0.0.1:44676,DS-445875bd-4432-439a-b8f9-21cb13bd1cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:36911,DS-9e3073f7-b678-451f-9b49-36d94635cb84,DISK], DatanodeInfoWithStorage[127.0.0.1:42997,DS-fe6a752a-9a0a-427e-bdf8-0aec467bea56,DISK], DatanodeInfoWithStorage[127.0.0.1:35389,DS-1e98d91e-ae43-4796-aa2e-f13c7e3851aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38076,DS-bc35885c-0907-4c1b-b1a1-deb0225aedd0,DISK], DatanodeInfoWithStorage[127.0.0.1:34525,DS-829ceec3-8147-4e7d-8d38-72f3fd096100,DISK], DatanodeInfoWithStorage[127.0.0.1:33085,DS-40c0b12d-6310-435c-a9d7-72533adca67d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1363859894-172.17.0.19-1596982774564:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37034,DS-a809491e-2492-464c-aaac-45817ea8a90d,DISK], DatanodeInfoWithStorage[127.0.0.1:44676,DS-445875bd-4432-439a-b8f9-21cb13bd1cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:36911,DS-9e3073f7-b678-451f-9b49-36d94635cb84,DISK], DatanodeInfoWithStorage[127.0.0.1:42997,DS-fe6a752a-9a0a-427e-bdf8-0aec467bea56,DISK], DatanodeInfoWithStorage[127.0.0.1:35389,DS-1e98d91e-ae43-4796-aa2e-f13c7e3851aa,DISK], DatanodeInfoWithStorage[127.0.0.1:38076,DS-bc35885c-0907-4c1b-b1a1-deb0225aedd0,DISK], DatanodeInfoWithStorage[127.0.0.1:34525,DS-829ceec3-8147-4e7d-8d38-72f3fd096100,DISK], DatanodeInfoWithStorage[127.0.0.1:33085,DS-40c0b12d-6310-435c-a9d7-72533adca67d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.xattrs.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-509815643-172.17.0.19-1596983266287:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41488,DS-6839997b-dad6-491e-ba58-6a828d8459ae,DISK], DatanodeInfoWithStorage[127.0.0.1:38414,DS-e5469a4c-b771-43d6-a323-ef8a87f32b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:40668,DS-484308a5-fbca-49ca-a72e-369d86e1380c,DISK], DatanodeInfoWithStorage[127.0.0.1:44000,DS-033045c1-7f0b-4efb-bc7e-2f6f5b723423,DISK], DatanodeInfoWithStorage[127.0.0.1:36101,DS-a9e5cc9f-fca5-436b-a2e5-49bda8a74744,DISK], DatanodeInfoWithStorage[127.0.0.1:45733,DS-296a3a27-864d-4f8b-af42-165626ce8fc0,DISK], DatanodeInfoWithStorage[127.0.0.1:39918,DS-8c625522-1b0e-4f79-9a13-92aa7ed664bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43342,DS-315f7fd6-de2f-4409-8986-53d31241f2ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-509815643-172.17.0.19-1596983266287:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41488,DS-6839997b-dad6-491e-ba58-6a828d8459ae,DISK], DatanodeInfoWithStorage[127.0.0.1:38414,DS-e5469a4c-b771-43d6-a323-ef8a87f32b7c,DISK], DatanodeInfoWithStorage[127.0.0.1:40668,DS-484308a5-fbca-49ca-a72e-369d86e1380c,DISK], DatanodeInfoWithStorage[127.0.0.1:44000,DS-033045c1-7f0b-4efb-bc7e-2f6f5b723423,DISK], DatanodeInfoWithStorage[127.0.0.1:36101,DS-a9e5cc9f-fca5-436b-a2e5-49bda8a74744,DISK], DatanodeInfoWithStorage[127.0.0.1:45733,DS-296a3a27-864d-4f8b-af42-165626ce8fc0,DISK], DatanodeInfoWithStorage[127.0.0.1:39918,DS-8c625522-1b0e-4f79-9a13-92aa7ed664bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43342,DS-315f7fd6-de2f-4409-8986-53d31241f2ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.xattrs.enabled
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1250739535-172.17.0.19-1596983638610:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40008,DS-fb47eaf3-111e-4f0c-8bd8-fab840eb805f,DISK], DatanodeInfoWithStorage[127.0.0.1:34071,DS-7f6453ea-6900-46a6-8487-1edfccf80319,DISK], DatanodeInfoWithStorage[127.0.0.1:37800,DS-4e98e06c-9122-4d62-80b7-14948346cd13,DISK], DatanodeInfoWithStorage[127.0.0.1:33604,DS-ebbe5f0f-c68e-4b9b-a401-2a7c4491fbc2,DISK], DatanodeInfoWithStorage[127.0.0.1:41729,DS-f627041b-0902-4470-8fe2-147495d9cf2c,DISK], DatanodeInfoWithStorage[127.0.0.1:39865,DS-028e1532-e02e-4f07-be50-f4d689024c9b,DISK], DatanodeInfoWithStorage[127.0.0.1:42579,DS-ee12f295-5712-44fe-8dd7-7903308f8039,DISK], DatanodeInfoWithStorage[127.0.0.1:42365,DS-6196af1d-7593-463f-b11d-f7ac1733a806,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1250739535-172.17.0.19-1596983638610:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40008,DS-fb47eaf3-111e-4f0c-8bd8-fab840eb805f,DISK], DatanodeInfoWithStorage[127.0.0.1:34071,DS-7f6453ea-6900-46a6-8487-1edfccf80319,DISK], DatanodeInfoWithStorage[127.0.0.1:37800,DS-4e98e06c-9122-4d62-80b7-14948346cd13,DISK], DatanodeInfoWithStorage[127.0.0.1:33604,DS-ebbe5f0f-c68e-4b9b-a401-2a7c4491fbc2,DISK], DatanodeInfoWithStorage[127.0.0.1:41729,DS-f627041b-0902-4470-8fe2-147495d9cf2c,DISK], DatanodeInfoWithStorage[127.0.0.1:39865,DS-028e1532-e02e-4f07-be50-f4d689024c9b,DISK], DatanodeInfoWithStorage[127.0.0.1:42579,DS-ee12f295-5712-44fe-8dd7-7903308f8039,DISK], DatanodeInfoWithStorage[127.0.0.1:42365,DS-6196af1d-7593-463f-b11d-f7ac1733a806,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5236
