reconf_parameter: dfs.namenode.datanode.registration.ip-hostname-check
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.datanode.registration.ip-hostname-check
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1691825924-172.17.0.4-1595411111532:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45842,DS-d6786b73-0d76-4188-9941-e501947e7628,DISK], DatanodeInfoWithStorage[127.0.0.1:42310,DS-18973520-4147-47d5-a8a5-0d699a750067,DISK], DatanodeInfoWithStorage[127.0.0.1:44124,DS-ec3d27d4-08f3-4b22-94ac-cb41bb75029a,DISK], DatanodeInfoWithStorage[127.0.0.1:46325,DS-13356a04-9026-4a7f-8c78-30545f264e45,DISK], DatanodeInfoWithStorage[127.0.0.1:45505,DS-c332c948-8551-463e-ba4f-926124eacef3,DISK], DatanodeInfoWithStorage[127.0.0.1:35356,DS-66b3567c-fb6c-4b0a-921b-0b240ba46f24,DISK], DatanodeInfoWithStorage[127.0.0.1:46713,DS-33cce6b9-16b6-497c-b806-7d5c4286d9f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42586,DS-1c2d599a-86b4-42a2-9c91-25cd8ee551c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1691825924-172.17.0.4-1595411111532:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45842,DS-d6786b73-0d76-4188-9941-e501947e7628,DISK], DatanodeInfoWithStorage[127.0.0.1:42310,DS-18973520-4147-47d5-a8a5-0d699a750067,DISK], DatanodeInfoWithStorage[127.0.0.1:44124,DS-ec3d27d4-08f3-4b22-94ac-cb41bb75029a,DISK], DatanodeInfoWithStorage[127.0.0.1:46325,DS-13356a04-9026-4a7f-8c78-30545f264e45,DISK], DatanodeInfoWithStorage[127.0.0.1:45505,DS-c332c948-8551-463e-ba4f-926124eacef3,DISK], DatanodeInfoWithStorage[127.0.0.1:35356,DS-66b3567c-fb6c-4b0a-921b-0b240ba46f24,DISK], DatanodeInfoWithStorage[127.0.0.1:46713,DS-33cce6b9-16b6-497c-b806-7d5c4286d9f9,DISK], DatanodeInfoWithStorage[127.0.0.1:42586,DS-1c2d599a-86b4-42a2-9c91-25cd8ee551c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.datanode.registration.ip-hostname-check
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-899104557-172.17.0.4-1595411376617:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45630,DS-4de788fe-a631-4360-bc26-616669d52b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:43873,DS-c53569fd-e7dc-47ef-9144-94e93528bb89,DISK], DatanodeInfoWithStorage[127.0.0.1:39293,DS-39f61021-5835-402d-850a-e735ac637479,DISK], DatanodeInfoWithStorage[127.0.0.1:35257,DS-3a4ec7ac-5119-4519-8a09-62d4d56105b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45652,DS-f4f64a8b-6505-4684-82cd-486005952f17,DISK], DatanodeInfoWithStorage[127.0.0.1:42588,DS-2ee8c72e-d7d7-4605-93f9-7804d40253f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38329,DS-65a8bea0-00dd-4f12-93d4-0e8349b3e9ae,DISK], DatanodeInfoWithStorage[127.0.0.1:38895,DS-833ae92a-c93a-4899-97c5-8fbab46c0f1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-899104557-172.17.0.4-1595411376617:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45630,DS-4de788fe-a631-4360-bc26-616669d52b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:43873,DS-c53569fd-e7dc-47ef-9144-94e93528bb89,DISK], DatanodeInfoWithStorage[127.0.0.1:39293,DS-39f61021-5835-402d-850a-e735ac637479,DISK], DatanodeInfoWithStorage[127.0.0.1:35257,DS-3a4ec7ac-5119-4519-8a09-62d4d56105b7,DISK], DatanodeInfoWithStorage[127.0.0.1:45652,DS-f4f64a8b-6505-4684-82cd-486005952f17,DISK], DatanodeInfoWithStorage[127.0.0.1:42588,DS-2ee8c72e-d7d7-4605-93f9-7804d40253f1,DISK], DatanodeInfoWithStorage[127.0.0.1:38329,DS-65a8bea0-00dd-4f12-93d4-0e8349b3e9ae,DISK], DatanodeInfoWithStorage[127.0.0.1:38895,DS-833ae92a-c93a-4899-97c5-8fbab46c0f1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.datanode.registration.ip-hostname-check
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1228927744-172.17.0.4-1595411539271:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32835,DS-a7202299-d953-4736-bb9e-f21e3e8a97af,DISK], DatanodeInfoWithStorage[127.0.0.1:34820,DS-881f0bc0-50dc-4882-afad-2b4f91099e74,DISK], DatanodeInfoWithStorage[127.0.0.1:42195,DS-86e4beaa-940e-4f58-94a1-fcd1d16ddd73,DISK], DatanodeInfoWithStorage[127.0.0.1:37046,DS-8fa1844c-2d52-48a8-994b-66a1f8f14727,DISK], DatanodeInfoWithStorage[127.0.0.1:35465,DS-7eb5e6bc-2124-4656-a1e8-fe6b7daa2cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:39377,DS-4a624b33-4589-4a8c-bd98-8a5f8d8acada,DISK], DatanodeInfoWithStorage[127.0.0.1:41014,DS-e4073472-3a44-4e90-9937-ee9485b68c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:44011,DS-6fbb3c79-fac3-45bc-ae75-86e0e8be9bd8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1228927744-172.17.0.4-1595411539271:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32835,DS-a7202299-d953-4736-bb9e-f21e3e8a97af,DISK], DatanodeInfoWithStorage[127.0.0.1:34820,DS-881f0bc0-50dc-4882-afad-2b4f91099e74,DISK], DatanodeInfoWithStorage[127.0.0.1:42195,DS-86e4beaa-940e-4f58-94a1-fcd1d16ddd73,DISK], DatanodeInfoWithStorage[127.0.0.1:37046,DS-8fa1844c-2d52-48a8-994b-66a1f8f14727,DISK], DatanodeInfoWithStorage[127.0.0.1:35465,DS-7eb5e6bc-2124-4656-a1e8-fe6b7daa2cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:39377,DS-4a624b33-4589-4a8c-bd98-8a5f8d8acada,DISK], DatanodeInfoWithStorage[127.0.0.1:41014,DS-e4073472-3a44-4e90-9937-ee9485b68c2b,DISK], DatanodeInfoWithStorage[127.0.0.1:44011,DS-6fbb3c79-fac3-45bc-ae75-86e0e8be9bd8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.datanode.registration.ip-hostname-check
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1077504286-172.17.0.4-1595411686127:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45275,DS-a4d00712-aa5a-44ed-8db9-8aa83c21daf9,DISK], DatanodeInfoWithStorage[127.0.0.1:35519,DS-71dd1ab9-8be4-4a76-886d-b942b5828611,DISK], DatanodeInfoWithStorage[127.0.0.1:36981,DS-56bcd91f-a0de-4be7-a9f4-4ac3da94e7ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42794,DS-542b120b-d726-4702-b3a0-d9e1ec4b4c90,DISK], DatanodeInfoWithStorage[127.0.0.1:35039,DS-b83da13b-469c-4f25-b550-bac101464839,DISK], DatanodeInfoWithStorage[127.0.0.1:39059,DS-c75f0a00-58a8-424b-91c3-ce5253c1b808,DISK], DatanodeInfoWithStorage[127.0.0.1:40768,DS-97490c3f-690d-42f9-b948-f47436d0ea80,DISK], DatanodeInfoWithStorage[127.0.0.1:45143,DS-3816a1d1-f2d1-4550-bc72-6caf7a7939e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1077504286-172.17.0.4-1595411686127:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45275,DS-a4d00712-aa5a-44ed-8db9-8aa83c21daf9,DISK], DatanodeInfoWithStorage[127.0.0.1:35519,DS-71dd1ab9-8be4-4a76-886d-b942b5828611,DISK], DatanodeInfoWithStorage[127.0.0.1:36981,DS-56bcd91f-a0de-4be7-a9f4-4ac3da94e7ea,DISK], DatanodeInfoWithStorage[127.0.0.1:42794,DS-542b120b-d726-4702-b3a0-d9e1ec4b4c90,DISK], DatanodeInfoWithStorage[127.0.0.1:35039,DS-b83da13b-469c-4f25-b550-bac101464839,DISK], DatanodeInfoWithStorage[127.0.0.1:39059,DS-c75f0a00-58a8-424b-91c3-ce5253c1b808,DISK], DatanodeInfoWithStorage[127.0.0.1:40768,DS-97490c3f-690d-42f9-b948-f47436d0ea80,DISK], DatanodeInfoWithStorage[127.0.0.1:45143,DS-3816a1d1-f2d1-4550-bc72-6caf7a7939e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.datanode.registration.ip-hostname-check
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-922125748-172.17.0.4-1595412040083:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35332,DS-f1872623-c8ed-42e3-8371-d751026a9a43,DISK], DatanodeInfoWithStorage[127.0.0.1:37323,DS-29cb8989-a12f-47e0-886b-2078402d10ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45790,DS-9597b1f4-f397-4332-aa1e-b71b43de0087,DISK], DatanodeInfoWithStorage[127.0.0.1:39859,DS-81946572-9c05-42b5-9466-12961746f760,DISK], DatanodeInfoWithStorage[127.0.0.1:37850,DS-42b2ff50-806d-4284-9470-fc59e36a5ed0,DISK], DatanodeInfoWithStorage[127.0.0.1:46816,DS-c97e12e3-6ff7-4453-b042-872743617805,DISK], DatanodeInfoWithStorage[127.0.0.1:42485,DS-bb99f11a-c960-4489-8a28-5b7dd0b19f63,DISK], DatanodeInfoWithStorage[127.0.0.1:37877,DS-f349f63f-442c-4206-8ac2-63a4f3220c58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-922125748-172.17.0.4-1595412040083:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35332,DS-f1872623-c8ed-42e3-8371-d751026a9a43,DISK], DatanodeInfoWithStorage[127.0.0.1:37323,DS-29cb8989-a12f-47e0-886b-2078402d10ef,DISK], DatanodeInfoWithStorage[127.0.0.1:45790,DS-9597b1f4-f397-4332-aa1e-b71b43de0087,DISK], DatanodeInfoWithStorage[127.0.0.1:39859,DS-81946572-9c05-42b5-9466-12961746f760,DISK], DatanodeInfoWithStorage[127.0.0.1:37850,DS-42b2ff50-806d-4284-9470-fc59e36a5ed0,DISK], DatanodeInfoWithStorage[127.0.0.1:46816,DS-c97e12e3-6ff7-4453-b042-872743617805,DISK], DatanodeInfoWithStorage[127.0.0.1:42485,DS-bb99f11a-c960-4489-8a28-5b7dd0b19f63,DISK], DatanodeInfoWithStorage[127.0.0.1:37877,DS-f349f63f-442c-4206-8ac2-63a4f3220c58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.datanode.registration.ip-hostname-check
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1121513419-172.17.0.4-1595412216772:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39397,DS-d8644f45-b864-4d4c-b7f6-70159a33b116,DISK], DatanodeInfoWithStorage[127.0.0.1:43932,DS-87ccadc6-eebe-4b89-a8ef-a425810fad4d,DISK], DatanodeInfoWithStorage[127.0.0.1:40364,DS-ba7f74f5-7d9e-45ac-ab23-3aee941b59bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44512,DS-e6b3da55-bdf6-4ddc-b2b1-efb597cd4386,DISK], DatanodeInfoWithStorage[127.0.0.1:41075,DS-aa86da64-fb0a-47b8-9b00-3640c64335a6,DISK], DatanodeInfoWithStorage[127.0.0.1:43920,DS-13185dc1-6fd3-4da5-ba81-3174b4b5ff63,DISK], DatanodeInfoWithStorage[127.0.0.1:35199,DS-ea5a4679-c4ba-4e53-a457-769959a13192,DISK], DatanodeInfoWithStorage[127.0.0.1:35394,DS-a582adee-4ebf-4d4c-9534-a26cb1a8fb0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1121513419-172.17.0.4-1595412216772:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39397,DS-d8644f45-b864-4d4c-b7f6-70159a33b116,DISK], DatanodeInfoWithStorage[127.0.0.1:43932,DS-87ccadc6-eebe-4b89-a8ef-a425810fad4d,DISK], DatanodeInfoWithStorage[127.0.0.1:40364,DS-ba7f74f5-7d9e-45ac-ab23-3aee941b59bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44512,DS-e6b3da55-bdf6-4ddc-b2b1-efb597cd4386,DISK], DatanodeInfoWithStorage[127.0.0.1:41075,DS-aa86da64-fb0a-47b8-9b00-3640c64335a6,DISK], DatanodeInfoWithStorage[127.0.0.1:43920,DS-13185dc1-6fd3-4da5-ba81-3174b4b5ff63,DISK], DatanodeInfoWithStorage[127.0.0.1:35199,DS-ea5a4679-c4ba-4e53-a457-769959a13192,DISK], DatanodeInfoWithStorage[127.0.0.1:35394,DS-a582adee-4ebf-4d4c-9534-a26cb1a8fb0f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.datanode.registration.ip-hostname-check
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-561976868-172.17.0.4-1595412423916:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40244,DS-5881a53d-6230-4125-b1eb-ebfc63a163bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39473,DS-e17afb77-08a7-483b-b4ff-0efbf4ce3bf9,DISK], DatanodeInfoWithStorage[127.0.0.1:39709,DS-aa9e0bb9-daf8-4219-93c3-94f22f6ca015,DISK], DatanodeInfoWithStorage[127.0.0.1:42469,DS-b358990a-e155-4805-a7d7-c4fe33848359,DISK], DatanodeInfoWithStorage[127.0.0.1:45034,DS-fcafaa0d-4a39-4b38-be5b-a72dbeeff297,DISK], DatanodeInfoWithStorage[127.0.0.1:43317,DS-18776bd1-76c9-47a4-91d2-c35996b530c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37712,DS-b59cc1eb-db83-4410-bfb4-782f93416fd2,DISK], DatanodeInfoWithStorage[127.0.0.1:36050,DS-123d3731-0f36-420e-84c0-f7727c21be61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-561976868-172.17.0.4-1595412423916:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40244,DS-5881a53d-6230-4125-b1eb-ebfc63a163bb,DISK], DatanodeInfoWithStorage[127.0.0.1:39473,DS-e17afb77-08a7-483b-b4ff-0efbf4ce3bf9,DISK], DatanodeInfoWithStorage[127.0.0.1:39709,DS-aa9e0bb9-daf8-4219-93c3-94f22f6ca015,DISK], DatanodeInfoWithStorage[127.0.0.1:42469,DS-b358990a-e155-4805-a7d7-c4fe33848359,DISK], DatanodeInfoWithStorage[127.0.0.1:45034,DS-fcafaa0d-4a39-4b38-be5b-a72dbeeff297,DISK], DatanodeInfoWithStorage[127.0.0.1:43317,DS-18776bd1-76c9-47a4-91d2-c35996b530c3,DISK], DatanodeInfoWithStorage[127.0.0.1:37712,DS-b59cc1eb-db83-4410-bfb4-782f93416fd2,DISK], DatanodeInfoWithStorage[127.0.0.1:36050,DS-123d3731-0f36-420e-84c0-f7727c21be61,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.datanode.registration.ip-hostname-check
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1374625176-172.17.0.4-1595412721776:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35023,DS-74d9e727-0186-42b6-aef2-74fbecdaa545,DISK], DatanodeInfoWithStorage[127.0.0.1:45502,DS-4e45ce79-fa80-4281-9620-2124d5df3a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:40163,DS-c91ddfb8-0f24-4f68-9cb7-f78b9558c08e,DISK], DatanodeInfoWithStorage[127.0.0.1:46824,DS-bc322651-103d-4224-87c2-195f3832c42f,DISK], DatanodeInfoWithStorage[127.0.0.1:44670,DS-64d46376-dddb-4fe9-bdcb-f8e1d29be3a0,DISK], DatanodeInfoWithStorage[127.0.0.1:42630,DS-b5f9d9bc-318c-44a0-8ef3-b926a1175b40,DISK], DatanodeInfoWithStorage[127.0.0.1:40732,DS-bed0361f-c571-4eb5-954d-cdea7bde7fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:43396,DS-af287ef7-569f-4e76-855c-6d912885b909,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1374625176-172.17.0.4-1595412721776:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35023,DS-74d9e727-0186-42b6-aef2-74fbecdaa545,DISK], DatanodeInfoWithStorage[127.0.0.1:45502,DS-4e45ce79-fa80-4281-9620-2124d5df3a0f,DISK], DatanodeInfoWithStorage[127.0.0.1:40163,DS-c91ddfb8-0f24-4f68-9cb7-f78b9558c08e,DISK], DatanodeInfoWithStorage[127.0.0.1:46824,DS-bc322651-103d-4224-87c2-195f3832c42f,DISK], DatanodeInfoWithStorage[127.0.0.1:44670,DS-64d46376-dddb-4fe9-bdcb-f8e1d29be3a0,DISK], DatanodeInfoWithStorage[127.0.0.1:42630,DS-b5f9d9bc-318c-44a0-8ef3-b926a1175b40,DISK], DatanodeInfoWithStorage[127.0.0.1:40732,DS-bed0361f-c571-4eb5-954d-cdea7bde7fc3,DISK], DatanodeInfoWithStorage[127.0.0.1:43396,DS-af287ef7-569f-4e76-855c-6d912885b909,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.namenode.datanode.registration.ip-hostname-check
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-608306040-172.17.0.4-1595412753741:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35440,DS-e6125c23-b38c-4c01-921d-ec36d61a2381,DISK], DatanodeInfoWithStorage[127.0.0.1:38707,DS-f57406fa-09a0-464d-b18b-3cfde0852001,DISK], DatanodeInfoWithStorage[127.0.0.1:41667,DS-cb2ab378-815e-45d6-9021-ccaa48c41647,DISK], DatanodeInfoWithStorage[127.0.0.1:32801,DS-7e51a140-31c0-4c7d-b82a-f67ba562ff02,DISK], DatanodeInfoWithStorage[127.0.0.1:43214,DS-627a242f-312f-41e3-ae14-1cff1ce9447d,DISK], DatanodeInfoWithStorage[127.0.0.1:36587,DS-f1601613-46c9-417a-a8af-ed768d36f729,DISK], DatanodeInfoWithStorage[127.0.0.1:33933,DS-c1b4f7bd-1078-4f68-823f-1dbdd634eca7,DISK], DatanodeInfoWithStorage[127.0.0.1:43570,DS-83ccc6e7-9269-4114-8b04-766c8e9932e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-608306040-172.17.0.4-1595412753741:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35440,DS-e6125c23-b38c-4c01-921d-ec36d61a2381,DISK], DatanodeInfoWithStorage[127.0.0.1:38707,DS-f57406fa-09a0-464d-b18b-3cfde0852001,DISK], DatanodeInfoWithStorage[127.0.0.1:41667,DS-cb2ab378-815e-45d6-9021-ccaa48c41647,DISK], DatanodeInfoWithStorage[127.0.0.1:32801,DS-7e51a140-31c0-4c7d-b82a-f67ba562ff02,DISK], DatanodeInfoWithStorage[127.0.0.1:43214,DS-627a242f-312f-41e3-ae14-1cff1ce9447d,DISK], DatanodeInfoWithStorage[127.0.0.1:36587,DS-f1601613-46c9-417a-a8af-ed768d36f729,DISK], DatanodeInfoWithStorage[127.0.0.1:33933,DS-c1b4f7bd-1078-4f68-823f-1dbdd634eca7,DISK], DatanodeInfoWithStorage[127.0.0.1:43570,DS-83ccc6e7-9269-4114-8b04-766c8e9932e7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.datanode.registration.ip-hostname-check
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-827019686-172.17.0.4-1595412824594:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39914,DS-e4abea34-e757-49a7-a37d-27ddef4a5c67,DISK], DatanodeInfoWithStorage[127.0.0.1:40290,DS-f0c7b35c-35b5-46a0-9692-15c13d750ee9,DISK], DatanodeInfoWithStorage[127.0.0.1:33579,DS-db1a6927-d10d-4cbd-bc8c-97b52a4324ec,DISK], DatanodeInfoWithStorage[127.0.0.1:32885,DS-d06ae6d6-41e1-46e8-b181-f7f240e16f5a,DISK], DatanodeInfoWithStorage[127.0.0.1:37472,DS-714e84d5-e652-4b32-a3a8-753c6532eacb,DISK], DatanodeInfoWithStorage[127.0.0.1:39569,DS-a553bdc9-e184-46fb-a713-458aaf613927,DISK], DatanodeInfoWithStorage[127.0.0.1:36715,DS-3531dad4-ac94-4dcf-9bb1-f98afab18b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:38696,DS-e2a6c503-5248-4f7d-9dd2-b9c3e2eb2c76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-827019686-172.17.0.4-1595412824594:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39914,DS-e4abea34-e757-49a7-a37d-27ddef4a5c67,DISK], DatanodeInfoWithStorage[127.0.0.1:40290,DS-f0c7b35c-35b5-46a0-9692-15c13d750ee9,DISK], DatanodeInfoWithStorage[127.0.0.1:33579,DS-db1a6927-d10d-4cbd-bc8c-97b52a4324ec,DISK], DatanodeInfoWithStorage[127.0.0.1:32885,DS-d06ae6d6-41e1-46e8-b181-f7f240e16f5a,DISK], DatanodeInfoWithStorage[127.0.0.1:37472,DS-714e84d5-e652-4b32-a3a8-753c6532eacb,DISK], DatanodeInfoWithStorage[127.0.0.1:39569,DS-a553bdc9-e184-46fb-a713-458aaf613927,DISK], DatanodeInfoWithStorage[127.0.0.1:36715,DS-3531dad4-ac94-4dcf-9bb1-f98afab18b2f,DISK], DatanodeInfoWithStorage[127.0.0.1:38696,DS-e2a6c503-5248-4f7d-9dd2-b9c3e2eb2c76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.datanode.registration.ip-hostname-check
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-324663095-172.17.0.4-1595414278487:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45619,DS-1b8c1ff9-5c8a-4567-b4a8-e34194423231,DISK], DatanodeInfoWithStorage[127.0.0.1:36120,DS-ccd287a7-d484-46de-80e4-73030ef4b914,DISK], DatanodeInfoWithStorage[127.0.0.1:34362,DS-e8b66979-7188-4e51-9bd8-e4b47d2cfbbe,DISK], DatanodeInfoWithStorage[127.0.0.1:46457,DS-64f8cbd5-bd78-4792-b4d2-fa497eebc2a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41992,DS-a8bf2568-0937-41e0-8a58-0e3179d0959c,DISK], DatanodeInfoWithStorage[127.0.0.1:43822,DS-bb404a9d-6a83-4881-a4bb-7295f7e11f51,DISK], DatanodeInfoWithStorage[127.0.0.1:41106,DS-6ab6d18d-0d10-4cef-821b-dfcc709b6c13,DISK], DatanodeInfoWithStorage[127.0.0.1:35882,DS-17a999f1-e72f-4a1f-9e87-229f198c7936,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-324663095-172.17.0.4-1595414278487:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45619,DS-1b8c1ff9-5c8a-4567-b4a8-e34194423231,DISK], DatanodeInfoWithStorage[127.0.0.1:36120,DS-ccd287a7-d484-46de-80e4-73030ef4b914,DISK], DatanodeInfoWithStorage[127.0.0.1:34362,DS-e8b66979-7188-4e51-9bd8-e4b47d2cfbbe,DISK], DatanodeInfoWithStorage[127.0.0.1:46457,DS-64f8cbd5-bd78-4792-b4d2-fa497eebc2a0,DISK], DatanodeInfoWithStorage[127.0.0.1:41992,DS-a8bf2568-0937-41e0-8a58-0e3179d0959c,DISK], DatanodeInfoWithStorage[127.0.0.1:43822,DS-bb404a9d-6a83-4881-a4bb-7295f7e11f51,DISK], DatanodeInfoWithStorage[127.0.0.1:41106,DS-6ab6d18d-0d10-4cef-821b-dfcc709b6c13,DISK], DatanodeInfoWithStorage[127.0.0.1:35882,DS-17a999f1-e72f-4a1f-9e87-229f198c7936,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.datanode.registration.ip-hostname-check
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1606104368-172.17.0.4-1595414311639:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34298,DS-8734d5a9-d61b-4e83-82c5-eadac9c663b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36941,DS-d8327b79-9630-4f2b-8704-1322052b8d79,DISK], DatanodeInfoWithStorage[127.0.0.1:35838,DS-5fa42ad4-e208-4df9-ae1e-af3e14b09703,DISK], DatanodeInfoWithStorage[127.0.0.1:44128,DS-4a3097a9-be5e-4394-b4dd-493500d0a237,DISK], DatanodeInfoWithStorage[127.0.0.1:39226,DS-e320952b-c93a-4fa1-998a-93f42f3b147a,DISK], DatanodeInfoWithStorage[127.0.0.1:32882,DS-7091184d-abb2-4dde-92d2-51afb6aa2bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:46722,DS-776696ad-11b2-4ff5-9953-eedd4b0dee97,DISK], DatanodeInfoWithStorage[127.0.0.1:39825,DS-510aaca5-25bc-45f2-b4a8-a46d75f62833,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1606104368-172.17.0.4-1595414311639:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34298,DS-8734d5a9-d61b-4e83-82c5-eadac9c663b4,DISK], DatanodeInfoWithStorage[127.0.0.1:36941,DS-d8327b79-9630-4f2b-8704-1322052b8d79,DISK], DatanodeInfoWithStorage[127.0.0.1:35838,DS-5fa42ad4-e208-4df9-ae1e-af3e14b09703,DISK], DatanodeInfoWithStorage[127.0.0.1:44128,DS-4a3097a9-be5e-4394-b4dd-493500d0a237,DISK], DatanodeInfoWithStorage[127.0.0.1:39226,DS-e320952b-c93a-4fa1-998a-93f42f3b147a,DISK], DatanodeInfoWithStorage[127.0.0.1:32882,DS-7091184d-abb2-4dde-92d2-51afb6aa2bd8,DISK], DatanodeInfoWithStorage[127.0.0.1:46722,DS-776696ad-11b2-4ff5-9953-eedd4b0dee97,DISK], DatanodeInfoWithStorage[127.0.0.1:39825,DS-510aaca5-25bc-45f2-b4a8-a46d75f62833,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.datanode.registration.ip-hostname-check
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1781992777-172.17.0.4-1595414422032:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42763,DS-33803615-6f54-4984-9539-c4df6e214458,DISK], DatanodeInfoWithStorage[127.0.0.1:38101,DS-35e88a82-4db7-4347-8cb5-29feb174486b,DISK], DatanodeInfoWithStorage[127.0.0.1:39162,DS-91040ae9-a8dc-4f6a-9548-870444ad15da,DISK], DatanodeInfoWithStorage[127.0.0.1:46590,DS-b8d4c3f3-6280-473d-b820-0a5773cbb5b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40095,DS-c0a5f00e-bc1f-45db-a735-c7acfdade3b2,DISK], DatanodeInfoWithStorage[127.0.0.1:32826,DS-724b86fe-351b-4571-a2be-606d201019e9,DISK], DatanodeInfoWithStorage[127.0.0.1:39529,DS-76825c77-2437-4860-8420-4cdda60ee710,DISK], DatanodeInfoWithStorage[127.0.0.1:42216,DS-64b110c7-977c-442f-b098-cdbe705b6b16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1781992777-172.17.0.4-1595414422032:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42763,DS-33803615-6f54-4984-9539-c4df6e214458,DISK], DatanodeInfoWithStorage[127.0.0.1:38101,DS-35e88a82-4db7-4347-8cb5-29feb174486b,DISK], DatanodeInfoWithStorage[127.0.0.1:39162,DS-91040ae9-a8dc-4f6a-9548-870444ad15da,DISK], DatanodeInfoWithStorage[127.0.0.1:46590,DS-b8d4c3f3-6280-473d-b820-0a5773cbb5b0,DISK], DatanodeInfoWithStorage[127.0.0.1:40095,DS-c0a5f00e-bc1f-45db-a735-c7acfdade3b2,DISK], DatanodeInfoWithStorage[127.0.0.1:32826,DS-724b86fe-351b-4571-a2be-606d201019e9,DISK], DatanodeInfoWithStorage[127.0.0.1:39529,DS-76825c77-2437-4860-8420-4cdda60ee710,DISK], DatanodeInfoWithStorage[127.0.0.1:42216,DS-64b110c7-977c-442f-b098-cdbe705b6b16,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.datanode.registration.ip-hostname-check
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-438237076-172.17.0.4-1595414607352:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35374,DS-100cebde-a7e1-4e36-9844-3a7ba0d6d2a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43233,DS-7fcdee80-c9e6-405c-806c-27f9df1c81a4,DISK], DatanodeInfoWithStorage[127.0.0.1:38618,DS-5223521c-8dce-4b8b-9518-af2335d53e00,DISK], DatanodeInfoWithStorage[127.0.0.1:46829,DS-63b38734-babe-4d96-983f-ee83a1b68e38,DISK], DatanodeInfoWithStorage[127.0.0.1:41548,DS-cc4bcbaa-a56e-4e32-9fa9-346fc821afa3,DISK], DatanodeInfoWithStorage[127.0.0.1:32861,DS-ffbd572b-9350-48df-8c63-4a96acba3b11,DISK], DatanodeInfoWithStorage[127.0.0.1:43623,DS-0e3fed9a-e4c9-4190-99c1-a89276943a7b,DISK], DatanodeInfoWithStorage[127.0.0.1:41310,DS-3de24898-331e-47cd-9364-89aeef5e796c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-438237076-172.17.0.4-1595414607352:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35374,DS-100cebde-a7e1-4e36-9844-3a7ba0d6d2a0,DISK], DatanodeInfoWithStorage[127.0.0.1:43233,DS-7fcdee80-c9e6-405c-806c-27f9df1c81a4,DISK], DatanodeInfoWithStorage[127.0.0.1:38618,DS-5223521c-8dce-4b8b-9518-af2335d53e00,DISK], DatanodeInfoWithStorage[127.0.0.1:46829,DS-63b38734-babe-4d96-983f-ee83a1b68e38,DISK], DatanodeInfoWithStorage[127.0.0.1:41548,DS-cc4bcbaa-a56e-4e32-9fa9-346fc821afa3,DISK], DatanodeInfoWithStorage[127.0.0.1:32861,DS-ffbd572b-9350-48df-8c63-4a96acba3b11,DISK], DatanodeInfoWithStorage[127.0.0.1:43623,DS-0e3fed9a-e4c9-4190-99c1-a89276943a7b,DISK], DatanodeInfoWithStorage[127.0.0.1:41310,DS-3de24898-331e-47cd-9364-89aeef5e796c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.datanode.registration.ip-hostname-check
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-985773728-172.17.0.4-1595414846551:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33405,DS-45c9a24f-f6c4-4e9a-8d80-37636134193e,DISK], DatanodeInfoWithStorage[127.0.0.1:45042,DS-8e2a12ed-b905-4deb-b9bd-d1637c1c365d,DISK], DatanodeInfoWithStorage[127.0.0.1:38831,DS-f868b84f-aaa6-4833-acef-99480dc135f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38345,DS-a7fb6151-6b91-48ff-903d-5262b0b5d0d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36046,DS-3564793b-0242-41be-8311-79068f04ada5,DISK], DatanodeInfoWithStorage[127.0.0.1:37661,DS-f8d12400-a6c4-45bd-803a-69eee4434109,DISK], DatanodeInfoWithStorage[127.0.0.1:36644,DS-4959f5c2-5568-4fcf-8e23-aaba6d050361,DISK], DatanodeInfoWithStorage[127.0.0.1:34813,DS-d416bd14-4d62-4ee3-b9ef-0dfad47729c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-985773728-172.17.0.4-1595414846551:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33405,DS-45c9a24f-f6c4-4e9a-8d80-37636134193e,DISK], DatanodeInfoWithStorage[127.0.0.1:45042,DS-8e2a12ed-b905-4deb-b9bd-d1637c1c365d,DISK], DatanodeInfoWithStorage[127.0.0.1:38831,DS-f868b84f-aaa6-4833-acef-99480dc135f5,DISK], DatanodeInfoWithStorage[127.0.0.1:38345,DS-a7fb6151-6b91-48ff-903d-5262b0b5d0d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36046,DS-3564793b-0242-41be-8311-79068f04ada5,DISK], DatanodeInfoWithStorage[127.0.0.1:37661,DS-f8d12400-a6c4-45bd-803a-69eee4434109,DISK], DatanodeInfoWithStorage[127.0.0.1:36644,DS-4959f5c2-5568-4fcf-8e23-aaba6d050361,DISK], DatanodeInfoWithStorage[127.0.0.1:34813,DS-d416bd14-4d62-4ee3-b9ef-0dfad47729c1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.datanode.registration.ip-hostname-check
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-386547282-172.17.0.4-1595415044875:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39737,DS-200bb487-a0ac-472e-817b-57e89d09fa3d,DISK], DatanodeInfoWithStorage[127.0.0.1:33985,DS-dd4e1f15-1b5f-4b66-b88e-34077b981547,DISK], DatanodeInfoWithStorage[127.0.0.1:39788,DS-cdc75048-ef5d-4ab4-aced-5ac5b27b384f,DISK], DatanodeInfoWithStorage[127.0.0.1:46440,DS-ef35b3d7-65ac-49c7-85e4-12d978165da5,DISK], DatanodeInfoWithStorage[127.0.0.1:36277,DS-7db14abf-3879-460f-a03d-9fde9ce878bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38034,DS-967905bd-1782-44a3-bac3-3331b7be528c,DISK], DatanodeInfoWithStorage[127.0.0.1:45266,DS-e9fb8571-6c50-4a64-9313-3736856a343f,DISK], DatanodeInfoWithStorage[127.0.0.1:40592,DS-d7a7e62f-5c14-452c-a491-9c49bc26f177,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-386547282-172.17.0.4-1595415044875:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39737,DS-200bb487-a0ac-472e-817b-57e89d09fa3d,DISK], DatanodeInfoWithStorage[127.0.0.1:33985,DS-dd4e1f15-1b5f-4b66-b88e-34077b981547,DISK], DatanodeInfoWithStorage[127.0.0.1:39788,DS-cdc75048-ef5d-4ab4-aced-5ac5b27b384f,DISK], DatanodeInfoWithStorage[127.0.0.1:46440,DS-ef35b3d7-65ac-49c7-85e4-12d978165da5,DISK], DatanodeInfoWithStorage[127.0.0.1:36277,DS-7db14abf-3879-460f-a03d-9fde9ce878bf,DISK], DatanodeInfoWithStorage[127.0.0.1:38034,DS-967905bd-1782-44a3-bac3-3331b7be528c,DISK], DatanodeInfoWithStorage[127.0.0.1:45266,DS-e9fb8571-6c50-4a64-9313-3736856a343f,DISK], DatanodeInfoWithStorage[127.0.0.1:40592,DS-d7a7e62f-5c14-452c-a491-9c49bc26f177,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.datanode.registration.ip-hostname-check
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1851030242-172.17.0.4-1595415149382:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44537,DS-7a5de6a2-f3d0-405e-909b-94935a8be6b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34072,DS-e7a85c5b-d8f9-4705-ba35-9cd02d4d7b5b,DISK], DatanodeInfoWithStorage[127.0.0.1:38553,DS-cee4a602-fee2-496e-9224-40d231203642,DISK], DatanodeInfoWithStorage[127.0.0.1:43730,DS-af6a79df-c93d-49dc-8692-50a26dba299f,DISK], DatanodeInfoWithStorage[127.0.0.1:34877,DS-9a8f4ec6-de15-4d94-b2f8-33e7681966bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35280,DS-56ab7cdb-eae3-4e4e-a964-7233b2b537d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46639,DS-60e25147-623e-4966-9956-042e861e862b,DISK], DatanodeInfoWithStorage[127.0.0.1:38168,DS-ea992e27-432f-4de3-9fea-bbd75e62938f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1851030242-172.17.0.4-1595415149382:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44537,DS-7a5de6a2-f3d0-405e-909b-94935a8be6b1,DISK], DatanodeInfoWithStorage[127.0.0.1:34072,DS-e7a85c5b-d8f9-4705-ba35-9cd02d4d7b5b,DISK], DatanodeInfoWithStorage[127.0.0.1:38553,DS-cee4a602-fee2-496e-9224-40d231203642,DISK], DatanodeInfoWithStorage[127.0.0.1:43730,DS-af6a79df-c93d-49dc-8692-50a26dba299f,DISK], DatanodeInfoWithStorage[127.0.0.1:34877,DS-9a8f4ec6-de15-4d94-b2f8-33e7681966bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35280,DS-56ab7cdb-eae3-4e4e-a964-7233b2b537d0,DISK], DatanodeInfoWithStorage[127.0.0.1:46639,DS-60e25147-623e-4966-9956-042e861e862b,DISK], DatanodeInfoWithStorage[127.0.0.1:38168,DS-ea992e27-432f-4de3-9fea-bbd75e62938f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.datanode.registration.ip-hostname-check
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-376850797-172.17.0.4-1595415259284:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34761,DS-38b972a4-5a98-498d-b99a-e01db251922b,DISK], DatanodeInfoWithStorage[127.0.0.1:46399,DS-22f4d261-67b6-4c56-a0c3-253d2db0123c,DISK], DatanodeInfoWithStorage[127.0.0.1:36884,DS-0e6b950c-13f6-4d25-9d64-38324b4461b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36090,DS-39e15f08-33c8-43b0-99b3-d94eb83e148b,DISK], DatanodeInfoWithStorage[127.0.0.1:41301,DS-5b993561-11e4-4a41-a6a2-d567517ce6fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35470,DS-3e179b88-4310-4c38-b0b0-6546f667c01b,DISK], DatanodeInfoWithStorage[127.0.0.1:39006,DS-bf53e1d9-a881-4b0f-8d87-34c2e8be5207,DISK], DatanodeInfoWithStorage[127.0.0.1:46497,DS-75b1d4b6-a5fb-44cc-a598-df8f81d1638f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-376850797-172.17.0.4-1595415259284:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34761,DS-38b972a4-5a98-498d-b99a-e01db251922b,DISK], DatanodeInfoWithStorage[127.0.0.1:46399,DS-22f4d261-67b6-4c56-a0c3-253d2db0123c,DISK], DatanodeInfoWithStorage[127.0.0.1:36884,DS-0e6b950c-13f6-4d25-9d64-38324b4461b6,DISK], DatanodeInfoWithStorage[127.0.0.1:36090,DS-39e15f08-33c8-43b0-99b3-d94eb83e148b,DISK], DatanodeInfoWithStorage[127.0.0.1:41301,DS-5b993561-11e4-4a41-a6a2-d567517ce6fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35470,DS-3e179b88-4310-4c38-b0b0-6546f667c01b,DISK], DatanodeInfoWithStorage[127.0.0.1:39006,DS-bf53e1d9-a881-4b0f-8d87-34c2e8be5207,DISK], DatanodeInfoWithStorage[127.0.0.1:46497,DS-75b1d4b6-a5fb-44cc-a598-df8f81d1638f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.namenode.datanode.registration.ip-hostname-check
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-334867942-172.17.0.4-1595415598875:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39653,DS-8d8ec4f9-49b9-49eb-871b-1b853b2ebcb2,DISK], DatanodeInfoWithStorage[127.0.0.1:44551,DS-4779cc32-0d84-4fee-9aeb-a0c6c2f7d02b,DISK], DatanodeInfoWithStorage[127.0.0.1:33020,DS-d0fbcb35-cef2-4289-b00e-f99e0a6f5ac2,DISK], DatanodeInfoWithStorage[127.0.0.1:37933,DS-4ca8e500-4c7c-44e8-88fb-140ea5dff22b,DISK], DatanodeInfoWithStorage[127.0.0.1:40160,DS-7eb40214-f155-4191-b8df-fb48e1e73645,DISK], DatanodeInfoWithStorage[127.0.0.1:46601,DS-fd2f4871-fbb7-474a-98b2-ba638776db2a,DISK], DatanodeInfoWithStorage[127.0.0.1:39025,DS-f2539f0a-0687-4196-89d7-b6140007ac4c,DISK], DatanodeInfoWithStorage[127.0.0.1:45642,DS-493639cb-7e4b-4c31-b0a9-4d17415f189e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-334867942-172.17.0.4-1595415598875:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39653,DS-8d8ec4f9-49b9-49eb-871b-1b853b2ebcb2,DISK], DatanodeInfoWithStorage[127.0.0.1:44551,DS-4779cc32-0d84-4fee-9aeb-a0c6c2f7d02b,DISK], DatanodeInfoWithStorage[127.0.0.1:33020,DS-d0fbcb35-cef2-4289-b00e-f99e0a6f5ac2,DISK], DatanodeInfoWithStorage[127.0.0.1:37933,DS-4ca8e500-4c7c-44e8-88fb-140ea5dff22b,DISK], DatanodeInfoWithStorage[127.0.0.1:40160,DS-7eb40214-f155-4191-b8df-fb48e1e73645,DISK], DatanodeInfoWithStorage[127.0.0.1:46601,DS-fd2f4871-fbb7-474a-98b2-ba638776db2a,DISK], DatanodeInfoWithStorage[127.0.0.1:39025,DS-f2539f0a-0687-4196-89d7-b6140007ac4c,DISK], DatanodeInfoWithStorage[127.0.0.1:45642,DS-493639cb-7e4b-4c31-b0a9-4d17415f189e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.namenode.datanode.registration.ip-hostname-check
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery1
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-518183025-172.17.0.4-1595416200326:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36423,DS-8a6efde5-db48-47a7-9ecb-74f9215173b3,DISK], DatanodeInfoWithStorage[127.0.0.1:38850,DS-bcf99929-5acc-49dc-941f-2894bde1f445,DISK], DatanodeInfoWithStorage[127.0.0.1:41231,DS-6d9d5472-d4f5-481f-9901-1f93ad586831,DISK], DatanodeInfoWithStorage[127.0.0.1:40142,DS-a4b001be-ea52-44f7-84dd-4a817de0bbce,DISK], DatanodeInfoWithStorage[127.0.0.1:42196,DS-a51ecc8e-3997-4e2f-8b94-e0144e2ba43a,DISK], DatanodeInfoWithStorage[127.0.0.1:42315,DS-78582e82-d9d6-4579-8e80-4e26022cc18e,DISK], DatanodeInfoWithStorage[127.0.0.1:42151,DS-9faa21c5-7c19-425f-becb-1edd97bbc8f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33018,DS-488aaab6-b774-4269-9962-b560c1a9c141,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-518183025-172.17.0.4-1595416200326:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36423,DS-8a6efde5-db48-47a7-9ecb-74f9215173b3,DISK], DatanodeInfoWithStorage[127.0.0.1:38850,DS-bcf99929-5acc-49dc-941f-2894bde1f445,DISK], DatanodeInfoWithStorage[127.0.0.1:41231,DS-6d9d5472-d4f5-481f-9901-1f93ad586831,DISK], DatanodeInfoWithStorage[127.0.0.1:40142,DS-a4b001be-ea52-44f7-84dd-4a817de0bbce,DISK], DatanodeInfoWithStorage[127.0.0.1:42196,DS-a51ecc8e-3997-4e2f-8b94-e0144e2ba43a,DISK], DatanodeInfoWithStorage[127.0.0.1:42315,DS-78582e82-d9d6-4579-8e80-4e26022cc18e,DISK], DatanodeInfoWithStorage[127.0.0.1:42151,DS-9faa21c5-7c19-425f-becb-1edd97bbc8f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33018,DS-488aaab6-b774-4269-9962-b560c1a9c141,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery1(TestFileChecksum.java:312)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 16 out of 50
result: false positive !!!
Total execution time in seconds : 5250
