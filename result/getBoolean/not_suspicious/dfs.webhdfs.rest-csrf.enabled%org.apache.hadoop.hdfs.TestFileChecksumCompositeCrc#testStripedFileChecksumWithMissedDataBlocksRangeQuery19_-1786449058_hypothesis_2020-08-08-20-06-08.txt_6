reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1190546506-172.17.0.18-1596917186798:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37108,DS-d988699b-6dac-49a6-b6e0-5117851f93ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38704,DS-abbbb9f3-990e-46ab-8e85-a31f92e427fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41889,DS-48a1a4ac-1866-412d-b82d-7b19d717c1d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42760,DS-dd8d822b-14b4-4e31-8907-e23fab31a5a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35779,DS-d74aa7cc-60a1-44ab-b839-ceb69ddadb9a,DISK], DatanodeInfoWithStorage[127.0.0.1:34055,DS-8b02d019-7680-4e8a-a1ed-3dcb488fd16c,DISK], DatanodeInfoWithStorage[127.0.0.1:43971,DS-1cb84731-f5bb-4d96-8140-70dfb2ef4fe6,DISK], DatanodeInfoWithStorage[127.0.0.1:39865,DS-70af1d53-b44f-4d9c-911c-caf5b9fc02de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1190546506-172.17.0.18-1596917186798:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37108,DS-d988699b-6dac-49a6-b6e0-5117851f93ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38704,DS-abbbb9f3-990e-46ab-8e85-a31f92e427fd,DISK], DatanodeInfoWithStorage[127.0.0.1:41889,DS-48a1a4ac-1866-412d-b82d-7b19d717c1d6,DISK], DatanodeInfoWithStorage[127.0.0.1:42760,DS-dd8d822b-14b4-4e31-8907-e23fab31a5a0,DISK], DatanodeInfoWithStorage[127.0.0.1:35779,DS-d74aa7cc-60a1-44ab-b839-ceb69ddadb9a,DISK], DatanodeInfoWithStorage[127.0.0.1:34055,DS-8b02d019-7680-4e8a-a1ed-3dcb488fd16c,DISK], DatanodeInfoWithStorage[127.0.0.1:43971,DS-1cb84731-f5bb-4d96-8140-70dfb2ef4fe6,DISK], DatanodeInfoWithStorage[127.0.0.1:39865,DS-70af1d53-b44f-4d9c-911c-caf5b9fc02de,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1696914208-172.17.0.18-1596917327074:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36461,DS-482e92bb-a9f0-4b18-9a3c-c99c88ba44b9,DISK], DatanodeInfoWithStorage[127.0.0.1:40843,DS-e4174369-9e87-40b7-812f-eab9ed7ec7b6,DISK], DatanodeInfoWithStorage[127.0.0.1:42618,DS-2e027446-e87e-4203-8c4e-d0f6d846e4b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40883,DS-c263e48a-8040-4eb1-898b-272152b19cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:33257,DS-8f89c2d3-da88-480b-a0b4-fbdbbf5d31c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33127,DS-e61c9d48-d8bb-4109-861a-dec5a099e7e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40637,DS-78fa40a1-7636-43dd-925a-5b83a4809b87,DISK], DatanodeInfoWithStorage[127.0.0.1:44772,DS-80fdfca3-e134-4f3a-9b1f-cbeb946979e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1696914208-172.17.0.18-1596917327074:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36461,DS-482e92bb-a9f0-4b18-9a3c-c99c88ba44b9,DISK], DatanodeInfoWithStorage[127.0.0.1:40843,DS-e4174369-9e87-40b7-812f-eab9ed7ec7b6,DISK], DatanodeInfoWithStorage[127.0.0.1:42618,DS-2e027446-e87e-4203-8c4e-d0f6d846e4b6,DISK], DatanodeInfoWithStorage[127.0.0.1:40883,DS-c263e48a-8040-4eb1-898b-272152b19cfa,DISK], DatanodeInfoWithStorage[127.0.0.1:33257,DS-8f89c2d3-da88-480b-a0b4-fbdbbf5d31c6,DISK], DatanodeInfoWithStorage[127.0.0.1:33127,DS-e61c9d48-d8bb-4109-861a-dec5a099e7e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40637,DS-78fa40a1-7636-43dd-925a-5b83a4809b87,DISK], DatanodeInfoWithStorage[127.0.0.1:44772,DS-80fdfca3-e134-4f3a-9b1f-cbeb946979e4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1077744291-172.17.0.18-1596917467039:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33336,DS-995b74f6-6eb9-4359-a758-b21b19dae161,DISK], DatanodeInfoWithStorage[127.0.0.1:46345,DS-1d82df62-3f22-4d72-af27-4dd9b5b56592,DISK], DatanodeInfoWithStorage[127.0.0.1:34819,DS-0e976732-21ce-4636-bc33-a64be3c61105,DISK], DatanodeInfoWithStorage[127.0.0.1:37654,DS-baaca64c-95b0-4fc9-8945-7b975e10045b,DISK], DatanodeInfoWithStorage[127.0.0.1:37274,DS-3c3209a1-f9dc-44f3-8055-635005310618,DISK], DatanodeInfoWithStorage[127.0.0.1:34478,DS-5122105b-43d5-4112-90b1-2fda39259075,DISK], DatanodeInfoWithStorage[127.0.0.1:34449,DS-da6f6b96-17cd-46ff-90ea-0aa737e431c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33314,DS-7642e79a-9bae-44ba-b46f-bc9c38fda539,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1077744291-172.17.0.18-1596917467039:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33336,DS-995b74f6-6eb9-4359-a758-b21b19dae161,DISK], DatanodeInfoWithStorage[127.0.0.1:46345,DS-1d82df62-3f22-4d72-af27-4dd9b5b56592,DISK], DatanodeInfoWithStorage[127.0.0.1:34819,DS-0e976732-21ce-4636-bc33-a64be3c61105,DISK], DatanodeInfoWithStorage[127.0.0.1:37654,DS-baaca64c-95b0-4fc9-8945-7b975e10045b,DISK], DatanodeInfoWithStorage[127.0.0.1:37274,DS-3c3209a1-f9dc-44f3-8055-635005310618,DISK], DatanodeInfoWithStorage[127.0.0.1:34478,DS-5122105b-43d5-4112-90b1-2fda39259075,DISK], DatanodeInfoWithStorage[127.0.0.1:34449,DS-da6f6b96-17cd-46ff-90ea-0aa737e431c1,DISK], DatanodeInfoWithStorage[127.0.0.1:33314,DS-7642e79a-9bae-44ba-b46f-bc9c38fda539,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1071803686-172.17.0.18-1596918091994:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39075,DS-f2eea3fe-7701-4a33-a4bf-9e0184857903,DISK], DatanodeInfoWithStorage[127.0.0.1:41583,DS-bc7ef6dc-da3b-4250-96f8-fcd99ef956a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46084,DS-22d5fb95-cb3c-49f6-82b8-93d445113181,DISK], DatanodeInfoWithStorage[127.0.0.1:34930,DS-1a2d2478-62d0-43dd-a04a-c251075fa0db,DISK], DatanodeInfoWithStorage[127.0.0.1:37848,DS-f4ed0a15-c109-416e-8b6f-2207b3790c19,DISK], DatanodeInfoWithStorage[127.0.0.1:43486,DS-31b8b89d-282c-4599-8e9a-0bdf9d7435f0,DISK], DatanodeInfoWithStorage[127.0.0.1:41237,DS-10499939-190f-415f-bdf1-f94fc5492532,DISK], DatanodeInfoWithStorage[127.0.0.1:35038,DS-2ac9b9a8-12c5-41f3-959d-2028d2e53262,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1071803686-172.17.0.18-1596918091994:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39075,DS-f2eea3fe-7701-4a33-a4bf-9e0184857903,DISK], DatanodeInfoWithStorage[127.0.0.1:41583,DS-bc7ef6dc-da3b-4250-96f8-fcd99ef956a2,DISK], DatanodeInfoWithStorage[127.0.0.1:46084,DS-22d5fb95-cb3c-49f6-82b8-93d445113181,DISK], DatanodeInfoWithStorage[127.0.0.1:34930,DS-1a2d2478-62d0-43dd-a04a-c251075fa0db,DISK], DatanodeInfoWithStorage[127.0.0.1:37848,DS-f4ed0a15-c109-416e-8b6f-2207b3790c19,DISK], DatanodeInfoWithStorage[127.0.0.1:43486,DS-31b8b89d-282c-4599-8e9a-0bdf9d7435f0,DISK], DatanodeInfoWithStorage[127.0.0.1:41237,DS-10499939-190f-415f-bdf1-f94fc5492532,DISK], DatanodeInfoWithStorage[127.0.0.1:35038,DS-2ac9b9a8-12c5-41f3-959d-2028d2e53262,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2083255824-172.17.0.18-1596918292542:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36477,DS-10c14997-a2e5-40d6-82f0-905bb36efc83,DISK], DatanodeInfoWithStorage[127.0.0.1:35736,DS-dbac217f-22d3-4315-a72f-ad9a2f144c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:36856,DS-94992457-d36a-4cd3-9a51-1ff756924c21,DISK], DatanodeInfoWithStorage[127.0.0.1:37108,DS-368c31f5-0827-4d29-abd7-9c9ccebdced2,DISK], DatanodeInfoWithStorage[127.0.0.1:34799,DS-c1dadd60-3bf9-46e6-bd75-fc820f08b363,DISK], DatanodeInfoWithStorage[127.0.0.1:33574,DS-0874c8fc-fcc6-4828-a6ce-853c072bcb28,DISK], DatanodeInfoWithStorage[127.0.0.1:39375,DS-77b78a08-b646-4061-9b19-f424ffaaaf63,DISK], DatanodeInfoWithStorage[127.0.0.1:36784,DS-136191e9-9372-4454-a16a-3f9303afe405,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2083255824-172.17.0.18-1596918292542:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36477,DS-10c14997-a2e5-40d6-82f0-905bb36efc83,DISK], DatanodeInfoWithStorage[127.0.0.1:35736,DS-dbac217f-22d3-4315-a72f-ad9a2f144c7f,DISK], DatanodeInfoWithStorage[127.0.0.1:36856,DS-94992457-d36a-4cd3-9a51-1ff756924c21,DISK], DatanodeInfoWithStorage[127.0.0.1:37108,DS-368c31f5-0827-4d29-abd7-9c9ccebdced2,DISK], DatanodeInfoWithStorage[127.0.0.1:34799,DS-c1dadd60-3bf9-46e6-bd75-fc820f08b363,DISK], DatanodeInfoWithStorage[127.0.0.1:33574,DS-0874c8fc-fcc6-4828-a6ce-853c072bcb28,DISK], DatanodeInfoWithStorage[127.0.0.1:39375,DS-77b78a08-b646-4061-9b19-f424ffaaaf63,DISK], DatanodeInfoWithStorage[127.0.0.1:36784,DS-136191e9-9372-4454-a16a-3f9303afe405,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1358771441-172.17.0.18-1596918551450:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33528,DS-2c0c3965-2608-48f3-8f3f-a5ae2b0ef80c,DISK], DatanodeInfoWithStorage[127.0.0.1:37020,DS-6c31f7b1-433d-465d-84e9-3acae67eb661,DISK], DatanodeInfoWithStorage[127.0.0.1:44669,DS-c9425f78-dd2e-473d-874e-5d08d574bc6a,DISK], DatanodeInfoWithStorage[127.0.0.1:34617,DS-b8130974-b8e7-4d1c-b7d1-ce01a2036607,DISK], DatanodeInfoWithStorage[127.0.0.1:39281,DS-9353bb3d-6349-422f-bf6b-b236257aadd5,DISK], DatanodeInfoWithStorage[127.0.0.1:36078,DS-48a80d2d-6bdb-43a6-818b-250b3dd41bbb,DISK], DatanodeInfoWithStorage[127.0.0.1:33339,DS-f157183c-845c-4644-bf61-b7d72b97126a,DISK], DatanodeInfoWithStorage[127.0.0.1:36104,DS-83698b4a-ccd7-4642-8a0f-ad5c0d33eecd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1358771441-172.17.0.18-1596918551450:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33528,DS-2c0c3965-2608-48f3-8f3f-a5ae2b0ef80c,DISK], DatanodeInfoWithStorage[127.0.0.1:37020,DS-6c31f7b1-433d-465d-84e9-3acae67eb661,DISK], DatanodeInfoWithStorage[127.0.0.1:44669,DS-c9425f78-dd2e-473d-874e-5d08d574bc6a,DISK], DatanodeInfoWithStorage[127.0.0.1:34617,DS-b8130974-b8e7-4d1c-b7d1-ce01a2036607,DISK], DatanodeInfoWithStorage[127.0.0.1:39281,DS-9353bb3d-6349-422f-bf6b-b236257aadd5,DISK], DatanodeInfoWithStorage[127.0.0.1:36078,DS-48a80d2d-6bdb-43a6-818b-250b3dd41bbb,DISK], DatanodeInfoWithStorage[127.0.0.1:33339,DS-f157183c-845c-4644-bf61-b7d72b97126a,DISK], DatanodeInfoWithStorage[127.0.0.1:36104,DS-83698b4a-ccd7-4642-8a0f-ad5c0d33eecd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-266926336-172.17.0.18-1596919183859:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45706,DS-69230498-0ff8-4859-8059-6691680405d3,DISK], DatanodeInfoWithStorage[127.0.0.1:41849,DS-35658687-2faf-423e-b3df-ec9a12f1e4fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40717,DS-c834b2cb-a3ba-4d61-87a9-03a2199bba71,DISK], DatanodeInfoWithStorage[127.0.0.1:43336,DS-ed50f0d7-54fb-4215-8672-9fa5b411b94e,DISK], DatanodeInfoWithStorage[127.0.0.1:41451,DS-68d9af35-e2cf-4dad-bf15-87d465f2a0f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43337,DS-a7f4f0da-e4f6-49f6-a234-64d5af397805,DISK], DatanodeInfoWithStorage[127.0.0.1:34018,DS-d9e1b373-27f1-4462-8a6a-f412e3fcd5b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40813,DS-3cb6f52f-42e2-44b5-b0bc-c30fc56e9b53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-266926336-172.17.0.18-1596919183859:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45706,DS-69230498-0ff8-4859-8059-6691680405d3,DISK], DatanodeInfoWithStorage[127.0.0.1:41849,DS-35658687-2faf-423e-b3df-ec9a12f1e4fa,DISK], DatanodeInfoWithStorage[127.0.0.1:40717,DS-c834b2cb-a3ba-4d61-87a9-03a2199bba71,DISK], DatanodeInfoWithStorage[127.0.0.1:43336,DS-ed50f0d7-54fb-4215-8672-9fa5b411b94e,DISK], DatanodeInfoWithStorage[127.0.0.1:41451,DS-68d9af35-e2cf-4dad-bf15-87d465f2a0f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43337,DS-a7f4f0da-e4f6-49f6-a234-64d5af397805,DISK], DatanodeInfoWithStorage[127.0.0.1:34018,DS-d9e1b373-27f1-4462-8a6a-f412e3fcd5b2,DISK], DatanodeInfoWithStorage[127.0.0.1:40813,DS-3cb6f52f-42e2-44b5-b0bc-c30fc56e9b53,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-795217914-172.17.0.18-1596919388034:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44040,DS-ad1e6d45-bfca-4ca3-a61a-990a5f9c28b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44798,DS-b8782521-9f09-432c-8a0b-dd57da30a9bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42111,DS-ee928b15-f30e-4824-8d1f-5814d768ac2f,DISK], DatanodeInfoWithStorage[127.0.0.1:39917,DS-94b33bf0-77f7-4020-aa1f-489efcdb13c8,DISK], DatanodeInfoWithStorage[127.0.0.1:37594,DS-5c6ea65d-9d51-44a2-ad21-90720120ed7e,DISK], DatanodeInfoWithStorage[127.0.0.1:36564,DS-ceb5ed20-36b8-423c-9e41-e7c86ace6b21,DISK], DatanodeInfoWithStorage[127.0.0.1:45568,DS-5cee3471-7003-4996-b2c9-67dc54272760,DISK], DatanodeInfoWithStorage[127.0.0.1:42542,DS-b5e4385d-ce0d-4322-9784-8c586d0a699f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-795217914-172.17.0.18-1596919388034:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44040,DS-ad1e6d45-bfca-4ca3-a61a-990a5f9c28b2,DISK], DatanodeInfoWithStorage[127.0.0.1:44798,DS-b8782521-9f09-432c-8a0b-dd57da30a9bd,DISK], DatanodeInfoWithStorage[127.0.0.1:42111,DS-ee928b15-f30e-4824-8d1f-5814d768ac2f,DISK], DatanodeInfoWithStorage[127.0.0.1:39917,DS-94b33bf0-77f7-4020-aa1f-489efcdb13c8,DISK], DatanodeInfoWithStorage[127.0.0.1:37594,DS-5c6ea65d-9d51-44a2-ad21-90720120ed7e,DISK], DatanodeInfoWithStorage[127.0.0.1:36564,DS-ceb5ed20-36b8-423c-9e41-e7c86ace6b21,DISK], DatanodeInfoWithStorage[127.0.0.1:45568,DS-5cee3471-7003-4996-b2c9-67dc54272760,DISK], DatanodeInfoWithStorage[127.0.0.1:42542,DS-b5e4385d-ce0d-4322-9784-8c586d0a699f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-628514584-172.17.0.18-1596919595943:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37863,DS-287f9a5c-27b4-4b1d-ab79-1fa1fb7bc30b,DISK], DatanodeInfoWithStorage[127.0.0.1:39114,DS-919b6868-3c9d-4678-aa6a-383e49a1a154,DISK], DatanodeInfoWithStorage[127.0.0.1:46753,DS-2089e24c-c937-4276-a05d-21199c2124dd,DISK], DatanodeInfoWithStorage[127.0.0.1:35223,DS-eef9bcdf-6cbb-4f4a-a0a9-6eff8310d329,DISK], DatanodeInfoWithStorage[127.0.0.1:36316,DS-7b29e407-09f6-48d7-a546-05b57be8be76,DISK], DatanodeInfoWithStorage[127.0.0.1:44149,DS-9f633155-02b6-451d-9dd6-ec237f7f566f,DISK], DatanodeInfoWithStorage[127.0.0.1:35378,DS-2170be1c-029b-4607-9012-6f7fe5221723,DISK], DatanodeInfoWithStorage[127.0.0.1:33869,DS-62877698-fde8-4573-a20e-991920a4fe33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-628514584-172.17.0.18-1596919595943:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37863,DS-287f9a5c-27b4-4b1d-ab79-1fa1fb7bc30b,DISK], DatanodeInfoWithStorage[127.0.0.1:39114,DS-919b6868-3c9d-4678-aa6a-383e49a1a154,DISK], DatanodeInfoWithStorage[127.0.0.1:46753,DS-2089e24c-c937-4276-a05d-21199c2124dd,DISK], DatanodeInfoWithStorage[127.0.0.1:35223,DS-eef9bcdf-6cbb-4f4a-a0a9-6eff8310d329,DISK], DatanodeInfoWithStorage[127.0.0.1:36316,DS-7b29e407-09f6-48d7-a546-05b57be8be76,DISK], DatanodeInfoWithStorage[127.0.0.1:44149,DS-9f633155-02b6-451d-9dd6-ec237f7f566f,DISK], DatanodeInfoWithStorage[127.0.0.1:35378,DS-2170be1c-029b-4607-9012-6f7fe5221723,DISK], DatanodeInfoWithStorage[127.0.0.1:33869,DS-62877698-fde8-4573-a20e-991920a4fe33,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1227928473-172.17.0.18-1596919635426:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33529,DS-c5b96240-5421-45b9-bc1e-780aec8f1c91,DISK], DatanodeInfoWithStorage[127.0.0.1:39870,DS-dd7ceb96-9b75-4fa4-918e-5abf51f2a9d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36654,DS-8fc1444c-476b-4b53-b384-4166b6c8f81f,DISK], DatanodeInfoWithStorage[127.0.0.1:38318,DS-95f3c808-03e3-4588-aaf2-945bde27b0dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37833,DS-1ec4d777-9792-4173-8cd8-a3d9b7f4cb2c,DISK], DatanodeInfoWithStorage[127.0.0.1:38910,DS-feac4945-cd67-4be5-8c01-07ea5ac9cd87,DISK], DatanodeInfoWithStorage[127.0.0.1:35473,DS-2970544d-f481-4e06-98ba-6117f78f30ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34507,DS-04a839df-1f7f-4f4c-bfd2-1230a3b47345,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1227928473-172.17.0.18-1596919635426:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33529,DS-c5b96240-5421-45b9-bc1e-780aec8f1c91,DISK], DatanodeInfoWithStorage[127.0.0.1:39870,DS-dd7ceb96-9b75-4fa4-918e-5abf51f2a9d1,DISK], DatanodeInfoWithStorage[127.0.0.1:36654,DS-8fc1444c-476b-4b53-b384-4166b6c8f81f,DISK], DatanodeInfoWithStorage[127.0.0.1:38318,DS-95f3c808-03e3-4588-aaf2-945bde27b0dc,DISK], DatanodeInfoWithStorage[127.0.0.1:37833,DS-1ec4d777-9792-4173-8cd8-a3d9b7f4cb2c,DISK], DatanodeInfoWithStorage[127.0.0.1:38910,DS-feac4945-cd67-4be5-8c01-07ea5ac9cd87,DISK], DatanodeInfoWithStorage[127.0.0.1:35473,DS-2970544d-f481-4e06-98ba-6117f78f30ae,DISK], DatanodeInfoWithStorage[127.0.0.1:34507,DS-04a839df-1f7f-4f4c-bfd2-1230a3b47345,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1841348525-172.17.0.18-1596919825391:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37901,DS-3fa1d8b6-f629-4ce8-a0cf-c3bc6353b245,DISK], DatanodeInfoWithStorage[127.0.0.1:36436,DS-2b4750f6-4072-4ad2-a65e-96aea39fd6d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40773,DS-95df30e2-1e45-4b83-9038-a852bfbb75fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40721,DS-8cd1f9fa-9cae-4054-a4c3-69f938d077e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45861,DS-7a83cc06-02ee-40cd-884d-4bc9fd5ee9af,DISK], DatanodeInfoWithStorage[127.0.0.1:32798,DS-95aadd2c-21ac-41e5-82b5-305d71377cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:36468,DS-a3119804-b82f-4227-8630-612e27a32d82,DISK], DatanodeInfoWithStorage[127.0.0.1:39621,DS-53b322f2-db34-48a4-b470-c6b6699e10d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1841348525-172.17.0.18-1596919825391:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37901,DS-3fa1d8b6-f629-4ce8-a0cf-c3bc6353b245,DISK], DatanodeInfoWithStorage[127.0.0.1:36436,DS-2b4750f6-4072-4ad2-a65e-96aea39fd6d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40773,DS-95df30e2-1e45-4b83-9038-a852bfbb75fc,DISK], DatanodeInfoWithStorage[127.0.0.1:40721,DS-8cd1f9fa-9cae-4054-a4c3-69f938d077e7,DISK], DatanodeInfoWithStorage[127.0.0.1:45861,DS-7a83cc06-02ee-40cd-884d-4bc9fd5ee9af,DISK], DatanodeInfoWithStorage[127.0.0.1:32798,DS-95aadd2c-21ac-41e5-82b5-305d71377cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:36468,DS-a3119804-b82f-4227-8630-612e27a32d82,DISK], DatanodeInfoWithStorage[127.0.0.1:39621,DS-53b322f2-db34-48a4-b470-c6b6699e10d5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-480576524-172.17.0.18-1596920443792:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41773,DS-f0a9d647-0f02-4584-bffb-04c346e61426,DISK], DatanodeInfoWithStorage[127.0.0.1:46682,DS-3805a885-0920-4833-9ae3-5c97dc3e1cfb,DISK], DatanodeInfoWithStorage[127.0.0.1:41231,DS-c2dee705-e73e-47d0-a0e1-820226e0ff73,DISK], DatanodeInfoWithStorage[127.0.0.1:44711,DS-deb8fa0b-57ad-4fee-99f1-6ccc0bdfad4e,DISK], DatanodeInfoWithStorage[127.0.0.1:43557,DS-7462428a-cefa-47ab-84dc-82f9bd8a09d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34866,DS-63d2d984-4362-49b1-8daa-1713943df112,DISK], DatanodeInfoWithStorage[127.0.0.1:36501,DS-1cb7fbf6-5228-4683-ae0d-a45fcf3b8194,DISK], DatanodeInfoWithStorage[127.0.0.1:44687,DS-f6b1c97f-f109-4063-be5c-bc71b9461c4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-480576524-172.17.0.18-1596920443792:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41773,DS-f0a9d647-0f02-4584-bffb-04c346e61426,DISK], DatanodeInfoWithStorage[127.0.0.1:46682,DS-3805a885-0920-4833-9ae3-5c97dc3e1cfb,DISK], DatanodeInfoWithStorage[127.0.0.1:41231,DS-c2dee705-e73e-47d0-a0e1-820226e0ff73,DISK], DatanodeInfoWithStorage[127.0.0.1:44711,DS-deb8fa0b-57ad-4fee-99f1-6ccc0bdfad4e,DISK], DatanodeInfoWithStorage[127.0.0.1:43557,DS-7462428a-cefa-47ab-84dc-82f9bd8a09d7,DISK], DatanodeInfoWithStorage[127.0.0.1:34866,DS-63d2d984-4362-49b1-8daa-1713943df112,DISK], DatanodeInfoWithStorage[127.0.0.1:36501,DS-1cb7fbf6-5228-4683-ae0d-a45fcf3b8194,DISK], DatanodeInfoWithStorage[127.0.0.1:44687,DS-f6b1c97f-f109-4063-be5c-bc71b9461c4b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-224205188-172.17.0.18-1596920479475:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34104,DS-d5c031e7-5a41-4e52-b503-1edf76e0d349,DISK], DatanodeInfoWithStorage[127.0.0.1:42479,DS-1de76881-d973-4acf-aeff-11613b51ccff,DISK], DatanodeInfoWithStorage[127.0.0.1:41550,DS-fa2a2563-fdd3-470a-9a19-3ac24d415a69,DISK], DatanodeInfoWithStorage[127.0.0.1:40734,DS-4a2614d6-6071-4a24-8df2-aa37b1cfacaa,DISK], DatanodeInfoWithStorage[127.0.0.1:44940,DS-3c3c3c3f-24ed-48ba-8d72-26c3acb35061,DISK], DatanodeInfoWithStorage[127.0.0.1:42163,DS-a9ba7057-3a01-44c9-af5f-976219fc25b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34000,DS-e80c9dad-02b0-4a2e-b8df-e5bd76fa42e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36070,DS-e739bc0b-790e-420f-83c5-db8b9bd1bda4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-224205188-172.17.0.18-1596920479475:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34104,DS-d5c031e7-5a41-4e52-b503-1edf76e0d349,DISK], DatanodeInfoWithStorage[127.0.0.1:42479,DS-1de76881-d973-4acf-aeff-11613b51ccff,DISK], DatanodeInfoWithStorage[127.0.0.1:41550,DS-fa2a2563-fdd3-470a-9a19-3ac24d415a69,DISK], DatanodeInfoWithStorage[127.0.0.1:40734,DS-4a2614d6-6071-4a24-8df2-aa37b1cfacaa,DISK], DatanodeInfoWithStorage[127.0.0.1:44940,DS-3c3c3c3f-24ed-48ba-8d72-26c3acb35061,DISK], DatanodeInfoWithStorage[127.0.0.1:42163,DS-a9ba7057-3a01-44c9-af5f-976219fc25b6,DISK], DatanodeInfoWithStorage[127.0.0.1:34000,DS-e80c9dad-02b0-4a2e-b8df-e5bd76fa42e6,DISK], DatanodeInfoWithStorage[127.0.0.1:36070,DS-e739bc0b-790e-420f-83c5-db8b9bd1bda4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1251922616-172.17.0.18-1596920516586:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45899,DS-feeb432d-97f1-42e9-83e5-cc152a0d5dca,DISK], DatanodeInfoWithStorage[127.0.0.1:42240,DS-f34ec2e2-73ca-4bbd-a0f8-384119728325,DISK], DatanodeInfoWithStorage[127.0.0.1:45054,DS-7b039899-a169-480c-8bcf-6d7886396982,DISK], DatanodeInfoWithStorage[127.0.0.1:40285,DS-a0d46713-6508-4814-831e-bc86aa983942,DISK], DatanodeInfoWithStorage[127.0.0.1:42647,DS-65b2eeb4-dbf7-4914-ad1f-50f3df79970e,DISK], DatanodeInfoWithStorage[127.0.0.1:35452,DS-d71d70a2-4668-4ca1-bc50-9fc49939e699,DISK], DatanodeInfoWithStorage[127.0.0.1:46881,DS-c9a2c804-e655-4442-93ae-ec91fb21a9ec,DISK], DatanodeInfoWithStorage[127.0.0.1:42400,DS-58066bbb-e947-4228-860a-9266d9f2cd8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1251922616-172.17.0.18-1596920516586:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45899,DS-feeb432d-97f1-42e9-83e5-cc152a0d5dca,DISK], DatanodeInfoWithStorage[127.0.0.1:42240,DS-f34ec2e2-73ca-4bbd-a0f8-384119728325,DISK], DatanodeInfoWithStorage[127.0.0.1:45054,DS-7b039899-a169-480c-8bcf-6d7886396982,DISK], DatanodeInfoWithStorage[127.0.0.1:40285,DS-a0d46713-6508-4814-831e-bc86aa983942,DISK], DatanodeInfoWithStorage[127.0.0.1:42647,DS-65b2eeb4-dbf7-4914-ad1f-50f3df79970e,DISK], DatanodeInfoWithStorage[127.0.0.1:35452,DS-d71d70a2-4668-4ca1-bc50-9fc49939e699,DISK], DatanodeInfoWithStorage[127.0.0.1:46881,DS-c9a2c804-e655-4442-93ae-ec91fb21a9ec,DISK], DatanodeInfoWithStorage[127.0.0.1:42400,DS-58066bbb-e947-4228-860a-9266d9f2cd8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-669659913-172.17.0.18-1596921101606:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45371,DS-b424b3a9-d628-4151-a11e-b74984ce0c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:35492,DS-ee5fe21a-6403-4abc-8b90-8d873d3c952b,DISK], DatanodeInfoWithStorage[127.0.0.1:39578,DS-3361d0d3-4cd7-4530-9dc7-cf9bd4b7d361,DISK], DatanodeInfoWithStorage[127.0.0.1:46840,DS-f165dc0f-8c7b-4195-819d-5f3a0962e1dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39146,DS-98cb697f-ff11-4217-b8a5-2a9cd68598d6,DISK], DatanodeInfoWithStorage[127.0.0.1:46090,DS-8e25cee0-7a30-4d32-9417-45f7a186fd2b,DISK], DatanodeInfoWithStorage[127.0.0.1:44578,DS-23b9cee2-0441-4eae-adae-64dd25f47817,DISK], DatanodeInfoWithStorage[127.0.0.1:39448,DS-bd59ea46-7309-482d-afdd-fe3b01ef3a2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-669659913-172.17.0.18-1596921101606:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45371,DS-b424b3a9-d628-4151-a11e-b74984ce0c2e,DISK], DatanodeInfoWithStorage[127.0.0.1:35492,DS-ee5fe21a-6403-4abc-8b90-8d873d3c952b,DISK], DatanodeInfoWithStorage[127.0.0.1:39578,DS-3361d0d3-4cd7-4530-9dc7-cf9bd4b7d361,DISK], DatanodeInfoWithStorage[127.0.0.1:46840,DS-f165dc0f-8c7b-4195-819d-5f3a0962e1dc,DISK], DatanodeInfoWithStorage[127.0.0.1:39146,DS-98cb697f-ff11-4217-b8a5-2a9cd68598d6,DISK], DatanodeInfoWithStorage[127.0.0.1:46090,DS-8e25cee0-7a30-4d32-9417-45f7a186fd2b,DISK], DatanodeInfoWithStorage[127.0.0.1:44578,DS-23b9cee2-0441-4eae-adae-64dd25f47817,DISK], DatanodeInfoWithStorage[127.0.0.1:39448,DS-bd59ea46-7309-482d-afdd-fe3b01ef3a2f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.webhdfs.rest-csrf.enabled
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery19
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-209771892-172.17.0.18-1596921974854:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38571,DS-2616dcb1-6618-406c-8b6c-5d2c211be75f,DISK], DatanodeInfoWithStorage[127.0.0.1:45656,DS-4914e3c6-41cd-4ce8-b133-39497d8e2c10,DISK], DatanodeInfoWithStorage[127.0.0.1:36934,DS-5ccd41c7-c1dc-41dd-bd55-e02a9544527e,DISK], DatanodeInfoWithStorage[127.0.0.1:45946,DS-115bba93-e644-415a-8bdf-10fa31f93da6,DISK], DatanodeInfoWithStorage[127.0.0.1:44876,DS-22dffe7d-dfe0-4d07-9072-30378933c800,DISK], DatanodeInfoWithStorage[127.0.0.1:33215,DS-d5aa4c5c-d2dc-49cf-9298-a44aa5b4567a,DISK], DatanodeInfoWithStorage[127.0.0.1:46103,DS-704593b7-fc11-442a-b81a-45aac33d884f,DISK], DatanodeInfoWithStorage[127.0.0.1:37167,DS-c56ae872-bffb-4691-8c06-a69ed5256e0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-209771892-172.17.0.18-1596921974854:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38571,DS-2616dcb1-6618-406c-8b6c-5d2c211be75f,DISK], DatanodeInfoWithStorage[127.0.0.1:45656,DS-4914e3c6-41cd-4ce8-b133-39497d8e2c10,DISK], DatanodeInfoWithStorage[127.0.0.1:36934,DS-5ccd41c7-c1dc-41dd-bd55-e02a9544527e,DISK], DatanodeInfoWithStorage[127.0.0.1:45946,DS-115bba93-e644-415a-8bdf-10fa31f93da6,DISK], DatanodeInfoWithStorage[127.0.0.1:44876,DS-22dffe7d-dfe0-4d07-9072-30378933c800,DISK], DatanodeInfoWithStorage[127.0.0.1:33215,DS-d5aa4c5c-d2dc-49cf-9298-a44aa5b4567a,DISK], DatanodeInfoWithStorage[127.0.0.1:46103,DS-704593b7-fc11-442a-b81a-45aac33d884f,DISK], DatanodeInfoWithStorage[127.0.0.1:37167,DS-c56ae872-bffb-4691-8c06-a69ed5256e0c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery19(TestFileChecksum.java:519)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 7 out of 50
result: might be true error
Total execution time in seconds : 5341
