reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-999214200-172.17.0.17-1596918307783:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43641,DS-3f00c85a-c2a6-46f6-9b79-eb4555087224,DISK], DatanodeInfoWithStorage[127.0.0.1:38100,DS-00b3aa75-e7b3-43af-8e9d-b3424b9bb57b,DISK], DatanodeInfoWithStorage[127.0.0.1:41500,DS-192a76bd-5ec9-464b-8b0a-9cf375b4fe36,DISK], DatanodeInfoWithStorage[127.0.0.1:34946,DS-759eda08-8bc3-466e-a407-d626c15a019f,DISK], DatanodeInfoWithStorage[127.0.0.1:35704,DS-e3ba6dcb-1f39-4a2f-ba63-5111534cb993,DISK], DatanodeInfoWithStorage[127.0.0.1:41530,DS-90dd315f-e843-4435-95b7-bf2c87cdbbd7,DISK], DatanodeInfoWithStorage[127.0.0.1:45594,DS-e773b475-047a-4729-a325-1d6cb2c69c5a,DISK], DatanodeInfoWithStorage[127.0.0.1:44784,DS-b97144d8-52d2-4324-885b-4217bedb9bf1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-999214200-172.17.0.17-1596918307783:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43641,DS-3f00c85a-c2a6-46f6-9b79-eb4555087224,DISK], DatanodeInfoWithStorage[127.0.0.1:38100,DS-00b3aa75-e7b3-43af-8e9d-b3424b9bb57b,DISK], DatanodeInfoWithStorage[127.0.0.1:41500,DS-192a76bd-5ec9-464b-8b0a-9cf375b4fe36,DISK], DatanodeInfoWithStorage[127.0.0.1:34946,DS-759eda08-8bc3-466e-a407-d626c15a019f,DISK], DatanodeInfoWithStorage[127.0.0.1:35704,DS-e3ba6dcb-1f39-4a2f-ba63-5111534cb993,DISK], DatanodeInfoWithStorage[127.0.0.1:41530,DS-90dd315f-e843-4435-95b7-bf2c87cdbbd7,DISK], DatanodeInfoWithStorage[127.0.0.1:45594,DS-e773b475-047a-4729-a325-1d6cb2c69c5a,DISK], DatanodeInfoWithStorage[127.0.0.1:44784,DS-b97144d8-52d2-4324-885b-4217bedb9bf1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-740025693-172.17.0.17-1596918938303:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41991,DS-90b6b316-9bba-4f65-bdc7-460a95fdb201,DISK], DatanodeInfoWithStorage[127.0.0.1:41065,DS-4e970c8c-7539-40ef-8a77-b37ca1f954a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34815,DS-1c74077f-d4ff-479b-a8b4-77e7353eea87,DISK], DatanodeInfoWithStorage[127.0.0.1:36075,DS-da882849-7956-4c86-ab1b-9630599474e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35809,DS-77e2abc7-8423-4ea5-9d61-76ff5432f40f,DISK], DatanodeInfoWithStorage[127.0.0.1:42609,DS-e249e9e6-af22-4806-aa32-ca59ba0a6385,DISK], DatanodeInfoWithStorage[127.0.0.1:38953,DS-fa92a0bf-c457-408a-a4d2-b2c17c008c3f,DISK], DatanodeInfoWithStorage[127.0.0.1:35462,DS-7973e1e8-028b-470d-8330-1c82f307301a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-740025693-172.17.0.17-1596918938303:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41991,DS-90b6b316-9bba-4f65-bdc7-460a95fdb201,DISK], DatanodeInfoWithStorage[127.0.0.1:41065,DS-4e970c8c-7539-40ef-8a77-b37ca1f954a0,DISK], DatanodeInfoWithStorage[127.0.0.1:34815,DS-1c74077f-d4ff-479b-a8b4-77e7353eea87,DISK], DatanodeInfoWithStorage[127.0.0.1:36075,DS-da882849-7956-4c86-ab1b-9630599474e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35809,DS-77e2abc7-8423-4ea5-9d61-76ff5432f40f,DISK], DatanodeInfoWithStorage[127.0.0.1:42609,DS-e249e9e6-af22-4806-aa32-ca59ba0a6385,DISK], DatanodeInfoWithStorage[127.0.0.1:38953,DS-fa92a0bf-c457-408a-a4d2-b2c17c008c3f,DISK], DatanodeInfoWithStorage[127.0.0.1:35462,DS-7973e1e8-028b-470d-8330-1c82f307301a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-561120515-172.17.0.17-1596919102763:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39325,DS-75d85050-87e4-4906-8bfb-8a6e2b952612,DISK], DatanodeInfoWithStorage[127.0.0.1:43712,DS-10db2d3e-fb1e-40c8-8e84-efddcf7b1fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:45261,DS-18353c38-4158-4cb4-b666-223a4fdea385,DISK], DatanodeInfoWithStorage[127.0.0.1:38884,DS-ed029bd5-da95-4b06-b48e-31e3874f26c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33557,DS-65dd66c8-a6ca-477a-8421-93dc81198878,DISK], DatanodeInfoWithStorage[127.0.0.1:40338,DS-eba80bce-628d-45bc-b83c-f533ce1533c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40578,DS-23b7c0dd-adc3-4a0b-8715-78a1fadd0d38,DISK], DatanodeInfoWithStorage[127.0.0.1:44895,DS-fd96759b-8677-4458-8ed5-97f88411cf5a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-561120515-172.17.0.17-1596919102763:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39325,DS-75d85050-87e4-4906-8bfb-8a6e2b952612,DISK], DatanodeInfoWithStorage[127.0.0.1:43712,DS-10db2d3e-fb1e-40c8-8e84-efddcf7b1fb0,DISK], DatanodeInfoWithStorage[127.0.0.1:45261,DS-18353c38-4158-4cb4-b666-223a4fdea385,DISK], DatanodeInfoWithStorage[127.0.0.1:38884,DS-ed029bd5-da95-4b06-b48e-31e3874f26c0,DISK], DatanodeInfoWithStorage[127.0.0.1:33557,DS-65dd66c8-a6ca-477a-8421-93dc81198878,DISK], DatanodeInfoWithStorage[127.0.0.1:40338,DS-eba80bce-628d-45bc-b83c-f533ce1533c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40578,DS-23b7c0dd-adc3-4a0b-8715-78a1fadd0d38,DISK], DatanodeInfoWithStorage[127.0.0.1:44895,DS-fd96759b-8677-4458-8ed5-97f88411cf5a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1644961073-172.17.0.17-1596919166146:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44710,DS-fd9fecbb-ce7e-4dd1-8c24-40f64d031817,DISK], DatanodeInfoWithStorage[127.0.0.1:37468,DS-ed474465-ac72-4d24-b9f7-e14e1c9e9288,DISK], DatanodeInfoWithStorage[127.0.0.1:46203,DS-f1b4311f-1d3a-49a8-bb45-3433b0169c56,DISK], DatanodeInfoWithStorage[127.0.0.1:38175,DS-c8b72a57-919e-4cbd-9ae9-f2d82dfcedcd,DISK], DatanodeInfoWithStorage[127.0.0.1:41285,DS-b216aa22-38fa-426a-b804-de65c7775902,DISK], DatanodeInfoWithStorage[127.0.0.1:45163,DS-c85954a0-cf07-473a-ae03-7dc50db40530,DISK], DatanodeInfoWithStorage[127.0.0.1:36556,DS-63ee0aa5-b3ba-4bf9-aec0-6f70b9ba2fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:45481,DS-2eb0ba0d-be4a-4337-ae5d-86cfda7157e8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1644961073-172.17.0.17-1596919166146:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44710,DS-fd9fecbb-ce7e-4dd1-8c24-40f64d031817,DISK], DatanodeInfoWithStorage[127.0.0.1:37468,DS-ed474465-ac72-4d24-b9f7-e14e1c9e9288,DISK], DatanodeInfoWithStorage[127.0.0.1:46203,DS-f1b4311f-1d3a-49a8-bb45-3433b0169c56,DISK], DatanodeInfoWithStorage[127.0.0.1:38175,DS-c8b72a57-919e-4cbd-9ae9-f2d82dfcedcd,DISK], DatanodeInfoWithStorage[127.0.0.1:41285,DS-b216aa22-38fa-426a-b804-de65c7775902,DISK], DatanodeInfoWithStorage[127.0.0.1:45163,DS-c85954a0-cf07-473a-ae03-7dc50db40530,DISK], DatanodeInfoWithStorage[127.0.0.1:36556,DS-63ee0aa5-b3ba-4bf9-aec0-6f70b9ba2fc1,DISK], DatanodeInfoWithStorage[127.0.0.1:45481,DS-2eb0ba0d-be4a-4337-ae5d-86cfda7157e8,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-742954805-172.17.0.17-1596919207408:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44363,DS-05c5e303-7bbd-401c-a264-fa207e3921c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43141,DS-915568fd-617d-46aa-b4b1-f2b759d32bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:35084,DS-574f5795-fceb-4cd7-a362-fcd35b86eeca,DISK], DatanodeInfoWithStorage[127.0.0.1:44575,DS-33bf5115-9c41-4051-88e8-54b7f79a1417,DISK], DatanodeInfoWithStorage[127.0.0.1:41133,DS-2e010cb5-f773-4267-a7ec-99b0ee71f66f,DISK], DatanodeInfoWithStorage[127.0.0.1:38067,DS-6d2d978a-b0cc-48e8-a1e6-16579bc293d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34003,DS-f0b57724-c8a6-47f6-bf41-e81011edd1cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38687,DS-ca8dc89a-ca96-4db0-ad20-508973549310,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-742954805-172.17.0.17-1596919207408:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44363,DS-05c5e303-7bbd-401c-a264-fa207e3921c8,DISK], DatanodeInfoWithStorage[127.0.0.1:43141,DS-915568fd-617d-46aa-b4b1-f2b759d32bc3,DISK], DatanodeInfoWithStorage[127.0.0.1:35084,DS-574f5795-fceb-4cd7-a362-fcd35b86eeca,DISK], DatanodeInfoWithStorage[127.0.0.1:44575,DS-33bf5115-9c41-4051-88e8-54b7f79a1417,DISK], DatanodeInfoWithStorage[127.0.0.1:41133,DS-2e010cb5-f773-4267-a7ec-99b0ee71f66f,DISK], DatanodeInfoWithStorage[127.0.0.1:38067,DS-6d2d978a-b0cc-48e8-a1e6-16579bc293d3,DISK], DatanodeInfoWithStorage[127.0.0.1:34003,DS-f0b57724-c8a6-47f6-bf41-e81011edd1cb,DISK], DatanodeInfoWithStorage[127.0.0.1:38687,DS-ca8dc89a-ca96-4db0-ad20-508973549310,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2129087325-172.17.0.17-1596919427523:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40807,DS-8b0b0d7e-acc8-41a5-b5f4-4b04964700cd,DISK], DatanodeInfoWithStorage[127.0.0.1:36236,DS-76c2370d-2f1d-4d28-8c4d-9fba93be9e68,DISK], DatanodeInfoWithStorage[127.0.0.1:46234,DS-626e4431-92ff-4fe3-b3fa-6933aedaadea,DISK], DatanodeInfoWithStorage[127.0.0.1:40613,DS-0643c518-895e-4c07-8bee-aabc482c5553,DISK], DatanodeInfoWithStorage[127.0.0.1:39603,DS-0c372eef-f1e2-4bcb-89d5-1916907df4b1,DISK], DatanodeInfoWithStorage[127.0.0.1:43193,DS-55e58b75-ea5f-4475-9596-1a177e8cd7c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40633,DS-39971cc1-ccdd-412c-be4c-20e8a243ca62,DISK], DatanodeInfoWithStorage[127.0.0.1:37793,DS-e7d2a76c-dced-4ae3-b054-5c4d8f5d4d5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2129087325-172.17.0.17-1596919427523:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40807,DS-8b0b0d7e-acc8-41a5-b5f4-4b04964700cd,DISK], DatanodeInfoWithStorage[127.0.0.1:36236,DS-76c2370d-2f1d-4d28-8c4d-9fba93be9e68,DISK], DatanodeInfoWithStorage[127.0.0.1:46234,DS-626e4431-92ff-4fe3-b3fa-6933aedaadea,DISK], DatanodeInfoWithStorage[127.0.0.1:40613,DS-0643c518-895e-4c07-8bee-aabc482c5553,DISK], DatanodeInfoWithStorage[127.0.0.1:39603,DS-0c372eef-f1e2-4bcb-89d5-1916907df4b1,DISK], DatanodeInfoWithStorage[127.0.0.1:43193,DS-55e58b75-ea5f-4475-9596-1a177e8cd7c5,DISK], DatanodeInfoWithStorage[127.0.0.1:40633,DS-39971cc1-ccdd-412c-be4c-20e8a243ca62,DISK], DatanodeInfoWithStorage[127.0.0.1:37793,DS-e7d2a76c-dced-4ae3-b054-5c4d8f5d4d5c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-222647844-172.17.0.17-1596919581022:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46206,DS-07b788fa-c078-4f11-8fd5-edbe8ef90ffa,DISK], DatanodeInfoWithStorage[127.0.0.1:41469,DS-f961d5fa-efa1-4331-9b7f-dec15fd36782,DISK], DatanodeInfoWithStorage[127.0.0.1:40001,DS-bb55e7ad-e84b-44a0-b17b-f7d776d40f2b,DISK], DatanodeInfoWithStorage[127.0.0.1:37943,DS-13fce99b-b523-425d-a82d-8dbac2911b8a,DISK], DatanodeInfoWithStorage[127.0.0.1:36978,DS-677728b7-271c-4763-8738-2d668b95cfdd,DISK], DatanodeInfoWithStorage[127.0.0.1:38558,DS-7dbd2295-4f3e-496a-a158-3040e52e59c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39916,DS-f3028539-2863-4452-80bb-d94ebcbb0a97,DISK], DatanodeInfoWithStorage[127.0.0.1:44486,DS-947fa1fb-5fdc-4837-a1ba-f8ac85a54907,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-222647844-172.17.0.17-1596919581022:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46206,DS-07b788fa-c078-4f11-8fd5-edbe8ef90ffa,DISK], DatanodeInfoWithStorage[127.0.0.1:41469,DS-f961d5fa-efa1-4331-9b7f-dec15fd36782,DISK], DatanodeInfoWithStorage[127.0.0.1:40001,DS-bb55e7ad-e84b-44a0-b17b-f7d776d40f2b,DISK], DatanodeInfoWithStorage[127.0.0.1:37943,DS-13fce99b-b523-425d-a82d-8dbac2911b8a,DISK], DatanodeInfoWithStorage[127.0.0.1:36978,DS-677728b7-271c-4763-8738-2d668b95cfdd,DISK], DatanodeInfoWithStorage[127.0.0.1:38558,DS-7dbd2295-4f3e-496a-a158-3040e52e59c5,DISK], DatanodeInfoWithStorage[127.0.0.1:39916,DS-f3028539-2863-4452-80bb-d94ebcbb0a97,DISK], DatanodeInfoWithStorage[127.0.0.1:44486,DS-947fa1fb-5fdc-4837-a1ba-f8ac85a54907,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-975859870-172.17.0.17-1596919670859:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37511,DS-fb34a259-93ba-436f-b6e6-af8a5d751332,DISK], DatanodeInfoWithStorage[127.0.0.1:35975,DS-f82eb901-42c3-4810-86d9-80d36dcd0519,DISK], DatanodeInfoWithStorage[127.0.0.1:38128,DS-1482cf64-f520-4d78-b27a-aff1feb38855,DISK], DatanodeInfoWithStorage[127.0.0.1:42902,DS-ad16b873-158c-4c72-b6ed-c7a4ec5d7231,DISK], DatanodeInfoWithStorage[127.0.0.1:38921,DS-f9120e1f-3dcd-481b-aa14-2c1798895940,DISK], DatanodeInfoWithStorage[127.0.0.1:33122,DS-64226060-f4ce-4cf2-8dc2-34ab293003b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42407,DS-20f2645a-5b78-49af-9b11-14e1d01d323b,DISK], DatanodeInfoWithStorage[127.0.0.1:35272,DS-84fd8e1c-3968-47fd-94dc-b896bc90b94b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-975859870-172.17.0.17-1596919670859:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37511,DS-fb34a259-93ba-436f-b6e6-af8a5d751332,DISK], DatanodeInfoWithStorage[127.0.0.1:35975,DS-f82eb901-42c3-4810-86d9-80d36dcd0519,DISK], DatanodeInfoWithStorage[127.0.0.1:38128,DS-1482cf64-f520-4d78-b27a-aff1feb38855,DISK], DatanodeInfoWithStorage[127.0.0.1:42902,DS-ad16b873-158c-4c72-b6ed-c7a4ec5d7231,DISK], DatanodeInfoWithStorage[127.0.0.1:38921,DS-f9120e1f-3dcd-481b-aa14-2c1798895940,DISK], DatanodeInfoWithStorage[127.0.0.1:33122,DS-64226060-f4ce-4cf2-8dc2-34ab293003b0,DISK], DatanodeInfoWithStorage[127.0.0.1:42407,DS-20f2645a-5b78-49af-9b11-14e1d01d323b,DISK], DatanodeInfoWithStorage[127.0.0.1:35272,DS-84fd8e1c-3968-47fd-94dc-b896bc90b94b,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-520512896-172.17.0.17-1596919962643:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40056,DS-01154654-b689-4e84-ad85-25fef27d9fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:43266,DS-bd895b5b-85be-41ab-b101-89d3da6ae8eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35008,DS-9f14473d-a3d8-43d8-b557-259ce038d4b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43094,DS-1f052fab-9275-407a-96ec-e78abae12fbf,DISK], DatanodeInfoWithStorage[127.0.0.1:44604,DS-9f86fe61-75e1-4850-8a22-979f0eb9e654,DISK], DatanodeInfoWithStorage[127.0.0.1:36205,DS-1a1bc35a-120d-49fa-92b5-8e89c7c99c47,DISK], DatanodeInfoWithStorage[127.0.0.1:37175,DS-fd531391-95e5-4037-af3c-2510df63fb7d,DISK], DatanodeInfoWithStorage[127.0.0.1:45263,DS-20578d01-df14-4731-bb26-d4fa31474a1f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-520512896-172.17.0.17-1596919962643:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40056,DS-01154654-b689-4e84-ad85-25fef27d9fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:43266,DS-bd895b5b-85be-41ab-b101-89d3da6ae8eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35008,DS-9f14473d-a3d8-43d8-b557-259ce038d4b2,DISK], DatanodeInfoWithStorage[127.0.0.1:43094,DS-1f052fab-9275-407a-96ec-e78abae12fbf,DISK], DatanodeInfoWithStorage[127.0.0.1:44604,DS-9f86fe61-75e1-4850-8a22-979f0eb9e654,DISK], DatanodeInfoWithStorage[127.0.0.1:36205,DS-1a1bc35a-120d-49fa-92b5-8e89c7c99c47,DISK], DatanodeInfoWithStorage[127.0.0.1:37175,DS-fd531391-95e5-4037-af3c-2510df63fb7d,DISK], DatanodeInfoWithStorage[127.0.0.1:45263,DS-20578d01-df14-4731-bb26-d4fa31474a1f,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1869051923-172.17.0.17-1596920402528:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38675,DS-e46d7d21-3a6b-4021-81b0-6190ce075e27,DISK], DatanodeInfoWithStorage[127.0.0.1:45299,DS-bb5ca94c-e194-4106-8393-1b38c289e798,DISK], DatanodeInfoWithStorage[127.0.0.1:45213,DS-00d17b2e-f50f-437d-b172-fe57c7fd48da,DISK], DatanodeInfoWithStorage[127.0.0.1:43986,DS-cb7cb374-2656-47c1-a9e2-cf023e958527,DISK], DatanodeInfoWithStorage[127.0.0.1:35295,DS-8d27ff25-c9ff-46af-bcd3-95d3c6156f96,DISK], DatanodeInfoWithStorage[127.0.0.1:44810,DS-a1963229-da9d-4dac-8500-3c6bc23a47c0,DISK], DatanodeInfoWithStorage[127.0.0.1:38885,DS-4e9a7f6a-708b-42f8-9ec3-af5b1fdba580,DISK], DatanodeInfoWithStorage[127.0.0.1:41546,DS-74012123-7108-4ee1-b358-08f6938d33b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1869051923-172.17.0.17-1596920402528:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38675,DS-e46d7d21-3a6b-4021-81b0-6190ce075e27,DISK], DatanodeInfoWithStorage[127.0.0.1:45299,DS-bb5ca94c-e194-4106-8393-1b38c289e798,DISK], DatanodeInfoWithStorage[127.0.0.1:45213,DS-00d17b2e-f50f-437d-b172-fe57c7fd48da,DISK], DatanodeInfoWithStorage[127.0.0.1:43986,DS-cb7cb374-2656-47c1-a9e2-cf023e958527,DISK], DatanodeInfoWithStorage[127.0.0.1:35295,DS-8d27ff25-c9ff-46af-bcd3-95d3c6156f96,DISK], DatanodeInfoWithStorage[127.0.0.1:44810,DS-a1963229-da9d-4dac-8500-3c6bc23a47c0,DISK], DatanodeInfoWithStorage[127.0.0.1:38885,DS-4e9a7f6a-708b-42f8-9ec3-af5b1fdba580,DISK], DatanodeInfoWithStorage[127.0.0.1:41546,DS-74012123-7108-4ee1-b358-08f6938d33b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1881675344-172.17.0.17-1596920470541:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45470,DS-a1600520-d8f7-4eb3-b7f1-bc4977a11e97,DISK], DatanodeInfoWithStorage[127.0.0.1:38564,DS-fc6053ed-1842-4519-8b88-f2f26a2f83cd,DISK], DatanodeInfoWithStorage[127.0.0.1:32975,DS-1fe0b90c-da19-440f-acd8-0a7950ebb74f,DISK], DatanodeInfoWithStorage[127.0.0.1:35735,DS-7abe3a5f-b1ee-4a86-9f87-d2dd20c4ee2b,DISK], DatanodeInfoWithStorage[127.0.0.1:43252,DS-eb86e472-817c-4c54-a242-23bc635311ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36104,DS-3c936d37-bd51-4524-a579-8a3ba7f6afe3,DISK], DatanodeInfoWithStorage[127.0.0.1:37702,DS-15dd1527-5160-481b-8764-ff2743bc14fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37676,DS-a82c7b4f-517e-4800-9d92-31c7ac270cb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1881675344-172.17.0.17-1596920470541:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45470,DS-a1600520-d8f7-4eb3-b7f1-bc4977a11e97,DISK], DatanodeInfoWithStorage[127.0.0.1:38564,DS-fc6053ed-1842-4519-8b88-f2f26a2f83cd,DISK], DatanodeInfoWithStorage[127.0.0.1:32975,DS-1fe0b90c-da19-440f-acd8-0a7950ebb74f,DISK], DatanodeInfoWithStorage[127.0.0.1:35735,DS-7abe3a5f-b1ee-4a86-9f87-d2dd20c4ee2b,DISK], DatanodeInfoWithStorage[127.0.0.1:43252,DS-eb86e472-817c-4c54-a242-23bc635311ac,DISK], DatanodeInfoWithStorage[127.0.0.1:36104,DS-3c936d37-bd51-4524-a579-8a3ba7f6afe3,DISK], DatanodeInfoWithStorage[127.0.0.1:37702,DS-15dd1527-5160-481b-8764-ff2743bc14fb,DISK], DatanodeInfoWithStorage[127.0.0.1:37676,DS-a82c7b4f-517e-4800-9d92-31c7ac270cb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1472838335-172.17.0.17-1596920785196:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40930,DS-5779e62a-893c-4e93-9294-8bc67b178833,DISK], DatanodeInfoWithStorage[127.0.0.1:33909,DS-b12983dd-66fa-4a12-bd6c-23f88d7e3dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:45765,DS-6ea13e70-7c34-441a-9bff-40a0a9e77458,DISK], DatanodeInfoWithStorage[127.0.0.1:35576,DS-b579b736-be91-4a03-9e69-fb21e7ec7bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:41051,DS-ccf1eeec-08a6-4c9d-9069-df026833f208,DISK], DatanodeInfoWithStorage[127.0.0.1:46113,DS-f516f838-3274-4fa6-80eb-5a3626a74e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:36682,DS-641beb46-8c16-4ea0-a62d-878a98585517,DISK], DatanodeInfoWithStorage[127.0.0.1:38342,DS-e23856ac-b9af-4821-b85c-c5b1141dedad,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1472838335-172.17.0.17-1596920785196:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40930,DS-5779e62a-893c-4e93-9294-8bc67b178833,DISK], DatanodeInfoWithStorage[127.0.0.1:33909,DS-b12983dd-66fa-4a12-bd6c-23f88d7e3dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:45765,DS-6ea13e70-7c34-441a-9bff-40a0a9e77458,DISK], DatanodeInfoWithStorage[127.0.0.1:35576,DS-b579b736-be91-4a03-9e69-fb21e7ec7bb7,DISK], DatanodeInfoWithStorage[127.0.0.1:41051,DS-ccf1eeec-08a6-4c9d-9069-df026833f208,DISK], DatanodeInfoWithStorage[127.0.0.1:46113,DS-f516f838-3274-4fa6-80eb-5a3626a74e6b,DISK], DatanodeInfoWithStorage[127.0.0.1:36682,DS-641beb46-8c16-4ea0-a62d-878a98585517,DISK], DatanodeInfoWithStorage[127.0.0.1:38342,DS-e23856ac-b9af-4821-b85c-c5b1141dedad,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1652775562-172.17.0.17-1596920821204:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34090,DS-c348ab2b-58d4-4df9-abad-f4feb99118fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35344,DS-e9f7a370-6619-496d-af9f-ce31a00ee82c,DISK], DatanodeInfoWithStorage[127.0.0.1:42615,DS-74e005ca-d4d4-4e36-8637-da1893302337,DISK], DatanodeInfoWithStorage[127.0.0.1:34550,DS-46b3b376-f1ae-4dbf-a9a3-11875e6b328a,DISK], DatanodeInfoWithStorage[127.0.0.1:36795,DS-055ce666-cdc0-46b5-87f0-b19d4f04361f,DISK], DatanodeInfoWithStorage[127.0.0.1:39973,DS-8b339a4f-2c4b-4847-9ad7-4b1ad0aa1d42,DISK], DatanodeInfoWithStorage[127.0.0.1:38526,DS-09108825-67c0-4291-970b-c17841ce8d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:37445,DS-591091fe-f3d7-4631-862c-79442cbd7ba4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1652775562-172.17.0.17-1596920821204:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34090,DS-c348ab2b-58d4-4df9-abad-f4feb99118fe,DISK], DatanodeInfoWithStorage[127.0.0.1:35344,DS-e9f7a370-6619-496d-af9f-ce31a00ee82c,DISK], DatanodeInfoWithStorage[127.0.0.1:42615,DS-74e005ca-d4d4-4e36-8637-da1893302337,DISK], DatanodeInfoWithStorage[127.0.0.1:34550,DS-46b3b376-f1ae-4dbf-a9a3-11875e6b328a,DISK], DatanodeInfoWithStorage[127.0.0.1:36795,DS-055ce666-cdc0-46b5-87f0-b19d4f04361f,DISK], DatanodeInfoWithStorage[127.0.0.1:39973,DS-8b339a4f-2c4b-4847-9ad7-4b1ad0aa1d42,DISK], DatanodeInfoWithStorage[127.0.0.1:38526,DS-09108825-67c0-4291-970b-c17841ce8d5c,DISK], DatanodeInfoWithStorage[127.0.0.1:37445,DS-591091fe-f3d7-4631-862c-79442cbd7ba4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1799277660-172.17.0.17-1596920932354:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42077,DS-d1038e8e-ce47-4cc1-9d8b-183e68bbde8c,DISK], DatanodeInfoWithStorage[127.0.0.1:42356,DS-49bc1beb-44ea-41dc-9dca-8cd2b766a6bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36367,DS-e8da8e8a-84ed-43d3-89aa-76ccb0b1f3f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41506,DS-48f95210-9094-454e-bab7-03c3440a6ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:38574,DS-8d79c0e4-1f59-47c3-ab0b-7f5d5456a643,DISK], DatanodeInfoWithStorage[127.0.0.1:42640,DS-d9655d57-7803-4c57-b72c-dc6f5fcbb067,DISK], DatanodeInfoWithStorage[127.0.0.1:46865,DS-20d015b2-c14e-4da7-9fbe-81f6aaa64627,DISK], DatanodeInfoWithStorage[127.0.0.1:33534,DS-cd80b2b9-6033-4000-879a-61592fe3c05a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1799277660-172.17.0.17-1596920932354:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42077,DS-d1038e8e-ce47-4cc1-9d8b-183e68bbde8c,DISK], DatanodeInfoWithStorage[127.0.0.1:42356,DS-49bc1beb-44ea-41dc-9dca-8cd2b766a6bf,DISK], DatanodeInfoWithStorage[127.0.0.1:36367,DS-e8da8e8a-84ed-43d3-89aa-76ccb0b1f3f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41506,DS-48f95210-9094-454e-bab7-03c3440a6ebc,DISK], DatanodeInfoWithStorage[127.0.0.1:38574,DS-8d79c0e4-1f59-47c3-ab0b-7f5d5456a643,DISK], DatanodeInfoWithStorage[127.0.0.1:42640,DS-d9655d57-7803-4c57-b72c-dc6f5fcbb067,DISK], DatanodeInfoWithStorage[127.0.0.1:46865,DS-20d015b2-c14e-4da7-9fbe-81f6aaa64627,DISK], DatanodeInfoWithStorage[127.0.0.1:33534,DS-cd80b2b9-6033-4000-879a-61592fe3c05a,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-330789370-172.17.0.17-1596921175112:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37054,DS-a8766592-79fe-46b8-9b5c-459fd0384cb3,DISK], DatanodeInfoWithStorage[127.0.0.1:33584,DS-c30dc16a-e123-495c-8618-688e46b1f8f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37329,DS-e2ed76a4-2f0f-474d-bcaf-4ac2da948d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:42240,DS-398aa960-9356-4946-8a92-df43b20eb9c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36487,DS-dca20efa-914b-474f-a424-5280a9613421,DISK], DatanodeInfoWithStorage[127.0.0.1:35514,DS-c8d14851-03c4-417f-9883-e49e18f4746f,DISK], DatanodeInfoWithStorage[127.0.0.1:46029,DS-cdf07046-2a37-4a76-9fb6-7dc9cf034dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:35320,DS-8cd70c67-208b-44d2-9717-3dff818190c4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-330789370-172.17.0.17-1596921175112:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37054,DS-a8766592-79fe-46b8-9b5c-459fd0384cb3,DISK], DatanodeInfoWithStorage[127.0.0.1:33584,DS-c30dc16a-e123-495c-8618-688e46b1f8f1,DISK], DatanodeInfoWithStorage[127.0.0.1:37329,DS-e2ed76a4-2f0f-474d-bcaf-4ac2da948d2b,DISK], DatanodeInfoWithStorage[127.0.0.1:42240,DS-398aa960-9356-4946-8a92-df43b20eb9c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36487,DS-dca20efa-914b-474f-a424-5280a9613421,DISK], DatanodeInfoWithStorage[127.0.0.1:35514,DS-c8d14851-03c4-417f-9883-e49e18f4746f,DISK], DatanodeInfoWithStorage[127.0.0.1:46029,DS-cdf07046-2a37-4a76-9fb6-7dc9cf034dbf,DISK], DatanodeInfoWithStorage[127.0.0.1:35320,DS-8cd70c67-208b-44d2-9717-3dff818190c4,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1214230808-172.17.0.17-1596921356395:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45540,DS-63a61974-b9a1-4b61-8d58-4a202a6aa320,DISK], DatanodeInfoWithStorage[127.0.0.1:33369,DS-dee3c2fc-bc0f-4009-88a9-c1d27255314b,DISK], DatanodeInfoWithStorage[127.0.0.1:42025,DS-6f20d0b2-63e9-41bf-9ca4-e26225544f69,DISK], DatanodeInfoWithStorage[127.0.0.1:44206,DS-73c012f5-4228-4187-86cf-e4287874a359,DISK], DatanodeInfoWithStorage[127.0.0.1:38208,DS-7790103d-3dcd-48df-be48-819af6f4f143,DISK], DatanodeInfoWithStorage[127.0.0.1:46500,DS-e71d845f-bede-447c-baca-5d6d88b76aca,DISK], DatanodeInfoWithStorage[127.0.0.1:36087,DS-232b47e5-d744-4acd-ab31-4a2210c1b95a,DISK], DatanodeInfoWithStorage[127.0.0.1:33876,DS-b7901161-b2b6-495f-b427-b2537e31ac22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1214230808-172.17.0.17-1596921356395:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45540,DS-63a61974-b9a1-4b61-8d58-4a202a6aa320,DISK], DatanodeInfoWithStorage[127.0.0.1:33369,DS-dee3c2fc-bc0f-4009-88a9-c1d27255314b,DISK], DatanodeInfoWithStorage[127.0.0.1:42025,DS-6f20d0b2-63e9-41bf-9ca4-e26225544f69,DISK], DatanodeInfoWithStorage[127.0.0.1:44206,DS-73c012f5-4228-4187-86cf-e4287874a359,DISK], DatanodeInfoWithStorage[127.0.0.1:38208,DS-7790103d-3dcd-48df-be48-819af6f4f143,DISK], DatanodeInfoWithStorage[127.0.0.1:46500,DS-e71d845f-bede-447c-baca-5d6d88b76aca,DISK], DatanodeInfoWithStorage[127.0.0.1:36087,DS-232b47e5-d744-4acd-ab31-4a2210c1b95a,DISK], DatanodeInfoWithStorage[127.0.0.1:33876,DS-b7901161-b2b6-495f-b427-b2537e31ac22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-669854414-172.17.0.17-1596921389790:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46117,DS-891282a1-5a53-4820-9ac7-69b13eb5390c,DISK], DatanodeInfoWithStorage[127.0.0.1:38873,DS-a29885a7-8731-4d32-b7d7-97b0e97f8ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:34552,DS-7d039e81-db8d-4f4d-9898-24a39ec8cde2,DISK], DatanodeInfoWithStorage[127.0.0.1:36037,DS-1d4a68a4-ecd6-45e4-a501-8b2351f37ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:46196,DS-b785e6d0-7b10-4e82-a243-cba888ebc4ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42478,DS-cb22947b-61a3-4dbb-93ee-2b349b0ab950,DISK], DatanodeInfoWithStorage[127.0.0.1:42751,DS-94d2c922-f453-4587-b796-75f5c7ded588,DISK], DatanodeInfoWithStorage[127.0.0.1:40886,DS-4be53817-37f2-4498-99f7-e9081b8614d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-669854414-172.17.0.17-1596921389790:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46117,DS-891282a1-5a53-4820-9ac7-69b13eb5390c,DISK], DatanodeInfoWithStorage[127.0.0.1:38873,DS-a29885a7-8731-4d32-b7d7-97b0e97f8ea6,DISK], DatanodeInfoWithStorage[127.0.0.1:34552,DS-7d039e81-db8d-4f4d-9898-24a39ec8cde2,DISK], DatanodeInfoWithStorage[127.0.0.1:36037,DS-1d4a68a4-ecd6-45e4-a501-8b2351f37ddd,DISK], DatanodeInfoWithStorage[127.0.0.1:46196,DS-b785e6d0-7b10-4e82-a243-cba888ebc4ca,DISK], DatanodeInfoWithStorage[127.0.0.1:42478,DS-cb22947b-61a3-4dbb-93ee-2b349b0ab950,DISK], DatanodeInfoWithStorage[127.0.0.1:42751,DS-94d2c922-f453-4587-b796-75f5c7ded588,DISK], DatanodeInfoWithStorage[127.0.0.1:40886,DS-4be53817-37f2-4498-99f7-e9081b8614d8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1776229851-172.17.0.17-1596921421987:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46224,DS-93f04a20-6d17-46a0-808b-db190c277bf6,DISK], DatanodeInfoWithStorage[127.0.0.1:32866,DS-7a907120-226a-4a6e-951a-e19eb3bfbb25,DISK], DatanodeInfoWithStorage[127.0.0.1:33076,DS-20b5914b-49ae-4836-bbaa-6a3567f11578,DISK], DatanodeInfoWithStorage[127.0.0.1:39129,DS-3420842d-2997-417f-b92a-c4c0c7dfec7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36705,DS-0c838380-9561-4bab-973b-470550beeeb4,DISK], DatanodeInfoWithStorage[127.0.0.1:36213,DS-f44a7382-cb06-4917-bdee-b07f0c52c8de,DISK], DatanodeInfoWithStorage[127.0.0.1:39215,DS-9179049f-61c8-416b-a245-e0f09f5bfa13,DISK], DatanodeInfoWithStorage[127.0.0.1:35335,DS-b0461778-4675-4a1e-9472-70f041cf0538,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1776229851-172.17.0.17-1596921421987:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46224,DS-93f04a20-6d17-46a0-808b-db190c277bf6,DISK], DatanodeInfoWithStorage[127.0.0.1:32866,DS-7a907120-226a-4a6e-951a-e19eb3bfbb25,DISK], DatanodeInfoWithStorage[127.0.0.1:33076,DS-20b5914b-49ae-4836-bbaa-6a3567f11578,DISK], DatanodeInfoWithStorage[127.0.0.1:39129,DS-3420842d-2997-417f-b92a-c4c0c7dfec7a,DISK], DatanodeInfoWithStorage[127.0.0.1:36705,DS-0c838380-9561-4bab-973b-470550beeeb4,DISK], DatanodeInfoWithStorage[127.0.0.1:36213,DS-f44a7382-cb06-4917-bdee-b07f0c52c8de,DISK], DatanodeInfoWithStorage[127.0.0.1:39215,DS-9179049f-61c8-416b-a245-e0f09f5bfa13,DISK], DatanodeInfoWithStorage[127.0.0.1:35335,DS-b0461778-4675-4a1e-9472-70f041cf0538,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1736423516-172.17.0.17-1596921863283:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43500,DS-3de17d0c-2b32-49b9-817e-4b8c24447ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:44375,DS-98c97a53-0e26-46f9-87cc-2f88f16acf4d,DISK], DatanodeInfoWithStorage[127.0.0.1:33537,DS-68068e36-6b75-4c83-a598-5ea3606e807c,DISK], DatanodeInfoWithStorage[127.0.0.1:39139,DS-24276854-7f44-4982-b0ca-f85bd50944d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41325,DS-f54aad71-7ee7-4151-8042-9ca6b4e56610,DISK], DatanodeInfoWithStorage[127.0.0.1:39437,DS-1ab764be-ee62-4c70-ae71-7d6c7ef64af3,DISK], DatanodeInfoWithStorage[127.0.0.1:35266,DS-721b3e68-fe29-43ed-a33e-4bd404b1a928,DISK], DatanodeInfoWithStorage[127.0.0.1:33223,DS-2ce553fa-8718-49ae-8fb1-28992a9dabed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1736423516-172.17.0.17-1596921863283:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43500,DS-3de17d0c-2b32-49b9-817e-4b8c24447ff0,DISK], DatanodeInfoWithStorage[127.0.0.1:44375,DS-98c97a53-0e26-46f9-87cc-2f88f16acf4d,DISK], DatanodeInfoWithStorage[127.0.0.1:33537,DS-68068e36-6b75-4c83-a598-5ea3606e807c,DISK], DatanodeInfoWithStorage[127.0.0.1:39139,DS-24276854-7f44-4982-b0ca-f85bd50944d2,DISK], DatanodeInfoWithStorage[127.0.0.1:41325,DS-f54aad71-7ee7-4151-8042-9ca6b4e56610,DISK], DatanodeInfoWithStorage[127.0.0.1:39437,DS-1ab764be-ee62-4c70-ae71-7d6c7ef64af3,DISK], DatanodeInfoWithStorage[127.0.0.1:35266,DS-721b3e68-fe29-43ed-a33e-4bd404b1a928,DISK], DatanodeInfoWithStorage[127.0.0.1:33223,DS-2ce553fa-8718-49ae-8fb1-28992a9dabed,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-984311172-172.17.0.17-1596921932653:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37666,DS-2d0da11e-dae4-481e-bcc7-55927959c7ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42115,DS-3e8c258a-4093-4c0a-86eb-53314c2c4589,DISK], DatanodeInfoWithStorage[127.0.0.1:36715,DS-288ac693-8165-4357-8121-626e995f5658,DISK], DatanodeInfoWithStorage[127.0.0.1:33486,DS-177b4239-587c-41b5-8d62-0223cf68e744,DISK], DatanodeInfoWithStorage[127.0.0.1:35852,DS-052d0a89-b568-47a1-9d1d-057d1678832f,DISK], DatanodeInfoWithStorage[127.0.0.1:46688,DS-1f177cbe-9a97-4def-8e4e-01e86ccb73d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42831,DS-58677bb2-8c46-4371-8587-8ab541719e88,DISK], DatanodeInfoWithStorage[127.0.0.1:45746,DS-3f58a5d6-a733-4151-a90e-366038e93fac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-984311172-172.17.0.17-1596921932653:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37666,DS-2d0da11e-dae4-481e-bcc7-55927959c7ae,DISK], DatanodeInfoWithStorage[127.0.0.1:42115,DS-3e8c258a-4093-4c0a-86eb-53314c2c4589,DISK], DatanodeInfoWithStorage[127.0.0.1:36715,DS-288ac693-8165-4357-8121-626e995f5658,DISK], DatanodeInfoWithStorage[127.0.0.1:33486,DS-177b4239-587c-41b5-8d62-0223cf68e744,DISK], DatanodeInfoWithStorage[127.0.0.1:35852,DS-052d0a89-b568-47a1-9d1d-057d1678832f,DISK], DatanodeInfoWithStorage[127.0.0.1:46688,DS-1f177cbe-9a97-4def-8e4e-01e86ccb73d9,DISK], DatanodeInfoWithStorage[127.0.0.1:42831,DS-58677bb2-8c46-4371-8587-8ab541719e88,DISK], DatanodeInfoWithStorage[127.0.0.1:45746,DS-3f58a5d6-a733-4151-a90e-366038e93fac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-452793047-172.17.0.17-1596922011918:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43262,DS-3df595e7-32bd-463c-b29c-bd449fc0e510,DISK], DatanodeInfoWithStorage[127.0.0.1:39610,DS-6128c971-1fdd-4f3c-a10f-1e1c4687ebc9,DISK], DatanodeInfoWithStorage[127.0.0.1:38457,DS-367ad988-cfc4-4547-b073-a39ef8c54c5b,DISK], DatanodeInfoWithStorage[127.0.0.1:36541,DS-8d250539-f6c3-4ac4-a86c-e91239fc71db,DISK], DatanodeInfoWithStorage[127.0.0.1:45720,DS-cb1cf04c-0364-446e-bb71-c601f495aa92,DISK], DatanodeInfoWithStorage[127.0.0.1:38164,DS-bc5db50c-40fd-453f-afac-b3268d7a6aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:36679,DS-be5f268b-4eeb-431c-9806-a862687c158e,DISK], DatanodeInfoWithStorage[127.0.0.1:44093,DS-3ea8b6fc-711d-4c79-9d1c-2cc0c5908630,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-452793047-172.17.0.17-1596922011918:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43262,DS-3df595e7-32bd-463c-b29c-bd449fc0e510,DISK], DatanodeInfoWithStorage[127.0.0.1:39610,DS-6128c971-1fdd-4f3c-a10f-1e1c4687ebc9,DISK], DatanodeInfoWithStorage[127.0.0.1:38457,DS-367ad988-cfc4-4547-b073-a39ef8c54c5b,DISK], DatanodeInfoWithStorage[127.0.0.1:36541,DS-8d250539-f6c3-4ac4-a86c-e91239fc71db,DISK], DatanodeInfoWithStorage[127.0.0.1:45720,DS-cb1cf04c-0364-446e-bb71-c601f495aa92,DISK], DatanodeInfoWithStorage[127.0.0.1:38164,DS-bc5db50c-40fd-453f-afac-b3268d7a6aa9,DISK], DatanodeInfoWithStorage[127.0.0.1:36679,DS-be5f268b-4eeb-431c-9806-a862687c158e,DISK], DatanodeInfoWithStorage[127.0.0.1:44093,DS-3ea8b6fc-711d-4c79-9d1c-2cc0c5908630,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-808262412-172.17.0.17-1596922086433:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38602,DS-7c3182ed-8e41-4902-9f86-79bca2afe18d,DISK], DatanodeInfoWithStorage[127.0.0.1:40301,DS-79936ce5-69a2-4a2b-89b1-f0f14cd3d0cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35452,DS-fcac0aaa-ca90-40f6-957b-01105faa5e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:44523,DS-22e19dc5-8012-4c18-8a99-cfcd386ae0de,DISK], DatanodeInfoWithStorage[127.0.0.1:37840,DS-215c8670-57fb-4986-8182-9446c1152d23,DISK], DatanodeInfoWithStorage[127.0.0.1:42562,DS-3e196a26-7f5d-4077-b6a6-e51160a87c86,DISK], DatanodeInfoWithStorage[127.0.0.1:33896,DS-d5d609a9-a3c8-4c81-a165-07edd5285e41,DISK], DatanodeInfoWithStorage[127.0.0.1:44516,DS-e47c0fb6-5709-4356-b741-f86a60dd5b49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-808262412-172.17.0.17-1596922086433:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38602,DS-7c3182ed-8e41-4902-9f86-79bca2afe18d,DISK], DatanodeInfoWithStorage[127.0.0.1:40301,DS-79936ce5-69a2-4a2b-89b1-f0f14cd3d0cb,DISK], DatanodeInfoWithStorage[127.0.0.1:35452,DS-fcac0aaa-ca90-40f6-957b-01105faa5e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:44523,DS-22e19dc5-8012-4c18-8a99-cfcd386ae0de,DISK], DatanodeInfoWithStorage[127.0.0.1:37840,DS-215c8670-57fb-4986-8182-9446c1152d23,DISK], DatanodeInfoWithStorage[127.0.0.1:42562,DS-3e196a26-7f5d-4077-b6a6-e51160a87c86,DISK], DatanodeInfoWithStorage[127.0.0.1:33896,DS-d5d609a9-a3c8-4c81-a165-07edd5285e41,DISK], DatanodeInfoWithStorage[127.0.0.1:44516,DS-e47c0fb6-5709-4356-b741-f86a60dd5b49,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-22551961-172.17.0.17-1596922204583:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35154,DS-3835f103-5db9-45d9-ad77-a2eb061e0544,DISK], DatanodeInfoWithStorage[127.0.0.1:41564,DS-e70aa9bc-36ae-4303-ba1d-eae512e17d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:40833,DS-aeaecf86-a43b-499a-8ede-099244782e36,DISK], DatanodeInfoWithStorage[127.0.0.1:41950,DS-b5ecc897-ec20-442e-9bfd-581526af773a,DISK], DatanodeInfoWithStorage[127.0.0.1:37782,DS-6c879b18-294b-40dd-9e43-8036b60a9d36,DISK], DatanodeInfoWithStorage[127.0.0.1:34823,DS-836b0a39-42d5-40d0-8942-76ca8fce1c98,DISK], DatanodeInfoWithStorage[127.0.0.1:39068,DS-1b13cd62-a588-468d-b5af-95f4285a38e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38893,DS-274a6166-c13f-4773-b07e-8f30820cc2a9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-22551961-172.17.0.17-1596922204583:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35154,DS-3835f103-5db9-45d9-ad77-a2eb061e0544,DISK], DatanodeInfoWithStorage[127.0.0.1:41564,DS-e70aa9bc-36ae-4303-ba1d-eae512e17d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:40833,DS-aeaecf86-a43b-499a-8ede-099244782e36,DISK], DatanodeInfoWithStorage[127.0.0.1:41950,DS-b5ecc897-ec20-442e-9bfd-581526af773a,DISK], DatanodeInfoWithStorage[127.0.0.1:37782,DS-6c879b18-294b-40dd-9e43-8036b60a9d36,DISK], DatanodeInfoWithStorage[127.0.0.1:34823,DS-836b0a39-42d5-40d0-8942-76ca8fce1c98,DISK], DatanodeInfoWithStorage[127.0.0.1:39068,DS-1b13cd62-a588-468d-b5af-95f4285a38e3,DISK], DatanodeInfoWithStorage[127.0.0.1:38893,DS-274a6166-c13f-4773-b07e-8f30820cc2a9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1634304215-172.17.0.17-1596922587467:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39814,DS-9122dfff-a3ab-42ba-8f72-d4d95347bf15,DISK], DatanodeInfoWithStorage[127.0.0.1:37817,DS-39e2e302-9059-426b-9d98-c41d758071dd,DISK], DatanodeInfoWithStorage[127.0.0.1:32903,DS-cd2cadb6-10f8-46af-b572-b0f96fab249a,DISK], DatanodeInfoWithStorage[127.0.0.1:45197,DS-1ca40ce2-2d8c-484c-b57c-d35e25ebc7c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36137,DS-1c1cde7b-9919-442d-b072-ad817aadb783,DISK], DatanodeInfoWithStorage[127.0.0.1:43835,DS-5dc05fa4-fb2b-416d-bfaf-78fba5bd027a,DISK], DatanodeInfoWithStorage[127.0.0.1:45541,DS-2d9f0335-172d-46c0-ba8a-d893b2545891,DISK], DatanodeInfoWithStorage[127.0.0.1:38218,DS-1c8b524c-8f2c-478e-b241-ec32d6fce271,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1634304215-172.17.0.17-1596922587467:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39814,DS-9122dfff-a3ab-42ba-8f72-d4d95347bf15,DISK], DatanodeInfoWithStorage[127.0.0.1:37817,DS-39e2e302-9059-426b-9d98-c41d758071dd,DISK], DatanodeInfoWithStorage[127.0.0.1:32903,DS-cd2cadb6-10f8-46af-b572-b0f96fab249a,DISK], DatanodeInfoWithStorage[127.0.0.1:45197,DS-1ca40ce2-2d8c-484c-b57c-d35e25ebc7c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36137,DS-1c1cde7b-9919-442d-b072-ad817aadb783,DISK], DatanodeInfoWithStorage[127.0.0.1:43835,DS-5dc05fa4-fb2b-416d-bfaf-78fba5bd027a,DISK], DatanodeInfoWithStorage[127.0.0.1:45541,DS-2d9f0335-172d-46c0-ba8a-d893b2545891,DISK], DatanodeInfoWithStorage[127.0.0.1:38218,DS-1c8b524c-8f2c-478e-b241-ec32d6fce271,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1388403493-172.17.0.17-1596922878169:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44540,DS-c465ff25-c43c-4a15-9397-9aebf81e18e7,DISK], DatanodeInfoWithStorage[127.0.0.1:32980,DS-049eba08-c215-40ca-8a99-9d0b61ed7d2c,DISK], DatanodeInfoWithStorage[127.0.0.1:35022,DS-36081ca8-2651-44bc-a91b-7e019ead71e8,DISK], DatanodeInfoWithStorage[127.0.0.1:45524,DS-a9cb136f-695b-414b-8f11-b69a4729bb0d,DISK], DatanodeInfoWithStorage[127.0.0.1:34337,DS-19e1b2e6-30fd-45b5-915d-b1c7b3baf220,DISK], DatanodeInfoWithStorage[127.0.0.1:40676,DS-319b813e-e8b6-47a4-b548-a0026604a324,DISK], DatanodeInfoWithStorage[127.0.0.1:34847,DS-173229cb-f666-4a68-8078-4a3624ceeba1,DISK], DatanodeInfoWithStorage[127.0.0.1:42629,DS-4ae9f5a0-4cfa-43c2-93c2-0fb2b10be3e9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1388403493-172.17.0.17-1596922878169:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44540,DS-c465ff25-c43c-4a15-9397-9aebf81e18e7,DISK], DatanodeInfoWithStorage[127.0.0.1:32980,DS-049eba08-c215-40ca-8a99-9d0b61ed7d2c,DISK], DatanodeInfoWithStorage[127.0.0.1:35022,DS-36081ca8-2651-44bc-a91b-7e019ead71e8,DISK], DatanodeInfoWithStorage[127.0.0.1:45524,DS-a9cb136f-695b-414b-8f11-b69a4729bb0d,DISK], DatanodeInfoWithStorage[127.0.0.1:34337,DS-19e1b2e6-30fd-45b5-915d-b1c7b3baf220,DISK], DatanodeInfoWithStorage[127.0.0.1:40676,DS-319b813e-e8b6-47a4-b548-a0026604a324,DISK], DatanodeInfoWithStorage[127.0.0.1:34847,DS-173229cb-f666-4a68-8078-4a3624ceeba1,DISK], DatanodeInfoWithStorage[127.0.0.1:42629,DS-4ae9f5a0-4cfa-43c2-93c2-0fb2b10be3e9,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-930676601-172.17.0.17-1596923245279:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43716,DS-8eb45737-3b5e-492e-add8-8195f0b623df,DISK], DatanodeInfoWithStorage[127.0.0.1:35255,DS-1f95e666-b3e6-440f-bb68-953527d69ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:33640,DS-c8e49d28-705a-42dc-a70e-e760a993c4dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36230,DS-f953c5ac-70c8-4bb9-bdf0-cd073dbdffca,DISK], DatanodeInfoWithStorage[127.0.0.1:41301,DS-4682290c-c0be-4830-ad7f-e36e065bb5ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43345,DS-2b711a2e-9988-4959-92d2-5764e3894b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:35415,DS-74b3e3a5-1546-4c23-8698-d3d380d5b1c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43762,DS-538f574e-d2c2-48f5-859e-eb508ebff439,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-930676601-172.17.0.17-1596923245279:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43716,DS-8eb45737-3b5e-492e-add8-8195f0b623df,DISK], DatanodeInfoWithStorage[127.0.0.1:35255,DS-1f95e666-b3e6-440f-bb68-953527d69ce8,DISK], DatanodeInfoWithStorage[127.0.0.1:33640,DS-c8e49d28-705a-42dc-a70e-e760a993c4dd,DISK], DatanodeInfoWithStorage[127.0.0.1:36230,DS-f953c5ac-70c8-4bb9-bdf0-cd073dbdffca,DISK], DatanodeInfoWithStorage[127.0.0.1:41301,DS-4682290c-c0be-4830-ad7f-e36e065bb5ee,DISK], DatanodeInfoWithStorage[127.0.0.1:43345,DS-2b711a2e-9988-4959-92d2-5764e3894b4a,DISK], DatanodeInfoWithStorage[127.0.0.1:35415,DS-74b3e3a5-1546-4c23-8698-d3d380d5b1c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43762,DS-538f574e-d2c2-48f5-859e-eb508ebff439,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.sync.behind.writes
component: hdfs:DataNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery7
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1458385198-172.17.0.17-1596923288751:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40005,DS-35533c82-1d97-4e2f-9d74-f366f968e9e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39261,DS-e7d7b2a4-3f7e-4c26-bebc-e74c1e705415,DISK], DatanodeInfoWithStorage[127.0.0.1:43734,DS-30d9edb7-f437-4020-832f-cfa3bbaf8d58,DISK], DatanodeInfoWithStorage[127.0.0.1:44282,DS-0fd2b66b-9261-4e1a-a2be-700f2eebd723,DISK], DatanodeInfoWithStorage[127.0.0.1:34816,DS-2e60b54a-abe2-4f42-b942-916e9c34815e,DISK], DatanodeInfoWithStorage[127.0.0.1:38044,DS-3c4f98f0-adb8-42ae-8c10-80038b33aae5,DISK], DatanodeInfoWithStorage[127.0.0.1:33934,DS-6d2a1cbc-c610-4db9-b316-ca96835b2035,DISK], DatanodeInfoWithStorage[127.0.0.1:35526,DS-9d4aa741-d05d-4f47-9c9e-b177e7e4a624,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1458385198-172.17.0.17-1596923288751:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40005,DS-35533c82-1d97-4e2f-9d74-f366f968e9e1,DISK], DatanodeInfoWithStorage[127.0.0.1:39261,DS-e7d7b2a4-3f7e-4c26-bebc-e74c1e705415,DISK], DatanodeInfoWithStorage[127.0.0.1:43734,DS-30d9edb7-f437-4020-832f-cfa3bbaf8d58,DISK], DatanodeInfoWithStorage[127.0.0.1:44282,DS-0fd2b66b-9261-4e1a-a2be-700f2eebd723,DISK], DatanodeInfoWithStorage[127.0.0.1:34816,DS-2e60b54a-abe2-4f42-b942-916e9c34815e,DISK], DatanodeInfoWithStorage[127.0.0.1:38044,DS-3c4f98f0-adb8-42ae-8c10-80038b33aae5,DISK], DatanodeInfoWithStorage[127.0.0.1:33934,DS-6d2a1cbc-c610-4db9-b316-ca96835b2035,DISK], DatanodeInfoWithStorage[127.0.0.1:35526,DS-9d4aa741-d05d-4f47-9c9e-b177e7e4a624,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery7(TestFileChecksum.java:377)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5312
