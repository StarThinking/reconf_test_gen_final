reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-707141004-172.17.0.13-1596867765630:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41036,DS-3314791d-91d9-4502-9a88-50704b2b359d,DISK], DatanodeInfoWithStorage[127.0.0.1:34451,DS-d341e619-289c-44db-9b3f-47082f3c64d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38033,DS-12943761-29f5-4da0-899c-7984ba49e8f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36869,DS-89fc47d1-6d97-4eb8-b4ae-b9799a3421c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37306,DS-8c7fe857-3c90-49eb-8d54-063f8c9c13b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44016,DS-ead21e5e-4da0-47cd-830a-a72b5b38935e,DISK], DatanodeInfoWithStorage[127.0.0.1:39947,DS-ab558764-eaec-4ebe-b734-cc542e822e84,DISK], DatanodeInfoWithStorage[127.0.0.1:36728,DS-05b3e558-2940-4d71-a38e-fa65be90d4bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-707141004-172.17.0.13-1596867765630:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41036,DS-3314791d-91d9-4502-9a88-50704b2b359d,DISK], DatanodeInfoWithStorage[127.0.0.1:34451,DS-d341e619-289c-44db-9b3f-47082f3c64d9,DISK], DatanodeInfoWithStorage[127.0.0.1:38033,DS-12943761-29f5-4da0-899c-7984ba49e8f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36869,DS-89fc47d1-6d97-4eb8-b4ae-b9799a3421c7,DISK], DatanodeInfoWithStorage[127.0.0.1:37306,DS-8c7fe857-3c90-49eb-8d54-063f8c9c13b4,DISK], DatanodeInfoWithStorage[127.0.0.1:44016,DS-ead21e5e-4da0-47cd-830a-a72b5b38935e,DISK], DatanodeInfoWithStorage[127.0.0.1:39947,DS-ab558764-eaec-4ebe-b734-cc542e822e84,DISK], DatanodeInfoWithStorage[127.0.0.1:36728,DS-05b3e558-2940-4d71-a38e-fa65be90d4bc,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-928967215-172.17.0.13-1596868045445:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34588,DS-5954dfff-1082-47f0-97c4-73f80d92839e,DISK], DatanodeInfoWithStorage[127.0.0.1:46204,DS-9dde2dc7-a179-43f3-ad3b-e536d7512701,DISK], DatanodeInfoWithStorage[127.0.0.1:39256,DS-451a458e-f621-4be6-b188-07006e46a11b,DISK], DatanodeInfoWithStorage[127.0.0.1:42173,DS-e7264605-d269-4e19-bfe5-5204c17a5f99,DISK], DatanodeInfoWithStorage[127.0.0.1:43423,DS-5e4bb0ca-cb4a-446b-b671-504370b7d9c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39490,DS-efab5e97-5689-4bce-ac67-7f811c2151c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44151,DS-59a482e5-c884-4b88-83c2-360716cde6e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33967,DS-68f0ff5a-2cbb-4faf-96ce-c7ed909f2de3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-928967215-172.17.0.13-1596868045445:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34588,DS-5954dfff-1082-47f0-97c4-73f80d92839e,DISK], DatanodeInfoWithStorage[127.0.0.1:46204,DS-9dde2dc7-a179-43f3-ad3b-e536d7512701,DISK], DatanodeInfoWithStorage[127.0.0.1:39256,DS-451a458e-f621-4be6-b188-07006e46a11b,DISK], DatanodeInfoWithStorage[127.0.0.1:42173,DS-e7264605-d269-4e19-bfe5-5204c17a5f99,DISK], DatanodeInfoWithStorage[127.0.0.1:43423,DS-5e4bb0ca-cb4a-446b-b671-504370b7d9c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39490,DS-efab5e97-5689-4bce-ac67-7f811c2151c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44151,DS-59a482e5-c884-4b88-83c2-360716cde6e9,DISK], DatanodeInfoWithStorage[127.0.0.1:33967,DS-68f0ff5a-2cbb-4faf-96ce-c7ed909f2de3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-573833411-172.17.0.13-1596868125214:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46540,DS-46842640-25a5-4870-a11d-83f2f0fc0d35,DISK], DatanodeInfoWithStorage[127.0.0.1:43998,DS-a1d00f51-6150-470e-abc8-f11eee733e70,DISK], DatanodeInfoWithStorage[127.0.0.1:41898,DS-933d3ca0-8ab3-4dae-a2b4-4b60b8f06152,DISK], DatanodeInfoWithStorage[127.0.0.1:36842,DS-10d1dca7-1b29-4b5f-bd6d-dd5713ea6e45,DISK], DatanodeInfoWithStorage[127.0.0.1:34932,DS-5dae81b8-0253-442d-b814-82e893e22d58,DISK], DatanodeInfoWithStorage[127.0.0.1:39389,DS-5aaa9cf9-af1b-4560-8182-88ad9775cbf9,DISK], DatanodeInfoWithStorage[127.0.0.1:39528,DS-0d345a4f-0f1e-4fbd-8435-ec54ee7d3ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:38005,DS-f163d762-1e06-435a-b528-96f4a636f2ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-573833411-172.17.0.13-1596868125214:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46540,DS-46842640-25a5-4870-a11d-83f2f0fc0d35,DISK], DatanodeInfoWithStorage[127.0.0.1:43998,DS-a1d00f51-6150-470e-abc8-f11eee733e70,DISK], DatanodeInfoWithStorage[127.0.0.1:41898,DS-933d3ca0-8ab3-4dae-a2b4-4b60b8f06152,DISK], DatanodeInfoWithStorage[127.0.0.1:36842,DS-10d1dca7-1b29-4b5f-bd6d-dd5713ea6e45,DISK], DatanodeInfoWithStorage[127.0.0.1:34932,DS-5dae81b8-0253-442d-b814-82e893e22d58,DISK], DatanodeInfoWithStorage[127.0.0.1:39389,DS-5aaa9cf9-af1b-4560-8182-88ad9775cbf9,DISK], DatanodeInfoWithStorage[127.0.0.1:39528,DS-0d345a4f-0f1e-4fbd-8435-ec54ee7d3ac4,DISK], DatanodeInfoWithStorage[127.0.0.1:38005,DS-f163d762-1e06-435a-b528-96f4a636f2ce,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-184692500-172.17.0.13-1596868585420:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41964,DS-17015409-3942-4b50-9fc5-38fd5ec83eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:38281,DS-f5672518-46be-41f0-ac02-ad9e2db699bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33085,DS-d9b3efc3-a687-4f54-9952-ce9335c4bfa5,DISK], DatanodeInfoWithStorage[127.0.0.1:37840,DS-bc074e15-11a8-4fdd-9b9a-ee50f0c485b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45538,DS-72c2ff9d-7f03-4b22-bb70-5c6a1ad9f590,DISK], DatanodeInfoWithStorage[127.0.0.1:35518,DS-0724cda1-e199-4170-8bb2-fc3972936a64,DISK], DatanodeInfoWithStorage[127.0.0.1:33205,DS-d9f2422f-78bb-44e7-87f0-020ef0a0a353,DISK], DatanodeInfoWithStorage[127.0.0.1:35720,DS-3ba596c4-d6b4-4721-a7a4-6f4c8ca16104,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-184692500-172.17.0.13-1596868585420:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41964,DS-17015409-3942-4b50-9fc5-38fd5ec83eaa,DISK], DatanodeInfoWithStorage[127.0.0.1:38281,DS-f5672518-46be-41f0-ac02-ad9e2db699bf,DISK], DatanodeInfoWithStorage[127.0.0.1:33085,DS-d9b3efc3-a687-4f54-9952-ce9335c4bfa5,DISK], DatanodeInfoWithStorage[127.0.0.1:37840,DS-bc074e15-11a8-4fdd-9b9a-ee50f0c485b9,DISK], DatanodeInfoWithStorage[127.0.0.1:45538,DS-72c2ff9d-7f03-4b22-bb70-5c6a1ad9f590,DISK], DatanodeInfoWithStorage[127.0.0.1:35518,DS-0724cda1-e199-4170-8bb2-fc3972936a64,DISK], DatanodeInfoWithStorage[127.0.0.1:33205,DS-d9f2422f-78bb-44e7-87f0-020ef0a0a353,DISK], DatanodeInfoWithStorage[127.0.0.1:35720,DS-3ba596c4-d6b4-4721-a7a4-6f4c8ca16104,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1464790386-172.17.0.13-1596869091257:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41822,DS-fdd31177-05e6-413e-9be4-4732328f6f56,DISK], DatanodeInfoWithStorage[127.0.0.1:40006,DS-71c3c180-d5f8-4323-a63b-afd190b914e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44871,DS-8f302633-bb95-4b7d-9c88-3cb18724db72,DISK], DatanodeInfoWithStorage[127.0.0.1:34156,DS-89e85b08-59e2-4ea6-86f5-69ec8c53e29f,DISK], DatanodeInfoWithStorage[127.0.0.1:35742,DS-bca32b1e-cfdf-4b2f-ab72-8872c4884bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:34493,DS-efaa2f88-ddd2-4476-9214-8f0b2fcd7eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:42042,DS-c0060097-3afd-4233-9d46-4df08af6631b,DISK], DatanodeInfoWithStorage[127.0.0.1:34746,DS-17e3a88e-2d1d-417a-9a90-639ea2582fa5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1464790386-172.17.0.13-1596869091257:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41822,DS-fdd31177-05e6-413e-9be4-4732328f6f56,DISK], DatanodeInfoWithStorage[127.0.0.1:40006,DS-71c3c180-d5f8-4323-a63b-afd190b914e7,DISK], DatanodeInfoWithStorage[127.0.0.1:44871,DS-8f302633-bb95-4b7d-9c88-3cb18724db72,DISK], DatanodeInfoWithStorage[127.0.0.1:34156,DS-89e85b08-59e2-4ea6-86f5-69ec8c53e29f,DISK], DatanodeInfoWithStorage[127.0.0.1:35742,DS-bca32b1e-cfdf-4b2f-ab72-8872c4884bc7,DISK], DatanodeInfoWithStorage[127.0.0.1:34493,DS-efaa2f88-ddd2-4476-9214-8f0b2fcd7eb2,DISK], DatanodeInfoWithStorage[127.0.0.1:42042,DS-c0060097-3afd-4233-9d46-4df08af6631b,DISK], DatanodeInfoWithStorage[127.0.0.1:34746,DS-17e3a88e-2d1d-417a-9a90-639ea2582fa5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-303928621-172.17.0.13-1596869497690:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45207,DS-0ebd2c70-7eca-42b7-8413-dc5677a9f142,DISK], DatanodeInfoWithStorage[127.0.0.1:38222,DS-7b023bb7-f4c5-476a-8fdf-ce0251063469,DISK], DatanodeInfoWithStorage[127.0.0.1:36050,DS-0db984a3-da7e-47f2-8a93-489fb4db6417,DISK], DatanodeInfoWithStorage[127.0.0.1:43285,DS-cc29a4d8-da5c-461a-89b8-519d1424e65c,DISK], DatanodeInfoWithStorage[127.0.0.1:37331,DS-3aca978d-c8b2-471f-b810-9df7c0469301,DISK], DatanodeInfoWithStorage[127.0.0.1:43483,DS-746e1ef3-0094-4bb8-9923-2da5582e0845,DISK], DatanodeInfoWithStorage[127.0.0.1:40859,DS-42a0e267-15b9-4c55-a0eb-1750cc04c521,DISK], DatanodeInfoWithStorage[127.0.0.1:42507,DS-56b95c6b-e8ab-44c7-b051-879bd51dfd36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-303928621-172.17.0.13-1596869497690:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45207,DS-0ebd2c70-7eca-42b7-8413-dc5677a9f142,DISK], DatanodeInfoWithStorage[127.0.0.1:38222,DS-7b023bb7-f4c5-476a-8fdf-ce0251063469,DISK], DatanodeInfoWithStorage[127.0.0.1:36050,DS-0db984a3-da7e-47f2-8a93-489fb4db6417,DISK], DatanodeInfoWithStorage[127.0.0.1:43285,DS-cc29a4d8-da5c-461a-89b8-519d1424e65c,DISK], DatanodeInfoWithStorage[127.0.0.1:37331,DS-3aca978d-c8b2-471f-b810-9df7c0469301,DISK], DatanodeInfoWithStorage[127.0.0.1:43483,DS-746e1ef3-0094-4bb8-9923-2da5582e0845,DISK], DatanodeInfoWithStorage[127.0.0.1:40859,DS-42a0e267-15b9-4c55-a0eb-1750cc04c521,DISK], DatanodeInfoWithStorage[127.0.0.1:42507,DS-56b95c6b-e8ab-44c7-b051-879bd51dfd36,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-468269732-172.17.0.13-1596869609513:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40463,DS-806fcbd4-1aa1-40a2-8f3e-16056a973a01,DISK], DatanodeInfoWithStorage[127.0.0.1:42936,DS-6284706c-8f18-4e84-8753-5108e775d036,DISK], DatanodeInfoWithStorage[127.0.0.1:42523,DS-449dccd7-4c37-4918-8973-9752c77dd607,DISK], DatanodeInfoWithStorage[127.0.0.1:36738,DS-1094aac6-2f9f-472f-8d84-58397a4d4a88,DISK], DatanodeInfoWithStorage[127.0.0.1:35567,DS-bc9e95d3-b62a-4211-93ff-f58d2cdbfb17,DISK], DatanodeInfoWithStorage[127.0.0.1:42463,DS-533934f9-d1d9-4981-91d2-cb6eb6cea06f,DISK], DatanodeInfoWithStorage[127.0.0.1:37881,DS-e0d5ee0e-1cc0-45a1-857d-e3fe99699198,DISK], DatanodeInfoWithStorage[127.0.0.1:33276,DS-a2995c32-70bc-48fc-b5a2-07afd9404280,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-468269732-172.17.0.13-1596869609513:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40463,DS-806fcbd4-1aa1-40a2-8f3e-16056a973a01,DISK], DatanodeInfoWithStorage[127.0.0.1:42936,DS-6284706c-8f18-4e84-8753-5108e775d036,DISK], DatanodeInfoWithStorage[127.0.0.1:42523,DS-449dccd7-4c37-4918-8973-9752c77dd607,DISK], DatanodeInfoWithStorage[127.0.0.1:36738,DS-1094aac6-2f9f-472f-8d84-58397a4d4a88,DISK], DatanodeInfoWithStorage[127.0.0.1:35567,DS-bc9e95d3-b62a-4211-93ff-f58d2cdbfb17,DISK], DatanodeInfoWithStorage[127.0.0.1:42463,DS-533934f9-d1d9-4981-91d2-cb6eb6cea06f,DISK], DatanodeInfoWithStorage[127.0.0.1:37881,DS-e0d5ee0e-1cc0-45a1-857d-e3fe99699198,DISK], DatanodeInfoWithStorage[127.0.0.1:33276,DS-a2995c32-70bc-48fc-b5a2-07afd9404280,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1869724654-172.17.0.13-1596870259460:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44048,DS-44495243-7b6e-433c-8df5-6a0bbcd8af46,DISK], DatanodeInfoWithStorage[127.0.0.1:38653,DS-93d77843-f2df-40f8-8e1d-5a5b05abe932,DISK], DatanodeInfoWithStorage[127.0.0.1:40555,DS-42b34ad1-4975-447c-a129-9f18443f36b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33628,DS-3ff5029d-8a65-4c18-8061-0d6c6cc48858,DISK], DatanodeInfoWithStorage[127.0.0.1:33258,DS-e8c6cda0-21f7-495e-895d-927c5ea27a7e,DISK], DatanodeInfoWithStorage[127.0.0.1:38444,DS-294a9a60-f09a-4920-a301-7fd1ce90e85a,DISK], DatanodeInfoWithStorage[127.0.0.1:34276,DS-7fe283de-523c-4a93-9099-f923662ccc93,DISK], DatanodeInfoWithStorage[127.0.0.1:34110,DS-140aa1d2-0fcd-4e16-bdbc-c253e6caa048,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1869724654-172.17.0.13-1596870259460:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44048,DS-44495243-7b6e-433c-8df5-6a0bbcd8af46,DISK], DatanodeInfoWithStorage[127.0.0.1:38653,DS-93d77843-f2df-40f8-8e1d-5a5b05abe932,DISK], DatanodeInfoWithStorage[127.0.0.1:40555,DS-42b34ad1-4975-447c-a129-9f18443f36b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33628,DS-3ff5029d-8a65-4c18-8061-0d6c6cc48858,DISK], DatanodeInfoWithStorage[127.0.0.1:33258,DS-e8c6cda0-21f7-495e-895d-927c5ea27a7e,DISK], DatanodeInfoWithStorage[127.0.0.1:38444,DS-294a9a60-f09a-4920-a301-7fd1ce90e85a,DISK], DatanodeInfoWithStorage[127.0.0.1:34276,DS-7fe283de-523c-4a93-9099-f923662ccc93,DISK], DatanodeInfoWithStorage[127.0.0.1:34110,DS-140aa1d2-0fcd-4e16-bdbc-c253e6caa048,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-635620166-172.17.0.13-1596870429604:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45847,DS-fceeea8a-b575-457f-b216-959b5ab5dc38,DISK], DatanodeInfoWithStorage[127.0.0.1:33161,DS-779464ee-051f-40af-b88f-8c18206a4f97,DISK], DatanodeInfoWithStorage[127.0.0.1:42084,DS-5ec5efb9-a817-486c-90a0-9c01c7c83f55,DISK], DatanodeInfoWithStorage[127.0.0.1:37138,DS-78d9d621-c653-4468-872a-d0499c0ed09a,DISK], DatanodeInfoWithStorage[127.0.0.1:43460,DS-493f79d4-4254-4101-bf43-ab32450c2f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:38060,DS-e349401e-efe1-4b93-8f6f-9303caeb2a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:37664,DS-519ae148-7bd8-4dc0-9426-c99398024853,DISK], DatanodeInfoWithStorage[127.0.0.1:44509,DS-c3019caa-ff8e-4441-9317-c05fffe84314,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-635620166-172.17.0.13-1596870429604:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45847,DS-fceeea8a-b575-457f-b216-959b5ab5dc38,DISK], DatanodeInfoWithStorage[127.0.0.1:33161,DS-779464ee-051f-40af-b88f-8c18206a4f97,DISK], DatanodeInfoWithStorage[127.0.0.1:42084,DS-5ec5efb9-a817-486c-90a0-9c01c7c83f55,DISK], DatanodeInfoWithStorage[127.0.0.1:37138,DS-78d9d621-c653-4468-872a-d0499c0ed09a,DISK], DatanodeInfoWithStorage[127.0.0.1:43460,DS-493f79d4-4254-4101-bf43-ab32450c2f1d,DISK], DatanodeInfoWithStorage[127.0.0.1:38060,DS-e349401e-efe1-4b93-8f6f-9303caeb2a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:37664,DS-519ae148-7bd8-4dc0-9426-c99398024853,DISK], DatanodeInfoWithStorage[127.0.0.1:44509,DS-c3019caa-ff8e-4441-9317-c05fffe84314,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-788145659-172.17.0.13-1596870823408:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42105,DS-c577420e-a3de-4485-9797-dd131f8a8747,DISK], DatanodeInfoWithStorage[127.0.0.1:45766,DS-b674680a-3160-4253-8535-202d1ca0eef7,DISK], DatanodeInfoWithStorage[127.0.0.1:40230,DS-c6f62542-ff16-49b2-81d0-78cb46b5849c,DISK], DatanodeInfoWithStorage[127.0.0.1:37894,DS-a7ff3a68-1950-42c7-ac40-fa5b64a73458,DISK], DatanodeInfoWithStorage[127.0.0.1:40130,DS-cb4a450c-8e49-47d5-ba14-b51dd0baa929,DISK], DatanodeInfoWithStorage[127.0.0.1:46469,DS-3d7cb899-2818-44ae-bb4e-4eb5cb4dd5df,DISK], DatanodeInfoWithStorage[127.0.0.1:42285,DS-b2d214ce-7b71-419c-b5a4-7d8712c9a1c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41867,DS-6d9d8b8d-4a8b-450b-b8ab-c0534a9b1edb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-788145659-172.17.0.13-1596870823408:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42105,DS-c577420e-a3de-4485-9797-dd131f8a8747,DISK], DatanodeInfoWithStorage[127.0.0.1:45766,DS-b674680a-3160-4253-8535-202d1ca0eef7,DISK], DatanodeInfoWithStorage[127.0.0.1:40230,DS-c6f62542-ff16-49b2-81d0-78cb46b5849c,DISK], DatanodeInfoWithStorage[127.0.0.1:37894,DS-a7ff3a68-1950-42c7-ac40-fa5b64a73458,DISK], DatanodeInfoWithStorage[127.0.0.1:40130,DS-cb4a450c-8e49-47d5-ba14-b51dd0baa929,DISK], DatanodeInfoWithStorage[127.0.0.1:46469,DS-3d7cb899-2818-44ae-bb4e-4eb5cb4dd5df,DISK], DatanodeInfoWithStorage[127.0.0.1:42285,DS-b2d214ce-7b71-419c-b5a4-7d8712c9a1c3,DISK], DatanodeInfoWithStorage[127.0.0.1:41867,DS-6d9d8b8d-4a8b-450b-b8ab-c0534a9b1edb,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-934499610-172.17.0.13-1596870900212:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38840,DS-7ae8e584-3a4a-467b-9440-d397fc7dd745,DISK], DatanodeInfoWithStorage[127.0.0.1:43109,DS-3b5c7a9f-c084-479e-95cc-1907073dafff,DISK], DatanodeInfoWithStorage[127.0.0.1:32819,DS-ed4fcb50-3ac0-4724-9992-26229d1aea88,DISK], DatanodeInfoWithStorage[127.0.0.1:44389,DS-467d5051-0517-42ee-ac92-ee49526ea059,DISK], DatanodeInfoWithStorage[127.0.0.1:46868,DS-97ee6ec5-a3be-4505-94ff-bc7f98473090,DISK], DatanodeInfoWithStorage[127.0.0.1:37687,DS-3ea64cf4-51b4-4129-abf6-4c5ce3181b80,DISK], DatanodeInfoWithStorage[127.0.0.1:36456,DS-c9230a2c-287e-4e5f-9fed-a49b7f0312f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45451,DS-9467fca8-b912-4257-95ed-0868b0119eae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-934499610-172.17.0.13-1596870900212:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38840,DS-7ae8e584-3a4a-467b-9440-d397fc7dd745,DISK], DatanodeInfoWithStorage[127.0.0.1:43109,DS-3b5c7a9f-c084-479e-95cc-1907073dafff,DISK], DatanodeInfoWithStorage[127.0.0.1:32819,DS-ed4fcb50-3ac0-4724-9992-26229d1aea88,DISK], DatanodeInfoWithStorage[127.0.0.1:44389,DS-467d5051-0517-42ee-ac92-ee49526ea059,DISK], DatanodeInfoWithStorage[127.0.0.1:46868,DS-97ee6ec5-a3be-4505-94ff-bc7f98473090,DISK], DatanodeInfoWithStorage[127.0.0.1:37687,DS-3ea64cf4-51b4-4129-abf6-4c5ce3181b80,DISK], DatanodeInfoWithStorage[127.0.0.1:36456,DS-c9230a2c-287e-4e5f-9fed-a49b7f0312f3,DISK], DatanodeInfoWithStorage[127.0.0.1:45451,DS-9467fca8-b912-4257-95ed-0868b0119eae,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-157849967-172.17.0.13-1596870969414:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41722,DS-39e34ae1-2691-44e7-9d7c-3d305afd70cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40159,DS-4b28c8ae-1aeb-475b-bee9-630715fe3cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:40713,DS-a435d743-9c32-4c69-ac01-487dc46619f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37860,DS-f7f1211e-1db4-4546-9e21-f2214f056bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:34852,DS-943dad67-4887-47e8-b6d1-aa84f313f30b,DISK], DatanodeInfoWithStorage[127.0.0.1:40961,DS-a0fbf2c9-5bfc-49a4-b1c7-ce525dc14579,DISK], DatanodeInfoWithStorage[127.0.0.1:37501,DS-9fd40b4f-edab-48d2-b5d7-eaddcadf0718,DISK], DatanodeInfoWithStorage[127.0.0.1:37958,DS-51634cdb-2f8d-43e2-b007-396ad25620cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-157849967-172.17.0.13-1596870969414:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41722,DS-39e34ae1-2691-44e7-9d7c-3d305afd70cb,DISK], DatanodeInfoWithStorage[127.0.0.1:40159,DS-4b28c8ae-1aeb-475b-bee9-630715fe3cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:40713,DS-a435d743-9c32-4c69-ac01-487dc46619f9,DISK], DatanodeInfoWithStorage[127.0.0.1:37860,DS-f7f1211e-1db4-4546-9e21-f2214f056bf3,DISK], DatanodeInfoWithStorage[127.0.0.1:34852,DS-943dad67-4887-47e8-b6d1-aa84f313f30b,DISK], DatanodeInfoWithStorage[127.0.0.1:40961,DS-a0fbf2c9-5bfc-49a4-b1c7-ce525dc14579,DISK], DatanodeInfoWithStorage[127.0.0.1:37501,DS-9fd40b4f-edab-48d2-b5d7-eaddcadf0718,DISK], DatanodeInfoWithStorage[127.0.0.1:37958,DS-51634cdb-2f8d-43e2-b007-396ad25620cf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1836123926-172.17.0.13-1596871012616:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34441,DS-a8e9e729-bd18-475c-8df1-5cbb802a823b,DISK], DatanodeInfoWithStorage[127.0.0.1:45678,DS-5ed1cdcb-6894-4b95-9d6b-b7cdec4764f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34737,DS-13533480-c346-4bbb-972e-4d9a11aabdf5,DISK], DatanodeInfoWithStorage[127.0.0.1:39037,DS-6caa3bf8-1d40-4932-8c88-8aabde494021,DISK], DatanodeInfoWithStorage[127.0.0.1:35817,DS-88a7885d-903f-4a17-95bf-dfa25352937b,DISK], DatanodeInfoWithStorage[127.0.0.1:40608,DS-919fa459-aaad-46cd-88b2-164d7a3e4f67,DISK], DatanodeInfoWithStorage[127.0.0.1:37276,DS-b3d3baa5-4687-439c-b475-3811512790fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42276,DS-c0bef8a4-ee8a-4a1b-be8c-76a6cacf94a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1836123926-172.17.0.13-1596871012616:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34441,DS-a8e9e729-bd18-475c-8df1-5cbb802a823b,DISK], DatanodeInfoWithStorage[127.0.0.1:45678,DS-5ed1cdcb-6894-4b95-9d6b-b7cdec4764f1,DISK], DatanodeInfoWithStorage[127.0.0.1:34737,DS-13533480-c346-4bbb-972e-4d9a11aabdf5,DISK], DatanodeInfoWithStorage[127.0.0.1:39037,DS-6caa3bf8-1d40-4932-8c88-8aabde494021,DISK], DatanodeInfoWithStorage[127.0.0.1:35817,DS-88a7885d-903f-4a17-95bf-dfa25352937b,DISK], DatanodeInfoWithStorage[127.0.0.1:40608,DS-919fa459-aaad-46cd-88b2-164d7a3e4f67,DISK], DatanodeInfoWithStorage[127.0.0.1:37276,DS-b3d3baa5-4687-439c-b475-3811512790fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42276,DS-c0bef8a4-ee8a-4a1b-be8c-76a6cacf94a0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1250290286-172.17.0.13-1596871156952:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43247,DS-429929bb-2762-4979-a339-43068e487ec2,DISK], DatanodeInfoWithStorage[127.0.0.1:35210,DS-1c41c4a9-428b-4989-bb82-0d372955df92,DISK], DatanodeInfoWithStorage[127.0.0.1:46703,DS-e7f06bf6-b390-490b-8866-ae5a7d495292,DISK], DatanodeInfoWithStorage[127.0.0.1:33865,DS-820a3929-c949-4331-b782-0265e4387c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:45465,DS-2045dad4-aef7-4025-b9b9-5a821724dcd6,DISK], DatanodeInfoWithStorage[127.0.0.1:36903,DS-e40f1096-6f7a-44d3-aa18-54ce0a2003c4,DISK], DatanodeInfoWithStorage[127.0.0.1:39183,DS-4ae10f7d-8187-4d4b-a3d4-3cdc8b0f06a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39996,DS-f62ec78b-8559-472c-9a41-0bc479481726,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1250290286-172.17.0.13-1596871156952:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43247,DS-429929bb-2762-4979-a339-43068e487ec2,DISK], DatanodeInfoWithStorage[127.0.0.1:35210,DS-1c41c4a9-428b-4989-bb82-0d372955df92,DISK], DatanodeInfoWithStorage[127.0.0.1:46703,DS-e7f06bf6-b390-490b-8866-ae5a7d495292,DISK], DatanodeInfoWithStorage[127.0.0.1:33865,DS-820a3929-c949-4331-b782-0265e4387c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:45465,DS-2045dad4-aef7-4025-b9b9-5a821724dcd6,DISK], DatanodeInfoWithStorage[127.0.0.1:36903,DS-e40f1096-6f7a-44d3-aa18-54ce0a2003c4,DISK], DatanodeInfoWithStorage[127.0.0.1:39183,DS-4ae10f7d-8187-4d4b-a3d4-3cdc8b0f06a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39996,DS-f62ec78b-8559-472c-9a41-0bc479481726,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1159541993-172.17.0.13-1596871381452:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34863,DS-d814a431-f368-4532-ac92-29908835cf1a,DISK], DatanodeInfoWithStorage[127.0.0.1:34786,DS-ca3e638f-0657-481b-8546-4b559a4e912c,DISK], DatanodeInfoWithStorage[127.0.0.1:34515,DS-b6388d37-002a-4695-9055-ea810a4363ba,DISK], DatanodeInfoWithStorage[127.0.0.1:32804,DS-de1aada3-8bd6-4a54-b437-01215b3465a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44860,DS-b317cd1b-5629-43b2-8c2c-826802ec6a12,DISK], DatanodeInfoWithStorage[127.0.0.1:33211,DS-989021c8-d187-4ac3-9f68-59f8bf3c1d8e,DISK], DatanodeInfoWithStorage[127.0.0.1:34927,DS-8e721912-7e72-4098-9208-7d6d7e255bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:38080,DS-d4092507-4871-481d-a3d2-708f5b6f615c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1159541993-172.17.0.13-1596871381452:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34863,DS-d814a431-f368-4532-ac92-29908835cf1a,DISK], DatanodeInfoWithStorage[127.0.0.1:34786,DS-ca3e638f-0657-481b-8546-4b559a4e912c,DISK], DatanodeInfoWithStorage[127.0.0.1:34515,DS-b6388d37-002a-4695-9055-ea810a4363ba,DISK], DatanodeInfoWithStorage[127.0.0.1:32804,DS-de1aada3-8bd6-4a54-b437-01215b3465a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44860,DS-b317cd1b-5629-43b2-8c2c-826802ec6a12,DISK], DatanodeInfoWithStorage[127.0.0.1:33211,DS-989021c8-d187-4ac3-9f68-59f8bf3c1d8e,DISK], DatanodeInfoWithStorage[127.0.0.1:34927,DS-8e721912-7e72-4098-9208-7d6d7e255bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:38080,DS-d4092507-4871-481d-a3d2-708f5b6f615c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2084175618-172.17.0.13-1596871704890:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37208,DS-025f7aac-3c6e-4a0c-9114-6d5892401122,DISK], DatanodeInfoWithStorage[127.0.0.1:35887,DS-2d56880b-3348-418e-8659-db1a8bb56f63,DISK], DatanodeInfoWithStorage[127.0.0.1:36298,DS-fca99409-9bf5-4522-bd1d-1f716a1f3a2b,DISK], DatanodeInfoWithStorage[127.0.0.1:40568,DS-bdf48258-6804-49fb-a616-ffb91161f3ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44798,DS-b23a1a52-b931-4046-aea9-a02f7b056746,DISK], DatanodeInfoWithStorage[127.0.0.1:37338,DS-e13df804-b899-4afb-9384-306d4e84c9d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43923,DS-6a1eaa22-05ad-4d64-94fc-e9d68bc27d28,DISK], DatanodeInfoWithStorage[127.0.0.1:37185,DS-44b65f25-337a-4e9d-bee9-a6cb6a213050,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2084175618-172.17.0.13-1596871704890:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37208,DS-025f7aac-3c6e-4a0c-9114-6d5892401122,DISK], DatanodeInfoWithStorage[127.0.0.1:35887,DS-2d56880b-3348-418e-8659-db1a8bb56f63,DISK], DatanodeInfoWithStorage[127.0.0.1:36298,DS-fca99409-9bf5-4522-bd1d-1f716a1f3a2b,DISK], DatanodeInfoWithStorage[127.0.0.1:40568,DS-bdf48258-6804-49fb-a616-ffb91161f3ba,DISK], DatanodeInfoWithStorage[127.0.0.1:44798,DS-b23a1a52-b931-4046-aea9-a02f7b056746,DISK], DatanodeInfoWithStorage[127.0.0.1:37338,DS-e13df804-b899-4afb-9384-306d4e84c9d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43923,DS-6a1eaa22-05ad-4d64-94fc-e9d68bc27d28,DISK], DatanodeInfoWithStorage[127.0.0.1:37185,DS-44b65f25-337a-4e9d-bee9-a6cb6a213050,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.sync.behind.writes.in.background
component: hdfs:DataNode
v1: true
v2: false
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery20
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1922864889-172.17.0.13-1596872705158:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46766,DS-9ded6636-7578-4221-87b7-5d2afd2f102f,DISK], DatanodeInfoWithStorage[127.0.0.1:42817,DS-5d13b7fd-881b-414a-866f-de95d82fb72b,DISK], DatanodeInfoWithStorage[127.0.0.1:41420,DS-1f8f0224-7e90-4266-b38b-eaa64da03b89,DISK], DatanodeInfoWithStorage[127.0.0.1:39844,DS-f0ca5a95-7982-45f1-ab33-8bf05a9ba89d,DISK], DatanodeInfoWithStorage[127.0.0.1:43631,DS-93b61435-03e1-4ac5-b6db-9d4ad857292f,DISK], DatanodeInfoWithStorage[127.0.0.1:37980,DS-0a88be80-2f01-4502-9434-120052104ced,DISK], DatanodeInfoWithStorage[127.0.0.1:44699,DS-f6825168-5300-4d04-a000-3d3a6260d915,DISK], DatanodeInfoWithStorage[127.0.0.1:34475,DS-818567ca-db13-4aa0-9893-4b03b5814133,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1922864889-172.17.0.13-1596872705158:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46766,DS-9ded6636-7578-4221-87b7-5d2afd2f102f,DISK], DatanodeInfoWithStorage[127.0.0.1:42817,DS-5d13b7fd-881b-414a-866f-de95d82fb72b,DISK], DatanodeInfoWithStorage[127.0.0.1:41420,DS-1f8f0224-7e90-4266-b38b-eaa64da03b89,DISK], DatanodeInfoWithStorage[127.0.0.1:39844,DS-f0ca5a95-7982-45f1-ab33-8bf05a9ba89d,DISK], DatanodeInfoWithStorage[127.0.0.1:43631,DS-93b61435-03e1-4ac5-b6db-9d4ad857292f,DISK], DatanodeInfoWithStorage[127.0.0.1:37980,DS-0a88be80-2f01-4502-9434-120052104ced,DISK], DatanodeInfoWithStorage[127.0.0.1:44699,DS-f6825168-5300-4d04-a000-3d3a6260d915,DISK], DatanodeInfoWithStorage[127.0.0.1:34475,DS-818567ca-db13-4aa0-9893-4b03b5814133,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery20(TestFileChecksum.java:533)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5361
