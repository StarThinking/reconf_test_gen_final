reconf_parameter: dfs.client.read.shortcircuit
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1185531839-172.17.0.20-1595308273380:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34410,DS-a29ae544-9569-43be-b447-b8ba5ec4d310,DISK], DatanodeInfoWithStorage[127.0.0.1:42638,DS-63981240-5dd1-44cf-b476-1cdcaf739980,DISK], DatanodeInfoWithStorage[127.0.0.1:45892,DS-c02088e4-f3eb-4db1-b75d-8985770a8ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:38435,DS-0df3a42c-87d1-4add-9fc2-06a520c0c3e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38829,DS-c92a74a4-fc90-4cc2-be71-efdf8f48c630,DISK], DatanodeInfoWithStorage[127.0.0.1:36540,DS-7727e5b2-531e-42b1-889a-b889dbd1f3de,DISK], DatanodeInfoWithStorage[127.0.0.1:35995,DS-37ebc1d3-2400-44de-90f2-250de8ae1347,DISK], DatanodeInfoWithStorage[127.0.0.1:40357,DS-84c7bb06-8b6f-4b78-9c4b-e17ac986e527,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1185531839-172.17.0.20-1595308273380:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34410,DS-a29ae544-9569-43be-b447-b8ba5ec4d310,DISK], DatanodeInfoWithStorage[127.0.0.1:42638,DS-63981240-5dd1-44cf-b476-1cdcaf739980,DISK], DatanodeInfoWithStorage[127.0.0.1:45892,DS-c02088e4-f3eb-4db1-b75d-8985770a8ba0,DISK], DatanodeInfoWithStorage[127.0.0.1:38435,DS-0df3a42c-87d1-4add-9fc2-06a520c0c3e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38829,DS-c92a74a4-fc90-4cc2-be71-efdf8f48c630,DISK], DatanodeInfoWithStorage[127.0.0.1:36540,DS-7727e5b2-531e-42b1-889a-b889dbd1f3de,DISK], DatanodeInfoWithStorage[127.0.0.1:35995,DS-37ebc1d3-2400-44de-90f2-250de8ae1347,DISK], DatanodeInfoWithStorage[127.0.0.1:40357,DS-84c7bb06-8b6f-4b78-9c4b-e17ac986e527,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-836542123-172.17.0.20-1595308857417:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46394,DS-1caf2c1a-29ee-424b-a62d-1e6a44ef9ced,DISK], DatanodeInfoWithStorage[127.0.0.1:38719,DS-bb73ae97-442a-4cd6-aa40-3e4a8cf5818f,DISK], DatanodeInfoWithStorage[127.0.0.1:34604,DS-1c2f078f-e837-48ed-8466-38f4ec0611d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45195,DS-c2270195-0be1-4c55-9c21-04778137c4af,DISK], DatanodeInfoWithStorage[127.0.0.1:33532,DS-716d22f0-b583-4be3-b059-ff41971c4c4b,DISK], DatanodeInfoWithStorage[127.0.0.1:34086,DS-925dba0e-f9ff-4d8a-8364-b0a62e392b03,DISK], DatanodeInfoWithStorage[127.0.0.1:36585,DS-6c1c2e3a-f0ee-4680-8f63-33fb24aac502,DISK], DatanodeInfoWithStorage[127.0.0.1:34371,DS-425b0fbe-7b52-4de7-bb83-a1189844e93e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-836542123-172.17.0.20-1595308857417:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46394,DS-1caf2c1a-29ee-424b-a62d-1e6a44ef9ced,DISK], DatanodeInfoWithStorage[127.0.0.1:38719,DS-bb73ae97-442a-4cd6-aa40-3e4a8cf5818f,DISK], DatanodeInfoWithStorage[127.0.0.1:34604,DS-1c2f078f-e837-48ed-8466-38f4ec0611d8,DISK], DatanodeInfoWithStorage[127.0.0.1:45195,DS-c2270195-0be1-4c55-9c21-04778137c4af,DISK], DatanodeInfoWithStorage[127.0.0.1:33532,DS-716d22f0-b583-4be3-b059-ff41971c4c4b,DISK], DatanodeInfoWithStorage[127.0.0.1:34086,DS-925dba0e-f9ff-4d8a-8364-b0a62e392b03,DISK], DatanodeInfoWithStorage[127.0.0.1:36585,DS-6c1c2e3a-f0ee-4680-8f63-33fb24aac502,DISK], DatanodeInfoWithStorage[127.0.0.1:34371,DS-425b0fbe-7b52-4de7-bb83-a1189844e93e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1654260536-172.17.0.20-1595309224218:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36612,DS-119f7e5f-d782-4e49-8c40-c99823b784fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38168,DS-cbe52a26-35e2-4e8a-a5b1-2ef906ab9158,DISK], DatanodeInfoWithStorage[127.0.0.1:36705,DS-bd0f362d-555e-4188-a29e-0ea54705a948,DISK], DatanodeInfoWithStorage[127.0.0.1:45313,DS-b5ffccce-b562-4ef1-aa3c-0f6e4cb67559,DISK], DatanodeInfoWithStorage[127.0.0.1:40448,DS-7d779873-2266-4f37-9930-bfc977dbc9b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44662,DS-280bce9a-24d6-4c87-b72c-2e152aeaf239,DISK], DatanodeInfoWithStorage[127.0.0.1:42623,DS-09fa8cf9-ed5d-47d2-b7e7-18e263a63173,DISK], DatanodeInfoWithStorage[127.0.0.1:40295,DS-8153470e-50ff-4c5b-b60f-a453d4685f0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1654260536-172.17.0.20-1595309224218:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36612,DS-119f7e5f-d782-4e49-8c40-c99823b784fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38168,DS-cbe52a26-35e2-4e8a-a5b1-2ef906ab9158,DISK], DatanodeInfoWithStorage[127.0.0.1:36705,DS-bd0f362d-555e-4188-a29e-0ea54705a948,DISK], DatanodeInfoWithStorage[127.0.0.1:45313,DS-b5ffccce-b562-4ef1-aa3c-0f6e4cb67559,DISK], DatanodeInfoWithStorage[127.0.0.1:40448,DS-7d779873-2266-4f37-9930-bfc977dbc9b9,DISK], DatanodeInfoWithStorage[127.0.0.1:44662,DS-280bce9a-24d6-4c87-b72c-2e152aeaf239,DISK], DatanodeInfoWithStorage[127.0.0.1:42623,DS-09fa8cf9-ed5d-47d2-b7e7-18e263a63173,DISK], DatanodeInfoWithStorage[127.0.0.1:40295,DS-8153470e-50ff-4c5b-b60f-a453d4685f0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-542159046-172.17.0.20-1595309490138:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39753,DS-2a11b906-5354-4973-90c9-12247f114075,DISK], DatanodeInfoWithStorage[127.0.0.1:37402,DS-4568ff77-17ab-4674-8ae6-52c701b6c032,DISK], DatanodeInfoWithStorage[127.0.0.1:34891,DS-32a33762-bee6-4b30-ab7f-a25e6371a8e7,DISK], DatanodeInfoWithStorage[127.0.0.1:35904,DS-cb9cbcd0-874d-4b4a-bf86-3b27502125e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44689,DS-57128118-8fcb-4ad3-b8a5-17dc9ba1787d,DISK], DatanodeInfoWithStorage[127.0.0.1:45041,DS-377951d7-4cd2-4716-a769-95779db129e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34892,DS-076b7bbc-0a91-4c67-b39f-491caf9d42f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37016,DS-b62d2076-554d-4442-8e37-7c6f2a7274c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-542159046-172.17.0.20-1595309490138:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39753,DS-2a11b906-5354-4973-90c9-12247f114075,DISK], DatanodeInfoWithStorage[127.0.0.1:37402,DS-4568ff77-17ab-4674-8ae6-52c701b6c032,DISK], DatanodeInfoWithStorage[127.0.0.1:34891,DS-32a33762-bee6-4b30-ab7f-a25e6371a8e7,DISK], DatanodeInfoWithStorage[127.0.0.1:35904,DS-cb9cbcd0-874d-4b4a-bf86-3b27502125e0,DISK], DatanodeInfoWithStorage[127.0.0.1:44689,DS-57128118-8fcb-4ad3-b8a5-17dc9ba1787d,DISK], DatanodeInfoWithStorage[127.0.0.1:45041,DS-377951d7-4cd2-4716-a769-95779db129e3,DISK], DatanodeInfoWithStorage[127.0.0.1:34892,DS-076b7bbc-0a91-4c67-b39f-491caf9d42f6,DISK], DatanodeInfoWithStorage[127.0.0.1:37016,DS-b62d2076-554d-4442-8e37-7c6f2a7274c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1993472650-172.17.0.20-1595309676726:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45486,DS-e0389f1c-3607-4f72-9b7f-3c28f11d1cb7,DISK], DatanodeInfoWithStorage[127.0.0.1:35018,DS-53086a7c-406f-421e-96cf-d3c503436c03,DISK], DatanodeInfoWithStorage[127.0.0.1:33568,DS-a636ff01-7fb0-4a39-845c-63a1aadec26f,DISK], DatanodeInfoWithStorage[127.0.0.1:46875,DS-389decfc-ec05-422d-803c-1a5667aeba08,DISK], DatanodeInfoWithStorage[127.0.0.1:42297,DS-4a670963-964d-4f67-b277-c89476bc3e8f,DISK], DatanodeInfoWithStorage[127.0.0.1:33573,DS-19e24e08-5ec1-48af-ab64-1e4a098b4606,DISK], DatanodeInfoWithStorage[127.0.0.1:43549,DS-82c940cf-8436-4968-b6b0-02f1ef7bed77,DISK], DatanodeInfoWithStorage[127.0.0.1:35460,DS-f9a1b947-9fe1-4a0f-bede-5f5d25ce2345,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1993472650-172.17.0.20-1595309676726:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45486,DS-e0389f1c-3607-4f72-9b7f-3c28f11d1cb7,DISK], DatanodeInfoWithStorage[127.0.0.1:35018,DS-53086a7c-406f-421e-96cf-d3c503436c03,DISK], DatanodeInfoWithStorage[127.0.0.1:33568,DS-a636ff01-7fb0-4a39-845c-63a1aadec26f,DISK], DatanodeInfoWithStorage[127.0.0.1:46875,DS-389decfc-ec05-422d-803c-1a5667aeba08,DISK], DatanodeInfoWithStorage[127.0.0.1:42297,DS-4a670963-964d-4f67-b277-c89476bc3e8f,DISK], DatanodeInfoWithStorage[127.0.0.1:33573,DS-19e24e08-5ec1-48af-ab64-1e4a098b4606,DISK], DatanodeInfoWithStorage[127.0.0.1:43549,DS-82c940cf-8436-4968-b6b0-02f1ef7bed77,DISK], DatanodeInfoWithStorage[127.0.0.1:35460,DS-f9a1b947-9fe1-4a0f-bede-5f5d25ce2345,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1567336330-172.17.0.20-1595309860797:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43767,DS-1758ef9a-336d-4415-85c9-3376a5c282c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37532,DS-88b3c684-a174-4e83-bd67-09d3dbe8fc9f,DISK], DatanodeInfoWithStorage[127.0.0.1:42010,DS-0af723ee-65dd-4234-b6f0-a408d86d7e92,DISK], DatanodeInfoWithStorage[127.0.0.1:42062,DS-c105eaba-3bfb-4700-9be0-bfd34123d937,DISK], DatanodeInfoWithStorage[127.0.0.1:37427,DS-939f3b83-e146-4f71-ae19-3ab3d388c3b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37926,DS-22777c27-9fdc-4d0d-ae5f-a172f5f4984c,DISK], DatanodeInfoWithStorage[127.0.0.1:46408,DS-d008c961-0767-405c-98f0-73689eaec89c,DISK], DatanodeInfoWithStorage[127.0.0.1:36936,DS-c34796c5-525d-485b-9cdf-a09964b1f30c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1567336330-172.17.0.20-1595309860797:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43767,DS-1758ef9a-336d-4415-85c9-3376a5c282c2,DISK], DatanodeInfoWithStorage[127.0.0.1:37532,DS-88b3c684-a174-4e83-bd67-09d3dbe8fc9f,DISK], DatanodeInfoWithStorage[127.0.0.1:42010,DS-0af723ee-65dd-4234-b6f0-a408d86d7e92,DISK], DatanodeInfoWithStorage[127.0.0.1:42062,DS-c105eaba-3bfb-4700-9be0-bfd34123d937,DISK], DatanodeInfoWithStorage[127.0.0.1:37427,DS-939f3b83-e146-4f71-ae19-3ab3d388c3b8,DISK], DatanodeInfoWithStorage[127.0.0.1:37926,DS-22777c27-9fdc-4d0d-ae5f-a172f5f4984c,DISK], DatanodeInfoWithStorage[127.0.0.1:46408,DS-d008c961-0767-405c-98f0-73689eaec89c,DISK], DatanodeInfoWithStorage[127.0.0.1:36936,DS-c34796c5-525d-485b-9cdf-a09964b1f30c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1768687155-172.17.0.20-1595310089124:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39404,DS-bd2d0729-b59f-4c1f-a738-4a8a24c7ec1a,DISK], DatanodeInfoWithStorage[127.0.0.1:39326,DS-2ece00be-773d-4ac0-946d-e796c3c9a768,DISK], DatanodeInfoWithStorage[127.0.0.1:36334,DS-d13ae988-3bae-418f-a2d2-d248fdcf9a80,DISK], DatanodeInfoWithStorage[127.0.0.1:38619,DS-65dcfd85-7c80-44c0-ad3d-bb2adf8d6231,DISK], DatanodeInfoWithStorage[127.0.0.1:40519,DS-a39d66ab-6115-44fd-b05a-3e2ded379fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:43785,DS-87254243-ec0a-439b-84ab-6fa64f165581,DISK], DatanodeInfoWithStorage[127.0.0.1:44044,DS-4296254f-2f42-480f-a23e-f61956272769,DISK], DatanodeInfoWithStorage[127.0.0.1:36469,DS-ba8d18c4-8824-42e9-9a0c-bcbd4511d6e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1768687155-172.17.0.20-1595310089124:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39404,DS-bd2d0729-b59f-4c1f-a738-4a8a24c7ec1a,DISK], DatanodeInfoWithStorage[127.0.0.1:39326,DS-2ece00be-773d-4ac0-946d-e796c3c9a768,DISK], DatanodeInfoWithStorage[127.0.0.1:36334,DS-d13ae988-3bae-418f-a2d2-d248fdcf9a80,DISK], DatanodeInfoWithStorage[127.0.0.1:38619,DS-65dcfd85-7c80-44c0-ad3d-bb2adf8d6231,DISK], DatanodeInfoWithStorage[127.0.0.1:40519,DS-a39d66ab-6115-44fd-b05a-3e2ded379fe3,DISK], DatanodeInfoWithStorage[127.0.0.1:43785,DS-87254243-ec0a-439b-84ab-6fa64f165581,DISK], DatanodeInfoWithStorage[127.0.0.1:44044,DS-4296254f-2f42-480f-a23e-f61956272769,DISK], DatanodeInfoWithStorage[127.0.0.1:36469,DS-ba8d18c4-8824-42e9-9a0c-bcbd4511d6e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-751271541-172.17.0.20-1595310130224:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37423,DS-636ddb5a-741a-4a84-a10e-c974f8223164,DISK], DatanodeInfoWithStorage[127.0.0.1:44970,DS-ba2207a8-fba9-408c-8b54-b5b669e74bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:36783,DS-812cd181-6d27-4282-aa0c-8e95e8e4d7c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38712,DS-6ca1acba-85b6-4948-a984-f59c7fecc6e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46685,DS-7212b37f-ca73-4ddd-94f7-5db4d74d9fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:39930,DS-dd5dfab5-f7cd-4c6c-9695-684bb7af1967,DISK], DatanodeInfoWithStorage[127.0.0.1:44472,DS-f41d0404-b13a-4255-884c-2f4c00de2c87,DISK], DatanodeInfoWithStorage[127.0.0.1:34631,DS-c619047f-ec75-49e1-91c9-236c4a200ff8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-751271541-172.17.0.20-1595310130224:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37423,DS-636ddb5a-741a-4a84-a10e-c974f8223164,DISK], DatanodeInfoWithStorage[127.0.0.1:44970,DS-ba2207a8-fba9-408c-8b54-b5b669e74bb2,DISK], DatanodeInfoWithStorage[127.0.0.1:36783,DS-812cd181-6d27-4282-aa0c-8e95e8e4d7c3,DISK], DatanodeInfoWithStorage[127.0.0.1:38712,DS-6ca1acba-85b6-4948-a984-f59c7fecc6e5,DISK], DatanodeInfoWithStorage[127.0.0.1:46685,DS-7212b37f-ca73-4ddd-94f7-5db4d74d9fd9,DISK], DatanodeInfoWithStorage[127.0.0.1:39930,DS-dd5dfab5-f7cd-4c6c-9695-684bb7af1967,DISK], DatanodeInfoWithStorage[127.0.0.1:44472,DS-f41d0404-b13a-4255-884c-2f4c00de2c87,DISK], DatanodeInfoWithStorage[127.0.0.1:34631,DS-c619047f-ec75-49e1-91c9-236c4a200ff8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1760668823-172.17.0.20-1595310305021:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35995,DS-d5c40839-facf-4e2f-82d8-c28d330a3975,DISK], DatanodeInfoWithStorage[127.0.0.1:43823,DS-ec3bf161-12fc-4031-961b-fb3031d375e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34140,DS-aece17dc-0668-4e82-83ce-94e8a03648e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35096,DS-d8841291-ea88-433a-99d8-f3792c038035,DISK], DatanodeInfoWithStorage[127.0.0.1:34062,DS-7ac6d5ed-1fa1-401e-bbb2-80fdfb319282,DISK], DatanodeInfoWithStorage[127.0.0.1:36704,DS-9d46ff30-6b6d-4312-8712-2947a16a73ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41730,DS-5b72ee95-8169-49c3-ae8a-87040d4119f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42626,DS-223ef374-a102-4f5c-b6fa-44e83685154d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1760668823-172.17.0.20-1595310305021:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35995,DS-d5c40839-facf-4e2f-82d8-c28d330a3975,DISK], DatanodeInfoWithStorage[127.0.0.1:43823,DS-ec3bf161-12fc-4031-961b-fb3031d375e5,DISK], DatanodeInfoWithStorage[127.0.0.1:34140,DS-aece17dc-0668-4e82-83ce-94e8a03648e6,DISK], DatanodeInfoWithStorage[127.0.0.1:35096,DS-d8841291-ea88-433a-99d8-f3792c038035,DISK], DatanodeInfoWithStorage[127.0.0.1:34062,DS-7ac6d5ed-1fa1-401e-bbb2-80fdfb319282,DISK], DatanodeInfoWithStorage[127.0.0.1:36704,DS-9d46ff30-6b6d-4312-8712-2947a16a73ea,DISK], DatanodeInfoWithStorage[127.0.0.1:41730,DS-5b72ee95-8169-49c3-ae8a-87040d4119f0,DISK], DatanodeInfoWithStorage[127.0.0.1:42626,DS-223ef374-a102-4f5c-b6fa-44e83685154d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2065862989-172.17.0.20-1595310673089:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39056,DS-caaea515-5b75-47ec-af8d-9d34c749586b,DISK], DatanodeInfoWithStorage[127.0.0.1:43089,DS-4fd99fd3-20f1-45db-8fda-8fafb9a8462a,DISK], DatanodeInfoWithStorage[127.0.0.1:41060,DS-fc648a45-5a23-4053-bbfa-e0f1429cfb58,DISK], DatanodeInfoWithStorage[127.0.0.1:35887,DS-d535c508-7111-480b-a152-d92283b3efaf,DISK], DatanodeInfoWithStorage[127.0.0.1:37477,DS-c68b4ba3-fa76-4146-a15b-fae221475a1e,DISK], DatanodeInfoWithStorage[127.0.0.1:44051,DS-b3b35830-7947-49f2-9c01-8f1afb388b5a,DISK], DatanodeInfoWithStorage[127.0.0.1:38591,DS-ab8d6ae4-04ff-4f5b-954e-7d539ba73fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:42141,DS-66667cb9-3568-4fd4-a6a7-5b9b3bdd7ab6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2065862989-172.17.0.20-1595310673089:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39056,DS-caaea515-5b75-47ec-af8d-9d34c749586b,DISK], DatanodeInfoWithStorage[127.0.0.1:43089,DS-4fd99fd3-20f1-45db-8fda-8fafb9a8462a,DISK], DatanodeInfoWithStorage[127.0.0.1:41060,DS-fc648a45-5a23-4053-bbfa-e0f1429cfb58,DISK], DatanodeInfoWithStorage[127.0.0.1:35887,DS-d535c508-7111-480b-a152-d92283b3efaf,DISK], DatanodeInfoWithStorage[127.0.0.1:37477,DS-c68b4ba3-fa76-4146-a15b-fae221475a1e,DISK], DatanodeInfoWithStorage[127.0.0.1:44051,DS-b3b35830-7947-49f2-9c01-8f1afb388b5a,DISK], DatanodeInfoWithStorage[127.0.0.1:38591,DS-ab8d6ae4-04ff-4f5b-954e-7d539ba73fa4,DISK], DatanodeInfoWithStorage[127.0.0.1:42141,DS-66667cb9-3568-4fd4-a6a7-5b9b3bdd7ab6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2067974558-172.17.0.20-1595311085686:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46169,DS-68bd9b81-c6ef-4386-8b9d-d5d15295bf15,DISK], DatanodeInfoWithStorage[127.0.0.1:40500,DS-0b9744a3-89c8-4d5e-b726-8b0af7e5f25e,DISK], DatanodeInfoWithStorage[127.0.0.1:43689,DS-41025f29-3676-4640-bfe9-71fe2349eec9,DISK], DatanodeInfoWithStorage[127.0.0.1:44378,DS-06093d4c-d73e-4ab3-add8-9254750f7d23,DISK], DatanodeInfoWithStorage[127.0.0.1:44075,DS-c98cde95-2f5d-4cd8-acc7-511b2288c81d,DISK], DatanodeInfoWithStorage[127.0.0.1:32889,DS-318547d1-cfac-4a17-b304-7b72ddd5d2b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42487,DS-1cc78f37-1e12-4494-9b72-e1d07025055b,DISK], DatanodeInfoWithStorage[127.0.0.1:44245,DS-07a21ba3-654d-49a1-b47b-79b6bcb90d76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2067974558-172.17.0.20-1595311085686:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46169,DS-68bd9b81-c6ef-4386-8b9d-d5d15295bf15,DISK], DatanodeInfoWithStorage[127.0.0.1:40500,DS-0b9744a3-89c8-4d5e-b726-8b0af7e5f25e,DISK], DatanodeInfoWithStorage[127.0.0.1:43689,DS-41025f29-3676-4640-bfe9-71fe2349eec9,DISK], DatanodeInfoWithStorage[127.0.0.1:44378,DS-06093d4c-d73e-4ab3-add8-9254750f7d23,DISK], DatanodeInfoWithStorage[127.0.0.1:44075,DS-c98cde95-2f5d-4cd8-acc7-511b2288c81d,DISK], DatanodeInfoWithStorage[127.0.0.1:32889,DS-318547d1-cfac-4a17-b304-7b72ddd5d2b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42487,DS-1cc78f37-1e12-4494-9b72-e1d07025055b,DISK], DatanodeInfoWithStorage[127.0.0.1:44245,DS-07a21ba3-654d-49a1-b47b-79b6bcb90d76,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1279810188-172.17.0.20-1595311628479:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42149,DS-7d0ae6c2-9175-4070-a4b3-b3c73ee2087c,DISK], DatanodeInfoWithStorage[127.0.0.1:37351,DS-2e1358eb-36a1-4c9a-8209-bc086bd79b50,DISK], DatanodeInfoWithStorage[127.0.0.1:33717,DS-c613dc53-688b-4a91-b1c6-44e23fbdccce,DISK], DatanodeInfoWithStorage[127.0.0.1:40903,DS-59181a2b-5c79-4479-8bb8-e7b3620dfa0d,DISK], DatanodeInfoWithStorage[127.0.0.1:36116,DS-89e16784-9ea8-4631-b13b-66e71e5204a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35860,DS-a19b53b2-a8ba-4018-b537-fa5d2a7ed4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41319,DS-4959a49c-2b39-4d2d-9db0-e4fca372d8be,DISK], DatanodeInfoWithStorage[127.0.0.1:36473,DS-711416ba-2c08-42b6-8ec9-ad8e36973e8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1279810188-172.17.0.20-1595311628479:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42149,DS-7d0ae6c2-9175-4070-a4b3-b3c73ee2087c,DISK], DatanodeInfoWithStorage[127.0.0.1:37351,DS-2e1358eb-36a1-4c9a-8209-bc086bd79b50,DISK], DatanodeInfoWithStorage[127.0.0.1:33717,DS-c613dc53-688b-4a91-b1c6-44e23fbdccce,DISK], DatanodeInfoWithStorage[127.0.0.1:40903,DS-59181a2b-5c79-4479-8bb8-e7b3620dfa0d,DISK], DatanodeInfoWithStorage[127.0.0.1:36116,DS-89e16784-9ea8-4631-b13b-66e71e5204a2,DISK], DatanodeInfoWithStorage[127.0.0.1:35860,DS-a19b53b2-a8ba-4018-b537-fa5d2a7ed4aa,DISK], DatanodeInfoWithStorage[127.0.0.1:41319,DS-4959a49c-2b39-4d2d-9db0-e4fca372d8be,DISK], DatanodeInfoWithStorage[127.0.0.1:36473,DS-711416ba-2c08-42b6-8ec9-ad8e36973e8a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-34415564-172.17.0.20-1595311669370:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36243,DS-5dac1d4d-a295-42e1-a5c2-37284df95267,DISK], DatanodeInfoWithStorage[127.0.0.1:40744,DS-fe99595a-2f58-4bd7-94ff-ea77628d87a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44944,DS-047d5168-b522-4724-865a-85f798c79e9b,DISK], DatanodeInfoWithStorage[127.0.0.1:34960,DS-773664e5-2af8-4434-bffa-2764aedb9764,DISK], DatanodeInfoWithStorage[127.0.0.1:34925,DS-d9b1372a-5ff5-40e3-b33d-3483b28eeb1e,DISK], DatanodeInfoWithStorage[127.0.0.1:40252,DS-8cf2c7d5-efc7-4a59-9f4b-8e30ec20c74c,DISK], DatanodeInfoWithStorage[127.0.0.1:37029,DS-d2bd3947-212c-4773-925e-eafcb7940921,DISK], DatanodeInfoWithStorage[127.0.0.1:38286,DS-e6b7fb84-703e-4d12-bf31-1a7a2c73f46b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-34415564-172.17.0.20-1595311669370:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36243,DS-5dac1d4d-a295-42e1-a5c2-37284df95267,DISK], DatanodeInfoWithStorage[127.0.0.1:40744,DS-fe99595a-2f58-4bd7-94ff-ea77628d87a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44944,DS-047d5168-b522-4724-865a-85f798c79e9b,DISK], DatanodeInfoWithStorage[127.0.0.1:34960,DS-773664e5-2af8-4434-bffa-2764aedb9764,DISK], DatanodeInfoWithStorage[127.0.0.1:34925,DS-d9b1372a-5ff5-40e3-b33d-3483b28eeb1e,DISK], DatanodeInfoWithStorage[127.0.0.1:40252,DS-8cf2c7d5-efc7-4a59-9f4b-8e30ec20c74c,DISK], DatanodeInfoWithStorage[127.0.0.1:37029,DS-d2bd3947-212c-4773-925e-eafcb7940921,DISK], DatanodeInfoWithStorage[127.0.0.1:38286,DS-e6b7fb84-703e-4d12-bf31-1a7a2c73f46b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-741622804-172.17.0.20-1595311742243:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35245,DS-1e8586cd-dead-4f1a-817e-e4fd7f779bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:45607,DS-c0853589-addc-4b4a-bbd2-9b1a0f2361d9,DISK], DatanodeInfoWithStorage[127.0.0.1:32991,DS-67f5b9b7-e575-40e9-a884-aac4ac68a378,DISK], DatanodeInfoWithStorage[127.0.0.1:34373,DS-a976ac69-d13d-460c-9004-a44ab67e7e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:38119,DS-bebc11f8-4778-4cee-b387-beeba1444164,DISK], DatanodeInfoWithStorage[127.0.0.1:34314,DS-a1ffff54-e9fe-46fa-b630-e11fe64e8cff,DISK], DatanodeInfoWithStorage[127.0.0.1:44088,DS-3a2b977a-a2c6-4b5b-9e21-1e71757c9a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:44003,DS-454a245d-2c1d-4a32-bc6d-71b8e1bfc6c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-741622804-172.17.0.20-1595311742243:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35245,DS-1e8586cd-dead-4f1a-817e-e4fd7f779bd6,DISK], DatanodeInfoWithStorage[127.0.0.1:45607,DS-c0853589-addc-4b4a-bbd2-9b1a0f2361d9,DISK], DatanodeInfoWithStorage[127.0.0.1:32991,DS-67f5b9b7-e575-40e9-a884-aac4ac68a378,DISK], DatanodeInfoWithStorage[127.0.0.1:34373,DS-a976ac69-d13d-460c-9004-a44ab67e7e1d,DISK], DatanodeInfoWithStorage[127.0.0.1:38119,DS-bebc11f8-4778-4cee-b387-beeba1444164,DISK], DatanodeInfoWithStorage[127.0.0.1:34314,DS-a1ffff54-e9fe-46fa-b630-e11fe64e8cff,DISK], DatanodeInfoWithStorage[127.0.0.1:44088,DS-3a2b977a-a2c6-4b5b-9e21-1e71757c9a0b,DISK], DatanodeInfoWithStorage[127.0.0.1:44003,DS-454a245d-2c1d-4a32-bc6d-71b8e1bfc6c6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-788888111-172.17.0.20-1595311922792:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38735,DS-65bdaa83-dfe5-47cd-8236-268a05e51dec,DISK], DatanodeInfoWithStorage[127.0.0.1:36319,DS-dba29a49-174c-46af-9279-918b28f35a97,DISK], DatanodeInfoWithStorage[127.0.0.1:41450,DS-c28676f8-f8d7-43a9-9c0f-c8a41d771e50,DISK], DatanodeInfoWithStorage[127.0.0.1:44653,DS-1415a148-c426-4147-8a36-9d06ab0c264b,DISK], DatanodeInfoWithStorage[127.0.0.1:46716,DS-f698d791-cde6-4277-967e-391d55202875,DISK], DatanodeInfoWithStorage[127.0.0.1:37326,DS-c43f6087-a51b-4f15-9caf-af00d49b50a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42710,DS-610ffc37-c333-463c-9f64-98d7669a0d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:42277,DS-2b56b153-5055-42b6-b080-33b37582fb7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-788888111-172.17.0.20-1595311922792:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38735,DS-65bdaa83-dfe5-47cd-8236-268a05e51dec,DISK], DatanodeInfoWithStorage[127.0.0.1:36319,DS-dba29a49-174c-46af-9279-918b28f35a97,DISK], DatanodeInfoWithStorage[127.0.0.1:41450,DS-c28676f8-f8d7-43a9-9c0f-c8a41d771e50,DISK], DatanodeInfoWithStorage[127.0.0.1:44653,DS-1415a148-c426-4147-8a36-9d06ab0c264b,DISK], DatanodeInfoWithStorage[127.0.0.1:46716,DS-f698d791-cde6-4277-967e-391d55202875,DISK], DatanodeInfoWithStorage[127.0.0.1:37326,DS-c43f6087-a51b-4f15-9caf-af00d49b50a5,DISK], DatanodeInfoWithStorage[127.0.0.1:42710,DS-610ffc37-c333-463c-9f64-98d7669a0d1b,DISK], DatanodeInfoWithStorage[127.0.0.1:42277,DS-2b56b153-5055-42b6-b080-33b37582fb7f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-558145702-172.17.0.20-1595312058443:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39614,DS-5929307c-19e3-433c-8ce9-abe1a82cfe55,DISK], DatanodeInfoWithStorage[127.0.0.1:39987,DS-36352521-9ece-4ffa-91a3-705a31dde05f,DISK], DatanodeInfoWithStorage[127.0.0.1:35038,DS-fb2cee13-93a9-4465-b9d6-e302782dc71a,DISK], DatanodeInfoWithStorage[127.0.0.1:42061,DS-b68aac80-79b4-44f0-9d9d-106002805251,DISK], DatanodeInfoWithStorage[127.0.0.1:46143,DS-2861a5af-2f34-4f35-853c-b7e7d15c8211,DISK], DatanodeInfoWithStorage[127.0.0.1:39590,DS-9648a61f-81f1-46a8-bb16-855aafe6be38,DISK], DatanodeInfoWithStorage[127.0.0.1:43014,DS-b4edb75e-acfa-439e-9bad-cf6406faec45,DISK], DatanodeInfoWithStorage[127.0.0.1:42399,DS-2419fa6d-dae0-4b28-b378-19313187e8b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-558145702-172.17.0.20-1595312058443:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39614,DS-5929307c-19e3-433c-8ce9-abe1a82cfe55,DISK], DatanodeInfoWithStorage[127.0.0.1:39987,DS-36352521-9ece-4ffa-91a3-705a31dde05f,DISK], DatanodeInfoWithStorage[127.0.0.1:35038,DS-fb2cee13-93a9-4465-b9d6-e302782dc71a,DISK], DatanodeInfoWithStorage[127.0.0.1:42061,DS-b68aac80-79b4-44f0-9d9d-106002805251,DISK], DatanodeInfoWithStorage[127.0.0.1:46143,DS-2861a5af-2f34-4f35-853c-b7e7d15c8211,DISK], DatanodeInfoWithStorage[127.0.0.1:39590,DS-9648a61f-81f1-46a8-bb16-855aafe6be38,DISK], DatanodeInfoWithStorage[127.0.0.1:43014,DS-b4edb75e-acfa-439e-9bad-cf6406faec45,DISK], DatanodeInfoWithStorage[127.0.0.1:42399,DS-2419fa6d-dae0-4b28-b378-19313187e8b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2124225997-172.17.0.20-1595312448881:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40025,DS-6d68e9ce-73fe-4f2c-86c0-466e9e728df5,DISK], DatanodeInfoWithStorage[127.0.0.1:46198,DS-63b552de-6ec9-45b1-878d-0dac2485bedd,DISK], DatanodeInfoWithStorage[127.0.0.1:37163,DS-ad329351-d5fc-422d-8ea9-af4ec65af381,DISK], DatanodeInfoWithStorage[127.0.0.1:43731,DS-5d7ec1c4-4ed1-4bb3-9cd5-4f28769eb2e5,DISK], DatanodeInfoWithStorage[127.0.0.1:37376,DS-bd4504ad-dfed-4464-a8cc-c13d720dd542,DISK], DatanodeInfoWithStorage[127.0.0.1:41642,DS-dde02e53-dbf6-4e95-8239-f0e60b79f97e,DISK], DatanodeInfoWithStorage[127.0.0.1:40549,DS-e9d2d687-e076-4d2f-9b19-45a81eb713c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44367,DS-c08b14f8-7081-4032-b9b8-73f281d7adc5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2124225997-172.17.0.20-1595312448881:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40025,DS-6d68e9ce-73fe-4f2c-86c0-466e9e728df5,DISK], DatanodeInfoWithStorage[127.0.0.1:46198,DS-63b552de-6ec9-45b1-878d-0dac2485bedd,DISK], DatanodeInfoWithStorage[127.0.0.1:37163,DS-ad329351-d5fc-422d-8ea9-af4ec65af381,DISK], DatanodeInfoWithStorage[127.0.0.1:43731,DS-5d7ec1c4-4ed1-4bb3-9cd5-4f28769eb2e5,DISK], DatanodeInfoWithStorage[127.0.0.1:37376,DS-bd4504ad-dfed-4464-a8cc-c13d720dd542,DISK], DatanodeInfoWithStorage[127.0.0.1:41642,DS-dde02e53-dbf6-4e95-8239-f0e60b79f97e,DISK], DatanodeInfoWithStorage[127.0.0.1:40549,DS-e9d2d687-e076-4d2f-9b19-45a81eb713c5,DISK], DatanodeInfoWithStorage[127.0.0.1:44367,DS-c08b14f8-7081-4032-b9b8-73f281d7adc5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1939091262-172.17.0.20-1595312680472:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41047,DS-5e324421-1a77-4a2d-92c2-1056b7ac353a,DISK], DatanodeInfoWithStorage[127.0.0.1:43982,DS-d8c66ee2-d147-4635-b442-552d5629ca5d,DISK], DatanodeInfoWithStorage[127.0.0.1:40255,DS-aaa10f12-0fd1-4edc-ad06-7d0f89682dbe,DISK], DatanodeInfoWithStorage[127.0.0.1:42177,DS-cc2aadd5-28a5-47b1-8722-49e9ab66c122,DISK], DatanodeInfoWithStorage[127.0.0.1:45521,DS-e53ab149-89c1-4377-b3a6-2090a56552f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40357,DS-13c0c6a6-ad0c-45fd-a39b-593ba4cbd25e,DISK], DatanodeInfoWithStorage[127.0.0.1:46770,DS-c1405f65-a03d-4e10-a975-892d06dd1409,DISK], DatanodeInfoWithStorage[127.0.0.1:33160,DS-8cc1230f-453a-4cc1-865b-c99861e47fb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1939091262-172.17.0.20-1595312680472:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41047,DS-5e324421-1a77-4a2d-92c2-1056b7ac353a,DISK], DatanodeInfoWithStorage[127.0.0.1:43982,DS-d8c66ee2-d147-4635-b442-552d5629ca5d,DISK], DatanodeInfoWithStorage[127.0.0.1:40255,DS-aaa10f12-0fd1-4edc-ad06-7d0f89682dbe,DISK], DatanodeInfoWithStorage[127.0.0.1:42177,DS-cc2aadd5-28a5-47b1-8722-49e9ab66c122,DISK], DatanodeInfoWithStorage[127.0.0.1:45521,DS-e53ab149-89c1-4377-b3a6-2090a56552f1,DISK], DatanodeInfoWithStorage[127.0.0.1:40357,DS-13c0c6a6-ad0c-45fd-a39b-593ba4cbd25e,DISK], DatanodeInfoWithStorage[127.0.0.1:46770,DS-c1405f65-a03d-4e10-a975-892d06dd1409,DISK], DatanodeInfoWithStorage[127.0.0.1:33160,DS-8cc1230f-453a-4cc1-865b-c99861e47fb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2142751413-172.17.0.20-1595312956095:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43140,DS-53d52ebc-9e6e-43bc-af82-efdba7506a42,DISK], DatanodeInfoWithStorage[127.0.0.1:45097,DS-369e41ee-0a0d-45c5-a094-39aecbcb805d,DISK], DatanodeInfoWithStorage[127.0.0.1:44451,DS-a23a084b-e492-461c-aa27-2ad42988fe29,DISK], DatanodeInfoWithStorage[127.0.0.1:33642,DS-4f628f83-73dc-4cac-ac78-09d3e56b4765,DISK], DatanodeInfoWithStorage[127.0.0.1:46845,DS-dee1ef38-3828-4913-8744-e48706db13af,DISK], DatanodeInfoWithStorage[127.0.0.1:39260,DS-f819c830-8cb7-4c7e-a88e-b632986fe2d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38070,DS-e6e19fd3-0523-491c-903e-75fb62d54083,DISK], DatanodeInfoWithStorage[127.0.0.1:34640,DS-c8585a11-eeb4-4f85-a018-355ccdc87a91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2142751413-172.17.0.20-1595312956095:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43140,DS-53d52ebc-9e6e-43bc-af82-efdba7506a42,DISK], DatanodeInfoWithStorage[127.0.0.1:45097,DS-369e41ee-0a0d-45c5-a094-39aecbcb805d,DISK], DatanodeInfoWithStorage[127.0.0.1:44451,DS-a23a084b-e492-461c-aa27-2ad42988fe29,DISK], DatanodeInfoWithStorage[127.0.0.1:33642,DS-4f628f83-73dc-4cac-ac78-09d3e56b4765,DISK], DatanodeInfoWithStorage[127.0.0.1:46845,DS-dee1ef38-3828-4913-8744-e48706db13af,DISK], DatanodeInfoWithStorage[127.0.0.1:39260,DS-f819c830-8cb7-4c7e-a88e-b632986fe2d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38070,DS-e6e19fd3-0523-491c-903e-75fb62d54083,DISK], DatanodeInfoWithStorage[127.0.0.1:34640,DS-c8585a11-eeb4-4f85-a018-355ccdc87a91,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery2
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2144764687-172.17.0.20-1595313523828:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39274,DS-6fc746ec-13ed-4a47-88d3-02cdf602efb7,DISK], DatanodeInfoWithStorage[127.0.0.1:37936,DS-e751c888-2751-47f7-af37-8a8ad0898013,DISK], DatanodeInfoWithStorage[127.0.0.1:39871,DS-47259d2f-a063-466d-99f5-6f1d33708265,DISK], DatanodeInfoWithStorage[127.0.0.1:40184,DS-05925a58-1361-4270-aeff-7891496e4c66,DISK], DatanodeInfoWithStorage[127.0.0.1:41186,DS-c157d869-dd87-4b5e-b6ec-7238e8af9b16,DISK], DatanodeInfoWithStorage[127.0.0.1:38319,DS-074fd715-0c06-4103-b02f-8953846edee7,DISK], DatanodeInfoWithStorage[127.0.0.1:44250,DS-c3930b45-4a35-4d40-96fe-d901a37f41e7,DISK], DatanodeInfoWithStorage[127.0.0.1:41353,DS-a2de8ad1-5dff-4406-9a18-4c6f0d2cec20,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2144764687-172.17.0.20-1595313523828:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39274,DS-6fc746ec-13ed-4a47-88d3-02cdf602efb7,DISK], DatanodeInfoWithStorage[127.0.0.1:37936,DS-e751c888-2751-47f7-af37-8a8ad0898013,DISK], DatanodeInfoWithStorage[127.0.0.1:39871,DS-47259d2f-a063-466d-99f5-6f1d33708265,DISK], DatanodeInfoWithStorage[127.0.0.1:40184,DS-05925a58-1361-4270-aeff-7891496e4c66,DISK], DatanodeInfoWithStorage[127.0.0.1:41186,DS-c157d869-dd87-4b5e-b6ec-7238e8af9b16,DISK], DatanodeInfoWithStorage[127.0.0.1:38319,DS-074fd715-0c06-4103-b02f-8953846edee7,DISK], DatanodeInfoWithStorage[127.0.0.1:44250,DS-c3930b45-4a35-4d40-96fe-d901a37f41e7,DISK], DatanodeInfoWithStorage[127.0.0.1:41353,DS-a2de8ad1-5dff-4406-9a18-4c6f0d2cec20,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery2(TestFileChecksum.java:322)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5347
