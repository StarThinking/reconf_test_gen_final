reconf_parameter: dfs.client.read.shortcircuit.skip.checksum
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.skip.checksum
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1552537362-172.17.0.13-1591747141621:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45166,DS-54fe9d31-f5e5-488c-a6d0-55174cf32599,DISK], DatanodeInfoWithStorage[127.0.0.1:33489,DS-d37188aa-7ee9-4e4c-8170-3156de5a9b95,DISK], DatanodeInfoWithStorage[127.0.0.1:45545,DS-7827abe5-1771-4f69-a6f5-0cf9717b4099,DISK], DatanodeInfoWithStorage[127.0.0.1:43657,DS-b6b18754-d29a-45d3-b3f5-ff841e6d3713,DISK], DatanodeInfoWithStorage[127.0.0.1:32904,DS-edefbd31-3a0e-4c64-8889-11c24914feb5,DISK], DatanodeInfoWithStorage[127.0.0.1:45119,DS-67f35cba-0bb9-4b6f-bfc4-146042317a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:36391,DS-da984ce1-5914-4feb-a002-b7b03fed7dd9,DISK], DatanodeInfoWithStorage[127.0.0.1:38492,DS-c2b3b6ba-29b9-4d9e-b719-c8514ec808c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1552537362-172.17.0.13-1591747141621:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45166,DS-54fe9d31-f5e5-488c-a6d0-55174cf32599,DISK], DatanodeInfoWithStorage[127.0.0.1:33489,DS-d37188aa-7ee9-4e4c-8170-3156de5a9b95,DISK], DatanodeInfoWithStorage[127.0.0.1:45545,DS-7827abe5-1771-4f69-a6f5-0cf9717b4099,DISK], DatanodeInfoWithStorage[127.0.0.1:43657,DS-b6b18754-d29a-45d3-b3f5-ff841e6d3713,DISK], DatanodeInfoWithStorage[127.0.0.1:32904,DS-edefbd31-3a0e-4c64-8889-11c24914feb5,DISK], DatanodeInfoWithStorage[127.0.0.1:45119,DS-67f35cba-0bb9-4b6f-bfc4-146042317a4a,DISK], DatanodeInfoWithStorage[127.0.0.1:36391,DS-da984ce1-5914-4feb-a002-b7b03fed7dd9,DISK], DatanodeInfoWithStorage[127.0.0.1:38492,DS-c2b3b6ba-29b9-4d9e-b719-c8514ec808c3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.skip.checksum
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1118313580-172.17.0.13-1591747442809:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44318,DS-46c75a81-09b1-4d2a-8e24-01679e062813,DISK], DatanodeInfoWithStorage[127.0.0.1:35328,DS-091c00ba-57e0-4ff9-8639-af6bd4b1f03f,DISK], DatanodeInfoWithStorage[127.0.0.1:37101,DS-c1deb9b0-dff0-4133-ab73-7c75201cdc00,DISK], DatanodeInfoWithStorage[127.0.0.1:33952,DS-f8499099-1333-4737-9825-fb61a27c0175,DISK], DatanodeInfoWithStorage[127.0.0.1:45679,DS-ca2c162e-e594-4e34-a30c-3b8ae4e53415,DISK], DatanodeInfoWithStorage[127.0.0.1:43403,DS-23fd02ab-4b58-4a99-9806-523d436af2fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34955,DS-e78d2b6c-e44c-485d-ac6c-7de2f060d414,DISK], DatanodeInfoWithStorage[127.0.0.1:33815,DS-1902c882-b5a7-4af7-90ae-d93ad923e66a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1118313580-172.17.0.13-1591747442809:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44318,DS-46c75a81-09b1-4d2a-8e24-01679e062813,DISK], DatanodeInfoWithStorage[127.0.0.1:35328,DS-091c00ba-57e0-4ff9-8639-af6bd4b1f03f,DISK], DatanodeInfoWithStorage[127.0.0.1:37101,DS-c1deb9b0-dff0-4133-ab73-7c75201cdc00,DISK], DatanodeInfoWithStorage[127.0.0.1:33952,DS-f8499099-1333-4737-9825-fb61a27c0175,DISK], DatanodeInfoWithStorage[127.0.0.1:45679,DS-ca2c162e-e594-4e34-a30c-3b8ae4e53415,DISK], DatanodeInfoWithStorage[127.0.0.1:43403,DS-23fd02ab-4b58-4a99-9806-523d436af2fc,DISK], DatanodeInfoWithStorage[127.0.0.1:34955,DS-e78d2b6c-e44c-485d-ac6c-7de2f060d414,DISK], DatanodeInfoWithStorage[127.0.0.1:33815,DS-1902c882-b5a7-4af7-90ae-d93ad923e66a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.skip.checksum
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1594116937-172.17.0.13-1591748145052:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40857,DS-b29186fb-5ad1-435c-967c-ca0fb5c1e839,DISK], DatanodeInfoWithStorage[127.0.0.1:35614,DS-ffff1085-6619-48d4-a54e-c5e82d19ec80,DISK], DatanodeInfoWithStorage[127.0.0.1:39500,DS-d6820a43-db3e-4a10-81e3-f5bf8ab2c970,DISK], DatanodeInfoWithStorage[127.0.0.1:37275,DS-88d10dc7-e243-412e-96c7-2546e1d94761,DISK], DatanodeInfoWithStorage[127.0.0.1:36900,DS-e4fa8df5-ebba-4faf-ba96-b864214e0c63,DISK], DatanodeInfoWithStorage[127.0.0.1:41350,DS-09543373-46a1-480c-af35-33d23f3ebba2,DISK], DatanodeInfoWithStorage[127.0.0.1:43183,DS-26ccc06c-78f5-4d0f-9632-a4763801ad16,DISK], DatanodeInfoWithStorage[127.0.0.1:36019,DS-3dd477e4-cc64-460d-afe9-900d714f9c1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1594116937-172.17.0.13-1591748145052:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40857,DS-b29186fb-5ad1-435c-967c-ca0fb5c1e839,DISK], DatanodeInfoWithStorage[127.0.0.1:35614,DS-ffff1085-6619-48d4-a54e-c5e82d19ec80,DISK], DatanodeInfoWithStorage[127.0.0.1:39500,DS-d6820a43-db3e-4a10-81e3-f5bf8ab2c970,DISK], DatanodeInfoWithStorage[127.0.0.1:37275,DS-88d10dc7-e243-412e-96c7-2546e1d94761,DISK], DatanodeInfoWithStorage[127.0.0.1:36900,DS-e4fa8df5-ebba-4faf-ba96-b864214e0c63,DISK], DatanodeInfoWithStorage[127.0.0.1:41350,DS-09543373-46a1-480c-af35-33d23f3ebba2,DISK], DatanodeInfoWithStorage[127.0.0.1:43183,DS-26ccc06c-78f5-4d0f-9632-a4763801ad16,DISK], DatanodeInfoWithStorage[127.0.0.1:36019,DS-3dd477e4-cc64-460d-afe9-900d714f9c1d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.skip.checksum
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1612856275-172.17.0.13-1591748183284:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36920,DS-4080c950-3c6c-43e3-8e92-5998ded2e26e,DISK], DatanodeInfoWithStorage[127.0.0.1:39356,DS-b05f7d69-b9c3-4af7-b02c-94d6e2d2885e,DISK], DatanodeInfoWithStorage[127.0.0.1:44543,DS-a5a1f6bf-fda5-49c6-b95f-324cb8bc0210,DISK], DatanodeInfoWithStorage[127.0.0.1:35123,DS-bc9be239-2683-4f81-b291-9cc3dbe53dda,DISK], DatanodeInfoWithStorage[127.0.0.1:34385,DS-000281d9-877d-497e-87df-7636b4db097e,DISK], DatanodeInfoWithStorage[127.0.0.1:40039,DS-794e26c7-43b3-4c64-8251-586213d14f24,DISK], DatanodeInfoWithStorage[127.0.0.1:36185,DS-dc8854ea-bd31-4ec0-8054-1f170257c853,DISK], DatanodeInfoWithStorage[127.0.0.1:45762,DS-9d2dc2a2-08e7-4d63-a815-a81d1fe115cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1612856275-172.17.0.13-1591748183284:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36920,DS-4080c950-3c6c-43e3-8e92-5998ded2e26e,DISK], DatanodeInfoWithStorage[127.0.0.1:39356,DS-b05f7d69-b9c3-4af7-b02c-94d6e2d2885e,DISK], DatanodeInfoWithStorage[127.0.0.1:44543,DS-a5a1f6bf-fda5-49c6-b95f-324cb8bc0210,DISK], DatanodeInfoWithStorage[127.0.0.1:35123,DS-bc9be239-2683-4f81-b291-9cc3dbe53dda,DISK], DatanodeInfoWithStorage[127.0.0.1:34385,DS-000281d9-877d-497e-87df-7636b4db097e,DISK], DatanodeInfoWithStorage[127.0.0.1:40039,DS-794e26c7-43b3-4c64-8251-586213d14f24,DISK], DatanodeInfoWithStorage[127.0.0.1:36185,DS-dc8854ea-bd31-4ec0-8054-1f170257c853,DISK], DatanodeInfoWithStorage[127.0.0.1:45762,DS-9d2dc2a2-08e7-4d63-a815-a81d1fe115cd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.skip.checksum
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1457883669-172.17.0.13-1591748243781:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44187,DS-1b0358f7-e1e9-463a-b105-cde6a907996e,DISK], DatanodeInfoWithStorage[127.0.0.1:42124,DS-965ea95b-e1b7-4d1a-b242-72c406ef95e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45736,DS-bd2a2194-0b67-45ac-a3fb-41713bab4331,DISK], DatanodeInfoWithStorage[127.0.0.1:34131,DS-ee0eeca6-b393-42b0-a4b6-8af737d28cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:40351,DS-d27f41ee-0421-4e9d-9454-305455386e54,DISK], DatanodeInfoWithStorage[127.0.0.1:43230,DS-af768375-e2d1-4ff0-9dfc-70b6166061f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41942,DS-a935d618-6140-46c0-b5e7-882eb30828c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33880,DS-27b403f2-7854-45f0-9516-876dd8138940,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1457883669-172.17.0.13-1591748243781:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44187,DS-1b0358f7-e1e9-463a-b105-cde6a907996e,DISK], DatanodeInfoWithStorage[127.0.0.1:42124,DS-965ea95b-e1b7-4d1a-b242-72c406ef95e3,DISK], DatanodeInfoWithStorage[127.0.0.1:45736,DS-bd2a2194-0b67-45ac-a3fb-41713bab4331,DISK], DatanodeInfoWithStorage[127.0.0.1:34131,DS-ee0eeca6-b393-42b0-a4b6-8af737d28cb9,DISK], DatanodeInfoWithStorage[127.0.0.1:40351,DS-d27f41ee-0421-4e9d-9454-305455386e54,DISK], DatanodeInfoWithStorage[127.0.0.1:43230,DS-af768375-e2d1-4ff0-9dfc-70b6166061f9,DISK], DatanodeInfoWithStorage[127.0.0.1:41942,DS-a935d618-6140-46c0-b5e7-882eb30828c3,DISK], DatanodeInfoWithStorage[127.0.0.1:33880,DS-27b403f2-7854-45f0-9516-876dd8138940,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.skip.checksum
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1880692878-172.17.0.13-1591748450239:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45648,DS-a5bc943c-2e4a-49ff-a1d6-bb671657267e,DISK], DatanodeInfoWithStorage[127.0.0.1:33711,DS-f2798f5a-23df-42c8-a413-213d3454e4fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38912,DS-beba3792-a6fb-46ba-a106-5e763552f283,DISK], DatanodeInfoWithStorage[127.0.0.1:43746,DS-bbc4bb11-abd7-4444-b7d1-065a93d59e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:44899,DS-1a5d18d9-2dc9-4e94-b47c-16116d3b6afc,DISK], DatanodeInfoWithStorage[127.0.0.1:45787,DS-c3fa4276-3b0a-484f-8add-53c108f9ba7f,DISK], DatanodeInfoWithStorage[127.0.0.1:34772,DS-d3054a4c-7083-4727-89ae-5db68e66a554,DISK], DatanodeInfoWithStorage[127.0.0.1:46385,DS-8f3cdc56-bb01-43fb-985c-caf9d9ac7e2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1880692878-172.17.0.13-1591748450239:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45648,DS-a5bc943c-2e4a-49ff-a1d6-bb671657267e,DISK], DatanodeInfoWithStorage[127.0.0.1:33711,DS-f2798f5a-23df-42c8-a413-213d3454e4fe,DISK], DatanodeInfoWithStorage[127.0.0.1:38912,DS-beba3792-a6fb-46ba-a106-5e763552f283,DISK], DatanodeInfoWithStorage[127.0.0.1:43746,DS-bbc4bb11-abd7-4444-b7d1-065a93d59e5f,DISK], DatanodeInfoWithStorage[127.0.0.1:44899,DS-1a5d18d9-2dc9-4e94-b47c-16116d3b6afc,DISK], DatanodeInfoWithStorage[127.0.0.1:45787,DS-c3fa4276-3b0a-484f-8add-53c108f9ba7f,DISK], DatanodeInfoWithStorage[127.0.0.1:34772,DS-d3054a4c-7083-4727-89ae-5db68e66a554,DISK], DatanodeInfoWithStorage[127.0.0.1:46385,DS-8f3cdc56-bb01-43fb-985c-caf9d9ac7e2b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.skip.checksum
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-706422658-172.17.0.13-1591748551854:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39376,DS-1d1e70a6-7387-44a9-8027-adae87360422,DISK], DatanodeInfoWithStorage[127.0.0.1:33764,DS-22778545-521d-487e-aa1a-71eef967313b,DISK], DatanodeInfoWithStorage[127.0.0.1:35715,DS-d186ccaa-b912-47f0-8ccf-0a3f53398f0d,DISK], DatanodeInfoWithStorage[127.0.0.1:36267,DS-145e0185-be4e-4021-8edd-a37756f3fc66,DISK], DatanodeInfoWithStorage[127.0.0.1:43763,DS-40c9ecb8-fa52-4200-ad62-2c396893e327,DISK], DatanodeInfoWithStorage[127.0.0.1:43155,DS-293daff8-92bf-45c7-9dc8-d2f72904c142,DISK], DatanodeInfoWithStorage[127.0.0.1:41274,DS-5cea5e55-c68a-4245-8c0a-6c7828a2b68c,DISK], DatanodeInfoWithStorage[127.0.0.1:40317,DS-07c72848-ff22-49eb-9737-e289be7110b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-706422658-172.17.0.13-1591748551854:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39376,DS-1d1e70a6-7387-44a9-8027-adae87360422,DISK], DatanodeInfoWithStorage[127.0.0.1:33764,DS-22778545-521d-487e-aa1a-71eef967313b,DISK], DatanodeInfoWithStorage[127.0.0.1:35715,DS-d186ccaa-b912-47f0-8ccf-0a3f53398f0d,DISK], DatanodeInfoWithStorage[127.0.0.1:36267,DS-145e0185-be4e-4021-8edd-a37756f3fc66,DISK], DatanodeInfoWithStorage[127.0.0.1:43763,DS-40c9ecb8-fa52-4200-ad62-2c396893e327,DISK], DatanodeInfoWithStorage[127.0.0.1:43155,DS-293daff8-92bf-45c7-9dc8-d2f72904c142,DISK], DatanodeInfoWithStorage[127.0.0.1:41274,DS-5cea5e55-c68a-4245-8c0a-6c7828a2b68c,DISK], DatanodeInfoWithStorage[127.0.0.1:40317,DS-07c72848-ff22-49eb-9737-e289be7110b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.skip.checksum
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-465930034-172.17.0.13-1591748767060:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35035,DS-a16b83f8-7729-4a8e-bdc9-901f651f13c2,DISK], DatanodeInfoWithStorage[127.0.0.1:36648,DS-0c1e3405-f4b5-4a90-98de-1fb505c6f5c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34041,DS-c7f1f687-c428-4bf8-91fe-86cfde09c886,DISK], DatanodeInfoWithStorage[127.0.0.1:39637,DS-f18fd790-8f5a-4a1c-aa16-cb7cbc727258,DISK], DatanodeInfoWithStorage[127.0.0.1:36583,DS-80c6c17d-bf8a-47e3-a212-678baca286f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36431,DS-3c755848-60ee-4536-82f7-cf8ce6b94644,DISK], DatanodeInfoWithStorage[127.0.0.1:43829,DS-bbfa1f2a-fd74-499a-8f57-4c62ce96a7c2,DISK], DatanodeInfoWithStorage[127.0.0.1:41727,DS-1706cf24-e4ef-4e8c-b83f-78ce5a536e8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-465930034-172.17.0.13-1591748767060:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35035,DS-a16b83f8-7729-4a8e-bdc9-901f651f13c2,DISK], DatanodeInfoWithStorage[127.0.0.1:36648,DS-0c1e3405-f4b5-4a90-98de-1fb505c6f5c7,DISK], DatanodeInfoWithStorage[127.0.0.1:34041,DS-c7f1f687-c428-4bf8-91fe-86cfde09c886,DISK], DatanodeInfoWithStorage[127.0.0.1:39637,DS-f18fd790-8f5a-4a1c-aa16-cb7cbc727258,DISK], DatanodeInfoWithStorage[127.0.0.1:36583,DS-80c6c17d-bf8a-47e3-a212-678baca286f9,DISK], DatanodeInfoWithStorage[127.0.0.1:36431,DS-3c755848-60ee-4536-82f7-cf8ce6b94644,DISK], DatanodeInfoWithStorage[127.0.0.1:43829,DS-bbfa1f2a-fd74-499a-8f57-4c62ce96a7c2,DISK], DatanodeInfoWithStorage[127.0.0.1:41727,DS-1706cf24-e4ef-4e8c-b83f-78ce5a536e8d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.skip.checksum
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1172993846-172.17.0.13-1591749368240:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41572,DS-ed6ec1cc-2862-493a-86c8-6dc5dcbec8a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42405,DS-d6c34c2c-933a-49d3-b24c-d4b2e02fedc6,DISK], DatanodeInfoWithStorage[127.0.0.1:46201,DS-1a18b770-fcec-4333-b6c7-7d02ad1ce500,DISK], DatanodeInfoWithStorage[127.0.0.1:37462,DS-dd3246ce-8469-40fe-b256-4eb2750920cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38172,DS-ca3684e9-e498-4633-8f48-45d98cbf8173,DISK], DatanodeInfoWithStorage[127.0.0.1:44237,DS-e65b22c3-c1dd-43ae-8080-def428257397,DISK], DatanodeInfoWithStorage[127.0.0.1:35926,DS-7f723b1e-ec57-45c4-b8e8-629e66c39dda,DISK], DatanodeInfoWithStorage[127.0.0.1:33865,DS-5d629e7c-4576-430a-b164-cf6ff5c13857,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1172993846-172.17.0.13-1591749368240:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41572,DS-ed6ec1cc-2862-493a-86c8-6dc5dcbec8a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42405,DS-d6c34c2c-933a-49d3-b24c-d4b2e02fedc6,DISK], DatanodeInfoWithStorage[127.0.0.1:46201,DS-1a18b770-fcec-4333-b6c7-7d02ad1ce500,DISK], DatanodeInfoWithStorage[127.0.0.1:37462,DS-dd3246ce-8469-40fe-b256-4eb2750920cd,DISK], DatanodeInfoWithStorage[127.0.0.1:38172,DS-ca3684e9-e498-4633-8f48-45d98cbf8173,DISK], DatanodeInfoWithStorage[127.0.0.1:44237,DS-e65b22c3-c1dd-43ae-8080-def428257397,DISK], DatanodeInfoWithStorage[127.0.0.1:35926,DS-7f723b1e-ec57-45c4-b8e8-629e66c39dda,DISK], DatanodeInfoWithStorage[127.0.0.1:33865,DS-5d629e7c-4576-430a-b164-cf6ff5c13857,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.skip.checksum
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-893575684-172.17.0.13-1591749407956:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42758,DS-2f4280ff-fa90-4a78-82f0-9a3752e6864b,DISK], DatanodeInfoWithStorage[127.0.0.1:42682,DS-83eb5ff6-9b5c-4e5c-baab-ce2e0d7cc765,DISK], DatanodeInfoWithStorage[127.0.0.1:35358,DS-15d3b882-2442-4cdf-89f9-954d0449a8e5,DISK], DatanodeInfoWithStorage[127.0.0.1:33907,DS-4cbe4f3f-e7e9-4c82-8729-e225fdf5514c,DISK], DatanodeInfoWithStorage[127.0.0.1:44066,DS-af20fe59-81c2-4bf6-8251-08d6d9b9857f,DISK], DatanodeInfoWithStorage[127.0.0.1:39121,DS-7362b106-d602-438b-9cbe-b20ecf87f4ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38320,DS-8c51c674-6212-4c9c-a2e2-46899ed11529,DISK], DatanodeInfoWithStorage[127.0.0.1:37368,DS-aa6bbe7f-da8f-4295-9506-208ea68d2a37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-893575684-172.17.0.13-1591749407956:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42758,DS-2f4280ff-fa90-4a78-82f0-9a3752e6864b,DISK], DatanodeInfoWithStorage[127.0.0.1:42682,DS-83eb5ff6-9b5c-4e5c-baab-ce2e0d7cc765,DISK], DatanodeInfoWithStorage[127.0.0.1:35358,DS-15d3b882-2442-4cdf-89f9-954d0449a8e5,DISK], DatanodeInfoWithStorage[127.0.0.1:33907,DS-4cbe4f3f-e7e9-4c82-8729-e225fdf5514c,DISK], DatanodeInfoWithStorage[127.0.0.1:44066,DS-af20fe59-81c2-4bf6-8251-08d6d9b9857f,DISK], DatanodeInfoWithStorage[127.0.0.1:39121,DS-7362b106-d602-438b-9cbe-b20ecf87f4ab,DISK], DatanodeInfoWithStorage[127.0.0.1:38320,DS-8c51c674-6212-4c9c-a2e2-46899ed11529,DISK], DatanodeInfoWithStorage[127.0.0.1:37368,DS-aa6bbe7f-da8f-4295-9506-208ea68d2a37,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.skip.checksum
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1017400520-172.17.0.13-1591749654120:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44001,DS-582030b7-c5b8-4e6f-94bf-ab4d9416b5c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46745,DS-e458259b-8508-4aa5-91ce-b57ea06da433,DISK], DatanodeInfoWithStorage[127.0.0.1:39973,DS-cb636cde-6bd8-44a4-8937-eaa9456cbaec,DISK], DatanodeInfoWithStorage[127.0.0.1:36445,DS-88bce1b4-d174-4fec-bf29-9be61695eda8,DISK], DatanodeInfoWithStorage[127.0.0.1:37449,DS-76b8ed9c-4b5c-4b22-8078-5f37c59e967e,DISK], DatanodeInfoWithStorage[127.0.0.1:36925,DS-123bc910-8a26-4767-b14b-c68693cab40b,DISK], DatanodeInfoWithStorage[127.0.0.1:34673,DS-e27bf715-3250-43d8-a363-9ed6505231ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39420,DS-ce4e0ff5-1f01-4dd7-b0ca-429ce237a17e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1017400520-172.17.0.13-1591749654120:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44001,DS-582030b7-c5b8-4e6f-94bf-ab4d9416b5c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46745,DS-e458259b-8508-4aa5-91ce-b57ea06da433,DISK], DatanodeInfoWithStorage[127.0.0.1:39973,DS-cb636cde-6bd8-44a4-8937-eaa9456cbaec,DISK], DatanodeInfoWithStorage[127.0.0.1:36445,DS-88bce1b4-d174-4fec-bf29-9be61695eda8,DISK], DatanodeInfoWithStorage[127.0.0.1:37449,DS-76b8ed9c-4b5c-4b22-8078-5f37c59e967e,DISK], DatanodeInfoWithStorage[127.0.0.1:36925,DS-123bc910-8a26-4767-b14b-c68693cab40b,DISK], DatanodeInfoWithStorage[127.0.0.1:34673,DS-e27bf715-3250-43d8-a363-9ed6505231ec,DISK], DatanodeInfoWithStorage[127.0.0.1:39420,DS-ce4e0ff5-1f01-4dd7-b0ca-429ce237a17e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.skip.checksum
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1527128188-172.17.0.13-1591749722850:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35541,DS-805d2a45-24fd-46fc-a134-f502abfd734a,DISK], DatanodeInfoWithStorage[127.0.0.1:46354,DS-674082d9-4e2a-4af4-924b-b0412280d67a,DISK], DatanodeInfoWithStorage[127.0.0.1:34861,DS-b951d610-f622-4385-88f9-244d07590ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:33412,DS-e03dae3f-5e4f-412b-9b09-0a15a865606c,DISK], DatanodeInfoWithStorage[127.0.0.1:44276,DS-535a5b94-bd03-45ad-8dac-f21861e1ca5b,DISK], DatanodeInfoWithStorage[127.0.0.1:42148,DS-1626c1f2-7f68-47d4-b4bf-81120638eecd,DISK], DatanodeInfoWithStorage[127.0.0.1:42046,DS-14e3cbcd-13f1-42d0-b0b6-16efeb197791,DISK], DatanodeInfoWithStorage[127.0.0.1:34600,DS-37e3b7fc-39d9-4d68-97ed-297c72143fb1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1527128188-172.17.0.13-1591749722850:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35541,DS-805d2a45-24fd-46fc-a134-f502abfd734a,DISK], DatanodeInfoWithStorage[127.0.0.1:46354,DS-674082d9-4e2a-4af4-924b-b0412280d67a,DISK], DatanodeInfoWithStorage[127.0.0.1:34861,DS-b951d610-f622-4385-88f9-244d07590ff1,DISK], DatanodeInfoWithStorage[127.0.0.1:33412,DS-e03dae3f-5e4f-412b-9b09-0a15a865606c,DISK], DatanodeInfoWithStorage[127.0.0.1:44276,DS-535a5b94-bd03-45ad-8dac-f21861e1ca5b,DISK], DatanodeInfoWithStorage[127.0.0.1:42148,DS-1626c1f2-7f68-47d4-b4bf-81120638eecd,DISK], DatanodeInfoWithStorage[127.0.0.1:42046,DS-14e3cbcd-13f1-42d0-b0b6-16efeb197791,DISK], DatanodeInfoWithStorage[127.0.0.1:34600,DS-37e3b7fc-39d9-4d68-97ed-297c72143fb1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.skip.checksum
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-476827315-172.17.0.13-1591751142848:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44412,DS-efe7d091-f817-4d86-9312-cf7a90c47589,DISK], DatanodeInfoWithStorage[127.0.0.1:41122,DS-7d47d363-e679-4c84-b43a-2e795a44cdb8,DISK], DatanodeInfoWithStorage[127.0.0.1:35657,DS-b48d4d1b-00d1-49e7-91f9-b02316a4e354,DISK], DatanodeInfoWithStorage[127.0.0.1:36133,DS-859221be-6afc-4bbe-8809-f7c6917f2dcd,DISK], DatanodeInfoWithStorage[127.0.0.1:38912,DS-34b4cbef-f2ed-49fb-9653-f153bdee05ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45379,DS-29d879e0-e30d-4669-ab5b-cc509fcf64c7,DISK], DatanodeInfoWithStorage[127.0.0.1:41135,DS-c393eb73-dd81-4627-8f3c-737127e078ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33047,DS-f9dd8da3-6fa0-4737-aa36-8d4b9b1e6784,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-476827315-172.17.0.13-1591751142848:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44412,DS-efe7d091-f817-4d86-9312-cf7a90c47589,DISK], DatanodeInfoWithStorage[127.0.0.1:41122,DS-7d47d363-e679-4c84-b43a-2e795a44cdb8,DISK], DatanodeInfoWithStorage[127.0.0.1:35657,DS-b48d4d1b-00d1-49e7-91f9-b02316a4e354,DISK], DatanodeInfoWithStorage[127.0.0.1:36133,DS-859221be-6afc-4bbe-8809-f7c6917f2dcd,DISK], DatanodeInfoWithStorage[127.0.0.1:38912,DS-34b4cbef-f2ed-49fb-9653-f153bdee05ac,DISK], DatanodeInfoWithStorage[127.0.0.1:45379,DS-29d879e0-e30d-4669-ab5b-cc509fcf64c7,DISK], DatanodeInfoWithStorage[127.0.0.1:41135,DS-c393eb73-dd81-4627-8f3c-737127e078ff,DISK], DatanodeInfoWithStorage[127.0.0.1:33047,DS-f9dd8da3-6fa0-4737-aa36-8d4b9b1e6784,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.skip.checksum
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-131907287-172.17.0.13-1591751177268:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36667,DS-f0002963-289a-4d49-b1ab-d0c040c2df15,DISK], DatanodeInfoWithStorage[127.0.0.1:37534,DS-8ef00d33-4103-45b7-8303-fd553623afc7,DISK], DatanodeInfoWithStorage[127.0.0.1:45218,DS-ea6e1fd5-ee5d-4484-89e0-792e7df7d97e,DISK], DatanodeInfoWithStorage[127.0.0.1:32885,DS-0f61e1ec-ecd8-444a-aaff-2b9407887668,DISK], DatanodeInfoWithStorage[127.0.0.1:44483,DS-c11564d0-eb17-4dec-96d9-4b932154e712,DISK], DatanodeInfoWithStorage[127.0.0.1:34369,DS-12f2cb1e-5267-4b76-a3ba-3a940a757fdc,DISK], DatanodeInfoWithStorage[127.0.0.1:37298,DS-1f587601-d1d5-4205-9139-0387577dd86d,DISK], DatanodeInfoWithStorage[127.0.0.1:36526,DS-c669fba5-9d96-49b5-8abb-3387ddecf89e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-131907287-172.17.0.13-1591751177268:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36667,DS-f0002963-289a-4d49-b1ab-d0c040c2df15,DISK], DatanodeInfoWithStorage[127.0.0.1:37534,DS-8ef00d33-4103-45b7-8303-fd553623afc7,DISK], DatanodeInfoWithStorage[127.0.0.1:45218,DS-ea6e1fd5-ee5d-4484-89e0-792e7df7d97e,DISK], DatanodeInfoWithStorage[127.0.0.1:32885,DS-0f61e1ec-ecd8-444a-aaff-2b9407887668,DISK], DatanodeInfoWithStorage[127.0.0.1:44483,DS-c11564d0-eb17-4dec-96d9-4b932154e712,DISK], DatanodeInfoWithStorage[127.0.0.1:34369,DS-12f2cb1e-5267-4b76-a3ba-3a940a757fdc,DISK], DatanodeInfoWithStorage[127.0.0.1:37298,DS-1f587601-d1d5-4205-9139-0387577dd86d,DISK], DatanodeInfoWithStorage[127.0.0.1:36526,DS-c669fba5-9d96-49b5-8abb-3387ddecf89e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.read.shortcircuit.skip.checksum
component: hdfs:NameNode
v1: false
v2: true
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery16
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-967767277-172.17.0.13-1591751868846:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42669,DS-3ea6d381-93ef-466c-ad66-1e2f5ff89d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:45653,DS-2d4d77bc-a279-454f-a763-e194e06f305e,DISK], DatanodeInfoWithStorage[127.0.0.1:38170,DS-21e0cfab-2d2d-42ee-bb9b-a2e247f017de,DISK], DatanodeInfoWithStorage[127.0.0.1:37862,DS-bc446a45-f8b4-478a-a4e3-bd9aec8cd555,DISK], DatanodeInfoWithStorage[127.0.0.1:35384,DS-694c15b1-e153-4cf0-a876-c2a6c40dacac,DISK], DatanodeInfoWithStorage[127.0.0.1:33485,DS-93dbdb84-975e-49de-a37b-584156cbeefc,DISK], DatanodeInfoWithStorage[127.0.0.1:33327,DS-e4ab6d98-cf1b-42a0-884e-1e174ad2ef0c,DISK], DatanodeInfoWithStorage[127.0.0.1:33033,DS-ac1da46c-0a13-4ae7-b075-cce0a18a1c3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-967767277-172.17.0.13-1591751868846:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42669,DS-3ea6d381-93ef-466c-ad66-1e2f5ff89d1f,DISK], DatanodeInfoWithStorage[127.0.0.1:45653,DS-2d4d77bc-a279-454f-a763-e194e06f305e,DISK], DatanodeInfoWithStorage[127.0.0.1:38170,DS-21e0cfab-2d2d-42ee-bb9b-a2e247f017de,DISK], DatanodeInfoWithStorage[127.0.0.1:37862,DS-bc446a45-f8b4-478a-a4e3-bd9aec8cd555,DISK], DatanodeInfoWithStorage[127.0.0.1:35384,DS-694c15b1-e153-4cf0-a876-c2a6c40dacac,DISK], DatanodeInfoWithStorage[127.0.0.1:33485,DS-93dbdb84-975e-49de-a37b-584156cbeefc,DISK], DatanodeInfoWithStorage[127.0.0.1:33327,DS-e4ab6d98-cf1b-42a0-884e-1e174ad2ef0c,DISK], DatanodeInfoWithStorage[127.0.0.1:33033,DS-ac1da46c-0a13-4ae7-b075-cce0a18a1c3f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery16(TestFileChecksum.java:479)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 5 out of 50
result: might be true error
Total execution time in seconds : 5291
