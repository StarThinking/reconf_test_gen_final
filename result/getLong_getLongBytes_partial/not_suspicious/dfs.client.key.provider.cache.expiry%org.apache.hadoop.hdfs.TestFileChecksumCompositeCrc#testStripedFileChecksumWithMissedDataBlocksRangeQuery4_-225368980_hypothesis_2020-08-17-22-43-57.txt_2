reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 864000000
v2: 864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 864000000
v2: 864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-660923607-172.17.0.17-1597704250305:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42379,DS-84ea22c7-3d20-4058-b9d5-d1002eca7c53,DISK], DatanodeInfoWithStorage[127.0.0.1:45916,DS-435f1959-8b97-46bb-b4b9-10c3f6641dec,DISK], DatanodeInfoWithStorage[127.0.0.1:36479,DS-bdfec295-7a92-4225-8c6b-b4fa10f3be16,DISK], DatanodeInfoWithStorage[127.0.0.1:45580,DS-57f11d3f-14c0-4fd5-950c-1dd4836c8ff5,DISK], DatanodeInfoWithStorage[127.0.0.1:45867,DS-c50a080a-85de-42eb-96ce-d83636730414,DISK], DatanodeInfoWithStorage[127.0.0.1:40417,DS-7e6439ee-3149-44f5-b69c-719a7fae789c,DISK], DatanodeInfoWithStorage[127.0.0.1:34311,DS-017f491e-ab33-4edd-ab61-dbb8dc04bc3e,DISK], DatanodeInfoWithStorage[127.0.0.1:34279,DS-c56c5cec-20ae-490e-a3c7-99bb2cdacfb8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-660923607-172.17.0.17-1597704250305:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42379,DS-84ea22c7-3d20-4058-b9d5-d1002eca7c53,DISK], DatanodeInfoWithStorage[127.0.0.1:45916,DS-435f1959-8b97-46bb-b4b9-10c3f6641dec,DISK], DatanodeInfoWithStorage[127.0.0.1:36479,DS-bdfec295-7a92-4225-8c6b-b4fa10f3be16,DISK], DatanodeInfoWithStorage[127.0.0.1:45580,DS-57f11d3f-14c0-4fd5-950c-1dd4836c8ff5,DISK], DatanodeInfoWithStorage[127.0.0.1:45867,DS-c50a080a-85de-42eb-96ce-d83636730414,DISK], DatanodeInfoWithStorage[127.0.0.1:40417,DS-7e6439ee-3149-44f5-b69c-719a7fae789c,DISK], DatanodeInfoWithStorage[127.0.0.1:34311,DS-017f491e-ab33-4edd-ab61-dbb8dc04bc3e,DISK], DatanodeInfoWithStorage[127.0.0.1:34279,DS-c56c5cec-20ae-490e-a3c7-99bb2cdacfb8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 864000000
v2: 864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2144354637-172.17.0.17-1597704938699:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44088,DS-9ebf7b82-9747-41d6-83af-d240ef8ed945,DISK], DatanodeInfoWithStorage[127.0.0.1:40796,DS-242d193d-b021-4452-a356-44b8d593506b,DISK], DatanodeInfoWithStorage[127.0.0.1:43106,DS-b6ce6564-7c32-4b01-8fab-45c3dd8b4303,DISK], DatanodeInfoWithStorage[127.0.0.1:42299,DS-4f8d903d-43dc-40ce-a02c-a4459afbb449,DISK], DatanodeInfoWithStorage[127.0.0.1:39605,DS-768246ec-fe3b-4200-8df9-5296f2254f6e,DISK], DatanodeInfoWithStorage[127.0.0.1:43703,DS-8435544a-4716-4e74-bc2e-97954ccafbcf,DISK], DatanodeInfoWithStorage[127.0.0.1:42018,DS-b5a0465f-68d6-4129-aefa-721d3db5b693,DISK], DatanodeInfoWithStorage[127.0.0.1:40899,DS-49c55b98-e0d6-4269-8231-284c15b151c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2144354637-172.17.0.17-1597704938699:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44088,DS-9ebf7b82-9747-41d6-83af-d240ef8ed945,DISK], DatanodeInfoWithStorage[127.0.0.1:40796,DS-242d193d-b021-4452-a356-44b8d593506b,DISK], DatanodeInfoWithStorage[127.0.0.1:43106,DS-b6ce6564-7c32-4b01-8fab-45c3dd8b4303,DISK], DatanodeInfoWithStorage[127.0.0.1:42299,DS-4f8d903d-43dc-40ce-a02c-a4459afbb449,DISK], DatanodeInfoWithStorage[127.0.0.1:39605,DS-768246ec-fe3b-4200-8df9-5296f2254f6e,DISK], DatanodeInfoWithStorage[127.0.0.1:43703,DS-8435544a-4716-4e74-bc2e-97954ccafbcf,DISK], DatanodeInfoWithStorage[127.0.0.1:42018,DS-b5a0465f-68d6-4129-aefa-721d3db5b693,DISK], DatanodeInfoWithStorage[127.0.0.1:40899,DS-49c55b98-e0d6-4269-8231-284c15b151c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 864000000
v2: 864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1621332922-172.17.0.17-1597705051933:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43603,DS-0bb7648f-3208-438b-8ab5-a036012a559c,DISK], DatanodeInfoWithStorage[127.0.0.1:44060,DS-9dbb0574-69a3-4fec-9cb9-e91b0338dc0c,DISK], DatanodeInfoWithStorage[127.0.0.1:40047,DS-29009221-1c7b-46b9-b790-b4376ab746da,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-6208aaa2-e70a-4cf1-9848-22266b8fdcb1,DISK], DatanodeInfoWithStorage[127.0.0.1:38603,DS-9a280ee8-2cdb-42c5-b059-1f1515a01792,DISK], DatanodeInfoWithStorage[127.0.0.1:41824,DS-e5e6ab02-fdd3-4a36-81d8-5b920ea96951,DISK], DatanodeInfoWithStorage[127.0.0.1:34148,DS-ec1fcc76-a5f2-4f00-8174-8de023684484,DISK], DatanodeInfoWithStorage[127.0.0.1:37757,DS-98f6693d-3d2b-4496-b0e7-4e924fcd77e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1621332922-172.17.0.17-1597705051933:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43603,DS-0bb7648f-3208-438b-8ab5-a036012a559c,DISK], DatanodeInfoWithStorage[127.0.0.1:44060,DS-9dbb0574-69a3-4fec-9cb9-e91b0338dc0c,DISK], DatanodeInfoWithStorage[127.0.0.1:40047,DS-29009221-1c7b-46b9-b790-b4376ab746da,DISK], DatanodeInfoWithStorage[127.0.0.1:42233,DS-6208aaa2-e70a-4cf1-9848-22266b8fdcb1,DISK], DatanodeInfoWithStorage[127.0.0.1:38603,DS-9a280ee8-2cdb-42c5-b059-1f1515a01792,DISK], DatanodeInfoWithStorage[127.0.0.1:41824,DS-e5e6ab02-fdd3-4a36-81d8-5b920ea96951,DISK], DatanodeInfoWithStorage[127.0.0.1:34148,DS-ec1fcc76-a5f2-4f00-8174-8de023684484,DISK], DatanodeInfoWithStorage[127.0.0.1:37757,DS-98f6693d-3d2b-4496-b0e7-4e924fcd77e6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 864000000
v2: 864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1571027516-172.17.0.17-1597705434306:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39031,DS-43e7e6d3-25fc-431e-8afd-9568e0d2a8ec,DISK], DatanodeInfoWithStorage[127.0.0.1:43026,DS-4c34696a-610a-4bf4-8c53-5a3de7ee03aa,DISK], DatanodeInfoWithStorage[127.0.0.1:46433,DS-9e9eabd7-b3bc-4054-971b-2c3daca90e62,DISK], DatanodeInfoWithStorage[127.0.0.1:36999,DS-852c4906-11a3-4a1e-98f9-100db2f6a066,DISK], DatanodeInfoWithStorage[127.0.0.1:38988,DS-67d109d3-742d-4043-9c03-6969869e2f89,DISK], DatanodeInfoWithStorage[127.0.0.1:36831,DS-2237f860-ffba-4854-8133-0717b93792c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45783,DS-d60bb947-d355-4567-84dd-759e3ca683f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43911,DS-e6888e28-3da2-4631-8f5a-1b2f477f4e93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1571027516-172.17.0.17-1597705434306:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39031,DS-43e7e6d3-25fc-431e-8afd-9568e0d2a8ec,DISK], DatanodeInfoWithStorage[127.0.0.1:43026,DS-4c34696a-610a-4bf4-8c53-5a3de7ee03aa,DISK], DatanodeInfoWithStorage[127.0.0.1:46433,DS-9e9eabd7-b3bc-4054-971b-2c3daca90e62,DISK], DatanodeInfoWithStorage[127.0.0.1:36999,DS-852c4906-11a3-4a1e-98f9-100db2f6a066,DISK], DatanodeInfoWithStorage[127.0.0.1:38988,DS-67d109d3-742d-4043-9c03-6969869e2f89,DISK], DatanodeInfoWithStorage[127.0.0.1:36831,DS-2237f860-ffba-4854-8133-0717b93792c1,DISK], DatanodeInfoWithStorage[127.0.0.1:45783,DS-d60bb947-d355-4567-84dd-759e3ca683f4,DISK], DatanodeInfoWithStorage[127.0.0.1:43911,DS-e6888e28-3da2-4631-8f5a-1b2f477f4e93,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 864000000
v2: 864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-130327126-172.17.0.17-1597705691487:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35150,DS-ce4307cd-fcc7-41eb-8478-cf1734aeacc2,DISK], DatanodeInfoWithStorage[127.0.0.1:46251,DS-6bd0283c-89c6-40d1-b79f-62ed2c0a138d,DISK], DatanodeInfoWithStorage[127.0.0.1:44531,DS-4722cf90-84c3-46e7-804d-610c065d623b,DISK], DatanodeInfoWithStorage[127.0.0.1:37845,DS-2d511711-9b1c-41cd-a5a5-ef44ac50800c,DISK], DatanodeInfoWithStorage[127.0.0.1:36256,DS-1d6a6fda-b0d2-48d5-a6cd-84e550c4e72c,DISK], DatanodeInfoWithStorage[127.0.0.1:34170,DS-cce0964d-5c95-4d70-8040-5d8fe8097ef3,DISK], DatanodeInfoWithStorage[127.0.0.1:39831,DS-7a533037-8814-4887-a020-a740fd7279c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34691,DS-62a390b7-ce39-4b42-ae70-18ededadcf8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-130327126-172.17.0.17-1597705691487:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35150,DS-ce4307cd-fcc7-41eb-8478-cf1734aeacc2,DISK], DatanodeInfoWithStorage[127.0.0.1:46251,DS-6bd0283c-89c6-40d1-b79f-62ed2c0a138d,DISK], DatanodeInfoWithStorage[127.0.0.1:44531,DS-4722cf90-84c3-46e7-804d-610c065d623b,DISK], DatanodeInfoWithStorage[127.0.0.1:37845,DS-2d511711-9b1c-41cd-a5a5-ef44ac50800c,DISK], DatanodeInfoWithStorage[127.0.0.1:36256,DS-1d6a6fda-b0d2-48d5-a6cd-84e550c4e72c,DISK], DatanodeInfoWithStorage[127.0.0.1:34170,DS-cce0964d-5c95-4d70-8040-5d8fe8097ef3,DISK], DatanodeInfoWithStorage[127.0.0.1:39831,DS-7a533037-8814-4887-a020-a740fd7279c2,DISK], DatanodeInfoWithStorage[127.0.0.1:34691,DS-62a390b7-ce39-4b42-ae70-18ededadcf8b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 864000000
v2: 864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1260751797-172.17.0.17-1597706115932:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41253,DS-9f052fcb-b13b-4184-a9ae-e9eee5436e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:41920,DS-5f22471a-8787-41f2-8e24-c5bb6e7999be,DISK], DatanodeInfoWithStorage[127.0.0.1:35187,DS-b5b21a3d-d6e1-4f8c-be27-fce650dd18b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45829,DS-2d3ca67c-af22-47ce-ac4a-7544ed0034fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46384,DS-e7ae7783-4296-4856-9e53-913c1cbcbfa7,DISK], DatanodeInfoWithStorage[127.0.0.1:40247,DS-e280287c-2ad8-49df-bba2-09550820cdb0,DISK], DatanodeInfoWithStorage[127.0.0.1:46819,DS-beb806d1-8bd2-4763-98fb-1141bf6e8c60,DISK], DatanodeInfoWithStorage[127.0.0.1:43884,DS-07cb934b-e86b-4140-a6db-e5b55bcf1790,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1260751797-172.17.0.17-1597706115932:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41253,DS-9f052fcb-b13b-4184-a9ae-e9eee5436e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:41920,DS-5f22471a-8787-41f2-8e24-c5bb6e7999be,DISK], DatanodeInfoWithStorage[127.0.0.1:35187,DS-b5b21a3d-d6e1-4f8c-be27-fce650dd18b2,DISK], DatanodeInfoWithStorage[127.0.0.1:45829,DS-2d3ca67c-af22-47ce-ac4a-7544ed0034fd,DISK], DatanodeInfoWithStorage[127.0.0.1:46384,DS-e7ae7783-4296-4856-9e53-913c1cbcbfa7,DISK], DatanodeInfoWithStorage[127.0.0.1:40247,DS-e280287c-2ad8-49df-bba2-09550820cdb0,DISK], DatanodeInfoWithStorage[127.0.0.1:46819,DS-beb806d1-8bd2-4763-98fb-1141bf6e8c60,DISK], DatanodeInfoWithStorage[127.0.0.1:43884,DS-07cb934b-e86b-4140-a6db-e5b55bcf1790,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 864000000
v2: 864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-169503488-172.17.0.17-1597706229168:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44087,DS-bc239108-3fb6-4138-906c-0e5813dc4add,DISK], DatanodeInfoWithStorage[127.0.0.1:33070,DS-f955c48a-d1fe-4ba6-bb59-17f97df56c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:37855,DS-912eeb1b-9aef-412b-941d-63a8ded85eee,DISK], DatanodeInfoWithStorage[127.0.0.1:43539,DS-a0b52f7f-2539-45b3-ac51-3dd1fd936e51,DISK], DatanodeInfoWithStorage[127.0.0.1:46319,DS-89a9c61f-8066-47b3-a102-1ea345076144,DISK], DatanodeInfoWithStorage[127.0.0.1:36828,DS-3eb37f16-871b-40a7-b265-f5c978847b73,DISK], DatanodeInfoWithStorage[127.0.0.1:36100,DS-df48e4ac-e70e-49ac-a589-7c8af56bdbee,DISK], DatanodeInfoWithStorage[127.0.0.1:44614,DS-28e2d7f0-d5ac-4a68-9f28-068e4451e6a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-169503488-172.17.0.17-1597706229168:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44087,DS-bc239108-3fb6-4138-906c-0e5813dc4add,DISK], DatanodeInfoWithStorage[127.0.0.1:33070,DS-f955c48a-d1fe-4ba6-bb59-17f97df56c1c,DISK], DatanodeInfoWithStorage[127.0.0.1:37855,DS-912eeb1b-9aef-412b-941d-63a8ded85eee,DISK], DatanodeInfoWithStorage[127.0.0.1:43539,DS-a0b52f7f-2539-45b3-ac51-3dd1fd936e51,DISK], DatanodeInfoWithStorage[127.0.0.1:46319,DS-89a9c61f-8066-47b3-a102-1ea345076144,DISK], DatanodeInfoWithStorage[127.0.0.1:36828,DS-3eb37f16-871b-40a7-b265-f5c978847b73,DISK], DatanodeInfoWithStorage[127.0.0.1:36100,DS-df48e4ac-e70e-49ac-a589-7c8af56bdbee,DISK], DatanodeInfoWithStorage[127.0.0.1:44614,DS-28e2d7f0-d5ac-4a68-9f28-068e4451e6a5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 864000000
v2: 864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1675833148-172.17.0.17-1597706615634:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41141,DS-88885524-cbfc-4e13-a1f4-39b6809b998d,DISK], DatanodeInfoWithStorage[127.0.0.1:38835,DS-7b291c50-77a1-4822-9637-845b074448c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35925,DS-bcfea49c-2546-4268-a414-6a1ac197da6a,DISK], DatanodeInfoWithStorage[127.0.0.1:38810,DS-67dd0258-53d6-4b01-8ae8-c966a76b1f68,DISK], DatanodeInfoWithStorage[127.0.0.1:32970,DS-ef8c23f3-36d9-4273-8284-7857959bc83b,DISK], DatanodeInfoWithStorage[127.0.0.1:35908,DS-39d27966-d738-4193-9382-f7975d1d7de5,DISK], DatanodeInfoWithStorage[127.0.0.1:45144,DS-8cf3319f-46b8-42bb-9c85-181d616ce022,DISK], DatanodeInfoWithStorage[127.0.0.1:36063,DS-10ba13d2-29f4-47c5-aed3-40b40a2bbacf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1675833148-172.17.0.17-1597706615634:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41141,DS-88885524-cbfc-4e13-a1f4-39b6809b998d,DISK], DatanodeInfoWithStorage[127.0.0.1:38835,DS-7b291c50-77a1-4822-9637-845b074448c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35925,DS-bcfea49c-2546-4268-a414-6a1ac197da6a,DISK], DatanodeInfoWithStorage[127.0.0.1:38810,DS-67dd0258-53d6-4b01-8ae8-c966a76b1f68,DISK], DatanodeInfoWithStorage[127.0.0.1:32970,DS-ef8c23f3-36d9-4273-8284-7857959bc83b,DISK], DatanodeInfoWithStorage[127.0.0.1:35908,DS-39d27966-d738-4193-9382-f7975d1d7de5,DISK], DatanodeInfoWithStorage[127.0.0.1:45144,DS-8cf3319f-46b8-42bb-9c85-181d616ce022,DISK], DatanodeInfoWithStorage[127.0.0.1:36063,DS-10ba13d2-29f4-47c5-aed3-40b40a2bbacf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 864000000
v2: 864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1048075920-172.17.0.17-1597707063863:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33912,DS-0f316823-506e-4640-bca3-136d66501f7d,DISK], DatanodeInfoWithStorage[127.0.0.1:36909,DS-a0952998-0f27-41c0-b62b-f28bc437dcb6,DISK], DatanodeInfoWithStorage[127.0.0.1:46051,DS-9ad58e17-c12b-4e4d-96db-3af73afaa5bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34050,DS-aacef018-e0c5-466a-ba0d-9959f19f5e98,DISK], DatanodeInfoWithStorage[127.0.0.1:44066,DS-e4367109-c7c8-4232-a3e7-ff89fa92a57a,DISK], DatanodeInfoWithStorage[127.0.0.1:36427,DS-e499ada8-7ac5-42a5-847d-a6d128905b3d,DISK], DatanodeInfoWithStorage[127.0.0.1:39409,DS-52b317d1-75de-4253-a3ff-7bbe5814726e,DISK], DatanodeInfoWithStorage[127.0.0.1:45935,DS-85526647-82c9-4d42-b50c-52944ee48a64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1048075920-172.17.0.17-1597707063863:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33912,DS-0f316823-506e-4640-bca3-136d66501f7d,DISK], DatanodeInfoWithStorage[127.0.0.1:36909,DS-a0952998-0f27-41c0-b62b-f28bc437dcb6,DISK], DatanodeInfoWithStorage[127.0.0.1:46051,DS-9ad58e17-c12b-4e4d-96db-3af73afaa5bf,DISK], DatanodeInfoWithStorage[127.0.0.1:34050,DS-aacef018-e0c5-466a-ba0d-9959f19f5e98,DISK], DatanodeInfoWithStorage[127.0.0.1:44066,DS-e4367109-c7c8-4232-a3e7-ff89fa92a57a,DISK], DatanodeInfoWithStorage[127.0.0.1:36427,DS-e499ada8-7ac5-42a5-847d-a6d128905b3d,DISK], DatanodeInfoWithStorage[127.0.0.1:39409,DS-52b317d1-75de-4253-a3ff-7bbe5814726e,DISK], DatanodeInfoWithStorage[127.0.0.1:45935,DS-85526647-82c9-4d42-b50c-52944ee48a64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 864000000
v2: 864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-867613772-172.17.0.17-1597707184370:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39785,DS-ff3b713a-f911-4907-ae0c-eaf733caca14,DISK], DatanodeInfoWithStorage[127.0.0.1:43940,DS-34734d96-8d79-4bf3-a513-cb1603db93e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41804,DS-daf567d5-fdb2-4523-b63e-bbc95eda64e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37080,DS-b6720c67-9f85-4823-a211-4ab0380e2729,DISK], DatanodeInfoWithStorage[127.0.0.1:39606,DS-e36bc5da-2e07-48fb-a076-5b683bf1e290,DISK], DatanodeInfoWithStorage[127.0.0.1:44564,DS-ef94af44-dd3f-47ea-bdca-498eca8ce48b,DISK], DatanodeInfoWithStorage[127.0.0.1:34925,DS-544ed9bf-71f6-43ff-a51f-e71e2d8caadc,DISK], DatanodeInfoWithStorage[127.0.0.1:42673,DS-e3e3fec1-2bfb-4ed1-acba-8308925c916b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-867613772-172.17.0.17-1597707184370:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39785,DS-ff3b713a-f911-4907-ae0c-eaf733caca14,DISK], DatanodeInfoWithStorage[127.0.0.1:43940,DS-34734d96-8d79-4bf3-a513-cb1603db93e2,DISK], DatanodeInfoWithStorage[127.0.0.1:41804,DS-daf567d5-fdb2-4523-b63e-bbc95eda64e6,DISK], DatanodeInfoWithStorage[127.0.0.1:37080,DS-b6720c67-9f85-4823-a211-4ab0380e2729,DISK], DatanodeInfoWithStorage[127.0.0.1:39606,DS-e36bc5da-2e07-48fb-a076-5b683bf1e290,DISK], DatanodeInfoWithStorage[127.0.0.1:44564,DS-ef94af44-dd3f-47ea-bdca-498eca8ce48b,DISK], DatanodeInfoWithStorage[127.0.0.1:34925,DS-544ed9bf-71f6-43ff-a51f-e71e2d8caadc,DISK], DatanodeInfoWithStorage[127.0.0.1:42673,DS-e3e3fec1-2bfb-4ed1-acba-8308925c916b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 864000000
v2: 864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1345398529-172.17.0.17-1597707536598:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41232,DS-c0fe6933-7f63-4b50-b2b3-460c4e780754,DISK], DatanodeInfoWithStorage[127.0.0.1:46756,DS-6d3731dc-c2a9-4e2e-b2a9-e1336898522c,DISK], DatanodeInfoWithStorage[127.0.0.1:46659,DS-5fd8b965-e9b7-4a0c-ab1d-4eb44898908c,DISK], DatanodeInfoWithStorage[127.0.0.1:33714,DS-5f24553d-ab6b-47aa-898d-2b4042e0aaac,DISK], DatanodeInfoWithStorage[127.0.0.1:35636,DS-4ef4d457-13f7-4059-8524-065464719afe,DISK], DatanodeInfoWithStorage[127.0.0.1:38548,DS-fcf130d5-333e-40e5-b052-d8f62b5c6783,DISK], DatanodeInfoWithStorage[127.0.0.1:40709,DS-7d7e2145-c44f-4edb-9e06-468274b95c8b,DISK], DatanodeInfoWithStorage[127.0.0.1:46260,DS-2acd7fd0-02dc-46cb-b3ba-c3565578be66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1345398529-172.17.0.17-1597707536598:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41232,DS-c0fe6933-7f63-4b50-b2b3-460c4e780754,DISK], DatanodeInfoWithStorage[127.0.0.1:46756,DS-6d3731dc-c2a9-4e2e-b2a9-e1336898522c,DISK], DatanodeInfoWithStorage[127.0.0.1:46659,DS-5fd8b965-e9b7-4a0c-ab1d-4eb44898908c,DISK], DatanodeInfoWithStorage[127.0.0.1:33714,DS-5f24553d-ab6b-47aa-898d-2b4042e0aaac,DISK], DatanodeInfoWithStorage[127.0.0.1:35636,DS-4ef4d457-13f7-4059-8524-065464719afe,DISK], DatanodeInfoWithStorage[127.0.0.1:38548,DS-fcf130d5-333e-40e5-b052-d8f62b5c6783,DISK], DatanodeInfoWithStorage[127.0.0.1:40709,DS-7d7e2145-c44f-4edb-9e06-468274b95c8b,DISK], DatanodeInfoWithStorage[127.0.0.1:46260,DS-2acd7fd0-02dc-46cb-b3ba-c3565578be66,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 864000000
v2: 864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1221821229-172.17.0.17-1597707862666:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44716,DS-e7396fc0-9817-4f5f-a393-0057ba124d42,DISK], DatanodeInfoWithStorage[127.0.0.1:36899,DS-c193eda2-e159-417a-ae83-050a3f4951dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41754,DS-ed27ae05-bec6-4bff-a2c4-a47bf90a03a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33711,DS-e3c86778-6cf0-4f2b-9b0f-4e33d2fc3761,DISK], DatanodeInfoWithStorage[127.0.0.1:40353,DS-b6c4b31b-1479-4f36-9ded-0691ba17274b,DISK], DatanodeInfoWithStorage[127.0.0.1:37155,DS-b44a7625-1c67-4ff5-9635-acfab9e081dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33804,DS-ccf8f3ec-3ffd-46bb-86c7-777a71dc205f,DISK], DatanodeInfoWithStorage[127.0.0.1:39992,DS-1d2f85fc-8400-4f51-9934-bf555d90c5af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1221821229-172.17.0.17-1597707862666:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44716,DS-e7396fc0-9817-4f5f-a393-0057ba124d42,DISK], DatanodeInfoWithStorage[127.0.0.1:36899,DS-c193eda2-e159-417a-ae83-050a3f4951dd,DISK], DatanodeInfoWithStorage[127.0.0.1:41754,DS-ed27ae05-bec6-4bff-a2c4-a47bf90a03a3,DISK], DatanodeInfoWithStorage[127.0.0.1:33711,DS-e3c86778-6cf0-4f2b-9b0f-4e33d2fc3761,DISK], DatanodeInfoWithStorage[127.0.0.1:40353,DS-b6c4b31b-1479-4f36-9ded-0691ba17274b,DISK], DatanodeInfoWithStorage[127.0.0.1:37155,DS-b44a7625-1c67-4ff5-9635-acfab9e081dd,DISK], DatanodeInfoWithStorage[127.0.0.1:33804,DS-ccf8f3ec-3ffd-46bb-86c7-777a71dc205f,DISK], DatanodeInfoWithStorage[127.0.0.1:39992,DS-1d2f85fc-8400-4f51-9934-bf555d90c5af,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 864000000
v2: 864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-111932600-172.17.0.17-1597708281822:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36731,DS-3ec83a75-9b27-431e-972a-937e81a30210,DISK], DatanodeInfoWithStorage[127.0.0.1:40268,DS-a1cdf8a3-6847-41ba-83a1-68a0a04dd7ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45895,DS-a1638707-62f3-4d83-88e6-bd33186c3741,DISK], DatanodeInfoWithStorage[127.0.0.1:46861,DS-d0721022-01f8-4b27-bc21-66b6251c174f,DISK], DatanodeInfoWithStorage[127.0.0.1:45317,DS-abb6e297-0fa0-4ebe-bba5-7bc2613ed52e,DISK], DatanodeInfoWithStorage[127.0.0.1:40008,DS-559b9b93-e231-4320-8d6a-dd22bb1a2156,DISK], DatanodeInfoWithStorage[127.0.0.1:46021,DS-a034ebe6-987f-48a1-a091-ec341c524e89,DISK], DatanodeInfoWithStorage[127.0.0.1:40835,DS-e1e60915-4919-44e5-afbb-446144b7e3b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-111932600-172.17.0.17-1597708281822:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36731,DS-3ec83a75-9b27-431e-972a-937e81a30210,DISK], DatanodeInfoWithStorage[127.0.0.1:40268,DS-a1cdf8a3-6847-41ba-83a1-68a0a04dd7ce,DISK], DatanodeInfoWithStorage[127.0.0.1:45895,DS-a1638707-62f3-4d83-88e6-bd33186c3741,DISK], DatanodeInfoWithStorage[127.0.0.1:46861,DS-d0721022-01f8-4b27-bc21-66b6251c174f,DISK], DatanodeInfoWithStorage[127.0.0.1:45317,DS-abb6e297-0fa0-4ebe-bba5-7bc2613ed52e,DISK], DatanodeInfoWithStorage[127.0.0.1:40008,DS-559b9b93-e231-4320-8d6a-dd22bb1a2156,DISK], DatanodeInfoWithStorage[127.0.0.1:46021,DS-a034ebe6-987f-48a1-a091-ec341c524e89,DISK], DatanodeInfoWithStorage[127.0.0.1:40835,DS-e1e60915-4919-44e5-afbb-446144b7e3b6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 864000000
v2: 864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1724230439-172.17.0.17-1597708773416:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44135,DS-7296a160-792d-4b1f-aa12-430f454d1eac,DISK], DatanodeInfoWithStorage[127.0.0.1:43727,DS-0e614529-5627-4b48-9598-75c1a67a1152,DISK], DatanodeInfoWithStorage[127.0.0.1:45108,DS-bb2a1487-ddfe-48c9-a056-cee7da689e3e,DISK], DatanodeInfoWithStorage[127.0.0.1:36340,DS-cab5d300-0ec3-40c8-8faf-d972b72b7a68,DISK], DatanodeInfoWithStorage[127.0.0.1:33942,DS-b8d6d326-2e99-4603-91b9-3d732f8f7e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:39648,DS-f863fa7c-cade-493c-bc8f-8353a18861fd,DISK], DatanodeInfoWithStorage[127.0.0.1:43588,DS-09384a07-36d2-4e33-8f61-620792fe8ca0,DISK], DatanodeInfoWithStorage[127.0.0.1:33160,DS-c11b4ff3-6418-45f9-822a-70114585f11d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1724230439-172.17.0.17-1597708773416:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44135,DS-7296a160-792d-4b1f-aa12-430f454d1eac,DISK], DatanodeInfoWithStorage[127.0.0.1:43727,DS-0e614529-5627-4b48-9598-75c1a67a1152,DISK], DatanodeInfoWithStorage[127.0.0.1:45108,DS-bb2a1487-ddfe-48c9-a056-cee7da689e3e,DISK], DatanodeInfoWithStorage[127.0.0.1:36340,DS-cab5d300-0ec3-40c8-8faf-d972b72b7a68,DISK], DatanodeInfoWithStorage[127.0.0.1:33942,DS-b8d6d326-2e99-4603-91b9-3d732f8f7e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:39648,DS-f863fa7c-cade-493c-bc8f-8353a18861fd,DISK], DatanodeInfoWithStorage[127.0.0.1:43588,DS-09384a07-36d2-4e33-8f61-620792fe8ca0,DISK], DatanodeInfoWithStorage[127.0.0.1:33160,DS-c11b4ff3-6418-45f9-822a-70114585f11d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 864000000
v2: 864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1126507363-172.17.0.17-1597708974554:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43669,DS-41af6151-50a5-4bca-9a2c-a6fc2c8c7698,DISK], DatanodeInfoWithStorage[127.0.0.1:35471,DS-c9ac8ca1-6763-4217-9cad-3825b5f059a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44207,DS-77dd5282-9b02-4e92-9a76-44af9aa5f4e8,DISK], DatanodeInfoWithStorage[127.0.0.1:33319,DS-c503b2f7-8ef3-4c8e-a22b-4d05ce1d2a57,DISK], DatanodeInfoWithStorage[127.0.0.1:45476,DS-2fe25d89-0c2a-4ec6-a25d-6059da04f5d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40525,DS-78b51523-4965-4817-8111-6a06cf25f638,DISK], DatanodeInfoWithStorage[127.0.0.1:40246,DS-0a17fcf0-9242-4bd3-b2ba-bd880e14cdd1,DISK], DatanodeInfoWithStorage[127.0.0.1:35628,DS-9e1ab425-c994-4bdd-946e-b2e9292d6eff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1126507363-172.17.0.17-1597708974554:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43669,DS-41af6151-50a5-4bca-9a2c-a6fc2c8c7698,DISK], DatanodeInfoWithStorage[127.0.0.1:35471,DS-c9ac8ca1-6763-4217-9cad-3825b5f059a0,DISK], DatanodeInfoWithStorage[127.0.0.1:44207,DS-77dd5282-9b02-4e92-9a76-44af9aa5f4e8,DISK], DatanodeInfoWithStorage[127.0.0.1:33319,DS-c503b2f7-8ef3-4c8e-a22b-4d05ce1d2a57,DISK], DatanodeInfoWithStorage[127.0.0.1:45476,DS-2fe25d89-0c2a-4ec6-a25d-6059da04f5d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40525,DS-78b51523-4965-4817-8111-6a06cf25f638,DISK], DatanodeInfoWithStorage[127.0.0.1:40246,DS-0a17fcf0-9242-4bd3-b2ba-bd880e14cdd1,DISK], DatanodeInfoWithStorage[127.0.0.1:35628,DS-9e1ab425-c994-4bdd-946e-b2e9292d6eff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 864000000
v2: 864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1745400876-172.17.0.17-1597709011721:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41091,DS-b32735d9-dd38-442f-a7c9-384e801194df,DISK], DatanodeInfoWithStorage[127.0.0.1:34708,DS-0dd90d78-80f6-4762-826b-ff9b437ed377,DISK], DatanodeInfoWithStorage[127.0.0.1:39582,DS-effea9d2-33aa-4fd2-898f-f83fc5cc8c6e,DISK], DatanodeInfoWithStorage[127.0.0.1:45617,DS-5f027d9e-a200-40a3-9398-0165154d386e,DISK], DatanodeInfoWithStorage[127.0.0.1:36812,DS-059d6963-046a-4771-9cb0-cfbf00af5481,DISK], DatanodeInfoWithStorage[127.0.0.1:38168,DS-77f75628-afaf-4a8c-9506-b976780f8060,DISK], DatanodeInfoWithStorage[127.0.0.1:46808,DS-17ed0d20-a644-4311-83ef-26f578bf27c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46519,DS-0e2f08c5-e5c6-48ab-972f-0aa364e57bcf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1745400876-172.17.0.17-1597709011721:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41091,DS-b32735d9-dd38-442f-a7c9-384e801194df,DISK], DatanodeInfoWithStorage[127.0.0.1:34708,DS-0dd90d78-80f6-4762-826b-ff9b437ed377,DISK], DatanodeInfoWithStorage[127.0.0.1:39582,DS-effea9d2-33aa-4fd2-898f-f83fc5cc8c6e,DISK], DatanodeInfoWithStorage[127.0.0.1:45617,DS-5f027d9e-a200-40a3-9398-0165154d386e,DISK], DatanodeInfoWithStorage[127.0.0.1:36812,DS-059d6963-046a-4771-9cb0-cfbf00af5481,DISK], DatanodeInfoWithStorage[127.0.0.1:38168,DS-77f75628-afaf-4a8c-9506-b976780f8060,DISK], DatanodeInfoWithStorage[127.0.0.1:46808,DS-17ed0d20-a644-4311-83ef-26f578bf27c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46519,DS-0e2f08c5-e5c6-48ab-972f-0aa364e57bcf,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 864000000
v2: 864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-215213096-172.17.0.17-1597709415957:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37574,DS-e8b0dc6b-e8e0-4804-94bb-2c069cd588b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42062,DS-df6f77d3-0a39-4dbc-95b5-943f2802f33e,DISK], DatanodeInfoWithStorage[127.0.0.1:34390,DS-36a6f830-18cc-4fb9-8101-8afbde472216,DISK], DatanodeInfoWithStorage[127.0.0.1:35412,DS-31dc20ae-9182-4b9f-afd1-d66fb7f6af3e,DISK], DatanodeInfoWithStorage[127.0.0.1:40912,DS-253b4238-b8c3-4106-aa32-47ae49989c30,DISK], DatanodeInfoWithStorage[127.0.0.1:38195,DS-17ab3d49-f2a3-4d62-89fc-4115591caf10,DISK], DatanodeInfoWithStorage[127.0.0.1:40494,DS-f18653d5-f6ad-4796-aaa4-70b87bfd1aa4,DISK], DatanodeInfoWithStorage[127.0.0.1:37986,DS-58cb03f9-0411-4b91-b0ef-19520b2a8125,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-215213096-172.17.0.17-1597709415957:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37574,DS-e8b0dc6b-e8e0-4804-94bb-2c069cd588b9,DISK], DatanodeInfoWithStorage[127.0.0.1:42062,DS-df6f77d3-0a39-4dbc-95b5-943f2802f33e,DISK], DatanodeInfoWithStorage[127.0.0.1:34390,DS-36a6f830-18cc-4fb9-8101-8afbde472216,DISK], DatanodeInfoWithStorage[127.0.0.1:35412,DS-31dc20ae-9182-4b9f-afd1-d66fb7f6af3e,DISK], DatanodeInfoWithStorage[127.0.0.1:40912,DS-253b4238-b8c3-4106-aa32-47ae49989c30,DISK], DatanodeInfoWithStorage[127.0.0.1:38195,DS-17ab3d49-f2a3-4d62-89fc-4115591caf10,DISK], DatanodeInfoWithStorage[127.0.0.1:40494,DS-f18653d5-f6ad-4796-aaa4-70b87bfd1aa4,DISK], DatanodeInfoWithStorage[127.0.0.1:37986,DS-58cb03f9-0411-4b91-b0ef-19520b2a8125,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 864000000
v2: 864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-432345801-172.17.0.17-1597709646741:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36667,DS-9f682159-ea8e-42a5-a532-c080d9df4edb,DISK], DatanodeInfoWithStorage[127.0.0.1:36372,DS-a2b78e68-f2de-4890-bcae-020380006cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:33589,DS-c4f8e567-b2c0-497c-82dd-8de3e4f7509a,DISK], DatanodeInfoWithStorage[127.0.0.1:34883,DS-97200b4e-80c0-43dd-b3c3-ba47b3db2bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:36182,DS-9e6e2126-3f98-4208-b526-3a27a0d5b30d,DISK], DatanodeInfoWithStorage[127.0.0.1:36958,DS-69912c34-c3d2-49f1-be7a-0953178b9613,DISK], DatanodeInfoWithStorage[127.0.0.1:42567,DS-1f374399-4abe-4bbc-84b9-007c684b2b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:42301,DS-a4de0d19-bfaa-4187-84d1-5986080f091a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-432345801-172.17.0.17-1597709646741:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36667,DS-9f682159-ea8e-42a5-a532-c080d9df4edb,DISK], DatanodeInfoWithStorage[127.0.0.1:36372,DS-a2b78e68-f2de-4890-bcae-020380006cfe,DISK], DatanodeInfoWithStorage[127.0.0.1:33589,DS-c4f8e567-b2c0-497c-82dd-8de3e4f7509a,DISK], DatanodeInfoWithStorage[127.0.0.1:34883,DS-97200b4e-80c0-43dd-b3c3-ba47b3db2bf0,DISK], DatanodeInfoWithStorage[127.0.0.1:36182,DS-9e6e2126-3f98-4208-b526-3a27a0d5b30d,DISK], DatanodeInfoWithStorage[127.0.0.1:36958,DS-69912c34-c3d2-49f1-be7a-0953178b9613,DISK], DatanodeInfoWithStorage[127.0.0.1:42567,DS-1f374399-4abe-4bbc-84b9-007c684b2b6d,DISK], DatanodeInfoWithStorage[127.0.0.1:42301,DS-a4de0d19-bfaa-4187-84d1-5986080f091a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.client.key.provider.cache.expiry
component: hdfs:NameNode
v1: 864000000
v2: 864
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1763876476-172.17.0.17-1597709906457:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44903,DS-d7eda916-71ab-40f3-826c-c95a8394dadd,DISK], DatanodeInfoWithStorage[127.0.0.1:45740,DS-0b248beb-4bf2-4965-91d0-c192ec71e792,DISK], DatanodeInfoWithStorage[127.0.0.1:38769,DS-0a059bee-ca7b-4416-bbcd-c47281866596,DISK], DatanodeInfoWithStorage[127.0.0.1:45200,DS-a308e1f0-1d45-4c58-830b-da1bfc9a4e30,DISK], DatanodeInfoWithStorage[127.0.0.1:42897,DS-d776ee54-3690-479c-af30-6f10f217c96a,DISK], DatanodeInfoWithStorage[127.0.0.1:44404,DS-eb1218a6-16d0-4e11-a612-ea0047ec667a,DISK], DatanodeInfoWithStorage[127.0.0.1:35104,DS-1cc8ec0b-68b4-4e64-98c1-fc067c67de2c,DISK], DatanodeInfoWithStorage[127.0.0.1:37204,DS-fe81f56f-b70b-4943-b372-e54c5698edf3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1763876476-172.17.0.17-1597709906457:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44903,DS-d7eda916-71ab-40f3-826c-c95a8394dadd,DISK], DatanodeInfoWithStorage[127.0.0.1:45740,DS-0b248beb-4bf2-4965-91d0-c192ec71e792,DISK], DatanodeInfoWithStorage[127.0.0.1:38769,DS-0a059bee-ca7b-4416-bbcd-c47281866596,DISK], DatanodeInfoWithStorage[127.0.0.1:45200,DS-a308e1f0-1d45-4c58-830b-da1bfc9a4e30,DISK], DatanodeInfoWithStorage[127.0.0.1:42897,DS-d776ee54-3690-479c-af30-6f10f217c96a,DISK], DatanodeInfoWithStorage[127.0.0.1:44404,DS-eb1218a6-16d0-4e11-a612-ea0047ec667a,DISK], DatanodeInfoWithStorage[127.0.0.1:35104,DS-1cc8ec0b-68b4-4e64-98c1-fc067c67de2c,DISK], DatanodeInfoWithStorage[127.0.0.1:37204,DS-fe81f56f-b70b-4943-b372-e54c5698edf3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 7 out of 50
v1v1v2v2 failed with probability 12 out of 50
result: false positive !!!
Total execution time in seconds : 5729
