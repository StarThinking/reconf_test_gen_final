reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 1000m
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 1000m
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-535482721-172.17.0.7-1597715680273:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42152,DS-911a2e95-24f9-4549-8f30-796d4ed76f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:34774,DS-3815ede6-9d0c-4984-b7b2-7ac4452d41bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33878,DS-d756d344-5002-49c8-b90d-b1eb00fa9492,DISK], DatanodeInfoWithStorage[127.0.0.1:43184,DS-811620af-2b22-4f77-9925-420a3669b90d,DISK], DatanodeInfoWithStorage[127.0.0.1:35304,DS-76262231-06a0-4347-bd99-bd1d4cf0b424,DISK], DatanodeInfoWithStorage[127.0.0.1:41424,DS-8d88f434-ab4e-4d75-897c-0931a0429b94,DISK], DatanodeInfoWithStorage[127.0.0.1:45315,DS-e75b2dc4-2b91-40f8-ad5c-4ba60fb39125,DISK], DatanodeInfoWithStorage[127.0.0.1:36796,DS-8d5697ef-cfe7-4a77-905f-199a88ef7ddc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-535482721-172.17.0.7-1597715680273:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42152,DS-911a2e95-24f9-4549-8f30-796d4ed76f9b,DISK], DatanodeInfoWithStorage[127.0.0.1:34774,DS-3815ede6-9d0c-4984-b7b2-7ac4452d41bb,DISK], DatanodeInfoWithStorage[127.0.0.1:33878,DS-d756d344-5002-49c8-b90d-b1eb00fa9492,DISK], DatanodeInfoWithStorage[127.0.0.1:43184,DS-811620af-2b22-4f77-9925-420a3669b90d,DISK], DatanodeInfoWithStorage[127.0.0.1:35304,DS-76262231-06a0-4347-bd99-bd1d4cf0b424,DISK], DatanodeInfoWithStorage[127.0.0.1:41424,DS-8d88f434-ab4e-4d75-897c-0931a0429b94,DISK], DatanodeInfoWithStorage[127.0.0.1:45315,DS-e75b2dc4-2b91-40f8-ad5c-4ba60fb39125,DISK], DatanodeInfoWithStorage[127.0.0.1:36796,DS-8d5697ef-cfe7-4a77-905f-199a88ef7ddc,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 1000m
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1975090701-172.17.0.7-1597715753895:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33724,DS-7529de2f-dbb2-4cb0-9a47-fe8995e2fbcc,DISK], DatanodeInfoWithStorage[127.0.0.1:37797,DS-c712dbcd-7607-4b87-b875-eaaa14cdecbb,DISK], DatanodeInfoWithStorage[127.0.0.1:43097,DS-ac0ffc69-cc13-4f57-96e0-51c87f787300,DISK], DatanodeInfoWithStorage[127.0.0.1:44500,DS-8bb41e44-be9e-4ba6-a8a7-142b6cb86c60,DISK], DatanodeInfoWithStorage[127.0.0.1:43189,DS-f94a5f7f-17cb-4811-8eb3-6f9f165f0f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:33160,DS-3686b311-c5a7-4020-b0f9-c4a108dfff44,DISK], DatanodeInfoWithStorage[127.0.0.1:32833,DS-5548366b-6590-4c95-84cb-15693e99b152,DISK], DatanodeInfoWithStorage[127.0.0.1:44299,DS-0660bb0d-fd8b-4721-a176-a941a5440c64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1975090701-172.17.0.7-1597715753895:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33724,DS-7529de2f-dbb2-4cb0-9a47-fe8995e2fbcc,DISK], DatanodeInfoWithStorage[127.0.0.1:37797,DS-c712dbcd-7607-4b87-b875-eaaa14cdecbb,DISK], DatanodeInfoWithStorage[127.0.0.1:43097,DS-ac0ffc69-cc13-4f57-96e0-51c87f787300,DISK], DatanodeInfoWithStorage[127.0.0.1:44500,DS-8bb41e44-be9e-4ba6-a8a7-142b6cb86c60,DISK], DatanodeInfoWithStorage[127.0.0.1:43189,DS-f94a5f7f-17cb-4811-8eb3-6f9f165f0f0e,DISK], DatanodeInfoWithStorage[127.0.0.1:33160,DS-3686b311-c5a7-4020-b0f9-c4a108dfff44,DISK], DatanodeInfoWithStorage[127.0.0.1:32833,DS-5548366b-6590-4c95-84cb-15693e99b152,DISK], DatanodeInfoWithStorage[127.0.0.1:44299,DS-0660bb0d-fd8b-4721-a176-a941a5440c64,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 1000m
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2070003809-172.17.0.7-1597715830281:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46526,DS-93425b4a-b233-45a2-bf07-ff884d7c2605,DISK], DatanodeInfoWithStorage[127.0.0.1:43698,DS-223e01ef-6fbe-428a-96c9-78587dc74c19,DISK], DatanodeInfoWithStorage[127.0.0.1:33195,DS-3c379b0f-1ae9-40d3-bc2b-0de34d8f7fd0,DISK], DatanodeInfoWithStorage[127.0.0.1:43043,DS-471b4913-5fa4-4866-8c62-bd20871c62bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34356,DS-df7da096-f201-45be-973b-4e6066e94b20,DISK], DatanodeInfoWithStorage[127.0.0.1:43889,DS-0aad002c-635a-457b-b215-63e334990532,DISK], DatanodeInfoWithStorage[127.0.0.1:38222,DS-67cba805-dc6a-4ff4-911b-3fb29b01c773,DISK], DatanodeInfoWithStorage[127.0.0.1:41499,DS-718fcfe5-01d9-4c7e-9889-59034d609075,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2070003809-172.17.0.7-1597715830281:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46526,DS-93425b4a-b233-45a2-bf07-ff884d7c2605,DISK], DatanodeInfoWithStorage[127.0.0.1:43698,DS-223e01ef-6fbe-428a-96c9-78587dc74c19,DISK], DatanodeInfoWithStorage[127.0.0.1:33195,DS-3c379b0f-1ae9-40d3-bc2b-0de34d8f7fd0,DISK], DatanodeInfoWithStorage[127.0.0.1:43043,DS-471b4913-5fa4-4866-8c62-bd20871c62bb,DISK], DatanodeInfoWithStorage[127.0.0.1:34356,DS-df7da096-f201-45be-973b-4e6066e94b20,DISK], DatanodeInfoWithStorage[127.0.0.1:43889,DS-0aad002c-635a-457b-b215-63e334990532,DISK], DatanodeInfoWithStorage[127.0.0.1:38222,DS-67cba805-dc6a-4ff4-911b-3fb29b01c773,DISK], DatanodeInfoWithStorage[127.0.0.1:41499,DS-718fcfe5-01d9-4c7e-9889-59034d609075,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 1000m
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-409121845-172.17.0.7-1597716024620:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43484,DS-59a43681-ffe6-4809-b23d-359f7d7b24ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39484,DS-cb3265ab-5fd0-4d62-977b-51779b0a6dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:34156,DS-87fd6e71-eeb2-42c1-ac58-6500f75dc8ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35729,DS-764080aa-9df5-40d7-9f8c-3b542518fe38,DISK], DatanodeInfoWithStorage[127.0.0.1:36639,DS-cd2ff7d2-251e-40b2-bf51-4aa8c497d0cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35374,DS-b59f6a36-57ca-4db5-91d9-b9e40c80a56b,DISK], DatanodeInfoWithStorage[127.0.0.1:44573,DS-a16bb045-7f36-4d2a-9792-300c214870d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40204,DS-531db8cb-ecc7-4d34-8f54-a9023171acde,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-409121845-172.17.0.7-1597716024620:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43484,DS-59a43681-ffe6-4809-b23d-359f7d7b24ca,DISK], DatanodeInfoWithStorage[127.0.0.1:39484,DS-cb3265ab-5fd0-4d62-977b-51779b0a6dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:34156,DS-87fd6e71-eeb2-42c1-ac58-6500f75dc8ee,DISK], DatanodeInfoWithStorage[127.0.0.1:35729,DS-764080aa-9df5-40d7-9f8c-3b542518fe38,DISK], DatanodeInfoWithStorage[127.0.0.1:36639,DS-cd2ff7d2-251e-40b2-bf51-4aa8c497d0cc,DISK], DatanodeInfoWithStorage[127.0.0.1:35374,DS-b59f6a36-57ca-4db5-91d9-b9e40c80a56b,DISK], DatanodeInfoWithStorage[127.0.0.1:44573,DS-a16bb045-7f36-4d2a-9792-300c214870d3,DISK], DatanodeInfoWithStorage[127.0.0.1:40204,DS-531db8cb-ecc7-4d34-8f54-a9023171acde,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 1000m
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1505553510-172.17.0.7-1597716099878:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46674,DS-069cc062-26a2-4944-b0c6-2785c8170705,DISK], DatanodeInfoWithStorage[127.0.0.1:43392,DS-b8b4a4f0-e205-4d14-ac59-3b32caa31920,DISK], DatanodeInfoWithStorage[127.0.0.1:36314,DS-0dbbd583-3166-4178-ae3c-04cedddc656f,DISK], DatanodeInfoWithStorage[127.0.0.1:43866,DS-996ad448-e0fe-42e6-8c60-c0166520db15,DISK], DatanodeInfoWithStorage[127.0.0.1:43147,DS-78cfabea-3dd8-4d82-8c4c-b37b6d8eda92,DISK], DatanodeInfoWithStorage[127.0.0.1:44678,DS-64e4e337-978b-4c15-a26e-3b589e273021,DISK], DatanodeInfoWithStorage[127.0.0.1:45228,DS-b4216c27-99ed-40f2-ae0e-61c5ea522ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:39150,DS-46fe51b8-a621-4bb9-a7b5-75faecf4f940,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1505553510-172.17.0.7-1597716099878:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46674,DS-069cc062-26a2-4944-b0c6-2785c8170705,DISK], DatanodeInfoWithStorage[127.0.0.1:43392,DS-b8b4a4f0-e205-4d14-ac59-3b32caa31920,DISK], DatanodeInfoWithStorage[127.0.0.1:36314,DS-0dbbd583-3166-4178-ae3c-04cedddc656f,DISK], DatanodeInfoWithStorage[127.0.0.1:43866,DS-996ad448-e0fe-42e6-8c60-c0166520db15,DISK], DatanodeInfoWithStorage[127.0.0.1:43147,DS-78cfabea-3dd8-4d82-8c4c-b37b6d8eda92,DISK], DatanodeInfoWithStorage[127.0.0.1:44678,DS-64e4e337-978b-4c15-a26e-3b589e273021,DISK], DatanodeInfoWithStorage[127.0.0.1:45228,DS-b4216c27-99ed-40f2-ae0e-61c5ea522ee7,DISK], DatanodeInfoWithStorage[127.0.0.1:39150,DS-46fe51b8-a621-4bb9-a7b5-75faecf4f940,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 1000m
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1094436721-172.17.0.7-1597716404538:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35962,DS-e1201b87-3f6b-48df-97b4-5810e75f9dda,DISK], DatanodeInfoWithStorage[127.0.0.1:45792,DS-81e2ee20-7441-43e7-9729-2bd0502fd84e,DISK], DatanodeInfoWithStorage[127.0.0.1:38754,DS-d93b4a4c-b4b3-458c-aa95-b867276a4d7a,DISK], DatanodeInfoWithStorage[127.0.0.1:38713,DS-3a13df94-591b-42a8-9e91-636ee8bdfd03,DISK], DatanodeInfoWithStorage[127.0.0.1:41464,DS-dc68d327-6678-484a-a79f-ce8114fb9f93,DISK], DatanodeInfoWithStorage[127.0.0.1:33057,DS-d34c0a79-c559-466a-b332-1657e15af5eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34755,DS-4f208386-b3a2-41b3-a923-9474fd41f86e,DISK], DatanodeInfoWithStorage[127.0.0.1:35552,DS-5eea751c-a524-4683-a43a-1d8f07a147b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1094436721-172.17.0.7-1597716404538:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35962,DS-e1201b87-3f6b-48df-97b4-5810e75f9dda,DISK], DatanodeInfoWithStorage[127.0.0.1:45792,DS-81e2ee20-7441-43e7-9729-2bd0502fd84e,DISK], DatanodeInfoWithStorage[127.0.0.1:38754,DS-d93b4a4c-b4b3-458c-aa95-b867276a4d7a,DISK], DatanodeInfoWithStorage[127.0.0.1:38713,DS-3a13df94-591b-42a8-9e91-636ee8bdfd03,DISK], DatanodeInfoWithStorage[127.0.0.1:41464,DS-dc68d327-6678-484a-a79f-ce8114fb9f93,DISK], DatanodeInfoWithStorage[127.0.0.1:33057,DS-d34c0a79-c559-466a-b332-1657e15af5eb,DISK], DatanodeInfoWithStorage[127.0.0.1:34755,DS-4f208386-b3a2-41b3-a923-9474fd41f86e,DISK], DatanodeInfoWithStorage[127.0.0.1:35552,DS-5eea751c-a524-4683-a43a-1d8f07a147b8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 1000m
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-703914752-172.17.0.7-1597716441722:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44836,DS-062d2706-286d-4a8b-852f-b6241fda9f80,DISK], DatanodeInfoWithStorage[127.0.0.1:44915,DS-bb74d8d0-ff4a-4a4e-b502-2cf7057a5d30,DISK], DatanodeInfoWithStorage[127.0.0.1:37206,DS-77ae2e4d-5b43-4d54-b674-33f7fa60fb13,DISK], DatanodeInfoWithStorage[127.0.0.1:39659,DS-78875d9f-974a-43fc-adf1-d38f0ddf864d,DISK], DatanodeInfoWithStorage[127.0.0.1:42788,DS-ad7142b3-0b42-4e65-b5bc-f449e76d60c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35104,DS-3b35a401-a3b4-4eb5-babf-83ba662a3b2e,DISK], DatanodeInfoWithStorage[127.0.0.1:37900,DS-b00178a7-5016-4a97-8d41-63380755a69f,DISK], DatanodeInfoWithStorage[127.0.0.1:35944,DS-b7dd61b1-94dd-4415-8103-7740e9790b2e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-703914752-172.17.0.7-1597716441722:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44836,DS-062d2706-286d-4a8b-852f-b6241fda9f80,DISK], DatanodeInfoWithStorage[127.0.0.1:44915,DS-bb74d8d0-ff4a-4a4e-b502-2cf7057a5d30,DISK], DatanodeInfoWithStorage[127.0.0.1:37206,DS-77ae2e4d-5b43-4d54-b674-33f7fa60fb13,DISK], DatanodeInfoWithStorage[127.0.0.1:39659,DS-78875d9f-974a-43fc-adf1-d38f0ddf864d,DISK], DatanodeInfoWithStorage[127.0.0.1:42788,DS-ad7142b3-0b42-4e65-b5bc-f449e76d60c2,DISK], DatanodeInfoWithStorage[127.0.0.1:35104,DS-3b35a401-a3b4-4eb5-babf-83ba662a3b2e,DISK], DatanodeInfoWithStorage[127.0.0.1:37900,DS-b00178a7-5016-4a97-8d41-63380755a69f,DISK], DatanodeInfoWithStorage[127.0.0.1:35944,DS-b7dd61b1-94dd-4415-8103-7740e9790b2e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 1000m
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-392497893-172.17.0.7-1597716548880:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40008,DS-77b12cb5-5d98-4e6b-9490-4f7a27d56ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:35575,DS-3044ac59-92a6-4bbe-b898-654efb3abbe5,DISK], DatanodeInfoWithStorage[127.0.0.1:34799,DS-4de330c4-00bb-41fe-9cf4-2f3c47a31f73,DISK], DatanodeInfoWithStorage[127.0.0.1:44939,DS-868a89a1-6267-4bb1-8684-f42effbfce97,DISK], DatanodeInfoWithStorage[127.0.0.1:41391,DS-b9b62fcf-856b-468e-9fec-0f568f783bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:43570,DS-addbc78d-a4d7-4265-80e7-497b1049eb42,DISK], DatanodeInfoWithStorage[127.0.0.1:38649,DS-a99d7f9e-f403-4695-9b25-a767a47ced79,DISK], DatanodeInfoWithStorage[127.0.0.1:44915,DS-98d44950-c8f4-4ba5-8f70-463dd9021596,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-392497893-172.17.0.7-1597716548880:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40008,DS-77b12cb5-5d98-4e6b-9490-4f7a27d56ae9,DISK], DatanodeInfoWithStorage[127.0.0.1:35575,DS-3044ac59-92a6-4bbe-b898-654efb3abbe5,DISK], DatanodeInfoWithStorage[127.0.0.1:34799,DS-4de330c4-00bb-41fe-9cf4-2f3c47a31f73,DISK], DatanodeInfoWithStorage[127.0.0.1:44939,DS-868a89a1-6267-4bb1-8684-f42effbfce97,DISK], DatanodeInfoWithStorage[127.0.0.1:41391,DS-b9b62fcf-856b-468e-9fec-0f568f783bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:43570,DS-addbc78d-a4d7-4265-80e7-497b1049eb42,DISK], DatanodeInfoWithStorage[127.0.0.1:38649,DS-a99d7f9e-f403-4695-9b25-a767a47ced79,DISK], DatanodeInfoWithStorage[127.0.0.1:44915,DS-98d44950-c8f4-4ba5-8f70-463dd9021596,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 1000m
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-54557817-172.17.0.7-1597716584687:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41083,DS-7d601a67-3387-4e34-b466-fa98661a41db,DISK], DatanodeInfoWithStorage[127.0.0.1:42086,DS-e2d4c45f-c445-4cbb-9e27-19ed5e36d42e,DISK], DatanodeInfoWithStorage[127.0.0.1:41525,DS-19827041-84e6-4df1-b404-b9016428e82f,DISK], DatanodeInfoWithStorage[127.0.0.1:40445,DS-83414aef-cc33-4d1d-8d98-90ea36492c3b,DISK], DatanodeInfoWithStorage[127.0.0.1:33905,DS-dd75c779-b5cd-4f93-b731-7d82b924bc83,DISK], DatanodeInfoWithStorage[127.0.0.1:32869,DS-c3cbb615-a8e6-4b92-b59b-78e6556af54e,DISK], DatanodeInfoWithStorage[127.0.0.1:34319,DS-ada21989-e7e6-47bb-a18b-e7a78b2ff6b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33811,DS-a0a11411-f710-4979-abf1-914173547ec2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-54557817-172.17.0.7-1597716584687:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41083,DS-7d601a67-3387-4e34-b466-fa98661a41db,DISK], DatanodeInfoWithStorage[127.0.0.1:42086,DS-e2d4c45f-c445-4cbb-9e27-19ed5e36d42e,DISK], DatanodeInfoWithStorage[127.0.0.1:41525,DS-19827041-84e6-4df1-b404-b9016428e82f,DISK], DatanodeInfoWithStorage[127.0.0.1:40445,DS-83414aef-cc33-4d1d-8d98-90ea36492c3b,DISK], DatanodeInfoWithStorage[127.0.0.1:33905,DS-dd75c779-b5cd-4f93-b731-7d82b924bc83,DISK], DatanodeInfoWithStorage[127.0.0.1:32869,DS-c3cbb615-a8e6-4b92-b59b-78e6556af54e,DISK], DatanodeInfoWithStorage[127.0.0.1:34319,DS-ada21989-e7e6-47bb-a18b-e7a78b2ff6b9,DISK], DatanodeInfoWithStorage[127.0.0.1:33811,DS-a0a11411-f710-4979-abf1-914173547ec2,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 1000m
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-132345021-172.17.0.7-1597717011348:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37021,DS-41762e66-1494-423c-9d41-732fa18da95c,DISK], DatanodeInfoWithStorage[127.0.0.1:38343,DS-c4721713-bd86-4074-b0e8-fd9f36ef3dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:34916,DS-7b4fd5b4-241a-4a52-89e4-41afab6f750d,DISK], DatanodeInfoWithStorage[127.0.0.1:46316,DS-5f807e21-a267-40c2-8b1d-3a2befd33193,DISK], DatanodeInfoWithStorage[127.0.0.1:38670,DS-3230dff8-e57e-4495-b331-64d629a83c39,DISK], DatanodeInfoWithStorage[127.0.0.1:34694,DS-6cf250f7-75f6-4b14-9af2-dcb0d9af1fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:34727,DS-1318fb1d-980f-4694-bf78-159ef69ca768,DISK], DatanodeInfoWithStorage[127.0.0.1:34226,DS-dd4e6c9c-5af0-4120-bb26-64eef981b91f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-132345021-172.17.0.7-1597717011348:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37021,DS-41762e66-1494-423c-9d41-732fa18da95c,DISK], DatanodeInfoWithStorage[127.0.0.1:38343,DS-c4721713-bd86-4074-b0e8-fd9f36ef3dcc,DISK], DatanodeInfoWithStorage[127.0.0.1:34916,DS-7b4fd5b4-241a-4a52-89e4-41afab6f750d,DISK], DatanodeInfoWithStorage[127.0.0.1:46316,DS-5f807e21-a267-40c2-8b1d-3a2befd33193,DISK], DatanodeInfoWithStorage[127.0.0.1:38670,DS-3230dff8-e57e-4495-b331-64d629a83c39,DISK], DatanodeInfoWithStorage[127.0.0.1:34694,DS-6cf250f7-75f6-4b14-9af2-dcb0d9af1fd8,DISK], DatanodeInfoWithStorage[127.0.0.1:34727,DS-1318fb1d-980f-4694-bf78-159ef69ca768,DISK], DatanodeInfoWithStorage[127.0.0.1:34226,DS-dd4e6c9c-5af0-4120-bb26-64eef981b91f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 1000m
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-860008851-172.17.0.7-1597717124360:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39464,DS-6c43e1df-b4ce-469c-821b-182b27cf3365,DISK], DatanodeInfoWithStorage[127.0.0.1:46067,DS-5ff54b8d-d7d2-4dfe-992c-128c9b99f680,DISK], DatanodeInfoWithStorage[127.0.0.1:36292,DS-82183931-99d1-4b91-971b-f539e0d18df9,DISK], DatanodeInfoWithStorage[127.0.0.1:34279,DS-63caf66e-34c0-48a4-865c-1c56a41560fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46520,DS-708b5bd6-3ce5-4119-ae5d-41a0be85191c,DISK], DatanodeInfoWithStorage[127.0.0.1:34928,DS-46b7c890-d6e7-430c-bcfa-db42f6234ace,DISK], DatanodeInfoWithStorage[127.0.0.1:37221,DS-b55e8dd9-9e9d-4085-8c6b-093c28144409,DISK], DatanodeInfoWithStorage[127.0.0.1:44812,DS-bbae14ea-711d-4fb3-bb40-3cd7d4d87305,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-860008851-172.17.0.7-1597717124360:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39464,DS-6c43e1df-b4ce-469c-821b-182b27cf3365,DISK], DatanodeInfoWithStorage[127.0.0.1:46067,DS-5ff54b8d-d7d2-4dfe-992c-128c9b99f680,DISK], DatanodeInfoWithStorage[127.0.0.1:36292,DS-82183931-99d1-4b91-971b-f539e0d18df9,DISK], DatanodeInfoWithStorage[127.0.0.1:34279,DS-63caf66e-34c0-48a4-865c-1c56a41560fb,DISK], DatanodeInfoWithStorage[127.0.0.1:46520,DS-708b5bd6-3ce5-4119-ae5d-41a0be85191c,DISK], DatanodeInfoWithStorage[127.0.0.1:34928,DS-46b7c890-d6e7-430c-bcfa-db42f6234ace,DISK], DatanodeInfoWithStorage[127.0.0.1:37221,DS-b55e8dd9-9e9d-4085-8c6b-093c28144409,DISK], DatanodeInfoWithStorage[127.0.0.1:44812,DS-bbae14ea-711d-4fb3-bb40-3cd7d4d87305,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 1000m
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1155208389-172.17.0.7-1597717249657:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39239,DS-f257b480-b308-445a-836f-fbbf874293c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46756,DS-8c278181-7fec-4ff2-bf6e-ecd89f46327a,DISK], DatanodeInfoWithStorage[127.0.0.1:34934,DS-40d4fd97-3697-4427-934d-304b1e715e32,DISK], DatanodeInfoWithStorage[127.0.0.1:41272,DS-8e78f5e4-4173-4854-afda-a6e49f9a1de6,DISK], DatanodeInfoWithStorage[127.0.0.1:43020,DS-20d97ea3-5dbf-4061-a9d6-b5a99f23d5c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43680,DS-7904f769-8b27-445a-822d-aebe54d25183,DISK], DatanodeInfoWithStorage[127.0.0.1:45091,DS-34d6fae3-dc2d-4c45-a3ae-3d9cd27ab989,DISK], DatanodeInfoWithStorage[127.0.0.1:46564,DS-2df2d019-9bac-4b57-a02f-6fbacb70d307,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1155208389-172.17.0.7-1597717249657:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39239,DS-f257b480-b308-445a-836f-fbbf874293c6,DISK], DatanodeInfoWithStorage[127.0.0.1:46756,DS-8c278181-7fec-4ff2-bf6e-ecd89f46327a,DISK], DatanodeInfoWithStorage[127.0.0.1:34934,DS-40d4fd97-3697-4427-934d-304b1e715e32,DISK], DatanodeInfoWithStorage[127.0.0.1:41272,DS-8e78f5e4-4173-4854-afda-a6e49f9a1de6,DISK], DatanodeInfoWithStorage[127.0.0.1:43020,DS-20d97ea3-5dbf-4061-a9d6-b5a99f23d5c4,DISK], DatanodeInfoWithStorage[127.0.0.1:43680,DS-7904f769-8b27-445a-822d-aebe54d25183,DISK], DatanodeInfoWithStorage[127.0.0.1:45091,DS-34d6fae3-dc2d-4c45-a3ae-3d9cd27ab989,DISK], DatanodeInfoWithStorage[127.0.0.1:46564,DS-2df2d019-9bac-4b57-a02f-6fbacb70d307,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 1000m
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1261239609-172.17.0.7-1597717281492:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39167,DS-dd824af6-4629-47b5-8457-e5bde3d95c7d,DISK], DatanodeInfoWithStorage[127.0.0.1:37323,DS-67405b19-c10c-4317-8f0b-04dbb66d341c,DISK], DatanodeInfoWithStorage[127.0.0.1:45193,DS-2a1ec5a8-9796-4a64-b7fa-c486239bcddb,DISK], DatanodeInfoWithStorage[127.0.0.1:42166,DS-6b1e3b42-34ba-401f-bfa5-5a6fccc073b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39978,DS-f5a479eb-3a3e-4ccc-a7cc-8841109cb263,DISK], DatanodeInfoWithStorage[127.0.0.1:46095,DS-c84a5b1e-2626-457f-be2d-46f238035649,DISK], DatanodeInfoWithStorage[127.0.0.1:34552,DS-942a45a0-fbc0-471f-9c3c-20b0d0dffd48,DISK], DatanodeInfoWithStorage[127.0.0.1:33474,DS-bbbce905-b436-4c34-8ba7-4713b29938e3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1261239609-172.17.0.7-1597717281492:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39167,DS-dd824af6-4629-47b5-8457-e5bde3d95c7d,DISK], DatanodeInfoWithStorage[127.0.0.1:37323,DS-67405b19-c10c-4317-8f0b-04dbb66d341c,DISK], DatanodeInfoWithStorage[127.0.0.1:45193,DS-2a1ec5a8-9796-4a64-b7fa-c486239bcddb,DISK], DatanodeInfoWithStorage[127.0.0.1:42166,DS-6b1e3b42-34ba-401f-bfa5-5a6fccc073b8,DISK], DatanodeInfoWithStorage[127.0.0.1:39978,DS-f5a479eb-3a3e-4ccc-a7cc-8841109cb263,DISK], DatanodeInfoWithStorage[127.0.0.1:46095,DS-c84a5b1e-2626-457f-be2d-46f238035649,DISK], DatanodeInfoWithStorage[127.0.0.1:34552,DS-942a45a0-fbc0-471f-9c3c-20b0d0dffd48,DISK], DatanodeInfoWithStorage[127.0.0.1:33474,DS-bbbce905-b436-4c34-8ba7-4713b29938e3,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 1000m
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-944435926-172.17.0.7-1597717322389:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40630,DS-7f248fdb-43ed-434d-805f-91d91c8a4734,DISK], DatanodeInfoWithStorage[127.0.0.1:41111,DS-3e64d0f8-bc32-4497-a50f-484d9918e9c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46441,DS-f5890e20-f716-46e7-ac65-d808796e41c7,DISK], DatanodeInfoWithStorage[127.0.0.1:41346,DS-f538b909-b62c-43de-bd4b-5321fe142123,DISK], DatanodeInfoWithStorage[127.0.0.1:45013,DS-6f557b28-8530-4d5c-a149-90da709f1de6,DISK], DatanodeInfoWithStorage[127.0.0.1:39843,DS-1b650e1e-065d-4d66-8f24-9d7fd7b9d46e,DISK], DatanodeInfoWithStorage[127.0.0.1:34760,DS-dad3d7d5-39c4-407a-a9ba-a78dd3cc8162,DISK], DatanodeInfoWithStorage[127.0.0.1:39416,DS-f1458f9f-2332-41e5-85a6-db502d26d551,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-944435926-172.17.0.7-1597717322389:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40630,DS-7f248fdb-43ed-434d-805f-91d91c8a4734,DISK], DatanodeInfoWithStorage[127.0.0.1:41111,DS-3e64d0f8-bc32-4497-a50f-484d9918e9c0,DISK], DatanodeInfoWithStorage[127.0.0.1:46441,DS-f5890e20-f716-46e7-ac65-d808796e41c7,DISK], DatanodeInfoWithStorage[127.0.0.1:41346,DS-f538b909-b62c-43de-bd4b-5321fe142123,DISK], DatanodeInfoWithStorage[127.0.0.1:45013,DS-6f557b28-8530-4d5c-a149-90da709f1de6,DISK], DatanodeInfoWithStorage[127.0.0.1:39843,DS-1b650e1e-065d-4d66-8f24-9d7fd7b9d46e,DISK], DatanodeInfoWithStorage[127.0.0.1:34760,DS-dad3d7d5-39c4-407a-a9ba-a78dd3cc8162,DISK], DatanodeInfoWithStorage[127.0.0.1:39416,DS-f1458f9f-2332-41e5-85a6-db502d26d551,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 1000m
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1993997779-172.17.0.7-1597717431375:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37660,DS-b9e8463c-e0a6-4c0b-b956-d88e731a0113,DISK], DatanodeInfoWithStorage[127.0.0.1:38448,DS-1edeac19-2e03-4019-be2e-0e360874fd14,DISK], DatanodeInfoWithStorage[127.0.0.1:42893,DS-f727a2af-6283-4d47-ae74-c5d9d4ae5755,DISK], DatanodeInfoWithStorage[127.0.0.1:40939,DS-ed5ce13a-9723-4ccf-a599-43a8aebfb48d,DISK], DatanodeInfoWithStorage[127.0.0.1:36891,DS-78a08e94-1f94-45e7-b9f7-dbd207a798d4,DISK], DatanodeInfoWithStorage[127.0.0.1:34669,DS-3fb51d28-577e-44ef-a385-3084385ffb12,DISK], DatanodeInfoWithStorage[127.0.0.1:38805,DS-9c6f7050-2e09-4409-a0b4-66f2d33e081f,DISK], DatanodeInfoWithStorage[127.0.0.1:36652,DS-547712b3-1200-4267-8fcc-809964fe996c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1993997779-172.17.0.7-1597717431375:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37660,DS-b9e8463c-e0a6-4c0b-b956-d88e731a0113,DISK], DatanodeInfoWithStorage[127.0.0.1:38448,DS-1edeac19-2e03-4019-be2e-0e360874fd14,DISK], DatanodeInfoWithStorage[127.0.0.1:42893,DS-f727a2af-6283-4d47-ae74-c5d9d4ae5755,DISK], DatanodeInfoWithStorage[127.0.0.1:40939,DS-ed5ce13a-9723-4ccf-a599-43a8aebfb48d,DISK], DatanodeInfoWithStorage[127.0.0.1:36891,DS-78a08e94-1f94-45e7-b9f7-dbd207a798d4,DISK], DatanodeInfoWithStorage[127.0.0.1:34669,DS-3fb51d28-577e-44ef-a385-3084385ffb12,DISK], DatanodeInfoWithStorage[127.0.0.1:38805,DS-9c6f7050-2e09-4409-a0b4-66f2d33e081f,DISK], DatanodeInfoWithStorage[127.0.0.1:36652,DS-547712b3-1200-4267-8fcc-809964fe996c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 1000m
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1618915725-172.17.0.7-1597717465115:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39975,DS-13d89983-7205-4b6a-8afa-632c101ab043,DISK], DatanodeInfoWithStorage[127.0.0.1:43061,DS-2c84f92e-527b-4288-b0af-3d46cdf8f1d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42499,DS-9e9bf0a5-877c-4613-be90-c096c3a045c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38294,DS-130bfeba-ce8e-40b5-b50d-0244bdcc36ec,DISK], DatanodeInfoWithStorage[127.0.0.1:43787,DS-1b718cc3-d8a9-4bf2-986d-0b893d171fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:34153,DS-e97546dd-bb9f-42a4-bfff-8e51bb01030c,DISK], DatanodeInfoWithStorage[127.0.0.1:33812,DS-efe86225-01ab-45d8-bf28-f9ebf1597e32,DISK], DatanodeInfoWithStorage[127.0.0.1:46845,DS-0a553936-c8cf-4df9-bbd2-f51b8a542739,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1618915725-172.17.0.7-1597717465115:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39975,DS-13d89983-7205-4b6a-8afa-632c101ab043,DISK], DatanodeInfoWithStorage[127.0.0.1:43061,DS-2c84f92e-527b-4288-b0af-3d46cdf8f1d3,DISK], DatanodeInfoWithStorage[127.0.0.1:42499,DS-9e9bf0a5-877c-4613-be90-c096c3a045c9,DISK], DatanodeInfoWithStorage[127.0.0.1:38294,DS-130bfeba-ce8e-40b5-b50d-0244bdcc36ec,DISK], DatanodeInfoWithStorage[127.0.0.1:43787,DS-1b718cc3-d8a9-4bf2-986d-0b893d171fd3,DISK], DatanodeInfoWithStorage[127.0.0.1:34153,DS-e97546dd-bb9f-42a4-bfff-8e51bb01030c,DISK], DatanodeInfoWithStorage[127.0.0.1:33812,DS-efe86225-01ab-45d8-bf28-f9ebf1597e32,DISK], DatanodeInfoWithStorage[127.0.0.1:46845,DS-0a553936-c8cf-4df9-bbd2-f51b8a542739,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 1000m
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2020271814-172.17.0.7-1597717821095:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40880,DS-79647b9b-37f2-4595-af14-94749ddbea38,DISK], DatanodeInfoWithStorage[127.0.0.1:45567,DS-3740bf07-2899-43f6-a8a7-f24481703171,DISK], DatanodeInfoWithStorage[127.0.0.1:33817,DS-6158102b-47b0-40bc-81ed-9301d8b918c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39517,DS-00586118-cc17-4565-9295-d5e2fdd44209,DISK], DatanodeInfoWithStorage[127.0.0.1:42323,DS-be849d80-cb0a-4c23-97cf-2650b8a42b38,DISK], DatanodeInfoWithStorage[127.0.0.1:35954,DS-d7ec816c-bca0-4d22-9dc9-cb8c82adc3ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43377,DS-42f08fc1-45c8-43f9-9947-774076c99416,DISK], DatanodeInfoWithStorage[127.0.0.1:37133,DS-91814e30-d2c4-4f73-adaa-bfdb7dece82e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2020271814-172.17.0.7-1597717821095:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40880,DS-79647b9b-37f2-4595-af14-94749ddbea38,DISK], DatanodeInfoWithStorage[127.0.0.1:45567,DS-3740bf07-2899-43f6-a8a7-f24481703171,DISK], DatanodeInfoWithStorage[127.0.0.1:33817,DS-6158102b-47b0-40bc-81ed-9301d8b918c2,DISK], DatanodeInfoWithStorage[127.0.0.1:39517,DS-00586118-cc17-4565-9295-d5e2fdd44209,DISK], DatanodeInfoWithStorage[127.0.0.1:42323,DS-be849d80-cb0a-4c23-97cf-2650b8a42b38,DISK], DatanodeInfoWithStorage[127.0.0.1:35954,DS-d7ec816c-bca0-4d22-9dc9-cb8c82adc3ea,DISK], DatanodeInfoWithStorage[127.0.0.1:43377,DS-42f08fc1-45c8-43f9-9947-774076c99416,DISK], DatanodeInfoWithStorage[127.0.0.1:37133,DS-91814e30-d2c4-4f73-adaa-bfdb7dece82e,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 1000m
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-802244341-172.17.0.7-1597718658088:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45340,DS-aa4e8021-9d40-4dec-959b-c687eb02fdf1,DISK], DatanodeInfoWithStorage[127.0.0.1:36752,DS-a27717f9-34e5-49cc-9435-20d6c12cc026,DISK], DatanodeInfoWithStorage[127.0.0.1:37601,DS-22e46318-e53d-41c5-9c4c-998217aa4a8c,DISK], DatanodeInfoWithStorage[127.0.0.1:35415,DS-973c59a4-a080-450e-9c44-d0daf604d0fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43710,DS-5a49aad9-ca5b-4242-b9cc-4fad1aa2bc61,DISK], DatanodeInfoWithStorage[127.0.0.1:46312,DS-982e0c81-2866-4dcf-9d9d-aa228e14b8bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38287,DS-c8d0fbd5-91d1-4dcc-b860-7e235831c833,DISK], DatanodeInfoWithStorage[127.0.0.1:37219,DS-e0d2ff6e-ba4c-4bab-8041-fc291fa1d27c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-802244341-172.17.0.7-1597718658088:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45340,DS-aa4e8021-9d40-4dec-959b-c687eb02fdf1,DISK], DatanodeInfoWithStorage[127.0.0.1:36752,DS-a27717f9-34e5-49cc-9435-20d6c12cc026,DISK], DatanodeInfoWithStorage[127.0.0.1:37601,DS-22e46318-e53d-41c5-9c4c-998217aa4a8c,DISK], DatanodeInfoWithStorage[127.0.0.1:35415,DS-973c59a4-a080-450e-9c44-d0daf604d0fa,DISK], DatanodeInfoWithStorage[127.0.0.1:43710,DS-5a49aad9-ca5b-4242-b9cc-4fad1aa2bc61,DISK], DatanodeInfoWithStorage[127.0.0.1:46312,DS-982e0c81-2866-4dcf-9d9d-aa228e14b8bd,DISK], DatanodeInfoWithStorage[127.0.0.1:38287,DS-c8d0fbd5-91d1-4dcc-b860-7e235831c833,DISK], DatanodeInfoWithStorage[127.0.0.1:37219,DS-e0d2ff6e-ba4c-4bab-8041-fc291fa1d27c,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 1000m
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1177243432-172.17.0.7-1597719601576:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44225,DS-d1da7ffd-92a6-4a16-bd16-d9f049ff6f2c,DISK], DatanodeInfoWithStorage[127.0.0.1:36349,DS-b2b2b16c-8485-40e7-a52d-2a53ebcf6349,DISK], DatanodeInfoWithStorage[127.0.0.1:34091,DS-19aba169-571a-4201-931b-41ba6c4e91d5,DISK], DatanodeInfoWithStorage[127.0.0.1:39624,DS-2df52f09-415b-435e-bcc2-d42a323b5813,DISK], DatanodeInfoWithStorage[127.0.0.1:46246,DS-71d66ec2-095c-4e38-b2b5-3f63d29abc67,DISK], DatanodeInfoWithStorage[127.0.0.1:43634,DS-b2ac4c14-0578-4651-b151-a3ccda25d0c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45632,DS-17abd630-6611-48e3-ac89-3d7a01b1b0e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35928,DS-1b0e8225-4817-4ef5-b927-d7d768b81844,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1177243432-172.17.0.7-1597719601576:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44225,DS-d1da7ffd-92a6-4a16-bd16-d9f049ff6f2c,DISK], DatanodeInfoWithStorage[127.0.0.1:36349,DS-b2b2b16c-8485-40e7-a52d-2a53ebcf6349,DISK], DatanodeInfoWithStorage[127.0.0.1:34091,DS-19aba169-571a-4201-931b-41ba6c4e91d5,DISK], DatanodeInfoWithStorage[127.0.0.1:39624,DS-2df52f09-415b-435e-bcc2-d42a323b5813,DISK], DatanodeInfoWithStorage[127.0.0.1:46246,DS-71d66ec2-095c-4e38-b2b5-3f63d29abc67,DISK], DatanodeInfoWithStorage[127.0.0.1:43634,DS-b2ac4c14-0578-4651-b151-a3ccda25d0c4,DISK], DatanodeInfoWithStorage[127.0.0.1:45632,DS-17abd630-6611-48e3-ac89-3d7a01b1b0e5,DISK], DatanodeInfoWithStorage[127.0.0.1:35928,DS-1b0e8225-4817-4ef5-b927-d7d768b81844,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 1000m
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1788121203-172.17.0.7-1597719710969:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34418,DS-ccbbd50d-a8f6-4882-9bac-b15bb98a5200,DISK], DatanodeInfoWithStorage[127.0.0.1:40485,DS-1a8beb30-e5bc-4d45-86b5-3f0c834808e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40030,DS-c0c12eef-66f3-4ecc-ac1b-3c2bc7d113e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44281,DS-919407ea-65d6-4b7c-86d4-cb4b2f2d69ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40463,DS-717547d2-c6e4-4be1-8188-1931f3326a33,DISK], DatanodeInfoWithStorage[127.0.0.1:42071,DS-024005d3-71a2-4273-be48-c8989d873cff,DISK], DatanodeInfoWithStorage[127.0.0.1:36076,DS-002bf932-1827-462b-85d7-422565df8734,DISK], DatanodeInfoWithStorage[127.0.0.1:40293,DS-5e1df2d5-1df3-4a3f-9717-4c87c7c5cbbd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1788121203-172.17.0.7-1597719710969:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34418,DS-ccbbd50d-a8f6-4882-9bac-b15bb98a5200,DISK], DatanodeInfoWithStorage[127.0.0.1:40485,DS-1a8beb30-e5bc-4d45-86b5-3f0c834808e8,DISK], DatanodeInfoWithStorage[127.0.0.1:40030,DS-c0c12eef-66f3-4ecc-ac1b-3c2bc7d113e3,DISK], DatanodeInfoWithStorage[127.0.0.1:44281,DS-919407ea-65d6-4b7c-86d4-cb4b2f2d69ea,DISK], DatanodeInfoWithStorage[127.0.0.1:40463,DS-717547d2-c6e4-4be1-8188-1931f3326a33,DISK], DatanodeInfoWithStorage[127.0.0.1:42071,DS-024005d3-71a2-4273-be48-c8989d873cff,DISK], DatanodeInfoWithStorage[127.0.0.1:36076,DS-002bf932-1827-462b-85d7-422565df8734,DISK], DatanodeInfoWithStorage[127.0.0.1:40293,DS-5e1df2d5-1df3-4a3f-9717-4c87c7c5cbbd,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 1000m
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-955913245-172.17.0.7-1597719854698:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45874,DS-7afa41bd-5b12-42a8-b654-f7be4ab6aafc,DISK], DatanodeInfoWithStorage[127.0.0.1:40676,DS-fb11da94-d795-48e3-8926-d50e86f2e5f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40151,DS-34aecb3d-08ba-452e-a57b-1a4017c32530,DISK], DatanodeInfoWithStorage[127.0.0.1:41266,DS-ae8a43cc-c8c5-4633-8c36-8d86ae4a5cf3,DISK], DatanodeInfoWithStorage[127.0.0.1:33914,DS-c84b64e6-8b42-4134-997b-1310c9493ecd,DISK], DatanodeInfoWithStorage[127.0.0.1:39591,DS-a7a33aab-058a-4127-ab16-6e356d098570,DISK], DatanodeInfoWithStorage[127.0.0.1:41283,DS-ebddd41b-4ff0-4ca7-aba1-08c05095976c,DISK], DatanodeInfoWithStorage[127.0.0.1:45674,DS-895c80d7-977d-4fbb-8a23-36e39d504c6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-955913245-172.17.0.7-1597719854698:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45874,DS-7afa41bd-5b12-42a8-b654-f7be4ab6aafc,DISK], DatanodeInfoWithStorage[127.0.0.1:40676,DS-fb11da94-d795-48e3-8926-d50e86f2e5f0,DISK], DatanodeInfoWithStorage[127.0.0.1:40151,DS-34aecb3d-08ba-452e-a57b-1a4017c32530,DISK], DatanodeInfoWithStorage[127.0.0.1:41266,DS-ae8a43cc-c8c5-4633-8c36-8d86ae4a5cf3,DISK], DatanodeInfoWithStorage[127.0.0.1:33914,DS-c84b64e6-8b42-4134-997b-1310c9493ecd,DISK], DatanodeInfoWithStorage[127.0.0.1:39591,DS-a7a33aab-058a-4127-ab16-6e356d098570,DISK], DatanodeInfoWithStorage[127.0.0.1:41283,DS-ebddd41b-4ff0-4ca7-aba1-08c05095976c,DISK], DatanodeInfoWithStorage[127.0.0.1:45674,DS-895c80d7-977d-4fbb-8a23-36e39d504c6a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 1000m
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-27418173-172.17.0.7-1597720385896:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34034,DS-59e84481-c136-4e8a-a871-91b94f8e6c51,DISK], DatanodeInfoWithStorage[127.0.0.1:41414,DS-57131ef7-627a-4cad-81f3-2666f4958964,DISK], DatanodeInfoWithStorage[127.0.0.1:41900,DS-2bebf6a4-8077-473c-90d7-f2ce0cfad14f,DISK], DatanodeInfoWithStorage[127.0.0.1:34727,DS-15766d56-233a-4f8b-9e7c-42710105d0d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43573,DS-3a77ecc9-9519-437c-bc00-ab21a6b23771,DISK], DatanodeInfoWithStorage[127.0.0.1:37174,DS-eed9c8d8-ca55-4f55-8f77-f0a59fe09160,DISK], DatanodeInfoWithStorage[127.0.0.1:44897,DS-54b8836d-d13c-4953-9930-762e65836502,DISK], DatanodeInfoWithStorage[127.0.0.1:33691,DS-c5090db0-70c1-4c42-a474-cc8918ee1dcf,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-27418173-172.17.0.7-1597720385896:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34034,DS-59e84481-c136-4e8a-a871-91b94f8e6c51,DISK], DatanodeInfoWithStorage[127.0.0.1:41414,DS-57131ef7-627a-4cad-81f3-2666f4958964,DISK], DatanodeInfoWithStorage[127.0.0.1:41900,DS-2bebf6a4-8077-473c-90d7-f2ce0cfad14f,DISK], DatanodeInfoWithStorage[127.0.0.1:34727,DS-15766d56-233a-4f8b-9e7c-42710105d0d9,DISK], DatanodeInfoWithStorage[127.0.0.1:43573,DS-3a77ecc9-9519-437c-bc00-ab21a6b23771,DISK], DatanodeInfoWithStorage[127.0.0.1:37174,DS-eed9c8d8-ca55-4f55-8f77-f0a59fe09160,DISK], DatanodeInfoWithStorage[127.0.0.1:44897,DS-54b8836d-d13c-4953-9930-762e65836502,DISK], DatanodeInfoWithStorage[127.0.0.1:33691,DS-c5090db0-70c1-4c42-a474-cc8918ee1dcf,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 1000m
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1293141765-172.17.0.7-1597720685897:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39479,DS-afd9958b-181e-405a-9e7b-5b01023cd90e,DISK], DatanodeInfoWithStorage[127.0.0.1:37831,DS-7039d7cb-4c8f-4c4c-bd2d-4c7f0dfe2018,DISK], DatanodeInfoWithStorage[127.0.0.1:46639,DS-666d795f-6074-4fd4-9cb1-61dfd0653216,DISK], DatanodeInfoWithStorage[127.0.0.1:45347,DS-75bc078a-12b3-4a5b-a9be-d8b56196f05c,DISK], DatanodeInfoWithStorage[127.0.0.1:45958,DS-774b9580-5fcd-45d1-ae30-38da79c257cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45091,DS-b4f5b4b9-e8fc-4911-b8f2-d2397d78e6c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35592,DS-81a27b58-7e4f-48b9-ac6e-c55b12e1f237,DISK], DatanodeInfoWithStorage[127.0.0.1:46196,DS-870d737a-7fdb-4b89-9324-2b91b674de5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1293141765-172.17.0.7-1597720685897:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39479,DS-afd9958b-181e-405a-9e7b-5b01023cd90e,DISK], DatanodeInfoWithStorage[127.0.0.1:37831,DS-7039d7cb-4c8f-4c4c-bd2d-4c7f0dfe2018,DISK], DatanodeInfoWithStorage[127.0.0.1:46639,DS-666d795f-6074-4fd4-9cb1-61dfd0653216,DISK], DatanodeInfoWithStorage[127.0.0.1:45347,DS-75bc078a-12b3-4a5b-a9be-d8b56196f05c,DISK], DatanodeInfoWithStorage[127.0.0.1:45958,DS-774b9580-5fcd-45d1-ae30-38da79c257cb,DISK], DatanodeInfoWithStorage[127.0.0.1:45091,DS-b4f5b4b9-e8fc-4911-b8f2-d2397d78e6c5,DISK], DatanodeInfoWithStorage[127.0.0.1:35592,DS-81a27b58-7e4f-48b9-ac6e-c55b12e1f237,DISK], DatanodeInfoWithStorage[127.0.0.1:46196,DS-870d737a-7fdb-4b89-9324-2b91b674de5b,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 1000m
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-957731475-172.17.0.7-1597720865147:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44268,DS-37853078-a4e9-42c0-aa87-32ac8686c220,DISK], DatanodeInfoWithStorage[127.0.0.1:34612,DS-e8c05a99-89fb-4f9e-84b9-9b1ff545db63,DISK], DatanodeInfoWithStorage[127.0.0.1:46296,DS-cc1c2cf4-c00b-462f-ab32-b2f7e53f923c,DISK], DatanodeInfoWithStorage[127.0.0.1:37747,DS-4a81a053-3161-49a5-b28a-16de7fd2a88d,DISK], DatanodeInfoWithStorage[127.0.0.1:40907,DS-d4de8bef-3b10-4025-954a-acec510fb0ed,DISK], DatanodeInfoWithStorage[127.0.0.1:45830,DS-6c524f8e-0c24-4c2b-93e4-7a3067390e06,DISK], DatanodeInfoWithStorage[127.0.0.1:44640,DS-ae669e2e-0ace-45df-b09d-95065400171d,DISK], DatanodeInfoWithStorage[127.0.0.1:39153,DS-3df697d6-aef4-4dfc-ae11-75ea11f822c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-957731475-172.17.0.7-1597720865147:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44268,DS-37853078-a4e9-42c0-aa87-32ac8686c220,DISK], DatanodeInfoWithStorage[127.0.0.1:34612,DS-e8c05a99-89fb-4f9e-84b9-9b1ff545db63,DISK], DatanodeInfoWithStorage[127.0.0.1:46296,DS-cc1c2cf4-c00b-462f-ab32-b2f7e53f923c,DISK], DatanodeInfoWithStorage[127.0.0.1:37747,DS-4a81a053-3161-49a5-b28a-16de7fd2a88d,DISK], DatanodeInfoWithStorage[127.0.0.1:40907,DS-d4de8bef-3b10-4025-954a-acec510fb0ed,DISK], DatanodeInfoWithStorage[127.0.0.1:45830,DS-6c524f8e-0c24-4c2b-93e4-7a3067390e06,DISK], DatanodeInfoWithStorage[127.0.0.1:44640,DS-ae669e2e-0ace-45df-b09d-95065400171d,DISK], DatanodeInfoWithStorage[127.0.0.1:39153,DS-3df697d6-aef4-4dfc-ae11-75ea11f822c4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.bp-ready.timeout
component: hdfs:DataNode
v1: 1000m
v2: 20
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksum#testStripedFileChecksumWithMissedDataBlocksRangeQuery6
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-287866675-172.17.0.7-1597721012068:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42614,DS-43ea889e-2900-4f56-9f93-3b840af6c9e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38479,DS-eeb69a1a-2160-41bc-bb4f-7897d7a9fb89,DISK], DatanodeInfoWithStorage[127.0.0.1:37047,DS-fa3dac1a-75eb-4454-8369-f1a99a90946a,DISK], DatanodeInfoWithStorage[127.0.0.1:41740,DS-907183be-ef7a-44f8-a819-c126eb0cff8c,DISK], DatanodeInfoWithStorage[127.0.0.1:34960,DS-56074b7a-faa5-4c30-b9aa-6eee6230dfa9,DISK], DatanodeInfoWithStorage[127.0.0.1:35967,DS-0245bdab-8f4f-4f6f-8fa1-d7c1ca087a59,DISK], DatanodeInfoWithStorage[127.0.0.1:43394,DS-ec2f98f6-f260-435c-a24f-4b493a818af6,DISK], DatanodeInfoWithStorage[127.0.0.1:39272,DS-8d53f6d5-e231-425e-918e-256d55b61c43,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-287866675-172.17.0.7-1597721012068:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42614,DS-43ea889e-2900-4f56-9f93-3b840af6c9e2,DISK], DatanodeInfoWithStorage[127.0.0.1:38479,DS-eeb69a1a-2160-41bc-bb4f-7897d7a9fb89,DISK], DatanodeInfoWithStorage[127.0.0.1:37047,DS-fa3dac1a-75eb-4454-8369-f1a99a90946a,DISK], DatanodeInfoWithStorage[127.0.0.1:41740,DS-907183be-ef7a-44f8-a819-c126eb0cff8c,DISK], DatanodeInfoWithStorage[127.0.0.1:34960,DS-56074b7a-faa5-4c30-b9aa-6eee6230dfa9,DISK], DatanodeInfoWithStorage[127.0.0.1:35967,DS-0245bdab-8f4f-4f6f-8fa1-d7c1ca087a59,DISK], DatanodeInfoWithStorage[127.0.0.1:43394,DS-ec2f98f6-f260-435c-a24f-4b493a818af6,DISK], DatanodeInfoWithStorage[127.0.0.1:39272,DS-8d53f6d5-e231-425e-918e-256d55b61c43,DISK]]; indices=[0, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery6(TestFileChecksum.java:366)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 9 out of 50
v1v1v2v2 failed with probability 15 out of 50
result: false positive !!!
Total execution time in seconds : 5602
