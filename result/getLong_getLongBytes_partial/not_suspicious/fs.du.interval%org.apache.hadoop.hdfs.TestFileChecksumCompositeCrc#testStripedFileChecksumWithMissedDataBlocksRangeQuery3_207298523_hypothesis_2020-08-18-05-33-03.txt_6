reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1440825443-172.17.0.14-1597728947709:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40407,DS-d245d05c-ea5e-4446-a63e-f1c120d23139,DISK], DatanodeInfoWithStorage[127.0.0.1:37540,DS-678c66a0-122d-4ffa-b1a6-83b65ad9d8e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35898,DS-ceb4327e-ab6d-4deb-85ea-47931d5f791b,DISK], DatanodeInfoWithStorage[127.0.0.1:42063,DS-943ba642-621c-4204-81ce-dac32b258608,DISK], DatanodeInfoWithStorage[127.0.0.1:41249,DS-b6d4e0be-1cbc-456b-86ad-bb0d24c9f1b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37967,DS-f73ebb62-a923-4078-9118-8b6467e2f1fb,DISK], DatanodeInfoWithStorage[127.0.0.1:33460,DS-737a4c2e-e84c-4d44-a05c-b051fe0d86a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41114,DS-0aea87c8-5b1b-43ba-acfa-ed06ecd2ffb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1440825443-172.17.0.14-1597728947709:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40407,DS-d245d05c-ea5e-4446-a63e-f1c120d23139,DISK], DatanodeInfoWithStorage[127.0.0.1:37540,DS-678c66a0-122d-4ffa-b1a6-83b65ad9d8e9,DISK], DatanodeInfoWithStorage[127.0.0.1:35898,DS-ceb4327e-ab6d-4deb-85ea-47931d5f791b,DISK], DatanodeInfoWithStorage[127.0.0.1:42063,DS-943ba642-621c-4204-81ce-dac32b258608,DISK], DatanodeInfoWithStorage[127.0.0.1:41249,DS-b6d4e0be-1cbc-456b-86ad-bb0d24c9f1b2,DISK], DatanodeInfoWithStorage[127.0.0.1:37967,DS-f73ebb62-a923-4078-9118-8b6467e2f1fb,DISK], DatanodeInfoWithStorage[127.0.0.1:33460,DS-737a4c2e-e84c-4d44-a05c-b051fe0d86a8,DISK], DatanodeInfoWithStorage[127.0.0.1:41114,DS-0aea87c8-5b1b-43ba-acfa-ed06ecd2ffb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1829669724-172.17.0.14-1597729322395:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38665,DS-fec97fea-8011-4292-9ea5-3980087bfa8d,DISK], DatanodeInfoWithStorage[127.0.0.1:35684,DS-e8a05061-326a-4ae8-aa0b-6043a37c6ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:35022,DS-8011276e-9fd2-4a69-8984-b4e6e2116cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:44017,DS-70589ca6-f414-4b36-a73d-dbe509379d56,DISK], DatanodeInfoWithStorage[127.0.0.1:38033,DS-574111f9-8cc1-46cc-bd84-8f7478ea9d96,DISK], DatanodeInfoWithStorage[127.0.0.1:33933,DS-03e2f6ff-de21-42d4-872d-b8b6fc340934,DISK], DatanodeInfoWithStorage[127.0.0.1:37110,DS-5b9235fd-095f-4c91-b23e-dcfbbd55d414,DISK], DatanodeInfoWithStorage[127.0.0.1:46336,DS-c9482e5c-a11a-4711-8158-f6b4e3646c50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1829669724-172.17.0.14-1597729322395:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38665,DS-fec97fea-8011-4292-9ea5-3980087bfa8d,DISK], DatanodeInfoWithStorage[127.0.0.1:35684,DS-e8a05061-326a-4ae8-aa0b-6043a37c6ef4,DISK], DatanodeInfoWithStorage[127.0.0.1:35022,DS-8011276e-9fd2-4a69-8984-b4e6e2116cb0,DISK], DatanodeInfoWithStorage[127.0.0.1:44017,DS-70589ca6-f414-4b36-a73d-dbe509379d56,DISK], DatanodeInfoWithStorage[127.0.0.1:38033,DS-574111f9-8cc1-46cc-bd84-8f7478ea9d96,DISK], DatanodeInfoWithStorage[127.0.0.1:33933,DS-03e2f6ff-de21-42d4-872d-b8b6fc340934,DISK], DatanodeInfoWithStorage[127.0.0.1:37110,DS-5b9235fd-095f-4c91-b23e-dcfbbd55d414,DISK], DatanodeInfoWithStorage[127.0.0.1:46336,DS-c9482e5c-a11a-4711-8158-f6b4e3646c50,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-614184799-172.17.0.14-1597729398224:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43898,DS-2a54a7ce-ae9c-448a-9d63-15fb067b11a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42921,DS-0ca2ac9d-1d51-45fa-a772-89cffe947b77,DISK], DatanodeInfoWithStorage[127.0.0.1:44844,DS-c4677250-75ff-483a-8ea5-0c4365e3d16a,DISK], DatanodeInfoWithStorage[127.0.0.1:37492,DS-d5fe84df-e071-4776-9df3-ea4d7ee752a9,DISK], DatanodeInfoWithStorage[127.0.0.1:34003,DS-e081d55f-af43-46ac-940b-07f2f3e4a68c,DISK], DatanodeInfoWithStorage[127.0.0.1:43328,DS-91a0d875-e439-4af6-97b1-8b73382f38a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34007,DS-113c3d2d-1e22-43e3-8a67-6f1570e44dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:32813,DS-81b87614-2a6c-4a95-9929-c843be60bd22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-614184799-172.17.0.14-1597729398224:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43898,DS-2a54a7ce-ae9c-448a-9d63-15fb067b11a3,DISK], DatanodeInfoWithStorage[127.0.0.1:42921,DS-0ca2ac9d-1d51-45fa-a772-89cffe947b77,DISK], DatanodeInfoWithStorage[127.0.0.1:44844,DS-c4677250-75ff-483a-8ea5-0c4365e3d16a,DISK], DatanodeInfoWithStorage[127.0.0.1:37492,DS-d5fe84df-e071-4776-9df3-ea4d7ee752a9,DISK], DatanodeInfoWithStorage[127.0.0.1:34003,DS-e081d55f-af43-46ac-940b-07f2f3e4a68c,DISK], DatanodeInfoWithStorage[127.0.0.1:43328,DS-91a0d875-e439-4af6-97b1-8b73382f38a6,DISK], DatanodeInfoWithStorage[127.0.0.1:34007,DS-113c3d2d-1e22-43e3-8a67-6f1570e44dbd,DISK], DatanodeInfoWithStorage[127.0.0.1:32813,DS-81b87614-2a6c-4a95-9929-c843be60bd22,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1182937344-172.17.0.14-1597729543972:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38546,DS-314cef2b-b0b2-44e1-828c-bb40cb104657,DISK], DatanodeInfoWithStorage[127.0.0.1:43193,DS-685f290b-1ac5-4251-902c-719ac8a76bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:40570,DS-e9f1f904-a7d1-4a1b-a802-c5fe10f73de8,DISK], DatanodeInfoWithStorage[127.0.0.1:38990,DS-6277162b-c56c-4309-9225-370e4b9151ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33079,DS-b0d251ec-f8df-4807-aa34-75bf709b7308,DISK], DatanodeInfoWithStorage[127.0.0.1:33988,DS-6a1bcd00-52ac-4553-8400-b72bc1392992,DISK], DatanodeInfoWithStorage[127.0.0.1:33013,DS-40781d8d-4280-40ae-af63-d623571904d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35419,DS-d4205229-8b9b-4f52-a55c-a4b7e926a3be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1182937344-172.17.0.14-1597729543972:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38546,DS-314cef2b-b0b2-44e1-828c-bb40cb104657,DISK], DatanodeInfoWithStorage[127.0.0.1:43193,DS-685f290b-1ac5-4251-902c-719ac8a76bcb,DISK], DatanodeInfoWithStorage[127.0.0.1:40570,DS-e9f1f904-a7d1-4a1b-a802-c5fe10f73de8,DISK], DatanodeInfoWithStorage[127.0.0.1:38990,DS-6277162b-c56c-4309-9225-370e4b9151ae,DISK], DatanodeInfoWithStorage[127.0.0.1:33079,DS-b0d251ec-f8df-4807-aa34-75bf709b7308,DISK], DatanodeInfoWithStorage[127.0.0.1:33988,DS-6a1bcd00-52ac-4553-8400-b72bc1392992,DISK], DatanodeInfoWithStorage[127.0.0.1:33013,DS-40781d8d-4280-40ae-af63-d623571904d6,DISK], DatanodeInfoWithStorage[127.0.0.1:35419,DS-d4205229-8b9b-4f52-a55c-a4b7e926a3be,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-942180340-172.17.0.14-1597730068785:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36464,DS-fb4e37dd-1c8d-4907-883c-c783972e96ce,DISK], DatanodeInfoWithStorage[127.0.0.1:35652,DS-c99943f5-ea3c-45d6-8d5e-c350155379bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37485,DS-e4f7193c-7000-4485-8b72-a4787332b829,DISK], DatanodeInfoWithStorage[127.0.0.1:37765,DS-0234c082-ca6a-4052-86cc-a8a410206cfb,DISK], DatanodeInfoWithStorage[127.0.0.1:43005,DS-fa12eb8a-6f16-4566-9d0d-f57475425fbb,DISK], DatanodeInfoWithStorage[127.0.0.1:46830,DS-e266f910-49b8-4ce0-9de6-c81577b39cef,DISK], DatanodeInfoWithStorage[127.0.0.1:35208,DS-b7809dd9-1214-443c-af7f-7203929a8e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:43860,DS-f0b39c37-5558-4b2c-8235-e07f66c96812,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-942180340-172.17.0.14-1597730068785:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36464,DS-fb4e37dd-1c8d-4907-883c-c783972e96ce,DISK], DatanodeInfoWithStorage[127.0.0.1:35652,DS-c99943f5-ea3c-45d6-8d5e-c350155379bf,DISK], DatanodeInfoWithStorage[127.0.0.1:37485,DS-e4f7193c-7000-4485-8b72-a4787332b829,DISK], DatanodeInfoWithStorage[127.0.0.1:37765,DS-0234c082-ca6a-4052-86cc-a8a410206cfb,DISK], DatanodeInfoWithStorage[127.0.0.1:43005,DS-fa12eb8a-6f16-4566-9d0d-f57475425fbb,DISK], DatanodeInfoWithStorage[127.0.0.1:46830,DS-e266f910-49b8-4ce0-9de6-c81577b39cef,DISK], DatanodeInfoWithStorage[127.0.0.1:35208,DS-b7809dd9-1214-443c-af7f-7203929a8e7d,DISK], DatanodeInfoWithStorage[127.0.0.1:43860,DS-f0b39c37-5558-4b2c-8235-e07f66c96812,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1526301503-172.17.0.14-1597730458442:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39067,DS-e6157431-16d4-4711-9837-5533206ccf4a,DISK], DatanodeInfoWithStorage[127.0.0.1:39482,DS-b9260d73-147e-4047-b32f-d7480ab4758a,DISK], DatanodeInfoWithStorage[127.0.0.1:41596,DS-cfb9776e-3e00-427d-bc16-4fa156ad56a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39926,DS-409a2aab-9162-4576-a7d5-19c78bf712d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45701,DS-b860386d-f02e-4bc1-9833-6380aed24c43,DISK], DatanodeInfoWithStorage[127.0.0.1:37994,DS-34aa9712-9068-4bbb-ac87-889bec5a49ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40597,DS-ce41d7e6-63bf-4873-a1b2-a8d8aa73351d,DISK], DatanodeInfoWithStorage[127.0.0.1:46098,DS-5d2f9cc3-f199-4e76-8f0d-2d1eca1bc30c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1526301503-172.17.0.14-1597730458442:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39067,DS-e6157431-16d4-4711-9837-5533206ccf4a,DISK], DatanodeInfoWithStorage[127.0.0.1:39482,DS-b9260d73-147e-4047-b32f-d7480ab4758a,DISK], DatanodeInfoWithStorage[127.0.0.1:41596,DS-cfb9776e-3e00-427d-bc16-4fa156ad56a5,DISK], DatanodeInfoWithStorage[127.0.0.1:39926,DS-409a2aab-9162-4576-a7d5-19c78bf712d4,DISK], DatanodeInfoWithStorage[127.0.0.1:45701,DS-b860386d-f02e-4bc1-9833-6380aed24c43,DISK], DatanodeInfoWithStorage[127.0.0.1:37994,DS-34aa9712-9068-4bbb-ac87-889bec5a49ed,DISK], DatanodeInfoWithStorage[127.0.0.1:40597,DS-ce41d7e6-63bf-4873-a1b2-a8d8aa73351d,DISK], DatanodeInfoWithStorage[127.0.0.1:46098,DS-5d2f9cc3-f199-4e76-8f0d-2d1eca1bc30c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-373352343-172.17.0.14-1597730606996:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39905,DS-a19b1faa-cc4f-4cab-a016-ea2cdc070f05,DISK], DatanodeInfoWithStorage[127.0.0.1:39297,DS-4b64348c-af29-4e3b-9914-d068bc78730e,DISK], DatanodeInfoWithStorage[127.0.0.1:34611,DS-da63dce3-162b-45ba-b770-753e663fbc07,DISK], DatanodeInfoWithStorage[127.0.0.1:37446,DS-f771fa11-7e96-4a13-bacf-a1a158d191eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46015,DS-164920e4-1de5-497d-96ad-7ae65e0d6779,DISK], DatanodeInfoWithStorage[127.0.0.1:38979,DS-21f5bc76-bb65-47e8-b360-00555d52d266,DISK], DatanodeInfoWithStorage[127.0.0.1:44371,DS-83b2463b-e426-4e5e-99f8-d610900fa6c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36722,DS-1638b947-4b81-4c48-98cd-5e966d6ee1fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-373352343-172.17.0.14-1597730606996:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39905,DS-a19b1faa-cc4f-4cab-a016-ea2cdc070f05,DISK], DatanodeInfoWithStorage[127.0.0.1:39297,DS-4b64348c-af29-4e3b-9914-d068bc78730e,DISK], DatanodeInfoWithStorage[127.0.0.1:34611,DS-da63dce3-162b-45ba-b770-753e663fbc07,DISK], DatanodeInfoWithStorage[127.0.0.1:37446,DS-f771fa11-7e96-4a13-bacf-a1a158d191eb,DISK], DatanodeInfoWithStorage[127.0.0.1:46015,DS-164920e4-1de5-497d-96ad-7ae65e0d6779,DISK], DatanodeInfoWithStorage[127.0.0.1:38979,DS-21f5bc76-bb65-47e8-b360-00555d52d266,DISK], DatanodeInfoWithStorage[127.0.0.1:44371,DS-83b2463b-e426-4e5e-99f8-d610900fa6c7,DISK], DatanodeInfoWithStorage[127.0.0.1:36722,DS-1638b947-4b81-4c48-98cd-5e966d6ee1fe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-897904338-172.17.0.14-1597730857490:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35868,DS-297c5c2f-59c5-48ad-a252-f195932edc2b,DISK], DatanodeInfoWithStorage[127.0.0.1:34100,DS-25084adc-2c73-47c1-b503-214697fd5bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:41271,DS-cf16e87a-4ddf-4d5d-a021-0e985fb35971,DISK], DatanodeInfoWithStorage[127.0.0.1:34662,DS-ceee797c-a2cc-44b2-bbbb-95ca21e4db97,DISK], DatanodeInfoWithStorage[127.0.0.1:45669,DS-bb350a34-ca3b-4eba-9577-c21d5a759ccf,DISK], DatanodeInfoWithStorage[127.0.0.1:45223,DS-c43db2c4-83fc-4f38-a457-983d1e7b890d,DISK], DatanodeInfoWithStorage[127.0.0.1:42502,DS-5ed1c533-46b2-4d50-a546-ecda1578cec3,DISK], DatanodeInfoWithStorage[127.0.0.1:42342,DS-3afb63b6-a5c1-4c2a-b5cc-654a8437b457,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-897904338-172.17.0.14-1597730857490:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35868,DS-297c5c2f-59c5-48ad-a252-f195932edc2b,DISK], DatanodeInfoWithStorage[127.0.0.1:34100,DS-25084adc-2c73-47c1-b503-214697fd5bcf,DISK], DatanodeInfoWithStorage[127.0.0.1:41271,DS-cf16e87a-4ddf-4d5d-a021-0e985fb35971,DISK], DatanodeInfoWithStorage[127.0.0.1:34662,DS-ceee797c-a2cc-44b2-bbbb-95ca21e4db97,DISK], DatanodeInfoWithStorage[127.0.0.1:45669,DS-bb350a34-ca3b-4eba-9577-c21d5a759ccf,DISK], DatanodeInfoWithStorage[127.0.0.1:45223,DS-c43db2c4-83fc-4f38-a457-983d1e7b890d,DISK], DatanodeInfoWithStorage[127.0.0.1:42502,DS-5ed1c533-46b2-4d50-a546-ecda1578cec3,DISK], DatanodeInfoWithStorage[127.0.0.1:42342,DS-3afb63b6-a5c1-4c2a-b5cc-654a8437b457,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-850311047-172.17.0.14-1597730893242:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44977,DS-8bf98777-1b0a-46ec-be4e-1040ae47180b,DISK], DatanodeInfoWithStorage[127.0.0.1:33056,DS-9fbab9cc-bd2e-4f5a-be99-310f22462fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:38151,DS-176ce55b-5d1d-4dc8-a25b-8bfb5ca16854,DISK], DatanodeInfoWithStorage[127.0.0.1:43441,DS-58ebe3b4-9ffb-4669-8880-904cbe52ca23,DISK], DatanodeInfoWithStorage[127.0.0.1:44903,DS-f8800fee-549c-4a9e-9019-bf5b61b4d41a,DISK], DatanodeInfoWithStorage[127.0.0.1:39977,DS-c8e064c3-13aa-47cc-af03-30da5d141c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:35593,DS-c20bd59b-500e-4b7e-9092-b16d58d67860,DISK], DatanodeInfoWithStorage[127.0.0.1:33953,DS-08ab9818-14e6-4ad7-9179-aca643668721,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-850311047-172.17.0.14-1597730893242:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44977,DS-8bf98777-1b0a-46ec-be4e-1040ae47180b,DISK], DatanodeInfoWithStorage[127.0.0.1:33056,DS-9fbab9cc-bd2e-4f5a-be99-310f22462fdb,DISK], DatanodeInfoWithStorage[127.0.0.1:38151,DS-176ce55b-5d1d-4dc8-a25b-8bfb5ca16854,DISK], DatanodeInfoWithStorage[127.0.0.1:43441,DS-58ebe3b4-9ffb-4669-8880-904cbe52ca23,DISK], DatanodeInfoWithStorage[127.0.0.1:44903,DS-f8800fee-549c-4a9e-9019-bf5b61b4d41a,DISK], DatanodeInfoWithStorage[127.0.0.1:39977,DS-c8e064c3-13aa-47cc-af03-30da5d141c3a,DISK], DatanodeInfoWithStorage[127.0.0.1:35593,DS-c20bd59b-500e-4b7e-9092-b16d58d67860,DISK], DatanodeInfoWithStorage[127.0.0.1:33953,DS-08ab9818-14e6-4ad7-9179-aca643668721,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-399164844-172.17.0.14-1597731123295:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44951,DS-062fdfb6-9a37-45ff-bba8-554c04d493df,DISK], DatanodeInfoWithStorage[127.0.0.1:34284,DS-b37b6c74-e35c-42d1-a628-4a410333fcc3,DISK], DatanodeInfoWithStorage[127.0.0.1:40754,DS-074df0ff-fecd-4409-a194-da6ae5810b3b,DISK], DatanodeInfoWithStorage[127.0.0.1:37100,DS-5abf6ea9-d48d-4f98-a886-d603ce8c23fd,DISK], DatanodeInfoWithStorage[127.0.0.1:32999,DS-7bd554e2-e907-4806-8a7a-dfbcecf7fd82,DISK], DatanodeInfoWithStorage[127.0.0.1:34050,DS-bb12e99c-5397-4aa6-88e0-20d6dc16eed0,DISK], DatanodeInfoWithStorage[127.0.0.1:43856,DS-20743ea8-d005-4c40-abc0-ff41fa510d0f,DISK], DatanodeInfoWithStorage[127.0.0.1:44406,DS-7125fe3a-3f0a-43a6-be24-f7ac9ad236e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-399164844-172.17.0.14-1597731123295:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44951,DS-062fdfb6-9a37-45ff-bba8-554c04d493df,DISK], DatanodeInfoWithStorage[127.0.0.1:34284,DS-b37b6c74-e35c-42d1-a628-4a410333fcc3,DISK], DatanodeInfoWithStorage[127.0.0.1:40754,DS-074df0ff-fecd-4409-a194-da6ae5810b3b,DISK], DatanodeInfoWithStorage[127.0.0.1:37100,DS-5abf6ea9-d48d-4f98-a886-d603ce8c23fd,DISK], DatanodeInfoWithStorage[127.0.0.1:32999,DS-7bd554e2-e907-4806-8a7a-dfbcecf7fd82,DISK], DatanodeInfoWithStorage[127.0.0.1:34050,DS-bb12e99c-5397-4aa6-88e0-20d6dc16eed0,DISK], DatanodeInfoWithStorage[127.0.0.1:43856,DS-20743ea8-d005-4c40-abc0-ff41fa510d0f,DISK], DatanodeInfoWithStorage[127.0.0.1:44406,DS-7125fe3a-3f0a-43a6-be24-f7ac9ad236e8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1118125252-172.17.0.14-1597731160850:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38911,DS-9c1c07a9-40fd-4956-9624-f856cb816c6b,DISK], DatanodeInfoWithStorage[127.0.0.1:33902,DS-37c2dd45-7d1a-4423-9f2b-ef46e633a60d,DISK], DatanodeInfoWithStorage[127.0.0.1:34404,DS-4984ae1c-1276-4bc3-8d56-ff6a9e916b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:36492,DS-5fb81a72-9ce9-4c7d-bdb1-780ad5af82e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41502,DS-492f0b7e-a9d4-43df-afe3-f7b86e0b1239,DISK], DatanodeInfoWithStorage[127.0.0.1:43150,DS-8da047ad-d6ee-479b-a59e-8c673138308d,DISK], DatanodeInfoWithStorage[127.0.0.1:44698,DS-8a6e910a-6854-43a5-8cc5-51334cdd1576,DISK], DatanodeInfoWithStorage[127.0.0.1:43637,DS-060d5a8a-7e35-4722-bce9-307cb7417ef2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1118125252-172.17.0.14-1597731160850:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38911,DS-9c1c07a9-40fd-4956-9624-f856cb816c6b,DISK], DatanodeInfoWithStorage[127.0.0.1:33902,DS-37c2dd45-7d1a-4423-9f2b-ef46e633a60d,DISK], DatanodeInfoWithStorage[127.0.0.1:34404,DS-4984ae1c-1276-4bc3-8d56-ff6a9e916b1f,DISK], DatanodeInfoWithStorage[127.0.0.1:36492,DS-5fb81a72-9ce9-4c7d-bdb1-780ad5af82e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41502,DS-492f0b7e-a9d4-43df-afe3-f7b86e0b1239,DISK], DatanodeInfoWithStorage[127.0.0.1:43150,DS-8da047ad-d6ee-479b-a59e-8c673138308d,DISK], DatanodeInfoWithStorage[127.0.0.1:44698,DS-8a6e910a-6854-43a5-8cc5-51334cdd1576,DISK], DatanodeInfoWithStorage[127.0.0.1:43637,DS-060d5a8a-7e35-4722-bce9-307cb7417ef2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-597991159-172.17.0.14-1597731491144:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41245,DS-94a85734-d381-40fc-aab8-978ce616d94e,DISK], DatanodeInfoWithStorage[127.0.0.1:41410,DS-51f95530-a4a1-43f6-a47b-cde815822cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:40112,DS-4fddcb99-5dba-4cce-8913-d0a158c642c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42245,DS-063143c6-39b7-4676-b95a-e54ac82cde2a,DISK], DatanodeInfoWithStorage[127.0.0.1:38957,DS-30f2829c-e0c1-404c-9422-7cedf2e33215,DISK], DatanodeInfoWithStorage[127.0.0.1:37483,DS-ad78ebe9-c173-4de4-a0af-400a7b04ea21,DISK], DatanodeInfoWithStorage[127.0.0.1:39530,DS-da7322b3-43f6-4182-9b9a-16647225b4b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35924,DS-907aaa05-3e7e-4199-bc46-782a56d82fbe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-597991159-172.17.0.14-1597731491144:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41245,DS-94a85734-d381-40fc-aab8-978ce616d94e,DISK], DatanodeInfoWithStorage[127.0.0.1:41410,DS-51f95530-a4a1-43f6-a47b-cde815822cbb,DISK], DatanodeInfoWithStorage[127.0.0.1:40112,DS-4fddcb99-5dba-4cce-8913-d0a158c642c7,DISK], DatanodeInfoWithStorage[127.0.0.1:42245,DS-063143c6-39b7-4676-b95a-e54ac82cde2a,DISK], DatanodeInfoWithStorage[127.0.0.1:38957,DS-30f2829c-e0c1-404c-9422-7cedf2e33215,DISK], DatanodeInfoWithStorage[127.0.0.1:37483,DS-ad78ebe9-c173-4de4-a0af-400a7b04ea21,DISK], DatanodeInfoWithStorage[127.0.0.1:39530,DS-da7322b3-43f6-4182-9b9a-16647225b4b3,DISK], DatanodeInfoWithStorage[127.0.0.1:35924,DS-907aaa05-3e7e-4199-bc46-782a56d82fbe,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1841594668-172.17.0.14-1597731530243:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38637,DS-ad0c0071-0e07-4eab-87a7-e864c7517619,DISK], DatanodeInfoWithStorage[127.0.0.1:33185,DS-0310eac0-91c4-402e-969a-08a0c94d74cc,DISK], DatanodeInfoWithStorage[127.0.0.1:40199,DS-9a754bbb-28fe-47d7-942b-52df83f290f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40392,DS-1cfa6fd1-e63c-4b2f-bc98-2c7f63199b53,DISK], DatanodeInfoWithStorage[127.0.0.1:46419,DS-f745664d-fe21-408d-b5a2-da16c78cf319,DISK], DatanodeInfoWithStorage[127.0.0.1:46756,DS-47f9305a-f512-4319-a60a-fedf6e9e6550,DISK], DatanodeInfoWithStorage[127.0.0.1:37192,DS-1eb53bd5-c916-47a5-954f-d0885dd439a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40674,DS-8c9268ac-9a4a-4eba-bac6-413bcda4aae3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1841594668-172.17.0.14-1597731530243:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38637,DS-ad0c0071-0e07-4eab-87a7-e864c7517619,DISK], DatanodeInfoWithStorage[127.0.0.1:33185,DS-0310eac0-91c4-402e-969a-08a0c94d74cc,DISK], DatanodeInfoWithStorage[127.0.0.1:40199,DS-9a754bbb-28fe-47d7-942b-52df83f290f6,DISK], DatanodeInfoWithStorage[127.0.0.1:40392,DS-1cfa6fd1-e63c-4b2f-bc98-2c7f63199b53,DISK], DatanodeInfoWithStorage[127.0.0.1:46419,DS-f745664d-fe21-408d-b5a2-da16c78cf319,DISK], DatanodeInfoWithStorage[127.0.0.1:46756,DS-47f9305a-f512-4319-a60a-fedf6e9e6550,DISK], DatanodeInfoWithStorage[127.0.0.1:37192,DS-1eb53bd5-c916-47a5-954f-d0885dd439a2,DISK], DatanodeInfoWithStorage[127.0.0.1:40674,DS-8c9268ac-9a4a-4eba-bac6-413bcda4aae3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1391046772-172.17.0.14-1597731678286:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38516,DS-1605100e-22e9-4e2d-8e6c-92aef99b613b,DISK], DatanodeInfoWithStorage[127.0.0.1:36619,DS-63b1525e-166b-49ad-b742-a074fa9a736f,DISK], DatanodeInfoWithStorage[127.0.0.1:44019,DS-556f3fde-44f3-48c8-b682-6223244e8c33,DISK], DatanodeInfoWithStorage[127.0.0.1:34112,DS-ab2ce397-4d77-4b99-9b71-9c61e74f739f,DISK], DatanodeInfoWithStorage[127.0.0.1:40322,DS-c3b0f5d9-5569-41ad-ab7e-38b3401c9b32,DISK], DatanodeInfoWithStorage[127.0.0.1:41150,DS-360abbd0-91ce-48ad-812c-bda878e6dab3,DISK], DatanodeInfoWithStorage[127.0.0.1:40326,DS-0cb1e498-5b2c-44df-8b31-f879954b8454,DISK], DatanodeInfoWithStorage[127.0.0.1:35473,DS-8eef722d-772c-49d8-8ac4-8b406109dace,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1391046772-172.17.0.14-1597731678286:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38516,DS-1605100e-22e9-4e2d-8e6c-92aef99b613b,DISK], DatanodeInfoWithStorage[127.0.0.1:36619,DS-63b1525e-166b-49ad-b742-a074fa9a736f,DISK], DatanodeInfoWithStorage[127.0.0.1:44019,DS-556f3fde-44f3-48c8-b682-6223244e8c33,DISK], DatanodeInfoWithStorage[127.0.0.1:34112,DS-ab2ce397-4d77-4b99-9b71-9c61e74f739f,DISK], DatanodeInfoWithStorage[127.0.0.1:40322,DS-c3b0f5d9-5569-41ad-ab7e-38b3401c9b32,DISK], DatanodeInfoWithStorage[127.0.0.1:41150,DS-360abbd0-91ce-48ad-812c-bda878e6dab3,DISK], DatanodeInfoWithStorage[127.0.0.1:40326,DS-0cb1e498-5b2c-44df-8b31-f879954b8454,DISK], DatanodeInfoWithStorage[127.0.0.1:35473,DS-8eef722d-772c-49d8-8ac4-8b406109dace,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1832955986-172.17.0.14-1597732346257:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45616,DS-5288758d-eb10-493b-8d96-39e66521a02f,DISK], DatanodeInfoWithStorage[127.0.0.1:39894,DS-823712cc-2049-4620-bc6c-aab846a21ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:33203,DS-35cd3f01-7d67-4710-bb71-e3ad163f30d3,DISK], DatanodeInfoWithStorage[127.0.0.1:43785,DS-f2a41192-da2d-4945-9907-a3e6f4f32411,DISK], DatanodeInfoWithStorage[127.0.0.1:42845,DS-aa5ae3b7-59ef-4ae3-80e9-0ed3cdae70fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42249,DS-11707884-7113-4da3-8033-0097d997195a,DISK], DatanodeInfoWithStorage[127.0.0.1:42003,DS-743750a0-9c72-4141-a701-0ef847e783ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35782,DS-0e576e52-8ea4-4b5a-80a4-3dbb177512ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1832955986-172.17.0.14-1597732346257:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45616,DS-5288758d-eb10-493b-8d96-39e66521a02f,DISK], DatanodeInfoWithStorage[127.0.0.1:39894,DS-823712cc-2049-4620-bc6c-aab846a21ae1,DISK], DatanodeInfoWithStorage[127.0.0.1:33203,DS-35cd3f01-7d67-4710-bb71-e3ad163f30d3,DISK], DatanodeInfoWithStorage[127.0.0.1:43785,DS-f2a41192-da2d-4945-9907-a3e6f4f32411,DISK], DatanodeInfoWithStorage[127.0.0.1:42845,DS-aa5ae3b7-59ef-4ae3-80e9-0ed3cdae70fc,DISK], DatanodeInfoWithStorage[127.0.0.1:42249,DS-11707884-7113-4da3-8033-0097d997195a,DISK], DatanodeInfoWithStorage[127.0.0.1:42003,DS-743750a0-9c72-4141-a701-0ef847e783ef,DISK], DatanodeInfoWithStorage[127.0.0.1:35782,DS-0e576e52-8ea4-4b5a-80a4-3dbb177512ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-124072421-172.17.0.14-1597732505737:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44103,DS-f48f8b34-9b31-41b4-a86e-407085bce4d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43158,DS-50afd97e-0093-43e1-b872-b29e74ab7e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:38958,DS-0bad10ef-ecc9-405c-8bad-8c1cda39f404,DISK], DatanodeInfoWithStorage[127.0.0.1:46715,DS-1d64594b-2e57-42eb-b208-09bcb14b3406,DISK], DatanodeInfoWithStorage[127.0.0.1:33820,DS-3dc23431-d2d7-429c-a781-a545114058b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36099,DS-002bfd1d-7b6b-40fa-ae5c-cb2d734e54ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34669,DS-55dcf2e3-0e99-4faa-af04-6723159a44b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36628,DS-df667e53-52f9-4a8e-806c-7edec583bfee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-124072421-172.17.0.14-1597732505737:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44103,DS-f48f8b34-9b31-41b4-a86e-407085bce4d7,DISK], DatanodeInfoWithStorage[127.0.0.1:43158,DS-50afd97e-0093-43e1-b872-b29e74ab7e3d,DISK], DatanodeInfoWithStorage[127.0.0.1:38958,DS-0bad10ef-ecc9-405c-8bad-8c1cda39f404,DISK], DatanodeInfoWithStorage[127.0.0.1:46715,DS-1d64594b-2e57-42eb-b208-09bcb14b3406,DISK], DatanodeInfoWithStorage[127.0.0.1:33820,DS-3dc23431-d2d7-429c-a781-a545114058b3,DISK], DatanodeInfoWithStorage[127.0.0.1:36099,DS-002bfd1d-7b6b-40fa-ae5c-cb2d734e54ad,DISK], DatanodeInfoWithStorage[127.0.0.1:34669,DS-55dcf2e3-0e99-4faa-af04-6723159a44b7,DISK], DatanodeInfoWithStorage[127.0.0.1:36628,DS-df667e53-52f9-4a8e-806c-7edec583bfee,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-484713176-172.17.0.14-1597732917421:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37516,DS-e9e7879c-28c6-4bec-ab59-8a399268a6c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43726,DS-e1184946-9b07-4a02-abab-1386324d500f,DISK], DatanodeInfoWithStorage[127.0.0.1:35477,DS-e2a737dd-9494-4b22-9a42-36e2f8e8b78d,DISK], DatanodeInfoWithStorage[127.0.0.1:33428,DS-bc6c1923-f8ac-4ad2-ba91-6105a1871d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:37597,DS-e8dc7b07-f8d8-45b8-ab3f-69e5230b6326,DISK], DatanodeInfoWithStorage[127.0.0.1:39360,DS-19e01598-1edb-4369-9ce0-71cfd7657d44,DISK], DatanodeInfoWithStorage[127.0.0.1:42790,DS-7168a5eb-f4a3-47e4-bf8e-d35e53996cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:33902,DS-bfebb092-61d0-4a9d-aaaa-ce656a4e7a8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-484713176-172.17.0.14-1597732917421:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37516,DS-e9e7879c-28c6-4bec-ab59-8a399268a6c3,DISK], DatanodeInfoWithStorage[127.0.0.1:43726,DS-e1184946-9b07-4a02-abab-1386324d500f,DISK], DatanodeInfoWithStorage[127.0.0.1:35477,DS-e2a737dd-9494-4b22-9a42-36e2f8e8b78d,DISK], DatanodeInfoWithStorage[127.0.0.1:33428,DS-bc6c1923-f8ac-4ad2-ba91-6105a1871d1d,DISK], DatanodeInfoWithStorage[127.0.0.1:37597,DS-e8dc7b07-f8d8-45b8-ab3f-69e5230b6326,DISK], DatanodeInfoWithStorage[127.0.0.1:39360,DS-19e01598-1edb-4369-9ce0-71cfd7657d44,DISK], DatanodeInfoWithStorage[127.0.0.1:42790,DS-7168a5eb-f4a3-47e4-bf8e-d35e53996cb8,DISK], DatanodeInfoWithStorage[127.0.0.1:33902,DS-bfebb092-61d0-4a9d-aaaa-ce656a4e7a8c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-209014317-172.17.0.14-1597732954278:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37676,DS-0de6efe8-9808-448a-a6cd-1e374f625a87,DISK], DatanodeInfoWithStorage[127.0.0.1:43790,DS-419b5cc8-8c32-4246-b25b-466eb88eb763,DISK], DatanodeInfoWithStorage[127.0.0.1:42644,DS-f88906ce-dfe1-4b6c-9c70-25438929828c,DISK], DatanodeInfoWithStorage[127.0.0.1:38121,DS-bb1983e1-d546-460f-b0ff-12c3a908121a,DISK], DatanodeInfoWithStorage[127.0.0.1:41974,DS-82cdf7a3-a500-446b-8eb5-c6deaa017b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:37484,DS-4545a43e-51f4-4be4-9b20-dabc41f3b1eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35531,DS-0623d0a3-d9a1-4f52-872d-de679b56e557,DISK], DatanodeInfoWithStorage[127.0.0.1:42898,DS-a914196d-5d84-4b4d-8793-0b0e53ef1d58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-209014317-172.17.0.14-1597732954278:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37676,DS-0de6efe8-9808-448a-a6cd-1e374f625a87,DISK], DatanodeInfoWithStorage[127.0.0.1:43790,DS-419b5cc8-8c32-4246-b25b-466eb88eb763,DISK], DatanodeInfoWithStorage[127.0.0.1:42644,DS-f88906ce-dfe1-4b6c-9c70-25438929828c,DISK], DatanodeInfoWithStorage[127.0.0.1:38121,DS-bb1983e1-d546-460f-b0ff-12c3a908121a,DISK], DatanodeInfoWithStorage[127.0.0.1:41974,DS-82cdf7a3-a500-446b-8eb5-c6deaa017b0b,DISK], DatanodeInfoWithStorage[127.0.0.1:37484,DS-4545a43e-51f4-4be4-9b20-dabc41f3b1eb,DISK], DatanodeInfoWithStorage[127.0.0.1:35531,DS-0623d0a3-d9a1-4f52-872d-de679b56e557,DISK], DatanodeInfoWithStorage[127.0.0.1:42898,DS-a914196d-5d84-4b4d-8793-0b0e53ef1d58,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1384316615-172.17.0.14-1597733799465:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36197,DS-e171302b-4da7-4bf6-9397-f3bf20adbd1f,DISK], DatanodeInfoWithStorage[127.0.0.1:39859,DS-c02974b3-0684-4efa-a622-370214d72620,DISK], DatanodeInfoWithStorage[127.0.0.1:40826,DS-1c37be98-1499-4c96-988f-a7bba114125f,DISK], DatanodeInfoWithStorage[127.0.0.1:41716,DS-1de93bf5-d2e2-4a55-be36-4fe129a41420,DISK], DatanodeInfoWithStorage[127.0.0.1:36891,DS-2d4c728c-071b-4910-b70b-3de334044ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:41426,DS-d540dc29-e9be-41c6-8e97-5caf5b4603b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34727,DS-c0c90753-6e6c-43f7-8d77-dac7ecd15f84,DISK], DatanodeInfoWithStorage[127.0.0.1:38896,DS-1d3d93fd-f936-4387-ae49-62b1d79f3838,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1384316615-172.17.0.14-1597733799465:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36197,DS-e171302b-4da7-4bf6-9397-f3bf20adbd1f,DISK], DatanodeInfoWithStorage[127.0.0.1:39859,DS-c02974b3-0684-4efa-a622-370214d72620,DISK], DatanodeInfoWithStorage[127.0.0.1:40826,DS-1c37be98-1499-4c96-988f-a7bba114125f,DISK], DatanodeInfoWithStorage[127.0.0.1:41716,DS-1de93bf5-d2e2-4a55-be36-4fe129a41420,DISK], DatanodeInfoWithStorage[127.0.0.1:36891,DS-2d4c728c-071b-4910-b70b-3de334044ba5,DISK], DatanodeInfoWithStorage[127.0.0.1:41426,DS-d540dc29-e9be-41c6-8e97-5caf5b4603b4,DISK], DatanodeInfoWithStorage[127.0.0.1:34727,DS-c0c90753-6e6c-43f7-8d77-dac7ecd15f84,DISK], DatanodeInfoWithStorage[127.0.0.1:38896,DS-1d3d93fd-f936-4387-ae49-62b1d79f3838,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-926005338-172.17.0.14-1597733913113:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46311,DS-d39b5edd-e0d5-46ea-940d-951305cdf9c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41222,DS-e39bf21b-9124-4d52-848b-10c661ae26a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41302,DS-9cf3217a-b63c-4ad0-9feb-e62391f0390b,DISK], DatanodeInfoWithStorage[127.0.0.1:37982,DS-89425a67-d4b5-4fb8-82d6-056f28c7aa5f,DISK], DatanodeInfoWithStorage[127.0.0.1:33165,DS-691cfdfe-7191-497a-b996-db36aaab0592,DISK], DatanodeInfoWithStorage[127.0.0.1:45101,DS-7181c10c-4ab8-40ee-abc1-50270c61e190,DISK], DatanodeInfoWithStorage[127.0.0.1:45091,DS-f293d187-606e-4c51-aeef-7b5f374c0704,DISK], DatanodeInfoWithStorage[127.0.0.1:40980,DS-1d693655-d534-408c-ac5a-8d7a60a6cf25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-926005338-172.17.0.14-1597733913113:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46311,DS-d39b5edd-e0d5-46ea-940d-951305cdf9c1,DISK], DatanodeInfoWithStorage[127.0.0.1:41222,DS-e39bf21b-9124-4d52-848b-10c661ae26a4,DISK], DatanodeInfoWithStorage[127.0.0.1:41302,DS-9cf3217a-b63c-4ad0-9feb-e62391f0390b,DISK], DatanodeInfoWithStorage[127.0.0.1:37982,DS-89425a67-d4b5-4fb8-82d6-056f28c7aa5f,DISK], DatanodeInfoWithStorage[127.0.0.1:33165,DS-691cfdfe-7191-497a-b996-db36aaab0592,DISK], DatanodeInfoWithStorage[127.0.0.1:45101,DS-7181c10c-4ab8-40ee-abc1-50270c61e190,DISK], DatanodeInfoWithStorage[127.0.0.1:45091,DS-f293d187-606e-4c51-aeef-7b5f374c0704,DISK], DatanodeInfoWithStorage[127.0.0.1:40980,DS-1d693655-d534-408c-ac5a-8d7a60a6cf25,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.du.interval
component: hdfs:DataNode
v1: 60000
v2: 600000
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery3
reconfPoint: -1
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-806760445-172.17.0.14-1597734064007:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40195,DS-e075f199-a60b-40af-a8da-279f41280aef,DISK], DatanodeInfoWithStorage[127.0.0.1:39092,DS-dde888bd-8cb4-45f0-ae6b-5af1252b9376,DISK], DatanodeInfoWithStorage[127.0.0.1:42651,DS-b4f39e46-5566-4cd3-b7c3-cda4ca57c0b8,DISK], DatanodeInfoWithStorage[127.0.0.1:36167,DS-b1bb3f4e-f164-4422-b49f-3a049ffe2a29,DISK], DatanodeInfoWithStorage[127.0.0.1:41239,DS-1dcab3f2-ae81-4647-9689-eaf69811a69e,DISK], DatanodeInfoWithStorage[127.0.0.1:38601,DS-f4e63bc7-8a78-4fa2-a390-27f6c2ac0b49,DISK], DatanodeInfoWithStorage[127.0.0.1:45976,DS-257e8c1b-da06-4f5b-b9d6-cdf8b2ce0916,DISK], DatanodeInfoWithStorage[127.0.0.1:45518,DS-a26e6896-23fa-4d59-bdb1-5e89aff6e821,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-806760445-172.17.0.14-1597734064007:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40195,DS-e075f199-a60b-40af-a8da-279f41280aef,DISK], DatanodeInfoWithStorage[127.0.0.1:39092,DS-dde888bd-8cb4-45f0-ae6b-5af1252b9376,DISK], DatanodeInfoWithStorage[127.0.0.1:42651,DS-b4f39e46-5566-4cd3-b7c3-cda4ca57c0b8,DISK], DatanodeInfoWithStorage[127.0.0.1:36167,DS-b1bb3f4e-f164-4422-b49f-3a049ffe2a29,DISK], DatanodeInfoWithStorage[127.0.0.1:41239,DS-1dcab3f2-ae81-4647-9689-eaf69811a69e,DISK], DatanodeInfoWithStorage[127.0.0.1:38601,DS-f4e63bc7-8a78-4fa2-a390-27f6c2ac0b49,DISK], DatanodeInfoWithStorage[127.0.0.1:45976,DS-257e8c1b-da06-4f5b-b9d6-cdf8b2ce0916,DISK], DatanodeInfoWithStorage[127.0.0.1:45518,DS-a26e6896-23fa-4d59-bdb1-5e89aff6e821,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery3(TestFileChecksum.java:333)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 3 out of 50
v1v1v2v2 failed with probability 16 out of 50
result: false positive !!!
Total execution time in seconds : 5621
