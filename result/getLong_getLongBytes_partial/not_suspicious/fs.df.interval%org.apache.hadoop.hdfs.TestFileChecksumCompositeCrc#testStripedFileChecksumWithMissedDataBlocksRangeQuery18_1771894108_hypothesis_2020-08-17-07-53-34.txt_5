reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1289035244-172.17.0.3-1597651287439:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44599,DS-7c3fb380-17fe-4e35-8510-9409ed57b87d,DISK], DatanodeInfoWithStorage[127.0.0.1:38556,DS-984d4e15-cb6a-4fe3-a183-33ee36ad78cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35719,DS-47b13838-e546-4691-a8c1-4b3c84ee32db,DISK], DatanodeInfoWithStorage[127.0.0.1:36518,DS-cf0316e8-8e84-42bb-896f-c84ff8579161,DISK], DatanodeInfoWithStorage[127.0.0.1:34365,DS-c36fbcf9-3036-41eb-b079-9d59e049b590,DISK], DatanodeInfoWithStorage[127.0.0.1:44884,DS-e56a367d-860b-452d-ad34-53963b84890a,DISK], DatanodeInfoWithStorage[127.0.0.1:36938,DS-fd542bd1-dc0d-4cf5-8b41-87656064486a,DISK], DatanodeInfoWithStorage[127.0.0.1:33337,DS-eeeee03d-be65-45f6-9fe1-23c99c1aaad2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1289035244-172.17.0.3-1597651287439:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44599,DS-7c3fb380-17fe-4e35-8510-9409ed57b87d,DISK], DatanodeInfoWithStorage[127.0.0.1:38556,DS-984d4e15-cb6a-4fe3-a183-33ee36ad78cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35719,DS-47b13838-e546-4691-a8c1-4b3c84ee32db,DISK], DatanodeInfoWithStorage[127.0.0.1:36518,DS-cf0316e8-8e84-42bb-896f-c84ff8579161,DISK], DatanodeInfoWithStorage[127.0.0.1:34365,DS-c36fbcf9-3036-41eb-b079-9d59e049b590,DISK], DatanodeInfoWithStorage[127.0.0.1:44884,DS-e56a367d-860b-452d-ad34-53963b84890a,DISK], DatanodeInfoWithStorage[127.0.0.1:36938,DS-fd542bd1-dc0d-4cf5-8b41-87656064486a,DISK], DatanodeInfoWithStorage[127.0.0.1:33337,DS-eeeee03d-be65-45f6-9fe1-23c99c1aaad2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-49840570-172.17.0.3-1597651546019:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41808,DS-598d05c9-caf0-4eb5-bc04-2d2bf4d85c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:33398,DS-3f537ee3-bc8a-4963-85f8-bf2d4c3e61c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36870,DS-921254f6-bb2f-4e5d-b2b0-ba4474d6eb7a,DISK], DatanodeInfoWithStorage[127.0.0.1:45050,DS-a16b4707-d56c-4d1a-ae4c-9ea5a0044d43,DISK], DatanodeInfoWithStorage[127.0.0.1:41532,DS-f2d336cc-0a52-4123-b023-71c673e9a1ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40143,DS-8e976219-de21-47ad-b658-24532553d98f,DISK], DatanodeInfoWithStorage[127.0.0.1:39562,DS-4069c259-504a-4ef1-95d2-577ea227773b,DISK], DatanodeInfoWithStorage[127.0.0.1:40783,DS-f60d374f-8915-4835-a7d0-c003a212939a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-49840570-172.17.0.3-1597651546019:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41808,DS-598d05c9-caf0-4eb5-bc04-2d2bf4d85c2a,DISK], DatanodeInfoWithStorage[127.0.0.1:33398,DS-3f537ee3-bc8a-4963-85f8-bf2d4c3e61c4,DISK], DatanodeInfoWithStorage[127.0.0.1:36870,DS-921254f6-bb2f-4e5d-b2b0-ba4474d6eb7a,DISK], DatanodeInfoWithStorage[127.0.0.1:45050,DS-a16b4707-d56c-4d1a-ae4c-9ea5a0044d43,DISK], DatanodeInfoWithStorage[127.0.0.1:41532,DS-f2d336cc-0a52-4123-b023-71c673e9a1ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40143,DS-8e976219-de21-47ad-b658-24532553d98f,DISK], DatanodeInfoWithStorage[127.0.0.1:39562,DS-4069c259-504a-4ef1-95d2-577ea227773b,DISK], DatanodeInfoWithStorage[127.0.0.1:40783,DS-f60d374f-8915-4835-a7d0-c003a212939a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-455250292-172.17.0.3-1597651622205:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38220,DS-22723446-0e16-4b8e-b79f-482109947862,DISK], DatanodeInfoWithStorage[127.0.0.1:33808,DS-b2a59a34-6b58-4288-bab0-099c305e90bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43895,DS-4813ec05-866a-42ef-8c5e-54396b40c509,DISK], DatanodeInfoWithStorage[127.0.0.1:38912,DS-72830d3d-6d19-4811-8387-001c21640d59,DISK], DatanodeInfoWithStorage[127.0.0.1:35764,DS-00a24d43-b83e-45e1-b0fa-efc225dc205b,DISK], DatanodeInfoWithStorage[127.0.0.1:39730,DS-63bbcb5c-e741-4477-9d7c-34b16431348c,DISK], DatanodeInfoWithStorage[127.0.0.1:44882,DS-e4b2fd80-0b0b-4432-bddb-6f8a36c91994,DISK], DatanodeInfoWithStorage[127.0.0.1:36752,DS-cf1833de-0c9e-406a-8911-ab8c7ec16434,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-455250292-172.17.0.3-1597651622205:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38220,DS-22723446-0e16-4b8e-b79f-482109947862,DISK], DatanodeInfoWithStorage[127.0.0.1:33808,DS-b2a59a34-6b58-4288-bab0-099c305e90bf,DISK], DatanodeInfoWithStorage[127.0.0.1:43895,DS-4813ec05-866a-42ef-8c5e-54396b40c509,DISK], DatanodeInfoWithStorage[127.0.0.1:38912,DS-72830d3d-6d19-4811-8387-001c21640d59,DISK], DatanodeInfoWithStorage[127.0.0.1:35764,DS-00a24d43-b83e-45e1-b0fa-efc225dc205b,DISK], DatanodeInfoWithStorage[127.0.0.1:39730,DS-63bbcb5c-e741-4477-9d7c-34b16431348c,DISK], DatanodeInfoWithStorage[127.0.0.1:44882,DS-e4b2fd80-0b0b-4432-bddb-6f8a36c91994,DISK], DatanodeInfoWithStorage[127.0.0.1:36752,DS-cf1833de-0c9e-406a-8911-ab8c7ec16434,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1539283929-172.17.0.3-1597651804056:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35370,DS-007cf773-8647-4f96-a9e3-fb08f2f43470,DISK], DatanodeInfoWithStorage[127.0.0.1:35240,DS-a0ac0b15-5cb2-4078-bc7d-5b6269595904,DISK], DatanodeInfoWithStorage[127.0.0.1:34987,DS-169020c2-ec27-46b9-b6c2-b38e8346d51f,DISK], DatanodeInfoWithStorage[127.0.0.1:45263,DS-5e03c920-f616-46d3-b0ae-c8b7834dc949,DISK], DatanodeInfoWithStorage[127.0.0.1:45268,DS-aa0c44a5-6773-4fea-a792-5973cc822cb1,DISK], DatanodeInfoWithStorage[127.0.0.1:38553,DS-6630bd15-0965-4038-b0d4-9e42057e50db,DISK], DatanodeInfoWithStorage[127.0.0.1:40496,DS-e608321a-f1a1-499c-9007-bfba4ff6c0c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40525,DS-2c961ec7-1f6f-4453-8aeb-e9819f7f2004,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1539283929-172.17.0.3-1597651804056:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35370,DS-007cf773-8647-4f96-a9e3-fb08f2f43470,DISK], DatanodeInfoWithStorage[127.0.0.1:35240,DS-a0ac0b15-5cb2-4078-bc7d-5b6269595904,DISK], DatanodeInfoWithStorage[127.0.0.1:34987,DS-169020c2-ec27-46b9-b6c2-b38e8346d51f,DISK], DatanodeInfoWithStorage[127.0.0.1:45263,DS-5e03c920-f616-46d3-b0ae-c8b7834dc949,DISK], DatanodeInfoWithStorage[127.0.0.1:45268,DS-aa0c44a5-6773-4fea-a792-5973cc822cb1,DISK], DatanodeInfoWithStorage[127.0.0.1:38553,DS-6630bd15-0965-4038-b0d4-9e42057e50db,DISK], DatanodeInfoWithStorage[127.0.0.1:40496,DS-e608321a-f1a1-499c-9007-bfba4ff6c0c0,DISK], DatanodeInfoWithStorage[127.0.0.1:40525,DS-2c961ec7-1f6f-4453-8aeb-e9819f7f2004,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1477325850-172.17.0.3-1597651955877:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35456,DS-130384e6-629d-4e6e-a045-2663a278c3f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40026,DS-ff90bc9a-988b-4f81-8ece-f2313fa9cd76,DISK], DatanodeInfoWithStorage[127.0.0.1:41076,DS-7a3eb196-f4cf-4991-a3d8-befa80d85fac,DISK], DatanodeInfoWithStorage[127.0.0.1:38105,DS-80858d52-02c2-4c18-bc10-50c507ba070a,DISK], DatanodeInfoWithStorage[127.0.0.1:44492,DS-9ce9c78f-1796-4258-97dc-627641948ead,DISK], DatanodeInfoWithStorage[127.0.0.1:43288,DS-01080208-01bf-4665-a2c9-3ecac9f443a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44626,DS-25566a84-e041-45c6-a67a-4b1535b0cede,DISK], DatanodeInfoWithStorage[127.0.0.1:39421,DS-c4fe1d2a-12a6-4580-98f4-207163c645f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1477325850-172.17.0.3-1597651955877:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35456,DS-130384e6-629d-4e6e-a045-2663a278c3f8,DISK], DatanodeInfoWithStorage[127.0.0.1:40026,DS-ff90bc9a-988b-4f81-8ece-f2313fa9cd76,DISK], DatanodeInfoWithStorage[127.0.0.1:41076,DS-7a3eb196-f4cf-4991-a3d8-befa80d85fac,DISK], DatanodeInfoWithStorage[127.0.0.1:38105,DS-80858d52-02c2-4c18-bc10-50c507ba070a,DISK], DatanodeInfoWithStorage[127.0.0.1:44492,DS-9ce9c78f-1796-4258-97dc-627641948ead,DISK], DatanodeInfoWithStorage[127.0.0.1:43288,DS-01080208-01bf-4665-a2c9-3ecac9f443a1,DISK], DatanodeInfoWithStorage[127.0.0.1:44626,DS-25566a84-e041-45c6-a67a-4b1535b0cede,DISK], DatanodeInfoWithStorage[127.0.0.1:39421,DS-c4fe1d2a-12a6-4580-98f4-207163c645f6,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1165028525-172.17.0.3-1597652026475:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35135,DS-d7706d7e-00c7-4aff-b053-cb1d2777ddd1,DISK], DatanodeInfoWithStorage[127.0.0.1:39149,DS-c4d5430c-07fe-436d-a8a7-4a3d51d90dd9,DISK], DatanodeInfoWithStorage[127.0.0.1:42702,DS-f7a6036f-945c-420f-86af-87aed76ce34e,DISK], DatanodeInfoWithStorage[127.0.0.1:35168,DS-810375ca-c8bf-4101-9799-a894b4ab3f85,DISK], DatanodeInfoWithStorage[127.0.0.1:46221,DS-2106267c-c562-4d58-adfa-776b20103a69,DISK], DatanodeInfoWithStorage[127.0.0.1:44534,DS-f489c5fb-7cce-40e2-b1df-a3c4cf8d0c26,DISK], DatanodeInfoWithStorage[127.0.0.1:42789,DS-ee7a19f3-7479-4c80-b2cb-0a41163f37e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37457,DS-6a19cd21-0db0-4b3d-a929-a78352c16e89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1165028525-172.17.0.3-1597652026475:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35135,DS-d7706d7e-00c7-4aff-b053-cb1d2777ddd1,DISK], DatanodeInfoWithStorage[127.0.0.1:39149,DS-c4d5430c-07fe-436d-a8a7-4a3d51d90dd9,DISK], DatanodeInfoWithStorage[127.0.0.1:42702,DS-f7a6036f-945c-420f-86af-87aed76ce34e,DISK], DatanodeInfoWithStorage[127.0.0.1:35168,DS-810375ca-c8bf-4101-9799-a894b4ab3f85,DISK], DatanodeInfoWithStorage[127.0.0.1:46221,DS-2106267c-c562-4d58-adfa-776b20103a69,DISK], DatanodeInfoWithStorage[127.0.0.1:44534,DS-f489c5fb-7cce-40e2-b1df-a3c4cf8d0c26,DISK], DatanodeInfoWithStorage[127.0.0.1:42789,DS-ee7a19f3-7479-4c80-b2cb-0a41163f37e7,DISK], DatanodeInfoWithStorage[127.0.0.1:37457,DS-6a19cd21-0db0-4b3d-a929-a78352c16e89,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1177398176-172.17.0.3-1597652103803:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43597,DS-9ea1e716-def5-4ce0-ab1e-349007a2d1ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40137,DS-03cce129-99dc-4399-a0e3-319a22aa29c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43852,DS-c6671990-5f2a-49c3-848f-d59b76f5fddc,DISK], DatanodeInfoWithStorage[127.0.0.1:45347,DS-af0a2bb6-c866-4172-bb57-ede555364183,DISK], DatanodeInfoWithStorage[127.0.0.1:46504,DS-614729fa-3174-40fc-8fdd-bf1725b9651b,DISK], DatanodeInfoWithStorage[127.0.0.1:42583,DS-732fae46-fbb2-41ce-83dd-db4e7bb9d386,DISK], DatanodeInfoWithStorage[127.0.0.1:44175,DS-57fb75ff-35d0-43b4-a7d3-c7cc640d3425,DISK], DatanodeInfoWithStorage[127.0.0.1:37657,DS-d32c9f1f-f653-4163-9ac0-020b139ea87c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1177398176-172.17.0.3-1597652103803:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43597,DS-9ea1e716-def5-4ce0-ab1e-349007a2d1ef,DISK], DatanodeInfoWithStorage[127.0.0.1:40137,DS-03cce129-99dc-4399-a0e3-319a22aa29c7,DISK], DatanodeInfoWithStorage[127.0.0.1:43852,DS-c6671990-5f2a-49c3-848f-d59b76f5fddc,DISK], DatanodeInfoWithStorage[127.0.0.1:45347,DS-af0a2bb6-c866-4172-bb57-ede555364183,DISK], DatanodeInfoWithStorage[127.0.0.1:46504,DS-614729fa-3174-40fc-8fdd-bf1725b9651b,DISK], DatanodeInfoWithStorage[127.0.0.1:42583,DS-732fae46-fbb2-41ce-83dd-db4e7bb9d386,DISK], DatanodeInfoWithStorage[127.0.0.1:44175,DS-57fb75ff-35d0-43b4-a7d3-c7cc640d3425,DISK], DatanodeInfoWithStorage[127.0.0.1:37657,DS-d32c9f1f-f653-4163-9ac0-020b139ea87c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1249455207-172.17.0.3-1597652216820:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43870,DS-da107305-5739-4fa2-834a-d9c6abf4c698,DISK], DatanodeInfoWithStorage[127.0.0.1:36422,DS-23527cc5-8c8b-4b13-970c-c7b2b33e6b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:40193,DS-8f1934d0-1e65-412f-b747-77ec8420e0d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40627,DS-fc7add64-3df4-4d01-85ef-fdae7562e911,DISK], DatanodeInfoWithStorage[127.0.0.1:46315,DS-593999bd-729b-486b-83d2-cd08c97406cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41654,DS-445484b6-ac3a-4359-ac68-886a01249f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:36683,DS-89504700-3277-4dcd-aaa8-e32f8b7fbfda,DISK], DatanodeInfoWithStorage[127.0.0.1:45975,DS-8942968d-b62b-4a5f-9c50-f21b29b10819,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1249455207-172.17.0.3-1597652216820:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43870,DS-da107305-5739-4fa2-834a-d9c6abf4c698,DISK], DatanodeInfoWithStorage[127.0.0.1:36422,DS-23527cc5-8c8b-4b13-970c-c7b2b33e6b1b,DISK], DatanodeInfoWithStorage[127.0.0.1:40193,DS-8f1934d0-1e65-412f-b747-77ec8420e0d6,DISK], DatanodeInfoWithStorage[127.0.0.1:40627,DS-fc7add64-3df4-4d01-85ef-fdae7562e911,DISK], DatanodeInfoWithStorage[127.0.0.1:46315,DS-593999bd-729b-486b-83d2-cd08c97406cb,DISK], DatanodeInfoWithStorage[127.0.0.1:41654,DS-445484b6-ac3a-4359-ac68-886a01249f6d,DISK], DatanodeInfoWithStorage[127.0.0.1:36683,DS-89504700-3277-4dcd-aaa8-e32f8b7fbfda,DISK], DatanodeInfoWithStorage[127.0.0.1:45975,DS-8942968d-b62b-4a5f-9c50-f21b29b10819,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1195302761-172.17.0.3-1597652289447:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35036,DS-1cd4c6cb-d6a8-4ff8-819d-893d2f1391e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33294,DS-6b7bafd5-2830-4ab0-a89f-aa14ec9d1966,DISK], DatanodeInfoWithStorage[127.0.0.1:38151,DS-712b1b9a-4fd0-4162-8b30-6bd405e6c22d,DISK], DatanodeInfoWithStorage[127.0.0.1:33049,DS-85721021-7a55-4d16-a8f8-9f5a7ff283cc,DISK], DatanodeInfoWithStorage[127.0.0.1:42757,DS-987296f6-fafc-4ee2-9cba-15e7d29bdf83,DISK], DatanodeInfoWithStorage[127.0.0.1:42665,DS-229232c8-4c89-4371-8825-3772f55cfc1f,DISK], DatanodeInfoWithStorage[127.0.0.1:45856,DS-2d3c9a16-8f2c-40f8-8986-cd1700306426,DISK], DatanodeInfoWithStorage[127.0.0.1:39137,DS-d4cd498d-0ec3-4c4a-b82b-c7879cd85b44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1195302761-172.17.0.3-1597652289447:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35036,DS-1cd4c6cb-d6a8-4ff8-819d-893d2f1391e0,DISK], DatanodeInfoWithStorage[127.0.0.1:33294,DS-6b7bafd5-2830-4ab0-a89f-aa14ec9d1966,DISK], DatanodeInfoWithStorage[127.0.0.1:38151,DS-712b1b9a-4fd0-4162-8b30-6bd405e6c22d,DISK], DatanodeInfoWithStorage[127.0.0.1:33049,DS-85721021-7a55-4d16-a8f8-9f5a7ff283cc,DISK], DatanodeInfoWithStorage[127.0.0.1:42757,DS-987296f6-fafc-4ee2-9cba-15e7d29bdf83,DISK], DatanodeInfoWithStorage[127.0.0.1:42665,DS-229232c8-4c89-4371-8825-3772f55cfc1f,DISK], DatanodeInfoWithStorage[127.0.0.1:45856,DS-2d3c9a16-8f2c-40f8-8986-cd1700306426,DISK], DatanodeInfoWithStorage[127.0.0.1:39137,DS-d4cd498d-0ec3-4c4a-b82b-c7879cd85b44,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1858105993-172.17.0.3-1597652322167:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43986,DS-f5559f1d-3df5-4558-89a4-50675b20f0a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35380,DS-5b1e4f85-16ab-4c4a-a7e9-6af98a8f505c,DISK], DatanodeInfoWithStorage[127.0.0.1:38803,DS-6d7dc6ce-1a9e-40bb-af5c-045afe7230e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41303,DS-f610170c-e805-4f3e-8ad9-5aad133f56ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41847,DS-dffa9b27-ce74-4c0d-89d5-8ad521586e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:43663,DS-46768154-b803-4d21-ac1c-251bbb5bee60,DISK], DatanodeInfoWithStorage[127.0.0.1:36688,DS-53839636-551a-46b8-a7d6-fc7e64ee79ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42730,DS-c853803a-0b10-4bf5-b135-bcc9b89ff7ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1858105993-172.17.0.3-1597652322167:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43986,DS-f5559f1d-3df5-4558-89a4-50675b20f0a6,DISK], DatanodeInfoWithStorage[127.0.0.1:35380,DS-5b1e4f85-16ab-4c4a-a7e9-6af98a8f505c,DISK], DatanodeInfoWithStorage[127.0.0.1:38803,DS-6d7dc6ce-1a9e-40bb-af5c-045afe7230e5,DISK], DatanodeInfoWithStorage[127.0.0.1:41303,DS-f610170c-e805-4f3e-8ad9-5aad133f56ae,DISK], DatanodeInfoWithStorage[127.0.0.1:41847,DS-dffa9b27-ce74-4c0d-89d5-8ad521586e5c,DISK], DatanodeInfoWithStorage[127.0.0.1:43663,DS-46768154-b803-4d21-ac1c-251bbb5bee60,DISK], DatanodeInfoWithStorage[127.0.0.1:36688,DS-53839636-551a-46b8-a7d6-fc7e64ee79ad,DISK], DatanodeInfoWithStorage[127.0.0.1:42730,DS-c853803a-0b10-4bf5-b135-bcc9b89ff7ca,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1330236909-172.17.0.3-1597652361003:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34348,DS-65257b33-95f3-4bd1-91ff-fd664d4c3bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:44505,DS-1d2601f9-38e5-450b-94af-99a03686cdcd,DISK], DatanodeInfoWithStorage[127.0.0.1:46680,DS-e027b708-6e80-45b2-b3cd-e4cc9a49099f,DISK], DatanodeInfoWithStorage[127.0.0.1:45407,DS-0409a9ee-f207-46b5-b36f-4857444d1e68,DISK], DatanodeInfoWithStorage[127.0.0.1:32964,DS-e6cb1e7c-9475-4ea5-a128-23ab092faeb7,DISK], DatanodeInfoWithStorage[127.0.0.1:35710,DS-4fc6c301-ba11-473d-8126-d175e62d28bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44660,DS-d946b373-b3ff-473d-8522-9a9d66bd6d8e,DISK], DatanodeInfoWithStorage[127.0.0.1:42490,DS-b6fdeb60-7c21-4b6b-95ab-7029eb8db208,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1330236909-172.17.0.3-1597652361003:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34348,DS-65257b33-95f3-4bd1-91ff-fd664d4c3bfa,DISK], DatanodeInfoWithStorage[127.0.0.1:44505,DS-1d2601f9-38e5-450b-94af-99a03686cdcd,DISK], DatanodeInfoWithStorage[127.0.0.1:46680,DS-e027b708-6e80-45b2-b3cd-e4cc9a49099f,DISK], DatanodeInfoWithStorage[127.0.0.1:45407,DS-0409a9ee-f207-46b5-b36f-4857444d1e68,DISK], DatanodeInfoWithStorage[127.0.0.1:32964,DS-e6cb1e7c-9475-4ea5-a128-23ab092faeb7,DISK], DatanodeInfoWithStorage[127.0.0.1:35710,DS-4fc6c301-ba11-473d-8126-d175e62d28bc,DISK], DatanodeInfoWithStorage[127.0.0.1:44660,DS-d946b373-b3ff-473d-8522-9a9d66bd6d8e,DISK], DatanodeInfoWithStorage[127.0.0.1:42490,DS-b6fdeb60-7c21-4b6b-95ab-7029eb8db208,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1152472356-172.17.0.3-1597652998602:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36904,DS-77698647-48be-41df-ad62-29106e1e2a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45656,DS-973ee842-67ab-4a75-acf9-642f19ba8bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:40309,DS-bf99f489-4082-40f0-965d-bcedb5ff739e,DISK], DatanodeInfoWithStorage[127.0.0.1:33305,DS-c292565d-c999-4ee6-87d6-e673ed4c1f87,DISK], DatanodeInfoWithStorage[127.0.0.1:41334,DS-e823fd6b-53a6-458b-b2bf-43764140bf1d,DISK], DatanodeInfoWithStorage[127.0.0.1:44413,DS-c3fc8837-574d-40e5-85ba-58682d9c4a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:45281,DS-f4eaab5f-32c7-4758-a0da-9ea724ce0628,DISK], DatanodeInfoWithStorage[127.0.0.1:40826,DS-3923f80e-119a-4bf3-b8f2-0117fd83a6ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1152472356-172.17.0.3-1597652998602:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36904,DS-77698647-48be-41df-ad62-29106e1e2a9c,DISK], DatanodeInfoWithStorage[127.0.0.1:45656,DS-973ee842-67ab-4a75-acf9-642f19ba8bdb,DISK], DatanodeInfoWithStorage[127.0.0.1:40309,DS-bf99f489-4082-40f0-965d-bcedb5ff739e,DISK], DatanodeInfoWithStorage[127.0.0.1:33305,DS-c292565d-c999-4ee6-87d6-e673ed4c1f87,DISK], DatanodeInfoWithStorage[127.0.0.1:41334,DS-e823fd6b-53a6-458b-b2bf-43764140bf1d,DISK], DatanodeInfoWithStorage[127.0.0.1:44413,DS-c3fc8837-574d-40e5-85ba-58682d9c4a1a,DISK], DatanodeInfoWithStorage[127.0.0.1:45281,DS-f4eaab5f-32c7-4758-a0da-9ea724ce0628,DISK], DatanodeInfoWithStorage[127.0.0.1:40826,DS-3923f80e-119a-4bf3-b8f2-0117fd83a6ad,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-325327949-172.17.0.3-1597653784292:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45130,DS-c5356cad-002b-494f-868a-fb92eacf569a,DISK], DatanodeInfoWithStorage[127.0.0.1:33064,DS-ed98697a-5d12-4602-9376-12ef32ca623e,DISK], DatanodeInfoWithStorage[127.0.0.1:37287,DS-e787ae85-97c0-41d7-88b3-5aeda9bb1f04,DISK], DatanodeInfoWithStorage[127.0.0.1:40715,DS-a6a0f7f6-08d9-4dd7-98de-8689efc2d86d,DISK], DatanodeInfoWithStorage[127.0.0.1:42365,DS-fb7eda51-54b0-43e8-ad4f-bda449504fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:39027,DS-48a56a54-7202-44df-85f5-5c58bcf09e20,DISK], DatanodeInfoWithStorage[127.0.0.1:42437,DS-beb6014e-5d9c-4c51-b8ea-313a6763b077,DISK], DatanodeInfoWithStorage[127.0.0.1:36265,DS-abbef39c-8c7e-474d-8b71-6abe62b08589,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-325327949-172.17.0.3-1597653784292:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45130,DS-c5356cad-002b-494f-868a-fb92eacf569a,DISK], DatanodeInfoWithStorage[127.0.0.1:33064,DS-ed98697a-5d12-4602-9376-12ef32ca623e,DISK], DatanodeInfoWithStorage[127.0.0.1:37287,DS-e787ae85-97c0-41d7-88b3-5aeda9bb1f04,DISK], DatanodeInfoWithStorage[127.0.0.1:40715,DS-a6a0f7f6-08d9-4dd7-98de-8689efc2d86d,DISK], DatanodeInfoWithStorage[127.0.0.1:42365,DS-fb7eda51-54b0-43e8-ad4f-bda449504fd5,DISK], DatanodeInfoWithStorage[127.0.0.1:39027,DS-48a56a54-7202-44df-85f5-5c58bcf09e20,DISK], DatanodeInfoWithStorage[127.0.0.1:42437,DS-beb6014e-5d9c-4c51-b8ea-313a6763b077,DISK], DatanodeInfoWithStorage[127.0.0.1:36265,DS-abbef39c-8c7e-474d-8b71-6abe62b08589,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1795735139-172.17.0.3-1597653890679:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37193,DS-69ddf5aa-65c4-4a07-98f3-1a63c114be6c,DISK], DatanodeInfoWithStorage[127.0.0.1:46751,DS-6c04ce4f-7ba6-4b41-bd01-9d5d4081d7f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43650,DS-2df89f85-a6e6-438a-bf32-10f5fd47ada1,DISK], DatanodeInfoWithStorage[127.0.0.1:33700,DS-f0d3b4d5-e8e2-4b09-9ecd-c3917df69d62,DISK], DatanodeInfoWithStorage[127.0.0.1:46419,DS-078bd008-38e6-4ad7-b0bf-4419c61192fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36070,DS-9e3af713-ae7b-4027-b016-625bcdf24531,DISK], DatanodeInfoWithStorage[127.0.0.1:38210,DS-5fa89221-14e5-4886-bc40-8987ce27db7c,DISK], DatanodeInfoWithStorage[127.0.0.1:39324,DS-57107e53-ceb0-44c3-a15f-d1114d36c781,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1795735139-172.17.0.3-1597653890679:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37193,DS-69ddf5aa-65c4-4a07-98f3-1a63c114be6c,DISK], DatanodeInfoWithStorage[127.0.0.1:46751,DS-6c04ce4f-7ba6-4b41-bd01-9d5d4081d7f5,DISK], DatanodeInfoWithStorage[127.0.0.1:43650,DS-2df89f85-a6e6-438a-bf32-10f5fd47ada1,DISK], DatanodeInfoWithStorage[127.0.0.1:33700,DS-f0d3b4d5-e8e2-4b09-9ecd-c3917df69d62,DISK], DatanodeInfoWithStorage[127.0.0.1:46419,DS-078bd008-38e6-4ad7-b0bf-4419c61192fd,DISK], DatanodeInfoWithStorage[127.0.0.1:36070,DS-9e3af713-ae7b-4027-b016-625bcdf24531,DISK], DatanodeInfoWithStorage[127.0.0.1:38210,DS-5fa89221-14e5-4886-bc40-8987ce27db7c,DISK], DatanodeInfoWithStorage[127.0.0.1:39324,DS-57107e53-ceb0-44c3-a15f-d1114d36c781,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2059924832-172.17.0.3-1597653967951:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38305,DS-6bc7fc47-9c28-4279-8c02-7c6573e5ab53,DISK], DatanodeInfoWithStorage[127.0.0.1:34678,DS-74d9d1f3-a325-4935-a64c-ab0d551e6203,DISK], DatanodeInfoWithStorage[127.0.0.1:43671,DS-08a012f0-1e8e-4676-aae1-1e223e9db7fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38320,DS-ce17f88a-71b3-4128-8899-b34f3a0c2c59,DISK], DatanodeInfoWithStorage[127.0.0.1:45850,DS-167953bd-e3e2-4598-9a72-6ccd5a70a825,DISK], DatanodeInfoWithStorage[127.0.0.1:33364,DS-80cf6a03-9a02-46d5-9fb3-8b9a21737715,DISK], DatanodeInfoWithStorage[127.0.0.1:45809,DS-e8e260c8-09a5-4ec2-9ffb-9a5b558fcb56,DISK], DatanodeInfoWithStorage[127.0.0.1:42804,DS-3dcc924d-81ff-494d-a70c-8da7e070c7ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2059924832-172.17.0.3-1597653967951:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38305,DS-6bc7fc47-9c28-4279-8c02-7c6573e5ab53,DISK], DatanodeInfoWithStorage[127.0.0.1:34678,DS-74d9d1f3-a325-4935-a64c-ab0d551e6203,DISK], DatanodeInfoWithStorage[127.0.0.1:43671,DS-08a012f0-1e8e-4676-aae1-1e223e9db7fc,DISK], DatanodeInfoWithStorage[127.0.0.1:38320,DS-ce17f88a-71b3-4128-8899-b34f3a0c2c59,DISK], DatanodeInfoWithStorage[127.0.0.1:45850,DS-167953bd-e3e2-4598-9a72-6ccd5a70a825,DISK], DatanodeInfoWithStorage[127.0.0.1:33364,DS-80cf6a03-9a02-46d5-9fb3-8b9a21737715,DISK], DatanodeInfoWithStorage[127.0.0.1:45809,DS-e8e260c8-09a5-4ec2-9ffb-9a5b558fcb56,DISK], DatanodeInfoWithStorage[127.0.0.1:42804,DS-3dcc924d-81ff-494d-a70c-8da7e070c7ff,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-881150447-172.17.0.3-1597654047699:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45103,DS-64010e47-3aa8-4347-b6c1-c8575f0df84a,DISK], DatanodeInfoWithStorage[127.0.0.1:38544,DS-d107aff9-f228-45d6-ad68-57281a993ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:46201,DS-26dc8cf6-0b2f-4e44-ae98-32b99714dfcf,DISK], DatanodeInfoWithStorage[127.0.0.1:36368,DS-a5477e4d-47f8-41e3-a44c-d9eef88e77da,DISK], DatanodeInfoWithStorage[127.0.0.1:42175,DS-f514ebe0-2978-4e8e-95d2-a78d5e34a034,DISK], DatanodeInfoWithStorage[127.0.0.1:38153,DS-8b60c162-824e-46b1-8233-9410af783319,DISK], DatanodeInfoWithStorage[127.0.0.1:40495,DS-430e9e17-5a19-473d-8c2b-d19a7ff8793c,DISK], DatanodeInfoWithStorage[127.0.0.1:36678,DS-1c6a1021-40c6-44be-aeb7-e035116be525,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-881150447-172.17.0.3-1597654047699:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45103,DS-64010e47-3aa8-4347-b6c1-c8575f0df84a,DISK], DatanodeInfoWithStorage[127.0.0.1:38544,DS-d107aff9-f228-45d6-ad68-57281a993ea3,DISK], DatanodeInfoWithStorage[127.0.0.1:46201,DS-26dc8cf6-0b2f-4e44-ae98-32b99714dfcf,DISK], DatanodeInfoWithStorage[127.0.0.1:36368,DS-a5477e4d-47f8-41e3-a44c-d9eef88e77da,DISK], DatanodeInfoWithStorage[127.0.0.1:42175,DS-f514ebe0-2978-4e8e-95d2-a78d5e34a034,DISK], DatanodeInfoWithStorage[127.0.0.1:38153,DS-8b60c162-824e-46b1-8233-9410af783319,DISK], DatanodeInfoWithStorage[127.0.0.1:40495,DS-430e9e17-5a19-473d-8c2b-d19a7ff8793c,DISK], DatanodeInfoWithStorage[127.0.0.1:36678,DS-1c6a1021-40c6-44be-aeb7-e035116be525,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-602317319-172.17.0.3-1597654486130:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43086,DS-eda4e450-2347-4dd4-8adc-21eba43f33ab,DISK], DatanodeInfoWithStorage[127.0.0.1:46130,DS-15861621-9ef7-49a0-99ed-15ae387b1691,DISK], DatanodeInfoWithStorage[127.0.0.1:34523,DS-21583690-a727-4132-8bf4-754aa93c67a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40484,DS-0dddf4b1-d43b-407d-9a02-face36a3bdef,DISK], DatanodeInfoWithStorage[127.0.0.1:37527,DS-809b8803-b37e-489d-a51e-119d6682f6bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35810,DS-289586b5-809f-450a-8fa0-4b0dbc843afd,DISK], DatanodeInfoWithStorage[127.0.0.1:46585,DS-594b49c4-b55d-4557-83a5-b34de46bda29,DISK], DatanodeInfoWithStorage[127.0.0.1:38072,DS-944e37f4-20d1-45de-a002-8f38a7f9b920,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-602317319-172.17.0.3-1597654486130:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43086,DS-eda4e450-2347-4dd4-8adc-21eba43f33ab,DISK], DatanodeInfoWithStorage[127.0.0.1:46130,DS-15861621-9ef7-49a0-99ed-15ae387b1691,DISK], DatanodeInfoWithStorage[127.0.0.1:34523,DS-21583690-a727-4132-8bf4-754aa93c67a7,DISK], DatanodeInfoWithStorage[127.0.0.1:40484,DS-0dddf4b1-d43b-407d-9a02-face36a3bdef,DISK], DatanodeInfoWithStorage[127.0.0.1:37527,DS-809b8803-b37e-489d-a51e-119d6682f6bb,DISK], DatanodeInfoWithStorage[127.0.0.1:35810,DS-289586b5-809f-450a-8fa0-4b0dbc843afd,DISK], DatanodeInfoWithStorage[127.0.0.1:46585,DS-594b49c4-b55d-4557-83a5-b34de46bda29,DISK], DatanodeInfoWithStorage[127.0.0.1:38072,DS-944e37f4-20d1-45de-a002-8f38a7f9b920,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-305947255-172.17.0.3-1597654522083:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44375,DS-128efcd2-e99f-45d2-b337-c910fbfefe74,DISK], DatanodeInfoWithStorage[127.0.0.1:40746,DS-7b11ee22-a617-49c1-8782-542824920086,DISK], DatanodeInfoWithStorage[127.0.0.1:45777,DS-d5323282-ebf6-4843-b6b8-e301510dc74d,DISK], DatanodeInfoWithStorage[127.0.0.1:35496,DS-cb47dbc0-4d00-4183-b7a5-63661a2be4f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46032,DS-4f069bc3-d54c-4189-8691-4ae5c77ed8f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41646,DS-edeb5d5a-7efb-44e9-8e66-4f2a2f90a103,DISK], DatanodeInfoWithStorage[127.0.0.1:42772,DS-f76b1219-0769-43c1-af8c-6946c9e213e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35402,DS-f6c71cec-c98d-45f5-84e3-d0c1ba9e7b68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-305947255-172.17.0.3-1597654522083:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44375,DS-128efcd2-e99f-45d2-b337-c910fbfefe74,DISK], DatanodeInfoWithStorage[127.0.0.1:40746,DS-7b11ee22-a617-49c1-8782-542824920086,DISK], DatanodeInfoWithStorage[127.0.0.1:45777,DS-d5323282-ebf6-4843-b6b8-e301510dc74d,DISK], DatanodeInfoWithStorage[127.0.0.1:35496,DS-cb47dbc0-4d00-4183-b7a5-63661a2be4f3,DISK], DatanodeInfoWithStorage[127.0.0.1:46032,DS-4f069bc3-d54c-4189-8691-4ae5c77ed8f3,DISK], DatanodeInfoWithStorage[127.0.0.1:41646,DS-edeb5d5a-7efb-44e9-8e66-4f2a2f90a103,DISK], DatanodeInfoWithStorage[127.0.0.1:42772,DS-f76b1219-0769-43c1-af8c-6946c9e213e8,DISK], DatanodeInfoWithStorage[127.0.0.1:35402,DS-f6c71cec-c98d-45f5-84e3-d0c1ba9e7b68,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1115761972-172.17.0.3-1597654748307:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43630,DS-9d8601c7-c299-447f-bd8c-5e0f8ff1b4cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35862,DS-eb01d167-acd2-4715-8936-8350afce21d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46007,DS-3cfb048c-cfe4-4a30-8319-ece405b5ebab,DISK], DatanodeInfoWithStorage[127.0.0.1:35224,DS-87e182a3-b1ce-4d95-bd76-b3302725b2d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43162,DS-1e93e87f-c3b0-4dda-8735-ed86a3417d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:44974,DS-c529fcbb-ea2d-4c37-a49c-7e5294bea3fb,DISK], DatanodeInfoWithStorage[127.0.0.1:43220,DS-4f747af4-fd60-43af-b437-34016ac73811,DISK], DatanodeInfoWithStorage[127.0.0.1:40956,DS-d7da760c-9153-4b7f-a102-476a3fc0ceb1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1115761972-172.17.0.3-1597654748307:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43630,DS-9d8601c7-c299-447f-bd8c-5e0f8ff1b4cf,DISK], DatanodeInfoWithStorage[127.0.0.1:35862,DS-eb01d167-acd2-4715-8936-8350afce21d7,DISK], DatanodeInfoWithStorage[127.0.0.1:46007,DS-3cfb048c-cfe4-4a30-8319-ece405b5ebab,DISK], DatanodeInfoWithStorage[127.0.0.1:35224,DS-87e182a3-b1ce-4d95-bd76-b3302725b2d4,DISK], DatanodeInfoWithStorage[127.0.0.1:43162,DS-1e93e87f-c3b0-4dda-8735-ed86a3417d3b,DISK], DatanodeInfoWithStorage[127.0.0.1:44974,DS-c529fcbb-ea2d-4c37-a49c-7e5294bea3fb,DISK], DatanodeInfoWithStorage[127.0.0.1:43220,DS-4f747af4-fd60-43af-b437-34016ac73811,DISK], DatanodeInfoWithStorage[127.0.0.1:40956,DS-d7da760c-9153-4b7f-a102-476a3fc0ceb1,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2140566091-172.17.0.3-1597654865882:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34431,DS-538c6700-eb8c-4144-a1e1-254f5e985e79,DISK], DatanodeInfoWithStorage[127.0.0.1:33003,DS-b2afe0bc-0c4e-4a67-b8c0-498551523683,DISK], DatanodeInfoWithStorage[127.0.0.1:33772,DS-23182efa-0a5c-416c-b51e-568873b06dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:41136,DS-402e0a4f-775e-4ebd-af6e-3e7f058607b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42602,DS-62d8e9d8-3cf2-467a-a697-2c21f6fdd290,DISK], DatanodeInfoWithStorage[127.0.0.1:38678,DS-fa4e55dd-2b29-4e20-b83c-e3950da3a0b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33021,DS-5e628dd2-cebd-439d-a375-a5335a681b69,DISK], DatanodeInfoWithStorage[127.0.0.1:45824,DS-46b1eac7-e1f1-4d3a-bf39-e957c8c4343d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2140566091-172.17.0.3-1597654865882:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34431,DS-538c6700-eb8c-4144-a1e1-254f5e985e79,DISK], DatanodeInfoWithStorage[127.0.0.1:33003,DS-b2afe0bc-0c4e-4a67-b8c0-498551523683,DISK], DatanodeInfoWithStorage[127.0.0.1:33772,DS-23182efa-0a5c-416c-b51e-568873b06dd2,DISK], DatanodeInfoWithStorage[127.0.0.1:41136,DS-402e0a4f-775e-4ebd-af6e-3e7f058607b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42602,DS-62d8e9d8-3cf2-467a-a697-2c21f6fdd290,DISK], DatanodeInfoWithStorage[127.0.0.1:38678,DS-fa4e55dd-2b29-4e20-b83c-e3950da3a0b3,DISK], DatanodeInfoWithStorage[127.0.0.1:33021,DS-5e628dd2-cebd-439d-a375-a5335a681b69,DISK], DatanodeInfoWithStorage[127.0.0.1:45824,DS-46b1eac7-e1f1-4d3a-bf39-e957c8c4343d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2130021396-172.17.0.3-1597655051465:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35003,DS-80babc8a-33cb-4b19-b46f-7e47456920df,DISK], DatanodeInfoWithStorage[127.0.0.1:43515,DS-509bd6d6-3c83-40ae-bac5-f84aa081d51e,DISK], DatanodeInfoWithStorage[127.0.0.1:34584,DS-f04a72f1-43b2-4b32-8388-eb0b72cd4ab1,DISK], DatanodeInfoWithStorage[127.0.0.1:34040,DS-a0a6577a-d3b5-4db8-a1e0-c1754f7f306b,DISK], DatanodeInfoWithStorage[127.0.0.1:33007,DS-1cf4a35b-2e06-45de-8a4f-84fc6ce193cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39928,DS-00354dd5-fe0f-4b72-8f93-63c250ffddcb,DISK], DatanodeInfoWithStorage[127.0.0.1:34068,DS-89674d0b-0c06-4d76-8fd3-ddf2537a97b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42804,DS-5c501e0e-a6df-4753-a32a-dbb37e899620,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-2130021396-172.17.0.3-1597655051465:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35003,DS-80babc8a-33cb-4b19-b46f-7e47456920df,DISK], DatanodeInfoWithStorage[127.0.0.1:43515,DS-509bd6d6-3c83-40ae-bac5-f84aa081d51e,DISK], DatanodeInfoWithStorage[127.0.0.1:34584,DS-f04a72f1-43b2-4b32-8388-eb0b72cd4ab1,DISK], DatanodeInfoWithStorage[127.0.0.1:34040,DS-a0a6577a-d3b5-4db8-a1e0-c1754f7f306b,DISK], DatanodeInfoWithStorage[127.0.0.1:33007,DS-1cf4a35b-2e06-45de-8a4f-84fc6ce193cf,DISK], DatanodeInfoWithStorage[127.0.0.1:39928,DS-00354dd5-fe0f-4b72-8f93-63c250ffddcb,DISK], DatanodeInfoWithStorage[127.0.0.1:34068,DS-89674d0b-0c06-4d76-8fd3-ddf2537a97b8,DISK], DatanodeInfoWithStorage[127.0.0.1:42804,DS-5c501e0e-a6df-4753-a32a-dbb37e899620,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-665521537-172.17.0.3-1597655163059:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33810,DS-3fad1762-9730-4fcf-845a-fbd6ca43b29e,DISK], DatanodeInfoWithStorage[127.0.0.1:44930,DS-2fcbdabf-8d8d-409f-937c-fec1953e759a,DISK], DatanodeInfoWithStorage[127.0.0.1:41179,DS-30750c39-8cbe-46e4-9a89-c84ffe844a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:43539,DS-dc729e4c-33e1-485c-94db-62929b5f9aee,DISK], DatanodeInfoWithStorage[127.0.0.1:35725,DS-5839958f-dc1e-475e-91da-d717ead60c50,DISK], DatanodeInfoWithStorage[127.0.0.1:34057,DS-76578174-f23d-472a-b88a-5dd0972d83df,DISK], DatanodeInfoWithStorage[127.0.0.1:45078,DS-be919ab9-0b4c-472e-9aa0-1aa9d00482a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44858,DS-60f639e3-154a-47aa-a1e6-98466c3ec04a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-665521537-172.17.0.3-1597655163059:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33810,DS-3fad1762-9730-4fcf-845a-fbd6ca43b29e,DISK], DatanodeInfoWithStorage[127.0.0.1:44930,DS-2fcbdabf-8d8d-409f-937c-fec1953e759a,DISK], DatanodeInfoWithStorage[127.0.0.1:41179,DS-30750c39-8cbe-46e4-9a89-c84ffe844a7f,DISK], DatanodeInfoWithStorage[127.0.0.1:43539,DS-dc729e4c-33e1-485c-94db-62929b5f9aee,DISK], DatanodeInfoWithStorage[127.0.0.1:35725,DS-5839958f-dc1e-475e-91da-d717ead60c50,DISK], DatanodeInfoWithStorage[127.0.0.1:34057,DS-76578174-f23d-472a-b88a-5dd0972d83df,DISK], DatanodeInfoWithStorage[127.0.0.1:45078,DS-be919ab9-0b4c-472e-9aa0-1aa9d00482a9,DISK], DatanodeInfoWithStorage[127.0.0.1:44858,DS-60f639e3-154a-47aa-a1e6-98466c3ec04a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1234741701-172.17.0.3-1597655491788:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36023,DS-07b2809a-920b-4e3c-9b0d-0ac9cb090b47,DISK], DatanodeInfoWithStorage[127.0.0.1:38250,DS-d231ce96-ee52-4c9b-8cda-fa4c2afd7cba,DISK], DatanodeInfoWithStorage[127.0.0.1:39616,DS-1a9c99a5-c4f4-4021-9b08-890ae0b7d379,DISK], DatanodeInfoWithStorage[127.0.0.1:35010,DS-9d226e07-ea50-4f8f-8f34-2915d0a2c11d,DISK], DatanodeInfoWithStorage[127.0.0.1:34077,DS-0c3dc63c-0e02-4790-b455-a12c824091eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44465,DS-1a8062eb-b312-4534-a571-c637cb431ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:43277,DS-9d7b8e00-50a2-46e4-9aa1-97eb150f35d0,DISK], DatanodeInfoWithStorage[127.0.0.1:37197,DS-9529ef5c-e967-4fb3-bcc3-89f37908aa18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1234741701-172.17.0.3-1597655491788:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:36023,DS-07b2809a-920b-4e3c-9b0d-0ac9cb090b47,DISK], DatanodeInfoWithStorage[127.0.0.1:38250,DS-d231ce96-ee52-4c9b-8cda-fa4c2afd7cba,DISK], DatanodeInfoWithStorage[127.0.0.1:39616,DS-1a9c99a5-c4f4-4021-9b08-890ae0b7d379,DISK], DatanodeInfoWithStorage[127.0.0.1:35010,DS-9d226e07-ea50-4f8f-8f34-2915d0a2c11d,DISK], DatanodeInfoWithStorage[127.0.0.1:34077,DS-0c3dc63c-0e02-4790-b455-a12c824091eb,DISK], DatanodeInfoWithStorage[127.0.0.1:44465,DS-1a8062eb-b312-4534-a571-c637cb431ff9,DISK], DatanodeInfoWithStorage[127.0.0.1:43277,DS-9d7b8e00-50a2-46e4-9aa1-97eb150f35d0,DISK], DatanodeInfoWithStorage[127.0.0.1:37197,DS-9529ef5c-e967-4fb3-bcc3-89f37908aa18,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-851197354-172.17.0.3-1597656044166:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35018,DS-035e254e-6154-45c4-afd0-d6abab0826de,DISK], DatanodeInfoWithStorage[127.0.0.1:34930,DS-5ebf8263-b52c-4fbe-ac7d-7e20817e55f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43658,DS-f943cb0f-3d84-47e8-8630-a2fb4cc6ae3b,DISK], DatanodeInfoWithStorage[127.0.0.1:33540,DS-8f88b506-87ca-4634-abbd-5180689129db,DISK], DatanodeInfoWithStorage[127.0.0.1:33658,DS-1f6cc9c5-89cd-41e2-8e07-c1eb21a9632c,DISK], DatanodeInfoWithStorage[127.0.0.1:36606,DS-79ea45fe-51c8-4b52-a71b-d7bb4bc47e8a,DISK], DatanodeInfoWithStorage[127.0.0.1:42416,DS-be1057f4-b295-44a2-a9b6-f7cc0b36dbf5,DISK], DatanodeInfoWithStorage[127.0.0.1:38865,DS-907c9e7d-9fc9-4138-b55d-03dc2faa4f6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-851197354-172.17.0.3-1597656044166:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35018,DS-035e254e-6154-45c4-afd0-d6abab0826de,DISK], DatanodeInfoWithStorage[127.0.0.1:34930,DS-5ebf8263-b52c-4fbe-ac7d-7e20817e55f3,DISK], DatanodeInfoWithStorage[127.0.0.1:43658,DS-f943cb0f-3d84-47e8-8630-a2fb4cc6ae3b,DISK], DatanodeInfoWithStorage[127.0.0.1:33540,DS-8f88b506-87ca-4634-abbd-5180689129db,DISK], DatanodeInfoWithStorage[127.0.0.1:33658,DS-1f6cc9c5-89cd-41e2-8e07-c1eb21a9632c,DISK], DatanodeInfoWithStorage[127.0.0.1:36606,DS-79ea45fe-51c8-4b52-a71b-d7bb4bc47e8a,DISK], DatanodeInfoWithStorage[127.0.0.1:42416,DS-be1057f4-b295-44a2-a9b6-f7cc0b36dbf5,DISK], DatanodeInfoWithStorage[127.0.0.1:38865,DS-907c9e7d-9fc9-4138-b55d-03dc2faa4f6e,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: fs.df.interval
component: hdfs:NameNode
v1: 60000
v2: 60
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery18
reconfPoint: 1
result: -1
failureMessage: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1610565980-172.17.0.3-1597656198217:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44955,DS-0b5da703-0f82-4bfe-9956-90c70ae192b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46501,DS-7a5d4ae0-c803-4142-8de7-464d63c51335,DISK], DatanodeInfoWithStorage[127.0.0.1:37369,DS-598d0357-79eb-497a-a67a-9dcab1796b52,DISK], DatanodeInfoWithStorage[127.0.0.1:42330,DS-b8b76b63-3638-4569-b99a-758dca5f002b,DISK], DatanodeInfoWithStorage[127.0.0.1:33210,DS-7f69582f-b4f9-4c67-9951-377dcf939d17,DISK], DatanodeInfoWithStorage[127.0.0.1:33239,DS-5af85d17-f47b-4fd5-bed7-905bf81bcb3d,DISK], DatanodeInfoWithStorage[127.0.0.1:35402,DS-4ea6d368-8324-485a-bde4-fad290d5f10f,DISK], DatanodeInfoWithStorage[127.0.0.1:35103,DS-3ff238fd-67cf-449b-b7d9-7f9f6b821e88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum3': Fail to get block checksum for LocatedStripedBlock{BP-1610565980-172.17.0.3-1597656198217:blk_-9223372036854775776_1002; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44955,DS-0b5da703-0f82-4bfe-9956-90c70ae192b7,DISK], DatanodeInfoWithStorage[127.0.0.1:46501,DS-7a5d4ae0-c803-4142-8de7-464d63c51335,DISK], DatanodeInfoWithStorage[127.0.0.1:37369,DS-598d0357-79eb-497a-a67a-9dcab1796b52,DISK], DatanodeInfoWithStorage[127.0.0.1:42330,DS-b8b76b63-3638-4569-b99a-758dca5f002b,DISK], DatanodeInfoWithStorage[127.0.0.1:33210,DS-7f69582f-b4f9-4c67-9951-377dcf939d17,DISK], DatanodeInfoWithStorage[127.0.0.1:33239,DS-5af85d17-f47b-4fd5-bed7-905bf81bcb3d,DISK], DatanodeInfoWithStorage[127.0.0.1:35402,DS-4ea6d368-8324-485a-bde4-fad290d5f10f,DISK], DatanodeInfoWithStorage[127.0.0.1:35103,DS-3ff238fd-67cf-449b-b7d9-7f9f6b821e88,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery18(TestFileChecksum.java:506)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 10 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5542
