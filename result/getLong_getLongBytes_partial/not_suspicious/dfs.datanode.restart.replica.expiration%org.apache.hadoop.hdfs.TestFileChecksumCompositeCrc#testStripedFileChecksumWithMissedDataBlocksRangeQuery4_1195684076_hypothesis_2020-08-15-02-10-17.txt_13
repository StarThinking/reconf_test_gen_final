reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 60
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 60
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1559385337-172.17.0.13-1597457435648:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44554,DS-6db13011-06b1-4111-a82b-c6a9ae5f1c57,DISK], DatanodeInfoWithStorage[127.0.0.1:40614,DS-1241f132-1272-4eb9-873a-50440cbcd5ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34979,DS-d3b432c1-c200-4dbe-bd5c-efd6420d875a,DISK], DatanodeInfoWithStorage[127.0.0.1:46506,DS-a9af62a9-3ec4-426d-9bef-f6742634acf0,DISK], DatanodeInfoWithStorage[127.0.0.1:46078,DS-d76feb52-da55-4b83-a902-c9fb68c2137e,DISK], DatanodeInfoWithStorage[127.0.0.1:37544,DS-87f1cd24-12cb-4bcc-82d6-5225809e9f3a,DISK], DatanodeInfoWithStorage[127.0.0.1:38188,DS-3d89df4a-d07a-400c-83ed-0005d5b6910f,DISK], DatanodeInfoWithStorage[127.0.0.1:39879,DS-56be90cc-16f2-4327-a84e-2db5bcb8c4c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1559385337-172.17.0.13-1597457435648:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44554,DS-6db13011-06b1-4111-a82b-c6a9ae5f1c57,DISK], DatanodeInfoWithStorage[127.0.0.1:40614,DS-1241f132-1272-4eb9-873a-50440cbcd5ee,DISK], DatanodeInfoWithStorage[127.0.0.1:34979,DS-d3b432c1-c200-4dbe-bd5c-efd6420d875a,DISK], DatanodeInfoWithStorage[127.0.0.1:46506,DS-a9af62a9-3ec4-426d-9bef-f6742634acf0,DISK], DatanodeInfoWithStorage[127.0.0.1:46078,DS-d76feb52-da55-4b83-a902-c9fb68c2137e,DISK], DatanodeInfoWithStorage[127.0.0.1:37544,DS-87f1cd24-12cb-4bcc-82d6-5225809e9f3a,DISK], DatanodeInfoWithStorage[127.0.0.1:38188,DS-3d89df4a-d07a-400c-83ed-0005d5b6910f,DISK], DatanodeInfoWithStorage[127.0.0.1:39879,DS-56be90cc-16f2-4327-a84e-2db5bcb8c4c9,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 60
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-47683811-172.17.0.13-1597458554702:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40620,DS-194c59ab-49d0-4b29-88b0-c5c98d62e815,DISK], DatanodeInfoWithStorage[127.0.0.1:39307,DS-9ef5091f-0f68-4464-ad43-15940c5d03d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35273,DS-859ff0a0-c53e-4027-ac75-4264c0f03347,DISK], DatanodeInfoWithStorage[127.0.0.1:39221,DS-08e5d513-1b26-477b-9c77-58b42e28fec9,DISK], DatanodeInfoWithStorage[127.0.0.1:42253,DS-c003d161-91b4-4966-bf71-b2ed72714a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:42411,DS-517ed21a-2f9a-4d9c-be4d-e3641c15a0d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38024,DS-74270119-c5ca-4c8f-9be8-6705b3f32784,DISK], DatanodeInfoWithStorage[127.0.0.1:45690,DS-089d6c0f-4e86-4f42-b26d-0969dec07467,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-47683811-172.17.0.13-1597458554702:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40620,DS-194c59ab-49d0-4b29-88b0-c5c98d62e815,DISK], DatanodeInfoWithStorage[127.0.0.1:39307,DS-9ef5091f-0f68-4464-ad43-15940c5d03d1,DISK], DatanodeInfoWithStorage[127.0.0.1:35273,DS-859ff0a0-c53e-4027-ac75-4264c0f03347,DISK], DatanodeInfoWithStorage[127.0.0.1:39221,DS-08e5d513-1b26-477b-9c77-58b42e28fec9,DISK], DatanodeInfoWithStorage[127.0.0.1:42253,DS-c003d161-91b4-4966-bf71-b2ed72714a3a,DISK], DatanodeInfoWithStorage[127.0.0.1:42411,DS-517ed21a-2f9a-4d9c-be4d-e3641c15a0d1,DISK], DatanodeInfoWithStorage[127.0.0.1:38024,DS-74270119-c5ca-4c8f-9be8-6705b3f32784,DISK], DatanodeInfoWithStorage[127.0.0.1:45690,DS-089d6c0f-4e86-4f42-b26d-0969dec07467,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 60
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1318497715-172.17.0.13-1597458834358:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35967,DS-67c92f24-f0a4-41ba-b9ee-f6424f31f1ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45067,DS-a612b94a-7b90-42e8-add6-15a130d71edb,DISK], DatanodeInfoWithStorage[127.0.0.1:45143,DS-29370bdc-eba1-4052-a14d-e64b1bb66c08,DISK], DatanodeInfoWithStorage[127.0.0.1:43208,DS-a617afb3-c699-4f57-943f-31c31036aedf,DISK], DatanodeInfoWithStorage[127.0.0.1:41224,DS-523270d6-1e42-485d-b713-3925b9c5b05b,DISK], DatanodeInfoWithStorage[127.0.0.1:35822,DS-4778ce99-0a3f-40d7-94ec-4ca7f461a896,DISK], DatanodeInfoWithStorage[127.0.0.1:35523,DS-01a18c6b-8e2c-492b-ae87-2e2e541e6205,DISK], DatanodeInfoWithStorage[127.0.0.1:42964,DS-377d5d7b-6ab3-4c31-b2f8-0f63c14d0e56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1318497715-172.17.0.13-1597458834358:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35967,DS-67c92f24-f0a4-41ba-b9ee-f6424f31f1ba,DISK], DatanodeInfoWithStorage[127.0.0.1:45067,DS-a612b94a-7b90-42e8-add6-15a130d71edb,DISK], DatanodeInfoWithStorage[127.0.0.1:45143,DS-29370bdc-eba1-4052-a14d-e64b1bb66c08,DISK], DatanodeInfoWithStorage[127.0.0.1:43208,DS-a617afb3-c699-4f57-943f-31c31036aedf,DISK], DatanodeInfoWithStorage[127.0.0.1:41224,DS-523270d6-1e42-485d-b713-3925b9c5b05b,DISK], DatanodeInfoWithStorage[127.0.0.1:35822,DS-4778ce99-0a3f-40d7-94ec-4ca7f461a896,DISK], DatanodeInfoWithStorage[127.0.0.1:35523,DS-01a18c6b-8e2c-492b-ae87-2e2e541e6205,DISK], DatanodeInfoWithStorage[127.0.0.1:42964,DS-377d5d7b-6ab3-4c31-b2f8-0f63c14d0e56,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 60
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1553182439-172.17.0.13-1597458908311:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41129,DS-3f9bc291-515b-4cb5-a25a-152bab6651f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39951,DS-49ea22e9-b84d-4e9c-a2aa-4bfdb3ad4a7c,DISK], DatanodeInfoWithStorage[127.0.0.1:34589,DS-02588ba5-be8a-400a-ac5f-1cf0cd835f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:33150,DS-b5427685-6261-4dc6-8684-d5e9658e0be9,DISK], DatanodeInfoWithStorage[127.0.0.1:41885,DS-848c7193-404a-43d3-b095-d4d2118a4dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:37948,DS-1a1cd40e-ffa1-40c1-9b72-2ce3c917ea86,DISK], DatanodeInfoWithStorage[127.0.0.1:45802,DS-7867e64e-ce9f-462b-8514-af77c5be0bae,DISK], DatanodeInfoWithStorage[127.0.0.1:35863,DS-c7238e66-b9ad-4aaf-9036-222fc20124df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1553182439-172.17.0.13-1597458908311:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41129,DS-3f9bc291-515b-4cb5-a25a-152bab6651f9,DISK], DatanodeInfoWithStorage[127.0.0.1:39951,DS-49ea22e9-b84d-4e9c-a2aa-4bfdb3ad4a7c,DISK], DatanodeInfoWithStorage[127.0.0.1:34589,DS-02588ba5-be8a-400a-ac5f-1cf0cd835f9c,DISK], DatanodeInfoWithStorage[127.0.0.1:33150,DS-b5427685-6261-4dc6-8684-d5e9658e0be9,DISK], DatanodeInfoWithStorage[127.0.0.1:41885,DS-848c7193-404a-43d3-b095-d4d2118a4dc9,DISK], DatanodeInfoWithStorage[127.0.0.1:37948,DS-1a1cd40e-ffa1-40c1-9b72-2ce3c917ea86,DISK], DatanodeInfoWithStorage[127.0.0.1:45802,DS-7867e64e-ce9f-462b-8514-af77c5be0bae,DISK], DatanodeInfoWithStorage[127.0.0.1:35863,DS-c7238e66-b9ad-4aaf-9036-222fc20124df,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 60
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1437160682-172.17.0.13-1597459022309:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37961,DS-3abe703e-8232-4f31-8f97-b859b19ecf7c,DISK], DatanodeInfoWithStorage[127.0.0.1:38434,DS-f287e64e-fd30-469d-a75e-9e9ac38dcf10,DISK], DatanodeInfoWithStorage[127.0.0.1:34116,DS-d2db5f87-ac8b-4368-8314-e99b3176fc77,DISK], DatanodeInfoWithStorage[127.0.0.1:33341,DS-619943c0-e606-4ac3-9f05-2688eeba82ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34898,DS-9705a839-1f50-4dde-b5cc-0f9b50e76200,DISK], DatanodeInfoWithStorage[127.0.0.1:41727,DS-061c2a27-f45a-4a08-a481-9c7b38070070,DISK], DatanodeInfoWithStorage[127.0.0.1:41138,DS-85e56234-b252-439c-ae82-1b497ae2ca6e,DISK], DatanodeInfoWithStorage[127.0.0.1:40479,DS-a471d710-8038-46c2-aa75-07185ef8f5a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1437160682-172.17.0.13-1597459022309:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37961,DS-3abe703e-8232-4f31-8f97-b859b19ecf7c,DISK], DatanodeInfoWithStorage[127.0.0.1:38434,DS-f287e64e-fd30-469d-a75e-9e9ac38dcf10,DISK], DatanodeInfoWithStorage[127.0.0.1:34116,DS-d2db5f87-ac8b-4368-8314-e99b3176fc77,DISK], DatanodeInfoWithStorage[127.0.0.1:33341,DS-619943c0-e606-4ac3-9f05-2688eeba82ec,DISK], DatanodeInfoWithStorage[127.0.0.1:34898,DS-9705a839-1f50-4dde-b5cc-0f9b50e76200,DISK], DatanodeInfoWithStorage[127.0.0.1:41727,DS-061c2a27-f45a-4a08-a481-9c7b38070070,DISK], DatanodeInfoWithStorage[127.0.0.1:41138,DS-85e56234-b252-439c-ae82-1b497ae2ca6e,DISK], DatanodeInfoWithStorage[127.0.0.1:40479,DS-a471d710-8038-46c2-aa75-07185ef8f5a7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 60
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-876888107-172.17.0.13-1597459091667:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33668,DS-01daf070-e583-4434-8b10-5f961493227c,DISK], DatanodeInfoWithStorage[127.0.0.1:42763,DS-ff958d3b-dc9f-4650-92d5-ee5f88dea1f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33342,DS-79444851-7688-42bb-bcf7-6a263442385c,DISK], DatanodeInfoWithStorage[127.0.0.1:39169,DS-491559a5-6091-48c8-8639-9ebb2cbdf728,DISK], DatanodeInfoWithStorage[127.0.0.1:36287,DS-2cef4e00-163d-4d83-a28f-9145f41d0eb6,DISK], DatanodeInfoWithStorage[127.0.0.1:36172,DS-945825d0-33a7-424e-ab73-88761a857a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:36539,DS-3ee92ce7-0ca5-4fe5-9098-e035e1a35302,DISK], DatanodeInfoWithStorage[127.0.0.1:38305,DS-33e10653-d691-4ac7-80f7-95b6ccddd149,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-876888107-172.17.0.13-1597459091667:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33668,DS-01daf070-e583-4434-8b10-5f961493227c,DISK], DatanodeInfoWithStorage[127.0.0.1:42763,DS-ff958d3b-dc9f-4650-92d5-ee5f88dea1f2,DISK], DatanodeInfoWithStorage[127.0.0.1:33342,DS-79444851-7688-42bb-bcf7-6a263442385c,DISK], DatanodeInfoWithStorage[127.0.0.1:39169,DS-491559a5-6091-48c8-8639-9ebb2cbdf728,DISK], DatanodeInfoWithStorage[127.0.0.1:36287,DS-2cef4e00-163d-4d83-a28f-9145f41d0eb6,DISK], DatanodeInfoWithStorage[127.0.0.1:36172,DS-945825d0-33a7-424e-ab73-88761a857a5f,DISK], DatanodeInfoWithStorage[127.0.0.1:36539,DS-3ee92ce7-0ca5-4fe5-9098-e035e1a35302,DISK], DatanodeInfoWithStorage[127.0.0.1:38305,DS-33e10653-d691-4ac7-80f7-95b6ccddd149,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 60
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1543946650-172.17.0.13-1597459397946:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37070,DS-a52d2f07-eee8-4538-ba39-53ee72f51eb5,DISK], DatanodeInfoWithStorage[127.0.0.1:38727,DS-d49380e8-4ee4-4e34-a0d9-1c8ce3e74107,DISK], DatanodeInfoWithStorage[127.0.0.1:46765,DS-b18f0855-9f37-415e-915d-d8bbce66e6ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36797,DS-ecf85284-71ed-45d1-9402-c3699fbc1cc8,DISK], DatanodeInfoWithStorage[127.0.0.1:41484,DS-363d9016-e54d-4e71-81b1-9410a62790cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34391,DS-fb326beb-362d-437f-bfae-4b7c8f6b130d,DISK], DatanodeInfoWithStorage[127.0.0.1:39646,DS-a919df08-2925-47f7-9d83-6560d5cdeff1,DISK], DatanodeInfoWithStorage[127.0.0.1:39990,DS-10d51fd0-6f89-4d27-be96-dba26f7d9649,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1543946650-172.17.0.13-1597459397946:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37070,DS-a52d2f07-eee8-4538-ba39-53ee72f51eb5,DISK], DatanodeInfoWithStorage[127.0.0.1:38727,DS-d49380e8-4ee4-4e34-a0d9-1c8ce3e74107,DISK], DatanodeInfoWithStorage[127.0.0.1:46765,DS-b18f0855-9f37-415e-915d-d8bbce66e6ee,DISK], DatanodeInfoWithStorage[127.0.0.1:36797,DS-ecf85284-71ed-45d1-9402-c3699fbc1cc8,DISK], DatanodeInfoWithStorage[127.0.0.1:41484,DS-363d9016-e54d-4e71-81b1-9410a62790cd,DISK], DatanodeInfoWithStorage[127.0.0.1:34391,DS-fb326beb-362d-437f-bfae-4b7c8f6b130d,DISK], DatanodeInfoWithStorage[127.0.0.1:39646,DS-a919df08-2925-47f7-9d83-6560d5cdeff1,DISK], DatanodeInfoWithStorage[127.0.0.1:39990,DS-10d51fd0-6f89-4d27-be96-dba26f7d9649,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 60
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1322168136-172.17.0.13-1597459508528:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33115,DS-d6194830-d69c-45ab-8b53-d708d057792e,DISK], DatanodeInfoWithStorage[127.0.0.1:44662,DS-ca2863f6-0a58-4f31-99d8-102d2e6d936b,DISK], DatanodeInfoWithStorage[127.0.0.1:42720,DS-d00f49b6-7c11-4207-9135-ffaf71662a3b,DISK], DatanodeInfoWithStorage[127.0.0.1:36936,DS-dd983e6d-8368-44a9-a15c-99331d798388,DISK], DatanodeInfoWithStorage[127.0.0.1:41084,DS-cf39bb9e-8819-4aa7-a39b-4a4c93f87412,DISK], DatanodeInfoWithStorage[127.0.0.1:37147,DS-4b538e8d-c356-4794-a401-41b9a874544a,DISK], DatanodeInfoWithStorage[127.0.0.1:39674,DS-e1f55d03-6959-49af-b04b-1e47989a5582,DISK], DatanodeInfoWithStorage[127.0.0.1:36811,DS-9ed24dc3-678d-421f-a749-be1c34e87215,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1322168136-172.17.0.13-1597459508528:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33115,DS-d6194830-d69c-45ab-8b53-d708d057792e,DISK], DatanodeInfoWithStorage[127.0.0.1:44662,DS-ca2863f6-0a58-4f31-99d8-102d2e6d936b,DISK], DatanodeInfoWithStorage[127.0.0.1:42720,DS-d00f49b6-7c11-4207-9135-ffaf71662a3b,DISK], DatanodeInfoWithStorage[127.0.0.1:36936,DS-dd983e6d-8368-44a9-a15c-99331d798388,DISK], DatanodeInfoWithStorage[127.0.0.1:41084,DS-cf39bb9e-8819-4aa7-a39b-4a4c93f87412,DISK], DatanodeInfoWithStorage[127.0.0.1:37147,DS-4b538e8d-c356-4794-a401-41b9a874544a,DISK], DatanodeInfoWithStorage[127.0.0.1:39674,DS-e1f55d03-6959-49af-b04b-1e47989a5582,DISK], DatanodeInfoWithStorage[127.0.0.1:36811,DS-9ed24dc3-678d-421f-a749-be1c34e87215,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 60
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1662265539-172.17.0.13-1597459626627:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33431,DS-978b9650-f244-4e42-876a-83b74fd14734,DISK], DatanodeInfoWithStorage[127.0.0.1:46777,DS-557f148e-839f-47b2-a3e1-c20fbcfb317d,DISK], DatanodeInfoWithStorage[127.0.0.1:44994,DS-d724166d-c45d-47d5-b3ab-be9c480ec3c4,DISK], DatanodeInfoWithStorage[127.0.0.1:34631,DS-83486b1f-e152-49b0-8a2d-9f3c862e8f06,DISK], DatanodeInfoWithStorage[127.0.0.1:39742,DS-68359826-bd89-4e2b-b334-eec8e8133b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:38797,DS-7d953603-b9e5-4092-a3d6-db445c4c3108,DISK], DatanodeInfoWithStorage[127.0.0.1:37910,DS-c219fbc4-dfa6-448b-a322-5341f14b63e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37019,DS-7924553d-f6c8-49e0-930e-b407a57973e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1662265539-172.17.0.13-1597459626627:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33431,DS-978b9650-f244-4e42-876a-83b74fd14734,DISK], DatanodeInfoWithStorage[127.0.0.1:46777,DS-557f148e-839f-47b2-a3e1-c20fbcfb317d,DISK], DatanodeInfoWithStorage[127.0.0.1:44994,DS-d724166d-c45d-47d5-b3ab-be9c480ec3c4,DISK], DatanodeInfoWithStorage[127.0.0.1:34631,DS-83486b1f-e152-49b0-8a2d-9f3c862e8f06,DISK], DatanodeInfoWithStorage[127.0.0.1:39742,DS-68359826-bd89-4e2b-b334-eec8e8133b4b,DISK], DatanodeInfoWithStorage[127.0.0.1:38797,DS-7d953603-b9e5-4092-a3d6-db445c4c3108,DISK], DatanodeInfoWithStorage[127.0.0.1:37910,DS-c219fbc4-dfa6-448b-a322-5341f14b63e3,DISK], DatanodeInfoWithStorage[127.0.0.1:37019,DS-7924553d-f6c8-49e0-930e-b407a57973e0,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 60
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1210758946-172.17.0.13-1597460151421:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39510,DS-cb33a979-be8f-4970-a954-972ba3bc461e,DISK], DatanodeInfoWithStorage[127.0.0.1:36792,DS-d47ea14b-ff59-436b-95b0-748b9cb3e189,DISK], DatanodeInfoWithStorage[127.0.0.1:35320,DS-41279516-b957-4dad-b6b2-70ec75615791,DISK], DatanodeInfoWithStorage[127.0.0.1:37634,DS-bc3082f8-46d2-438b-b2fa-cce2a55d95fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34315,DS-6d990ff0-813b-4d1d-a92c-fd55911dd01e,DISK], DatanodeInfoWithStorage[127.0.0.1:36971,DS-e516d3ec-e739-45a1-bd2d-d561261ac019,DISK], DatanodeInfoWithStorage[127.0.0.1:36327,DS-0b517445-a818-46d0-8750-a0b3c26bd129,DISK], DatanodeInfoWithStorage[127.0.0.1:33132,DS-8603ea7d-c1d5-495c-8642-606fb93c4b81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1210758946-172.17.0.13-1597460151421:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39510,DS-cb33a979-be8f-4970-a954-972ba3bc461e,DISK], DatanodeInfoWithStorage[127.0.0.1:36792,DS-d47ea14b-ff59-436b-95b0-748b9cb3e189,DISK], DatanodeInfoWithStorage[127.0.0.1:35320,DS-41279516-b957-4dad-b6b2-70ec75615791,DISK], DatanodeInfoWithStorage[127.0.0.1:37634,DS-bc3082f8-46d2-438b-b2fa-cce2a55d95fb,DISK], DatanodeInfoWithStorage[127.0.0.1:34315,DS-6d990ff0-813b-4d1d-a92c-fd55911dd01e,DISK], DatanodeInfoWithStorage[127.0.0.1:36971,DS-e516d3ec-e739-45a1-bd2d-d561261ac019,DISK], DatanodeInfoWithStorage[127.0.0.1:36327,DS-0b517445-a818-46d0-8750-a0b3c26bd129,DISK], DatanodeInfoWithStorage[127.0.0.1:33132,DS-8603ea7d-c1d5-495c-8642-606fb93c4b81,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 60
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-850903166-172.17.0.13-1597460183343:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44819,DS-d857eab7-3bcd-4b19-bbf8-84b6eec20070,DISK], DatanodeInfoWithStorage[127.0.0.1:46418,DS-7b658b07-d0d2-41ae-99d2-4c94cad3dd90,DISK], DatanodeInfoWithStorage[127.0.0.1:33236,DS-10f87551-8a13-4e38-97a6-e3622e916e04,DISK], DatanodeInfoWithStorage[127.0.0.1:42226,DS-dbb2223e-5708-48cb-ba38-48f618a510d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36769,DS-2e2a22ea-5012-45ea-a4df-b5919e0ac915,DISK], DatanodeInfoWithStorage[127.0.0.1:33387,DS-cc9f00dd-fb56-4811-aaaa-ca7a0d4a28ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37895,DS-092a450f-8004-4b4f-bf5e-deac11bbbd1a,DISK], DatanodeInfoWithStorage[127.0.0.1:46149,DS-2bf22ab3-7826-49ce-9136-566766441db2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-850903166-172.17.0.13-1597460183343:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:44819,DS-d857eab7-3bcd-4b19-bbf8-84b6eec20070,DISK], DatanodeInfoWithStorage[127.0.0.1:46418,DS-7b658b07-d0d2-41ae-99d2-4c94cad3dd90,DISK], DatanodeInfoWithStorage[127.0.0.1:33236,DS-10f87551-8a13-4e38-97a6-e3622e916e04,DISK], DatanodeInfoWithStorage[127.0.0.1:42226,DS-dbb2223e-5708-48cb-ba38-48f618a510d7,DISK], DatanodeInfoWithStorage[127.0.0.1:36769,DS-2e2a22ea-5012-45ea-a4df-b5919e0ac915,DISK], DatanodeInfoWithStorage[127.0.0.1:33387,DS-cc9f00dd-fb56-4811-aaaa-ca7a0d4a28ac,DISK], DatanodeInfoWithStorage[127.0.0.1:37895,DS-092a450f-8004-4b4f-bf5e-deac11bbbd1a,DISK], DatanodeInfoWithStorage[127.0.0.1:46149,DS-2bf22ab3-7826-49ce-9136-566766441db2,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 60
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1306113109-172.17.0.13-1597460546231:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32816,DS-756ec4cb-83ee-475b-9e48-dbad4f0d6c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:36280,DS-cdd32f1f-dfcf-40c8-8ce9-96f3483c8580,DISK], DatanodeInfoWithStorage[127.0.0.1:40907,DS-934b5e9a-9ec9-4812-b70f-0e4105dceedd,DISK], DatanodeInfoWithStorage[127.0.0.1:46164,DS-db107d45-7de1-4ed7-9055-c7714aded469,DISK], DatanodeInfoWithStorage[127.0.0.1:33380,DS-ec47760f-a0cc-4be7-bc88-9d8ba87068c7,DISK], DatanodeInfoWithStorage[127.0.0.1:41118,DS-012ffe1d-952d-4b74-a850-a1a447acca9c,DISK], DatanodeInfoWithStorage[127.0.0.1:37876,DS-77c91944-d4c1-4677-b3c1-1d06aa19e8b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39906,DS-7b0e6c22-f656-4478-9c7a-927b6a9e1eb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1306113109-172.17.0.13-1597460546231:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:32816,DS-756ec4cb-83ee-475b-9e48-dbad4f0d6c5f,DISK], DatanodeInfoWithStorage[127.0.0.1:36280,DS-cdd32f1f-dfcf-40c8-8ce9-96f3483c8580,DISK], DatanodeInfoWithStorage[127.0.0.1:40907,DS-934b5e9a-9ec9-4812-b70f-0e4105dceedd,DISK], DatanodeInfoWithStorage[127.0.0.1:46164,DS-db107d45-7de1-4ed7-9055-c7714aded469,DISK], DatanodeInfoWithStorage[127.0.0.1:33380,DS-ec47760f-a0cc-4be7-bc88-9d8ba87068c7,DISK], DatanodeInfoWithStorage[127.0.0.1:41118,DS-012ffe1d-952d-4b74-a850-a1a447acca9c,DISK], DatanodeInfoWithStorage[127.0.0.1:37876,DS-77c91944-d4c1-4677-b3c1-1d06aa19e8b7,DISK], DatanodeInfoWithStorage[127.0.0.1:39906,DS-7b0e6c22-f656-4478-9c7a-927b6a9e1eb5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 60
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-13728687-172.17.0.13-1597460658853:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42804,DS-bbc05e13-739d-4871-828c-3e6df3ca5342,DISK], DatanodeInfoWithStorage[127.0.0.1:34961,DS-9fd2165a-6361-4dd6-8366-a5d4a2a4671f,DISK], DatanodeInfoWithStorage[127.0.0.1:33453,DS-f59693ea-dbb2-49e2-9d98-4bdc78db455c,DISK], DatanodeInfoWithStorage[127.0.0.1:34927,DS-13767fb8-c6cc-4723-967c-b1be610fdee7,DISK], DatanodeInfoWithStorage[127.0.0.1:33947,DS-701aec72-acf7-4f80-b2e6-5a3018c5f443,DISK], DatanodeInfoWithStorage[127.0.0.1:39136,DS-1d96a9b2-0c21-4983-99da-73c85a2e9a38,DISK], DatanodeInfoWithStorage[127.0.0.1:43946,DS-11d04f58-ea22-4962-ab37-f395f0a9c8ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45907,DS-1cf6b926-55dd-498b-8394-af3ed170fc4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-13728687-172.17.0.13-1597460658853:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42804,DS-bbc05e13-739d-4871-828c-3e6df3ca5342,DISK], DatanodeInfoWithStorage[127.0.0.1:34961,DS-9fd2165a-6361-4dd6-8366-a5d4a2a4671f,DISK], DatanodeInfoWithStorage[127.0.0.1:33453,DS-f59693ea-dbb2-49e2-9d98-4bdc78db455c,DISK], DatanodeInfoWithStorage[127.0.0.1:34927,DS-13767fb8-c6cc-4723-967c-b1be610fdee7,DISK], DatanodeInfoWithStorage[127.0.0.1:33947,DS-701aec72-acf7-4f80-b2e6-5a3018c5f443,DISK], DatanodeInfoWithStorage[127.0.0.1:39136,DS-1d96a9b2-0c21-4983-99da-73c85a2e9a38,DISK], DatanodeInfoWithStorage[127.0.0.1:43946,DS-11d04f58-ea22-4962-ab37-f395f0a9c8ea,DISK], DatanodeInfoWithStorage[127.0.0.1:45907,DS-1cf6b926-55dd-498b-8394-af3ed170fc4f,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 60
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1688405534-172.17.0.13-1597461429509:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46675,DS-9c43bd91-6f84-4c6e-8e8f-4925399cff4a,DISK], DatanodeInfoWithStorage[127.0.0.1:34350,DS-92103ebd-9c6c-48f5-b5dc-6952ddf9750d,DISK], DatanodeInfoWithStorage[127.0.0.1:43135,DS-ed0e163f-4073-4d73-8e61-9dcef2a1493b,DISK], DatanodeInfoWithStorage[127.0.0.1:37535,DS-aafb87ed-5076-4243-9a84-75c8a80c0df1,DISK], DatanodeInfoWithStorage[127.0.0.1:38878,DS-614eb74e-75dc-4f70-abdc-7d0a57db2057,DISK], DatanodeInfoWithStorage[127.0.0.1:40049,DS-0ad98732-ae6a-45e9-bd3a-7d37141c8813,DISK], DatanodeInfoWithStorage[127.0.0.1:43041,DS-2164b87e-e08b-4e29-af80-e7dc1a343df3,DISK], DatanodeInfoWithStorage[127.0.0.1:33508,DS-daff39e6-db32-4e70-abe8-e3895a76e3f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1688405534-172.17.0.13-1597461429509:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:46675,DS-9c43bd91-6f84-4c6e-8e8f-4925399cff4a,DISK], DatanodeInfoWithStorage[127.0.0.1:34350,DS-92103ebd-9c6c-48f5-b5dc-6952ddf9750d,DISK], DatanodeInfoWithStorage[127.0.0.1:43135,DS-ed0e163f-4073-4d73-8e61-9dcef2a1493b,DISK], DatanodeInfoWithStorage[127.0.0.1:37535,DS-aafb87ed-5076-4243-9a84-75c8a80c0df1,DISK], DatanodeInfoWithStorage[127.0.0.1:38878,DS-614eb74e-75dc-4f70-abdc-7d0a57db2057,DISK], DatanodeInfoWithStorage[127.0.0.1:40049,DS-0ad98732-ae6a-45e9-bd3a-7d37141c8813,DISK], DatanodeInfoWithStorage[127.0.0.1:43041,DS-2164b87e-e08b-4e29-af80-e7dc1a343df3,DISK], DatanodeInfoWithStorage[127.0.0.1:33508,DS-daff39e6-db32-4e70-abe8-e3895a76e3f4,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 60
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1668570507-172.17.0.13-1597461508154:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35338,DS-ffbab81c-3f4f-4ded-8b5f-1db4cda1ec71,DISK], DatanodeInfoWithStorage[127.0.0.1:33490,DS-7ff09935-ba4e-4f09-81ce-0da6ef2d1782,DISK], DatanodeInfoWithStorage[127.0.0.1:42071,DS-26bcab0a-a6c2-4a69-abb9-515d1957ca56,DISK], DatanodeInfoWithStorage[127.0.0.1:40669,DS-e9bfed9c-7cdc-47e1-9778-d8aa1123e78e,DISK], DatanodeInfoWithStorage[127.0.0.1:42399,DS-31a147a9-f729-422e-81c1-91b60f145b70,DISK], DatanodeInfoWithStorage[127.0.0.1:36867,DS-c2298434-dcae-46f3-8a0a-adb6988e2604,DISK], DatanodeInfoWithStorage[127.0.0.1:45994,DS-48e38ac7-12c0-41c2-be1a-6afc06c43c60,DISK], DatanodeInfoWithStorage[127.0.0.1:38498,DS-e6d603f5-52f8-414c-8986-a334b1edd70c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1668570507-172.17.0.13-1597461508154:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35338,DS-ffbab81c-3f4f-4ded-8b5f-1db4cda1ec71,DISK], DatanodeInfoWithStorage[127.0.0.1:33490,DS-7ff09935-ba4e-4f09-81ce-0da6ef2d1782,DISK], DatanodeInfoWithStorage[127.0.0.1:42071,DS-26bcab0a-a6c2-4a69-abb9-515d1957ca56,DISK], DatanodeInfoWithStorage[127.0.0.1:40669,DS-e9bfed9c-7cdc-47e1-9778-d8aa1123e78e,DISK], DatanodeInfoWithStorage[127.0.0.1:42399,DS-31a147a9-f729-422e-81c1-91b60f145b70,DISK], DatanodeInfoWithStorage[127.0.0.1:36867,DS-c2298434-dcae-46f3-8a0a-adb6988e2604,DISK], DatanodeInfoWithStorage[127.0.0.1:45994,DS-48e38ac7-12c0-41c2-be1a-6afc06c43c60,DISK], DatanodeInfoWithStorage[127.0.0.1:38498,DS-e6d603f5-52f8-414c-8986-a334b1edd70c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.datanode.restart.replica.expiration
component: hdfs:DataNode
v1: 60
v2: 50
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -2
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-796300852-172.17.0.13-1597461934517:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33776,DS-f4276cca-540c-47c8-9a47-12b017253ce5,DISK], DatanodeInfoWithStorage[127.0.0.1:39601,DS-eb7e985d-e18e-459b-9763-65eb1d74dbe0,DISK], DatanodeInfoWithStorage[127.0.0.1:36283,DS-eda26590-ebed-4883-a53f-651d18e84163,DISK], DatanodeInfoWithStorage[127.0.0.1:42522,DS-453d6f7d-f215-465d-b090-61e7535a0185,DISK], DatanodeInfoWithStorage[127.0.0.1:34412,DS-7c1e37f9-324f-411b-968f-f32f6b89a2c0,DISK], DatanodeInfoWithStorage[127.0.0.1:32912,DS-9c00bf0f-0a3b-4dbf-a664-24bc29287a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:34895,DS-a089fcd9-f47c-4dfe-9a2f-fa4db449c414,DISK], DatanodeInfoWithStorage[127.0.0.1:45949,DS-d5a4e6ff-184d-4ad3-bee9-08c819f8fbc5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-796300852-172.17.0.13-1597461934517:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33776,DS-f4276cca-540c-47c8-9a47-12b017253ce5,DISK], DatanodeInfoWithStorage[127.0.0.1:39601,DS-eb7e985d-e18e-459b-9763-65eb1d74dbe0,DISK], DatanodeInfoWithStorage[127.0.0.1:36283,DS-eda26590-ebed-4883-a53f-651d18e84163,DISK], DatanodeInfoWithStorage[127.0.0.1:42522,DS-453d6f7d-f215-465d-b090-61e7535a0185,DISK], DatanodeInfoWithStorage[127.0.0.1:34412,DS-7c1e37f9-324f-411b-968f-f32f6b89a2c0,DISK], DatanodeInfoWithStorage[127.0.0.1:32912,DS-9c00bf0f-0a3b-4dbf-a664-24bc29287a5e,DISK], DatanodeInfoWithStorage[127.0.0.1:34895,DS-a089fcd9-f47c-4dfe-9a2f-fa4db449c414,DISK], DatanodeInfoWithStorage[127.0.0.1:45949,DS-d5a4e6ff-184d-4ad3-bee9-08c819f8fbc5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1
v1v2 failed with probability 5 out of 50
v1v1v2v2 failed with probability 10 out of 50
result: false positive !!!
Total execution time in seconds : 5720
