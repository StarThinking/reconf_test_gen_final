reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1396959047-172.17.0.21-1597685340512:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34857,DS-f49bceba-d438-4a29-889d-34de710e841e,DISK], DatanodeInfoWithStorage[127.0.0.1:33146,DS-46567884-aaad-4f7c-8d27-e3976c19e402,DISK], DatanodeInfoWithStorage[127.0.0.1:45607,DS-02728fb0-fdd4-47be-be3b-f53e41c822de,DISK], DatanodeInfoWithStorage[127.0.0.1:34592,DS-bc9f1411-a54a-4fd3-ae40-ca8207a09fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:33340,DS-1cfa4288-1e45-413e-9399-2d034160d5db,DISK], DatanodeInfoWithStorage[127.0.0.1:40864,DS-af73fc38-8fee-4b7b-85be-f47c9a7084f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33471,DS-dbbbd463-0222-491b-898e-a41d74e283da,DISK], DatanodeInfoWithStorage[127.0.0.1:43607,DS-8f4c2643-622f-47ed-b751-7212a5b7a107,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1396959047-172.17.0.21-1597685340512:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:34857,DS-f49bceba-d438-4a29-889d-34de710e841e,DISK], DatanodeInfoWithStorage[127.0.0.1:33146,DS-46567884-aaad-4f7c-8d27-e3976c19e402,DISK], DatanodeInfoWithStorage[127.0.0.1:45607,DS-02728fb0-fdd4-47be-be3b-f53e41c822de,DISK], DatanodeInfoWithStorage[127.0.0.1:34592,DS-bc9f1411-a54a-4fd3-ae40-ca8207a09fb1,DISK], DatanodeInfoWithStorage[127.0.0.1:33340,DS-1cfa4288-1e45-413e-9399-2d034160d5db,DISK], DatanodeInfoWithStorage[127.0.0.1:40864,DS-af73fc38-8fee-4b7b-85be-f47c9a7084f1,DISK], DatanodeInfoWithStorage[127.0.0.1:33471,DS-dbbbd463-0222-491b-898e-a41d74e283da,DISK], DatanodeInfoWithStorage[127.0.0.1:43607,DS-8f4c2643-622f-47ed-b751-7212a5b7a107,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2133394442-172.17.0.21-1597685425871:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33238,DS-a1441357-7029-4653-9608-5bceb9341100,DISK], DatanodeInfoWithStorage[127.0.0.1:36582,DS-994f15fe-7a5b-432f-8ed3-2f4f626d3249,DISK], DatanodeInfoWithStorage[127.0.0.1:36257,DS-2590609f-c971-4043-a0c7-23ba13a6cb63,DISK], DatanodeInfoWithStorage[127.0.0.1:38040,DS-d6f99984-81ed-4f1c-9465-6428147308ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37537,DS-72320316-2efb-4d23-8fde-57d1702d0797,DISK], DatanodeInfoWithStorage[127.0.0.1:39897,DS-fc8dc7a3-f930-43e7-a2cc-4475b589d3db,DISK], DatanodeInfoWithStorage[127.0.0.1:38069,DS-a06adb41-643d-46c6-ab15-1d456226bda0,DISK], DatanodeInfoWithStorage[127.0.0.1:37739,DS-e0bd4ab1-eaa9-4119-96b6-9d7d211ff7b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2133394442-172.17.0.21-1597685425871:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:33238,DS-a1441357-7029-4653-9608-5bceb9341100,DISK], DatanodeInfoWithStorage[127.0.0.1:36582,DS-994f15fe-7a5b-432f-8ed3-2f4f626d3249,DISK], DatanodeInfoWithStorage[127.0.0.1:36257,DS-2590609f-c971-4043-a0c7-23ba13a6cb63,DISK], DatanodeInfoWithStorage[127.0.0.1:38040,DS-d6f99984-81ed-4f1c-9465-6428147308ca,DISK], DatanodeInfoWithStorage[127.0.0.1:37537,DS-72320316-2efb-4d23-8fde-57d1702d0797,DISK], DatanodeInfoWithStorage[127.0.0.1:39897,DS-fc8dc7a3-f930-43e7-a2cc-4475b589d3db,DISK], DatanodeInfoWithStorage[127.0.0.1:38069,DS-a06adb41-643d-46c6-ab15-1d456226bda0,DISK], DatanodeInfoWithStorage[127.0.0.1:37739,DS-e0bd4ab1-eaa9-4119-96b6-9d7d211ff7b3,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-851336129-172.17.0.21-1597685534752:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45327,DS-b8d5e39f-9ce9-48b8-9bfd-16747bd25e82,DISK], DatanodeInfoWithStorage[127.0.0.1:44084,DS-397452cb-7259-4eef-8cd4-13fc0fc19834,DISK], DatanodeInfoWithStorage[127.0.0.1:45496,DS-a289ab49-a9fd-4a12-9b71-0c7a7a8fc74b,DISK], DatanodeInfoWithStorage[127.0.0.1:46689,DS-cac0b907-210a-4e47-af43-535d18883607,DISK], DatanodeInfoWithStorage[127.0.0.1:38639,DS-c53d61ce-0db2-4237-a8a6-54b4c8c36535,DISK], DatanodeInfoWithStorage[127.0.0.1:35040,DS-e68e9c0f-5d2e-4b0a-9b88-e21e264e701a,DISK], DatanodeInfoWithStorage[127.0.0.1:33106,DS-d116d104-7ef0-43d0-93a2-ecd2a7fc8835,DISK], DatanodeInfoWithStorage[127.0.0.1:43032,DS-5d0bae63-8065-4e30-8ad0-857dc2959fe7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-851336129-172.17.0.21-1597685534752:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:45327,DS-b8d5e39f-9ce9-48b8-9bfd-16747bd25e82,DISK], DatanodeInfoWithStorage[127.0.0.1:44084,DS-397452cb-7259-4eef-8cd4-13fc0fc19834,DISK], DatanodeInfoWithStorage[127.0.0.1:45496,DS-a289ab49-a9fd-4a12-9b71-0c7a7a8fc74b,DISK], DatanodeInfoWithStorage[127.0.0.1:46689,DS-cac0b907-210a-4e47-af43-535d18883607,DISK], DatanodeInfoWithStorage[127.0.0.1:38639,DS-c53d61ce-0db2-4237-a8a6-54b4c8c36535,DISK], DatanodeInfoWithStorage[127.0.0.1:35040,DS-e68e9c0f-5d2e-4b0a-9b88-e21e264e701a,DISK], DatanodeInfoWithStorage[127.0.0.1:33106,DS-d116d104-7ef0-43d0-93a2-ecd2a7fc8835,DISK], DatanodeInfoWithStorage[127.0.0.1:43032,DS-5d0bae63-8065-4e30-8ad0-857dc2959fe7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-960019664-172.17.0.21-1597685927536:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39963,DS-47ec5af5-2bc2-48b9-b2f5-0215beeea1b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41868,DS-2446a979-7101-4300-8df6-94d550ae1dee,DISK], DatanodeInfoWithStorage[127.0.0.1:41764,DS-3ee6fa43-e825-4563-8487-84443b54b590,DISK], DatanodeInfoWithStorage[127.0.0.1:41697,DS-de749a2d-d172-4064-9392-af8a2ba0c7b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42517,DS-a1af151d-8aff-403b-8c11-7e26c3a34f27,DISK], DatanodeInfoWithStorage[127.0.0.1:45906,DS-8bc9a686-16ef-4480-8d84-d2d9381c3107,DISK], DatanodeInfoWithStorage[127.0.0.1:43562,DS-47a7dac9-0e49-43fd-a377-b0cdb51be8a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39493,DS-e6ccd22f-5a5c-4f45-96a6-6e71a5b74096,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-960019664-172.17.0.21-1597685927536:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:39963,DS-47ec5af5-2bc2-48b9-b2f5-0215beeea1b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41868,DS-2446a979-7101-4300-8df6-94d550ae1dee,DISK], DatanodeInfoWithStorage[127.0.0.1:41764,DS-3ee6fa43-e825-4563-8487-84443b54b590,DISK], DatanodeInfoWithStorage[127.0.0.1:41697,DS-de749a2d-d172-4064-9392-af8a2ba0c7b5,DISK], DatanodeInfoWithStorage[127.0.0.1:42517,DS-a1af151d-8aff-403b-8c11-7e26c3a34f27,DISK], DatanodeInfoWithStorage[127.0.0.1:45906,DS-8bc9a686-16ef-4480-8d84-d2d9381c3107,DISK], DatanodeInfoWithStorage[127.0.0.1:43562,DS-47a7dac9-0e49-43fd-a377-b0cdb51be8a0,DISK], DatanodeInfoWithStorage[127.0.0.1:39493,DS-e6ccd22f-5a5c-4f45-96a6-6e71a5b74096,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2085927385-172.17.0.21-1597686039205:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37675,DS-2bb2cb59-fef0-4dac-95e9-5d65707d3a68,DISK], DatanodeInfoWithStorage[127.0.0.1:35774,DS-8c83669d-21ea-4e70-bd9b-abe994cba016,DISK], DatanodeInfoWithStorage[127.0.0.1:44551,DS-65ad00fa-344d-4dfb-ae0e-1464a2b58329,DISK], DatanodeInfoWithStorage[127.0.0.1:39228,DS-8340eab9-c2e0-4ecc-bb69-9de5c4c676ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44377,DS-52522eef-4dc2-4585-a362-c3d0e4244b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:35278,DS-5864e6ed-28e0-4bd6-add4-963b303feddc,DISK], DatanodeInfoWithStorage[127.0.0.1:40986,DS-ba91cacc-dc7d-43d3-a876-80f6e6ca0348,DISK], DatanodeInfoWithStorage[127.0.0.1:34064,DS-a73f6f32-1ff4-40fe-9e53-aa988c6a5cf5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2085927385-172.17.0.21-1597686039205:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:37675,DS-2bb2cb59-fef0-4dac-95e9-5d65707d3a68,DISK], DatanodeInfoWithStorage[127.0.0.1:35774,DS-8c83669d-21ea-4e70-bd9b-abe994cba016,DISK], DatanodeInfoWithStorage[127.0.0.1:44551,DS-65ad00fa-344d-4dfb-ae0e-1464a2b58329,DISK], DatanodeInfoWithStorage[127.0.0.1:39228,DS-8340eab9-c2e0-4ecc-bb69-9de5c4c676ff,DISK], DatanodeInfoWithStorage[127.0.0.1:44377,DS-52522eef-4dc2-4585-a362-c3d0e4244b5d,DISK], DatanodeInfoWithStorage[127.0.0.1:35278,DS-5864e6ed-28e0-4bd6-add4-963b303feddc,DISK], DatanodeInfoWithStorage[127.0.0.1:40986,DS-ba91cacc-dc7d-43d3-a876-80f6e6ca0348,DISK], DatanodeInfoWithStorage[127.0.0.1:34064,DS-a73f6f32-1ff4-40fe-9e53-aa988c6a5cf5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is -1
v1v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2019561163-172.17.0.21-1597686749286:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40153,DS-7c0cd8b3-fd1c-4aa8-a24a-d9975cd60603,DISK], DatanodeInfoWithStorage[127.0.0.1:33093,DS-a67c3b76-b11b-4553-84cb-c8e06ec55ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:45059,DS-f69f5382-5a57-45f4-bba8-b4430088983d,DISK], DatanodeInfoWithStorage[127.0.0.1:38451,DS-09427d24-2c6b-4dcd-8d50-447f17d011b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39267,DS-b0def929-eb03-4f97-b9d9-fe3b60f99d05,DISK], DatanodeInfoWithStorage[127.0.0.1:34102,DS-bfa7d528-8419-487e-9510-51fbd23c305c,DISK], DatanodeInfoWithStorage[127.0.0.1:37205,DS-0b12f9c2-e0b3-4987-807b-43ecd7015aad,DISK], DatanodeInfoWithStorage[127.0.0.1:32979,DS-82749362-4416-4c00-a368-59bbec499c72,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2019561163-172.17.0.21-1597686749286:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40153,DS-7c0cd8b3-fd1c-4aa8-a24a-d9975cd60603,DISK], DatanodeInfoWithStorage[127.0.0.1:33093,DS-a67c3b76-b11b-4553-84cb-c8e06ec55ca8,DISK], DatanodeInfoWithStorage[127.0.0.1:45059,DS-f69f5382-5a57-45f4-bba8-b4430088983d,DISK], DatanodeInfoWithStorage[127.0.0.1:38451,DS-09427d24-2c6b-4dcd-8d50-447f17d011b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39267,DS-b0def929-eb03-4f97-b9d9-fe3b60f99d05,DISK], DatanodeInfoWithStorage[127.0.0.1:34102,DS-bfa7d528-8419-487e-9510-51fbd23c305c,DISK], DatanodeInfoWithStorage[127.0.0.1:37205,DS-0b12f9c2-e0b3-4987-807b-43ecd7015aad,DISK], DatanodeInfoWithStorage[127.0.0.1:32979,DS-82749362-4416-4c00-a368-59bbec499c72,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-278396618-172.17.0.21-1597687130170:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40778,DS-168c37c7-1196-4569-bada-20b6fa0dceb9,DISK], DatanodeInfoWithStorage[127.0.0.1:43530,DS-c06c8ce3-6eef-4bd2-af6d-9799b155736c,DISK], DatanodeInfoWithStorage[127.0.0.1:40365,DS-ee1b5ef8-7332-48e3-a689-06d4726f6a81,DISK], DatanodeInfoWithStorage[127.0.0.1:45746,DS-22447835-6c31-4ad0-8855-2548371985c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46077,DS-c0d22946-4b86-476a-8fa4-693cf2910809,DISK], DatanodeInfoWithStorage[127.0.0.1:44868,DS-5ec5fb02-be33-4fba-8756-7e1cd8ccc28b,DISK], DatanodeInfoWithStorage[127.0.0.1:43601,DS-94952330-64ab-4c91-a9c8-91783c3621e9,DISK], DatanodeInfoWithStorage[127.0.0.1:39121,DS-2979c867-d334-47a8-acfe-0c8c5a4844a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-278396618-172.17.0.21-1597687130170:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40778,DS-168c37c7-1196-4569-bada-20b6fa0dceb9,DISK], DatanodeInfoWithStorage[127.0.0.1:43530,DS-c06c8ce3-6eef-4bd2-af6d-9799b155736c,DISK], DatanodeInfoWithStorage[127.0.0.1:40365,DS-ee1b5ef8-7332-48e3-a689-06d4726f6a81,DISK], DatanodeInfoWithStorage[127.0.0.1:45746,DS-22447835-6c31-4ad0-8855-2548371985c9,DISK], DatanodeInfoWithStorage[127.0.0.1:46077,DS-c0d22946-4b86-476a-8fa4-693cf2910809,DISK], DatanodeInfoWithStorage[127.0.0.1:44868,DS-5ec5fb02-be33-4fba-8756-7e1cd8ccc28b,DISK], DatanodeInfoWithStorage[127.0.0.1:43601,DS-94952330-64ab-4c91-a9c8-91783c3621e9,DISK], DatanodeInfoWithStorage[127.0.0.1:39121,DS-2979c867-d334-47a8-acfe-0c8c5a4844a8,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1952681046-172.17.0.21-1597687727649:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40734,DS-20f8ccf0-ffbe-4c24-82c1-efbf6e1b9da5,DISK], DatanodeInfoWithStorage[127.0.0.1:44669,DS-f343317d-ed64-4a3c-8705-fdbf6fb88d75,DISK], DatanodeInfoWithStorage[127.0.0.1:42317,DS-7711b5af-a765-4518-af9f-82f63cdff8ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39082,DS-6adb5f17-2891-4caf-86ef-dd43cc0e383e,DISK], DatanodeInfoWithStorage[127.0.0.1:41496,DS-7f9a4e9d-52ea-4d31-b201-2767edb993b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39431,DS-a7ea8714-8304-46f8-9620-4ff2e2abe484,DISK], DatanodeInfoWithStorage[127.0.0.1:43734,DS-6193fa35-e4f7-49c9-b0d4-e5e5347aadf8,DISK], DatanodeInfoWithStorage[127.0.0.1:33894,DS-2ac568af-b297-40f0-ae0d-82095cdc8e2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1952681046-172.17.0.21-1597687727649:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:40734,DS-20f8ccf0-ffbe-4c24-82c1-efbf6e1b9da5,DISK], DatanodeInfoWithStorage[127.0.0.1:44669,DS-f343317d-ed64-4a3c-8705-fdbf6fb88d75,DISK], DatanodeInfoWithStorage[127.0.0.1:42317,DS-7711b5af-a765-4518-af9f-82f63cdff8ef,DISK], DatanodeInfoWithStorage[127.0.0.1:39082,DS-6adb5f17-2891-4caf-86ef-dd43cc0e383e,DISK], DatanodeInfoWithStorage[127.0.0.1:41496,DS-7f9a4e9d-52ea-4d31-b201-2767edb993b6,DISK], DatanodeInfoWithStorage[127.0.0.1:39431,DS-a7ea8714-8304-46f8-9620-4ff2e2abe484,DISK], DatanodeInfoWithStorage[127.0.0.1:43734,DS-6193fa35-e4f7-49c9-b0d4-e5e5347aadf8,DISK], DatanodeInfoWithStorage[127.0.0.1:33894,DS-2ac568af-b297-40f0-ae0d-82095cdc8e2a,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-989466150-172.17.0.21-1597688373559:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38008,DS-ac3d294e-471b-40a4-918a-16d36eed6ab0,DISK], DatanodeInfoWithStorage[127.0.0.1:45364,DS-845c5e72-c7f0-413f-89a9-0d70144cc1cb,DISK], DatanodeInfoWithStorage[127.0.0.1:42346,DS-309e7742-6fa6-4119-a3e7-c221bc7ea16a,DISK], DatanodeInfoWithStorage[127.0.0.1:32771,DS-abe11587-34fb-49d1-b6c5-b11ef909f082,DISK], DatanodeInfoWithStorage[127.0.0.1:36117,DS-e88c5c50-99bc-425b-987f-7ffdc1255ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:34783,DS-1a6be896-6582-497a-bf14-a88f0397d4c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36488,DS-f2eebdf3-3a4e-4e37-8771-1824142119e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41659,DS-fa16bd70-9a8b-4273-9594-fb7507045273,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-989466150-172.17.0.21-1597688373559:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:38008,DS-ac3d294e-471b-40a4-918a-16d36eed6ab0,DISK], DatanodeInfoWithStorage[127.0.0.1:45364,DS-845c5e72-c7f0-413f-89a9-0d70144cc1cb,DISK], DatanodeInfoWithStorage[127.0.0.1:42346,DS-309e7742-6fa6-4119-a3e7-c221bc7ea16a,DISK], DatanodeInfoWithStorage[127.0.0.1:32771,DS-abe11587-34fb-49d1-b6c5-b11ef909f082,DISK], DatanodeInfoWithStorage[127.0.0.1:36117,DS-e88c5c50-99bc-425b-987f-7ffdc1255ba8,DISK], DatanodeInfoWithStorage[127.0.0.1:34783,DS-1a6be896-6582-497a-bf14-a88f0397d4c9,DISK], DatanodeInfoWithStorage[127.0.0.1:36488,DS-f2eebdf3-3a4e-4e37-8771-1824142119e4,DISK], DatanodeInfoWithStorage[127.0.0.1:41659,DS-fa16bd70-9a8b-4273-9594-fb7507045273,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2132415343-172.17.0.21-1597688569245:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41120,DS-5a8ed25b-fcc7-4601-aa14-c0e7f55559b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37001,DS-d9046709-1aa4-413b-9049-6d1ca0c106ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34107,DS-dd1a9c4d-1f4a-4ce5-886e-03a074b49b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:39507,DS-2b70324e-c207-4130-b657-689d5550ec50,DISK], DatanodeInfoWithStorage[127.0.0.1:46055,DS-39dd1f5d-fe6d-4240-9f76-1017c3950221,DISK], DatanodeInfoWithStorage[127.0.0.1:46281,DS-13387757-cb56-4455-8006-91dcf5d47ce3,DISK], DatanodeInfoWithStorage[127.0.0.1:38618,DS-fa91a4f5-c5dc-42ad-8cdd-2380bfeb09a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37751,DS-11a29ab4-add9-4145-ad2d-4942916b2aac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-2132415343-172.17.0.21-1597688569245:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:41120,DS-5a8ed25b-fcc7-4601-aa14-c0e7f55559b3,DISK], DatanodeInfoWithStorage[127.0.0.1:37001,DS-d9046709-1aa4-413b-9049-6d1ca0c106ea,DISK], DatanodeInfoWithStorage[127.0.0.1:34107,DS-dd1a9c4d-1f4a-4ce5-886e-03a074b49b7f,DISK], DatanodeInfoWithStorage[127.0.0.1:39507,DS-2b70324e-c207-4130-b657-689d5550ec50,DISK], DatanodeInfoWithStorage[127.0.0.1:46055,DS-39dd1f5d-fe6d-4240-9f76-1017c3950221,DISK], DatanodeInfoWithStorage[127.0.0.1:46281,DS-13387757-cb56-4455-8006-91dcf5d47ce3,DISK], DatanodeInfoWithStorage[127.0.0.1:38618,DS-fa91a4f5-c5dc-42ad-8cdd-2380bfeb09a4,DISK], DatanodeInfoWithStorage[127.0.0.1:37751,DS-11a29ab4-add9-4145-ad2d-4942916b2aac,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-63437198-172.17.0.21-1597688831589:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42443,DS-4f39059f-8594-422b-846b-5b3129b071e5,DISK], DatanodeInfoWithStorage[127.0.0.1:37768,DS-39615429-37fb-4cf4-817f-5487190d2cc9,DISK], DatanodeInfoWithStorage[127.0.0.1:46553,DS-dbc7b75a-17ab-486a-962d-bf93c4eb25d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41527,DS-5fdc8c04-b37b-48f2-8c5e-cda93e53dd13,DISK], DatanodeInfoWithStorage[127.0.0.1:46413,DS-64e93c3e-145b-4d9a-9009-b5f4b38f025d,DISK], DatanodeInfoWithStorage[127.0.0.1:34645,DS-d2aa7f77-7a1e-40d2-9772-57d509333393,DISK], DatanodeInfoWithStorage[127.0.0.1:42801,DS-68572700-b080-4996-ab6e-e1c94713db31,DISK], DatanodeInfoWithStorage[127.0.0.1:42689,DS-adfc1e4a-896a-44c9-bd0c-7c224f7f42f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-63437198-172.17.0.21-1597688831589:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42443,DS-4f39059f-8594-422b-846b-5b3129b071e5,DISK], DatanodeInfoWithStorage[127.0.0.1:37768,DS-39615429-37fb-4cf4-817f-5487190d2cc9,DISK], DatanodeInfoWithStorage[127.0.0.1:46553,DS-dbc7b75a-17ab-486a-962d-bf93c4eb25d1,DISK], DatanodeInfoWithStorage[127.0.0.1:41527,DS-5fdc8c04-b37b-48f2-8c5e-cda93e53dd13,DISK], DatanodeInfoWithStorage[127.0.0.1:46413,DS-64e93c3e-145b-4d9a-9009-b5f4b38f025d,DISK], DatanodeInfoWithStorage[127.0.0.1:34645,DS-d2aa7f77-7a1e-40d2-9772-57d509333393,DISK], DatanodeInfoWithStorage[127.0.0.1:42801,DS-68572700-b080-4996-ab6e-e1c94713db31,DISK], DatanodeInfoWithStorage[127.0.0.1:42689,DS-adfc1e4a-896a-44c9-bd0c-7c224f7f42f5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-929857032-172.17.0.21-1597689474865:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35365,DS-ca88826f-effe-4e9b-9e20-7f8b4bd8c440,DISK], DatanodeInfoWithStorage[127.0.0.1:44720,DS-808c12da-2652-4de2-b1aa-736e57e36306,DISK], DatanodeInfoWithStorage[127.0.0.1:41911,DS-b627b35a-9acc-4553-9642-354c74a048f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42679,DS-0a8462c0-d57e-4a65-9508-5d58e0392032,DISK], DatanodeInfoWithStorage[127.0.0.1:34467,DS-77ad4c7e-6d6c-4b8d-82ce-7788121d3b89,DISK], DatanodeInfoWithStorage[127.0.0.1:41837,DS-74921b28-0331-496c-8568-5fc8b51bf421,DISK], DatanodeInfoWithStorage[127.0.0.1:35880,DS-e6bc2395-fc92-4900-8cb5-3ddd1e684569,DISK], DatanodeInfoWithStorage[127.0.0.1:44762,DS-225048cd-c165-46c2-a9a9-d285037661d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-929857032-172.17.0.21-1597689474865:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:35365,DS-ca88826f-effe-4e9b-9e20-7f8b4bd8c440,DISK], DatanodeInfoWithStorage[127.0.0.1:44720,DS-808c12da-2652-4de2-b1aa-736e57e36306,DISK], DatanodeInfoWithStorage[127.0.0.1:41911,DS-b627b35a-9acc-4553-9642-354c74a048f3,DISK], DatanodeInfoWithStorage[127.0.0.1:42679,DS-0a8462c0-d57e-4a65-9508-5d58e0392032,DISK], DatanodeInfoWithStorage[127.0.0.1:34467,DS-77ad4c7e-6d6c-4b8d-82ce-7788121d3b89,DISK], DatanodeInfoWithStorage[127.0.0.1:41837,DS-74921b28-0331-496c-8568-5fc8b51bf421,DISK], DatanodeInfoWithStorage[127.0.0.1:35880,DS-e6bc2395-fc92-4900-8cb5-3ddd1e684569,DISK], DatanodeInfoWithStorage[127.0.0.1:44762,DS-225048cd-c165-46c2-a9a9-d285037661d7,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1002942592-172.17.0.21-1597689862435:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42833,DS-44d923cb-5f9f-45df-b164-71f780ff0310,DISK], DatanodeInfoWithStorage[127.0.0.1:39482,DS-2be9c3fc-5d53-47bb-a1ae-ae6f0765cbc3,DISK], DatanodeInfoWithStorage[127.0.0.1:42581,DS-4305b19a-6570-45d2-b4d2-38cce1f73f5e,DISK], DatanodeInfoWithStorage[127.0.0.1:41252,DS-de66b70c-eefc-4a48-bd0e-d5153a34c9f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34803,DS-d72a374d-7706-45d0-934b-fa1dccd718b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41469,DS-aa9ee80f-abd9-43bf-97fa-bfef41974136,DISK], DatanodeInfoWithStorage[127.0.0.1:40312,DS-86cf9419-2eae-42ac-8da4-11b8b586f961,DISK], DatanodeInfoWithStorage[127.0.0.1:35317,DS-181f4c94-5af0-4c25-831b-05cada8faf0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1002942592-172.17.0.21-1597689862435:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:42833,DS-44d923cb-5f9f-45df-b164-71f780ff0310,DISK], DatanodeInfoWithStorage[127.0.0.1:39482,DS-2be9c3fc-5d53-47bb-a1ae-ae6f0765cbc3,DISK], DatanodeInfoWithStorage[127.0.0.1:42581,DS-4305b19a-6570-45d2-b4d2-38cce1f73f5e,DISK], DatanodeInfoWithStorage[127.0.0.1:41252,DS-de66b70c-eefc-4a48-bd0e-d5153a34c9f5,DISK], DatanodeInfoWithStorage[127.0.0.1:34803,DS-d72a374d-7706-45d0-934b-fa1dccd718b1,DISK], DatanodeInfoWithStorage[127.0.0.1:41469,DS-aa9ee80f-abd9-43bf-97fa-bfef41974136,DISK], DatanodeInfoWithStorage[127.0.0.1:40312,DS-86cf9419-2eae-42ac-8da4-11b8b586f961,DISK], DatanodeInfoWithStorage[127.0.0.1:35317,DS-181f4c94-5af0-4c25-831b-05cada8faf0d,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is -1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-266393539-172.17.0.21-1597690207234:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43812,DS-80d77f43-7a7d-4ee6-b3e5-cd93a505656b,DISK], DatanodeInfoWithStorage[127.0.0.1:35195,DS-1700a0f7-5051-48eb-8286-d7249a6b4bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:33650,DS-2e90d231-286e-4195-8152-cfed8eb9128f,DISK], DatanodeInfoWithStorage[127.0.0.1:46465,DS-a4ce9806-8345-469e-b8d1-c4b04af36e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:35306,DS-e4c0d9c8-e322-4d3f-b26e-bd2bd31cb4e0,DISK], DatanodeInfoWithStorage[127.0.0.1:39437,DS-0efcf72e-74c3-4ba1-a083-e657e784d672,DISK], DatanodeInfoWithStorage[127.0.0.1:45797,DS-424fa7ed-b5ce-4668-93a3-8990f61fe38a,DISK], DatanodeInfoWithStorage[127.0.0.1:35198,DS-da0b9178-5b07-46d4-b46d-9b7281a65ae5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-266393539-172.17.0.21-1597690207234:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43812,DS-80d77f43-7a7d-4ee6-b3e5-cd93a505656b,DISK], DatanodeInfoWithStorage[127.0.0.1:35195,DS-1700a0f7-5051-48eb-8286-d7249a6b4bb8,DISK], DatanodeInfoWithStorage[127.0.0.1:33650,DS-2e90d231-286e-4195-8152-cfed8eb9128f,DISK], DatanodeInfoWithStorage[127.0.0.1:46465,DS-a4ce9806-8345-469e-b8d1-c4b04af36e4c,DISK], DatanodeInfoWithStorage[127.0.0.1:35306,DS-e4c0d9c8-e322-4d3f-b26e-bd2bd31cb4e0,DISK], DatanodeInfoWithStorage[127.0.0.1:39437,DS-0efcf72e-74c3-4ba1-a083-e657e784d672,DISK], DatanodeInfoWithStorage[127.0.0.1:45797,DS-424fa7ed-b5ce-4668-93a3-8990f61fe38a,DISK], DatanodeInfoWithStorage[127.0.0.1:35198,DS-da0b9178-5b07-46d4-b46d-9b7281a65ae5,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)



Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is 1

Test vvMode=v2v2
tr.result is 1

Test vvMode=v1v2
tr.result is 1

Test vvMode=v1v1
tr.result is -1

Test vvMode=v2v2
tr.result is 1
v1v1 or v2v2 test failed !!!
reconf_parameter: dfs.block.scanner.volume.bytes.per.second
component: hdfs:DataNode
v1: 1048576
v2: 32768
testProject: hdfs
unitTest: org.apache.hadoop.hdfs.TestFileChecksumCompositeCrc#testStripedFileChecksumWithMissedDataBlocksRangeQuery4
reconfPoint: -3
result: -1
failureMessage: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1205645244-172.17.0.21-1597690777530:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43929,DS-47c5e378-334a-464e-b6cc-d9efca9ff59f,DISK], DatanodeInfoWithStorage[127.0.0.1:36654,DS-b5433216-201d-4ac4-bd71-01479e562f36,DISK], DatanodeInfoWithStorage[127.0.0.1:39921,DS-e05f8321-ca28-4ee5-b037-fa6c89ab040e,DISK], DatanodeInfoWithStorage[127.0.0.1:46744,DS-c3df6c79-2abb-4d79-ab1d-8338d6d4fd49,DISK], DatanodeInfoWithStorage[127.0.0.1:35156,DS-9f6a26fd-1f30-4bbd-b97e-06e79a64ddd3,DISK], DatanodeInfoWithStorage[127.0.0.1:45891,DS-b2abc6ba-88ec-4352-bf95-8b89cfe4e5e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33432,DS-3b9ed93f-330a-4428-9f33-f3e16b961696,DISK], DatanodeInfoWithStorage[127.0.0.1:35650,DS-c01c5272-ac87-4033-99d1-0f966029565c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
stackTrace: org.apache.hadoop.fs.PathIOException: `/striped/stripedFileChecksum1': Fail to get block checksum for LocatedStripedBlock{BP-1205645244-172.17.0.21-1597690777530:blk_-9223372036854775792_1001; getBlockSize()=37748736; corrupt=false; offset=0; locs=[DatanodeInfoWithStorage[127.0.0.1:43929,DS-47c5e378-334a-464e-b6cc-d9efca9ff59f,DISK], DatanodeInfoWithStorage[127.0.0.1:36654,DS-b5433216-201d-4ac4-bd71-01479e562f36,DISK], DatanodeInfoWithStorage[127.0.0.1:39921,DS-e05f8321-ca28-4ee5-b037-fa6c89ab040e,DISK], DatanodeInfoWithStorage[127.0.0.1:46744,DS-c3df6c79-2abb-4d79-ab1d-8338d6d4fd49,DISK], DatanodeInfoWithStorage[127.0.0.1:35156,DS-9f6a26fd-1f30-4bbd-b97e-06e79a64ddd3,DISK], DatanodeInfoWithStorage[127.0.0.1:45891,DS-b2abc6ba-88ec-4352-bf95-8b89cfe4e5e7,DISK], DatanodeInfoWithStorage[127.0.0.1:33432,DS-3b9ed93f-330a-4428-9f33-f3e16b961696,DISK], DatanodeInfoWithStorage[127.0.0.1:35650,DS-c01c5272-ac87-4033-99d1-0f966029565c,DISK]]; indices=[1, 2, 3, 4, 5, 6, 7, 8]}
	at org.apache.hadoop.hdfs.FileChecksumHelper$StripedFileNonStripedChecksumComputer.checksumBlocks(FileChecksumHelper.java:640)
	at org.apache.hadoop.hdfs.FileChecksumHelper$FileChecksumComputer.compute(FileChecksumHelper.java:252)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumInternal(DFSClient.java:1790)
	at org.apache.hadoop.hdfs.DFSClient.getFileChecksumWithCombineMode(DFSClient.java:1810)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1712)
	at org.apache.hadoop.hdfs.DistributedFileSystem$34.doCall(DistributedFileSystem.java:1709)
	at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81)
	at org.apache.hadoop.hdfs.DistributedFileSystem.getFileChecksum(DistributedFileSystem.java:1726)
	at org.apache.hadoop.hdfs.TestFileChecksum.getFileChecksum(TestFileChecksum.java:584)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery(TestFileChecksum.java:295)
	at org.apache.hadoop.hdfs.TestFileChecksum.testStripedFileChecksumWithMissedDataBlocksRangeQuery4(TestFileChecksum.java:344)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)
	at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)
	at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)
	at org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)
	at org.junit.internal.runners.statements.FailOnTimeout$StatementThread.run(FailOnTimeout.java:74)


v1v2 failed with probability 1 out of 50
v1v1v2v2 failed with probability 14 out of 50
result: false positive !!!
Total execution time in seconds : 5846
